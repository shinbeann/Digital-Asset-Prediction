{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(date_start)\n",
    "print(date_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 100 top symbols\n",
      "Fetching data for BTC/USDT\n",
      "✓ Collected 15 days of data for BTC/USDT\n",
      "Fetching data for ETH/USDT\n",
      "✓ Collected 15 days of data for ETH/USDT\n",
      "Fetching data for BNB/USDT\n",
      "✓ Collected 15 days of data for BNB/USDT\n",
      "Fetching data for NEO/USDT\n",
      "✓ Collected 15 days of data for NEO/USDT\n",
      "Fetching data for LTC/USDT\n",
      "✓ Collected 15 days of data for LTC/USDT\n",
      "Fetching data for QTUM/USDT\n",
      "✓ Collected 15 days of data for QTUM/USDT\n",
      "Fetching data for ADA/USDT\n",
      "✓ Collected 15 days of data for ADA/USDT\n",
      "Fetching data for XRP/USDT\n",
      "✓ Collected 15 days of data for XRP/USDT\n",
      "Fetching data for EOS/USDT\n",
      "✓ Collected 15 days of data for EOS/USDT\n",
      "Fetching data for TUSD/USDT\n",
      "✓ Collected 15 days of data for TUSD/USDT\n",
      "Fetching data for IOTA/USDT\n",
      "✓ Collected 15 days of data for IOTA/USDT\n",
      "Fetching data for XLM/USDT\n",
      "✓ Collected 15 days of data for XLM/USDT\n",
      "Fetching data for ONT/USDT\n",
      "✓ Collected 15 days of data for ONT/USDT\n",
      "Fetching data for TRX/USDT\n",
      "✓ Collected 15 days of data for TRX/USDT\n",
      "Fetching data for ETC/USDT\n",
      "✓ Collected 15 days of data for ETC/USDT\n",
      "Fetching data for ICX/USDT\n",
      "✓ Collected 15 days of data for ICX/USDT\n",
      "Fetching data for VET/USDT\n",
      "✓ Collected 15 days of data for VET/USDT\n",
      "Fetching data for USDC/USDT\n",
      "✓ Collected 15 days of data for USDC/USDT\n",
      "Fetching data for LINK/USDT\n",
      "✓ Collected 15 days of data for LINK/USDT\n",
      "Fetching data for ONG/USDT\n",
      "✓ Collected 15 days of data for ONG/USDT\n",
      "Fetching data for HOT/USDT\n",
      "✓ Collected 15 days of data for HOT/USDT\n",
      "Fetching data for ZIL/USDT\n",
      "✓ Collected 15 days of data for ZIL/USDT\n",
      "Fetching data for ZRX/USDT\n",
      "✓ Collected 15 days of data for ZRX/USDT\n",
      "Fetching data for FET/USDT\n",
      "✓ Collected 15 days of data for FET/USDT\n",
      "Fetching data for BAT/USDT\n",
      "✓ Collected 15 days of data for BAT/USDT\n",
      "Fetching data for ZEC/USDT\n",
      "✓ Collected 15 days of data for ZEC/USDT\n",
      "Fetching data for IOST/USDT\n",
      "✓ Collected 15 days of data for IOST/USDT\n",
      "Fetching data for CELR/USDT\n",
      "✓ Collected 15 days of data for CELR/USDT\n",
      "Fetching data for DASH/USDT\n",
      "✓ Collected 15 days of data for DASH/USDT\n",
      "Fetching data for THETA/USDT\n",
      "✓ Collected 15 days of data for THETA/USDT\n",
      "Fetching data for ENJ/USDT\n",
      "✓ Collected 15 days of data for ENJ/USDT\n",
      "Fetching data for ATOM/USDT\n",
      "✓ Collected 15 days of data for ATOM/USDT\n",
      "Fetching data for TFUEL/USDT\n",
      "✓ Collected 15 days of data for TFUEL/USDT\n",
      "Fetching data for ONE/USDT\n",
      "✓ Collected 15 days of data for ONE/USDT\n",
      "Fetching data for ALGO/USDT\n",
      "✓ Collected 15 days of data for ALGO/USDT\n",
      "Fetching data for DOGE/USDT\n",
      "✓ Collected 15 days of data for DOGE/USDT\n",
      "Fetching data for DUSK/USDT\n",
      "✓ Collected 15 days of data for DUSK/USDT\n",
      "Fetching data for ANKR/USDT\n",
      "✓ Collected 15 days of data for ANKR/USDT\n",
      "Fetching data for WIN/USDT\n",
      "✓ Collected 15 days of data for WIN/USDT\n",
      "Fetching data for COS/USDT\n",
      "✓ Collected 15 days of data for COS/USDT\n",
      "Fetching data for MTL/USDT\n",
      "✓ Collected 15 days of data for MTL/USDT\n",
      "Fetching data for DENT/USDT\n",
      "✓ Collected 15 days of data for DENT/USDT\n",
      "Fetching data for WAN/USDT\n",
      "✓ Collected 15 days of data for WAN/USDT\n",
      "Fetching data for FUN/USDT\n",
      "✓ Collected 15 days of data for FUN/USDT\n",
      "Fetching data for CVC/USDT\n",
      "✓ Collected 15 days of data for CVC/USDT\n",
      "Fetching data for CHZ/USDT\n",
      "✓ Collected 15 days of data for CHZ/USDT\n",
      "Fetching data for BAND/USDT\n",
      "✓ Collected 15 days of data for BAND/USDT\n",
      "Fetching data for XTZ/USDT\n",
      "✓ Collected 15 days of data for XTZ/USDT\n",
      "Fetching data for RVN/USDT\n",
      "✓ Collected 15 days of data for RVN/USDT\n",
      "Fetching data for HBAR/USDT\n",
      "✓ Collected 15 days of data for HBAR/USDT\n",
      "Fetching data for NKN/USDT\n",
      "✓ Collected 15 days of data for NKN/USDT\n",
      "Fetching data for STX/USDT\n",
      "✓ Collected 15 days of data for STX/USDT\n",
      "Fetching data for KAVA/USDT\n",
      "✓ Collected 15 days of data for KAVA/USDT\n",
      "Fetching data for ARPA/USDT\n",
      "✓ Collected 15 days of data for ARPA/USDT\n",
      "Fetching data for IOTX/USDT\n",
      "✓ Collected 15 days of data for IOTX/USDT\n",
      "Fetching data for RLC/USDT\n",
      "✓ Collected 15 days of data for RLC/USDT\n",
      "Fetching data for BCH/USDT\n",
      "✓ Collected 15 days of data for BCH/USDT\n",
      "Fetching data for FTT/USDT\n",
      "✓ Collected 15 days of data for FTT/USDT\n",
      "Fetching data for EUR/USDT\n",
      "✓ Collected 15 days of data for EUR/USDT\n",
      "Fetching data for OGN/USDT\n",
      "✓ Collected 15 days of data for OGN/USDT\n",
      "Fetching data for LSK/USDT\n",
      "✓ Collected 15 days of data for LSK/USDT\n",
      "Fetching data for BNT/USDT\n",
      "✓ Collected 15 days of data for BNT/USDT\n",
      "Fetching data for LTO/USDT\n",
      "✓ Collected 15 days of data for LTO/USDT\n",
      "Fetching data for MBL/USDT\n",
      "✓ Collected 15 days of data for MBL/USDT\n",
      "Fetching data for COTI/USDT\n",
      "✓ Collected 15 days of data for COTI/USDT\n",
      "Fetching data for STPT/USDT\n",
      "✓ Collected 15 days of data for STPT/USDT\n",
      "Fetching data for DATA/USDT\n",
      "✓ Collected 15 days of data for DATA/USDT\n",
      "Fetching data for SOL/USDT\n",
      "✓ Collected 15 days of data for SOL/USDT\n",
      "Fetching data for CTSI/USDT\n",
      "✓ Collected 15 days of data for CTSI/USDT\n",
      "Fetching data for HIVE/USDT\n",
      "✓ Collected 15 days of data for HIVE/USDT\n",
      "Fetching data for CHR/USDT\n",
      "✓ Collected 15 days of data for CHR/USDT\n",
      "Fetching data for ARDR/USDT\n",
      "✓ Collected 15 days of data for ARDR/USDT\n",
      "Fetching data for MDT/USDT\n",
      "✓ Collected 15 days of data for MDT/USDT\n",
      "Fetching data for KNC/USDT\n",
      "✓ Collected 15 days of data for KNC/USDT\n",
      "Fetching data for LRC/USDT\n",
      "✓ Collected 15 days of data for LRC/USDT\n",
      "Fetching data for COMP/USDT\n",
      "✓ Collected 15 days of data for COMP/USDT\n",
      "Fetching data for SC/USDT\n",
      "✓ Collected 15 days of data for SC/USDT\n",
      "Fetching data for ZEN/USDT\n",
      "✓ Collected 15 days of data for ZEN/USDT\n",
      "Fetching data for SNX/USDT\n",
      "✓ Collected 15 days of data for SNX/USDT\n",
      "Fetching data for VTHO/USDT\n",
      "✓ Collected 15 days of data for VTHO/USDT\n",
      "Fetching data for DGB/USDT\n",
      "✓ Collected 15 days of data for DGB/USDT\n",
      "Fetching data for SXP/USDT\n",
      "✓ Collected 15 days of data for SXP/USDT\n",
      "Fetching data for MKR/USDT\n",
      "✓ Collected 15 days of data for MKR/USDT\n",
      "Fetching data for DCR/USDT\n",
      "✓ Collected 15 days of data for DCR/USDT\n",
      "Fetching data for STORJ/USDT\n",
      "✓ Collected 15 days of data for STORJ/USDT\n",
      "Fetching data for MANA/USDT\n",
      "✓ Collected 15 days of data for MANA/USDT\n",
      "Fetching data for YFI/USDT\n",
      "✓ Collected 15 days of data for YFI/USDT\n",
      "Fetching data for KMD/USDT\n",
      "✓ Collected 15 days of data for KMD/USDT\n",
      "Fetching data for JST/USDT\n",
      "✓ Collected 15 days of data for JST/USDT\n",
      "Fetching data for CRV/USDT\n",
      "✓ Collected 15 days of data for CRV/USDT\n",
      "Fetching data for SAND/USDT\n",
      "✓ Collected 15 days of data for SAND/USDT\n",
      "Fetching data for NMR/USDT\n",
      "✓ Collected 15 days of data for NMR/USDT\n",
      "Fetching data for DOT/USDT\n",
      "✓ Collected 15 days of data for DOT/USDT\n",
      "Fetching data for LUNA/USDT\n",
      "✓ Collected 15 days of data for LUNA/USDT\n",
      "Fetching data for RSR/USDT\n",
      "✓ Collected 15 days of data for RSR/USDT\n",
      "Fetching data for PAXG/USDT\n",
      "✓ Collected 15 days of data for PAXG/USDT\n",
      "Fetching data for TRB/USDT\n",
      "✓ Collected 15 days of data for TRB/USDT\n",
      "Fetching data for SUSHI/USDT\n",
      "✓ Collected 15 days of data for SUSHI/USDT\n",
      "Fetching data for KSM/USDT\n",
      "✓ Collected 15 days of data for KSM/USDT\n",
      "Fetching data for EGLD/USDT\n",
      "✓ Collected 15 days of data for EGLD/USDT\n",
      "\n",
      "✅ Data collection complete. Saved to market_df\n",
      "Symbols collected: 100\n",
      "Total records: 1500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BinanceDataScraper:\n",
    "    def __init__(self, api_key=None, api_secret=None):\n",
    "        \"\"\"\n",
    "        Initialize Binance exchange connection\n",
    "        \n",
    "        Args:\n",
    "            api_key (str, optional): Binance API key from .env\n",
    "            api_secret (str, optional): Binance API secret from .env\n",
    "        \"\"\"\n",
    "        # Fetch keys from environment variables if not provided\n",
    "        api_key = api_key or os.getenv('KEY_1')\n",
    "        api_secret = api_secret or os.getenv('KEY_2')\n",
    "        \n",
    "        # Initialize exchange\n",
    "        self.exchange = ccxt.binance({\n",
    "            'apiKey': api_key,\n",
    "            'secret': api_secret,\n",
    "            'enableRateLimit': True,\n",
    "            'options': {\n",
    "                'defaultType': 'spot'  # Use spot market by default\n",
    "            }\n",
    "        })\n",
    "\n",
    "    def fetch_comprehensive_data(self, symbol):\n",
    "        \"\"\"\n",
    "        Fetch comprehensive cryptocurrency data\n",
    "        \n",
    "        Args:\n",
    "            symbol (str): Trading pair symbol (e.g., 'BTC/USDT')\n",
    "            start_date (str): Start date in YYYY-MM-DD format\n",
    "            end_date (str): End date in YYYY-MM-DD format\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: Comprehensive cryptocurrency data\n",
    "        \"\"\"\n",
    "        today = datetime.now()\n",
    "        yest = today - timedelta(days=1)\n",
    "        fifteen_days_ago = today - timedelta(days=15)\n",
    "\n",
    "        # Format dates\n",
    "        date_start = fifteen_days_ago.strftime(\"%Y-%m-%d\")\n",
    "        date_end = yest.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Convert dates to timestamps (in milliseconds)\n",
    "        start_timestamp = int(datetime.strptime(date_start, '%Y-%m-%d').timestamp() * 1000)\n",
    "        end_timestamp = int(datetime.strptime(date_end, '%Y-%m-%d').timestamp() * 1000)\n",
    "        \n",
    "        # Initialize empty list to store all OHLCV data\n",
    "        ohlcv_data = []\n",
    "        \n",
    "        # Fetch data in chunks to avoid API limitations\n",
    "        current_start = start_timestamp\n",
    "        while current_start < end_timestamp:\n",
    "            try:\n",
    "                # Fetch 500 candles at a time (Binance limit)\n",
    "                candles = self.exchange.fetch_ohlcv(\n",
    "                    symbol, \n",
    "                    timeframe='1d', \n",
    "                    since=current_start,\n",
    "                    limit=500\n",
    "                )\n",
    "                \n",
    "                # Break if no more data\n",
    "                if not candles:\n",
    "                    break\n",
    "                \n",
    "                # Add to data list\n",
    "                ohlcv_data.extend(candles)\n",
    "                \n",
    "                # Update start timestamp for next iteration\n",
    "                current_start = candles[-1][0] + 1\n",
    "                \n",
    "                # Respect rate limits\n",
    "                time.sleep(self.exchange.rateLimit / 1000)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {symbol}: {e}\")\n",
    "                break\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "        \n",
    "        # Convert timestamp to datetime and set as index\n",
    "        df['date'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        \n",
    "        # Calculate market cap (estimated using close price and volume)\n",
    "        # Note: This is a rough estimation and may not be entirely accurate\n",
    "        df['market_cap'] = df['close'] * df['volume']\n",
    "        \n",
    "        # Compute daily returns\n",
    "        df['daily_return'] = df['close'].pct_change()\n",
    "        \n",
    "        # Select and rename columns\n",
    "        result_df = df[['date', 'close', 'volume', 'market_cap', 'daily_return']].copy()\n",
    "        result_df.columns = ['date', 'price', 'volume', 'market_cap', 'daily_return']\n",
    "        \n",
    "        # Add asset column\n",
    "        result_df['asset'] = symbol  # Use base currency as asset name\n",
    "        \n",
    "        # Set date as index\n",
    "        result_df.set_index('date', inplace=True)\n",
    "        \n",
    "        # Filter date range\n",
    "        result_df = result_df.loc[date_start:date_end]\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    def fetch_top_symbols(self, limit=100):\n",
    "        \"\"\"\n",
    "        Fetch top trading symbols by volume\n",
    "        \n",
    "        Args:\n",
    "            limit (int): Number of top symbols to return\n",
    "        \n",
    "        Returns:\n",
    "            list: Top trading symbols\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load markets\n",
    "            self.exchange.load_markets()\n",
    "            \n",
    "            # Sort markets by daily volume\n",
    "            markets = sorted(\n",
    "                self.exchange.markets.values(), \n",
    "                key=lambda x: x.get('quote', 'USDT') == 'USDT' and x.get('active', False),\n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "            # Filter USDT pairs and get top symbols\n",
    "            usdt_pairs = [\n",
    "                market['symbol'] for market in markets \n",
    "                if market['quote'] == 'USDT' and market['active']\n",
    "            ]\n",
    "            \n",
    "            return usdt_pairs[:limit]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching top symbols: {e}\")\n",
    "            return []\n",
    "\n",
    "def main():\n",
    "    # Initialize scraper using environment variables\n",
    "    scraper = BinanceDataScraper()\n",
    "    \n",
    "    # Get top trading symbols\n",
    "    top_symbols = scraper.fetch_top_symbols(limit=100)\n",
    "    print(f\"Fetching data for {len(top_symbols)} top symbols\")\n",
    "    \n",
    "    # Dictionary to store all data\n",
    "    all_data = {}\n",
    "    \n",
    "    # Fetch data for each symbol\n",
    "    for symbol in top_symbols:\n",
    "        try:\n",
    "            print(f\"Fetching data for {symbol}\")\n",
    "            df = scraper.fetch_comprehensive_data(symbol)\n",
    "            \n",
    "            if not df.empty:\n",
    "                all_data[symbol] = df\n",
    "                print(f\"✓ Collected {len(df)} days of data for {symbol}\")\n",
    "            \n",
    "            # Optional: Add a small delay between symbol fetches\n",
    "            time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {e}\")\n",
    "    \n",
    "    # Combine all data\n",
    "    if all_data:\n",
    "        # Concatenate all dataframes\n",
    "        market_df = pd.concat(all_data.values())\n",
    "        \n",
    "        print(f\"\\n✅ Data collection complete. Saved to market_df\")\n",
    "        print(f\"Symbols collected: {len(all_data)}\")\n",
    "        print(f\"Total records: {len(market_df)}\")\n",
    "    else:\n",
    "        print(\"No data collected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
