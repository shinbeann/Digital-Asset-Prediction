{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2eb401c",
   "metadata": {},
   "source": [
    "# Demo Inference\n",
    "Use this notebook to load models in directly and evaluate them on the test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6eb29b",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae38d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247b76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Required Modules #\n",
    "####################\n",
    "\n",
    "# Generic/Built-in\n",
    "import random\n",
    "import sys \n",
    "import os\n",
    "\n",
    "# Libs\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d25ff7",
   "metadata": {},
   "source": [
    "The cell below sets up the environment by adding the projectâ€™s root directory to the system path and changing the current working directory, enabling imports from the `/src` folder. **This cell should only be ran once per session.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94b98c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Ryan Lee\\\\Desktop\\\\50.038 Computational Data Science\\\\Digital-Asset-Prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the project directory \n",
    "current_dir = os.path.abspath('') # Current '\\notebooks' directory\n",
    "project_dir = os.path.abspath(os.path.join(current_dir, '..')) # Move up one level to project root directory\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "# Move up to project directory\n",
    "os.chdir(project_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f299193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ryan Lee\\.conda\\envs\\term6\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    }
   ],
   "source": [
    "# Import custom modules\n",
    "from src.dataset import *\n",
    "from src.models import *\n",
    "from src.train_eval import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4182d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding\n",
    "SEED = 42\n",
    "\n",
    "# To be safe, seed all modules for full reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # If using CUDA\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2018acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c674c9e",
   "metadata": {},
   "source": [
    "## 2. Prepare Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3ac968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "TRAIN_PATH = \"data/processed/train_set.csv\" # We only need training set to get back our normalization statistics\n",
    "TEST_PATH = \"data/processed/test_set.csv\"\n",
    "\n",
    "# Hyperparameters\n",
    "INPUT_SEQUENCE_LENGTH = 14 # Number of timesteps (days) in input sequence\n",
    "DATASET_STRIDE = 1\n",
    "BATCH_SIZE = 256 # not important for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fcfb1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples (sequences)\n",
      "Test: 10000\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset object\n",
    "test_dataset = CryptoDataset(\n",
    "    csv_file=TEST_PATH,\n",
    "    seq_length=INPUT_SEQUENCE_LENGTH,\n",
    "    stride=DATASET_STRIDE\n",
    ")\n",
    "\n",
    "print(\"Total number of samples (sequences)\")\n",
    "print(\"Test:\", len(test_dataset))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626c8bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': tensor([ 4.7167e+02,  4.8263e+02,  4.6039e+02,  4.7177e+02,  4.3276e+08,\n",
       "          6.2134e+07,  2.2808e+00,  4.3239e+03, -4.2273e-01,  4.6805e+01,\n",
       "          1.9130e+03]),\n",
       " 'std': tensor([3.6570e+03, 3.7372e+03, 3.5740e+03, 3.6608e+03, 4.5931e+09, 4.1551e+08,\n",
       "         6.3604e+02, 4.3362e+02, 3.1840e-01, 2.0331e+01, 1.3954e+02])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to normalize our input data w.r.t training set\n",
    "train_dataset = CryptoDataset(\n",
    "    csv_file=TRAIN_PATH,\n",
    "    seq_length=INPUT_SEQUENCE_LENGTH,\n",
    "    stride=DATASET_STRIDE\n",
    ")\n",
    "normalizer = Normalizer()\n",
    "normalizer.fit(training_dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa41da",
   "metadata": {},
   "source": [
    "## 3. Load Model\n",
    "You can load in our trained model parameters from `/saved_models`. For your convenience, the model hyperparameters for those trained parameters have been set as the default for the model class constructors. If you wish to review information about the model's training, you can refer to `/results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45cc7310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CryptoTransformer(\n",
       "  (embedding): Linear(in_features=11, out_features=64, bias=True)\n",
       "  (positional_encoder): SinusoidalPositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "model = CryptoTransformer()\n",
    "\n",
    "# Load model parameters\n",
    "model_params_path = \"saved_models/CryptoTransformer/Best_R2.pth\" # Specify path to `pth` file here\n",
    "model.load_state_dict(torch.load(model_params_path))\n",
    "\n",
    "model.to(device) # Manually assign here - usually training code does this automatically for us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3201620",
   "metadata": {},
   "source": [
    "## 4. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6594c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9131190.9354, MAE: 377.2178, R2: 0.8958, Explained Variance: 0.8970\n"
     ]
    }
   ],
   "source": [
    "final_evaluation_loss, final_mae, final_r2, final_explained_var = evaluate_crypto_model(model, test_loader, normalizer)\n",
    "print(f\"Loss: {final_evaluation_loss:.4f}, MAE: {final_mae:.4f}, R2: {final_r2:.4f}, Explained Variance: {final_explained_var:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9dc8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pformat\n",
    "import textwrap\n",
    "\n",
    "# Save results\n",
    "base_dir = \"demo_results\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "file_name = f\"{type(model).__name__}_demo_results.txt\" # Feel free to change\n",
    "results_file = os.path.join(base_dir, file_name)\n",
    "    \n",
    "text = textwrap.dedent(f\"\"\"\\\n",
    "    {type(model).__name__}\n",
    "    [Test Results]\n",
    "    Loss: {final_evaluation_loss}\n",
    "    MAE: {final_mae}\n",
    "    R2: {final_r2}\n",
    "    Explained Variance: {final_explained_var}\n",
    "\"\"\")\n",
    "\n",
    "with open(results_file, \"w\") as f:\n",
    "    f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "term6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
