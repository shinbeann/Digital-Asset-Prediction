{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys \n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\CH585'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the project directory \n",
    "current_dir = os.path.abspath('') # Current '\\notebooks' directory\n",
    "project_dir = os.path.abspath(os.path.join(current_dir, '..')) # Move up one level to project root directory\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "# Move up to project directory\n",
    "os.chdir(project_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import *\n",
    "from src.dataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\CH585\\\\Documents\\\\T6\\\\CDS\\\\50.038 project\\\\data\\\\processed\\\\combined_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADA/USDT' 'ALGO/USDT' 'ANKR/USDT' 'ARDR/USDT' 'ARPA/USDT' 'ATOM/USDT'\n",
      " 'BAL/USDT' 'BAND/USDT' 'BAT/USDT' 'BCH/USDT' 'BNB/USDT' 'BNT/USDT'\n",
      " 'BTC/USDT' 'CELR/USDT' 'CHR/USDT' 'CHZ/USDT' 'COMP/USDT' 'COS/USDT'\n",
      " 'COTI/USDT' 'CRV/USDT' 'CTSI/USDT' 'CTXC/USDT' 'CVC/USDT' 'DASH/USDT'\n",
      " 'DATA/USDT' 'DCR/USDT' 'DENT/USDT' 'DGB/USDT' 'DOGE/USDT' 'DOT/USDT'\n",
      " 'DUSK/USDT' 'ENJ/USDT' 'EOS/USDT' 'ETC/USDT' 'ETH/USDT' 'EUR/USDT'\n",
      " 'FET/USDT' 'FTT/USDT' 'FUN/USDT' 'HBAR/USDT' 'HIVE/USDT' 'HOT/USDT'\n",
      " 'ICX/USDT' 'IOST/USDT' 'IOTA/USDT' 'IOTX/USDT' 'JST/USDT' 'KAVA/USDT'\n",
      " 'KMD/USDT' 'KNC/USDT' 'LINK/USDT' 'LRC/USDT' 'LSK/USDT' 'LTC/USDT'\n",
      " 'LTO/USDT' 'LUNA/USDT' 'MANA/USDT' 'MBL/USDT' 'MDT/USDT' 'MKR/USDT'\n",
      " 'MTL/USDT' 'NEO/USDT' 'NKN/USDT' 'NMR/USDT' 'NULS/USDT' 'OGN/USDT'\n",
      " 'ONE/USDT' 'ONG/USDT' 'ONT/USDT' 'PAXG/USDT' 'QTUM/USDT' 'RLC/USDT'\n",
      " 'RSR/USDT' 'RVN/USDT' 'SAND/USDT' 'SC/USDT' 'SNX/USDT' 'SOL/USDT'\n",
      " 'STORJ/USDT' 'STPT/USDT' 'STX/USDT' 'SXP/USDT' 'TFUEL/USDT' 'THETA/USDT'\n",
      " 'TROY/USDT' 'TRX/USDT' 'TUSD/USDT' 'USDC/USDT' 'VET/USDT' 'VTHO/USDT'\n",
      " 'WAN/USDT' 'WIN/USDT' 'XLM/USDT' 'XRP/USDT' 'XTZ/USDT' 'YFI/USDT'\n",
      " 'ZEC/USDT' 'ZEN/USDT' 'ZIL/USDT' 'ZRX/USDT']\n"
     ]
    }
   ],
   "source": [
    "unique_symbols = df['symbol'].unique()\n",
    "print(unique_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Days per symbol in final dataset:\n",
      "symbol\n",
      "ADA/USDT     14\n",
      "ALGO/USDT    14\n",
      "ANKR/USDT    14\n",
      "ARDR/USDT    14\n",
      "ARPA/USDT    14\n",
      "             ..\n",
      "YFI/USDT     14\n",
      "ZEC/USDT     14\n",
      "ZEN/USDT     14\n",
      "ZIL/USDT     14\n",
      "ZRX/USDT     14\n",
      "Length: 100, dtype: int64\n",
      "\n",
      "Successfully processed 100 out of 100 tickers\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your original dataframe\n",
    "df['date'] = pd.to_datetime(df['date'])  # Ensure date is datetime type\n",
    "df = df.sort_values(['symbol', 'date'])  # Sort by symbol and date\n",
    "\n",
    "# Function to get valid 14-day sequences ending on a specific date for a symbol\n",
    "def get_14day_sequence_ending_on(symbol_data, end_date):\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    start_date = end_date - pd.Timedelta(days=13)  # 14 days inclusive\n",
    "    \n",
    "    # Filter data for the date range\n",
    "    sequence = symbol_data[(symbol_data['date'] >= start_date) & \n",
    "                          (symbol_data['date'] <= end_date)]\n",
    "    \n",
    "    # Check if we have all 14 consecutive days\n",
    "    if len(sequence) == 14:\n",
    "        # Verify the dates are consecutive\n",
    "        date_diff = sequence['date'].diff().dropna()\n",
    "        if all(date_diff == pd.Timedelta(days=1)):\n",
    "            return sequence\n",
    "    return None\n",
    "\n",
    "# Manually specify your 20 tickers and prediction date\n",
    "selected_tickers = ['ADA/USDT', 'ALGO/USDT', 'ANKR/USDT', 'ARDR/USDT', 'ARPA/USDT', 'ATOM/USDT',\n",
    "    'BAL/USDT', 'BAND/USDT', 'BAT/USDT', 'BCH/USDT', 'BNB/USDT', 'BNT/USDT',\n",
    "    'BTC/USDT', 'CELR/USDT', 'CHR/USDT', 'CHZ/USDT', 'COMP/USDT', 'COS/USDT',\n",
    "    'COTI/USDT', 'CRV/USDT', 'CTSI/USDT', 'CTXC/USDT', 'CVC/USDT', 'DASH/USDT',\n",
    "    'DATA/USDT', 'DCR/USDT', 'DENT/USDT', 'DGB/USDT', 'DOGE/USDT', 'DOT/USDT',\n",
    "    'DUSK/USDT', 'ENJ/USDT', 'EOS/USDT', 'ETC/USDT', 'ETH/USDT', 'EUR/USDT',\n",
    "    'FET/USDT', 'FTT/USDT', 'FUN/USDT', 'HBAR/USDT', 'HIVE/USDT', 'HOT/USDT',\n",
    "    'ICX/USDT', 'IOST/USDT', 'IOTA/USDT', 'IOTX/USDT', 'JST/USDT', 'KAVA/USDT',\n",
    "    'KMD/USDT', 'KNC/USDT', 'LINK/USDT', 'LRC/USDT', 'LSK/USDT', 'LTC/USDT',\n",
    "    'LTO/USDT', 'LUNA/USDT', 'MANA/USDT', 'MBL/USDT', 'MDT/USDT', 'MKR/USDT',\n",
    "    'MTL/USDT', 'NEO/USDT', 'NKN/USDT', 'NMR/USDT', 'NULS/USDT', 'OGN/USDT',\n",
    "    'ONE/USDT', 'ONG/USDT', 'ONT/USDT', 'PAXG/USDT', 'QTUM/USDT', 'RLC/USDT',\n",
    "    'RSR/USDT', 'RVN/USDT', 'SAND/USDT', 'SC/USDT', 'SNX/USDT', 'SOL/USDT',\n",
    "    'STORJ/USDT', 'STPT/USDT', 'STX/USDT', 'SXP/USDT', 'TFUEL/USDT', 'THETA/USDT',\n",
    "    'TROY/USDT', 'TRX/USDT', 'TUSD/USDT', 'USDC/USDT', 'VET/USDT', 'VTHO/USDT',\n",
    "    'WAN/USDT', 'WIN/USDT', 'XLM/USDT', 'XRP/USDT', 'XTZ/USDT', 'YFI/USDT',\n",
    "    'ZEC/USDT', 'ZEN/USDT', 'ZIL/USDT', 'ZRX/USDT']\n",
    "\n",
    "prediction_date = '2025-03-24'  # I hard-coded this for now bc all of the values are valid for 14-days\n",
    "selected_sequences = []\n",
    "\n",
    "for ticker in selected_tickers:\n",
    "    # Get all data for this symbol\n",
    "    symbol_data = df[df['symbol'] == ticker].sort_values('date')\n",
    "    \n",
    "    # Get the 14-day sequence ending on prediction_date\n",
    "    sequence = get_14day_sequence_ending_on(symbol_data, prediction_date)\n",
    "    \n",
    "    if sequence is not None:\n",
    "        selected_sequences.append(sequence)\n",
    "    else:\n",
    "        print(f\"Warning: No valid 14-day sequence ending on {prediction_date} for {ticker}\")\n",
    "\n",
    "# Combine all valid sequences into one dataframe\n",
    "if selected_sequences:\n",
    "    final_df = pd.concat(selected_sequences)\n",
    "    \n",
    "    # Verify we have exactly 14 days per symbol\n",
    "    print(\"\\nDays per symbol in final dataset:\")\n",
    "    print(final_df.groupby('symbol').size())\n",
    "    \n",
    "    # Save to CSV if needed\n",
    "    final_df.to_csv(project_root/ '14day_new_crypto_sequences_custom.csv', index=False)\n",
    "    print(f\"\\nSuccessfully processed {len(selected_sequences)} out of {len(selected_tickers)} tickers\")\n",
    "else:\n",
    "    print(\"No valid sequences found for the selected tickers and date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionDataset(Dataset):\n",
    "    \"\"\"Dataset for making predictions on pre-processed 14-day windows\"\"\"\n",
    "    def __init__(self, df, feature_cols, target_col='close'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame containing the 14-day sequences\n",
    "            feature_cols: List of feature column names to use\n",
    "            target_col: Name of target column (default 'close')\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df) // 14  # Each sequence is 14 days\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * 14\n",
    "        end_idx = start_idx + 14\n",
    "        \n",
    "        # Get input sequence features\n",
    "        sequence = self.df.iloc[start_idx:end_idx][self.feature_cols].values\n",
    "        # Get target (next day's close price)\n",
    "        target = self.df.iloc[end_idx][self.target_col] if end_idx < len(self.df) else 0\n",
    "        \n",
    "        X = torch.tensor(sequence, dtype=torch.float32)\n",
    "        y = torch.tensor(target, dtype=torch.float32)\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_crypto_prices(df, transformer_model, informer_model, normalizer, batch_size=32):\n",
    "    \"\"\"\n",
    "    Make predictions using both Transformer and Informer models on 14-day crypto sequences.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing 14-day sequences for multiple cryptocurrencies\n",
    "        transformer_model: Loaded CryptoTransformer model\n",
    "        informer_model: Loaded CryptoInformer model\n",
    "        normalizer: Normalizer object fitted to training data\n",
    "        batch_size: Batch size for prediction\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with predictions from both models\n",
    "    \"\"\"\n",
    "    # Ensure models are in eval mode\n",
    "    transformer_model.eval()\n",
    "    informer_model.eval()\n",
    "    \n",
    "    # Get feature columns (exclude date and symbol)\n",
    "    feature_cols = [col for col in df.columns if col not in ['date', 'symbol']]\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = PredictionDataset(df, feature_cols)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Store predictions\n",
    "    transformer_preds = []\n",
    "    informer_preds = []\n",
    "    dates = []\n",
    "    symbols = []\n",
    "    actual_closes = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            seq_batch, target_batch = batch\n",
    "            \n",
    "            # Normalize inputs\n",
    "            seq_batch = normalizer(seq_batch)\n",
    "            \n",
    "            # Get predictions from both models\n",
    "            transformer_output = transformer_model(seq_batch)\n",
    "            informer_output = informer_model(seq_batch)\n",
    "            \n",
    "            transformer_preds.extend(transformer_output.numpy())\n",
    "            informer_preds.extend(informer_output.numpy())\n",
    "    \n",
    "    # Create prediction DataFrame\n",
    "    # We'll align predictions with the last day of each 14-day window\n",
    "    prediction_points = []\n",
    "    for i in range(len(transformer_preds)):\n",
    "        idx = (i + 1) * 14 - 1  # Last index of each window\n",
    "        if idx < len(df):\n",
    "            prediction_points.append(idx)\n",
    "    \n",
    "    result_df = df.iloc[prediction_points].copy()\n",
    "    result_df['transformer_pred'] = transformer_preds[:len(prediction_points)]\n",
    "    result_df['informer_pred'] = informer_preds[:len(prediction_points)]\n",
    "    \n",
    "    # Calculate next day's actual close if available\n",
    "    result_df['next_close'] = result_df['close'].shift(-1)\n",
    "    \n",
    "    return result_df[['date', 'symbol', 'close', 'next_close', 'transformer_pred', 'informer_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to crypto_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # base directory\n",
    "    project_root = Path(\"C:/Users/CH585/Documents/T6/CDS/50.038 project\") \n",
    "\n",
    "    # Load your models (as you've shown)\n",
    "    transformer_model_path =  project_root / \"saved_models\" / \"CryptoTransformer_2025-04-09_21-31-23\" / \"CryptoTransformer_BEST_R2.pth\"\n",
    "    informer_model_path = project_root / \"saved_models\" / \"CryptoInformer_2025-04-10_15-11-19\" / \"CryptoInformer_BEST_R2.pth\"\n",
    "    \n",
    "    transformer_model = CryptoTransformer()  \n",
    "    informer_model = CryptoInformer()\n",
    "    \n",
    "    transformer_model.load_state_dict(torch.load(transformer_model_path, map_location=torch.device('cpu')))\n",
    "    informer_model.load_state_dict(torch.load(informer_model_path, map_location=torch.device('cpu')))\n",
    "    \n",
    "    train_data_path = project_root / \"data\" / \"processed\" / \"combined_dataset_v1.csv\"\n",
    "    train_dataset = CryptoDataset(train_data_path)\n",
    "    normalizer = Normalizer()\n",
    "    normalizer.fit(train_dataset)\n",
    "\n",
    "    # Load your input DataFrame (14-day windows for top 20 cryptos)\n",
    "    df = pd.read_csv( project_root /'14day_new_crypto_sequences_custom.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(['symbol', 'date'])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions_df = predict_crypto_prices(df, transformer_model, informer_model, normalizer)\n",
    "    \n",
    "    # Save results\n",
    "    predictions_df.to_csv(\"crypto_predictions.csv\", index=False)\n",
    "    print(\"Predictions saved to crypto_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date     symbol       close  next_close  transformer_pred  \\\n",
      "13   2025-03-24   ADA/USDT     0.73200     0.20360         -8.037679   \n",
      "27   2025-03-24  ALGO/USDT     0.20360     0.02058         -6.783334   \n",
      "41   2025-03-24  ANKR/USDT     0.02058     0.06380         -8.259130   \n",
      "55   2025-03-24  ARDR/USDT     0.06380     0.02994         -6.551928   \n",
      "69   2025-03-24  ARPA/USDT     0.02994     4.95600         -7.115588   \n",
      "...         ...        ...         ...         ...               ...   \n",
      "1343 2025-03-24   YFI/USDT  5416.00000    32.44000       3040.845947   \n",
      "1357 2025-03-24   ZEC/USDT    32.44000     9.67000         -5.993320   \n",
      "1371 2025-03-24   ZEN/USDT     9.67000     0.01296         -6.404458   \n",
      "1385 2025-03-24   ZIL/USDT     0.01296     0.29140         -7.215162   \n",
      "1399 2025-03-24   ZRX/USDT     0.29140         NaN         -6.636563   \n",
      "\n",
      "      informer_pred  \n",
      "13         9.188528  \n",
      "27         6.038890  \n",
      "41         7.980579  \n",
      "55         5.727973  \n",
      "69         6.122960  \n",
      "...             ...  \n",
      "1343    4734.952148  \n",
      "1357       6.034493  \n",
      "1371       5.809328  \n",
      "1385       6.771086  \n",
      "1399       5.717358  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['percentage_increase'] = (predictions_df['informer_pred'] - predictions_df['close']) / predictions_df['close'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date     symbol       close  next_close  transformer_pred  \\\n",
      "13   2025-03-24   ADA/USDT     0.73200     0.20360         -8.037679   \n",
      "27   2025-03-24  ALGO/USDT     0.20360     0.02058         -6.783334   \n",
      "41   2025-03-24  ANKR/USDT     0.02058     0.06380         -8.259130   \n",
      "55   2025-03-24  ARDR/USDT     0.06380     0.02994         -6.551928   \n",
      "69   2025-03-24  ARPA/USDT     0.02994     4.95600         -7.115588   \n",
      "...         ...        ...         ...         ...               ...   \n",
      "1343 2025-03-24   YFI/USDT  5416.00000    32.44000       3040.845947   \n",
      "1357 2025-03-24   ZEC/USDT    32.44000     9.67000         -5.993320   \n",
      "1371 2025-03-24   ZEN/USDT     9.67000     0.01296         -6.404458   \n",
      "1385 2025-03-24   ZIL/USDT     0.01296     0.29140         -7.215162   \n",
      "1399 2025-03-24   ZRX/USDT     0.29140         NaN         -6.636563   \n",
      "\n",
      "      informer_pred  percentage_increase  \n",
      "13         9.188528          1155.263396  \n",
      "27         6.038890          2866.056170  \n",
      "41         7.980579         38678.323126  \n",
      "55         5.727973          8878.013335  \n",
      "69         6.122960         20350.766913  \n",
      "...             ...                  ...  \n",
      "1343    4734.952148           -12.574739  \n",
      "1357       6.034493           -81.397987  \n",
      "1371       5.809328           -39.924223  \n",
      "1385       6.771086         52146.035617  \n",
      "1399       5.717358          1862.030760  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predictions saved to 'final_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the total percentage increase\n",
    "total_percentage_increase = predictions_df['percentage_increase'].sum()\n",
    "\n",
    "# if total_percentage_increase == 0:\n",
    "#     raise ValueError(\"Total percentage increase is zero, cannot calculate proportion.\")\n",
    "\n",
    "# Calculate the proportion for each symbol\n",
    "predictions_df['proportion'] = predictions_df['percentage_increase'] / total_percentage_increase\n",
    "\n",
    "# Calculate the number of coins for each symbol\n",
    "predictions_df['percent_of_coins'] = (predictions_df['proportion'] * 100).round()\n",
    "\n",
    "# Adjust the number of coins to ensure the total is 100\n",
    "total_coins = predictions_df['percent_of_coins'].sum()\n",
    "\n",
    "if total_coins != 100:\n",
    "    # Find the symbol with the largest rounding error\n",
    "    max_error_symbol = predictions_df.loc[predictions_df['percent_of_coins'].idxmax(), 'symbol']\n",
    "    # Adjust the number of coins for the symbol with the largest rounding error\n",
    "    predictions_df.loc[predictions_df['symbol'] == max_error_symbol, 'percent_of_coins'] -= total_coins - 100\n",
    "\n",
    "# Verify that the total number of coins is 100\n",
    "total_coins = predictions_df['percent_of_coins'].sum()\n",
    "assert total_coins == 100, \"Total number of coins is not 100\"\n",
    "\n",
    "predictions_df.to_csv(project_root/'final_predictions.csv', index=False)\n",
    "\n",
    "print(\"Final predictions saved to 'final_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date     symbol       close  next_close  transformer_pred  \\\n",
      "13   2025-03-24   ADA/USDT     0.73200     0.20360         -8.037679   \n",
      "27   2025-03-24  ALGO/USDT     0.20360     0.02058         -6.783334   \n",
      "41   2025-03-24  ANKR/USDT     0.02058     0.06380         -8.259130   \n",
      "55   2025-03-24  ARDR/USDT     0.06380     0.02994         -6.551928   \n",
      "69   2025-03-24  ARPA/USDT     0.02994     4.95600         -7.115588   \n",
      "...         ...        ...         ...         ...               ...   \n",
      "1343 2025-03-24   YFI/USDT  5416.00000    32.44000       3040.845947   \n",
      "1357 2025-03-24   ZEC/USDT    32.44000     9.67000         -5.993320   \n",
      "1371 2025-03-24   ZEN/USDT     9.67000     0.01296         -6.404458   \n",
      "1385 2025-03-24   ZIL/USDT     0.01296     0.29140         -7.215162   \n",
      "1399 2025-03-24   ZRX/USDT     0.29140         NaN         -6.636563   \n",
      "\n",
      "      informer_pred  percentage_increase    proportion  percent_of_coins  \n",
      "13         9.188528          1155.263396  2.282873e-05               0.0  \n",
      "27         6.038890          2866.056170  5.663506e-05               0.0  \n",
      "41         7.980579         38678.323126  7.643078e-04               0.0  \n",
      "55         5.727973          8878.013335  1.754351e-04               0.0  \n",
      "69         6.122960         20350.766913  4.021439e-04               0.0  \n",
      "...             ...                  ...           ...               ...  \n",
      "1343    4734.952148           -12.574739 -2.484847e-07              -0.0  \n",
      "1357       6.034493           -81.397987 -1.608475e-06              -0.0  \n",
      "1371       5.809328           -39.924223 -7.889276e-07              -0.0  \n",
      "1385       6.771086         52146.035617  1.030438e-03               0.0  \n",
      "1399       5.717358          1862.030760  3.679489e-05               0.0  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
