{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys \n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\CH585\\\\Documents\\\\T6'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the project directory \n",
    "current_dir = os.path.abspath('') # Current '\\notebooks' directory\n",
    "project_dir = os.path.abspath(os.path.join(current_dir, '..')) # Move up one level to project root directory\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "# Move up to project directory\n",
    "os.chdir(project_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import *\n",
    "from src.dataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\CH585\\\\Documents\\\\T6\\\\CDS\\\\50.038 project\\\\data\\\\processed\\\\combined_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADA/USDT' 'ALGO/USDT' 'ANKR/USDT' 'ARDR/USDT' 'ARPA/USDT' 'ATOM/USDT'\n",
      " 'BAL/USDT' 'BAND/USDT' 'BAT/USDT' 'BCH/USDT' 'BNB/USDT' 'BNT/USDT'\n",
      " 'BTC/USDT' 'CELR/USDT' 'CHR/USDT' 'CHZ/USDT' 'COMP/USDT' 'COS/USDT'\n",
      " 'COTI/USDT' 'CRV/USDT' 'CTSI/USDT' 'CTXC/USDT' 'CVC/USDT' 'DASH/USDT'\n",
      " 'DATA/USDT' 'DCR/USDT' 'DENT/USDT' 'DGB/USDT' 'DOGE/USDT' 'DOT/USDT'\n",
      " 'DUSK/USDT' 'ENJ/USDT' 'EOS/USDT' 'ETC/USDT' 'ETH/USDT' 'EUR/USDT'\n",
      " 'FET/USDT' 'FTT/USDT' 'FUN/USDT' 'HBAR/USDT' 'HIVE/USDT' 'HOT/USDT'\n",
      " 'ICX/USDT' 'IOST/USDT' 'IOTA/USDT' 'IOTX/USDT' 'JST/USDT' 'KAVA/USDT'\n",
      " 'KMD/USDT' 'KNC/USDT' 'LINK/USDT' 'LRC/USDT' 'LSK/USDT' 'LTC/USDT'\n",
      " 'LTO/USDT' 'LUNA/USDT' 'MANA/USDT' 'MBL/USDT' 'MDT/USDT' 'MKR/USDT'\n",
      " 'MTL/USDT' 'NEO/USDT' 'NKN/USDT' 'NMR/USDT' 'NULS/USDT' 'OGN/USDT'\n",
      " 'ONE/USDT' 'ONG/USDT' 'ONT/USDT' 'PAXG/USDT' 'QTUM/USDT' 'RLC/USDT'\n",
      " 'RSR/USDT' 'RVN/USDT' 'SAND/USDT' 'SC/USDT' 'SNX/USDT' 'SOL/USDT'\n",
      " 'STORJ/USDT' 'STPT/USDT' 'STX/USDT' 'SXP/USDT' 'TFUEL/USDT' 'THETA/USDT'\n",
      " 'TROY/USDT' 'TRX/USDT' 'TUSD/USDT' 'USDC/USDT' 'VET/USDT' 'VTHO/USDT'\n",
      " 'WAN/USDT' 'WIN/USDT' 'XLM/USDT' 'XRP/USDT' 'XTZ/USDT' 'YFI/USDT'\n",
      " 'ZEC/USDT' 'ZEN/USDT' 'ZIL/USDT' 'ZRX/USDT']\n"
     ]
    }
   ],
   "source": [
    "unique_symbols = df['symbol'].unique()\n",
    "print(unique_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Days per symbol in final dataset:\n",
      "symbol\n",
      "ADA/USDT     14\n",
      "ALGO/USDT    14\n",
      "ANKR/USDT    14\n",
      "ARDR/USDT    14\n",
      "ARPA/USDT    14\n",
      "             ..\n",
      "YFI/USDT     14\n",
      "ZEC/USDT     14\n",
      "ZEN/USDT     14\n",
      "ZIL/USDT     14\n",
      "ZRX/USDT     14\n",
      "Length: 100, dtype: int64\n",
      "\n",
      "Successfully processed 100 out of 100 tickers\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your original dataframe\n",
    "df['date'] = pd.to_datetime(df['date'])  # Ensure date is datetime type\n",
    "df = df.sort_values(['symbol', 'date'])  # Sort by symbol and date\n",
    "\n",
    "# Function to get valid 14-day sequences ending on a specific date for a symbol\n",
    "def get_14day_sequence_ending_on(symbol_data, end_date):\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    start_date = end_date - pd.Timedelta(days=13)  # 14 days inclusive\n",
    "    \n",
    "    # Filter data for the date range\n",
    "    sequence = symbol_data[(symbol_data['date'] >= start_date) & \n",
    "                          (symbol_data['date'] <= end_date)]\n",
    "    \n",
    "    # Check if we have all 14 consecutive days\n",
    "    if len(sequence) == 14:\n",
    "        # Verify the dates are consecutive\n",
    "        date_diff = sequence['date'].diff().dropna()\n",
    "        if all(date_diff == pd.Timedelta(days=1)):\n",
    "            return sequence\n",
    "    return None\n",
    "\n",
    "# Manually specify your 20 tickers and prediction date\n",
    "selected_tickers = ['ADA/USDT', 'ALGO/USDT', 'ANKR/USDT', 'ARDR/USDT', 'ARPA/USDT', 'ATOM/USDT',\n",
    "    'BAL/USDT', 'BAND/USDT', 'BAT/USDT', 'BCH/USDT', 'BNB/USDT', 'BNT/USDT',\n",
    "    'BTC/USDT', 'CELR/USDT', 'CHR/USDT', 'CHZ/USDT', 'COMP/USDT', 'COS/USDT',\n",
    "    'COTI/USDT', 'CRV/USDT', 'CTSI/USDT', 'CTXC/USDT', 'CVC/USDT', 'DASH/USDT',\n",
    "    'DATA/USDT', 'DCR/USDT', 'DENT/USDT', 'DGB/USDT', 'DOGE/USDT', 'DOT/USDT',\n",
    "    'DUSK/USDT', 'ENJ/USDT', 'EOS/USDT', 'ETC/USDT', 'ETH/USDT', 'EUR/USDT',\n",
    "    'FET/USDT', 'FTT/USDT', 'FUN/USDT', 'HBAR/USDT', 'HIVE/USDT', 'HOT/USDT',\n",
    "    'ICX/USDT', 'IOST/USDT', 'IOTA/USDT', 'IOTX/USDT', 'JST/USDT', 'KAVA/USDT',\n",
    "    'KMD/USDT', 'KNC/USDT', 'LINK/USDT', 'LRC/USDT', 'LSK/USDT', 'LTC/USDT',\n",
    "    'LTO/USDT', 'LUNA/USDT', 'MANA/USDT', 'MBL/USDT', 'MDT/USDT', 'MKR/USDT',\n",
    "    'MTL/USDT', 'NEO/USDT', 'NKN/USDT', 'NMR/USDT', 'NULS/USDT', 'OGN/USDT',\n",
    "    'ONE/USDT', 'ONG/USDT', 'ONT/USDT', 'PAXG/USDT', 'QTUM/USDT', 'RLC/USDT',\n",
    "    'RSR/USDT', 'RVN/USDT', 'SAND/USDT', 'SC/USDT', 'SNX/USDT', 'SOL/USDT',\n",
    "    'STORJ/USDT', 'STPT/USDT', 'STX/USDT', 'SXP/USDT', 'TFUEL/USDT', 'THETA/USDT',\n",
    "    'TROY/USDT', 'TRX/USDT', 'TUSD/USDT', 'USDC/USDT', 'VET/USDT', 'VTHO/USDT',\n",
    "    'WAN/USDT', 'WIN/USDT', 'XLM/USDT', 'XRP/USDT', 'XTZ/USDT', 'YFI/USDT',\n",
    "    'ZEC/USDT', 'ZEN/USDT', 'ZIL/USDT', 'ZRX/USDT']\n",
    "\n",
    "prediction_date = '2025-03-24'  # I hard-coded this for now bc all of the values are valid for 14-days\n",
    "selected_sequences = []\n",
    "\n",
    "for ticker in selected_tickers:\n",
    "    # Get all data for this symbol\n",
    "    symbol_data = df[df['symbol'] == ticker].sort_values('date')\n",
    "    \n",
    "    # Get the 14-day sequence ending on prediction_date\n",
    "    sequence = get_14day_sequence_ending_on(symbol_data, prediction_date)\n",
    "    \n",
    "    if sequence is not None:\n",
    "        selected_sequences.append(sequence)\n",
    "    else:\n",
    "        print(f\"Warning: No valid 14-day sequence ending on {prediction_date} for {ticker}\")\n",
    "\n",
    "# Combine all valid sequences into one dataframe\n",
    "if selected_sequences:\n",
    "    final_df = pd.concat(selected_sequences)\n",
    "    \n",
    "    # Verify we have exactly 14 days per symbol\n",
    "    print(\"\\nDays per symbol in final dataset:\")\n",
    "    print(final_df.groupby('symbol').size())\n",
    "    \n",
    "    # Save to CSV if needed\n",
    "    final_df.to_csv('14day_crypto_sequences_custom.csv', index=False)\n",
    "    print(f\"\\nSuccessfully processed {len(selected_sequences)} out of {len(selected_tickers)} tickers\")\n",
    "else:\n",
    "    print(\"No valid sequences found for the selected tickers and date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionDataset(Dataset):\n",
    "    \"\"\"Dataset for making predictions on pre-processed 14-day windows\"\"\"\n",
    "    def __init__(self, df, feature_cols, target_col='close'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame containing the 14-day sequences\n",
    "            feature_cols: List of feature column names to use\n",
    "            target_col: Name of target column (default 'close')\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df) // 14  # Each sequence is 14 days\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * 14\n",
    "        end_idx = start_idx + 14\n",
    "        \n",
    "        # Get input sequence features\n",
    "        sequence = self.df.iloc[start_idx:end_idx][self.feature_cols].values\n",
    "        # Get target (next day's close price)\n",
    "        target = self.df.iloc[end_idx][self.target_col] if end_idx < len(self.df) else 0\n",
    "        \n",
    "        X = torch.tensor(sequence, dtype=torch.float32)\n",
    "        y = torch.tensor(target, dtype=torch.float32)\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_crypto_prices(df, transformer_model, informer_model, normalizer, batch_size=32):\n",
    "    \"\"\"\n",
    "    Make predictions using both Transformer and Informer models on 14-day crypto sequences.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing 14-day sequences for multiple cryptocurrencies\n",
    "        transformer_model: Loaded CryptoTransformer model\n",
    "        informer_model: Loaded CryptoInformer model\n",
    "        normalizer: Normalizer object fitted to training data\n",
    "        batch_size: Batch size for prediction\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with predictions from both models\n",
    "    \"\"\"\n",
    "    # Ensure models are in eval mode\n",
    "    transformer_model.eval()\n",
    "    informer_model.eval()\n",
    "    \n",
    "    # Get feature columns (exclude date and symbol)\n",
    "    feature_cols = [col for col in df.columns if col not in ['date', 'symbol']]\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = PredictionDataset(df, feature_cols)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Store predictions\n",
    "    transformer_preds = []\n",
    "    informer_preds = []\n",
    "    dates = []\n",
    "    symbols = []\n",
    "    actual_closes = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            seq_batch, target_batch = batch\n",
    "            \n",
    "            # Normalize inputs\n",
    "            seq_batch = normalizer(seq_batch)\n",
    "            \n",
    "            # Get predictions from both models\n",
    "            transformer_output = transformer_model(seq_batch)\n",
    "            informer_output = informer_model(seq_batch)\n",
    "            \n",
    "            transformer_preds.extend(transformer_output.numpy())\n",
    "            informer_preds.extend(informer_output.numpy())\n",
    "    \n",
    "    # Create prediction DataFrame\n",
    "    # We'll align predictions with the last day of each 14-day window\n",
    "    prediction_points = []\n",
    "    for i in range(len(transformer_preds)):\n",
    "        idx = (i + 1) * 14 - 1  # Last index of each window\n",
    "        if idx < len(df):\n",
    "            prediction_points.append(idx)\n",
    "    \n",
    "    result_df = df.iloc[prediction_points].copy()\n",
    "    result_df['transformer_pred'] = transformer_preds[:len(prediction_points)]\n",
    "    result_df['informer_pred'] = informer_preds[:len(prediction_points)]\n",
    "    \n",
    "    # Calculate next day's actual close if available\n",
    "    result_df['next_close'] = result_df['close'].shift(-1)\n",
    "    \n",
    "    return result_df[['date', 'symbol', 'close', 'next_close', 'transformer_pred', 'informer_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to crypto_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # base directory\n",
    "    project_root = Path(\"C:/Users/CH585/Documents/T6/CDS/50.038 project\") \n",
    "\n",
    "    # Load your models (as you've shown)\n",
    "    transformer_model_path =  project_root / \"saved_models\" / \"CryptoTransformer_2025-04-09_21-31-23\" / \"CryptoTransformer_BEST_R2.pth\"\n",
    "    informer_model_path = project_root / \"saved_models\" / \"CryptoInformer_2025-04-10_15-11-19\" / \"CryptoInformer_BEST_R2.pth\"\n",
    "    \n",
    "    transformer_model = CryptoTransformer()  \n",
    "    informer_model = CryptoInformer()\n",
    "    \n",
    "    transformer_model.load_state_dict(torch.load(transformer_model_path, map_location=torch.device('cpu')))\n",
    "    informer_model.load_state_dict(torch.load(informer_model_path, map_location=torch.device('cpu')))\n",
    "    \n",
    "    train_data_path = project_root / \"data\" / \"processed\" / \"combined_dataset_v1.csv\"\n",
    "    train_dataset = CryptoDataset(train_data_path)\n",
    "    normalizer = Normalizer()\n",
    "    normalizer.fit(train_dataset)\n",
    "\n",
    "    # Load your input DataFrame (14-day windows for top 20 cryptos)\n",
    "    df = pd.read_csv( project_root / \"14day_crypto_sequences.csv\")\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(['symbol', 'date'])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions_df = predict_crypto_prices(df, transformer_model, informer_model, normalizer)\n",
    "    \n",
    "    # Save results\n",
    "    predictions_df.to_csv(\"crypto_predictions.csv\", index=False)\n",
    "    print(\"Predictions saved to crypto_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date     symbol     close  next_close  transformer_pred  \\\n",
      "223 2022-04-06  ALGO/USDT   0.76610     0.07738         -3.402411   \n",
      "181 2022-04-06  ANKR/USDT   0.07738     0.21540         -3.641147   \n",
      "265 2022-04-06  ARDR/USDT   0.21540     0.49450         -3.384016   \n",
      "41  2022-04-06   CHR/USDT   0.49450     0.27320         -3.575358   \n",
      "83  2022-04-06  CTXC/USDT   0.27320     0.07859         -3.526537   \n",
      "195 2022-04-06  DATA/USDT   0.07859    58.70000         -3.677750   \n",
      "167 2022-04-06   DCR/USDT  58.70000     1.08800         -2.926291   \n",
      "237 2022-04-06   EUR/USDT   1.08800     0.73600         -3.337081   \n",
      "251 2022-04-06  IOTA/USDT   0.73600     0.96680         -3.359458   \n",
      "13  2022-04-06   LRC/USDT   0.96680     0.05448         -3.539123   \n",
      "209 2022-04-06   MDT/USDT   0.05448     0.23410         -3.630283   \n",
      "69  2022-04-06   NKN/USDT   0.23410     0.05914         -3.453273   \n",
      "55  2022-04-06   RVN/USDT   0.05914     5.38400         -3.891538   \n",
      "279 2022-04-06   SNX/USDT   5.38400     0.09623         -3.064423   \n",
      "125 2022-04-06  STPT/USDT   0.09623     1.25800         -3.393280   \n",
      "139 2022-04-06   STX/USDT   1.25800     0.99990         -3.372596   \n",
      "97  2022-04-06  USDC/USDT   0.99990     0.20310         -3.451716   \n",
      "111 2022-04-06   XLM/USDT   0.20310     0.75950         -3.525788   \n",
      "27  2022-04-06   XRP/USDT   0.75950    41.30000         -3.484027   \n",
      "153 2022-04-06   ZEN/USDT  41.30000         NaN         -3.024556   \n",
      "\n",
      "     informer_pred  percentage_increase  proportion  percent_of_coins  \n",
      "223     106.787575         13839.116926    0.013706               1.0  \n",
      "181      96.706627        124876.255999    0.123671              12.0  \n",
      "265     109.913879         50927.799162    0.050436               5.0  \n",
      "41      105.676331         21270.339852    0.021065               2.0  \n",
      "83      107.894897         39393.007855    0.039013               4.0  \n",
      "195     106.390289        135273.825304    0.133968              13.0  \n",
      "167     117.530792           100.222815    0.000099               0.0  \n",
      "237     106.707726          9707.695361    0.009614               1.0  \n",
      "251     108.668503         14664.742229    0.014523               1.0  \n",
      "13      101.761292         10425.578352    0.010325               1.0  \n",
      "209     100.901535        185108.397640    0.183322              20.0  \n",
      "69      108.542343         46265.802281    0.045819               5.0  \n",
      "55       95.591888        161536.605390    0.159978              16.0  \n",
      "279     109.453766          1932.945131    0.001914               0.0  \n",
      "125     108.687523        112845.570912    0.111757              11.0  \n",
      "139     109.984894          8642.837345    0.008559               1.0  \n",
      "97       99.407593          9841.753453    0.009747               1.0  \n",
      "111     102.389473         50313.329868    0.049828               5.0  \n",
      "27       96.446663         12598.704793    0.012477               1.0  \n",
      "153     115.729004           180.215506    0.000178               0.0  \n"
     ]
    }
   ],
   "source": [
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['percentage_increase'] = (predictions_df['informer_pred'] - predictions_df['close']) / predictions_df['close'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date     symbol     close  next_close  transformer_pred  \\\n",
      "223 2022-04-06  ALGO/USDT   0.76610     0.07738         -3.402411   \n",
      "181 2022-04-06  ANKR/USDT   0.07738     0.21540         -3.641147   \n",
      "265 2022-04-06  ARDR/USDT   0.21540     0.49450         -3.384016   \n",
      "41  2022-04-06   CHR/USDT   0.49450     0.27320         -3.575358   \n",
      "83  2022-04-06  CTXC/USDT   0.27320     0.07859         -3.526537   \n",
      "195 2022-04-06  DATA/USDT   0.07859    58.70000         -3.677750   \n",
      "167 2022-04-06   DCR/USDT  58.70000     1.08800         -2.926291   \n",
      "237 2022-04-06   EUR/USDT   1.08800     0.73600         -3.337081   \n",
      "251 2022-04-06  IOTA/USDT   0.73600     0.96680         -3.359458   \n",
      "13  2022-04-06   LRC/USDT   0.96680     0.05448         -3.539123   \n",
      "209 2022-04-06   MDT/USDT   0.05448     0.23410         -3.630283   \n",
      "69  2022-04-06   NKN/USDT   0.23410     0.05914         -3.453273   \n",
      "55  2022-04-06   RVN/USDT   0.05914     5.38400         -3.891538   \n",
      "279 2022-04-06   SNX/USDT   5.38400     0.09623         -3.064423   \n",
      "125 2022-04-06  STPT/USDT   0.09623     1.25800         -3.393280   \n",
      "139 2022-04-06   STX/USDT   1.25800     0.99990         -3.372596   \n",
      "97  2022-04-06  USDC/USDT   0.99990     0.20310         -3.451716   \n",
      "111 2022-04-06   XLM/USDT   0.20310     0.75950         -3.525788   \n",
      "27  2022-04-06   XRP/USDT   0.75950    41.30000         -3.484027   \n",
      "153 2022-04-06   ZEN/USDT  41.30000         NaN         -3.024556   \n",
      "\n",
      "     informer_pred  percentage_increase  \n",
      "223     106.787575         13839.116926  \n",
      "181      96.706627        124876.255999  \n",
      "265     109.913879         50927.799162  \n",
      "41      105.676331         21270.339852  \n",
      "83      107.894897         39393.007855  \n",
      "195     106.390289        135273.825304  \n",
      "167     117.530792           100.222815  \n",
      "237     106.707726          9707.695361  \n",
      "251     108.668503         14664.742229  \n",
      "13      101.761292         10425.578352  \n",
      "209     100.901535        185108.397640  \n",
      "69      108.542343         46265.802281  \n",
      "55       95.591888        161536.605390  \n",
      "279     109.453766          1932.945131  \n",
      "125     108.687523        112845.570912  \n",
      "139     109.984894          8642.837345  \n",
      "97       99.407593          9841.753453  \n",
      "111     102.389473         50313.329868  \n",
      "27       96.446663         12598.704793  \n",
      "153     115.729004           180.215506  \n"
     ]
    }
   ],
   "source": [
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predictions saved to 'final_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the total percentage increase\n",
    "total_percentage_increase = predictions_df['percentage_increase'].sum()\n",
    "\n",
    "# if total_percentage_increase == 0:\n",
    "#     raise ValueError(\"Total percentage increase is zero, cannot calculate proportion.\")\n",
    "\n",
    "# Calculate the proportion for each symbol\n",
    "predictions_df['proportion'] = predictions_df['percentage_increase'] / total_percentage_increase\n",
    "\n",
    "# Calculate the number of coins for each symbol\n",
    "predictions_df['percent_of_coins'] = (predictions_df['proportion'] * 100).round()\n",
    "\n",
    "# Adjust the number of coins to ensure the total is 100\n",
    "total_coins = predictions_df['percent_of_coins'].sum()\n",
    "\n",
    "if total_coins != 100:\n",
    "    # Find the symbol with the largest rounding error\n",
    "    max_error_symbol = predictions_df.loc[predictions_df['percent_of_coins'].idxmax(), 'symbol']\n",
    "    # Adjust the number of coins for the symbol with the largest rounding error\n",
    "    predictions_df.loc[predictions_df['symbol'] == max_error_symbol, 'percent_of_coins'] -= total_coins - 100\n",
    "\n",
    "# Verify that the total number of coins is 100\n",
    "total_coins = predictions_df['percent_of_coins'].sum()\n",
    "assert total_coins == 100, \"Total number of coins is not 100\"\n",
    "\n",
    "predictions_df.to_csv(project_root/'final_predictions.csv', index=False)\n",
    "\n",
    "print(\"Final predictions saved to 'final_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date     symbol     close  next_close  transformer_pred  \\\n",
      "223 2022-04-06  ALGO/USDT   0.76610     0.07738         -3.402411   \n",
      "181 2022-04-06  ANKR/USDT   0.07738     0.21540         -3.641147   \n",
      "265 2022-04-06  ARDR/USDT   0.21540     0.49450         -3.384016   \n",
      "41  2022-04-06   CHR/USDT   0.49450     0.27320         -3.575358   \n",
      "83  2022-04-06  CTXC/USDT   0.27320     0.07859         -3.526537   \n",
      "195 2022-04-06  DATA/USDT   0.07859    58.70000         -3.677750   \n",
      "167 2022-04-06   DCR/USDT  58.70000     1.08800         -2.926291   \n",
      "237 2022-04-06   EUR/USDT   1.08800     0.73600         -3.337081   \n",
      "251 2022-04-06  IOTA/USDT   0.73600     0.96680         -3.359458   \n",
      "13  2022-04-06   LRC/USDT   0.96680     0.05448         -3.539123   \n",
      "209 2022-04-06   MDT/USDT   0.05448     0.23410         -3.630283   \n",
      "69  2022-04-06   NKN/USDT   0.23410     0.05914         -3.453273   \n",
      "55  2022-04-06   RVN/USDT   0.05914     5.38400         -3.891538   \n",
      "279 2022-04-06   SNX/USDT   5.38400     0.09623         -3.064423   \n",
      "125 2022-04-06  STPT/USDT   0.09623     1.25800         -3.393280   \n",
      "139 2022-04-06   STX/USDT   1.25800     0.99990         -3.372596   \n",
      "97  2022-04-06  USDC/USDT   0.99990     0.20310         -3.451716   \n",
      "111 2022-04-06   XLM/USDT   0.20310     0.75950         -3.525788   \n",
      "27  2022-04-06   XRP/USDT   0.75950    41.30000         -3.484027   \n",
      "153 2022-04-06   ZEN/USDT  41.30000         NaN         -3.024556   \n",
      "\n",
      "     informer_pred  percentage_increase  proportion  percent_of_coins  \n",
      "223     106.787575         13839.116926    0.013706               1.0  \n",
      "181      96.706627        124876.255999    0.123671              12.0  \n",
      "265     109.913879         50927.799162    0.050436               5.0  \n",
      "41      105.676331         21270.339852    0.021065               2.0  \n",
      "83      107.894897         39393.007855    0.039013               4.0  \n",
      "195     106.390289        135273.825304    0.133968              13.0  \n",
      "167     117.530792           100.222815    0.000099               0.0  \n",
      "237     106.707726          9707.695361    0.009614               1.0  \n",
      "251     108.668503         14664.742229    0.014523               1.0  \n",
      "13      101.761292         10425.578352    0.010325               1.0  \n",
      "209     100.901535        185108.397640    0.183322              20.0  \n",
      "69      108.542343         46265.802281    0.045819               5.0  \n",
      "55       95.591888        161536.605390    0.159978              16.0  \n",
      "279     109.453766          1932.945131    0.001914               0.0  \n",
      "125     108.687523        112845.570912    0.111757              11.0  \n",
      "139     109.984894          8642.837345    0.008559               1.0  \n",
      "97       99.407593          9841.753453    0.009747               1.0  \n",
      "111     102.389473         50313.329868    0.049828               5.0  \n",
      "27       96.446663         12598.704793    0.012477               1.0  \n",
      "153     115.729004           180.215506    0.000178               0.0  \n"
     ]
    }
   ],
   "source": [
    "print(predictions_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
