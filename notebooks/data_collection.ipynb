{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 737, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/vr/qwxtvrr17fn2qzlm0z4rq4br0000gn/T/ipykernel_11167/3527346051.py\", line 10, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Required Modules #\n",
    "####################\n",
    "\n",
    "# Generic/Built-in\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Libs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aishwaryaiyer/Documents/GitHub/Digital-Asset-Prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the project directory \n",
    "current_dir = os.path.abspath('') # Current '\\notebooks' directory\n",
    "project_dir = os.path.abspath(os.path.join(current_dir, '..')) # Move up one level to project root directory\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "# Move up to project directory\n",
    "os.chdir(project_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load in environment variables from `.env` file.\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FRED Data\n",
    "The **Federal Reserve Economic Data (FRED)** is an online database maintained by the research department at the Federal Reserve Bank of St. Louis. It provides a wide range of economic time series data.\n",
    "\n",
    "- The [FRED API](https://fred.stlouisfed.org/docs/api/fred/) will be used to retrieve the necessary datasets. An API key can be requested for free. Ensure that your API key is set by specifying it in the `FRED_API_KEY` environment variable.\n",
    "- Alternatively, the datasets can be downloaded directly from the website itself without making an account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_collection.data_scraper import fetch_data_from_fred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. 10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity\n",
    "The **10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity** spread measures the difference between long-term (10-year) and short-term (2-year) U.S. Treasury bond yields. A positive spread indicates a normal yield curve, suggesting confidence in economic growth, while a negative spread (inverted curve) may signal market concerns about an economic slowdown or impending recession.\n",
    "\n",
    "As a macro-economic indicator, this spread can be used in crypto price prediction by reflecting investor sentiment and economic expectations. A widening spread may indicate optimism, which could drive higher demand for risk assets like cryptocurrencies, while an inverted spread could signal economic uncertainty, potentially leading to market volatility and lower crypto prices.\n",
    "\n",
    "**Citation**:\n",
    "\n",
    "Federal Reserve Bank of St. Louis, 10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity [T10Y2Y], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/T10Y2Y, March 25, 2025. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data from FRED API: 400 Client Error: Bad Request for url: https://api.stlouisfed.org/fred/series/observations?series_id=T10Y2Y&observation_start=2019-09-08&observation_end=2025-04-04&file_type=json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = \"data/raw/treasury_constant_maturity_spread.csv\"\n",
    "\n",
    "df_t10y2y = fetch_data_from_fred(\n",
    "    series_id=\"T10Y2Y\",\n",
    "    start_date=\"2019-09-08\",\n",
    "    end_date=\"2025-04-04\",\n",
    "    output_filename=output_file\n",
    ")\n",
    "\n",
    "df_t10y2y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. S&P 500\n",
    "The observations for the S&P 500 represent the daily index value at market close. The market typically closes at 4 PM ET, except for holidays when it sometimes closes early.\n",
    "\n",
    "The Federal Reserve Bank of St. Louis and S&P Dow Jones Indices LLC have reached a new agreement on the use of Standard & Poors and Dow Jones Averages series in FRED. FRED and its associated services will include 10 years of daily history for Standard & Poors and Dow Jones Averages series.\n",
    "\n",
    "The S&P 500 is regarded as a gauge of the large cap U.S. equities market. The index includes 500 leading companies in leading industries of the U.S. economy, which are publicly held on either the NYSE or NASDAQ, and covers 75% of U.S. equities. Since this is a price index and not a total return index, the S&P 500 index here does not contain dividends. \n",
    "\n",
    "**Citation**:\n",
    "\n",
    "S&P Dow Jones Indices LLC, S&P 500 [SP500], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/SP500, March 27, 2025. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data from FRED API: 400 Client Error: Bad Request for url: https://api.stlouisfed.org/fred/series/observations?series_id=SP500&observation_start=2019-09-08&observation_end=2025-04-04&file_type=json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = \"data/raw/sp500.csv\"\n",
    "\n",
    "df_sp500 = fetch_data_from_fred(\n",
    "    series_id=\"SP500\",\n",
    "    start_date=\"2019-09-08\",\n",
    "    end_date=\"2025-04-04\",\n",
    "    output_filename=output_file\n",
    ")\n",
    "\n",
    "df_sp500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CoinGecko Data\n",
    "CoinGecko is a leading independent cryptocurrency data aggregator that provides comprehensive information on over 17,000 crypto assets and 1,200+ exchanges.\n",
    "- For the data we are scraping, we do **not** need any API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching top 2 cryptocurrency assets by market cap...\n",
      "Found 2 assets\n",
      "[1/2] Fetching daily data for bitcoin...\n",
      "✅ Successfully fetched 366 days of data for bitcoin\n",
      "Waiting 6 seconds to avoid API rate limits...\n",
      "[2/2] Fetching daily data for ethereum...\n",
      "✅ Successfully fetched 366 days of data for ethereum\n",
      "Waiting 3 seconds to avoid API rate limits...\n",
      "\n",
      "Combining data from all assets...\n",
      "\n",
      "✅ Daily data collection complete! Data saved as 'data/raw/top_crypto_daily_data.csv'.\n",
      "\n",
      "Summary:\n",
      "- Successfully collected data for 2 cryptocurrencies\n",
      "- Total records: 732\n",
      "- Date range: 2024-04-21 to 2025-04-20\n"
     ]
    }
   ],
   "source": [
    "from src.data_collection.data_scraper import fetch_top_crypto_data_from_coingecko\n",
    "\n",
    "df_top_crypto_data = fetch_top_crypto_data_from_coingecko(\n",
    "    limit=2,\n",
    "    vs_currency=\"usd\",\n",
    "    days=365,\n",
    "    output_filename=\"data/raw/top_crypto_daily_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binance Market Data\n",
    "Using Binance data, we will be collecting Close, Volume, Market Cap and Daily_return for each day from from 2022-03-24 to 2025-03-24\n",
    "- API key is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ccxt\n",
      "  Downloading ccxt-4.4.75-py2.py3-none-any.whl.metadata (131 kB)\n",
      "Requirement already satisfied: setuptools>=60.9.0 in /Users/aishwaryaiyer/Library/Python/3.11/lib/python/site-packages (from ccxt) (68.2.1)\n",
      "Requirement already satisfied: certifi>=2018.1.18 in /Users/aishwaryaiyer/Library/Python/3.11/lib/python/site-packages (from ccxt) (2023.7.22)\n",
      "Requirement already satisfied: requests>=2.18.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ccxt) (2.31.0)\n",
      "Requirement already satisfied: cryptography>=2.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ccxt) (42.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ccxt) (4.10.0)\n",
      "Requirement already satisfied: aiohttp<=3.10.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ccxt) (3.8.6)\n",
      "Collecting aiodns>=1.1.1 (from ccxt)\n",
      "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: yarl>=1.7.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ccxt) (1.9.2)\n",
      "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt)\n",
      "  Downloading pycares-4.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<=3.10.11->ccxt) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<=3.10.11->ccxt) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<=3.10.11->ccxt) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<=3.10.11->ccxt) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<=3.10.11->ccxt) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<=3.10.11->ccxt) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cryptography>=2.6.1->ccxt) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.18.4->ccxt) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.18.4->ccxt) (2.0.6)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt) (2.21)\n",
      "Downloading ccxt-4.4.75-py2.py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
      "Downloading pycares-4.6.0-cp311-cp311-macosx_11_0_arm64.whl (72 kB)\n",
      "Installing collected packages: pycares, aiodns, ccxt\n",
      "Successfully installed aiodns-3.2.0 ccxt-4.4.75 pycares-4.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ccxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "class BinanceDataScraper:\n",
    "    def __init__(self, api_key=None, api_secret=None):\n",
    "        \"\"\"\n",
    "        Initialize Binance exchange connection\n",
    "        \n",
    "        Args:\n",
    "            api_key (str, optional): Binance API key from .env\n",
    "            api_secret (str, optional): Binance API secret from .env\n",
    "        \"\"\"\n",
    "        # Fetch keys from environment variables if not provided\n",
    "        api_key = api_key or os.getenv('KEY_1')\n",
    "        api_secret = api_secret or os.getenv('KEY_2')\n",
    "        \n",
    "        # Initialize exchange\n",
    "        self.exchange = ccxt.binance({\n",
    "            'apiKey': api_key,\n",
    "            'secret': api_secret,\n",
    "            'enableRateLimit': True,\n",
    "            'options': {\n",
    "                'defaultType': 'spot'  # Use spot market by default\n",
    "            }\n",
    "        })\n",
    "\n",
    "    def fetch_comprehensive_data(self, \n",
    "                                  symbol, \n",
    "                                  start_date='2022-03-24', \n",
    "                                  end_date='2025-03-24'):\n",
    "        \"\"\"\n",
    "        Fetch comprehensive cryptocurrency data\n",
    "        \n",
    "        Args:\n",
    "            symbol (str): Trading pair symbol (e.g., 'BTC/USDT')\n",
    "            start_date (str): Start date in YYYY-MM-DD format\n",
    "            end_date (str): End date in YYYY-MM-DD format\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: Comprehensive cryptocurrency data\n",
    "        \"\"\"\n",
    "        # Convert dates to timestamps\n",
    "        start_timestamp = int(datetime.strptime(start_date, '%Y-%m-%d').timestamp() * 1000)\n",
    "        end_timestamp = int(datetime.strptime(end_date, '%Y-%m-%d').timestamp() * 1000)\n",
    "        \n",
    "        # Initialize empty list to store all OHLCV data\n",
    "        ohlcv_data = []\n",
    "        \n",
    "        # Fetch data in chunks to avoid API limitations\n",
    "        current_start = start_timestamp\n",
    "        while current_start < end_timestamp:\n",
    "            try:\n",
    "                # Fetch 500 candles at a time (Binance limit)\n",
    "                candles = self.exchange.fetch_ohlcv(\n",
    "                    symbol, \n",
    "                    timeframe='1d', \n",
    "                    since=current_start,\n",
    "                    limit=500\n",
    "                )\n",
    "                \n",
    "                # Break if no more data\n",
    "                if not candles:\n",
    "                    break\n",
    "                \n",
    "                # Add to data list\n",
    "                ohlcv_data.extend(candles)\n",
    "                \n",
    "                # Update start timestamp for next iteration\n",
    "                current_start = candles[-1][0] + 1\n",
    "                \n",
    "                # Respect rate limits\n",
    "                time.sleep(self.exchange.rateLimit / 1000)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {symbol}: {e}\")\n",
    "                break\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "        \n",
    "        # Convert timestamp to datetime and set as index\n",
    "        df['date'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        \n",
    "        # Calculate market cap (estimated using close price and volume)\n",
    "        # Note: This is a rough estimation and may not be entirely accurate\n",
    "        df['market_cap'] = df['close'] * df['volume']\n",
    "        \n",
    "        # Compute daily returns\n",
    "        df['daily_return'] = df['close'].pct_change()\n",
    "        \n",
    "        # Select and rename columns\n",
    "        result_df = df[['date', 'close', 'volume', 'market_cap', 'daily_return']].copy()\n",
    "        result_df.columns = ['date', 'price', 'volume', 'market_cap', 'daily_return']\n",
    "        \n",
    "        # Add asset column\n",
    "        result_df['asset'] = symbol  # Use base currency as asset name\n",
    "        \n",
    "        # Set date as index\n",
    "        result_df.set_index('date', inplace=True)\n",
    "        \n",
    "        # Filter date range\n",
    "        result_df = result_df.loc[start_date:end_date]\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    def fetch_top_symbols(self, limit=100):\n",
    "        \"\"\"\n",
    "        Fetch top trading symbols by volume\n",
    "        \n",
    "        Args:\n",
    "            limit (int): Number of top symbols to return\n",
    "        \n",
    "        Returns:\n",
    "            list: Top trading symbols\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load markets\n",
    "            self.exchange.load_markets()\n",
    "            \n",
    "            # Sort markets by daily volume\n",
    "            markets = sorted(\n",
    "                self.exchange.markets.values(), \n",
    "                key=lambda x: x.get('quote', 'USDT') == 'USDT' and x.get('active', False),\n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "            # Filter USDT pairs and get top symbols\n",
    "            usdt_pairs = [\n",
    "                market['symbol'] for market in markets \n",
    "                if market['quote'] == 'USDT' and market['active']\n",
    "            ]\n",
    "            \n",
    "            return usdt_pairs[:limit]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching top symbols: {e}\")\n",
    "            return []\n",
    "\n",
    "def main():\n",
    "    # Initialize scraper using environment variables\n",
    "    scraper = BinanceDataScraper()\n",
    "    \n",
    "    # Get top trading symbols\n",
    "    top_symbols = scraper.fetch_top_symbols(limit=100)\n",
    "    print(f\"Fetching data for {len(top_symbols)} top symbols\")\n",
    "    \n",
    "    # Dictionary to store all data\n",
    "    all_data = {}\n",
    "    \n",
    "    # Fetch data for each symbol\n",
    "    for symbol in top_symbols:\n",
    "        try:\n",
    "            print(f\"Fetching data for {symbol}\")\n",
    "            df = scraper.fetch_comprehensive_data(symbol)\n",
    "            \n",
    "            if not df.empty:\n",
    "                all_data[symbol] = df\n",
    "                print(f\"✓ Collected {len(df)} days of data for {symbol}\")\n",
    "            \n",
    "            # Optional: Add a small delay between symbol fetches\n",
    "            time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {e}\")\n",
    "    \n",
    "    # Combine all data\n",
    "    if all_data:\n",
    "        # Concatenate all dataframes\n",
    "        final_df = pd.concat(all_data.values())\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_filename = f\"binance_crypto_data_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "        final_df.to_csv(output_filename)\n",
    "        \n",
    "        print(f\"\\n✅ Data collection complete. Saved to {output_filename}\")\n",
    "        print(f\"Symbols collected: {len(all_data)}\")\n",
    "        print(f\"Total records: {len(final_df)}\")\n",
    "    else:\n",
    "        print(\"No data collected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binance Coin Data\n",
    "Using Binance data, we will be collecting Open, Low, High, Close data for each coin selected\n",
    "- API key is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ccxt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 166\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data collected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 126\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Initialize scraper using environment variables\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     scraper \u001b[38;5;241m=\u001b[39m \u001b[43mBinanceOHLCScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Get top trading symbols\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     top_symbols \u001b[38;5;241m=\u001b[39m scraper\u001b[38;5;241m.\u001b[39mfetch_top_symbols(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m, in \u001b[0;36mBinanceOHLCScraper.__init__\u001b[0;34m(self, api_key, api_secret)\u001b[0m\n\u001b[1;32m     14\u001b[0m api_secret \u001b[38;5;241m=\u001b[39m api_secret \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKEY_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Initialize exchange\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexchange \u001b[38;5;241m=\u001b[39m \u001b[43mccxt\u001b[49m\u001b[38;5;241m.\u001b[39mbinance({\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapiKey\u001b[39m\u001b[38;5;124m'\u001b[39m: api_key,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecret\u001b[39m\u001b[38;5;124m'\u001b[39m: api_secret,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menableRateLimit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefaultType\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspot\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Use spot market by default\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     }\n\u001b[1;32m     24\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ccxt' is not defined"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "class BinanceOHLCScraper:\n",
    "    def __init__(self, api_key=None, api_secret=None):\n",
    "        \"\"\"\n",
    "        Initialize Binance exchange connection\n",
    "        \n",
    "        Args:\n",
    "            api_key (str, optional): Binance API key from .env\n",
    "            api_secret (str, optional): Binance API secret from .env\n",
    "        \"\"\"\n",
    "        # Fetch keys from environment variables if not provided\n",
    "        api_key = api_key or os.getenv('KEY_1')\n",
    "        api_secret = api_secret or os.getenv('KEY_2')\n",
    "        \n",
    "        # Initialize exchange\n",
    "        self.exchange = ccxt.binance({\n",
    "            'apiKey': api_key,\n",
    "            'secret': api_secret,\n",
    "            'enableRateLimit': True,\n",
    "            'options': {\n",
    "                'defaultType': 'spot'  # Use spot market by default\n",
    "            }\n",
    "        })\n",
    "\n",
    "    def fetch_ohlcv_data(self, \n",
    "                          symbol, \n",
    "                          start_date='2022-03-24', \n",
    "                          end_date='2025-03-24', \n",
    "                          timeframe='1d'):\n",
    "        \"\"\"\n",
    "        Fetch OHLCV data for a given symbol and date range\n",
    "        \n",
    "        Args:\n",
    "            symbol (str): Trading pair symbol (e.g., 'BTC/USDT')\n",
    "            start_date (str): Start date in YYYY-MM-DD format\n",
    "            end_date (str): End date in YYYY-MM-DD format\n",
    "            timeframe (str): Candle timeframe (default: daily)\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: OHLCV data\n",
    "        \"\"\"\n",
    "        # Convert dates to timestamps\n",
    "        start_timestamp = int(datetime.strptime(start_date, '%Y-%m-%d').timestamp() * 1000)\n",
    "        end_timestamp = int(datetime.strptime(end_date, '%Y-%m-%d').timestamp() * 1000)\n",
    "        \n",
    "        # Initialize empty list to store all OHLCV data\n",
    "        ohlcv_data = []\n",
    "        \n",
    "        # Fetch data in chunks to avoid API limitations\n",
    "        current_start = start_timestamp\n",
    "        while current_start < end_timestamp:\n",
    "            try:\n",
    "                # Fetch 500 candles at a time (Binance limit)\n",
    "                candles = self.exchange.fetch_ohlcv(\n",
    "                    symbol, \n",
    "                    timeframe=timeframe, \n",
    "                    since=current_start,\n",
    "                    limit=500\n",
    "                )\n",
    "                \n",
    "                # Break if no more data\n",
    "                if not candles:\n",
    "                    break\n",
    "                \n",
    "                # Add to data list\n",
    "                ohlcv_data.extend(candles)\n",
    "                \n",
    "                # Update start timestamp for next iteration\n",
    "                current_start = candles[-1][0] + 1\n",
    "                \n",
    "                # Respect rate limits\n",
    "                time.sleep(self.exchange.rateLimit / 1000)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {symbol}: {e}\")\n",
    "                break\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "        \n",
    "        # Convert timestamp to datetime\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "        \n",
    "        # Filter date range\n",
    "        df = df.loc[start_date:end_date]\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def fetch_top_symbols(self, limit=100):\n",
    "        \"\"\"\n",
    "        Fetch top trading symbols by volume\n",
    "        \n",
    "        Args:\n",
    "            limit (int): Number of top symbols to return\n",
    "        \n",
    "        Returns:\n",
    "            list: Top trading symbols\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load markets\n",
    "            self.exchange.load_markets()\n",
    "            \n",
    "            # Sort markets by daily volume\n",
    "            markets = sorted(\n",
    "                self.exchange.markets.values(), \n",
    "                key=lambda x: x.get('quote', 'USDT') == 'USDT' and x.get('active', False),\n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "            # Filter USDT pairs and get top symbols\n",
    "            usdt_pairs = [\n",
    "                market['symbol'] for market in markets \n",
    "                if market['quote'] == 'USDT' and market['active']\n",
    "            ]\n",
    "            \n",
    "            return usdt_pairs[:limit]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching top symbols: {e}\")\n",
    "            return []\n",
    "\n",
    "def main():\n",
    "    # Initialize scraper using environment variables\n",
    "    scraper = BinanceOHLCScraper()\n",
    "    \n",
    "    # Get top trading symbols\n",
    "    top_symbols = scraper.fetch_top_symbols(limit=100)\n",
    "    print(f\"Fetching data for {len(top_symbols)} top symbols\")\n",
    "    \n",
    "    # Dictionary to store all data\n",
    "    all_data = {}\n",
    "    \n",
    "    # Fetch data for each symbol\n",
    "    for symbol in top_symbols:\n",
    "        try:\n",
    "            print(f\"Fetching data for {symbol}\")\n",
    "            df = scraper.fetch_ohlcv_data(symbol)\n",
    "            \n",
    "            if not df.empty:\n",
    "                all_data[symbol] = df\n",
    "                print(f\"✓ Collected {len(df)} days of data for {symbol}\")\n",
    "            \n",
    "            # Optional: Add a small delay between symbol fetches\n",
    "            time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {e}\")\n",
    "    \n",
    "    # Combine all data\n",
    "    if all_data:\n",
    "        # Create a MultiIndex DataFrame\n",
    "        final_df = pd.concat(all_data.values(), keys=all_data.keys(), names=['symbol'])\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_filename = f\"binance_ohlc_data_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "        final_df.to_csv(output_filename)\n",
    "        \n",
    "        print(f\"\\n✅ Data collection complete. Saved to {output_filename}\")\n",
    "        print(f\"Symbols collected: {len(all_data)}\")\n",
    "    else:\n",
    "        print(\"No data collected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "term6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
