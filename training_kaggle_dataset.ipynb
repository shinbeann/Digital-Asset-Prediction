{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for Kaggle Dataset\n",
    "Using this [Cryptocurrency Price Analysis Dataset from Kaggle](https://www.kaggle.com/datasets/adityamhaske/cryptocurrency-price-analysis-dataset/data) as proof-of-concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ryan Lee\\.conda\\envs\\term6\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Required Modules #\n",
    "####################\n",
    "\n",
    "# Libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Custom\n",
    "from src.dataset import *\n",
    "from src.models import *\n",
    "from src.train_eval import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "Download the dataset from the Kaggle [page](https://www.kaggle.com/datasets/adityamhaske/cryptocurrency-price-analysis-dataset/data). Alternatively, you can use the following `kagglehub` to download the dataset:\n",
    "\n",
    "```python\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "csv_path = kagglehub.dataset_download(\"adityamhaske/cryptocurrency-price-analysis-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ryan Lee\\Desktop\\50.038 Computational Data Science\\Digital-Asset-Prediction\\src\\dataset.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df['Date'] = pd.to_datetime(self.df['Date']) # Datetime conversion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 7879\n",
      "Crypto mapping: {'BTC': 0, 'ETH': 1, 'LTC': 2, 'XRP': 3}\n"
     ]
    }
   ],
   "source": [
    "# Update the path to the `crypto_combine.csv` file below:\n",
    "csv_path = \"data/kaggle_crypto_price_prediction/crypto_combine.csv\"\n",
    "seq_length = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Create the dataset\n",
    "dataset = CryptoDataset(csv_path, seq_length=seq_length)\n",
    "\n",
    "print(f\"Total sequences: {len(dataset)}\")\n",
    "print(\"Crypto mapping:\", dataset.crypto_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation set\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "`train_model` will save model parameters to `saved_models` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # standard for Adam\n",
    "num_epochs = 5000\n",
    "save_interval = num_epochs // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryptoGRU model loaded on cuda.\n",
      "Epoch [1/5000] | Time: 1.38s\n",
      "(Training) Loss: 1390000.2126\n",
      "(Validation) Loss: 1439565.3587, MAE: 5493.0205, R2: -0.2104\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2/5000] | Time: 0.24s\n",
      "(Training) Loss: 1372912.9429\n",
      "(Validation) Loss: 1439236.3073, MAE: 5490.3779, R2: -0.2101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3/5000] | Time: 0.19s\n",
      "(Training) Loss: 1383858.9759\n",
      "(Validation) Loss: 1438906.9054, MAE: 5487.6553, R2: -0.2099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4/5000] | Time: 0.18s\n",
      "(Training) Loss: 1386313.6701\n",
      "(Validation) Loss: 1438574.0394, MAE: 5484.9429, R2: -0.2096\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [5/5000] | Time: 0.18s\n",
      "(Training) Loss: 1407402.9137\n",
      "(Validation) Loss: 1438265.4273, MAE: 5482.4185, R2: -0.2093\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [6/5000] | Time: 0.17s\n",
      "(Training) Loss: 1380637.1929\n",
      "(Validation) Loss: 1437966.0800, MAE: 5479.9580, R2: -0.2091\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [7/5000] | Time: 0.18s\n",
      "(Training) Loss: 1394004.1967\n",
      "(Validation) Loss: 1437679.3549, MAE: 5477.6177, R2: -0.2088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [8/5000] | Time: 0.23s\n",
      "(Training) Loss: 1402521.0876\n",
      "(Validation) Loss: 1437367.8984, MAE: 5475.1177, R2: -0.2086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [9/5000] | Time: 0.20s\n",
      "(Training) Loss: 1397204.4239\n",
      "(Validation) Loss: 1437058.3111, MAE: 5472.6631, R2: -0.2083\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [10/5000] | Time: 0.22s\n",
      "(Training) Loss: 1376074.7094\n",
      "(Validation) Loss: 1436744.4267, MAE: 5470.2012, R2: -0.2081\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [11/5000] | Time: 0.19s\n",
      "(Training) Loss: 1372981.1802\n",
      "(Validation) Loss: 1436434.0063, MAE: 5467.7173, R2: -0.2078\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [12/5000] | Time: 0.17s\n",
      "(Training) Loss: 1399780.4442\n",
      "(Validation) Loss: 1436127.5124, MAE: 5465.2544, R2: -0.2075\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [13/5000] | Time: 0.17s\n",
      "(Training) Loss: 1373959.2843\n",
      "(Validation) Loss: 1435825.7625, MAE: 5462.8735, R2: -0.2073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [14/5000] | Time: 0.17s\n",
      "(Training) Loss: 1385133.7056\n",
      "(Validation) Loss: 1435529.1479, MAE: 5460.6089, R2: -0.2070\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [15/5000] | Time: 0.18s\n",
      "(Training) Loss: 1405020.2538\n",
      "(Validation) Loss: 1435231.0857, MAE: 5458.3618, R2: -0.2068\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [16/5000] | Time: 0.21s\n",
      "(Training) Loss: 1382348.0457\n",
      "(Validation) Loss: 1434937.5035, MAE: 5456.1885, R2: -0.2065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [17/5000] | Time: 0.18s\n",
      "(Training) Loss: 1374058.9124\n",
      "(Validation) Loss: 1434641.0159, MAE: 5454.0151, R2: -0.2063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [18/5000] | Time: 0.17s\n",
      "(Training) Loss: 1398155.4112\n",
      "(Validation) Loss: 1434346.7124, MAE: 5451.9023, R2: -0.2061\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [19/5000] | Time: 0.21s\n",
      "(Training) Loss: 1367981.5888\n",
      "(Validation) Loss: 1434053.5975, MAE: 5449.8364, R2: -0.2058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [20/5000] | Time: 0.18s\n",
      "(Training) Loss: 1367921.8807\n",
      "(Validation) Loss: 1433767.2076, MAE: 5447.8179, R2: -0.2056\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [21/5000] | Time: 0.19s\n",
      "(Training) Loss: 1374171.7360\n",
      "(Validation) Loss: 1433445.5365, MAE: 5445.5938, R2: -0.2053\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [22/5000] | Time: 0.20s\n",
      "(Training) Loss: 1396919.1091\n",
      "(Validation) Loss: 1433147.4083, MAE: 5443.5732, R2: -0.2051\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [23/5000] | Time: 0.18s\n",
      "(Training) Loss: 1417763.0520\n",
      "(Validation) Loss: 1432847.9797, MAE: 5441.5176, R2: -0.2048\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [24/5000] | Time: 0.18s\n",
      "(Training) Loss: 1376429.3947\n",
      "(Validation) Loss: 1432540.4800, MAE: 5439.4224, R2: -0.2045\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [25/5000] | Time: 0.18s\n",
      "(Training) Loss: 1379502.2246\n",
      "(Validation) Loss: 1432245.1200, MAE: 5437.4570, R2: -0.2043\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [26/5000] | Time: 0.19s\n",
      "(Training) Loss: 1375520.4194\n",
      "(Validation) Loss: 1431952.0610, MAE: 5435.4785, R2: -0.2041\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [27/5000] | Time: 0.24s\n",
      "(Training) Loss: 1370036.9594\n",
      "(Validation) Loss: 1431656.7517, MAE: 5433.5913, R2: -0.2038\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [28/5000] | Time: 0.21s\n",
      "(Training) Loss: 1359882.9661\n",
      "(Validation) Loss: 1431368.0305, MAE: 5431.6470, R2: -0.2036\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [29/5000] | Time: 0.22s\n",
      "(Training) Loss: 1403071.5216\n",
      "(Validation) Loss: 1431078.5727, MAE: 5429.7637, R2: -0.2033\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [30/5000] | Time: 0.19s\n",
      "(Training) Loss: 1363520.4365\n",
      "(Validation) Loss: 1430780.5105, MAE: 5427.8672, R2: -0.2031\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [31/5000] | Time: 0.21s\n",
      "(Training) Loss: 1375612.3617\n",
      "(Validation) Loss: 1430491.7994, MAE: 5425.9658, R2: -0.2028\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [32/5000] | Time: 0.23s\n",
      "(Training) Loss: 1373295.5850\n",
      "(Validation) Loss: 1430200.1930, MAE: 5424.0640, R2: -0.2026\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [33/5000] | Time: 0.26s\n",
      "(Training) Loss: 1380863.6104\n",
      "(Validation) Loss: 1429908.4241, MAE: 5422.2109, R2: -0.2024\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [34/5000] | Time: 0.20s\n",
      "(Training) Loss: 1383416.7830\n",
      "(Validation) Loss: 1429615.7714, MAE: 5420.2944, R2: -0.2021\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [35/5000] | Time: 0.21s\n",
      "(Training) Loss: 1376395.5508\n",
      "(Validation) Loss: 1429328.6298, MAE: 5418.5259, R2: -0.2019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [36/5000] | Time: 0.20s\n",
      "(Training) Loss: 1368165.3135\n",
      "(Validation) Loss: 1429035.5098, MAE: 5416.6948, R2: -0.2016\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [37/5000] | Time: 0.21s\n",
      "(Training) Loss: 1377616.6396\n",
      "(Validation) Loss: 1428748.4851, MAE: 5414.9175, R2: -0.2014\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [38/5000] | Time: 0.20s\n",
      "(Training) Loss: 1389057.8198\n",
      "(Validation) Loss: 1428460.0787, MAE: 5413.2617, R2: -0.2011\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [39/5000] | Time: 0.19s\n",
      "(Training) Loss: 1373566.7278\n",
      "(Validation) Loss: 1428165.2267, MAE: 5411.3750, R2: -0.2009\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [40/5000] | Time: 0.23s\n",
      "(Training) Loss: 1385580.1269\n",
      "(Validation) Loss: 1427878.8521, MAE: 5409.6001, R2: -0.2007\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [41/5000] | Time: 0.23s\n",
      "(Training) Loss: 1380766.2462\n",
      "(Validation) Loss: 1427589.6737, MAE: 5407.9053, R2: -0.2004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [42/5000] | Time: 0.20s\n",
      "(Training) Loss: 1376945.8376\n",
      "(Validation) Loss: 1427301.0997, MAE: 5406.2280, R2: -0.2002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [43/5000] | Time: 0.26s\n",
      "(Training) Loss: 1362950.5190\n",
      "(Validation) Loss: 1427011.0730, MAE: 5404.4888, R2: -0.1999\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [44/5000] | Time: 0.25s\n",
      "(Training) Loss: 1372928.0996\n",
      "(Validation) Loss: 1426726.1613, MAE: 5402.9321, R2: -0.1997\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [45/5000] | Time: 0.27s\n",
      "(Training) Loss: 1364426.1244\n",
      "(Validation) Loss: 1426437.4095, MAE: 5401.2324, R2: -0.1995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [46/5000] | Time: 0.29s\n",
      "(Training) Loss: 1362678.1764\n",
      "(Validation) Loss: 1426151.5276, MAE: 5399.7139, R2: -0.1992\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [47/5000] | Time: 0.26s\n",
      "(Training) Loss: 1358566.7817\n",
      "(Validation) Loss: 1425864.4775, MAE: 5397.8936, R2: -0.1990\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [48/5000] | Time: 0.30s\n",
      "(Training) Loss: 1385585.9150\n",
      "(Validation) Loss: 1425581.9530, MAE: 5396.7407, R2: -0.1987\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [49/5000] | Time: 0.26s\n",
      "(Training) Loss: 1355008.4442\n",
      "(Validation) Loss: 1425286.0902, MAE: 5394.7949, R2: -0.1985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [50/5000] | Time: 0.30s\n",
      "(Training) Loss: 1370897.0140\n",
      "(Validation) Loss: 1425002.0419, MAE: 5393.1982, R2: -0.1983\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [51/5000] | Time: 0.29s\n",
      "(Training) Loss: 1372997.6675\n",
      "(Validation) Loss: 1424715.9416, MAE: 5391.6611, R2: -0.1980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [52/5000] | Time: 0.21s\n",
      "(Training) Loss: 1371697.1612\n",
      "(Validation) Loss: 1424433.4121, MAE: 5390.0259, R2: -0.1978\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [53/5000] | Time: 0.20s\n",
      "(Training) Loss: 1365153.8832\n",
      "(Validation) Loss: 1424143.3244, MAE: 5388.4277, R2: -0.1975\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [54/5000] | Time: 0.21s\n",
      "(Training) Loss: 1367314.8706\n",
      "(Validation) Loss: 1423855.6089, MAE: 5386.9199, R2: -0.1973\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [55/5000] | Time: 0.17s\n",
      "(Training) Loss: 1375507.6688\n",
      "(Validation) Loss: 1423569.2394, MAE: 5385.6768, R2: -0.1971\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [56/5000] | Time: 0.17s\n",
      "(Training) Loss: 1365250.5736\n",
      "(Validation) Loss: 1423283.7079, MAE: 5383.9668, R2: -0.1968\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [57/5000] | Time: 0.23s\n",
      "(Training) Loss: 1396215.6041\n",
      "(Validation) Loss: 1422996.3378, MAE: 5382.4087, R2: -0.1966\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [58/5000] | Time: 0.21s\n",
      "(Training) Loss: 1375088.2665\n",
      "(Validation) Loss: 1422708.9727, MAE: 5380.9023, R2: -0.1964\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [59/5000] | Time: 0.20s\n",
      "(Training) Loss: 1367412.5711\n",
      "(Validation) Loss: 1422422.9587, MAE: 5379.4214, R2: -0.1961\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [60/5000] | Time: 0.18s\n",
      "(Training) Loss: 1399658.3211\n",
      "(Validation) Loss: 1422139.5759, MAE: 5378.1821, R2: -0.1959\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [61/5000] | Time: 0.18s\n",
      "(Training) Loss: 1356105.3750\n",
      "(Validation) Loss: 1421845.9937, MAE: 5376.9224, R2: -0.1956\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [62/5000] | Time: 0.21s\n",
      "(Training) Loss: 1359355.7525\n",
      "(Validation) Loss: 1421563.7994, MAE: 5375.2451, R2: -0.1954\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [63/5000] | Time: 0.21s\n",
      "(Training) Loss: 1400728.9289\n",
      "(Validation) Loss: 1421282.0571, MAE: 5373.7646, R2: -0.1952\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [64/5000] | Time: 0.17s\n",
      "(Training) Loss: 1351433.1634\n",
      "(Validation) Loss: 1420989.7549, MAE: 5372.4438, R2: -0.1949\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [65/5000] | Time: 0.21s\n",
      "(Training) Loss: 1364400.6980\n",
      "(Validation) Loss: 1420711.3702, MAE: 5371.0698, R2: -0.1947\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [66/5000] | Time: 0.18s\n",
      "(Training) Loss: 1381086.6066\n",
      "(Validation) Loss: 1420424.0102, MAE: 5369.5894, R2: -0.1944\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [67/5000] | Time: 0.19s\n",
      "(Training) Loss: 1377453.7525\n",
      "(Validation) Loss: 1420136.9854, MAE: 5368.5034, R2: -0.1942\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [68/5000] | Time: 0.19s\n",
      "(Training) Loss: 1369955.5673\n",
      "(Validation) Loss: 1419848.7060, MAE: 5366.9014, R2: -0.1940\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [69/5000] | Time: 0.19s\n",
      "(Training) Loss: 1356492.6497\n",
      "(Validation) Loss: 1419564.6527, MAE: 5365.3828, R2: -0.1937\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [70/5000] | Time: 0.17s\n",
      "(Training) Loss: 1358834.7386\n",
      "(Validation) Loss: 1419284.6679, MAE: 5364.1646, R2: -0.1935\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [71/5000] | Time: 0.18s\n",
      "(Training) Loss: 1375968.5838\n",
      "(Validation) Loss: 1418998.6844, MAE: 5362.8286, R2: -0.1933\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [72/5000] | Time: 0.17s\n",
      "(Training) Loss: 1366742.8338\n",
      "(Validation) Loss: 1418715.5606, MAE: 5361.5005, R2: -0.1930\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [73/5000] | Time: 0.23s\n",
      "(Training) Loss: 1369968.7551\n",
      "(Validation) Loss: 1418428.4190, MAE: 5360.2817, R2: -0.1928\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [74/5000] | Time: 0.24s\n",
      "(Training) Loss: 1363531.1142\n",
      "(Validation) Loss: 1418140.1244, MAE: 5358.6899, R2: -0.1925\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [75/5000] | Time: 0.19s\n",
      "(Training) Loss: 1374840.6612\n",
      "(Validation) Loss: 1417857.3816, MAE: 5358.1157, R2: -0.1923\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [76/5000] | Time: 0.19s\n",
      "(Training) Loss: 1360812.5508\n",
      "(Validation) Loss: 1417572.5968, MAE: 5355.9976, R2: -0.1921\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [77/5000] | Time: 0.20s\n",
      "(Training) Loss: 1366754.9137\n",
      "(Validation) Loss: 1417291.3879, MAE: 5354.9067, R2: -0.1918\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [78/5000] | Time: 0.20s\n",
      "(Training) Loss: 1354860.4746\n",
      "(Validation) Loss: 1417002.4686, MAE: 5353.8452, R2: -0.1916\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [79/5000] | Time: 0.21s\n",
      "(Training) Loss: 1357469.0622\n",
      "(Validation) Loss: 1416724.4292, MAE: 5352.1826, R2: -0.1914\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [80/5000] | Time: 0.24s\n",
      "(Training) Loss: 1387919.4987\n",
      "(Validation) Loss: 1416439.3752, MAE: 5350.7935, R2: -0.1911\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [81/5000] | Time: 0.23s\n",
      "(Training) Loss: 1381206.0013\n",
      "(Validation) Loss: 1416152.3251, MAE: 5349.4849, R2: -0.1909\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [82/5000] | Time: 0.21s\n",
      "(Training) Loss: 1368736.0406\n",
      "(Validation) Loss: 1415863.3549, MAE: 5348.1685, R2: -0.1906\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [83/5000] | Time: 0.21s\n",
      "(Training) Loss: 1357845.1472\n",
      "(Validation) Loss: 1415578.1943, MAE: 5346.8843, R2: -0.1904\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [84/5000] | Time: 0.22s\n",
      "(Training) Loss: 1348249.4353\n",
      "(Validation) Loss: 1415296.1778, MAE: 5346.0234, R2: -0.1902\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [85/5000] | Time: 0.26s\n",
      "(Training) Loss: 1349057.5279\n",
      "(Validation) Loss: 1415013.0946, MAE: 5344.2817, R2: -0.1899\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [86/5000] | Time: 0.23s\n",
      "(Training) Loss: 1349552.9321\n",
      "(Validation) Loss: 1414732.7187, MAE: 5342.8901, R2: -0.1897\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [87/5000] | Time: 0.23s\n",
      "(Training) Loss: 1389521.4746\n",
      "(Validation) Loss: 1414454.5168, MAE: 5341.6519, R2: -0.1895\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [88/5000] | Time: 0.22s\n",
      "(Training) Loss: 1359637.7582\n",
      "(Validation) Loss: 1414169.4375, MAE: 5340.4692, R2: -0.1892\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [89/5000] | Time: 0.21s\n",
      "(Training) Loss: 1351179.1142\n",
      "(Validation) Loss: 1413884.6019, MAE: 5338.9512, R2: -0.1890\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [90/5000] | Time: 0.21s\n",
      "(Training) Loss: 1384593.4315\n",
      "(Validation) Loss: 1413604.8610, MAE: 5337.7573, R2: -0.1888\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [91/5000] | Time: 0.21s\n",
      "(Training) Loss: 1373219.0241\n",
      "(Validation) Loss: 1413320.7010, MAE: 5336.3716, R2: -0.1885\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [92/5000] | Time: 0.20s\n",
      "(Training) Loss: 1370361.3629\n",
      "(Validation) Loss: 1413032.6654, MAE: 5335.1313, R2: -0.1883\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [93/5000] | Time: 0.19s\n",
      "(Training) Loss: 1351582.7500\n",
      "(Validation) Loss: 1412750.7454, MAE: 5333.7339, R2: -0.1880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [94/5000] | Time: 0.18s\n",
      "(Training) Loss: 1363623.1003\n",
      "(Validation) Loss: 1412467.4489, MAE: 5332.5205, R2: -0.1878\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [95/5000] | Time: 0.24s\n",
      "(Training) Loss: 1365774.7284\n",
      "(Validation) Loss: 1412185.6863, MAE: 5331.2690, R2: -0.1876\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [96/5000] | Time: 0.28s\n",
      "(Training) Loss: 1366004.4277\n",
      "(Validation) Loss: 1411901.6533, MAE: 5329.8877, R2: -0.1873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [97/5000] | Time: 0.22s\n",
      "(Training) Loss: 1362914.7246\n",
      "(Validation) Loss: 1411618.3010, MAE: 5329.0176, R2: -0.1871\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [98/5000] | Time: 0.22s\n",
      "(Training) Loss: 1344355.4816\n",
      "(Validation) Loss: 1411337.4070, MAE: 5327.4507, R2: -0.1869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [99/5000] | Time: 0.23s\n",
      "(Training) Loss: 1366607.4657\n",
      "(Validation) Loss: 1411055.7308, MAE: 5326.0522, R2: -0.1866\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [100/5000] | Time: 0.26s\n",
      "(Training) Loss: 1341384.9188\n",
      "(Validation) Loss: 1410774.4051, MAE: 5325.0439, R2: -0.1864\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [101/5000] | Time: 0.27s\n",
      "(Training) Loss: 1346446.5590\n",
      "(Validation) Loss: 1410492.7949, MAE: 5323.6104, R2: -0.1862\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [102/5000] | Time: 0.23s\n",
      "(Training) Loss: 1371656.7500\n",
      "(Validation) Loss: 1410213.9886, MAE: 5322.6299, R2: -0.1859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [103/5000] | Time: 0.21s\n",
      "(Training) Loss: 1359914.2411\n",
      "(Validation) Loss: 1409929.0108, MAE: 5320.9058, R2: -0.1857\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [104/5000] | Time: 0.22s\n",
      "(Training) Loss: 1355702.0558\n",
      "(Validation) Loss: 1409644.9676, MAE: 5319.5713, R2: -0.1855\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [105/5000] | Time: 0.26s\n",
      "(Training) Loss: 1359137.9943\n",
      "(Validation) Loss: 1409365.6584, MAE: 5318.6440, R2: -0.1852\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [106/5000] | Time: 0.20s\n",
      "(Training) Loss: 1351335.8668\n",
      "(Validation) Loss: 1409084.1295, MAE: 5317.3369, R2: -0.1850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [107/5000] | Time: 0.20s\n",
      "(Training) Loss: 1338630.4470\n",
      "(Validation) Loss: 1408801.6610, MAE: 5315.7471, R2: -0.1848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [108/5000] | Time: 0.20s\n",
      "(Training) Loss: 1378563.8261\n",
      "(Validation) Loss: 1408525.2521, MAE: 5314.9946, R2: -0.1845\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [109/5000] | Time: 0.20s\n",
      "(Training) Loss: 1351618.1421\n",
      "(Validation) Loss: 1408238.3848, MAE: 5313.5903, R2: -0.1843\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [110/5000] | Time: 0.21s\n",
      "(Training) Loss: 1356855.1967\n",
      "(Validation) Loss: 1407958.6184, MAE: 5311.9995, R2: -0.1841\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [111/5000] | Time: 0.21s\n",
      "(Training) Loss: 1345104.9772\n",
      "(Validation) Loss: 1407677.8006, MAE: 5310.8682, R2: -0.1838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [112/5000] | Time: 0.22s\n",
      "(Training) Loss: 1353349.6066\n",
      "(Validation) Loss: 1407398.5879, MAE: 5309.5522, R2: -0.1836\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [113/5000] | Time: 0.20s\n",
      "(Training) Loss: 1350869.8211\n",
      "(Validation) Loss: 1407115.0019, MAE: 5308.2588, R2: -0.1833\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [114/5000] | Time: 0.25s\n",
      "(Training) Loss: 1350225.4543\n",
      "(Validation) Loss: 1406834.6006, MAE: 5307.1138, R2: -0.1831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [115/5000] | Time: 0.24s\n",
      "(Training) Loss: 1373356.8046\n",
      "(Validation) Loss: 1406553.2698, MAE: 5305.5601, R2: -0.1829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [116/5000] | Time: 0.26s\n",
      "(Training) Loss: 1355125.9721\n",
      "(Validation) Loss: 1406269.5111, MAE: 5304.5522, R2: -0.1826\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [117/5000] | Time: 0.25s\n",
      "(Training) Loss: 1357900.2322\n",
      "(Validation) Loss: 1405987.8095, MAE: 5303.3755, R2: -0.1824\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [118/5000] | Time: 0.26s\n",
      "(Training) Loss: 1358489.2766\n",
      "(Validation) Loss: 1405705.2343, MAE: 5301.7964, R2: -0.1822\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [119/5000] | Time: 0.22s\n",
      "(Training) Loss: 1358553.6536\n",
      "(Validation) Loss: 1405424.1371, MAE: 5301.1304, R2: -0.1819\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [120/5000] | Time: 0.21s\n",
      "(Training) Loss: 1346215.7792\n",
      "(Validation) Loss: 1405142.4406, MAE: 5299.4126, R2: -0.1817\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [121/5000] | Time: 0.19s\n",
      "(Training) Loss: 1344448.7538\n",
      "(Validation) Loss: 1404862.5930, MAE: 5298.1655, R2: -0.1815\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [122/5000] | Time: 0.21s\n",
      "(Training) Loss: 1355915.8084\n",
      "(Validation) Loss: 1404585.4273, MAE: 5296.9648, R2: -0.1812\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [123/5000] | Time: 0.21s\n",
      "(Training) Loss: 1349015.9569\n",
      "(Validation) Loss: 1404302.9384, MAE: 5295.4824, R2: -0.1810\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [124/5000] | Time: 0.25s\n",
      "(Training) Loss: 1345385.6345\n",
      "(Validation) Loss: 1404021.9683, MAE: 5294.2764, R2: -0.1808\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [125/5000] | Time: 0.21s\n",
      "(Training) Loss: 1344253.0952\n",
      "(Validation) Loss: 1403744.6705, MAE: 5293.3252, R2: -0.1805\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [126/5000] | Time: 0.20s\n",
      "(Training) Loss: 1352067.8591\n",
      "(Validation) Loss: 1403464.0914, MAE: 5291.8623, R2: -0.1803\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [127/5000] | Time: 0.20s\n",
      "(Training) Loss: 1367691.6345\n",
      "(Validation) Loss: 1403184.8940, MAE: 5290.9917, R2: -0.1801\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [128/5000] | Time: 0.19s\n",
      "(Training) Loss: 1392000.5025\n",
      "(Validation) Loss: 1402900.6375, MAE: 5289.3413, R2: -0.1798\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [129/5000] | Time: 0.20s\n",
      "(Training) Loss: 1340634.2398\n",
      "(Validation) Loss: 1402615.1263, MAE: 5288.7339, R2: -0.1796\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [130/5000] | Time: 0.21s\n",
      "(Training) Loss: 1359876.9822\n",
      "(Validation) Loss: 1402340.4444, MAE: 5286.8398, R2: -0.1794\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [131/5000] | Time: 0.20s\n",
      "(Training) Loss: 1337434.1656\n",
      "(Validation) Loss: 1402057.6305, MAE: 5285.5103, R2: -0.1791\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [132/5000] | Time: 0.21s\n",
      "(Training) Loss: 1341829.0431\n",
      "(Validation) Loss: 1401775.7816, MAE: 5284.5078, R2: -0.1789\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [133/5000] | Time: 0.19s\n",
      "(Training) Loss: 1337105.6732\n",
      "(Validation) Loss: 1401502.0089, MAE: 5282.9688, R2: -0.1787\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [134/5000] | Time: 0.23s\n",
      "(Training) Loss: 1348392.5819\n",
      "(Validation) Loss: 1401219.8756, MAE: 5281.7773, R2: -0.1784\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [135/5000] | Time: 0.24s\n",
      "(Training) Loss: 1346860.7716\n",
      "(Validation) Loss: 1400940.8965, MAE: 5280.8223, R2: -0.1782\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [136/5000] | Time: 0.20s\n",
      "(Training) Loss: 1354833.7906\n",
      "(Validation) Loss: 1400662.6133, MAE: 5279.2627, R2: -0.1780\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [137/5000] | Time: 0.21s\n",
      "(Training) Loss: 1336041.3109\n",
      "(Validation) Loss: 1400377.8895, MAE: 5278.3677, R2: -0.1777\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [138/5000] | Time: 0.21s\n",
      "(Training) Loss: 1364589.9365\n",
      "(Validation) Loss: 1400101.6330, MAE: 5277.4341, R2: -0.1775\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [139/5000] | Time: 0.23s\n",
      "(Training) Loss: 1338515.1091\n",
      "(Validation) Loss: 1399821.1810, MAE: 5275.6597, R2: -0.1773\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [140/5000] | Time: 0.20s\n",
      "(Training) Loss: 1354849.4949\n",
      "(Validation) Loss: 1399542.4000, MAE: 5274.6782, R2: -0.1770\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [141/5000] | Time: 0.23s\n",
      "(Training) Loss: 1333826.6396\n",
      "(Validation) Loss: 1399260.4851, MAE: 5273.2314, R2: -0.1768\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [142/5000] | Time: 0.21s\n",
      "(Training) Loss: 1339928.9759\n",
      "(Validation) Loss: 1398983.8070, MAE: 5272.0469, R2: -0.1766\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [143/5000] | Time: 0.23s\n",
      "(Training) Loss: 1368606.5939\n",
      "(Validation) Loss: 1398704.5333, MAE: 5270.8926, R2: -0.1763\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [144/5000] | Time: 0.20s\n",
      "(Training) Loss: 1369674.1980\n",
      "(Validation) Loss: 1398425.1784, MAE: 5269.3633, R2: -0.1761\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [145/5000] | Time: 0.25s\n",
      "(Training) Loss: 1338044.2982\n",
      "(Validation) Loss: 1398142.6540, MAE: 5268.5776, R2: -0.1759\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [146/5000] | Time: 0.24s\n",
      "(Training) Loss: 1349378.7398\n",
      "(Validation) Loss: 1397865.0616, MAE: 5266.9209, R2: -0.1756\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [147/5000] | Time: 0.29s\n",
      "(Training) Loss: 1369842.3604\n",
      "(Validation) Loss: 1397582.8571, MAE: 5265.7354, R2: -0.1754\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [148/5000] | Time: 0.24s\n",
      "(Training) Loss: 1334559.0406\n",
      "(Validation) Loss: 1397300.3327, MAE: 5264.5142, R2: -0.1752\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [149/5000] | Time: 0.24s\n",
      "(Training) Loss: 1347921.5133\n",
      "(Validation) Loss: 1397024.8076, MAE: 5263.0923, R2: -0.1749\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [150/5000] | Time: 0.23s\n",
      "(Training) Loss: 1329508.9004\n",
      "(Validation) Loss: 1396742.1765, MAE: 5262.0669, R2: -0.1747\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [151/5000] | Time: 0.20s\n",
      "(Training) Loss: 1343047.1098\n",
      "(Validation) Loss: 1396468.8762, MAE: 5261.0771, R2: -0.1745\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [152/5000] | Time: 0.21s\n",
      "(Training) Loss: 1346620.3319\n",
      "(Validation) Loss: 1396190.6438, MAE: 5259.5820, R2: -0.1742\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [153/5000] | Time: 0.22s\n",
      "(Training) Loss: 1357509.9099\n",
      "(Validation) Loss: 1395913.1835, MAE: 5258.5894, R2: -0.1740\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [154/5000] | Time: 0.34s\n",
      "(Training) Loss: 1338497.6053\n",
      "(Validation) Loss: 1395630.2425, MAE: 5257.1919, R2: -0.1738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [155/5000] | Time: 0.25s\n",
      "(Training) Loss: 1361594.7576\n",
      "(Validation) Loss: 1395352.9346, MAE: 5255.9434, R2: -0.1735\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [156/5000] | Time: 0.30s\n",
      "(Training) Loss: 1342352.9695\n",
      "(Validation) Loss: 1395072.4622, MAE: 5255.0444, R2: -0.1733\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [157/5000] | Time: 0.32s\n",
      "(Training) Loss: 1377597.0470\n",
      "(Validation) Loss: 1394793.0768, MAE: 5253.8022, R2: -0.1731\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [158/5000] | Time: 0.26s\n",
      "(Training) Loss: 1340695.5990\n",
      "(Validation) Loss: 1394514.3721, MAE: 5252.6758, R2: -0.1728\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [159/5000] | Time: 0.25s\n",
      "(Training) Loss: 1347562.9702\n",
      "(Validation) Loss: 1394233.4222, MAE: 5251.2734, R2: -0.1726\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [160/5000] | Time: 0.26s\n",
      "(Training) Loss: 1349213.9670\n",
      "(Validation) Loss: 1393955.4184, MAE: 5250.2065, R2: -0.1724\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [161/5000] | Time: 0.23s\n",
      "(Training) Loss: 1339643.8325\n",
      "(Validation) Loss: 1393680.9194, MAE: 5248.8296, R2: -0.1721\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [162/5000] | Time: 0.26s\n",
      "(Training) Loss: 1343203.5343\n",
      "(Validation) Loss: 1393396.7187, MAE: 5247.4995, R2: -0.1719\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [163/5000] | Time: 0.25s\n",
      "(Training) Loss: 1341816.2462\n",
      "(Validation) Loss: 1393123.5251, MAE: 5246.4678, R2: -0.1717\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [164/5000] | Time: 0.22s\n",
      "(Training) Loss: 1356177.5152\n",
      "(Validation) Loss: 1392843.8095, MAE: 5245.2344, R2: -0.1715\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [165/5000] | Time: 0.25s\n",
      "(Training) Loss: 1336938.1345\n",
      "(Validation) Loss: 1392565.6737, MAE: 5244.0454, R2: -0.1712\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [166/5000] | Time: 0.27s\n",
      "(Training) Loss: 1330208.6967\n",
      "(Validation) Loss: 1392356.7848, MAE: 5243.5356, R2: -0.1710\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [167/5000] | Time: 0.28s\n",
      "(Training) Loss: 1333741.5901\n",
      "(Validation) Loss: 1392011.2305, MAE: 5241.7515, R2: -0.1708\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [168/5000] | Time: 0.27s\n",
      "(Training) Loss: 1331863.6599\n",
      "(Validation) Loss: 1391734.8114, MAE: 5240.6426, R2: -0.1705\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [169/5000] | Time: 0.27s\n",
      "(Training) Loss: 1336956.9975\n",
      "(Validation) Loss: 1391970.6565, MAE: 5243.3086, R2: -0.1707\n",
      "==========================================================================================\n",
      "Epoch [170/5000] | Time: 0.24s\n",
      "(Training) Loss: 1341334.0711\n",
      "(Validation) Loss: 1391177.4883, MAE: 5237.9473, R2: -0.1701\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [171/5000] | Time: 0.31s\n",
      "(Training) Loss: 1332050.6789\n",
      "(Validation) Loss: 1390902.2222, MAE: 5236.6567, R2: -0.1698\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [172/5000] | Time: 0.26s\n",
      "(Training) Loss: 1335687.1142\n",
      "(Validation) Loss: 1390625.1479, MAE: 5235.6294, R2: -0.1696\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [173/5000] | Time: 0.32s\n",
      "(Training) Loss: 1345313.9734\n",
      "(Validation) Loss: 1390344.4419, MAE: 5234.6655, R2: -0.1694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [174/5000] | Time: 0.25s\n",
      "(Training) Loss: 1347863.9962\n",
      "(Validation) Loss: 1390068.3225, MAE: 5233.2109, R2: -0.1691\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [175/5000] | Time: 0.28s\n",
      "(Training) Loss: 1341350.9645\n",
      "(Validation) Loss: 1389791.2838, MAE: 5231.8457, R2: -0.1689\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [176/5000] | Time: 0.27s\n",
      "(Training) Loss: 1319773.7350\n",
      "(Validation) Loss: 1389513.8438, MAE: 5231.3623, R2: -0.1687\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [177/5000] | Time: 0.25s\n",
      "(Training) Loss: 1323952.1326\n",
      "(Validation) Loss: 1389241.5949, MAE: 5230.0859, R2: -0.1684\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [178/5000] | Time: 0.25s\n",
      "(Training) Loss: 1341253.4492\n",
      "(Validation) Loss: 1388964.2210, MAE: 5228.4263, R2: -0.1682\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [179/5000] | Time: 0.25s\n",
      "(Training) Loss: 1351039.7322\n",
      "(Validation) Loss: 1388685.9632, MAE: 5227.0591, R2: -0.1680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [180/5000] | Time: 0.24s\n",
      "(Training) Loss: 1321112.1342\n",
      "(Validation) Loss: 1388408.3606, MAE: 5226.5381, R2: -0.1678\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [181/5000] | Time: 0.27s\n",
      "(Training) Loss: 1347007.4949\n",
      "(Validation) Loss: 1388132.3886, MAE: 5225.3779, R2: -0.1675\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [182/5000] | Time: 0.28s\n",
      "(Training) Loss: 1340209.0393\n",
      "(Validation) Loss: 1387849.8946, MAE: 5223.6255, R2: -0.1673\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [183/5000] | Time: 0.37s\n",
      "(Training) Loss: 1326512.9594\n",
      "(Validation) Loss: 1387575.1822, MAE: 5222.6899, R2: -0.1671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [184/5000] | Time: 0.33s\n",
      "(Training) Loss: 1346727.9645\n",
      "(Validation) Loss: 1387299.7841, MAE: 5221.2378, R2: -0.1668\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [185/5000] | Time: 0.25s\n",
      "(Training) Loss: 1336541.9302\n",
      "(Validation) Loss: 1387021.3790, MAE: 5220.0708, R2: -0.1666\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [186/5000] | Time: 0.21s\n",
      "(Training) Loss: 1331033.3617\n",
      "(Validation) Loss: 1386742.0444, MAE: 5218.8735, R2: -0.1664\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [187/5000] | Time: 0.20s\n",
      "(Training) Loss: 1320571.6409\n",
      "(Validation) Loss: 1386467.2203, MAE: 5217.7153, R2: -0.1661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [188/5000] | Time: 0.23s\n",
      "(Training) Loss: 1331949.9239\n",
      "(Validation) Loss: 1386193.9505, MAE: 5216.4561, R2: -0.1659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [189/5000] | Time: 0.19s\n",
      "(Training) Loss: 1326143.8769\n",
      "(Validation) Loss: 1385917.0641, MAE: 5215.6602, R2: -0.1657\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [190/5000] | Time: 0.20s\n",
      "(Training) Loss: 1350150.0190\n",
      "(Validation) Loss: 1385638.5676, MAE: 5214.1538, R2: -0.1654\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [191/5000] | Time: 0.20s\n",
      "(Training) Loss: 1355813.4289\n",
      "(Validation) Loss: 1385360.7314, MAE: 5212.8774, R2: -0.1652\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [192/5000] | Time: 0.19s\n",
      "(Training) Loss: 1336314.9175\n",
      "(Validation) Loss: 1385086.3695, MAE: 5212.0635, R2: -0.1650\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [193/5000] | Time: 0.20s\n",
      "(Training) Loss: 1326090.0063\n",
      "(Validation) Loss: 1384805.7448, MAE: 5211.4126, R2: -0.1648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [194/5000] | Time: 0.19s\n",
      "(Training) Loss: 1339058.5863\n",
      "(Validation) Loss: 1384533.4248, MAE: 5209.5000, R2: -0.1645\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [195/5000] | Time: 0.22s\n",
      "(Training) Loss: 1331884.0812\n",
      "(Validation) Loss: 1384257.1632, MAE: 5207.9951, R2: -0.1643\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [196/5000] | Time: 0.19s\n",
      "(Training) Loss: 1343568.9594\n",
      "(Validation) Loss: 1383978.0368, MAE: 5206.8999, R2: -0.1641\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [197/5000] | Time: 0.21s\n",
      "(Training) Loss: 1330550.1701\n",
      "(Validation) Loss: 1383697.8235, MAE: 5205.7808, R2: -0.1638\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [198/5000] | Time: 0.22s\n",
      "(Training) Loss: 1353400.0926\n",
      "(Validation) Loss: 1383426.4635, MAE: 5204.5859, R2: -0.1636\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [199/5000] | Time: 0.23s\n",
      "(Training) Loss: 1349902.1739\n",
      "(Validation) Loss: 1383147.6317, MAE: 5203.3208, R2: -0.1634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [200/5000] | Time: 0.20s\n",
      "(Training) Loss: 1325442.6371\n",
      "(Validation) Loss: 1382868.1549, MAE: 5201.9629, R2: -0.1631\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [201/5000] | Time: 0.19s\n",
      "(Training) Loss: 1339691.2957\n",
      "(Validation) Loss: 1382592.0000, MAE: 5200.8062, R2: -0.1629\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [202/5000] | Time: 0.23s\n",
      "(Training) Loss: 1334638.5787\n",
      "(Validation) Loss: 1382313.5898, MAE: 5199.9673, R2: -0.1627\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [203/5000] | Time: 0.24s\n",
      "(Training) Loss: 1321789.9201\n",
      "(Validation) Loss: 1382040.4622, MAE: 5198.6938, R2: -0.1624\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [204/5000] | Time: 0.21s\n",
      "(Training) Loss: 1325106.8718\n",
      "(Validation) Loss: 1381765.5924, MAE: 5197.4941, R2: -0.1622\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [205/5000] | Time: 0.21s\n",
      "(Training) Loss: 1375695.6891\n",
      "(Validation) Loss: 1381491.2711, MAE: 5196.5483, R2: -0.1620\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [206/5000] | Time: 0.22s\n",
      "(Training) Loss: 1359553.6472\n",
      "(Validation) Loss: 1381209.5594, MAE: 5195.0630, R2: -0.1618\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [207/5000] | Time: 0.21s\n",
      "(Training) Loss: 1330251.4518\n",
      "(Validation) Loss: 1380931.1594, MAE: 5193.4609, R2: -0.1615\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [208/5000] | Time: 0.22s\n",
      "(Training) Loss: 1336517.9492\n",
      "(Validation) Loss: 1380653.2419, MAE: 5192.6055, R2: -0.1613\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [209/5000] | Time: 0.25s\n",
      "(Training) Loss: 1313006.0701\n",
      "(Validation) Loss: 1380383.4717, MAE: 5192.2339, R2: -0.1611\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [210/5000] | Time: 0.23s\n",
      "(Training) Loss: 1336297.7576\n",
      "(Validation) Loss: 1380111.5022, MAE: 5190.6016, R2: -0.1608\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [211/5000] | Time: 0.22s\n",
      "(Training) Loss: 1328080.8864\n",
      "(Validation) Loss: 1379836.0025, MAE: 5189.9004, R2: -0.1606\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [212/5000] | Time: 0.25s\n",
      "(Training) Loss: 1335356.8020\n",
      "(Validation) Loss: 1379563.5759, MAE: 5188.4175, R2: -0.1604\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [213/5000] | Time: 0.26s\n",
      "(Training) Loss: 1342013.8782\n",
      "(Validation) Loss: 1379287.3244, MAE: 5186.8174, R2: -0.1602\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [214/5000] | Time: 0.37s\n",
      "(Training) Loss: 1330565.9397\n",
      "(Validation) Loss: 1379009.3562, MAE: 5185.6411, R2: -0.1599\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [215/5000] | Time: 0.25s\n",
      "(Training) Loss: 1330670.1764\n",
      "(Validation) Loss: 1378734.1816, MAE: 5184.6592, R2: -0.1597\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [216/5000] | Time: 0.26s\n",
      "(Training) Loss: 1325055.1003\n",
      "(Validation) Loss: 1378461.0489, MAE: 5182.9580, R2: -0.1595\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [217/5000] | Time: 0.29s\n",
      "(Training) Loss: 1340704.7525\n",
      "(Validation) Loss: 1378187.6165, MAE: 5182.0693, R2: -0.1592\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [218/5000] | Time: 0.34s\n",
      "(Training) Loss: 1320944.1294\n",
      "(Validation) Loss: 1377911.9543, MAE: 5180.4370, R2: -0.1590\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [219/5000] | Time: 0.28s\n",
      "(Training) Loss: 1348618.9353\n",
      "(Validation) Loss: 1377638.9943, MAE: 5179.5659, R2: -0.1588\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [220/5000] | Time: 0.32s\n",
      "(Training) Loss: 1329642.7843\n",
      "(Validation) Loss: 1377361.0971, MAE: 5178.2305, R2: -0.1585\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [221/5000] | Time: 0.23s\n",
      "(Training) Loss: 1318589.3344\n",
      "(Validation) Loss: 1377084.4190, MAE: 5177.3462, R2: -0.1583\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [222/5000] | Time: 0.28s\n",
      "(Training) Loss: 1331368.8109\n",
      "(Validation) Loss: 1376810.6463, MAE: 5175.9424, R2: -0.1581\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [223/5000] | Time: 0.25s\n",
      "(Training) Loss: 1334986.5926\n",
      "(Validation) Loss: 1376539.5048, MAE: 5174.8540, R2: -0.1579\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [224/5000] | Time: 0.23s\n",
      "(Training) Loss: 1315985.0184\n",
      "(Validation) Loss: 1376264.4216, MAE: 5173.4717, R2: -0.1576\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [225/5000] | Time: 0.20s\n",
      "(Training) Loss: 1328346.7868\n",
      "(Validation) Loss: 1375992.4317, MAE: 5172.4756, R2: -0.1574\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [226/5000] | Time: 0.23s\n",
      "(Training) Loss: 1320760.9442\n",
      "(Validation) Loss: 1375716.0381, MAE: 5171.5195, R2: -0.1572\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [227/5000] | Time: 0.26s\n",
      "(Training) Loss: 1354110.3864\n",
      "(Validation) Loss: 1375445.7397, MAE: 5170.2969, R2: -0.1569\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [228/5000] | Time: 0.22s\n",
      "(Training) Loss: 1340254.1865\n",
      "(Validation) Loss: 1375167.6546, MAE: 5169.1255, R2: -0.1567\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [229/5000] | Time: 0.19s\n",
      "(Training) Loss: 1317942.0863\n",
      "(Validation) Loss: 1374890.7530, MAE: 5167.6328, R2: -0.1565\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [230/5000] | Time: 0.21s\n",
      "(Training) Loss: 1318960.4010\n",
      "(Validation) Loss: 1374620.4292, MAE: 5167.1641, R2: -0.1563\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [231/5000] | Time: 0.20s\n",
      "(Training) Loss: 1339839.2538\n",
      "(Validation) Loss: 1374345.8794, MAE: 5166.0571, R2: -0.1560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [232/5000] | Time: 0.19s\n",
      "(Training) Loss: 1324128.1523\n",
      "(Validation) Loss: 1374072.7365, MAE: 5164.6860, R2: -0.1558\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [233/5000] | Time: 0.19s\n",
      "(Training) Loss: 1336416.7881\n",
      "(Validation) Loss: 1373801.0108, MAE: 5163.7266, R2: -0.1556\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [234/5000] | Time: 0.23s\n",
      "(Training) Loss: 1342967.3642\n",
      "(Validation) Loss: 1373525.1098, MAE: 5162.3452, R2: -0.1553\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [235/5000] | Time: 0.21s\n",
      "(Training) Loss: 1320857.2563\n",
      "(Validation) Loss: 1373248.0203, MAE: 5160.8301, R2: -0.1551\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [236/5000] | Time: 0.22s\n",
      "(Training) Loss: 1333556.5292\n",
      "(Validation) Loss: 1372975.9441, MAE: 5160.3770, R2: -0.1549\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [237/5000] | Time: 0.21s\n",
      "(Training) Loss: 1332010.6472\n",
      "(Validation) Loss: 1372699.8298, MAE: 5159.1382, R2: -0.1547\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [238/5000] | Time: 0.31s\n",
      "(Training) Loss: 1333032.1751\n",
      "(Validation) Loss: 1372425.5543, MAE: 5157.6836, R2: -0.1544\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [239/5000] | Time: 0.25s\n",
      "(Training) Loss: 1315854.9594\n",
      "(Validation) Loss: 1372156.2565, MAE: 5156.5522, R2: -0.1542\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [240/5000] | Time: 0.25s\n",
      "(Training) Loss: 1329894.7538\n",
      "(Validation) Loss: 1371882.1283, MAE: 5155.0288, R2: -0.1540\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [241/5000] | Time: 0.28s\n",
      "(Training) Loss: 1326781.6536\n",
      "(Validation) Loss: 1371607.7105, MAE: 5153.9170, R2: -0.1538\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [242/5000] | Time: 0.30s\n",
      "(Training) Loss: 1327009.0190\n",
      "(Validation) Loss: 1371336.0356, MAE: 5152.8804, R2: -0.1535\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [243/5000] | Time: 0.25s\n",
      "(Training) Loss: 1313854.3198\n",
      "(Validation) Loss: 1371063.4565, MAE: 5151.3750, R2: -0.1533\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [244/5000] | Time: 0.26s\n",
      "(Training) Loss: 1335513.6352\n",
      "(Validation) Loss: 1370792.1676, MAE: 5150.2500, R2: -0.1531\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [245/5000] | Time: 0.29s\n",
      "(Training) Loss: 1325962.6548\n",
      "(Validation) Loss: 1370515.1441, MAE: 5149.0088, R2: -0.1528\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [246/5000] | Time: 0.32s\n",
      "(Training) Loss: 1341291.3852\n",
      "(Validation) Loss: 1370238.5168, MAE: 5147.8237, R2: -0.1526\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [247/5000] | Time: 0.35s\n",
      "(Training) Loss: 1308785.7062\n",
      "(Validation) Loss: 1369967.7562, MAE: 5146.5415, R2: -0.1524\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [248/5000] | Time: 0.32s\n",
      "(Training) Loss: 1316542.6739\n",
      "(Validation) Loss: 1369695.4717, MAE: 5145.3569, R2: -0.1522\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [249/5000] | Time: 0.29s\n",
      "(Training) Loss: 1306270.9175\n",
      "(Validation) Loss: 1369423.4463, MAE: 5144.3398, R2: -0.1519\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [250/5000] | Time: 0.31s\n",
      "(Training) Loss: 1322865.2475\n",
      "(Validation) Loss: 1369156.1651, MAE: 5143.1772, R2: -0.1517\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [251/5000] | Time: 0.36s\n",
      "(Training) Loss: 1330869.1853\n",
      "(Validation) Loss: 1368882.0470, MAE: 5141.7900, R2: -0.1515\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [252/5000] | Time: 0.29s\n",
      "(Training) Loss: 1310621.1865\n",
      "(Validation) Loss: 1368605.4349, MAE: 5141.3364, R2: -0.1512\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [253/5000] | Time: 0.30s\n",
      "(Training) Loss: 1322874.5825\n",
      "(Validation) Loss: 1368336.6857, MAE: 5139.9111, R2: -0.1510\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [254/5000] | Time: 0.31s\n",
      "(Training) Loss: 1300286.5048\n",
      "(Validation) Loss: 1368063.4616, MAE: 5138.3916, R2: -0.1508\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [255/5000] | Time: 0.34s\n",
      "(Training) Loss: 1316904.9543\n",
      "(Validation) Loss: 1367793.4832, MAE: 5137.3770, R2: -0.1506\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [256/5000] | Time: 0.28s\n",
      "(Training) Loss: 1351574.1751\n",
      "(Validation) Loss: 1367523.5048, MAE: 5136.0127, R2: -0.1503\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [257/5000] | Time: 0.27s\n",
      "(Training) Loss: 1307606.7893\n",
      "(Validation) Loss: 1367245.6381, MAE: 5135.2490, R2: -0.1501\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [258/5000] | Time: 0.28s\n",
      "(Training) Loss: 1308395.9619\n",
      "(Validation) Loss: 1366979.8400, MAE: 5133.9956, R2: -0.1499\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [259/5000] | Time: 0.32s\n",
      "(Training) Loss: 1326217.7874\n",
      "(Validation) Loss: 1366707.5556, MAE: 5132.6348, R2: -0.1497\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [260/5000] | Time: 0.24s\n",
      "(Training) Loss: 1337899.0495\n",
      "(Validation) Loss: 1366435.7587, MAE: 5131.4185, R2: -0.1494\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [261/5000] | Time: 0.25s\n",
      "(Training) Loss: 1313944.9835\n",
      "(Validation) Loss: 1366159.5175, MAE: 5130.1313, R2: -0.1492\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [262/5000] | Time: 0.28s\n",
      "(Training) Loss: 1301080.9740\n",
      "(Validation) Loss: 1365891.3625, MAE: 5129.0259, R2: -0.1490\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [263/5000] | Time: 0.28s\n",
      "(Training) Loss: 1300936.4312\n",
      "(Validation) Loss: 1365620.4851, MAE: 5128.1099, R2: -0.1488\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [264/5000] | Time: 0.28s\n",
      "(Training) Loss: 1311094.8788\n",
      "(Validation) Loss: 1365353.7727, MAE: 5126.6147, R2: -0.1485\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [265/5000] | Time: 0.26s\n",
      "(Training) Loss: 1318421.1409\n",
      "(Validation) Loss: 1365079.9848, MAE: 5125.5923, R2: -0.1483\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [266/5000] | Time: 0.27s\n",
      "(Training) Loss: 1299424.7164\n",
      "(Validation) Loss: 1364810.9968, MAE: 5124.5059, R2: -0.1481\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [267/5000] | Time: 0.26s\n",
      "(Training) Loss: 1334256.8223\n",
      "(Validation) Loss: 1364540.6476, MAE: 5122.9893, R2: -0.1479\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [268/5000] | Time: 0.28s\n",
      "(Training) Loss: 1325098.3947\n",
      "(Validation) Loss: 1364268.2260, MAE: 5122.0386, R2: -0.1476\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [269/5000] | Time: 0.24s\n",
      "(Training) Loss: 1306776.2386\n",
      "(Validation) Loss: 1363994.1689, MAE: 5120.6450, R2: -0.1474\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [270/5000] | Time: 0.27s\n",
      "(Training) Loss: 1322958.9270\n",
      "(Validation) Loss: 1363722.0622, MAE: 5119.5942, R2: -0.1472\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [271/5000] | Time: 0.27s\n",
      "(Training) Loss: 1321031.8883\n",
      "(Validation) Loss: 1363449.9911, MAE: 5118.5430, R2: -0.1470\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [272/5000] | Time: 0.29s\n",
      "(Training) Loss: 1315754.3871\n",
      "(Validation) Loss: 1363176.1016, MAE: 5117.2642, R2: -0.1467\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [273/5000] | Time: 0.28s\n",
      "(Training) Loss: 1319901.4264\n",
      "(Validation) Loss: 1362909.0489, MAE: 5116.7666, R2: -0.1465\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [274/5000] | Time: 0.32s\n",
      "(Training) Loss: 1307027.3109\n",
      "(Validation) Loss: 1362636.1397, MAE: 5115.3311, R2: -0.1463\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [275/5000] | Time: 0.26s\n",
      "(Training) Loss: 1300464.8718\n",
      "(Validation) Loss: 1362365.6940, MAE: 5114.0312, R2: -0.1460\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [276/5000] | Time: 0.31s\n",
      "(Training) Loss: 1309988.6256\n",
      "(Validation) Loss: 1362098.0521, MAE: 5112.6729, R2: -0.1458\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [277/5000] | Time: 0.28s\n",
      "(Training) Loss: 1326296.8706\n",
      "(Validation) Loss: 1361828.6730, MAE: 5111.4839, R2: -0.1456\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [278/5000] | Time: 0.29s\n",
      "(Training) Loss: 1308570.6726\n",
      "(Validation) Loss: 1361554.4990, MAE: 5110.6338, R2: -0.1454\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [279/5000] | Time: 0.29s\n",
      "(Training) Loss: 1313419.5774\n",
      "(Validation) Loss: 1361283.2508, MAE: 5109.0854, R2: -0.1451\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [280/5000] | Time: 0.29s\n",
      "(Training) Loss: 1303509.9911\n",
      "(Validation) Loss: 1361016.4419, MAE: 5107.8716, R2: -0.1449\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [281/5000] | Time: 0.33s\n",
      "(Training) Loss: 1310821.6701\n",
      "(Validation) Loss: 1360742.7606, MAE: 5106.6899, R2: -0.1447\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [282/5000] | Time: 0.40s\n",
      "(Training) Loss: 1306465.1878\n",
      "(Validation) Loss: 1360473.1378, MAE: 5105.6187, R2: -0.1445\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [283/5000] | Time: 0.32s\n",
      "(Training) Loss: 1295527.1056\n",
      "(Validation) Loss: 1360205.7448, MAE: 5104.4399, R2: -0.1442\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [284/5000] | Time: 0.36s\n",
      "(Training) Loss: 1313917.5964\n",
      "(Validation) Loss: 1359936.2184, MAE: 5103.3330, R2: -0.1440\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [285/5000] | Time: 0.26s\n",
      "(Training) Loss: 1306239.4150\n",
      "(Validation) Loss: 1359665.7016, MAE: 5102.0293, R2: -0.1438\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [286/5000] | Time: 0.36s\n",
      "(Training) Loss: 1314124.0964\n",
      "(Validation) Loss: 1359395.8806, MAE: 5101.2710, R2: -0.1436\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [287/5000] | Time: 0.32s\n",
      "(Training) Loss: 1317641.9569\n",
      "(Validation) Loss: 1359123.0730, MAE: 5100.0718, R2: -0.1433\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [288/5000] | Time: 0.32s\n",
      "(Training) Loss: 1314862.6085\n",
      "(Validation) Loss: 1358853.4806, MAE: 5098.4414, R2: -0.1431\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [289/5000] | Time: 0.26s\n",
      "(Training) Loss: 1307268.6396\n",
      "(Validation) Loss: 1358584.3048, MAE: 5097.5874, R2: -0.1429\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [290/5000] | Time: 0.32s\n",
      "(Training) Loss: 1296886.8832\n",
      "(Validation) Loss: 1358317.7346, MAE: 5096.4106, R2: -0.1427\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [291/5000] | Time: 0.38s\n",
      "(Training) Loss: 1310981.8135\n",
      "(Validation) Loss: 1358049.2800, MAE: 5095.3101, R2: -0.1425\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [292/5000] | Time: 0.34s\n",
      "(Training) Loss: 1306107.9607\n",
      "(Validation) Loss: 1357776.7060, MAE: 5094.8071, R2: -0.1422\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [293/5000] | Time: 0.28s\n",
      "(Training) Loss: 1303006.7716\n",
      "(Validation) Loss: 1357504.0914, MAE: 5093.0151, R2: -0.1420\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [294/5000] | Time: 0.27s\n",
      "(Training) Loss: 1292029.5701\n",
      "(Validation) Loss: 1357236.1651, MAE: 5091.8418, R2: -0.1418\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [295/5000] | Time: 0.24s\n",
      "(Training) Loss: 1303362.0977\n",
      "(Validation) Loss: 1356966.9994, MAE: 5090.3940, R2: -0.1415\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [296/5000] | Time: 0.24s\n",
      "(Training) Loss: 1299556.5736\n",
      "(Validation) Loss: 1356699.8146, MAE: 5089.3623, R2: -0.1413\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [297/5000] | Time: 0.26s\n",
      "(Training) Loss: 1316498.1155\n",
      "(Validation) Loss: 1356432.3454, MAE: 5088.4014, R2: -0.1411\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [298/5000] | Time: 0.29s\n",
      "(Training) Loss: 1319660.1168\n",
      "(Validation) Loss: 1356161.9149, MAE: 5087.4746, R2: -0.1409\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [299/5000] | Time: 0.40s\n",
      "(Training) Loss: 1331095.7805\n",
      "(Validation) Loss: 1355885.9987, MAE: 5085.9146, R2: -0.1406\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [300/5000] | Time: 0.38s\n",
      "(Training) Loss: 1307024.9061\n",
      "(Validation) Loss: 1355613.6940, MAE: 5085.1846, R2: -0.1404\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [301/5000] | Time: 0.38s\n",
      "(Training) Loss: 1297892.4429\n",
      "(Validation) Loss: 1355344.2438, MAE: 5083.5503, R2: -0.1402\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [302/5000] | Time: 0.28s\n",
      "(Training) Loss: 1293668.3617\n",
      "(Validation) Loss: 1355076.3530, MAE: 5082.2129, R2: -0.1400\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [303/5000] | Time: 0.32s\n",
      "(Training) Loss: 1314341.0660\n",
      "(Validation) Loss: 1354810.4483, MAE: 5081.1650, R2: -0.1398\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [304/5000] | Time: 0.33s\n",
      "(Training) Loss: 1299632.6878\n",
      "(Validation) Loss: 1354541.5010, MAE: 5081.2051, R2: -0.1395\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [305/5000] | Time: 0.33s\n",
      "(Training) Loss: 1294907.6929\n",
      "(Validation) Loss: 1354270.5270, MAE: 5080.1484, R2: -0.1393\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [306/5000] | Time: 0.38s\n",
      "(Training) Loss: 1321150.8852\n",
      "(Validation) Loss: 1354002.4990, MAE: 5078.7173, R2: -0.1391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [307/5000] | Time: 0.33s\n",
      "(Training) Loss: 1298222.8997\n",
      "(Validation) Loss: 1353727.6800, MAE: 5076.7734, R2: -0.1388\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [308/5000] | Time: 0.41s\n",
      "(Training) Loss: 1299911.5292\n",
      "(Validation) Loss: 1353462.9892, MAE: 5075.6484, R2: -0.1386\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [309/5000] | Time: 0.44s\n",
      "(Training) Loss: 1321902.1751\n",
      "(Validation) Loss: 1353193.1886, MAE: 5074.6523, R2: -0.1384\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [310/5000] | Time: 0.40s\n",
      "(Training) Loss: 1322263.0343\n",
      "(Validation) Loss: 1354216.5283, MAE: 5079.1714, R2: -0.1393\n",
      "==========================================================================================\n",
      "Epoch [311/5000] | Time: 0.36s\n",
      "(Training) Loss: 1292429.1707\n",
      "(Validation) Loss: 1352648.7010, MAE: 5072.1904, R2: -0.1380\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [312/5000] | Time: 0.36s\n",
      "(Training) Loss: 1308609.1967\n",
      "(Validation) Loss: 1352386.4432, MAE: 5071.5845, R2: -0.1377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [313/5000] | Time: 0.33s\n",
      "(Training) Loss: 1307822.1072\n",
      "(Validation) Loss: 1352121.5441, MAE: 5069.8364, R2: -0.1375\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [314/5000] | Time: 0.28s\n",
      "(Training) Loss: 1328661.0723\n",
      "(Validation) Loss: 1351844.8356, MAE: 5068.4868, R2: -0.1373\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [315/5000] | Time: 0.27s\n",
      "(Training) Loss: 1289873.7646\n",
      "(Validation) Loss: 1351576.3403, MAE: 5067.8716, R2: -0.1371\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [316/5000] | Time: 0.29s\n",
      "(Training) Loss: 1291628.6117\n",
      "(Validation) Loss: 1351306.8800, MAE: 5066.3862, R2: -0.1368\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [317/5000] | Time: 0.29s\n",
      "(Training) Loss: 1306329.9714\n",
      "(Validation) Loss: 1351040.9041, MAE: 5064.9155, R2: -0.1366\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [318/5000] | Time: 0.27s\n",
      "(Training) Loss: 1294421.3744\n",
      "(Validation) Loss: 1350772.6222, MAE: 5063.9155, R2: -0.1364\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [319/5000] | Time: 0.38s\n",
      "(Training) Loss: 1294848.8439\n",
      "(Validation) Loss: 1350508.4140, MAE: 5062.7920, R2: -0.1362\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [320/5000] | Time: 0.45s\n",
      "(Training) Loss: 1284462.0143\n",
      "(Validation) Loss: 1350238.9029, MAE: 5061.7192, R2: -0.1359\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [321/5000] | Time: 0.41s\n",
      "(Training) Loss: 1294873.5190\n",
      "(Validation) Loss: 1349972.6679, MAE: 5060.4487, R2: -0.1357\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [322/5000] | Time: 0.25s\n",
      "(Training) Loss: 1292088.9670\n",
      "(Validation) Loss: 1349705.7575, MAE: 5059.6221, R2: -0.1355\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [323/5000] | Time: 0.41s\n",
      "(Training) Loss: 1293284.3706\n",
      "(Validation) Loss: 1349440.0356, MAE: 5058.9976, R2: -0.1353\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [324/5000] | Time: 0.34s\n",
      "(Training) Loss: 1299162.0673\n",
      "(Validation) Loss: 1349172.1092, MAE: 5056.9795, R2: -0.1351\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [325/5000] | Time: 0.27s\n",
      "(Training) Loss: 1282931.5159\n",
      "(Validation) Loss: 1348903.2330, MAE: 5056.4072, R2: -0.1348\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [326/5000] | Time: 0.30s\n",
      "(Training) Loss: 1298585.4156\n",
      "(Validation) Loss: 1348638.1308, MAE: 5054.7788, R2: -0.1346\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [327/5000] | Time: 0.26s\n",
      "(Training) Loss: 1318764.7440\n",
      "(Validation) Loss: 1348370.7683, MAE: 5053.7969, R2: -0.1344\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [328/5000] | Time: 0.31s\n",
      "(Training) Loss: 1305680.7513\n",
      "(Validation) Loss: 1348101.7549, MAE: 5052.4541, R2: -0.1342\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [329/5000] | Time: 0.36s\n",
      "(Training) Loss: 1285158.5133\n",
      "(Validation) Loss: 1347835.0679, MAE: 5051.5938, R2: -0.1339\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [330/5000] | Time: 0.34s\n",
      "(Training) Loss: 1296368.6079\n",
      "(Validation) Loss: 1347564.3479, MAE: 5050.2437, R2: -0.1337\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [331/5000] | Time: 0.30s\n",
      "(Training) Loss: 1302249.9575\n",
      "(Validation) Loss: 1347297.1530, MAE: 5049.3423, R2: -0.1335\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [332/5000] | Time: 0.31s\n",
      "(Training) Loss: 1308247.3617\n",
      "(Validation) Loss: 1347032.5029, MAE: 5047.7300, R2: -0.1333\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [333/5000] | Time: 0.34s\n",
      "(Training) Loss: 1320845.8718\n",
      "(Validation) Loss: 1346762.3314, MAE: 5047.2290, R2: -0.1330\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [334/5000] | Time: 0.29s\n",
      "(Training) Loss: 1302225.5241\n",
      "(Validation) Loss: 1346493.3994, MAE: 5046.0459, R2: -0.1328\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [335/5000] | Time: 0.32s\n",
      "(Training) Loss: 1294419.7062\n",
      "(Validation) Loss: 1346223.8324, MAE: 5044.8135, R2: -0.1326\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [336/5000] | Time: 0.27s\n",
      "(Training) Loss: 1299116.8820\n",
      "(Validation) Loss: 1345954.8343, MAE: 5043.4678, R2: -0.1324\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [337/5000] | Time: 0.26s\n",
      "(Training) Loss: 1335167.3947\n",
      "(Validation) Loss: 1345689.7981, MAE: 5042.2090, R2: -0.1322\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [338/5000] | Time: 0.26s\n",
      "(Training) Loss: 1303184.9524\n",
      "(Validation) Loss: 1345418.8648, MAE: 5041.1401, R2: -0.1319\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [339/5000] | Time: 0.30s\n",
      "(Training) Loss: 1299420.9258\n",
      "(Validation) Loss: 1345150.7708, MAE: 5039.9272, R2: -0.1317\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [340/5000] | Time: 0.27s\n",
      "(Training) Loss: 1301407.2525\n",
      "(Validation) Loss: 1344882.3619, MAE: 5038.8887, R2: -0.1315\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [341/5000] | Time: 0.29s\n",
      "(Training) Loss: 1279337.0504\n",
      "(Validation) Loss: 1344615.7410, MAE: 5037.4019, R2: -0.1313\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [342/5000] | Time: 0.28s\n",
      "(Training) Loss: 1295538.9239\n",
      "(Validation) Loss: 1344350.4813, MAE: 5036.5151, R2: -0.1310\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [343/5000] | Time: 0.32s\n",
      "(Training) Loss: 1310749.6485\n",
      "(Validation) Loss: 1344088.2083, MAE: 5037.0024, R2: -0.1308\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [344/5000] | Time: 0.36s\n",
      "(Training) Loss: 1307325.0086\n",
      "(Validation) Loss: 1343816.6248, MAE: 5034.1338, R2: -0.1306\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [345/5000] | Time: 0.31s\n",
      "(Training) Loss: 1312625.0038\n",
      "(Validation) Loss: 1343547.3575, MAE: 5033.0923, R2: -0.1304\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [346/5000] | Time: 0.28s\n",
      "(Training) Loss: 1295885.8477\n",
      "(Validation) Loss: 1343279.3752, MAE: 5032.6938, R2: -0.1301\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [347/5000] | Time: 0.28s\n",
      "(Training) Loss: 1279279.5105\n",
      "(Validation) Loss: 1343015.4260, MAE: 5030.8604, R2: -0.1299\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [348/5000] | Time: 0.25s\n",
      "(Training) Loss: 1322068.2056\n",
      "(Validation) Loss: 1342755.0883, MAE: 5029.5840, R2: -0.1297\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [349/5000] | Time: 0.26s\n",
      "(Training) Loss: 1281909.5051\n",
      "(Validation) Loss: 1342478.6794, MAE: 5028.6577, R2: -0.1295\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [350/5000] | Time: 0.30s\n",
      "(Training) Loss: 1300116.6802\n",
      "(Validation) Loss: 1342216.9905, MAE: 5027.2129, R2: -0.1293\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [351/5000] | Time: 0.31s\n",
      "(Training) Loss: 1291266.0102\n",
      "(Validation) Loss: 1341952.4013, MAE: 5027.2695, R2: -0.1290\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [352/5000] | Time: 0.32s\n",
      "(Training) Loss: 1299772.0089\n",
      "(Validation) Loss: 1341683.4133, MAE: 5024.7500, R2: -0.1288\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [353/5000] | Time: 0.31s\n",
      "(Training) Loss: 1285412.3350\n",
      "(Validation) Loss: 1341416.7517, MAE: 5023.9331, R2: -0.1286\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [354/5000] | Time: 0.32s\n",
      "(Training) Loss: 1284044.0603\n",
      "(Validation) Loss: 1341152.2286, MAE: 5023.1431, R2: -0.1284\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [355/5000] | Time: 0.27s\n",
      "(Training) Loss: 1304115.1339\n",
      "(Validation) Loss: 1340886.9333, MAE: 5022.6802, R2: -0.1281\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [356/5000] | Time: 0.26s\n",
      "(Training) Loss: 1305146.4099\n",
      "(Validation) Loss: 1340625.5390, MAE: 5020.8662, R2: -0.1279\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [357/5000] | Time: 0.28s\n",
      "(Training) Loss: 1285738.3629\n",
      "(Validation) Loss: 1340357.2267, MAE: 5019.3765, R2: -0.1277\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [358/5000] | Time: 0.28s\n",
      "(Training) Loss: 1302743.3553\n",
      "(Validation) Loss: 1340091.8044, MAE: 5018.3525, R2: -0.1275\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [359/5000] | Time: 0.28s\n",
      "(Training) Loss: 1285959.5412\n",
      "(Validation) Loss: 1339820.2971, MAE: 5016.9136, R2: -0.1273\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [360/5000] | Time: 0.26s\n",
      "(Training) Loss: 1297689.7348\n",
      "(Validation) Loss: 1339559.4260, MAE: 5015.8823, R2: -0.1270\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [361/5000] | Time: 0.26s\n",
      "(Training) Loss: 1301524.1358\n",
      "(Validation) Loss: 1339293.3537, MAE: 5014.7544, R2: -0.1268\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [362/5000] | Time: 0.29s\n",
      "(Training) Loss: 1283645.7887\n",
      "(Validation) Loss: 1339027.4946, MAE: 5014.0303, R2: -0.1266\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [363/5000] | Time: 0.27s\n",
      "(Training) Loss: 1309512.7766\n",
      "(Validation) Loss: 1338762.9105, MAE: 5012.4839, R2: -0.1264\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [364/5000] | Time: 0.26s\n",
      "(Training) Loss: 1303994.3921\n",
      "(Validation) Loss: 1338493.5162, MAE: 5011.0317, R2: -0.1262\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [365/5000] | Time: 0.28s\n",
      "(Training) Loss: 1284170.0520\n",
      "(Validation) Loss: 1338227.0425, MAE: 5010.2148, R2: -0.1259\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [366/5000] | Time: 0.27s\n",
      "(Training) Loss: 1320405.3452\n",
      "(Validation) Loss: 1337967.9238, MAE: 5010.0317, R2: -0.1257\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [367/5000] | Time: 0.28s\n",
      "(Training) Loss: 1280382.1282\n",
      "(Validation) Loss: 1337695.0959, MAE: 5007.9102, R2: -0.1255\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [368/5000] | Time: 0.27s\n",
      "(Training) Loss: 1284167.7367\n",
      "(Validation) Loss: 1337433.0463, MAE: 5006.9390, R2: -0.1253\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [369/5000] | Time: 0.27s\n",
      "(Training) Loss: 1286882.2145\n",
      "(Validation) Loss: 1337166.4152, MAE: 5005.3901, R2: -0.1250\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [370/5000] | Time: 0.30s\n",
      "(Training) Loss: 1283517.4829\n",
      "(Validation) Loss: 1336904.7365, MAE: 5004.6021, R2: -0.1248\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [371/5000] | Time: 0.29s\n",
      "(Training) Loss: 1285965.4315\n",
      "(Validation) Loss: 1336639.5429, MAE: 5004.0596, R2: -0.1246\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [372/5000] | Time: 0.30s\n",
      "(Training) Loss: 1287769.8388\n",
      "(Validation) Loss: 1336382.1410, MAE: 5003.5039, R2: -0.1244\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [373/5000] | Time: 0.28s\n",
      "(Training) Loss: 1311770.6459\n",
      "(Validation) Loss: 1336109.9581, MAE: 5001.2559, R2: -0.1242\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [374/5000] | Time: 0.28s\n",
      "(Training) Loss: 1312209.4315\n",
      "(Validation) Loss: 1335846.3949, MAE: 5000.4087, R2: -0.1239\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [375/5000] | Time: 0.41s\n",
      "(Training) Loss: 1296641.3934\n",
      "(Validation) Loss: 1335579.7130, MAE: 4998.7837, R2: -0.1237\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [376/5000] | Time: 0.26s\n",
      "(Training) Loss: 1287298.1123\n",
      "(Validation) Loss: 1335312.0152, MAE: 4998.4028, R2: -0.1235\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [377/5000] | Time: 0.27s\n",
      "(Training) Loss: 1294641.5317\n",
      "(Validation) Loss: 1335047.8730, MAE: 4996.6411, R2: -0.1233\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [378/5000] | Time: 0.29s\n",
      "(Training) Loss: 1275519.2557\n",
      "(Validation) Loss: 1334784.5740, MAE: 4996.0347, R2: -0.1231\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [379/5000] | Time: 0.25s\n",
      "(Training) Loss: 1288082.0470\n",
      "(Validation) Loss: 1334520.3048, MAE: 4995.0229, R2: -0.1228\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [380/5000] | Time: 0.27s\n",
      "(Training) Loss: 1296087.4822\n",
      "(Validation) Loss: 1334255.6800, MAE: 4993.6328, R2: -0.1226\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [381/5000] | Time: 0.33s\n",
      "(Training) Loss: 1284197.7766\n",
      "(Validation) Loss: 1333990.3187, MAE: 4992.5205, R2: -0.1224\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [382/5000] | Time: 0.33s\n",
      "(Training) Loss: 1287646.3211\n",
      "(Validation) Loss: 1333728.1270, MAE: 4991.0542, R2: -0.1222\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [383/5000] | Time: 0.25s\n",
      "(Training) Loss: 1298508.6485\n",
      "(Validation) Loss: 1333461.1098, MAE: 4989.9756, R2: -0.1220\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [384/5000] | Time: 0.25s\n",
      "(Training) Loss: 1271669.6129\n",
      "(Validation) Loss: 1333196.8660, MAE: 4989.6050, R2: -0.1217\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [385/5000] | Time: 0.27s\n",
      "(Training) Loss: 1275762.4353\n",
      "(Validation) Loss: 1332935.9898, MAE: 4988.4219, R2: -0.1215\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [386/5000] | Time: 0.31s\n",
      "(Training) Loss: 1282113.1561\n",
      "(Validation) Loss: 1332672.0102, MAE: 4986.6064, R2: -0.1213\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [387/5000] | Time: 0.26s\n",
      "(Training) Loss: 1269239.4800\n",
      "(Validation) Loss: 1332407.6343, MAE: 4985.4897, R2: -0.1211\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [388/5000] | Time: 0.25s\n",
      "(Training) Loss: 1278450.9086\n",
      "(Validation) Loss: 1332149.8565, MAE: 4984.4038, R2: -0.1209\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [389/5000] | Time: 0.26s\n",
      "(Training) Loss: 1276518.2005\n",
      "(Validation) Loss: 1331887.1010, MAE: 4984.3384, R2: -0.1207\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [390/5000] | Time: 0.26s\n",
      "(Training) Loss: 1301554.8230\n",
      "(Validation) Loss: 1331621.9073, MAE: 4982.9888, R2: -0.1204\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [391/5000] | Time: 0.25s\n",
      "(Training) Loss: 1278521.2107\n",
      "(Validation) Loss: 1331359.2990, MAE: 4981.2524, R2: -0.1202\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [392/5000] | Time: 0.22s\n",
      "(Training) Loss: 1290996.7322\n",
      "(Validation) Loss: 1331095.4108, MAE: 4980.1919, R2: -0.1200\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [393/5000] | Time: 0.24s\n",
      "(Training) Loss: 1275680.5654\n",
      "(Validation) Loss: 1330830.1816, MAE: 4978.9814, R2: -0.1198\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [394/5000] | Time: 0.30s\n",
      "(Training) Loss: 1298766.2449\n",
      "(Validation) Loss: 1330566.2476, MAE: 4977.8623, R2: -0.1195\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [395/5000] | Time: 0.31s\n",
      "(Training) Loss: 1279111.6561\n",
      "(Validation) Loss: 1330303.4006, MAE: 4976.8413, R2: -0.1193\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [396/5000] | Time: 0.24s\n",
      "(Training) Loss: 1283339.8401\n",
      "(Validation) Loss: 1330042.1587, MAE: 4976.6079, R2: -0.1191\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [397/5000] | Time: 0.21s\n",
      "(Training) Loss: 1286663.6485\n",
      "(Validation) Loss: 1329777.6406, MAE: 4974.8843, R2: -0.1189\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [398/5000] | Time: 0.37s\n",
      "(Training) Loss: 1286980.4835\n",
      "(Validation) Loss: 1329514.8343, MAE: 4974.4575, R2: -0.1187\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [399/5000] | Time: 0.23s\n",
      "(Training) Loss: 1293526.6282\n",
      "(Validation) Loss: 1329249.0565, MAE: 4972.2148, R2: -0.1185\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [400/5000] | Time: 0.21s\n",
      "(Training) Loss: 1277754.1091\n",
      "(Validation) Loss: 1328983.0756, MAE: 4971.3975, R2: -0.1182\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [401/5000] | Time: 0.21s\n",
      "(Training) Loss: 1276978.2221\n",
      "(Validation) Loss: 1328719.2330, MAE: 4970.8999, R2: -0.1180\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [402/5000] | Time: 0.21s\n",
      "(Training) Loss: 1281267.8490\n",
      "(Validation) Loss: 1328459.8451, MAE: 4969.5605, R2: -0.1178\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [403/5000] | Time: 0.21s\n",
      "(Training) Loss: 1281209.3388\n",
      "(Validation) Loss: 1328193.7524, MAE: 4967.8115, R2: -0.1176\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [404/5000] | Time: 0.23s\n",
      "(Training) Loss: 1299444.5114\n",
      "(Validation) Loss: 1327932.5562, MAE: 4967.2944, R2: -0.1174\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [405/5000] | Time: 0.22s\n",
      "(Training) Loss: 1288956.4353\n",
      "(Validation) Loss: 1327667.2863, MAE: 4965.9771, R2: -0.1171\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [406/5000] | Time: 0.21s\n",
      "(Training) Loss: 1284584.8154\n",
      "(Validation) Loss: 1327404.6730, MAE: 4964.8833, R2: -0.1169\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [407/5000] | Time: 0.22s\n",
      "(Training) Loss: 1271537.4023\n",
      "(Validation) Loss: 1327140.9117, MAE: 4963.7266, R2: -0.1167\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [408/5000] | Time: 0.23s\n",
      "(Training) Loss: 1280695.7195\n",
      "(Validation) Loss: 1326878.8927, MAE: 4962.7974, R2: -0.1165\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [409/5000] | Time: 0.26s\n",
      "(Training) Loss: 1276229.9556\n",
      "(Validation) Loss: 1326615.8679, MAE: 4962.2046, R2: -0.1163\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [410/5000] | Time: 0.29s\n",
      "(Training) Loss: 1279420.0470\n",
      "(Validation) Loss: 1326356.1194, MAE: 4960.3813, R2: -0.1160\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [411/5000] | Time: 0.28s\n",
      "(Training) Loss: 1286973.7627\n",
      "(Validation) Loss: 1326091.7841, MAE: 4959.0161, R2: -0.1158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [412/5000] | Time: 0.27s\n",
      "(Training) Loss: 1288715.4315\n",
      "(Validation) Loss: 1325826.5600, MAE: 4958.0679, R2: -0.1156\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [413/5000] | Time: 0.29s\n",
      "(Training) Loss: 1281113.8553\n",
      "(Validation) Loss: 1325572.9778, MAE: 4957.8018, R2: -0.1154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [414/5000] | Time: 0.28s\n",
      "(Training) Loss: 1263321.2319\n",
      "(Validation) Loss: 1325304.7670, MAE: 4956.8398, R2: -0.1152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [415/5000] | Time: 0.30s\n",
      "(Training) Loss: 1272848.8192\n",
      "(Validation) Loss: 1325045.0489, MAE: 4955.4082, R2: -0.1149\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [416/5000] | Time: 0.28s\n",
      "(Training) Loss: 1266340.2183\n",
      "(Validation) Loss: 1324783.9949, MAE: 4954.0942, R2: -0.1147\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [417/5000] | Time: 0.26s\n",
      "(Training) Loss: 1288058.6681\n",
      "(Validation) Loss: 1324527.2889, MAE: 4954.0605, R2: -0.1145\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [418/5000] | Time: 0.27s\n",
      "(Training) Loss: 1267341.6041\n",
      "(Validation) Loss: 1324258.4584, MAE: 4952.9194, R2: -0.1143\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [419/5000] | Time: 0.28s\n",
      "(Training) Loss: 1263122.2272\n",
      "(Validation) Loss: 1323997.6838, MAE: 4951.4141, R2: -0.1141\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [420/5000] | Time: 0.29s\n",
      "(Training) Loss: 1274627.3579\n",
      "(Validation) Loss: 1323739.6470, MAE: 4949.5894, R2: -0.1139\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [421/5000] | Time: 0.30s\n",
      "(Training) Loss: 1266854.1472\n",
      "(Validation) Loss: 1323476.4038, MAE: 4948.5322, R2: -0.1136\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [422/5000] | Time: 0.28s\n",
      "(Training) Loss: 1272219.3426\n",
      "(Validation) Loss: 1323214.8114, MAE: 4947.3960, R2: -0.1134\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [423/5000] | Time: 0.28s\n",
      "(Training) Loss: 1288637.2779\n",
      "(Validation) Loss: 1322954.9714, MAE: 4947.1758, R2: -0.1132\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [424/5000] | Time: 0.28s\n",
      "(Training) Loss: 1273453.2221\n",
      "(Validation) Loss: 1322693.0641, MAE: 4945.6475, R2: -0.1130\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [425/5000] | Time: 0.28s\n",
      "(Training) Loss: 1271174.1066\n",
      "(Validation) Loss: 1322429.6584, MAE: 4944.5103, R2: -0.1128\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [426/5000] | Time: 0.28s\n",
      "(Training) Loss: 1293354.1307\n",
      "(Validation) Loss: 1322167.4921, MAE: 4943.0146, R2: -0.1126\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [427/5000] | Time: 0.28s\n",
      "(Training) Loss: 1269733.3236\n",
      "(Validation) Loss: 1321905.9302, MAE: 4942.1987, R2: -0.1123\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [428/5000] | Time: 0.36s\n",
      "(Training) Loss: 1269942.0463\n",
      "(Validation) Loss: 1321644.7238, MAE: 4941.9141, R2: -0.1121\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [429/5000] | Time: 0.32s\n",
      "(Training) Loss: 1262822.4841\n",
      "(Validation) Loss: 1321384.0965, MAE: 4940.9907, R2: -0.1119\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [430/5000] | Time: 0.31s\n",
      "(Training) Loss: 1267952.4683\n",
      "(Validation) Loss: 1321122.7124, MAE: 4939.6167, R2: -0.1117\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [431/5000] | Time: 0.30s\n",
      "(Training) Loss: 1283866.0102\n",
      "(Validation) Loss: 1320864.1778, MAE: 4938.3496, R2: -0.1115\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [432/5000] | Time: 0.37s\n",
      "(Training) Loss: 1268915.7310\n",
      "(Validation) Loss: 1320600.5587, MAE: 4937.7148, R2: -0.1112\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [433/5000] | Time: 0.46s\n",
      "(Training) Loss: 1263390.9213\n",
      "(Validation) Loss: 1320341.0387, MAE: 4935.6455, R2: -0.1110\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [434/5000] | Time: 0.25s\n",
      "(Training) Loss: 1255876.0046\n",
      "(Validation) Loss: 1320080.1625, MAE: 4935.4741, R2: -0.1108\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [435/5000] | Time: 0.39s\n",
      "(Training) Loss: 1271382.6650\n",
      "(Validation) Loss: 1319821.5467, MAE: 4933.8184, R2: -0.1106\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [436/5000] | Time: 0.25s\n",
      "(Training) Loss: 1273397.9137\n",
      "(Validation) Loss: 1319559.9543, MAE: 4932.6016, R2: -0.1104\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [437/5000] | Time: 0.28s\n",
      "(Training) Loss: 1266524.3185\n",
      "(Validation) Loss: 1319298.0114, MAE: 4931.6699, R2: -0.1102\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [438/5000] | Time: 0.28s\n",
      "(Training) Loss: 1264414.2766\n",
      "(Validation) Loss: 1319036.2210, MAE: 4930.7544, R2: -0.1099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [439/5000] | Time: 0.35s\n",
      "(Training) Loss: 1274523.8997\n",
      "(Validation) Loss: 1318778.6870, MAE: 4929.6899, R2: -0.1097\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [440/5000] | Time: 0.33s\n",
      "(Training) Loss: 1253849.1931\n",
      "(Validation) Loss: 1318520.9346, MAE: 4929.3643, R2: -0.1095\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [441/5000] | Time: 0.29s\n",
      "(Training) Loss: 1285142.3636\n",
      "(Validation) Loss: 1318259.8044, MAE: 4927.6074, R2: -0.1093\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [442/5000] | Time: 0.25s\n",
      "(Training) Loss: 1262939.3896\n",
      "(Validation) Loss: 1317995.7740, MAE: 4926.0752, R2: -0.1091\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [443/5000] | Time: 0.28s\n",
      "(Training) Loss: 1269978.3109\n",
      "(Validation) Loss: 1317738.1790, MAE: 4925.3481, R2: -0.1089\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [444/5000] | Time: 0.27s\n",
      "(Training) Loss: 1266584.6618\n",
      "(Validation) Loss: 1317477.4908, MAE: 4924.0532, R2: -0.1086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [445/5000] | Time: 0.25s\n",
      "(Training) Loss: 1278592.7766\n",
      "(Validation) Loss: 1317216.5841, MAE: 4923.3091, R2: -0.1084\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [446/5000] | Time: 0.30s\n",
      "(Training) Loss: 1287313.0926\n",
      "(Validation) Loss: 1316956.9371, MAE: 4922.7349, R2: -0.1082\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [447/5000] | Time: 0.27s\n",
      "(Training) Loss: 1258289.4911\n",
      "(Validation) Loss: 1316692.4648, MAE: 4922.1484, R2: -0.1080\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [448/5000] | Time: 0.30s\n",
      "(Training) Loss: 1267425.7919\n",
      "(Validation) Loss: 1316429.9276, MAE: 4920.5366, R2: -0.1078\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [449/5000] | Time: 0.42s\n",
      "(Training) Loss: 1267439.8947\n",
      "(Validation) Loss: 1316178.9765, MAE: 4920.6255, R2: -0.1076\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [450/5000] | Time: 0.30s\n",
      "(Training) Loss: 1267441.2830\n",
      "(Validation) Loss: 1315909.3892, MAE: 4918.3936, R2: -0.1073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [451/5000] | Time: 0.26s\n",
      "(Training) Loss: 1271783.9695\n",
      "(Validation) Loss: 1315651.5302, MAE: 4917.4072, R2: -0.1071\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [452/5000] | Time: 0.32s\n",
      "(Training) Loss: 1269738.8490\n",
      "(Validation) Loss: 1315418.6616, MAE: 4921.0405, R2: -0.1069\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [453/5000] | Time: 0.41s\n",
      "(Training) Loss: 1258163.3452\n",
      "(Validation) Loss: 1315130.8241, MAE: 4914.7910, R2: -0.1067\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [454/5000] | Time: 0.32s\n",
      "(Training) Loss: 1271494.5102\n",
      "(Validation) Loss: 1314872.9041, MAE: 4914.2461, R2: -0.1065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [455/5000] | Time: 0.42s\n",
      "(Training) Loss: 1263718.0888\n",
      "(Validation) Loss: 1314610.3060, MAE: 4912.8569, R2: -0.1063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [456/5000] | Time: 0.25s\n",
      "(Training) Loss: 1264095.7779\n",
      "(Validation) Loss: 1314353.2749, MAE: 4911.1074, R2: -0.1060\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [457/5000] | Time: 0.42s\n",
      "(Training) Loss: 1259185.1256\n",
      "(Validation) Loss: 1314093.0235, MAE: 4911.4028, R2: -0.1058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [458/5000] | Time: 0.38s\n",
      "(Training) Loss: 1274264.2957\n",
      "(Validation) Loss: 1313829.1860, MAE: 4908.8325, R2: -0.1056\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [459/5000] | Time: 0.36s\n",
      "(Training) Loss: 1266778.9302\n",
      "(Validation) Loss: 1313570.9511, MAE: 4907.9370, R2: -0.1054\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [460/5000] | Time: 0.31s\n",
      "(Training) Loss: 1251651.3950\n",
      "(Validation) Loss: 1313307.1441, MAE: 4906.8530, R2: -0.1052\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [461/5000] | Time: 0.37s\n",
      "(Training) Loss: 1263307.7081\n",
      "(Validation) Loss: 1313052.9778, MAE: 4905.5869, R2: -0.1050\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [462/5000] | Time: 0.30s\n",
      "(Training) Loss: 1266043.5114\n",
      "(Validation) Loss: 1312788.2057, MAE: 4905.0400, R2: -0.1047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [463/5000] | Time: 0.27s\n",
      "(Training) Loss: 1248295.9569\n",
      "(Validation) Loss: 1312529.5695, MAE: 4904.0151, R2: -0.1045\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [464/5000] | Time: 0.29s\n",
      "(Training) Loss: 1267021.2322\n",
      "(Validation) Loss: 1312268.5308, MAE: 4902.4922, R2: -0.1043\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [465/5000] | Time: 0.27s\n",
      "(Training) Loss: 1269049.4251\n",
      "(Validation) Loss: 1312012.2819, MAE: 4902.2017, R2: -0.1041\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [466/5000] | Time: 0.40s\n",
      "(Training) Loss: 1255930.6929\n",
      "(Validation) Loss: 1311746.9257, MAE: 4900.6782, R2: -0.1039\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [467/5000] | Time: 0.36s\n",
      "(Training) Loss: 1262362.1383\n",
      "(Validation) Loss: 1311488.0813, MAE: 4898.9683, R2: -0.1037\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [468/5000] | Time: 0.30s\n",
      "(Training) Loss: 1261532.1332\n",
      "(Validation) Loss: 1311231.6343, MAE: 4898.5864, R2: -0.1034\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [469/5000] | Time: 0.27s\n",
      "(Training) Loss: 1260777.6117\n",
      "(Validation) Loss: 1310973.7854, MAE: 4897.4380, R2: -0.1032\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [470/5000] | Time: 0.26s\n",
      "(Training) Loss: 1266837.8173\n",
      "(Validation) Loss: 1310712.0965, MAE: 4896.3442, R2: -0.1030\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [471/5000] | Time: 0.33s\n",
      "(Training) Loss: 1260829.4162\n",
      "(Validation) Loss: 1310453.0794, MAE: 4894.9775, R2: -0.1028\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [472/5000] | Time: 0.27s\n",
      "(Training) Loss: 1260297.9010\n",
      "(Validation) Loss: 1310195.8654, MAE: 4896.0493, R2: -0.1026\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [473/5000] | Time: 0.24s\n",
      "(Training) Loss: 1246309.8203\n",
      "(Validation) Loss: 1309935.0400, MAE: 4893.1938, R2: -0.1024\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [474/5000] | Time: 0.25s\n",
      "(Training) Loss: 1269771.6472\n",
      "(Validation) Loss: 1309675.9416, MAE: 4892.1670, R2: -0.1021\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [475/5000] | Time: 0.25s\n",
      "(Training) Loss: 1261865.3604\n",
      "(Validation) Loss: 1309417.2952, MAE: 4891.4111, R2: -0.1019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [476/5000] | Time: 0.27s\n",
      "(Training) Loss: 1252858.5457\n",
      "(Validation) Loss: 1309160.8279, MAE: 4891.1953, R2: -0.1017\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [477/5000] | Time: 0.39s\n",
      "(Training) Loss: 1265439.3528\n",
      "(Validation) Loss: 1308898.8698, MAE: 4888.9990, R2: -0.1015\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [478/5000] | Time: 0.25s\n",
      "(Training) Loss: 1263793.8452\n",
      "(Validation) Loss: 1308638.9994, MAE: 4889.9243, R2: -0.1013\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [479/5000] | Time: 0.28s\n",
      "(Training) Loss: 1252968.9359\n",
      "(Validation) Loss: 1308376.2540, MAE: 4887.1382, R2: -0.1011\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [480/5000] | Time: 0.25s\n",
      "(Training) Loss: 1282326.4505\n",
      "(Validation) Loss: 1308122.0622, MAE: 4885.7861, R2: -0.1008\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [481/5000] | Time: 0.28s\n",
      "(Training) Loss: 1251660.7855\n",
      "(Validation) Loss: 1307855.3600, MAE: 4884.9521, R2: -0.1006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [482/5000] | Time: 0.29s\n",
      "(Training) Loss: 1268470.6789\n",
      "(Validation) Loss: 1307595.8959, MAE: 4884.1558, R2: -0.1004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [483/5000] | Time: 0.34s\n",
      "(Training) Loss: 1263246.2018\n",
      "(Validation) Loss: 1307340.1397, MAE: 4884.2773, R2: -0.1002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [484/5000] | Time: 0.29s\n",
      "(Training) Loss: 1277187.0330\n",
      "(Validation) Loss: 1307079.4616, MAE: 4881.7969, R2: -0.1000\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [485/5000] | Time: 0.36s\n",
      "(Training) Loss: 1280153.8096\n",
      "(Validation) Loss: 1306820.7644, MAE: 4881.1025, R2: -0.0998\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [486/5000] | Time: 0.30s\n",
      "(Training) Loss: 1272288.7747\n",
      "(Validation) Loss: 1306556.8660, MAE: 4879.7266, R2: -0.0995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [487/5000] | Time: 0.30s\n",
      "(Training) Loss: 1246913.8598\n",
      "(Validation) Loss: 1306299.7537, MAE: 4878.8828, R2: -0.0993\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [488/5000] | Time: 0.27s\n",
      "(Training) Loss: 1249321.4353\n",
      "(Validation) Loss: 1306045.9124, MAE: 4879.4023, R2: -0.0991\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [489/5000] | Time: 0.27s\n",
      "(Training) Loss: 1276050.3629\n",
      "(Validation) Loss: 1305789.7956, MAE: 4877.9668, R2: -0.0989\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [490/5000] | Time: 0.26s\n",
      "(Training) Loss: 1252492.9048\n",
      "(Validation) Loss: 1305526.7149, MAE: 4876.3101, R2: -0.0987\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [491/5000] | Time: 0.26s\n",
      "(Training) Loss: 1271431.1586\n",
      "(Validation) Loss: 1305270.2324, MAE: 4875.3428, R2: -0.0985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [492/5000] | Time: 0.38s\n",
      "(Training) Loss: 1268915.5273\n",
      "(Validation) Loss: 1305008.2184, MAE: 4874.7876, R2: -0.0983\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [493/5000] | Time: 0.31s\n",
      "(Training) Loss: 1255436.9093\n",
      "(Validation) Loss: 1304747.9568, MAE: 4872.1836, R2: -0.0980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [494/5000] | Time: 0.27s\n",
      "(Training) Loss: 1252028.4010\n",
      "(Validation) Loss: 1304495.9137, MAE: 4872.1562, R2: -0.0978\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [495/5000] | Time: 0.27s\n",
      "(Training) Loss: 1250295.3991\n",
      "(Validation) Loss: 1304233.2089, MAE: 4870.4189, R2: -0.0976\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [496/5000] | Time: 0.25s\n",
      "(Training) Loss: 1271741.3249\n",
      "(Validation) Loss: 1303977.4629, MAE: 4869.5303, R2: -0.0974\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [497/5000] | Time: 0.26s\n",
      "(Training) Loss: 1263079.9454\n",
      "(Validation) Loss: 1303717.6279, MAE: 4869.0537, R2: -0.0972\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [498/5000] | Time: 0.26s\n",
      "(Training) Loss: 1240025.3728\n",
      "(Validation) Loss: 1303458.9714, MAE: 4867.1792, R2: -0.0970\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [499/5000] | Time: 0.35s\n",
      "(Training) Loss: 1245106.0933\n",
      "(Validation) Loss: 1303206.7606, MAE: 4866.5459, R2: -0.0968\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [500/5000] | Time: 0.26s\n",
      "(Training) Loss: 1251789.2132\n",
      "(Validation) Loss: 1302946.8444, MAE: 4865.6411, R2: -0.0965\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch500.pth\n",
      "==========================================================================================\n",
      "Epoch [501/5000] | Time: 0.27s\n",
      "(Training) Loss: 1280743.5584\n",
      "(Validation) Loss: 1302692.8610, MAE: 4864.8921, R2: -0.0963\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [502/5000] | Time: 0.28s\n",
      "(Training) Loss: 1252838.8249\n",
      "(Validation) Loss: 1302437.2673, MAE: 4864.6089, R2: -0.0961\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [503/5000] | Time: 0.28s\n",
      "(Training) Loss: 1258045.7259\n",
      "(Validation) Loss: 1302172.9321, MAE: 4862.2026, R2: -0.0959\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [504/5000] | Time: 0.32s\n",
      "(Training) Loss: 1250178.4670\n",
      "(Validation) Loss: 1301918.5575, MAE: 4861.2310, R2: -0.0957\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [505/5000] | Time: 0.31s\n",
      "(Training) Loss: 1248256.9898\n",
      "(Validation) Loss: 1301666.9968, MAE: 4860.3696, R2: -0.0955\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [506/5000] | Time: 0.29s\n",
      "(Training) Loss: 1256277.3452\n",
      "(Validation) Loss: 1301404.2413, MAE: 4859.8447, R2: -0.0953\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [507/5000] | Time: 0.30s\n",
      "(Training) Loss: 1246406.2589\n",
      "(Validation) Loss: 1301146.7022, MAE: 4858.0840, R2: -0.0950\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [508/5000] | Time: 0.29s\n",
      "(Training) Loss: 1261215.7043\n",
      "(Validation) Loss: 1300890.3365, MAE: 4856.9985, R2: -0.0948\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [509/5000] | Time: 0.34s\n",
      "(Training) Loss: 1258744.0260\n",
      "(Validation) Loss: 1300632.9600, MAE: 4856.6914, R2: -0.0946\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [510/5000] | Time: 0.40s\n",
      "(Training) Loss: 1258092.7069\n",
      "(Validation) Loss: 1300374.1562, MAE: 4855.5239, R2: -0.0944\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [511/5000] | Time: 0.32s\n",
      "(Training) Loss: 1246772.9264\n",
      "(Validation) Loss: 1300117.3689, MAE: 4854.7607, R2: -0.0942\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [512/5000] | Time: 0.32s\n",
      "(Training) Loss: 1270114.7500\n",
      "(Validation) Loss: 1299860.8965, MAE: 4852.8442, R2: -0.0940\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [513/5000] | Time: 0.29s\n",
      "(Training) Loss: 1251528.4762\n",
      "(Validation) Loss: 1299607.0146, MAE: 4852.6240, R2: -0.0938\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [514/5000] | Time: 0.28s\n",
      "(Training) Loss: 1237335.6732\n",
      "(Validation) Loss: 1299347.4133, MAE: 4852.0874, R2: -0.0935\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [515/5000] | Time: 0.29s\n",
      "(Training) Loss: 1258255.5266\n",
      "(Validation) Loss: 1299096.3098, MAE: 4852.3354, R2: -0.0933\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [516/5000] | Time: 0.26s\n",
      "(Training) Loss: 1260801.2614\n",
      "(Validation) Loss: 1298837.4654, MAE: 4849.2300, R2: -0.0931\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [517/5000] | Time: 0.34s\n",
      "(Training) Loss: 1253142.8147\n",
      "(Validation) Loss: 1298576.4673, MAE: 4848.7998, R2: -0.0929\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [518/5000] | Time: 0.29s\n",
      "(Training) Loss: 1251212.4575\n",
      "(Validation) Loss: 1298321.9149, MAE: 4848.2378, R2: -0.0927\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [519/5000] | Time: 0.27s\n",
      "(Training) Loss: 1254192.2855\n",
      "(Validation) Loss: 1298066.1130, MAE: 4846.1748, R2: -0.0925\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [520/5000] | Time: 0.29s\n",
      "(Training) Loss: 1261286.1948\n",
      "(Validation) Loss: 1297813.0692, MAE: 4846.9326, R2: -0.0923\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [521/5000] | Time: 0.27s\n",
      "(Training) Loss: 1244406.5228\n",
      "(Validation) Loss: 1297550.0292, MAE: 4845.2705, R2: -0.0920\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [522/5000] | Time: 0.27s\n",
      "(Training) Loss: 1245310.2690\n",
      "(Validation) Loss: 1297297.1784, MAE: 4845.4976, R2: -0.0918\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [523/5000] | Time: 0.28s\n",
      "(Training) Loss: 1248563.7951\n",
      "(Validation) Loss: 1297035.6927, MAE: 4842.0239, R2: -0.0916\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [524/5000] | Time: 0.28s\n",
      "(Training) Loss: 1247832.0749\n",
      "(Validation) Loss: 1296779.3727, MAE: 4840.9829, R2: -0.0914\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [525/5000] | Time: 0.42s\n",
      "(Training) Loss: 1260532.1320\n",
      "(Validation) Loss: 1296524.6070, MAE: 4841.6675, R2: -0.0912\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [526/5000] | Time: 0.25s\n",
      "(Training) Loss: 1248412.8046\n",
      "(Validation) Loss: 1296266.2248, MAE: 4840.2280, R2: -0.0910\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [527/5000] | Time: 0.25s\n",
      "(Training) Loss: 1244193.3503\n",
      "(Validation) Loss: 1296011.7943, MAE: 4838.6230, R2: -0.0908\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [528/5000] | Time: 0.25s\n",
      "(Training) Loss: 1238684.5863\n",
      "(Validation) Loss: 1295760.5638, MAE: 4838.9932, R2: -0.0906\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [529/5000] | Time: 0.25s\n",
      "(Training) Loss: 1239564.6485\n",
      "(Validation) Loss: 1295502.2019, MAE: 4836.3506, R2: -0.0903\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [530/5000] | Time: 0.24s\n",
      "(Training) Loss: 1260282.7944\n",
      "(Validation) Loss: 1295243.6978, MAE: 4834.9053, R2: -0.0901\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [531/5000] | Time: 0.25s\n",
      "(Training) Loss: 1245828.9074\n",
      "(Validation) Loss: 1294990.7251, MAE: 4834.3384, R2: -0.0899\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [532/5000] | Time: 0.25s\n",
      "(Training) Loss: 1267622.0799\n",
      "(Validation) Loss: 1294733.9022, MAE: 4832.9624, R2: -0.0897\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [533/5000] | Time: 0.25s\n",
      "(Training) Loss: 1246775.2805\n",
      "(Validation) Loss: 1294472.3810, MAE: 4832.5186, R2: -0.0895\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [534/5000] | Time: 0.29s\n",
      "(Training) Loss: 1257543.3940\n",
      "(Validation) Loss: 1294216.2641, MAE: 4830.9800, R2: -0.0893\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [535/5000] | Time: 0.26s\n",
      "(Training) Loss: 1264072.8782\n",
      "(Validation) Loss: 1293966.1968, MAE: 4833.2109, R2: -0.0891\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [536/5000] | Time: 0.28s\n",
      "(Training) Loss: 1266104.7766\n",
      "(Validation) Loss: 1293703.9340, MAE: 4831.7383, R2: -0.0888\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [537/5000] | Time: 0.38s\n",
      "(Training) Loss: 1239010.8522\n",
      "(Validation) Loss: 1293447.0349, MAE: 4830.6401, R2: -0.0886\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [538/5000] | Time: 0.28s\n",
      "(Training) Loss: 1239785.0939\n",
      "(Validation) Loss: 1293191.8629, MAE: 4828.3447, R2: -0.0884\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [539/5000] | Time: 0.25s\n",
      "(Training) Loss: 1249270.3376\n",
      "(Validation) Loss: 1292936.9600, MAE: 4827.2988, R2: -0.0882\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [540/5000] | Time: 0.26s\n",
      "(Training) Loss: 1246021.0146\n",
      "(Validation) Loss: 1292684.0838, MAE: 4826.4233, R2: -0.0880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [541/5000] | Time: 0.27s\n",
      "(Training) Loss: 1247300.7005\n",
      "(Validation) Loss: 1292425.8286, MAE: 4825.0381, R2: -0.0878\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [542/5000] | Time: 0.25s\n",
      "(Training) Loss: 1250786.9841\n",
      "(Validation) Loss: 1292172.1854, MAE: 4824.3950, R2: -0.0876\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [543/5000] | Time: 0.27s\n",
      "(Training) Loss: 1231354.2640\n",
      "(Validation) Loss: 1291914.7683, MAE: 4824.8291, R2: -0.0873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [544/5000] | Time: 0.28s\n",
      "(Training) Loss: 1242551.9848\n",
      "(Validation) Loss: 1291665.2292, MAE: 4823.5542, R2: -0.0871\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [545/5000] | Time: 0.28s\n",
      "(Training) Loss: 1255852.3109\n",
      "(Validation) Loss: 1291413.0641, MAE: 4823.0947, R2: -0.0869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [546/5000] | Time: 0.29s\n",
      "(Training) Loss: 1240319.9124\n",
      "(Validation) Loss: 1291152.9803, MAE: 4820.4062, R2: -0.0867\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [547/5000] | Time: 0.30s\n",
      "(Training) Loss: 1239883.1377\n",
      "(Validation) Loss: 1290902.0140, MAE: 4821.3662, R2: -0.0865\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [548/5000] | Time: 0.40s\n",
      "(Training) Loss: 1259638.7919\n",
      "(Validation) Loss: 1290643.5505, MAE: 4817.4746, R2: -0.0863\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [549/5000] | Time: 0.30s\n",
      "(Training) Loss: 1234643.0952\n",
      "(Validation) Loss: 1290389.6990, MAE: 4817.7407, R2: -0.0861\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [550/5000] | Time: 0.25s\n",
      "(Training) Loss: 1264105.9645\n",
      "(Validation) Loss: 1290141.7803, MAE: 4818.0200, R2: -0.0859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [551/5000] | Time: 0.26s\n",
      "(Training) Loss: 1270011.8921\n",
      "(Validation) Loss: 1289881.1022, MAE: 4814.6128, R2: -0.0857\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [552/5000] | Time: 0.26s\n",
      "(Training) Loss: 1259714.9461\n",
      "(Validation) Loss: 1289618.4330, MAE: 4813.4702, R2: -0.0854\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [553/5000] | Time: 0.27s\n",
      "(Training) Loss: 1267497.7919\n",
      "(Validation) Loss: 1289362.9663, MAE: 4812.8545, R2: -0.0852\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [554/5000] | Time: 0.29s\n",
      "(Training) Loss: 1254420.2208\n",
      "(Validation) Loss: 1289106.1994, MAE: 4812.6899, R2: -0.0850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [555/5000] | Time: 0.30s\n",
      "(Training) Loss: 1244549.4061\n",
      "(Validation) Loss: 1288851.1949, MAE: 4811.8276, R2: -0.0848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [556/5000] | Time: 0.33s\n",
      "(Training) Loss: 1238809.8820\n",
      "(Validation) Loss: 1288599.2584, MAE: 4812.2964, R2: -0.0846\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [557/5000] | Time: 0.31s\n",
      "(Training) Loss: 1252266.3712\n",
      "(Validation) Loss: 1288336.6451, MAE: 4809.1689, R2: -0.0844\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [558/5000] | Time: 0.39s\n",
      "(Training) Loss: 1263671.0673\n",
      "(Validation) Loss: 1288087.1314, MAE: 4808.5400, R2: -0.0842\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [559/5000] | Time: 0.28s\n",
      "(Training) Loss: 1237690.2056\n",
      "(Validation) Loss: 1287833.6254, MAE: 4807.1211, R2: -0.0839\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [560/5000] | Time: 0.28s\n",
      "(Training) Loss: 1233868.8185\n",
      "(Validation) Loss: 1287578.6108, MAE: 4806.4663, R2: -0.0837\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [561/5000] | Time: 0.28s\n",
      "(Training) Loss: 1228348.4023\n",
      "(Validation) Loss: 1287331.1086, MAE: 4807.9785, R2: -0.0835\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [562/5000] | Time: 0.26s\n",
      "(Training) Loss: 1252363.9175\n",
      "(Validation) Loss: 1287072.4368, MAE: 4804.0103, R2: -0.0833\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [563/5000] | Time: 0.26s\n",
      "(Training) Loss: 1235092.0673\n",
      "(Validation) Loss: 1286817.4527, MAE: 4803.1401, R2: -0.0831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [564/5000] | Time: 0.28s\n",
      "(Training) Loss: 1252708.1364\n",
      "(Validation) Loss: 1286566.6337, MAE: 4803.1929, R2: -0.0829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [565/5000] | Time: 0.29s\n",
      "(Training) Loss: 1232773.9822\n",
      "(Validation) Loss: 1286311.3702, MAE: 4802.4497, R2: -0.0827\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [566/5000] | Time: 0.26s\n",
      "(Training) Loss: 1231359.3490\n",
      "(Validation) Loss: 1286059.4337, MAE: 4801.7681, R2: -0.0825\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [567/5000] | Time: 0.27s\n",
      "(Training) Loss: 1234674.2855\n",
      "(Validation) Loss: 1285802.7175, MAE: 4798.3838, R2: -0.0823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [568/5000] | Time: 0.26s\n",
      "(Training) Loss: 1240975.0349\n",
      "(Validation) Loss: 1285552.1625, MAE: 4798.9531, R2: -0.0820\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [569/5000] | Time: 0.33s\n",
      "(Training) Loss: 1233994.6536\n",
      "(Validation) Loss: 1285299.8451, MAE: 4798.2812, R2: -0.0818\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [570/5000] | Time: 0.38s\n",
      "(Training) Loss: 1251511.4391\n",
      "(Validation) Loss: 1285048.0457, MAE: 4798.0015, R2: -0.0816\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [571/5000] | Time: 0.30s\n",
      "(Training) Loss: 1226856.5533\n",
      "(Validation) Loss: 1284788.2921, MAE: 4795.0518, R2: -0.0814\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [572/5000] | Time: 0.34s\n",
      "(Training) Loss: 1232690.4632\n",
      "(Validation) Loss: 1284537.1276, MAE: 4794.4595, R2: -0.0812\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [573/5000] | Time: 0.37s\n",
      "(Training) Loss: 1222350.9235\n",
      "(Validation) Loss: 1284283.4997, MAE: 4794.1650, R2: -0.0810\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [574/5000] | Time: 0.31s\n",
      "(Training) Loss: 1245643.9188\n",
      "(Validation) Loss: 1284039.1467, MAE: 4794.0166, R2: -0.0808\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [575/5000] | Time: 0.28s\n",
      "(Training) Loss: 1246023.8921\n",
      "(Validation) Loss: 1283787.4489, MAE: 4793.7944, R2: -0.0806\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [576/5000] | Time: 0.32s\n",
      "(Training) Loss: 1244161.5926\n",
      "(Validation) Loss: 1283524.0432, MAE: 4791.2173, R2: -0.0804\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [577/5000] | Time: 0.41s\n",
      "(Training) Loss: 1248078.3249\n",
      "(Validation) Loss: 1283268.7289, MAE: 4789.5542, R2: -0.0801\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [578/5000] | Time: 0.28s\n",
      "(Training) Loss: 1228647.5964\n",
      "(Validation) Loss: 1283015.5276, MAE: 4788.8081, R2: -0.0799\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [579/5000] | Time: 0.28s\n",
      "(Training) Loss: 1241291.7665\n",
      "(Validation) Loss: 1284930.5295, MAE: 4798.7715, R2: -0.0815\n",
      "==========================================================================================\n",
      "Epoch [580/5000] | Time: 0.27s\n",
      "(Training) Loss: 1228002.8522\n",
      "(Validation) Loss: 1282512.0508, MAE: 4787.5889, R2: -0.0795\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [581/5000] | Time: 0.25s\n",
      "(Training) Loss: 1251040.8731\n",
      "(Validation) Loss: 1282265.9302, MAE: 4789.0366, R2: -0.0793\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [582/5000] | Time: 0.25s\n",
      "(Training) Loss: 1232385.2741\n",
      "(Validation) Loss: 1282007.5581, MAE: 4787.0498, R2: -0.0791\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [583/5000] | Time: 0.25s\n",
      "(Training) Loss: 1239510.9162\n",
      "(Validation) Loss: 1281750.6286, MAE: 4784.6528, R2: -0.0789\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [584/5000] | Time: 0.26s\n",
      "(Training) Loss: 1229661.0197\n",
      "(Validation) Loss: 1281503.2381, MAE: 4785.4507, R2: -0.0787\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [585/5000] | Time: 0.24s\n",
      "(Training) Loss: 1270883.4061\n",
      "(Validation) Loss: 1281246.8013, MAE: 4782.3999, R2: -0.0785\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [586/5000] | Time: 0.27s\n",
      "(Training) Loss: 1226397.2386\n",
      "(Validation) Loss: 1285555.8959, MAE: 4799.9639, R2: -0.0820\n",
      "==========================================================================================\n",
      "Epoch [587/5000] | Time: 0.41s\n",
      "(Training) Loss: 1226194.5736\n",
      "(Validation) Loss: 1285301.6787, MAE: 4797.1519, R2: -0.0818\n",
      "==========================================================================================\n",
      "Epoch [588/5000] | Time: 0.36s\n",
      "(Training) Loss: 1243136.5825\n",
      "(Validation) Loss: 1285052.9676, MAE: 4796.6021, R2: -0.0816\n",
      "==========================================================================================\n",
      "Epoch [589/5000] | Time: 0.25s\n",
      "(Training) Loss: 1246850.6396\n",
      "(Validation) Loss: 1284792.7365, MAE: 4794.7964, R2: -0.0814\n",
      "==========================================================================================\n",
      "Epoch [590/5000] | Time: 0.33s\n",
      "(Training) Loss: 1243083.6701\n",
      "(Validation) Loss: 1284540.5359, MAE: 4794.3472, R2: -0.0812\n",
      "==========================================================================================\n",
      "Epoch [591/5000] | Time: 0.35s\n",
      "(Training) Loss: 1235496.7462\n",
      "(Validation) Loss: 1284287.0095, MAE: 4793.6504, R2: -0.0810\n",
      "==========================================================================================\n",
      "Epoch [592/5000] | Time: 0.33s\n",
      "(Training) Loss: 1229620.1656\n",
      "(Validation) Loss: 1284040.7721, MAE: 4792.9888, R2: -0.0808\n",
      "==========================================================================================\n",
      "Epoch [593/5000] | Time: 0.30s\n",
      "(Training) Loss: 1238676.9949\n",
      "(Validation) Loss: 1283781.9378, MAE: 4792.0479, R2: -0.0806\n",
      "==========================================================================================\n",
      "Epoch [594/5000] | Time: 0.28s\n",
      "(Training) Loss: 1223440.2824\n",
      "(Validation) Loss: 1283527.1924, MAE: 4790.9033, R2: -0.0804\n",
      "==========================================================================================\n",
      "Epoch [595/5000] | Time: 0.33s\n",
      "(Training) Loss: 1248075.8832\n",
      "(Validation) Loss: 1283274.2806, MAE: 4790.1558, R2: -0.0801\n",
      "==========================================================================================\n",
      "Epoch [596/5000] | Time: 0.37s\n",
      "(Training) Loss: 1267590.7494\n",
      "(Validation) Loss: 1283019.8908, MAE: 4788.9761, R2: -0.0799\n",
      "==========================================================================================\n",
      "Epoch [597/5000] | Time: 0.37s\n",
      "(Training) Loss: 1242410.7614\n",
      "(Validation) Loss: 1282770.7225, MAE: 4792.5908, R2: -0.0797\n",
      "==========================================================================================\n",
      "Epoch [598/5000] | Time: 0.27s\n",
      "(Training) Loss: 1227134.4860\n",
      "(Validation) Loss: 1282510.7403, MAE: 4788.1045, R2: -0.0795\n",
      "==========================================================================================\n",
      "Epoch [599/5000] | Time: 0.25s\n",
      "(Training) Loss: 1227893.8966\n",
      "(Validation) Loss: 1282262.0495, MAE: 4789.5732, R2: -0.0793\n",
      "==========================================================================================\n",
      "Epoch [600/5000] | Time: 0.26s\n",
      "(Training) Loss: 1241995.7246\n",
      "(Validation) Loss: 1282005.1048, MAE: 4785.5137, R2: -0.0791\n",
      "==========================================================================================\n",
      "Epoch [601/5000] | Time: 0.25s\n",
      "(Training) Loss: 1239092.4150\n",
      "(Validation) Loss: 1281754.1587, MAE: 4784.5605, R2: -0.0789\n",
      "==========================================================================================\n",
      "Epoch [602/5000] | Time: 0.31s\n",
      "(Training) Loss: 1255445.5241\n",
      "(Validation) Loss: 1281500.5257, MAE: 4783.4395, R2: -0.0787\n",
      "==========================================================================================\n",
      "Epoch [603/5000] | Time: 0.28s\n",
      "(Training) Loss: 1249055.0355\n",
      "(Validation) Loss: 1281242.9410, MAE: 4782.8813, R2: -0.0785\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [604/5000] | Time: 0.35s\n",
      "(Training) Loss: 1229448.8484\n",
      "(Validation) Loss: 1280998.2171, MAE: 4782.8306, R2: -0.0783\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [605/5000] | Time: 0.37s\n",
      "(Training) Loss: 1255010.1764\n",
      "(Validation) Loss: 1280736.5638, MAE: 4782.3667, R2: -0.0780\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [606/5000] | Time: 0.44s\n",
      "(Training) Loss: 1240006.7195\n",
      "(Validation) Loss: 1280477.5111, MAE: 4778.9561, R2: -0.0778\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [607/5000] | Time: 0.36s\n",
      "(Training) Loss: 1229666.1066\n",
      "(Validation) Loss: 1280224.4063, MAE: 4780.0669, R2: -0.0776\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [608/5000] | Time: 0.29s\n",
      "(Training) Loss: 1245447.2195\n",
      "(Validation) Loss: 1279971.9365, MAE: 4777.0630, R2: -0.0774\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [609/5000] | Time: 0.29s\n",
      "(Training) Loss: 1240503.3388\n",
      "(Validation) Loss: 1279719.3092, MAE: 4776.9341, R2: -0.0772\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [610/5000] | Time: 0.29s\n",
      "(Training) Loss: 1247834.6041\n",
      "(Validation) Loss: 1279465.2902, MAE: 4777.0986, R2: -0.0770\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [611/5000] | Time: 0.26s\n",
      "(Training) Loss: 1234356.3642\n",
      "(Validation) Loss: 1279218.2959, MAE: 4776.8188, R2: -0.0768\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [612/5000] | Time: 0.27s\n",
      "(Training) Loss: 1230884.8991\n",
      "(Validation) Loss: 1278958.1410, MAE: 4774.8652, R2: -0.0766\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [613/5000] | Time: 0.23s\n",
      "(Training) Loss: 1234799.7322\n",
      "(Validation) Loss: 1278704.6197, MAE: 4774.6245, R2: -0.0763\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [614/5000] | Time: 0.24s\n",
      "(Training) Loss: 1231230.9315\n",
      "(Validation) Loss: 1278458.0521, MAE: 4774.6143, R2: -0.0761\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [615/5000] | Time: 0.27s\n",
      "(Training) Loss: 1228667.2500\n",
      "(Validation) Loss: 1278201.2698, MAE: 4771.5801, R2: -0.0759\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [616/5000] | Time: 0.25s\n",
      "(Training) Loss: 1233281.4740\n",
      "(Validation) Loss: 1277951.2076, MAE: 4770.4160, R2: -0.0757\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [617/5000] | Time: 0.32s\n",
      "(Training) Loss: 1226875.2500\n",
      "(Validation) Loss: 1277696.3556, MAE: 4769.4912, R2: -0.0755\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [618/5000] | Time: 0.24s\n",
      "(Training) Loss: 1225962.9810\n",
      "(Validation) Loss: 1277447.2229, MAE: 4768.3813, R2: -0.0753\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [619/5000] | Time: 0.24s\n",
      "(Training) Loss: 1248294.9734\n",
      "(Validation) Loss: 1277198.2629, MAE: 4767.5947, R2: -0.0751\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [620/5000] | Time: 0.27s\n",
      "(Training) Loss: 1231147.4048\n",
      "(Validation) Loss: 1276942.5067, MAE: 4766.6904, R2: -0.0749\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [621/5000] | Time: 0.25s\n",
      "(Training) Loss: 1224624.3769\n",
      "(Validation) Loss: 1276688.1270, MAE: 4765.1274, R2: -0.0747\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [622/5000] | Time: 0.26s\n",
      "(Training) Loss: 1236809.4962\n",
      "(Validation) Loss: 1276439.8933, MAE: 4764.9819, R2: -0.0745\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [623/5000] | Time: 0.26s\n",
      "(Training) Loss: 1214480.5531\n",
      "(Validation) Loss: 1276198.7606, MAE: 4765.5903, R2: -0.0743\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [624/5000] | Time: 0.32s\n",
      "(Training) Loss: 1217976.4124\n",
      "(Validation) Loss: 1275934.6794, MAE: 4762.9189, R2: -0.0740\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [625/5000] | Time: 0.37s\n",
      "(Training) Loss: 1240202.3274\n",
      "(Validation) Loss: 1275683.7283, MAE: 4761.2749, R2: -0.0738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [626/5000] | Time: 0.28s\n",
      "(Training) Loss: 1241576.0222\n",
      "(Validation) Loss: 1275434.1435, MAE: 4760.9995, R2: -0.0736\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [627/5000] | Time: 0.27s\n",
      "(Training) Loss: 1214696.4156\n",
      "(Validation) Loss: 1275178.6260, MAE: 4759.0386, R2: -0.0734\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [628/5000] | Time: 0.54s\n",
      "(Training) Loss: 1217277.0939\n",
      "(Validation) Loss: 1274929.1733, MAE: 4758.1611, R2: -0.0732\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [629/5000] | Time: 0.55s\n",
      "(Training) Loss: 1255542.8185\n",
      "(Validation) Loss: 1274684.8610, MAE: 4758.9351, R2: -0.0730\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [630/5000] | Time: 0.50s\n",
      "(Training) Loss: 1224573.6193\n",
      "(Validation) Loss: 1274428.8000, MAE: 4756.7798, R2: -0.0728\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [631/5000] | Time: 0.36s\n",
      "(Training) Loss: 1236642.7995\n",
      "(Validation) Loss: 1274179.4235, MAE: 4757.0840, R2: -0.0726\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [632/5000] | Time: 0.27s\n",
      "(Training) Loss: 1219159.2113\n",
      "(Validation) Loss: 1273924.3886, MAE: 4754.6157, R2: -0.0724\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [633/5000] | Time: 0.29s\n",
      "(Training) Loss: 1219307.7456\n",
      "(Validation) Loss: 1273680.6603, MAE: 4756.6401, R2: -0.0722\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [634/5000] | Time: 0.24s\n",
      "(Training) Loss: 1244672.1561\n",
      "(Validation) Loss: 1273425.1276, MAE: 4753.9985, R2: -0.0719\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [635/5000] | Time: 0.22s\n",
      "(Training) Loss: 1234169.7246\n",
      "(Validation) Loss: 1273174.8063, MAE: 4752.7920, R2: -0.0717\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [636/5000] | Time: 0.28s\n",
      "(Training) Loss: 1240391.4683\n",
      "(Validation) Loss: 1272926.6946, MAE: 4753.5063, R2: -0.0715\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [637/5000] | Time: 0.25s\n",
      "(Training) Loss: 1234922.9467\n",
      "(Validation) Loss: 1272671.2635, MAE: 4751.0850, R2: -0.0713\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [638/5000] | Time: 0.23s\n",
      "(Training) Loss: 1216171.4588\n",
      "(Validation) Loss: 1272415.0705, MAE: 4749.6826, R2: -0.0711\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [639/5000] | Time: 0.26s\n",
      "(Training) Loss: 1225034.2043\n",
      "(Validation) Loss: 1272171.3930, MAE: 4750.4692, R2: -0.0709\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [640/5000] | Time: 0.26s\n",
      "(Training) Loss: 1218821.4657\n",
      "(Validation) Loss: 1271920.4825, MAE: 4747.1929, R2: -0.0707\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [641/5000] | Time: 0.25s\n",
      "(Training) Loss: 1214300.2722\n",
      "(Validation) Loss: 1271671.7156, MAE: 4748.7495, R2: -0.0705\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [642/5000] | Time: 0.25s\n",
      "(Training) Loss: 1237194.1536\n",
      "(Validation) Loss: 1271425.2190, MAE: 4748.4565, R2: -0.0703\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [643/5000] | Time: 0.26s\n",
      "(Training) Loss: 1215107.4251\n",
      "(Validation) Loss: 1271169.9352, MAE: 4746.7798, R2: -0.0701\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [644/5000] | Time: 0.31s\n",
      "(Training) Loss: 1224561.3871\n",
      "(Validation) Loss: 1270919.9848, MAE: 4744.7305, R2: -0.0699\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [645/5000] | Time: 0.28s\n",
      "(Training) Loss: 1228227.9619\n",
      "(Validation) Loss: 1270679.0806, MAE: 4747.7754, R2: -0.0697\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [646/5000] | Time: 0.25s\n",
      "(Training) Loss: 1213819.2145\n",
      "(Validation) Loss: 1270420.8813, MAE: 4744.6216, R2: -0.0694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [647/5000] | Time: 0.27s\n",
      "(Training) Loss: 1227013.6085\n",
      "(Validation) Loss: 1270343.1619, MAE: 4745.0947, R2: -0.0694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [648/5000] | Time: 0.25s\n",
      "(Training) Loss: 1228383.4613\n",
      "(Validation) Loss: 1274937.7524, MAE: 4759.5127, R2: -0.0732\n",
      "==========================================================================================\n",
      "Epoch [649/5000] | Time: 0.26s\n",
      "(Training) Loss: 1219116.9308\n",
      "(Validation) Loss: 1274687.4667, MAE: 4758.6401, R2: -0.0730\n",
      "==========================================================================================\n",
      "Epoch [650/5000] | Time: 0.26s\n",
      "(Training) Loss: 1256635.2113\n",
      "(Validation) Loss: 1274436.2514, MAE: 4757.1104, R2: -0.0728\n",
      "==========================================================================================\n",
      "Epoch [651/5000] | Time: 0.28s\n",
      "(Training) Loss: 1229177.4670\n",
      "(Validation) Loss: 1274179.8400, MAE: 4756.4526, R2: -0.0726\n",
      "==========================================================================================\n",
      "Epoch [652/5000] | Time: 0.34s\n",
      "(Training) Loss: 1218947.7703\n",
      "(Validation) Loss: 1273930.0876, MAE: 4756.3047, R2: -0.0724\n",
      "==========================================================================================\n",
      "Epoch [653/5000] | Time: 0.36s\n",
      "(Training) Loss: 1212933.6098\n",
      "(Validation) Loss: 1273681.5238, MAE: 4755.7612, R2: -0.0722\n",
      "==========================================================================================\n",
      "Epoch [654/5000] | Time: 0.28s\n",
      "(Training) Loss: 1220196.0292\n",
      "(Validation) Loss: 1273431.2584, MAE: 4753.9360, R2: -0.0719\n",
      "==========================================================================================\n",
      "Epoch [655/5000] | Time: 0.30s\n",
      "(Training) Loss: 1235766.1129\n",
      "(Validation) Loss: 1273178.2603, MAE: 4754.1914, R2: -0.0717\n",
      "==========================================================================================\n",
      "Epoch [656/5000] | Time: 0.26s\n",
      "(Training) Loss: 1224847.3058\n",
      "(Validation) Loss: 1272923.3981, MAE: 4752.3853, R2: -0.0715\n",
      "==========================================================================================\n",
      "Epoch [657/5000] | Time: 0.28s\n",
      "(Training) Loss: 1226057.9232\n",
      "(Validation) Loss: 1272674.8190, MAE: 4750.3350, R2: -0.0713\n",
      "==========================================================================================\n",
      "Epoch [658/5000] | Time: 0.23s\n",
      "(Training) Loss: 1233621.8008\n",
      "(Validation) Loss: 1272429.1860, MAE: 4754.4243, R2: -0.0711\n",
      "==========================================================================================\n",
      "Epoch [659/5000] | Time: 0.29s\n",
      "(Training) Loss: 1225936.7183\n",
      "(Validation) Loss: 1272168.0762, MAE: 4749.2314, R2: -0.0709\n",
      "==========================================================================================\n",
      "Epoch [660/5000] | Time: 0.25s\n",
      "(Training) Loss: 1227800.5025\n",
      "(Validation) Loss: 1271923.6368, MAE: 4750.9214, R2: -0.0707\n",
      "==========================================================================================\n",
      "Epoch [661/5000] | Time: 0.24s\n",
      "(Training) Loss: 1229489.9569\n",
      "(Validation) Loss: 1271668.1346, MAE: 4747.5352, R2: -0.0705\n",
      "==========================================================================================\n",
      "Epoch [662/5000] | Time: 0.26s\n",
      "(Training) Loss: 1230554.9074\n",
      "(Validation) Loss: 1271417.3714, MAE: 4747.0542, R2: -0.0703\n",
      "==========================================================================================\n",
      "Epoch [663/5000] | Time: 0.28s\n",
      "(Training) Loss: 1209978.5510\n",
      "(Validation) Loss: 1271161.9759, MAE: 4744.5859, R2: -0.0701\n",
      "==========================================================================================\n",
      "Epoch [664/5000] | Time: 0.27s\n",
      "(Training) Loss: 1235621.1453\n",
      "(Validation) Loss: 1270916.4902, MAE: 4743.2817, R2: -0.0699\n",
      "==========================================================================================\n",
      "Epoch [665/5000] | Time: 0.25s\n",
      "(Training) Loss: 1226445.4810\n",
      "(Validation) Loss: 1270663.2229, MAE: 4743.7427, R2: -0.0696\n",
      "==========================================================================================\n",
      "Epoch [666/5000] | Time: 0.22s\n",
      "(Training) Loss: 1227940.2354\n",
      "(Validation) Loss: 1270415.7562, MAE: 4743.5693, R2: -0.0694\n",
      "==========================================================================================\n",
      "Epoch [667/5000] | Time: 0.24s\n",
      "(Training) Loss: 1216971.7830\n",
      "(Validation) Loss: 1270159.2330, MAE: 4741.0396, R2: -0.0692\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [668/5000] | Time: 0.26s\n",
      "(Training) Loss: 1241464.2195\n",
      "(Validation) Loss: 1269909.9683, MAE: 4740.6245, R2: -0.0690\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [669/5000] | Time: 0.26s\n",
      "(Training) Loss: 1224872.9201\n",
      "(Validation) Loss: 1269673.1835, MAE: 4741.1860, R2: -0.0688\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [670/5000] | Time: 0.26s\n",
      "(Training) Loss: 1225147.8655\n",
      "(Validation) Loss: 1269408.0762, MAE: 4741.1357, R2: -0.0686\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [671/5000] | Time: 0.37s\n",
      "(Training) Loss: 1257867.6713\n",
      "(Validation) Loss: 1269163.7029, MAE: 4741.0278, R2: -0.0684\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [672/5000] | Time: 0.25s\n",
      "(Training) Loss: 1222791.9201\n",
      "(Validation) Loss: 1268904.0203, MAE: 4737.5820, R2: -0.0682\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [673/5000] | Time: 0.23s\n",
      "(Training) Loss: 1233422.2322\n",
      "(Validation) Loss: 1268651.0832, MAE: 4736.4644, R2: -0.0680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [674/5000] | Time: 0.23s\n",
      "(Training) Loss: 1217704.3331\n",
      "(Validation) Loss: 1268399.0248, MAE: 4735.7808, R2: -0.0678\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [675/5000] | Time: 0.27s\n",
      "(Training) Loss: 1234350.7221\n",
      "(Validation) Loss: 1268150.4254, MAE: 4734.4951, R2: -0.0676\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [676/5000] | Time: 0.33s\n",
      "(Training) Loss: 1215176.0558\n",
      "(Validation) Loss: 1267897.3105, MAE: 4733.4536, R2: -0.0673\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [677/5000] | Time: 0.34s\n",
      "(Training) Loss: 1206674.9602\n",
      "(Validation) Loss: 1267647.2533, MAE: 4731.1284, R2: -0.0671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [678/5000] | Time: 0.31s\n",
      "(Training) Loss: 1214191.5266\n",
      "(Validation) Loss: 1267401.7422, MAE: 4733.4883, R2: -0.0669\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [679/5000] | Time: 0.37s\n",
      "(Training) Loss: 1238976.4772\n",
      "(Validation) Loss: 1267156.0178, MAE: 4730.8789, R2: -0.0667\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [680/5000] | Time: 0.33s\n",
      "(Training) Loss: 1219167.6675\n",
      "(Validation) Loss: 1266904.7060, MAE: 4731.5522, R2: -0.0665\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [681/5000] | Time: 0.39s\n",
      "(Training) Loss: 1222474.7538\n",
      "(Validation) Loss: 1266650.2603, MAE: 4728.6582, R2: -0.0663\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [682/5000] | Time: 0.32s\n",
      "(Training) Loss: 1228496.7919\n",
      "(Validation) Loss: 1266407.0451, MAE: 4730.1392, R2: -0.0661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [683/5000] | Time: 0.29s\n",
      "(Training) Loss: 1220119.1929\n",
      "(Validation) Loss: 1266149.9276, MAE: 4726.0166, R2: -0.0659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [684/5000] | Time: 0.26s\n",
      "(Training) Loss: 1231173.6041\n",
      "(Validation) Loss: 1265902.9029, MAE: 4725.4297, R2: -0.0657\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [685/5000] | Time: 0.27s\n",
      "(Training) Loss: 1221860.6789\n",
      "(Validation) Loss: 1265652.6832, MAE: 4724.7061, R2: -0.0655\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [686/5000] | Time: 0.22s\n",
      "(Training) Loss: 1227058.4930\n",
      "(Validation) Loss: 1265402.8952, MAE: 4724.0322, R2: -0.0653\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [687/5000] | Time: 0.23s\n",
      "(Training) Loss: 1210119.2246\n",
      "(Validation) Loss: 1265150.1613, MAE: 4724.1846, R2: -0.0651\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [688/5000] | Time: 0.29s\n",
      "(Training) Loss: 1222003.8287\n",
      "(Validation) Loss: 1264900.7289, MAE: 4721.0654, R2: -0.0648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [689/5000] | Time: 0.25s\n",
      "(Training) Loss: 1209404.0431\n",
      "(Validation) Loss: 1264655.2584, MAE: 4721.7583, R2: -0.0646\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [690/5000] | Time: 0.33s\n",
      "(Training) Loss: 1208208.4607\n",
      "(Validation) Loss: 1264405.6635, MAE: 4719.5889, R2: -0.0644\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [691/5000] | Time: 0.26s\n",
      "(Training) Loss: 1240204.1745\n",
      "(Validation) Loss: 1264157.2775, MAE: 4718.9673, R2: -0.0642\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [692/5000] | Time: 0.28s\n",
      "(Training) Loss: 1238616.5051\n",
      "(Validation) Loss: 1263906.2959, MAE: 4718.6836, R2: -0.0640\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [693/5000] | Time: 0.29s\n",
      "(Training) Loss: 1239790.2614\n",
      "(Validation) Loss: 1263654.8368, MAE: 4717.9263, R2: -0.0638\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [694/5000] | Time: 0.25s\n",
      "(Training) Loss: 1212079.1497\n",
      "(Validation) Loss: 1263405.0946, MAE: 4718.3442, R2: -0.0636\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [695/5000] | Time: 0.26s\n",
      "(Training) Loss: 1221681.1015\n",
      "(Validation) Loss: 1263155.7130, MAE: 4717.4951, R2: -0.0634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [696/5000] | Time: 0.27s\n",
      "(Training) Loss: 1230783.1980\n",
      "(Validation) Loss: 1262910.5676, MAE: 4716.5669, R2: -0.0632\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [697/5000] | Time: 0.26s\n",
      "(Training) Loss: 1206064.5755\n",
      "(Validation) Loss: 1262660.3784, MAE: 4719.2158, R2: -0.0630\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [698/5000] | Time: 0.27s\n",
      "(Training) Loss: 1233137.8997\n",
      "(Validation) Loss: 1262413.8565, MAE: 4716.5850, R2: -0.0628\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [699/5000] | Time: 0.38s\n",
      "(Training) Loss: 1215266.5635\n",
      "(Validation) Loss: 1267535.2025, MAE: 4731.3838, R2: -0.0670\n",
      "==========================================================================================\n",
      "Epoch [700/5000] | Time: 0.29s\n",
      "(Training) Loss: 1215041.1599\n",
      "(Validation) Loss: 1267286.3949, MAE: 4731.2661, R2: -0.0668\n",
      "==========================================================================================\n",
      "Epoch [701/5000] | Time: 0.26s\n",
      "(Training) Loss: 1247005.7081\n",
      "(Validation) Loss: 1267038.9181, MAE: 4730.8145, R2: -0.0666\n",
      "==========================================================================================\n",
      "Epoch [702/5000] | Time: 0.29s\n",
      "(Training) Loss: 1206807.4164\n",
      "(Validation) Loss: 1266781.0997, MAE: 4729.1494, R2: -0.0664\n",
      "==========================================================================================\n",
      "Epoch [703/5000] | Time: 0.32s\n",
      "(Training) Loss: 1241121.4975\n",
      "(Validation) Loss: 1266534.1714, MAE: 4728.5898, R2: -0.0662\n",
      "==========================================================================================\n",
      "Epoch [704/5000] | Time: 0.27s\n",
      "(Training) Loss: 1227270.8972\n",
      "(Validation) Loss: 1266296.2743, MAE: 4732.0396, R2: -0.0660\n",
      "==========================================================================================\n",
      "Epoch [705/5000] | Time: 0.27s\n",
      "(Training) Loss: 1226649.5444\n",
      "(Validation) Loss: 1266033.3613, MAE: 4726.6909, R2: -0.0658\n",
      "==========================================================================================\n",
      "Epoch [706/5000] | Time: 0.26s\n",
      "(Training) Loss: 1208367.9327\n",
      "(Validation) Loss: 1265780.0127, MAE: 4724.8364, R2: -0.0656\n",
      "==========================================================================================\n",
      "Epoch [707/5000] | Time: 0.24s\n",
      "(Training) Loss: 1232460.8934\n",
      "(Validation) Loss: 1265531.5657, MAE: 4724.8643, R2: -0.0654\n",
      "==========================================================================================\n",
      "Epoch [708/5000] | Time: 0.27s\n",
      "(Training) Loss: 1213047.6491\n",
      "(Validation) Loss: 1265286.4863, MAE: 4725.3662, R2: -0.0652\n",
      "==========================================================================================\n",
      "Epoch [709/5000] | Time: 0.27s\n",
      "(Training) Loss: 1204157.3589\n",
      "(Validation) Loss: 1265028.7340, MAE: 4723.6572, R2: -0.0650\n",
      "==========================================================================================\n",
      "Epoch [710/5000] | Time: 0.31s\n",
      "(Training) Loss: 1230106.1637\n",
      "(Validation) Loss: 1264782.4863, MAE: 4721.3062, R2: -0.0647\n",
      "==========================================================================================\n",
      "Epoch [711/5000] | Time: 0.28s\n",
      "(Training) Loss: 1204156.6004\n",
      "(Validation) Loss: 1264530.6210, MAE: 4720.6641, R2: -0.0645\n",
      "==========================================================================================\n",
      "Epoch [712/5000] | Time: 0.29s\n",
      "(Training) Loss: 1208759.0844\n",
      "(Validation) Loss: 1264283.0425, MAE: 4719.9004, R2: -0.0643\n",
      "==========================================================================================\n",
      "Epoch [713/5000] | Time: 0.25s\n",
      "(Training) Loss: 1215152.5647\n",
      "(Validation) Loss: 1264038.3441, MAE: 4720.6060, R2: -0.0641\n",
      "==========================================================================================\n",
      "Epoch [714/5000] | Time: 0.25s\n",
      "(Training) Loss: 1213673.6694\n",
      "(Validation) Loss: 1263787.4032, MAE: 4718.7725, R2: -0.0639\n",
      "==========================================================================================\n",
      "Epoch [715/5000] | Time: 0.26s\n",
      "(Training) Loss: 1207279.4613\n",
      "(Validation) Loss: 1263536.1016, MAE: 4717.0522, R2: -0.0637\n",
      "==========================================================================================\n",
      "Epoch [716/5000] | Time: 0.27s\n",
      "(Training) Loss: 1210546.9822\n",
      "(Validation) Loss: 1263286.6235, MAE: 4716.3325, R2: -0.0635\n",
      "==========================================================================================\n",
      "Epoch [717/5000] | Time: 0.28s\n",
      "(Training) Loss: 1231456.4569\n",
      "(Validation) Loss: 1263039.7867, MAE: 4715.6265, R2: -0.0633\n",
      "==========================================================================================\n",
      "Epoch [718/5000] | Time: 0.29s\n",
      "(Training) Loss: 1210234.3027\n",
      "(Validation) Loss: 1262793.4933, MAE: 4716.3027, R2: -0.0631\n",
      "==========================================================================================\n",
      "Epoch [719/5000] | Time: 0.33s\n",
      "(Training) Loss: 1233424.5393\n",
      "(Validation) Loss: 1262540.4902, MAE: 4713.8032, R2: -0.0629\n",
      "==========================================================================================\n",
      "Epoch [720/5000] | Time: 0.32s\n",
      "(Training) Loss: 1205596.3852\n",
      "(Validation) Loss: 1262283.5352, MAE: 4711.8457, R2: -0.0627\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [721/5000] | Time: 0.28s\n",
      "(Training) Loss: 1221429.0393\n",
      "(Validation) Loss: 1262041.9860, MAE: 4711.6758, R2: -0.0625\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [722/5000] | Time: 0.27s\n",
      "(Training) Loss: 1234961.7284\n",
      "(Validation) Loss: 1261796.0025, MAE: 4712.5171, R2: -0.0623\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [723/5000] | Time: 0.27s\n",
      "(Training) Loss: 1201303.1480\n",
      "(Validation) Loss: 1261541.1556, MAE: 4711.3037, R2: -0.0620\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [724/5000] | Time: 0.29s\n",
      "(Training) Loss: 1212303.6815\n",
      "(Validation) Loss: 1261289.0921, MAE: 4708.6328, R2: -0.0618\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [725/5000] | Time: 0.30s\n",
      "(Training) Loss: 1224354.2754\n",
      "(Validation) Loss: 1261045.6889, MAE: 4708.8657, R2: -0.0616\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [726/5000] | Time: 0.25s\n",
      "(Training) Loss: 1204486.0279\n",
      "(Validation) Loss: 1260794.2044, MAE: 4707.9097, R2: -0.0614\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [727/5000] | Time: 0.29s\n",
      "(Training) Loss: 1212970.4829\n",
      "(Validation) Loss: 1260544.5587, MAE: 4705.9307, R2: -0.0612\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [728/5000] | Time: 0.29s\n",
      "(Training) Loss: 1209692.6815\n",
      "(Validation) Loss: 1260307.5911, MAE: 4710.2329, R2: -0.0610\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [729/5000] | Time: 0.27s\n",
      "(Training) Loss: 1222389.3909\n",
      "(Validation) Loss: 1260049.0108, MAE: 4703.9087, R2: -0.0608\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [730/5000] | Time: 0.30s\n",
      "(Training) Loss: 1205137.8477\n",
      "(Validation) Loss: 1259797.6940, MAE: 4703.6099, R2: -0.0606\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [731/5000] | Time: 0.26s\n",
      "(Training) Loss: 1220134.6650\n",
      "(Validation) Loss: 1259549.2317, MAE: 4702.5947, R2: -0.0604\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [732/5000] | Time: 0.31s\n",
      "(Training) Loss: 1216251.2132\n",
      "(Validation) Loss: 1259300.2311, MAE: 4701.9243, R2: -0.0602\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [733/5000] | Time: 0.29s\n",
      "(Training) Loss: 1232233.8464\n",
      "(Validation) Loss: 1259052.9422, MAE: 4700.6455, R2: -0.0600\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [734/5000] | Time: 0.36s\n",
      "(Training) Loss: 1213899.2538\n",
      "(Validation) Loss: 1258801.3359, MAE: 4699.7393, R2: -0.0598\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [735/5000] | Time: 0.34s\n",
      "(Training) Loss: 1224063.8737\n",
      "(Validation) Loss: 1258554.3111, MAE: 4698.0449, R2: -0.0596\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [736/5000] | Time: 0.30s\n",
      "(Training) Loss: 1237757.1028\n",
      "(Validation) Loss: 1261175.8578, MAE: 4714.7446, R2: -0.0617\n",
      "==========================================================================================\n",
      "Epoch [737/5000] | Time: 0.28s\n",
      "(Training) Loss: 1212450.0514\n",
      "(Validation) Loss: 1258057.6457, MAE: 4698.6240, R2: -0.0591\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [738/5000] | Time: 0.31s\n",
      "(Training) Loss: 1231809.2132\n",
      "(Validation) Loss: 1257813.9835, MAE: 4700.1284, R2: -0.0589\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [739/5000] | Time: 0.35s\n",
      "(Training) Loss: 1222131.2779\n",
      "(Validation) Loss: 1257557.5111, MAE: 4697.3145, R2: -0.0587\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [740/5000] | Time: 0.27s\n",
      "(Training) Loss: 1202056.8160\n",
      "(Validation) Loss: 1257301.4298, MAE: 4693.6338, R2: -0.0585\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [741/5000] | Time: 0.23s\n",
      "(Training) Loss: 1219077.2741\n",
      "(Validation) Loss: 1257062.9435, MAE: 4695.0913, R2: -0.0583\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [742/5000] | Time: 0.24s\n",
      "(Training) Loss: 1211699.1751\n",
      "(Validation) Loss: 1256812.1905, MAE: 4693.5879, R2: -0.0581\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [743/5000] | Time: 0.25s\n",
      "(Training) Loss: 1235593.2640\n",
      "(Validation) Loss: 1256561.4984, MAE: 4692.1475, R2: -0.0579\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [744/5000] | Time: 0.26s\n",
      "(Training) Loss: 1221775.5799\n",
      "(Validation) Loss: 1256316.0990, MAE: 4692.5605, R2: -0.0577\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [745/5000] | Time: 0.26s\n",
      "(Training) Loss: 1226672.9359\n",
      "(Validation) Loss: 1256062.3238, MAE: 4689.7686, R2: -0.0575\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [746/5000] | Time: 0.25s\n",
      "(Training) Loss: 1203776.9302\n",
      "(Validation) Loss: 1255813.4197, MAE: 4690.0386, R2: -0.0573\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [747/5000] | Time: 0.25s\n",
      "(Training) Loss: 1202296.0533\n",
      "(Validation) Loss: 1255570.5448, MAE: 4690.3564, R2: -0.0571\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [748/5000] | Time: 0.28s\n",
      "(Training) Loss: 1217595.5457\n",
      "(Validation) Loss: 1255315.5962, MAE: 4686.4243, R2: -0.0569\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [749/5000] | Time: 0.33s\n",
      "(Training) Loss: 1207429.0381\n",
      "(Validation) Loss: 1255070.4965, MAE: 4685.7764, R2: -0.0567\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [750/5000] | Time: 0.30s\n",
      "(Training) Loss: 1223618.6846\n",
      "(Validation) Loss: 1254822.4559, MAE: 4685.0806, R2: -0.0564\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [751/5000] | Time: 0.28s\n",
      "(Training) Loss: 1226364.3528\n",
      "(Validation) Loss: 1254579.4489, MAE: 4686.1147, R2: -0.0562\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [752/5000] | Time: 0.28s\n",
      "(Training) Loss: 1198613.2544\n",
      "(Validation) Loss: 1254327.6749, MAE: 4683.3560, R2: -0.0560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [753/5000] | Time: 0.27s\n",
      "(Training) Loss: 1220589.5006\n",
      "(Validation) Loss: 1254079.1568, MAE: 4682.5029, R2: -0.0558\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [754/5000] | Time: 0.27s\n",
      "(Training) Loss: 1207696.7678\n",
      "(Validation) Loss: 1253837.2622, MAE: 4682.4062, R2: -0.0556\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [755/5000] | Time: 0.26s\n",
      "(Training) Loss: 1195791.7291\n",
      "(Validation) Loss: 1253589.2622, MAE: 4682.0005, R2: -0.0554\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [756/5000] | Time: 0.27s\n",
      "(Training) Loss: 1223303.4150\n",
      "(Validation) Loss: 1253347.3117, MAE: 4682.4224, R2: -0.0552\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [757/5000] | Time: 0.30s\n",
      "(Training) Loss: 1210151.1206\n",
      "(Validation) Loss: 1253090.9359, MAE: 4679.5864, R2: -0.0550\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [758/5000] | Time: 0.27s\n",
      "(Training) Loss: 1205363.3579\n",
      "(Validation) Loss: 1252848.9498, MAE: 4679.2988, R2: -0.0548\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [759/5000] | Time: 0.30s\n",
      "(Training) Loss: 1208947.9289\n",
      "(Validation) Loss: 1252595.9416, MAE: 4677.4658, R2: -0.0546\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [760/5000] | Time: 0.29s\n",
      "(Training) Loss: 1211452.6428\n",
      "(Validation) Loss: 1252351.6241, MAE: 4675.8604, R2: -0.0544\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [761/5000] | Time: 0.26s\n",
      "(Training) Loss: 1199906.3541\n",
      "(Validation) Loss: 1252103.0044, MAE: 4674.0479, R2: -0.0542\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [762/5000] | Time: 0.28s\n",
      "(Training) Loss: 1197088.2824\n",
      "(Validation) Loss: 1251858.0521, MAE: 4675.0947, R2: -0.0540\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [763/5000] | Time: 0.28s\n",
      "(Training) Loss: 1192551.9597\n",
      "(Validation) Loss: 1251610.8851, MAE: 4673.4023, R2: -0.0538\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [764/5000] | Time: 0.29s\n",
      "(Training) Loss: 1208252.7738\n",
      "(Validation) Loss: 1251372.0127, MAE: 4675.1592, R2: -0.0536\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [765/5000] | Time: 0.30s\n",
      "(Training) Loss: 1194870.7024\n",
      "(Validation) Loss: 1251122.5498, MAE: 4672.0439, R2: -0.0534\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [766/5000] | Time: 0.24s\n",
      "(Training) Loss: 1211482.5501\n",
      "(Validation) Loss: 1250876.5714, MAE: 4669.7949, R2: -0.0532\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [767/5000] | Time: 0.25s\n",
      "(Training) Loss: 1208952.4918\n",
      "(Validation) Loss: 1250628.5613, MAE: 4671.1592, R2: -0.0530\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [768/5000] | Time: 0.29s\n",
      "(Training) Loss: 1218095.2005\n",
      "(Validation) Loss: 1250379.9314, MAE: 4668.7515, R2: -0.0527\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [769/5000] | Time: 0.22s\n",
      "(Training) Loss: 1213206.5102\n",
      "(Validation) Loss: 1250128.9702, MAE: 4666.9053, R2: -0.0525\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [770/5000] | Time: 0.24s\n",
      "(Training) Loss: 1202313.4099\n",
      "(Validation) Loss: 1249888.5689, MAE: 4668.6001, R2: -0.0523\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [771/5000] | Time: 0.27s\n",
      "(Training) Loss: 1193183.6999\n",
      "(Validation) Loss: 1249642.4127, MAE: 4667.5332, R2: -0.0521\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [772/5000] | Time: 0.26s\n",
      "(Training) Loss: 1199338.2335\n",
      "(Validation) Loss: 1249395.9975, MAE: 4666.3408, R2: -0.0519\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [773/5000] | Time: 0.25s\n",
      "(Training) Loss: 1198246.2373\n",
      "(Validation) Loss: 1249151.5378, MAE: 4665.9370, R2: -0.0517\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [774/5000] | Time: 0.26s\n",
      "(Training) Loss: 1204338.5438\n",
      "(Validation) Loss: 1248901.3740, MAE: 4664.2329, R2: -0.0515\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [775/5000] | Time: 0.27s\n",
      "(Training) Loss: 1219335.7681\n",
      "(Validation) Loss: 1248659.1187, MAE: 4662.7192, R2: -0.0513\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [776/5000] | Time: 0.28s\n",
      "(Training) Loss: 1205595.2944\n",
      "(Validation) Loss: 1248407.8730, MAE: 4661.3652, R2: -0.0511\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [777/5000] | Time: 0.29s\n",
      "(Training) Loss: 1209449.3503\n",
      "(Validation) Loss: 1248163.8197, MAE: 4660.2988, R2: -0.0509\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [778/5000] | Time: 0.23s\n",
      "(Training) Loss: 1191620.4949\n",
      "(Validation) Loss: 1247922.5956, MAE: 4663.2227, R2: -0.0507\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [779/5000] | Time: 0.25s\n",
      "(Training) Loss: 1192847.5482\n",
      "(Validation) Loss: 1247673.7981, MAE: 4659.1382, R2: -0.0505\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [780/5000] | Time: 0.24s\n",
      "(Training) Loss: 1229288.5279\n",
      "(Validation) Loss: 1247422.5422, MAE: 4657.4097, R2: -0.0503\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [781/5000] | Time: 0.23s\n",
      "(Training) Loss: 1192434.1447\n",
      "(Validation) Loss: 1247182.4762, MAE: 4659.5034, R2: -0.0501\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [782/5000] | Time: 0.21s\n",
      "(Training) Loss: 1200219.2360\n",
      "(Validation) Loss: 1246933.9784, MAE: 4658.4907, R2: -0.0499\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [783/5000] | Time: 0.23s\n",
      "(Training) Loss: 1228884.6783\n",
      "(Validation) Loss: 1246684.2159, MAE: 4654.8799, R2: -0.0497\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [784/5000] | Time: 0.27s\n",
      "(Training) Loss: 1200985.9562\n",
      "(Validation) Loss: 1246440.7924, MAE: 4655.0674, R2: -0.0495\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [785/5000] | Time: 0.24s\n",
      "(Training) Loss: 1193520.5850\n",
      "(Validation) Loss: 1246188.5613, MAE: 4652.0288, R2: -0.0493\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [786/5000] | Time: 0.27s\n",
      "(Training) Loss: 1195033.1802\n",
      "(Validation) Loss: 1245949.8717, MAE: 4652.8169, R2: -0.0491\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [787/5000] | Time: 0.21s\n",
      "(Training) Loss: 1188375.0317\n",
      "(Validation) Loss: 1245704.0203, MAE: 4652.8535, R2: -0.0489\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [788/5000] | Time: 0.24s\n",
      "(Training) Loss: 1199835.9848\n",
      "(Validation) Loss: 1245461.2013, MAE: 4650.5986, R2: -0.0487\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [789/5000] | Time: 0.31s\n",
      "(Training) Loss: 1211408.7690\n",
      "(Validation) Loss: 1245217.2190, MAE: 4651.0112, R2: -0.0484\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [790/5000] | Time: 0.22s\n",
      "(Training) Loss: 1188061.4749\n",
      "(Validation) Loss: 1244966.0190, MAE: 4648.6191, R2: -0.0482\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [791/5000] | Time: 0.31s\n",
      "(Training) Loss: 1203602.5926\n",
      "(Validation) Loss: 1244723.1492, MAE: 4648.4917, R2: -0.0480\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [792/5000] | Time: 0.25s\n",
      "(Training) Loss: 1195295.4277\n",
      "(Validation) Loss: 1244484.4546, MAE: 4648.0342, R2: -0.0478\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [793/5000] | Time: 0.24s\n",
      "(Training) Loss: 1208230.5209\n",
      "(Validation) Loss: 1244238.8470, MAE: 4650.1372, R2: -0.0476\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [794/5000] | Time: 0.27s\n",
      "(Training) Loss: 1207036.8122\n",
      "(Validation) Loss: 1243984.2032, MAE: 4645.7290, R2: -0.0474\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [795/5000] | Time: 0.31s\n",
      "(Training) Loss: 1199240.5305\n",
      "(Validation) Loss: 1243741.2622, MAE: 4645.2529, R2: -0.0472\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [796/5000] | Time: 0.28s\n",
      "(Training) Loss: 1192903.0089\n",
      "(Validation) Loss: 1243494.1054, MAE: 4644.5884, R2: -0.0470\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [797/5000] | Time: 0.25s\n",
      "(Training) Loss: 1193523.6434\n",
      "(Validation) Loss: 1243249.8337, MAE: 4644.6504, R2: -0.0468\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [798/5000] | Time: 0.24s\n",
      "(Training) Loss: 1193913.9480\n",
      "(Validation) Loss: 1243007.3803, MAE: 4644.4116, R2: -0.0466\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [799/5000] | Time: 0.23s\n",
      "(Training) Loss: 1189103.6250\n",
      "(Validation) Loss: 1242755.7537, MAE: 4641.4331, R2: -0.0464\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [800/5000] | Time: 0.23s\n",
      "(Training) Loss: 1184247.1729\n",
      "(Validation) Loss: 1242518.7759, MAE: 4641.4248, R2: -0.0462\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [801/5000] | Time: 0.21s\n",
      "(Training) Loss: 1191745.3718\n",
      "(Validation) Loss: 1242272.8584, MAE: 4640.9253, R2: -0.0460\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [802/5000] | Time: 0.23s\n",
      "(Training) Loss: 1186574.6846\n",
      "(Validation) Loss: 1242034.3975, MAE: 4641.4385, R2: -0.0458\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [803/5000] | Time: 0.23s\n",
      "(Training) Loss: 1198854.8528\n",
      "(Validation) Loss: 1241785.9860, MAE: 4639.3281, R2: -0.0456\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [804/5000] | Time: 0.28s\n",
      "(Training) Loss: 1193475.2665\n",
      "(Validation) Loss: 1241538.1587, MAE: 4636.3647, R2: -0.0454\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [805/5000] | Time: 0.27s\n",
      "(Training) Loss: 1206830.0330\n",
      "(Validation) Loss: 1241293.5213, MAE: 4635.7661, R2: -0.0452\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [806/5000] | Time: 0.25s\n",
      "(Training) Loss: 1190734.0622\n",
      "(Validation) Loss: 1241052.3327, MAE: 4636.2856, R2: -0.0450\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [807/5000] | Time: 0.24s\n",
      "(Training) Loss: 1208356.1091\n",
      "(Validation) Loss: 1240801.6356, MAE: 4634.1108, R2: -0.0448\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [808/5000] | Time: 0.24s\n",
      "(Training) Loss: 1213153.0228\n",
      "(Validation) Loss: 1240557.7549, MAE: 4634.0640, R2: -0.0446\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [809/5000] | Time: 0.26s\n",
      "(Training) Loss: 1203682.4645\n",
      "(Validation) Loss: 1243382.5981, MAE: 4646.1172, R2: -0.0469\n",
      "==========================================================================================\n",
      "Epoch [810/5000] | Time: 0.26s\n",
      "(Training) Loss: 1196933.7291\n",
      "(Validation) Loss: 1243136.6908, MAE: 4642.8496, R2: -0.0467\n",
      "==========================================================================================\n",
      "Epoch [811/5000] | Time: 0.24s\n",
      "(Training) Loss: 1201505.2297\n",
      "(Validation) Loss: 1242901.3029, MAE: 4643.6699, R2: -0.0465\n",
      "==========================================================================================\n",
      "Epoch [812/5000] | Time: 0.26s\n",
      "(Training) Loss: 1218577.3344\n",
      "(Validation) Loss: 1242654.2883, MAE: 4642.2891, R2: -0.0463\n",
      "==========================================================================================\n",
      "Epoch [813/5000] | Time: 0.33s\n",
      "(Training) Loss: 1188873.4778\n",
      "(Validation) Loss: 1242445.4400, MAE: 4644.2031, R2: -0.0461\n",
      "==========================================================================================\n",
      "Epoch [814/5000] | Time: 0.24s\n",
      "(Training) Loss: 1190979.6003\n",
      "(Validation) Loss: 1242171.9467, MAE: 4643.4224, R2: -0.0459\n",
      "==========================================================================================\n",
      "Epoch [815/5000] | Time: 0.24s\n",
      "(Training) Loss: 1189023.4632\n",
      "(Validation) Loss: 1241927.7968, MAE: 4638.6963, R2: -0.0457\n",
      "==========================================================================================\n",
      "Epoch [816/5000] | Time: 0.28s\n",
      "(Training) Loss: 1214344.6599\n",
      "(Validation) Loss: 1241690.7276, MAE: 4638.6235, R2: -0.0455\n",
      "==========================================================================================\n",
      "Epoch [817/5000] | Time: 0.27s\n",
      "(Training) Loss: 1206692.4442\n",
      "(Validation) Loss: 1241440.9041, MAE: 4636.3589, R2: -0.0453\n",
      "==========================================================================================\n",
      "Epoch [818/5000] | Time: 0.26s\n",
      "(Training) Loss: 1190335.6015\n",
      "(Validation) Loss: 1241201.2698, MAE: 4635.5967, R2: -0.0451\n",
      "==========================================================================================\n",
      "Epoch [819/5000] | Time: 0.26s\n",
      "(Training) Loss: 1222484.2513\n",
      "(Validation) Loss: 1240959.0400, MAE: 4634.6934, R2: -0.0449\n",
      "==========================================================================================\n",
      "Epoch [820/5000] | Time: 0.36s\n",
      "(Training) Loss: 1188378.5127\n",
      "(Validation) Loss: 1240715.6470, MAE: 4634.3369, R2: -0.0447\n",
      "==========================================================================================\n",
      "Epoch [821/5000] | Time: 0.25s\n",
      "(Training) Loss: 1182430.8268\n",
      "(Validation) Loss: 1240473.1225, MAE: 4633.6040, R2: -0.0445\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [822/5000] | Time: 0.24s\n",
      "(Training) Loss: 1205183.7405\n",
      "(Validation) Loss: 1240238.8216, MAE: 4632.3872, R2: -0.0443\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [823/5000] | Time: 0.28s\n",
      "(Training) Loss: 1197408.3655\n",
      "(Validation) Loss: 1239990.6997, MAE: 4630.6948, R2: -0.0441\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [824/5000] | Time: 0.26s\n",
      "(Training) Loss: 1180362.8263\n",
      "(Validation) Loss: 1239753.1784, MAE: 4631.6118, R2: -0.0439\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [825/5000] | Time: 0.24s\n",
      "(Training) Loss: 1200327.8725\n",
      "(Validation) Loss: 1239512.4775, MAE: 4629.8101, R2: -0.0437\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [826/5000] | Time: 0.28s\n",
      "(Training) Loss: 1200565.3731\n",
      "(Validation) Loss: 1239289.1022, MAE: 4636.0947, R2: -0.0435\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [827/5000] | Time: 0.24s\n",
      "(Training) Loss: 1191334.2811\n",
      "(Validation) Loss: 1239031.2584, MAE: 4630.2715, R2: -0.0433\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [828/5000] | Time: 0.30s\n",
      "(Training) Loss: 1192605.4734\n",
      "(Validation) Loss: 1238792.1422, MAE: 4626.8735, R2: -0.0431\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [829/5000] | Time: 0.30s\n",
      "(Training) Loss: 1196241.3388\n",
      "(Validation) Loss: 1238547.2000, MAE: 4626.2954, R2: -0.0429\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [830/5000] | Time: 0.26s\n",
      "(Training) Loss: 1181468.0720\n",
      "(Validation) Loss: 1238306.5143, MAE: 4626.6055, R2: -0.0427\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [831/5000] | Time: 0.26s\n",
      "(Training) Loss: 1190055.9188\n",
      "(Validation) Loss: 1238068.1803, MAE: 4624.6836, R2: -0.0425\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [832/5000] | Time: 0.29s\n",
      "(Training) Loss: 1182550.1345\n",
      "(Validation) Loss: 1237827.8654, MAE: 4624.5176, R2: -0.0423\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [833/5000] | Time: 0.28s\n",
      "(Training) Loss: 1199908.8287\n",
      "(Validation) Loss: 1237586.7429, MAE: 4623.4648, R2: -0.0421\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [834/5000] | Time: 0.25s\n",
      "(Training) Loss: 1178794.0611\n",
      "(Validation) Loss: 1237347.5302, MAE: 4622.2881, R2: -0.0419\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [835/5000] | Time: 0.24s\n",
      "(Training) Loss: 1189803.9435\n",
      "(Validation) Loss: 1237108.4495, MAE: 4621.8276, R2: -0.0417\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [836/5000] | Time: 0.27s\n",
      "(Training) Loss: 1189590.3223\n",
      "(Validation) Loss: 1236865.4781, MAE: 4619.9253, R2: -0.0415\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [837/5000] | Time: 0.33s\n",
      "(Training) Loss: 1195190.9150\n",
      "(Validation) Loss: 1236629.7956, MAE: 4619.8428, R2: -0.0413\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [838/5000] | Time: 0.25s\n",
      "(Training) Loss: 1185681.7525\n",
      "(Validation) Loss: 1236385.5797, MAE: 4619.4248, R2: -0.0411\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [839/5000] | Time: 0.28s\n",
      "(Training) Loss: 1197143.8566\n",
      "(Validation) Loss: 1236145.4324, MAE: 4616.9985, R2: -0.0409\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [840/5000] | Time: 0.26s\n",
      "(Training) Loss: 1202681.8642\n",
      "(Validation) Loss: 1235914.9816, MAE: 4619.8706, R2: -0.0407\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [841/5000] | Time: 0.29s\n",
      "(Training) Loss: 1187692.5228\n",
      "(Validation) Loss: 1235663.0603, MAE: 4616.6772, R2: -0.0405\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [842/5000] | Time: 0.28s\n",
      "(Training) Loss: 1190479.3312\n",
      "(Validation) Loss: 1235423.2178, MAE: 4614.8789, R2: -0.0403\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [843/5000] | Time: 0.25s\n",
      "(Training) Loss: 1197729.1516\n",
      "(Validation) Loss: 1235189.2165, MAE: 4616.8550, R2: -0.0401\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [844/5000] | Time: 0.30s\n",
      "(Training) Loss: 1206688.3585\n",
      "(Validation) Loss: 1234966.9994, MAE: 4617.3179, R2: -0.0399\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [845/5000] | Time: 0.29s\n",
      "(Training) Loss: 1209417.9048\n",
      "(Validation) Loss: 1234702.7860, MAE: 4613.6211, R2: -0.0397\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [846/5000] | Time: 0.28s\n",
      "(Training) Loss: 1194148.2487\n",
      "(Validation) Loss: 1234459.6825, MAE: 4612.7461, R2: -0.0395\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [847/5000] | Time: 0.27s\n",
      "(Training) Loss: 1181522.6104\n",
      "(Validation) Loss: 1234214.7860, MAE: 4610.4722, R2: -0.0393\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [848/5000] | Time: 0.28s\n",
      "(Training) Loss: 1187086.2805\n",
      "(Validation) Loss: 1234006.9638, MAE: 4614.0303, R2: -0.0391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [849/5000] | Time: 0.24s\n",
      "(Training) Loss: 1199547.5793\n",
      "(Validation) Loss: 1233746.4533, MAE: 4610.6797, R2: -0.0389\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [850/5000] | Time: 0.23s\n",
      "(Training) Loss: 1180192.7678\n",
      "(Validation) Loss: 1233503.8730, MAE: 4611.1074, R2: -0.0387\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [851/5000] | Time: 0.27s\n",
      "(Training) Loss: 1178141.0520\n",
      "(Validation) Loss: 1233273.3562, MAE: 4612.6631, R2: -0.0385\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [852/5000] | Time: 0.31s\n",
      "(Training) Loss: 1191674.2392\n",
      "(Validation) Loss: 1233022.3949, MAE: 4606.3662, R2: -0.0383\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [853/5000] | Time: 0.29s\n",
      "(Training) Loss: 1202890.0368\n",
      "(Validation) Loss: 1232780.8203, MAE: 4605.4243, R2: -0.0381\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [854/5000] | Time: 0.35s\n",
      "(Training) Loss: 1218226.4251\n",
      "(Validation) Loss: 1232556.9422, MAE: 4605.6890, R2: -0.0379\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [855/5000] | Time: 0.32s\n",
      "(Training) Loss: 1190522.3401\n",
      "(Validation) Loss: 1232298.1283, MAE: 4604.1953, R2: -0.0377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [856/5000] | Time: 0.33s\n",
      "(Training) Loss: 1180212.8179\n",
      "(Validation) Loss: 1232060.6171, MAE: 4603.5752, R2: -0.0375\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [857/5000] | Time: 0.29s\n",
      "(Training) Loss: 1175936.3030\n",
      "(Validation) Loss: 1231834.4076, MAE: 4608.4619, R2: -0.0373\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [858/5000] | Time: 0.25s\n",
      "(Training) Loss: 1194744.2069\n",
      "(Validation) Loss: 1231582.1765, MAE: 4601.4170, R2: -0.0371\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [859/5000] | Time: 0.25s\n",
      "(Training) Loss: 1209930.1961\n",
      "(Validation) Loss: 1231344.0356, MAE: 4601.8193, R2: -0.0369\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [860/5000] | Time: 0.23s\n",
      "(Training) Loss: 1179563.4803\n",
      "(Validation) Loss: 1231100.8711, MAE: 4599.3545, R2: -0.0367\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [861/5000] | Time: 0.21s\n",
      "(Training) Loss: 1179556.4505\n",
      "(Validation) Loss: 1230864.0863, MAE: 4597.6392, R2: -0.0365\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [862/5000] | Time: 0.26s\n",
      "(Training) Loss: 1205398.6421\n",
      "(Validation) Loss: 1230625.5289, MAE: 4598.1582, R2: -0.0363\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [863/5000] | Time: 0.22s\n",
      "(Training) Loss: 1190042.8388\n",
      "(Validation) Loss: 1230388.4394, MAE: 4597.7671, R2: -0.0361\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [864/5000] | Time: 0.25s\n",
      "(Training) Loss: 1214358.0546\n",
      "(Validation) Loss: 1230143.3956, MAE: 4595.9316, R2: -0.0359\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [865/5000] | Time: 0.27s\n",
      "(Training) Loss: 1207323.0926\n",
      "(Validation) Loss: 1229905.4984, MAE: 4595.7871, R2: -0.0357\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [866/5000] | Time: 0.27s\n",
      "(Training) Loss: 1179838.5945\n",
      "(Validation) Loss: 1229660.5562, MAE: 4594.5635, R2: -0.0355\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [867/5000] | Time: 0.27s\n",
      "(Training) Loss: 1219968.9315\n",
      "(Validation) Loss: 1229422.3187, MAE: 4593.6973, R2: -0.0353\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [868/5000] | Time: 0.25s\n",
      "(Training) Loss: 1176486.3452\n",
      "(Validation) Loss: 1229182.7048, MAE: 4594.0649, R2: -0.0351\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [869/5000] | Time: 0.24s\n",
      "(Training) Loss: 1185886.2208\n",
      "(Validation) Loss: 1228965.6940, MAE: 4592.4424, R2: -0.0349\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [870/5000] | Time: 0.25s\n",
      "(Training) Loss: 1192505.6180\n",
      "(Validation) Loss: 1228706.4686, MAE: 4590.4517, R2: -0.0347\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [871/5000] | Time: 0.27s\n",
      "(Training) Loss: 1183211.4473\n",
      "(Validation) Loss: 1228467.7841, MAE: 4590.5894, R2: -0.0345\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [872/5000] | Time: 0.28s\n",
      "(Training) Loss: 1186896.3877\n",
      "(Validation) Loss: 1228227.4946, MAE: 4588.5542, R2: -0.0343\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [873/5000] | Time: 0.23s\n",
      "(Training) Loss: 1212443.5768\n",
      "(Validation) Loss: 1227992.1270, MAE: 4588.0024, R2: -0.0341\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [874/5000] | Time: 0.24s\n",
      "(Training) Loss: 1190145.3591\n",
      "(Validation) Loss: 1227766.4914, MAE: 4591.7148, R2: -0.0339\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [875/5000] | Time: 0.28s\n",
      "(Training) Loss: 1202815.9607\n",
      "(Validation) Loss: 1227515.2762, MAE: 4587.3540, R2: -0.0337\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [876/5000] | Time: 0.27s\n",
      "(Training) Loss: 1171317.3693\n",
      "(Validation) Loss: 1227277.0641, MAE: 4588.2769, R2: -0.0335\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [877/5000] | Time: 0.43s\n",
      "(Training) Loss: 1176532.1085\n",
      "(Validation) Loss: 1227031.7765, MAE: 4584.3604, R2: -0.0333\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [878/5000] | Time: 0.59s\n",
      "(Training) Loss: 1193689.7855\n",
      "(Validation) Loss: 1226810.4737, MAE: 4586.1499, R2: -0.0331\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [879/5000] | Time: 0.54s\n",
      "(Training) Loss: 1178410.7627\n",
      "(Validation) Loss: 1226558.5778, MAE: 4583.3257, R2: -0.0329\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [880/5000] | Time: 0.45s\n",
      "(Training) Loss: 1191426.8388\n",
      "(Validation) Loss: 1226321.7473, MAE: 4581.8931, R2: -0.0327\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [881/5000] | Time: 0.44s\n",
      "(Training) Loss: 1170946.3972\n",
      "(Validation) Loss: 1226085.8768, MAE: 4582.0913, R2: -0.0325\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [882/5000] | Time: 0.29s\n",
      "(Training) Loss: 1183544.1739\n",
      "(Validation) Loss: 1225850.3721, MAE: 4582.3218, R2: -0.0323\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [883/5000] | Time: 0.36s\n",
      "(Training) Loss: 1182959.9378\n",
      "(Validation) Loss: 1225612.3937, MAE: 4579.5693, R2: -0.0321\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [884/5000] | Time: 0.30s\n",
      "(Training) Loss: 1177586.5457\n",
      "(Validation) Loss: 1225374.7200, MAE: 4578.3291, R2: -0.0319\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [885/5000] | Time: 0.27s\n",
      "(Training) Loss: 1170710.3103\n",
      "(Validation) Loss: 1225136.2133, MAE: 4578.6025, R2: -0.0317\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [886/5000] | Time: 0.26s\n",
      "(Training) Loss: 1173590.8331\n",
      "(Validation) Loss: 1224901.0337, MAE: 4578.6382, R2: -0.0315\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [887/5000] | Time: 0.22s\n",
      "(Training) Loss: 1196673.8966\n",
      "(Validation) Loss: 1224745.2800, MAE: 4583.8325, R2: -0.0314\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [888/5000] | Time: 0.21s\n",
      "(Training) Loss: 1184859.6421\n",
      "(Validation) Loss: 1224431.3803, MAE: 4579.1582, R2: -0.0311\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [889/5000] | Time: 0.19s\n",
      "(Training) Loss: 1173524.6821\n",
      "(Validation) Loss: 1224192.8635, MAE: 4577.6011, R2: -0.0309\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [890/5000] | Time: 0.21s\n",
      "(Training) Loss: 1203841.8871\n",
      "(Validation) Loss: 1223951.4565, MAE: 4574.7109, R2: -0.0307\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [891/5000] | Time: 0.23s\n",
      "(Training) Loss: 1212691.3388\n",
      "(Validation) Loss: 1223708.6222, MAE: 4571.7285, R2: -0.0305\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [892/5000] | Time: 0.26s\n",
      "(Training) Loss: 1165191.2456\n",
      "(Validation) Loss: 1223465.2190, MAE: 4571.5054, R2: -0.0303\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [893/5000] | Time: 0.24s\n",
      "(Training) Loss: 1185977.2919\n",
      "(Validation) Loss: 1223239.9390, MAE: 4571.7163, R2: -0.0301\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [894/5000] | Time: 0.27s\n",
      "(Training) Loss: 1196593.7462\n",
      "(Validation) Loss: 1222996.2006, MAE: 4568.7998, R2: -0.0299\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [895/5000] | Time: 0.29s\n",
      "(Training) Loss: 1172166.6409\n",
      "(Validation) Loss: 1222762.4787, MAE: 4570.6655, R2: -0.0297\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [896/5000] | Time: 0.24s\n",
      "(Training) Loss: 1165616.5293\n",
      "(Validation) Loss: 1222523.1746, MAE: 4569.8965, R2: -0.0295\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [897/5000] | Time: 0.22s\n",
      "(Training) Loss: 1178964.0127\n",
      "(Validation) Loss: 1222289.9708, MAE: 4567.1567, R2: -0.0294\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [898/5000] | Time: 0.24s\n",
      "(Training) Loss: 1186048.8566\n",
      "(Validation) Loss: 1222060.6425, MAE: 4570.4453, R2: -0.0292\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [899/5000] | Time: 0.21s\n",
      "(Training) Loss: 1203317.0152\n",
      "(Validation) Loss: 1221814.6235, MAE: 4566.3989, R2: -0.0290\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [900/5000] | Time: 0.27s\n",
      "(Training) Loss: 1175782.9308\n",
      "(Validation) Loss: 1221571.1086, MAE: 4564.3008, R2: -0.0288\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [901/5000] | Time: 0.24s\n",
      "(Training) Loss: 1181394.7335\n",
      "(Validation) Loss: 1221334.6844, MAE: 4564.0991, R2: -0.0286\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [902/5000] | Time: 0.29s\n",
      "(Training) Loss: 1173970.5533\n",
      "(Validation) Loss: 1221097.1429, MAE: 4562.6299, R2: -0.0284\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [903/5000] | Time: 0.31s\n",
      "(Training) Loss: 1169836.2449\n",
      "(Validation) Loss: 1220862.9029, MAE: 4562.8413, R2: -0.0282\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [904/5000] | Time: 0.24s\n",
      "(Training) Loss: 1174720.8058\n",
      "(Validation) Loss: 1220625.3663, MAE: 4561.1094, R2: -0.0280\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [905/5000] | Time: 0.23s\n",
      "(Training) Loss: 1178602.8122\n",
      "(Validation) Loss: 1220393.2444, MAE: 4561.0278, R2: -0.0278\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [906/5000] | Time: 0.24s\n",
      "(Training) Loss: 1190221.9898\n",
      "(Validation) Loss: 1220157.4654, MAE: 4560.6177, R2: -0.0276\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [907/5000] | Time: 0.23s\n",
      "(Training) Loss: 1199014.7037\n",
      "(Validation) Loss: 1219918.1359, MAE: 4559.3643, R2: -0.0274\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [908/5000] | Time: 0.26s\n",
      "(Training) Loss: 1170221.0133\n",
      "(Validation) Loss: 1219676.8305, MAE: 4559.6045, R2: -0.0272\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [909/5000] | Time: 0.24s\n",
      "(Training) Loss: 1172873.6129\n",
      "(Validation) Loss: 1219442.2248, MAE: 4557.6284, R2: -0.0270\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [910/5000] | Time: 0.30s\n",
      "(Training) Loss: 1182539.7519\n",
      "(Validation) Loss: 1219214.6540, MAE: 4562.0229, R2: -0.0268\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [911/5000] | Time: 0.32s\n",
      "(Training) Loss: 1209288.8452\n",
      "(Validation) Loss: 1218976.4876, MAE: 4559.8081, R2: -0.0266\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [912/5000] | Time: 0.50s\n",
      "(Training) Loss: 1178392.9734\n",
      "(Validation) Loss: 1218728.1727, MAE: 4556.1465, R2: -0.0264\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [913/5000] | Time: 0.28s\n",
      "(Training) Loss: 1177505.4232\n",
      "(Validation) Loss: 1218490.4432, MAE: 4553.7554, R2: -0.0262\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [914/5000] | Time: 0.25s\n",
      "(Training) Loss: 1166271.3261\n",
      "(Validation) Loss: 1218255.6089, MAE: 4552.9678, R2: -0.0260\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [915/5000] | Time: 0.21s\n",
      "(Training) Loss: 1167197.4416\n",
      "(Validation) Loss: 1218018.4940, MAE: 4552.2705, R2: -0.0258\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [916/5000] | Time: 0.27s\n",
      "(Training) Loss: 1163585.5044\n",
      "(Validation) Loss: 1217788.0279, MAE: 4552.7119, R2: -0.0256\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [917/5000] | Time: 0.32s\n",
      "(Training) Loss: 1168407.7037\n",
      "(Validation) Loss: 1217554.3670, MAE: 4553.0654, R2: -0.0254\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [918/5000] | Time: 0.22s\n",
      "(Training) Loss: 1186528.6440\n",
      "(Validation) Loss: 1217311.2229, MAE: 4549.7754, R2: -0.0252\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [919/5000] | Time: 0.22s\n",
      "(Training) Loss: 1185483.1478\n",
      "(Validation) Loss: 1217081.8387, MAE: 4551.7197, R2: -0.0250\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [920/5000] | Time: 0.25s\n",
      "(Training) Loss: 1203022.2297\n",
      "(Validation) Loss: 1216838.0140, MAE: 4548.2646, R2: -0.0248\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [921/5000] | Time: 0.21s\n",
      "(Training) Loss: 1173833.4372\n",
      "(Validation) Loss: 1216598.0394, MAE: 4547.4937, R2: -0.0246\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [922/5000] | Time: 0.23s\n",
      "(Training) Loss: 1180937.2735\n",
      "(Validation) Loss: 1216363.7740, MAE: 4546.2773, R2: -0.0244\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [923/5000] | Time: 0.23s\n",
      "(Training) Loss: 1167422.4435\n",
      "(Validation) Loss: 1216124.6425, MAE: 4544.5396, R2: -0.0242\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [924/5000] | Time: 0.19s\n",
      "(Training) Loss: 1168112.0425\n",
      "(Validation) Loss: 1215892.7340, MAE: 4544.0913, R2: -0.0240\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [925/5000] | Time: 0.18s\n",
      "(Training) Loss: 1158871.9757\n",
      "(Validation) Loss: 1215656.8483, MAE: 4544.6357, R2: -0.0238\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [926/5000] | Time: 0.22s\n",
      "(Training) Loss: 1166929.1650\n",
      "(Validation) Loss: 1215424.9803, MAE: 4542.8643, R2: -0.0236\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [927/5000] | Time: 0.31s\n",
      "(Training) Loss: 1159222.6580\n",
      "(Validation) Loss: 1215188.6273, MAE: 4541.8599, R2: -0.0234\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [928/5000] | Time: 0.22s\n",
      "(Training) Loss: 1166989.0799\n",
      "(Validation) Loss: 1214966.6692, MAE: 4547.6313, R2: -0.0233\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [929/5000] | Time: 0.26s\n",
      "(Training) Loss: 1175213.5406\n",
      "(Validation) Loss: 1214721.7829, MAE: 4541.1182, R2: -0.0230\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [930/5000] | Time: 0.24s\n",
      "(Training) Loss: 1159418.6060\n",
      "(Validation) Loss: 1214489.5238, MAE: 4542.3237, R2: -0.0229\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [931/5000] | Time: 0.20s\n",
      "(Training) Loss: 1163969.9930\n",
      "(Validation) Loss: 1214248.8635, MAE: 4538.8662, R2: -0.0227\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [932/5000] | Time: 0.20s\n",
      "(Training) Loss: 1179878.6294\n",
      "(Validation) Loss: 1214014.4965, MAE: 4538.4854, R2: -0.0225\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [933/5000] | Time: 0.24s\n",
      "(Training) Loss: 1163589.7373\n",
      "(Validation) Loss: 1213777.9251, MAE: 4537.2583, R2: -0.0223\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [934/5000] | Time: 0.20s\n",
      "(Training) Loss: 1168620.8109\n",
      "(Validation) Loss: 1213546.1994, MAE: 4537.2935, R2: -0.0221\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [935/5000] | Time: 0.25s\n",
      "(Training) Loss: 1176019.5438\n",
      "(Validation) Loss: 1213313.9759, MAE: 4536.7979, R2: -0.0219\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [936/5000] | Time: 0.30s\n",
      "(Training) Loss: 1196437.9480\n",
      "(Validation) Loss: 1213075.1848, MAE: 4535.2939, R2: -0.0217\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [937/5000] | Time: 0.26s\n",
      "(Training) Loss: 1163680.2284\n",
      "(Validation) Loss: 1212845.4705, MAE: 4538.1162, R2: -0.0215\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [938/5000] | Time: 0.28s\n",
      "(Training) Loss: 1175342.0317\n",
      "(Validation) Loss: 1212601.3511, MAE: 4533.9741, R2: -0.0213\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [939/5000] | Time: 0.22s\n",
      "(Training) Loss: 1171646.1155\n",
      "(Validation) Loss: 1212360.4724, MAE: 4532.2554, R2: -0.0211\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [940/5000] | Time: 0.18s\n",
      "(Training) Loss: 1174634.6028\n",
      "(Validation) Loss: 1212128.3048, MAE: 4532.3984, R2: -0.0209\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [941/5000] | Time: 0.19s\n",
      "(Training) Loss: 1183568.5685\n",
      "(Validation) Loss: 1211893.8159, MAE: 4531.9282, R2: -0.0207\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [942/5000] | Time: 0.20s\n",
      "(Training) Loss: 1175493.6053\n",
      "(Validation) Loss: 1211652.9270, MAE: 4528.7539, R2: -0.0205\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [943/5000] | Time: 0.31s\n",
      "(Training) Loss: 1174830.1472\n",
      "(Validation) Loss: 1211416.6146, MAE: 4528.2935, R2: -0.0203\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [944/5000] | Time: 0.24s\n",
      "(Training) Loss: 1169569.5990\n",
      "(Validation) Loss: 1211180.2260, MAE: 4527.4829, R2: -0.0201\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [945/5000] | Time: 0.21s\n",
      "(Training) Loss: 1175433.1567\n",
      "(Validation) Loss: 1210948.2768, MAE: 4529.0796, R2: -0.0199\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [946/5000] | Time: 0.20s\n",
      "(Training) Loss: 1178058.4581\n",
      "(Validation) Loss: 1210733.3689, MAE: 4535.9316, R2: -0.0197\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [947/5000] | Time: 0.22s\n",
      "(Training) Loss: 1177691.7906\n",
      "(Validation) Loss: 1210475.0425, MAE: 4527.0728, R2: -0.0195\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [948/5000] | Time: 0.21s\n",
      "(Training) Loss: 1166872.0901\n",
      "(Validation) Loss: 1210242.0622, MAE: 4525.8623, R2: -0.0193\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [949/5000] | Time: 0.21s\n",
      "(Training) Loss: 1163547.2481\n",
      "(Validation) Loss: 1210010.2044, MAE: 4526.4155, R2: -0.0191\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [950/5000] | Time: 0.23s\n",
      "(Training) Loss: 1190835.1878\n",
      "(Validation) Loss: 1209784.7416, MAE: 4528.3403, R2: -0.0189\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [951/5000] | Time: 0.22s\n",
      "(Training) Loss: 1155682.5673\n",
      "(Validation) Loss: 1209528.9651, MAE: 4523.1274, R2: -0.0187\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [952/5000] | Time: 0.22s\n",
      "(Training) Loss: 1167363.9023\n",
      "(Validation) Loss: 1209296.2083, MAE: 4521.3008, R2: -0.0185\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [953/5000] | Time: 0.21s\n",
      "(Training) Loss: 1179545.8947\n",
      "(Validation) Loss: 1209058.1333, MAE: 4519.2012, R2: -0.0183\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [954/5000] | Time: 0.21s\n",
      "(Training) Loss: 1167565.6015\n",
      "(Validation) Loss: 1208824.5740, MAE: 4518.3784, R2: -0.0181\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [955/5000] | Time: 0.24s\n",
      "(Training) Loss: 1159531.7976\n",
      "(Validation) Loss: 1208591.4768, MAE: 4519.2202, R2: -0.0179\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [956/5000] | Time: 0.21s\n",
      "(Training) Loss: 1169483.7893\n",
      "(Validation) Loss: 1208360.9752, MAE: 4519.6006, R2: -0.0177\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [957/5000] | Time: 0.26s\n",
      "(Training) Loss: 1161348.0844\n",
      "(Validation) Loss: 1208127.1517, MAE: 4519.0566, R2: -0.0176\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [958/5000] | Time: 0.21s\n",
      "(Training) Loss: 1173074.1434\n",
      "(Validation) Loss: 1207893.5568, MAE: 4516.3525, R2: -0.0174\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [959/5000] | Time: 0.20s\n",
      "(Training) Loss: 1159875.1827\n",
      "(Validation) Loss: 1207681.9962, MAE: 4518.3643, R2: -0.0172\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [960/5000] | Time: 0.18s\n",
      "(Training) Loss: 1168113.0076\n",
      "(Validation) Loss: 1207419.5759, MAE: 4515.4624, R2: -0.0170\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [961/5000] | Time: 0.18s\n",
      "(Training) Loss: 1170603.3096\n",
      "(Validation) Loss: 1207185.1022, MAE: 4513.2798, R2: -0.0168\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [962/5000] | Time: 0.19s\n",
      "(Training) Loss: 1171016.1986\n",
      "(Validation) Loss: 1206947.4286, MAE: 4511.8770, R2: -0.0166\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [963/5000] | Time: 0.20s\n",
      "(Training) Loss: 1180656.6269\n",
      "(Validation) Loss: 1206791.1416, MAE: 4517.5278, R2: -0.0164\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [964/5000] | Time: 0.20s\n",
      "(Training) Loss: 1169232.4036\n",
      "(Validation) Loss: 1206481.8032, MAE: 4512.4790, R2: -0.0162\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [965/5000] | Time: 0.23s\n",
      "(Training) Loss: 1170789.9442\n",
      "(Validation) Loss: 1206247.4362, MAE: 4511.8247, R2: -0.0160\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [966/5000] | Time: 0.33s\n",
      "(Training) Loss: 1162186.8528\n",
      "(Validation) Loss: 1206015.6698, MAE: 4510.5186, R2: -0.0158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [967/5000] | Time: 0.23s\n",
      "(Training) Loss: 1156580.0888\n",
      "(Validation) Loss: 1205772.4190, MAE: 4507.5640, R2: -0.0156\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [968/5000] | Time: 0.24s\n",
      "(Training) Loss: 1160752.1732\n",
      "(Validation) Loss: 1205539.5759, MAE: 4507.4692, R2: -0.0154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [969/5000] | Time: 0.21s\n",
      "(Training) Loss: 1175602.9365\n",
      "(Validation) Loss: 1205316.3276, MAE: 4508.4771, R2: -0.0152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [970/5000] | Time: 0.19s\n",
      "(Training) Loss: 1166598.1923\n",
      "(Validation) Loss: 1205077.0895, MAE: 4507.4019, R2: -0.0150\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [971/5000] | Time: 0.18s\n",
      "(Training) Loss: 1164960.6834\n",
      "(Validation) Loss: 1204843.7740, MAE: 4507.0449, R2: -0.0148\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [972/5000] | Time: 0.19s\n",
      "(Training) Loss: 1166622.2602\n",
      "(Validation) Loss: 1204603.8552, MAE: 4503.7837, R2: -0.0146\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [973/5000] | Time: 0.20s\n",
      "(Training) Loss: 1168092.2849\n",
      "(Validation) Loss: 1204375.5022, MAE: 4505.0991, R2: -0.0144\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [974/5000] | Time: 0.20s\n",
      "(Training) Loss: 1169361.1701\n",
      "(Validation) Loss: 1204135.4260, MAE: 4504.3022, R2: -0.0142\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [975/5000] | Time: 0.21s\n",
      "(Training) Loss: 1166642.7786\n",
      "(Validation) Loss: 1203920.4521, MAE: 4503.9341, R2: -0.0141\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [976/5000] | Time: 0.19s\n",
      "(Training) Loss: 1155558.3610\n",
      "(Validation) Loss: 1203663.7765, MAE: 4500.7036, R2: -0.0138\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [977/5000] | Time: 0.19s\n",
      "(Training) Loss: 1159622.1701\n",
      "(Validation) Loss: 1203434.3060, MAE: 4499.8560, R2: -0.0136\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [978/5000] | Time: 0.34s\n",
      "(Training) Loss: 1146089.5356\n",
      "(Validation) Loss: 1203200.5587, MAE: 4498.5850, R2: -0.0135\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [979/5000] | Time: 0.28s\n",
      "(Training) Loss: 1150625.3813\n",
      "(Validation) Loss: 1202970.3365, MAE: 4498.2656, R2: -0.0133\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [980/5000] | Time: 0.23s\n",
      "(Training) Loss: 1160912.8566\n",
      "(Validation) Loss: 1202747.2660, MAE: 4498.4805, R2: -0.0131\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [981/5000] | Time: 0.25s\n",
      "(Training) Loss: 1168654.5241\n",
      "(Validation) Loss: 1202517.3841, MAE: 4501.1318, R2: -0.0129\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [982/5000] | Time: 0.30s\n",
      "(Training) Loss: 1159877.9721\n",
      "(Validation) Loss: 1202275.4997, MAE: 4498.2114, R2: -0.0127\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [983/5000] | Time: 0.26s\n",
      "(Training) Loss: 1173845.0914\n",
      "(Validation) Loss: 1202036.4749, MAE: 4494.1831, R2: -0.0125\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [984/5000] | Time: 0.24s\n",
      "(Training) Loss: 1159325.7957\n",
      "(Validation) Loss: 1201823.2381, MAE: 4495.3813, R2: -0.0123\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [985/5000] | Time: 0.25s\n",
      "(Training) Loss: 1176642.3414\n",
      "(Validation) Loss: 1201570.2857, MAE: 4494.5586, R2: -0.0121\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [986/5000] | Time: 0.45s\n",
      "(Training) Loss: 1145264.2443\n",
      "(Validation) Loss: 1201335.0806, MAE: 4492.8608, R2: -0.0119\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [987/5000] | Time: 0.44s\n",
      "(Training) Loss: 1171398.4562\n",
      "(Validation) Loss: 1201110.0597, MAE: 4493.1797, R2: -0.0117\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [988/5000] | Time: 0.87s\n",
      "(Training) Loss: 1153087.5742\n",
      "(Validation) Loss: 1200869.3892, MAE: 4492.3394, R2: -0.0115\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [989/5000] | Time: 1.12s\n",
      "(Training) Loss: 1175492.2957\n",
      "(Validation) Loss: 1200637.7295, MAE: 4490.4570, R2: -0.0113\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [990/5000] | Time: 0.95s\n",
      "(Training) Loss: 1157271.9803\n",
      "(Validation) Loss: 1200406.6692, MAE: 4491.8379, R2: -0.0111\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [991/5000] | Time: 0.91s\n",
      "(Training) Loss: 1156774.6516\n",
      "(Validation) Loss: 1200168.0254, MAE: 4488.2363, R2: -0.0109\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [992/5000] | Time: 0.63s\n",
      "(Training) Loss: 1175886.1345\n",
      "(Validation) Loss: 1200009.7727, MAE: 4490.7041, R2: -0.0108\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [993/5000] | Time: 0.70s\n",
      "(Training) Loss: 1161261.7297\n",
      "(Validation) Loss: 1199704.5232, MAE: 4487.5435, R2: -0.0105\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [994/5000] | Time: 0.33s\n",
      "(Training) Loss: 1160963.5197\n",
      "(Validation) Loss: 1199464.8889, MAE: 4485.5874, R2: -0.0103\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [995/5000] | Time: 0.32s\n",
      "(Training) Loss: 1156477.8071\n",
      "(Validation) Loss: 1199229.4857, MAE: 4484.1846, R2: -0.0101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [996/5000] | Time: 0.33s\n",
      "(Training) Loss: 1155565.2608\n",
      "(Validation) Loss: 1198995.9924, MAE: 4482.6968, R2: -0.0099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [997/5000] | Time: 0.36s\n",
      "(Training) Loss: 1179353.3864\n",
      "(Validation) Loss: 1198768.4317, MAE: 4483.5093, R2: -0.0098\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [998/5000] | Time: 0.30s\n",
      "(Training) Loss: 1161402.7354\n",
      "(Validation) Loss: 1198527.8781, MAE: 4481.7817, R2: -0.0096\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [999/5000] | Time: 0.65s\n",
      "(Training) Loss: 1183022.1973\n",
      "(Validation) Loss: 1198298.7835, MAE: 4481.1519, R2: -0.0094\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1000/5000] | Time: 0.92s\n",
      "(Training) Loss: 1150830.3579\n",
      "(Validation) Loss: 1198060.6730, MAE: 4481.4712, R2: -0.0092\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch1000.pth\n",
      "==========================================================================================\n",
      "Epoch [1001/5000] | Time: 0.79s\n",
      "(Training) Loss: 1164630.0203\n",
      "(Validation) Loss: 1197835.3575, MAE: 4480.6479, R2: -0.0090\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1002/5000] | Time: 0.46s\n",
      "(Training) Loss: 1160751.9404\n",
      "(Validation) Loss: 1197645.7041, MAE: 4488.6714, R2: -0.0088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1003/5000] | Time: 0.37s\n",
      "(Training) Loss: 1149308.9365\n",
      "(Validation) Loss: 1197363.0375, MAE: 4478.0967, R2: -0.0086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1004/5000] | Time: 0.38s\n",
      "(Training) Loss: 1149539.1383\n",
      "(Validation) Loss: 1197134.3187, MAE: 4477.4673, R2: -0.0084\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1005/5000] | Time: 0.48s\n",
      "(Training) Loss: 1140461.9725\n",
      "(Validation) Loss: 1196907.2457, MAE: 4477.4595, R2: -0.0082\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1006/5000] | Time: 0.32s\n",
      "(Training) Loss: 1168103.5146\n",
      "(Validation) Loss: 1200363.4438, MAE: 4490.9111, R2: -0.0111\n",
      "==========================================================================================\n",
      "Epoch [1007/5000] | Time: 0.49s\n",
      "(Training) Loss: 1153238.5241\n",
      "(Validation) Loss: 1200136.1270, MAE: 4489.2637, R2: -0.0109\n",
      "==========================================================================================\n",
      "Epoch [1008/5000] | Time: 0.97s\n",
      "(Training) Loss: 1154387.0355\n",
      "(Validation) Loss: 1199898.5295, MAE: 4487.5811, R2: -0.0107\n",
      "==========================================================================================\n",
      "Epoch [1009/5000] | Time: 0.35s\n",
      "(Training) Loss: 1157271.4213\n",
      "(Validation) Loss: 1199672.7111, MAE: 4489.5557, R2: -0.0105\n",
      "==========================================================================================\n",
      "Epoch [1010/5000] | Time: 1.03s\n",
      "(Training) Loss: 1184354.4734\n",
      "(Validation) Loss: 1199435.4133, MAE: 4484.3711, R2: -0.0103\n",
      "==========================================================================================\n",
      "Epoch [1011/5000] | Time: 0.93s\n",
      "(Training) Loss: 1142836.5600\n",
      "(Validation) Loss: 1199219.3981, MAE: 4489.8389, R2: -0.0101\n",
      "==========================================================================================\n",
      "Epoch [1012/5000] | Time: 0.56s\n",
      "(Training) Loss: 1151714.8046\n",
      "(Validation) Loss: 1198993.8997, MAE: 4490.0400, R2: -0.0099\n",
      "==========================================================================================\n",
      "Epoch [1013/5000] | Time: 0.89s\n",
      "(Training) Loss: 1161213.7728\n",
      "(Validation) Loss: 1199096.7467, MAE: 4486.5361, R2: -0.0101\n",
      "==========================================================================================\n",
      "Epoch [1014/5000] | Time: 0.27s\n",
      "(Training) Loss: 1164453.7348\n",
      "(Validation) Loss: 1198520.9702, MAE: 4482.5522, R2: -0.0096\n",
      "==========================================================================================\n",
      "Epoch [1015/5000] | Time: 0.27s\n",
      "(Training) Loss: 1141696.3107\n",
      "(Validation) Loss: 1198287.7968, MAE: 4480.1328, R2: -0.0094\n",
      "==========================================================================================\n",
      "Epoch [1016/5000] | Time: 0.24s\n",
      "(Training) Loss: 1149276.6307\n",
      "(Validation) Loss: 1198069.1352, MAE: 4482.4150, R2: -0.0092\n",
      "==========================================================================================\n",
      "Epoch [1017/5000] | Time: 0.23s\n",
      "(Training) Loss: 1146237.4575\n",
      "(Validation) Loss: 1197835.8451, MAE: 4480.7471, R2: -0.0090\n",
      "==========================================================================================\n",
      "Epoch [1018/5000] | Time: 0.24s\n",
      "(Training) Loss: 1148070.7418\n",
      "(Validation) Loss: 1197621.7854, MAE: 4480.3291, R2: -0.0088\n",
      "==========================================================================================\n",
      "Epoch [1019/5000] | Time: 0.25s\n",
      "(Training) Loss: 1147647.6091\n",
      "(Validation) Loss: 1197390.6590, MAE: 4478.5259, R2: -0.0086\n",
      "==========================================================================================\n",
      "Epoch [1020/5000] | Time: 0.21s\n",
      "(Training) Loss: 1146887.4429\n",
      "(Validation) Loss: 1197150.1054, MAE: 4476.3979, R2: -0.0084\n",
      "==========================================================================================\n",
      "Epoch [1021/5000] | Time: 0.24s\n",
      "(Training) Loss: 1159796.8306\n",
      "(Validation) Loss: 1196921.6457, MAE: 4476.6221, R2: -0.0082\n",
      "==========================================================================================\n",
      "Epoch [1022/5000] | Time: 0.24s\n",
      "(Training) Loss: 1141486.2484\n",
      "(Validation) Loss: 1196692.2006, MAE: 4478.0483, R2: -0.0080\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1023/5000] | Time: 0.20s\n",
      "(Training) Loss: 1164029.6409\n",
      "(Validation) Loss: 1196473.4019, MAE: 4479.2881, R2: -0.0078\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1024/5000] | Time: 0.22s\n",
      "(Training) Loss: 1140323.5462\n",
      "(Validation) Loss: 1196236.6832, MAE: 4476.2476, R2: -0.0077\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1025/5000] | Time: 0.22s\n",
      "(Training) Loss: 1153858.2525\n",
      "(Validation) Loss: 1196013.2724, MAE: 4474.0264, R2: -0.0075\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1026/5000] | Time: 0.24s\n",
      "(Training) Loss: 1158324.3867\n",
      "(Validation) Loss: 1195783.1619, MAE: 4474.7100, R2: -0.0073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1027/5000] | Time: 0.26s\n",
      "(Training) Loss: 1163913.4156\n",
      "(Validation) Loss: 1195546.5752, MAE: 4471.9976, R2: -0.0071\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1028/5000] | Time: 0.30s\n",
      "(Training) Loss: 1160505.9334\n",
      "(Validation) Loss: 1195319.1568, MAE: 4472.1494, R2: -0.0069\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1029/5000] | Time: 0.24s\n",
      "(Training) Loss: 1151294.1720\n",
      "(Validation) Loss: 1195084.0279, MAE: 4469.2915, R2: -0.0067\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1030/5000] | Time: 0.21s\n",
      "(Training) Loss: 1145224.9898\n",
      "(Validation) Loss: 1194859.0527, MAE: 4470.5132, R2: -0.0065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1031/5000] | Time: 0.23s\n",
      "(Training) Loss: 1146350.3052\n",
      "(Validation) Loss: 1194638.3492, MAE: 4471.4170, R2: -0.0063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1032/5000] | Time: 0.20s\n",
      "(Training) Loss: 1148775.5882\n",
      "(Validation) Loss: 1194401.8387, MAE: 4466.9316, R2: -0.0061\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1033/5000] | Time: 0.25s\n",
      "(Training) Loss: 1166037.1510\n",
      "(Validation) Loss: 1194190.7657, MAE: 4470.8931, R2: -0.0059\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1034/5000] | Time: 0.26s\n",
      "(Training) Loss: 1168422.9410\n",
      "(Validation) Loss: 1193941.2114, MAE: 4464.9834, R2: -0.0057\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1035/5000] | Time: 0.24s\n",
      "(Training) Loss: 1150000.3477\n",
      "(Validation) Loss: 1193712.2641, MAE: 4464.4717, R2: -0.0055\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1036/5000] | Time: 0.22s\n",
      "(Training) Loss: 1144742.8921\n",
      "(Validation) Loss: 1193496.4521, MAE: 4466.5259, R2: -0.0054\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1037/5000] | Time: 0.23s\n",
      "(Training) Loss: 1147775.7951\n",
      "(Validation) Loss: 1193315.9060, MAE: 4467.4487, R2: -0.0052\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1038/5000] | Time: 0.23s\n",
      "(Training) Loss: 1160413.5324\n",
      "(Validation) Loss: 1193035.1492, MAE: 4463.2734, R2: -0.0050\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1039/5000] | Time: 0.23s\n",
      "(Training) Loss: 1157094.3274\n",
      "(Validation) Loss: 1192803.2559, MAE: 4462.5605, R2: -0.0048\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1040/5000] | Time: 0.23s\n",
      "(Training) Loss: 1158835.0292\n",
      "(Validation) Loss: 1192588.7594, MAE: 4464.3271, R2: -0.0046\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1041/5000] | Time: 0.21s\n",
      "(Training) Loss: 1141263.9721\n",
      "(Validation) Loss: 1192347.9721, MAE: 4460.9326, R2: -0.0044\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1042/5000] | Time: 0.22s\n",
      "(Training) Loss: 1153408.4162\n",
      "(Validation) Loss: 1192135.1873, MAE: 4460.0649, R2: -0.0042\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1043/5000] | Time: 0.19s\n",
      "(Training) Loss: 1153797.3471\n",
      "(Validation) Loss: 1191892.6984, MAE: 4459.6128, R2: -0.0040\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1044/5000] | Time: 0.25s\n",
      "(Training) Loss: 1145589.8268\n",
      "(Validation) Loss: 1191657.9251, MAE: 4458.1323, R2: -0.0038\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1045/5000] | Time: 0.30s\n",
      "(Training) Loss: 1164623.5336\n",
      "(Validation) Loss: 1191447.2584, MAE: 4462.4858, R2: -0.0037\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1046/5000] | Time: 0.26s\n",
      "(Training) Loss: 1157270.4645\n",
      "(Validation) Loss: 1191202.4229, MAE: 4456.8428, R2: -0.0035\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1047/5000] | Time: 0.30s\n",
      "(Training) Loss: 1154150.4505\n",
      "(Validation) Loss: 1190979.6165, MAE: 4456.2041, R2: -0.0033\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1048/5000] | Time: 0.25s\n",
      "(Training) Loss: 1144275.4607\n",
      "(Validation) Loss: 1190741.2317, MAE: 4453.1440, R2: -0.0031\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1049/5000] | Time: 0.26s\n",
      "(Training) Loss: 1155189.6713\n",
      "(Validation) Loss: 1190514.6514, MAE: 4453.0498, R2: -0.0029\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1050/5000] | Time: 0.29s\n",
      "(Training) Loss: 1164301.0235\n",
      "(Validation) Loss: 1190307.2457, MAE: 4455.2886, R2: -0.0027\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1051/5000] | Time: 0.35s\n",
      "(Training) Loss: 1136561.7199\n",
      "(Validation) Loss: 1190074.2197, MAE: 4458.0195, R2: -0.0025\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1052/5000] | Time: 0.37s\n",
      "(Training) Loss: 1148137.0866\n",
      "(Validation) Loss: 1189831.8019, MAE: 4450.8164, R2: -0.0023\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1053/5000] | Time: 0.41s\n",
      "(Training) Loss: 1149459.9188\n",
      "(Validation) Loss: 1189607.2279, MAE: 4451.6821, R2: -0.0021\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1054/5000] | Time: 0.50s\n",
      "(Training) Loss: 1168413.7081\n",
      "(Validation) Loss: 1189384.0152, MAE: 4450.2173, R2: -0.0019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1055/5000] | Time: 0.49s\n",
      "(Training) Loss: 1148253.0901\n",
      "(Validation) Loss: 1189151.7410, MAE: 4449.3071, R2: -0.0017\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1056/5000] | Time: 0.53s\n",
      "(Training) Loss: 1149251.9867\n",
      "(Validation) Loss: 1188925.9683, MAE: 4449.4956, R2: -0.0016\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1057/5000] | Time: 0.48s\n",
      "(Training) Loss: 1153550.4632\n",
      "(Validation) Loss: 1188690.6057, MAE: 4446.9810, R2: -0.0014\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1058/5000] | Time: 0.33s\n",
      "(Training) Loss: 1154271.3880\n",
      "(Validation) Loss: 1188461.2978, MAE: 4445.0938, R2: -0.0012\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1059/5000] | Time: 0.28s\n",
      "(Training) Loss: 1160586.3731\n",
      "(Validation) Loss: 1188236.7289, MAE: 4445.0972, R2: -0.0010\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1060/5000] | Time: 0.30s\n",
      "(Training) Loss: 1172259.4055\n",
      "(Validation) Loss: 1188006.3086, MAE: 4443.6206, R2: -0.0008\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1061/5000] | Time: 0.38s\n",
      "(Training) Loss: 1164397.7449\n",
      "(Validation) Loss: 1187777.5340, MAE: 4443.3403, R2: -0.0006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1062/5000] | Time: 0.33s\n",
      "(Training) Loss: 1136599.6808\n",
      "(Validation) Loss: 1187547.2203, MAE: 4442.8359, R2: -0.0004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1063/5000] | Time: 0.31s\n",
      "(Training) Loss: 1144257.5133\n",
      "(Validation) Loss: 1187346.6514, MAE: 4444.0073, R2: -0.0002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1064/5000] | Time: 0.27s\n",
      "(Training) Loss: 1141325.4569\n",
      "(Validation) Loss: 1194820.9829, MAE: 4470.2769, R2: -0.0065\n",
      "==========================================================================================\n",
      "Epoch [1065/5000] | Time: 0.32s\n",
      "(Training) Loss: 1158512.4784\n",
      "(Validation) Loss: 1194604.6070, MAE: 4472.4873, R2: -0.0063\n",
      "==========================================================================================\n",
      "Epoch [1066/5000] | Time: 0.30s\n",
      "(Training) Loss: 1153420.7240\n",
      "(Validation) Loss: 1194361.4883, MAE: 4466.8730, R2: -0.0061\n",
      "==========================================================================================\n",
      "Epoch [1067/5000] | Time: 0.31s\n",
      "(Training) Loss: 1138664.7510\n",
      "(Validation) Loss: 1194132.5968, MAE: 4466.6035, R2: -0.0059\n",
      "==========================================================================================\n",
      "Epoch [1068/5000] | Time: 0.32s\n",
      "(Training) Loss: 1162802.6104\n",
      "(Validation) Loss: 1193911.0095, MAE: 4467.3467, R2: -0.0057\n",
      "==========================================================================================\n",
      "Epoch [1069/5000] | Time: 0.36s\n",
      "(Training) Loss: 1149046.3033\n",
      "(Validation) Loss: 1193683.0984, MAE: 4466.6895, R2: -0.0055\n",
      "==========================================================================================\n",
      "Epoch [1070/5000] | Time: 0.29s\n",
      "(Training) Loss: 1147966.3750\n",
      "(Validation) Loss: 1193447.1162, MAE: 4464.5381, R2: -0.0053\n",
      "==========================================================================================\n",
      "Epoch [1071/5000] | Time: 0.28s\n",
      "(Training) Loss: 1164111.0406\n",
      "(Validation) Loss: 1193215.4463, MAE: 4462.9575, R2: -0.0051\n",
      "==========================================================================================\n",
      "Epoch [1072/5000] | Time: 0.33s\n",
      "(Training) Loss: 1138467.1872\n",
      "(Validation) Loss: 1192990.7149, MAE: 4463.0000, R2: -0.0049\n",
      "==========================================================================================\n",
      "Epoch [1073/5000] | Time: 0.34s\n",
      "(Training) Loss: 1147975.2646\n",
      "(Validation) Loss: 1192766.0800, MAE: 4462.2803, R2: -0.0048\n",
      "==========================================================================================\n",
      "Epoch [1074/5000] | Time: 0.40s\n",
      "(Training) Loss: 1149029.9708\n",
      "(Validation) Loss: 1192536.8787, MAE: 4462.8345, R2: -0.0046\n",
      "==========================================================================================\n",
      "Epoch [1075/5000] | Time: 0.45s\n",
      "(Training) Loss: 1162293.1789\n",
      "(Validation) Loss: 1192305.9200, MAE: 4460.4233, R2: -0.0044\n",
      "==========================================================================================\n",
      "Epoch [1076/5000] | Time: 0.32s\n",
      "(Training) Loss: 1174142.7030\n",
      "(Validation) Loss: 1192075.6368, MAE: 4460.1826, R2: -0.0042\n",
      "==========================================================================================\n",
      "Epoch [1077/5000] | Time: 0.30s\n",
      "(Training) Loss: 1145312.7684\n",
      "(Validation) Loss: 1191847.1771, MAE: 4459.7627, R2: -0.0040\n",
      "==========================================================================================\n",
      "Epoch [1078/5000] | Time: 0.32s\n",
      "(Training) Loss: 1138771.9692\n",
      "(Validation) Loss: 1191613.8667, MAE: 4457.1318, R2: -0.0038\n",
      "==========================================================================================\n",
      "Epoch [1079/5000] | Time: 0.31s\n",
      "(Training) Loss: 1156206.1485\n",
      "(Validation) Loss: 1191384.7416, MAE: 4456.9912, R2: -0.0036\n",
      "==========================================================================================\n",
      "Epoch [1080/5000] | Time: 0.29s\n",
      "(Training) Loss: 1160548.2189\n",
      "(Validation) Loss: 1191174.4914, MAE: 4458.7188, R2: -0.0034\n",
      "==========================================================================================\n",
      "Epoch [1081/5000] | Time: 0.27s\n",
      "(Training) Loss: 1162770.6440\n",
      "(Validation) Loss: 1190934.7759, MAE: 4456.6182, R2: -0.0032\n",
      "==========================================================================================\n",
      "Epoch [1082/5000] | Time: 0.29s\n",
      "(Training) Loss: 1148012.9340\n",
      "(Validation) Loss: 1190696.9092, MAE: 4453.6914, R2: -0.0030\n",
      "==========================================================================================\n",
      "Epoch [1083/5000] | Time: 0.31s\n",
      "(Training) Loss: 1142893.2157\n",
      "(Validation) Loss: 1190476.9473, MAE: 4455.5356, R2: -0.0029\n",
      "==========================================================================================\n",
      "Epoch [1084/5000] | Time: 0.29s\n",
      "(Training) Loss: 1157221.6364\n",
      "(Validation) Loss: 1190246.8368, MAE: 4453.8652, R2: -0.0027\n",
      "==========================================================================================\n",
      "Epoch [1085/5000] | Time: 0.29s\n",
      "(Training) Loss: 1141979.8014\n",
      "(Validation) Loss: 1190014.9638, MAE: 4451.4946, R2: -0.0025\n",
      "==========================================================================================\n",
      "Epoch [1086/5000] | Time: 0.28s\n",
      "(Training) Loss: 1144483.3820\n",
      "(Validation) Loss: 1189805.9733, MAE: 4455.9141, R2: -0.0023\n",
      "==========================================================================================\n",
      "Epoch [1087/5000] | Time: 0.29s\n",
      "(Training) Loss: 1135708.4029\n",
      "(Validation) Loss: 1189576.1270, MAE: 4450.9604, R2: -0.0021\n",
      "==========================================================================================\n",
      "Epoch [1088/5000] | Time: 0.27s\n",
      "(Training) Loss: 1149146.6003\n",
      "(Validation) Loss: 1189335.3346, MAE: 4449.7607, R2: -0.0019\n",
      "==========================================================================================\n",
      "Epoch [1089/5000] | Time: 0.28s\n",
      "(Training) Loss: 1162999.3598\n",
      "(Validation) Loss: 1189109.2775, MAE: 4450.6631, R2: -0.0017\n",
      "==========================================================================================\n",
      "Epoch [1090/5000] | Time: 0.28s\n",
      "(Training) Loss: 1161559.5292\n",
      "(Validation) Loss: 1188876.7390, MAE: 4447.6929, R2: -0.0015\n",
      "==========================================================================================\n",
      "Epoch [1091/5000] | Time: 0.24s\n",
      "(Training) Loss: 1143043.4175\n",
      "(Validation) Loss: 1188679.8425, MAE: 4451.8682, R2: -0.0014\n",
      "==========================================================================================\n",
      "Epoch [1092/5000] | Time: 0.24s\n",
      "(Training) Loss: 1153144.2386\n",
      "(Validation) Loss: 1188432.8635, MAE: 4450.2280, R2: -0.0011\n",
      "==========================================================================================\n",
      "Epoch [1093/5000] | Time: 0.23s\n",
      "(Training) Loss: 1159291.1586\n",
      "(Validation) Loss: 1188208.1575, MAE: 4451.2153, R2: -0.0010\n",
      "==========================================================================================\n",
      "Epoch [1094/5000] | Time: 0.30s\n",
      "(Training) Loss: 1159834.6282\n",
      "(Validation) Loss: 1187973.1403, MAE: 4448.2656, R2: -0.0008\n",
      "==========================================================================================\n",
      "Epoch [1095/5000] | Time: 0.28s\n",
      "(Training) Loss: 1160114.2576\n",
      "(Validation) Loss: 1187760.0254, MAE: 4448.9434, R2: -0.0006\n",
      "==========================================================================================\n",
      "Epoch [1096/5000] | Time: 0.23s\n",
      "(Training) Loss: 1163554.6942\n",
      "(Validation) Loss: 1187511.7613, MAE: 4444.3950, R2: -0.0004\n",
      "==========================================================================================\n",
      "Epoch [1097/5000] | Time: 0.22s\n",
      "(Training) Loss: 1146339.9086\n",
      "(Validation) Loss: 1187282.0267, MAE: 4444.0664, R2: -0.0002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1098/5000] | Time: 0.27s\n",
      "(Training) Loss: 1172155.0317\n",
      "(Validation) Loss: 1187054.0851, MAE: 4442.7344, R2: -0.0000\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1099/5000] | Time: 0.27s\n",
      "(Training) Loss: 1130758.3988\n",
      "(Validation) Loss: 1186831.1619, MAE: 4442.3428, R2: 0.0002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1100/5000] | Time: 0.24s\n",
      "(Training) Loss: 1142737.3959\n",
      "(Validation) Loss: 1186598.3492, MAE: 4440.1885, R2: 0.0004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1101/5000] | Time: 0.26s\n",
      "(Training) Loss: 1160560.2525\n",
      "(Validation) Loss: 1186371.7587, MAE: 4438.4517, R2: 0.0006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1102/5000] | Time: 0.27s\n",
      "(Training) Loss: 1142838.1294\n",
      "(Validation) Loss: 1186151.1873, MAE: 4442.8301, R2: 0.0008\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1103/5000] | Time: 0.24s\n",
      "(Training) Loss: 1148291.9137\n",
      "(Validation) Loss: 1185918.1917, MAE: 4437.0835, R2: 0.0009\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1104/5000] | Time: 0.27s\n",
      "(Training) Loss: 1165723.2855\n",
      "(Validation) Loss: 1185693.1860, MAE: 4437.4038, R2: 0.0011\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1105/5000] | Time: 0.25s\n",
      "(Training) Loss: 1155576.4860\n",
      "(Validation) Loss: 1185464.3962, MAE: 4436.7134, R2: 0.0013\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1106/5000] | Time: 0.23s\n",
      "(Training) Loss: 1144632.8807\n",
      "(Validation) Loss: 1185234.3213, MAE: 4434.2808, R2: 0.0015\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1107/5000] | Time: 0.23s\n",
      "(Training) Loss: 1153981.7589\n",
      "(Validation) Loss: 1185005.5568, MAE: 4432.9907, R2: 0.0017\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1108/5000] | Time: 0.26s\n",
      "(Training) Loss: 1144325.6225\n",
      "(Validation) Loss: 1184784.8533, MAE: 4433.0522, R2: 0.0019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1109/5000] | Time: 0.24s\n",
      "(Training) Loss: 1147998.3541\n",
      "(Validation) Loss: 1184558.7454, MAE: 4432.6260, R2: 0.0021\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1110/5000] | Time: 0.25s\n",
      "(Training) Loss: 1131866.3039\n",
      "(Validation) Loss: 1184368.1930, MAE: 4439.1270, R2: 0.0022\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1111/5000] | Time: 0.25s\n",
      "(Training) Loss: 1144575.0013\n",
      "(Validation) Loss: 1184110.3644, MAE: 4433.9272, R2: 0.0025\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1112/5000] | Time: 0.28s\n",
      "(Training) Loss: 1158079.0343\n",
      "(Validation) Loss: 1183880.4927, MAE: 4429.9253, R2: 0.0026\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1113/5000] | Time: 0.28s\n",
      "(Training) Loss: 1141789.2970\n",
      "(Validation) Loss: 1183663.1619, MAE: 4433.0093, R2: 0.0028\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1114/5000] | Time: 0.24s\n",
      "(Training) Loss: 1140024.5032\n",
      "(Validation) Loss: 1183425.8590, MAE: 4429.0317, R2: 0.0030\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1115/5000] | Time: 0.26s\n",
      "(Training) Loss: 1164145.8363\n",
      "(Validation) Loss: 1183201.9505, MAE: 4427.9053, R2: 0.0032\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1116/5000] | Time: 0.28s\n",
      "(Training) Loss: 1134539.5501\n",
      "(Validation) Loss: 1182982.3035, MAE: 4430.1909, R2: 0.0034\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1117/5000] | Time: 0.26s\n",
      "(Training) Loss: 1151046.5711\n",
      "(Validation) Loss: 1182743.5429, MAE: 4425.4287, R2: 0.0036\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1118/5000] | Time: 0.27s\n",
      "(Training) Loss: 1145557.9334\n",
      "(Validation) Loss: 1182516.7797, MAE: 4424.5430, R2: 0.0038\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1119/5000] | Time: 0.28s\n",
      "(Training) Loss: 1139295.5987\n",
      "(Validation) Loss: 1182295.0908, MAE: 4425.6230, R2: 0.0040\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1120/5000] | Time: 0.25s\n",
      "(Training) Loss: 1133664.6555\n",
      "(Validation) Loss: 1182064.9854, MAE: 4422.3989, R2: 0.0042\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1121/5000] | Time: 0.24s\n",
      "(Training) Loss: 1154166.0444\n",
      "(Validation) Loss: 1181873.3257, MAE: 4426.4956, R2: 0.0043\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1122/5000] | Time: 0.25s\n",
      "(Training) Loss: 1135238.4924\n",
      "(Validation) Loss: 1181626.8343, MAE: 4424.9756, R2: 0.0045\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1123/5000] | Time: 0.23s\n",
      "(Training) Loss: 1142992.7126\n",
      "(Validation) Loss: 1181396.4648, MAE: 4422.7119, R2: 0.0047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1124/5000] | Time: 0.29s\n",
      "(Training) Loss: 1171772.5317\n",
      "(Validation) Loss: 1181168.9600, MAE: 4420.5898, R2: 0.0049\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1125/5000] | Time: 0.24s\n",
      "(Training) Loss: 1132945.0127\n",
      "(Validation) Loss: 1180936.9092, MAE: 4420.4263, R2: 0.0051\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1126/5000] | Time: 0.25s\n",
      "(Training) Loss: 1134768.2817\n",
      "(Validation) Loss: 1180726.8216, MAE: 4420.9585, R2: 0.0053\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1127/5000] | Time: 0.25s\n",
      "(Training) Loss: 1136879.3039\n",
      "(Validation) Loss: 1180506.8952, MAE: 4422.9473, R2: 0.0055\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1128/5000] | Time: 0.26s\n",
      "(Training) Loss: 1151545.8706\n",
      "(Validation) Loss: 1180264.6756, MAE: 4417.6602, R2: 0.0057\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1129/5000] | Time: 0.26s\n",
      "(Training) Loss: 1142259.9359\n",
      "(Validation) Loss: 1180060.3378, MAE: 4419.4927, R2: 0.0058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1130/5000] | Time: 0.29s\n",
      "(Training) Loss: 1124391.3121\n",
      "(Validation) Loss: 1179809.6914, MAE: 4415.3076, R2: 0.0060\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1131/5000] | Time: 0.25s\n",
      "(Training) Loss: 1161006.4156\n",
      "(Validation) Loss: 1179631.7968, MAE: 4418.3145, R2: 0.0062\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1132/5000] | Time: 0.26s\n",
      "(Training) Loss: 1151603.2805\n",
      "(Validation) Loss: 1179397.6889, MAE: 4425.0903, R2: 0.0064\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1133/5000] | Time: 0.27s\n",
      "(Training) Loss: 1152919.8496\n",
      "(Validation) Loss: 1179141.2267, MAE: 4415.5186, R2: 0.0066\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1134/5000] | Time: 0.24s\n",
      "(Training) Loss: 1135167.8401\n",
      "(Validation) Loss: 1178907.7181, MAE: 4413.3545, R2: 0.0068\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1135/5000] | Time: 0.27s\n",
      "(Training) Loss: 1167011.4651\n",
      "(Validation) Loss: 1178689.2952, MAE: 4412.7310, R2: 0.0070\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1136/5000] | Time: 0.28s\n",
      "(Training) Loss: 1132910.3858\n",
      "(Validation) Loss: 1178449.6356, MAE: 4409.6748, R2: 0.0072\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1137/5000] | Time: 0.28s\n",
      "(Training) Loss: 1143356.9258\n",
      "(Validation) Loss: 1178229.7702, MAE: 4409.8599, R2: 0.0074\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1138/5000] | Time: 0.27s\n",
      "(Training) Loss: 1149678.8978\n",
      "(Validation) Loss: 1178018.2349, MAE: 4410.6602, R2: 0.0075\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1139/5000] | Time: 0.28s\n",
      "(Training) Loss: 1163224.1110\n",
      "(Validation) Loss: 1177807.2838, MAE: 4412.5586, R2: 0.0077\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1140/5000] | Time: 0.29s\n",
      "(Training) Loss: 1122279.8837\n",
      "(Validation) Loss: 1177562.9816, MAE: 4413.8232, R2: 0.0079\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1141/5000] | Time: 0.26s\n",
      "(Training) Loss: 1131371.0768\n",
      "(Validation) Loss: 1177335.8629, MAE: 4408.2925, R2: 0.0081\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1142/5000] | Time: 0.29s\n",
      "(Training) Loss: 1133371.0057\n",
      "(Validation) Loss: 1177125.1403, MAE: 4411.8765, R2: 0.0083\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1143/5000] | Time: 0.27s\n",
      "(Training) Loss: 1127255.2398\n",
      "(Validation) Loss: 1176893.2673, MAE: 4409.6709, R2: 0.0085\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1144/5000] | Time: 0.27s\n",
      "(Training) Loss: 1132213.0279\n",
      "(Validation) Loss: 1176658.5092, MAE: 4405.4331, R2: 0.0087\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1145/5000] | Time: 0.29s\n",
      "(Training) Loss: 1122217.3219\n",
      "(Validation) Loss: 1176454.7352, MAE: 4410.3110, R2: 0.0088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1146/5000] | Time: 0.27s\n",
      "(Training) Loss: 1140612.7754\n",
      "(Validation) Loss: 1176214.1308, MAE: 4403.6050, R2: 0.0090\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1147/5000] | Time: 0.31s\n",
      "(Training) Loss: 1123181.5022\n",
      "(Validation) Loss: 1175988.0229, MAE: 4402.9849, R2: 0.0092\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1148/5000] | Time: 0.26s\n",
      "(Training) Loss: 1147098.9023\n",
      "(Validation) Loss: 1175762.3416, MAE: 4401.8247, R2: 0.0094\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1149/5000] | Time: 0.25s\n",
      "(Training) Loss: 1122096.2933\n",
      "(Validation) Loss: 1175545.7727, MAE: 4403.3320, R2: 0.0096\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1150/5000] | Time: 0.28s\n",
      "(Training) Loss: 1136495.7671\n",
      "(Validation) Loss: 1175320.4825, MAE: 4402.4697, R2: 0.0098\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1151/5000] | Time: 0.27s\n",
      "(Training) Loss: 1122608.3065\n",
      "(Validation) Loss: 1175095.7562, MAE: 4400.3096, R2: 0.0100\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1152/5000] | Time: 0.26s\n",
      "(Training) Loss: 1130551.9753\n",
      "(Validation) Loss: 1174891.8197, MAE: 4401.1035, R2: 0.0101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1153/5000] | Time: 0.25s\n",
      "(Training) Loss: 1130061.3211\n",
      "(Validation) Loss: 1174647.5886, MAE: 4397.8223, R2: 0.0103\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1154/5000] | Time: 0.26s\n",
      "(Training) Loss: 1138936.2678\n",
      "(Validation) Loss: 1174422.8267, MAE: 4396.6230, R2: 0.0105\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1155/5000] | Time: 0.30s\n",
      "(Training) Loss: 1127914.3255\n",
      "(Validation) Loss: 1174196.8000, MAE: 4395.0776, R2: 0.0107\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1156/5000] | Time: 0.23s\n",
      "(Training) Loss: 1123107.8528\n",
      "(Validation) Loss: 1173970.3162, MAE: 4393.9722, R2: 0.0109\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1157/5000] | Time: 0.26s\n",
      "(Training) Loss: 1155720.4588\n",
      "(Validation) Loss: 1173747.4032, MAE: 4393.8218, R2: 0.0111\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1158/5000] | Time: 0.27s\n",
      "(Training) Loss: 1138839.7697\n",
      "(Validation) Loss: 1173524.9168, MAE: 4395.4614, R2: 0.0113\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1159/5000] | Time: 0.28s\n",
      "(Training) Loss: 1134179.9074\n",
      "(Validation) Loss: 1173297.3511, MAE: 4391.6074, R2: 0.0115\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1160/5000] | Time: 0.36s\n",
      "(Training) Loss: 1124225.6294\n",
      "(Validation) Loss: 1173099.6317, MAE: 4393.0669, R2: 0.0116\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1161/5000] | Time: 0.25s\n",
      "(Training) Loss: 1119244.8875\n",
      "(Validation) Loss: 1172852.8203, MAE: 4391.7476, R2: 0.0118\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1162/5000] | Time: 0.25s\n",
      "(Training) Loss: 1139013.2094\n",
      "(Validation) Loss: 1172629.2317, MAE: 4390.6304, R2: 0.0120\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1163/5000] | Time: 0.23s\n",
      "(Training) Loss: 1154452.4442\n",
      "(Validation) Loss: 1172398.1257, MAE: 4388.3423, R2: 0.0122\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1164/5000] | Time: 0.27s\n",
      "(Training) Loss: 1132266.7684\n",
      "(Validation) Loss: 1172172.0584, MAE: 4388.6338, R2: 0.0124\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1165/5000] | Time: 0.26s\n",
      "(Training) Loss: 1140930.0926\n",
      "(Validation) Loss: 1171949.3537, MAE: 4387.6631, R2: 0.0126\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1166/5000] | Time: 0.24s\n",
      "(Training) Loss: 1132377.4074\n",
      "(Validation) Loss: 1171754.9765, MAE: 4389.4541, R2: 0.0127\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1167/5000] | Time: 0.25s\n",
      "(Training) Loss: 1121413.9905\n",
      "(Validation) Loss: 1171501.7092, MAE: 4385.8120, R2: 0.0130\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1168/5000] | Time: 0.28s\n",
      "(Training) Loss: 1140937.3718\n",
      "(Validation) Loss: 1171278.4863, MAE: 4386.4541, R2: 0.0131\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1169/5000] | Time: 0.26s\n",
      "(Training) Loss: 1136615.6789\n",
      "(Validation) Loss: 1171053.0641, MAE: 4384.0327, R2: 0.0133\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1170/5000] | Time: 0.27s\n",
      "(Training) Loss: 1123762.5152\n",
      "(Validation) Loss: 1171501.5670, MAE: 4404.0068, R2: 0.0130\n",
      "==========================================================================================\n",
      "Epoch [1171/5000] | Time: 0.25s\n",
      "(Training) Loss: 1144168.8135\n",
      "(Validation) Loss: 1178992.7517, MAE: 4419.6387, R2: 0.0067\n",
      "==========================================================================================\n",
      "Epoch [1172/5000] | Time: 0.29s\n",
      "(Training) Loss: 1149230.9467\n",
      "(Validation) Loss: 1178760.0660, MAE: 4415.7803, R2: 0.0069\n",
      "==========================================================================================\n",
      "Epoch [1173/5000] | Time: 0.27s\n",
      "(Training) Loss: 1129650.7931\n",
      "(Validation) Loss: 1178531.1390, MAE: 4414.1860, R2: 0.0071\n",
      "==========================================================================================\n",
      "Epoch [1174/5000] | Time: 0.34s\n",
      "(Training) Loss: 1132161.8902\n",
      "(Validation) Loss: 1174145.9302, MAE: 4399.8091, R2: 0.0108\n",
      "==========================================================================================\n",
      "Epoch [1175/5000] | Time: 0.32s\n",
      "(Training) Loss: 1129178.8439\n",
      "(Validation) Loss: 1173920.3454, MAE: 4398.7646, R2: 0.0109\n",
      "==========================================================================================\n",
      "Epoch [1176/5000] | Time: 0.31s\n",
      "(Training) Loss: 1125391.0095\n",
      "(Validation) Loss: 1173669.3029, MAE: 4392.5176, R2: 0.0111\n",
      "==========================================================================================\n",
      "Epoch [1177/5000] | Time: 0.34s\n",
      "(Training) Loss: 1155810.3782\n",
      "(Validation) Loss: 1173453.6076, MAE: 4393.7119, R2: 0.0113\n",
      "==========================================================================================\n",
      "Epoch [1178/5000] | Time: 0.31s\n",
      "(Training) Loss: 1139889.2449\n",
      "(Validation) Loss: 1173226.3162, MAE: 4392.0117, R2: 0.0115\n",
      "==========================================================================================\n",
      "Epoch [1179/5000] | Time: 0.32s\n",
      "(Training) Loss: 1138941.3655\n",
      "(Validation) Loss: 1177272.2235, MAE: 4411.3262, R2: 0.0081\n",
      "==========================================================================================\n",
      "Epoch [1180/5000] | Time: 0.29s\n",
      "(Training) Loss: 1133201.0254\n",
      "(Validation) Loss: 1177005.9683, MAE: 4406.0488, R2: 0.0084\n",
      "==========================================================================================\n",
      "Epoch [1181/5000] | Time: 0.29s\n",
      "(Training) Loss: 1128388.4676\n",
      "(Validation) Loss: 1176788.2819, MAE: 4405.3887, R2: 0.0086\n",
      "==========================================================================================\n",
      "Epoch [1182/5000] | Time: 0.26s\n",
      "(Training) Loss: 1134979.8249\n",
      "(Validation) Loss: 1176570.1689, MAE: 4404.9595, R2: 0.0087\n",
      "==========================================================================================\n",
      "Epoch [1183/5000] | Time: 0.28s\n",
      "(Training) Loss: 1124087.8004\n",
      "(Validation) Loss: 1176352.0965, MAE: 4403.9443, R2: 0.0089\n",
      "==========================================================================================\n",
      "Epoch [1184/5000] | Time: 0.27s\n",
      "(Training) Loss: 1149481.5431\n",
      "(Validation) Loss: 1176135.5327, MAE: 4403.9468, R2: 0.0091\n",
      "==========================================================================================\n",
      "Epoch [1185/5000] | Time: 0.34s\n",
      "(Training) Loss: 1133521.0241\n",
      "(Validation) Loss: 1175915.9010, MAE: 4403.2466, R2: 0.0093\n",
      "==========================================================================================\n",
      "Epoch [1186/5000] | Time: 0.31s\n",
      "(Training) Loss: 1139677.5025\n",
      "(Validation) Loss: 1175698.0317, MAE: 4402.5347, R2: 0.0095\n",
      "==========================================================================================\n",
      "Epoch [1187/5000] | Time: 0.30s\n",
      "(Training) Loss: 1139154.4105\n",
      "(Validation) Loss: 1175483.7689, MAE: 4403.1406, R2: 0.0096\n",
      "==========================================================================================\n",
      "Epoch [1188/5000] | Time: 0.27s\n",
      "(Training) Loss: 1134550.4346\n",
      "(Validation) Loss: 1175271.7765, MAE: 4402.8491, R2: 0.0098\n",
      "==========================================================================================\n",
      "Epoch [1189/5000] | Time: 0.28s\n",
      "(Training) Loss: 1123097.9727\n",
      "(Validation) Loss: 1175050.3365, MAE: 4399.7251, R2: 0.0100\n",
      "==========================================================================================\n",
      "Epoch [1190/5000] | Time: 0.30s\n",
      "(Training) Loss: 1145518.8566\n",
      "(Validation) Loss: 1175383.8629, MAE: 4403.6113, R2: 0.0097\n",
      "==========================================================================================\n",
      "Epoch [1191/5000] | Time: 0.28s\n",
      "(Training) Loss: 1131332.3223\n",
      "(Validation) Loss: 1174601.9810, MAE: 4397.5376, R2: 0.0104\n",
      "==========================================================================================\n",
      "Epoch [1192/5000] | Time: 0.25s\n",
      "(Training) Loss: 1156069.0603\n",
      "(Validation) Loss: 1174502.3187, MAE: 4410.7441, R2: 0.0104\n",
      "==========================================================================================\n",
      "Epoch [1193/5000] | Time: 0.34s\n",
      "(Training) Loss: 1133020.5076\n",
      "(Validation) Loss: 1174182.2883, MAE: 4399.7925, R2: 0.0107\n",
      "==========================================================================================\n",
      "Epoch [1194/5000] | Time: 0.29s\n",
      "(Training) Loss: 1151402.1815\n",
      "(Validation) Loss: 1173947.3168, MAE: 4395.0620, R2: 0.0109\n",
      "==========================================================================================\n",
      "Epoch [1195/5000] | Time: 0.32s\n",
      "(Training) Loss: 1146542.1256\n",
      "(Validation) Loss: 1173724.9117, MAE: 4394.1328, R2: 0.0111\n",
      "==========================================================================================\n",
      "Epoch [1196/5000] | Time: 0.27s\n",
      "(Training) Loss: 1139626.6402\n",
      "(Validation) Loss: 1173512.2946, MAE: 4393.9346, R2: 0.0113\n",
      "==========================================================================================\n",
      "Epoch [1197/5000] | Time: 0.27s\n",
      "(Training) Loss: 1140909.1345\n",
      "(Validation) Loss: 1173286.7708, MAE: 4391.8242, R2: 0.0115\n",
      "==========================================================================================\n",
      "Epoch [1198/5000] | Time: 0.33s\n",
      "(Training) Loss: 1121050.0984\n",
      "(Validation) Loss: 1173066.7530, MAE: 4390.8438, R2: 0.0117\n",
      "==========================================================================================\n",
      "Epoch [1199/5000] | Time: 0.30s\n",
      "(Training) Loss: 1157624.0584\n",
      "(Validation) Loss: 1172877.5314, MAE: 4392.5552, R2: 0.0118\n",
      "==========================================================================================\n",
      "Epoch [1200/5000] | Time: 0.31s\n",
      "(Training) Loss: 1135743.4797\n",
      "(Validation) Loss: 1172681.1276, MAE: 4394.4116, R2: 0.0120\n",
      "==========================================================================================\n",
      "Epoch [1201/5000] | Time: 0.26s\n",
      "(Training) Loss: 1139364.1726\n",
      "(Validation) Loss: 1172439.5683, MAE: 4394.1768, R2: 0.0122\n",
      "==========================================================================================\n",
      "Epoch [1202/5000] | Time: 0.27s\n",
      "(Training) Loss: 1136530.6168\n",
      "(Validation) Loss: 1172245.9987, MAE: 4398.7593, R2: 0.0123\n",
      "==========================================================================================\n",
      "Epoch [1203/5000] | Time: 0.29s\n",
      "(Training) Loss: 1143868.7094\n",
      "(Validation) Loss: 1172046.2070, MAE: 4395.3936, R2: 0.0125\n",
      "==========================================================================================\n",
      "Epoch [1204/5000] | Time: 0.25s\n",
      "(Training) Loss: 1134855.1916\n",
      "(Validation) Loss: 1171791.5124, MAE: 4393.3462, R2: 0.0127\n",
      "==========================================================================================\n",
      "Epoch [1205/5000] | Time: 0.25s\n",
      "(Training) Loss: 1130248.3997\n",
      "(Validation) Loss: 1171571.0781, MAE: 4388.9346, R2: 0.0129\n",
      "==========================================================================================\n",
      "Epoch [1206/5000] | Time: 0.27s\n",
      "(Training) Loss: 1136055.9194\n",
      "(Validation) Loss: 1171354.5448, MAE: 4388.7290, R2: 0.0131\n",
      "==========================================================================================\n",
      "Epoch [1207/5000] | Time: 0.27s\n",
      "(Training) Loss: 1129007.5146\n",
      "(Validation) Loss: 1171153.4425, MAE: 4387.6270, R2: 0.0132\n",
      "==========================================================================================\n",
      "Epoch [1208/5000] | Time: 0.29s\n",
      "(Training) Loss: 1144309.7329\n",
      "(Validation) Loss: 1170929.5086, MAE: 4390.6421, R2: 0.0134\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1209/5000] | Time: 0.31s\n",
      "(Training) Loss: 1140066.5102\n",
      "(Validation) Loss: 1170717.3587, MAE: 4389.6548, R2: 0.0136\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1210/5000] | Time: 0.32s\n",
      "(Training) Loss: 1120069.8509\n",
      "(Validation) Loss: 1170483.6368, MAE: 4384.1694, R2: 0.0138\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1211/5000] | Time: 0.30s\n",
      "(Training) Loss: 1150091.7195\n",
      "(Validation) Loss: 1170267.5708, MAE: 4384.2793, R2: 0.0140\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1212/5000] | Time: 0.31s\n",
      "(Training) Loss: 1116947.7614\n",
      "(Validation) Loss: 1170046.7048, MAE: 4382.7563, R2: 0.0142\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1213/5000] | Time: 0.36s\n",
      "(Training) Loss: 1124399.9810\n",
      "(Validation) Loss: 1169837.8260, MAE: 4383.1904, R2: 0.0143\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1214/5000] | Time: 0.44s\n",
      "(Training) Loss: 1144816.9886\n",
      "(Validation) Loss: 1169618.7632, MAE: 4380.6353, R2: 0.0145\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1215/5000] | Time: 0.37s\n",
      "(Training) Loss: 1134705.5761\n",
      "(Validation) Loss: 1169395.2660, MAE: 4378.6484, R2: 0.0147\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1216/5000] | Time: 0.29s\n",
      "(Training) Loss: 1128839.7265\n",
      "(Validation) Loss: 1169177.7778, MAE: 4380.3257, R2: 0.0149\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1217/5000] | Time: 0.28s\n",
      "(Training) Loss: 1119684.9778\n",
      "(Validation) Loss: 1168994.0165, MAE: 4384.3979, R2: 0.0150\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1218/5000] | Time: 0.21s\n",
      "(Training) Loss: 1145089.0971\n",
      "(Validation) Loss: 1168781.4959, MAE: 4383.0747, R2: 0.0152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1219/5000] | Time: 0.30s\n",
      "(Training) Loss: 1159376.9657\n",
      "(Validation) Loss: 1168553.5848, MAE: 4379.3887, R2: 0.0154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1220/5000] | Time: 0.26s\n",
      "(Training) Loss: 1157733.9220\n",
      "(Validation) Loss: 1168322.7987, MAE: 4378.5508, R2: 0.0156\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1221/5000] | Time: 0.27s\n",
      "(Training) Loss: 1146782.9619\n",
      "(Validation) Loss: 1168150.1968, MAE: 4389.9155, R2: 0.0157\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1222/5000] | Time: 0.25s\n",
      "(Training) Loss: 1117577.7582\n",
      "(Validation) Loss: 1167877.9784, MAE: 4377.4038, R2: 0.0160\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1223/5000] | Time: 0.23s\n",
      "(Training) Loss: 1124757.1104\n",
      "(Validation) Loss: 1167684.1041, MAE: 4378.6831, R2: 0.0161\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1224/5000] | Time: 0.27s\n",
      "(Training) Loss: 1131462.5558\n",
      "(Validation) Loss: 1167442.5346, MAE: 4371.4849, R2: 0.0163\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1225/5000] | Time: 0.27s\n",
      "(Training) Loss: 1134661.9239\n",
      "(Validation) Loss: 1167228.8508, MAE: 4372.3887, R2: 0.0165\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1226/5000] | Time: 0.25s\n",
      "(Training) Loss: 1123112.8096\n",
      "(Validation) Loss: 1167016.0305, MAE: 4371.6064, R2: 0.0167\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1227/5000] | Time: 0.25s\n",
      "(Training) Loss: 1130106.6187\n",
      "(Validation) Loss: 1166829.7346, MAE: 4375.3350, R2: 0.0168\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1228/5000] | Time: 0.32s\n",
      "(Training) Loss: 1115193.9873\n",
      "(Validation) Loss: 1166589.2724, MAE: 4371.2192, R2: 0.0170\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1229/5000] | Time: 0.25s\n",
      "(Training) Loss: 1137343.1789\n",
      "(Validation) Loss: 1166365.0387, MAE: 4368.7573, R2: 0.0172\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1230/5000] | Time: 0.26s\n",
      "(Training) Loss: 1119120.8617\n",
      "(Validation) Loss: 1166152.4978, MAE: 4369.0405, R2: 0.0174\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1231/5000] | Time: 0.25s\n",
      "(Training) Loss: 1128026.0419\n",
      "(Validation) Loss: 1165945.3613, MAE: 4369.0522, R2: 0.0176\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1232/5000] | Time: 0.26s\n",
      "(Training) Loss: 1137677.0863\n",
      "(Validation) Loss: 1165731.3727, MAE: 4367.8101, R2: 0.0178\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1233/5000] | Time: 0.24s\n",
      "(Training) Loss: 1157338.4143\n",
      "(Validation) Loss: 1165504.1727, MAE: 4365.1729, R2: 0.0179\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1234/5000] | Time: 0.26s\n",
      "(Training) Loss: 1113897.6053\n",
      "(Validation) Loss: 1165314.3060, MAE: 4368.1660, R2: 0.0181\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1235/5000] | Time: 0.26s\n",
      "(Training) Loss: 1141921.2418\n",
      "(Validation) Loss: 1165074.6819, MAE: 4364.8896, R2: 0.0183\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1236/5000] | Time: 0.30s\n",
      "(Training) Loss: 1123625.5102\n",
      "(Validation) Loss: 1164875.8400, MAE: 4367.6616, R2: 0.0185\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1237/5000] | Time: 0.27s\n",
      "(Training) Loss: 1123398.9797\n",
      "(Validation) Loss: 1164670.8724, MAE: 4367.2100, R2: 0.0186\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1238/5000] | Time: 0.28s\n",
      "(Training) Loss: 1129860.0032\n",
      "(Validation) Loss: 1164426.4483, MAE: 4362.1650, R2: 0.0188\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1239/5000] | Time: 0.28s\n",
      "(Training) Loss: 1144764.0984\n",
      "(Validation) Loss: 1164208.9803, MAE: 4362.1104, R2: 0.0190\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1240/5000] | Time: 0.27s\n",
      "(Training) Loss: 1116767.1599\n",
      "(Validation) Loss: 1164014.0140, MAE: 4362.6377, R2: 0.0192\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1241/5000] | Time: 0.30s\n",
      "(Training) Loss: 1118624.3553\n",
      "(Validation) Loss: 1163797.6127, MAE: 4361.5288, R2: 0.0194\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1242/5000] | Time: 0.29s\n",
      "(Training) Loss: 1113795.6345\n",
      "(Validation) Loss: 1163593.0921, MAE: 4362.5864, R2: 0.0195\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1243/5000] | Time: 0.32s\n",
      "(Training) Loss: 1114311.7005\n",
      "(Validation) Loss: 1163371.4489, MAE: 4361.2715, R2: 0.0197\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1244/5000] | Time: 0.26s\n",
      "(Training) Loss: 1135350.5876\n",
      "(Validation) Loss: 1163167.7917, MAE: 4366.1304, R2: 0.0199\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1245/5000] | Time: 0.26s\n",
      "(Training) Loss: 1134467.4911\n",
      "(Validation) Loss: 1167362.2806, MAE: 4375.2700, R2: 0.0164\n",
      "==========================================================================================\n",
      "Epoch [1246/5000] | Time: 0.34s\n",
      "(Training) Loss: 1129975.9137\n",
      "(Validation) Loss: 1167150.0292, MAE: 4376.8379, R2: 0.0166\n",
      "==========================================================================================\n",
      "Epoch [1247/5000] | Time: 0.29s\n",
      "(Training) Loss: 1131955.6713\n",
      "(Validation) Loss: 1166933.3943, MAE: 4373.6772, R2: 0.0168\n",
      "==========================================================================================\n",
      "Epoch [1248/5000] | Time: 0.27s\n",
      "(Training) Loss: 1125550.4975\n",
      "(Validation) Loss: 1166721.8946, MAE: 4373.1509, R2: 0.0169\n",
      "==========================================================================================\n",
      "Epoch [1249/5000] | Time: 0.32s\n",
      "(Training) Loss: 1112798.9882\n",
      "(Validation) Loss: 1166507.6165, MAE: 4372.5537, R2: 0.0171\n",
      "==========================================================================================\n",
      "Epoch [1250/5000] | Time: 0.34s\n",
      "(Training) Loss: 1116622.0527\n",
      "(Validation) Loss: 1166296.6603, MAE: 4371.4805, R2: 0.0173\n",
      "==========================================================================================\n",
      "Epoch [1251/5000] | Time: 0.31s\n",
      "(Training) Loss: 1114740.7814\n",
      "(Validation) Loss: 1166083.4286, MAE: 4370.7002, R2: 0.0175\n",
      "==========================================================================================\n",
      "Epoch [1252/5000] | Time: 0.30s\n",
      "(Training) Loss: 1136718.1256\n",
      "(Validation) Loss: 1165871.0654, MAE: 4368.3472, R2: 0.0176\n",
      "==========================================================================================\n",
      "Epoch [1253/5000] | Time: 0.28s\n",
      "(Training) Loss: 1124349.1954\n",
      "(Validation) Loss: 1165658.6006, MAE: 4368.3999, R2: 0.0178\n",
      "==========================================================================================\n",
      "Epoch [1254/5000] | Time: 0.26s\n",
      "(Training) Loss: 1142123.5860\n",
      "(Validation) Loss: 1165447.5429, MAE: 4367.8037, R2: 0.0180\n",
      "==========================================================================================\n",
      "Epoch [1255/5000] | Time: 0.26s\n",
      "(Training) Loss: 1131474.5774\n",
      "(Validation) Loss: 1165259.9213, MAE: 4368.3682, R2: 0.0182\n",
      "==========================================================================================\n",
      "Epoch [1256/5000] | Time: 0.25s\n",
      "(Training) Loss: 1131627.4137\n",
      "(Validation) Loss: 1165057.9403, MAE: 4369.1328, R2: 0.0183\n",
      "==========================================================================================\n",
      "Epoch [1257/5000] | Time: 0.26s\n",
      "(Training) Loss: 1118040.9588\n",
      "(Validation) Loss: 1164843.6165, MAE: 4371.5278, R2: 0.0185\n",
      "==========================================================================================\n",
      "Epoch [1258/5000] | Time: 0.26s\n",
      "(Training) Loss: 1131204.4099\n",
      "(Validation) Loss: 1164623.1517, MAE: 4367.7251, R2: 0.0187\n",
      "==========================================================================================\n",
      "Epoch [1259/5000] | Time: 0.28s\n",
      "(Training) Loss: 1117420.1815\n",
      "(Validation) Loss: 1164408.1879, MAE: 4365.7095, R2: 0.0189\n",
      "==========================================================================================\n",
      "Epoch [1260/5000] | Time: 0.28s\n",
      "(Training) Loss: 1111037.8058\n",
      "(Validation) Loss: 1164174.6895, MAE: 4365.1113, R2: 0.0191\n",
      "==========================================================================================\n",
      "Epoch [1261/5000] | Time: 0.26s\n",
      "(Training) Loss: 1136407.6371\n",
      "(Validation) Loss: 1163961.8946, MAE: 4362.6206, R2: 0.0192\n",
      "==========================================================================================\n",
      "Epoch [1262/5000] | Time: 0.31s\n",
      "(Training) Loss: 1124005.6967\n",
      "(Validation) Loss: 1163778.2552, MAE: 4366.3789, R2: 0.0194\n",
      "==========================================================================================\n",
      "Epoch [1263/5000] | Time: 0.28s\n",
      "(Training) Loss: 1118388.1536\n",
      "(Validation) Loss: 1163532.8914, MAE: 4360.0679, R2: 0.0196\n",
      "==========================================================================================\n",
      "Epoch [1264/5000] | Time: 0.33s\n",
      "(Training) Loss: 1131472.7259\n",
      "(Validation) Loss: 1163327.2889, MAE: 4360.7217, R2: 0.0198\n",
      "==========================================================================================\n",
      "Epoch [1265/5000] | Time: 0.31s\n",
      "(Training) Loss: 1126687.4803\n",
      "(Validation) Loss: 1163087.4108, MAE: 4358.8452, R2: 0.0200\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1266/5000] | Time: 0.29s\n",
      "(Training) Loss: 1129884.0679\n",
      "(Validation) Loss: 1162875.2965, MAE: 4356.8740, R2: 0.0201\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1267/5000] | Time: 0.34s\n",
      "(Training) Loss: 1111097.6171\n",
      "(Validation) Loss: 1162694.8063, MAE: 4362.3135, R2: 0.0203\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1268/5000] | Time: 0.30s\n",
      "(Training) Loss: 1128704.9343\n",
      "(Validation) Loss: 1162453.2775, MAE: 4357.3706, R2: 0.0205\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1269/5000] | Time: 0.30s\n",
      "(Training) Loss: 1120732.0000\n",
      "(Validation) Loss: 1162239.4667, MAE: 4356.0308, R2: 0.0207\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1270/5000] | Time: 0.28s\n",
      "(Training) Loss: 1131475.8033\n",
      "(Validation) Loss: 1162085.4044, MAE: 4358.3320, R2: 0.0208\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1271/5000] | Time: 0.30s\n",
      "(Training) Loss: 1112977.3331\n",
      "(Validation) Loss: 1161835.8400, MAE: 4355.7793, R2: 0.0210\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1272/5000] | Time: 0.30s\n",
      "(Training) Loss: 1110273.9689\n",
      "(Validation) Loss: 1161653.1251, MAE: 4363.6348, R2: 0.0212\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1273/5000] | Time: 0.28s\n",
      "(Training) Loss: 1122212.3522\n",
      "(Validation) Loss: 1161418.0927, MAE: 4353.7861, R2: 0.0214\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1274/5000] | Time: 0.26s\n",
      "(Training) Loss: 1115726.4194\n",
      "(Validation) Loss: 1161204.1092, MAE: 4352.3940, R2: 0.0215\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1275/5000] | Time: 0.28s\n",
      "(Training) Loss: 1124926.5838\n",
      "(Validation) Loss: 1161002.7683, MAE: 4355.7129, R2: 0.0217\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1276/5000] | Time: 0.34s\n",
      "(Training) Loss: 1113145.6821\n",
      "(Validation) Loss: 1160809.5949, MAE: 4358.9048, R2: 0.0219\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1277/5000] | Time: 0.29s\n",
      "(Training) Loss: 1109589.2310\n",
      "(Validation) Loss: 1160571.9619, MAE: 4350.8203, R2: 0.0221\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1278/5000] | Time: 0.29s\n",
      "(Training) Loss: 1129084.5133\n",
      "(Validation) Loss: 1160370.4127, MAE: 4350.8477, R2: 0.0222\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1279/5000] | Time: 0.28s\n",
      "(Training) Loss: 1147498.5406\n",
      "(Validation) Loss: 1160147.1340, MAE: 4349.3506, R2: 0.0224\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1280/5000] | Time: 0.33s\n",
      "(Training) Loss: 1117721.4968\n",
      "(Validation) Loss: 1159941.0489, MAE: 4349.4985, R2: 0.0226\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1281/5000] | Time: 0.31s\n",
      "(Training) Loss: 1127705.0571\n",
      "(Validation) Loss: 1159726.6590, MAE: 4350.2715, R2: 0.0228\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1282/5000] | Time: 0.31s\n",
      "(Training) Loss: 1119135.2868\n",
      "(Validation) Loss: 1159514.2756, MAE: 4347.3652, R2: 0.0229\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1283/5000] | Time: 0.34s\n",
      "(Training) Loss: 1119451.2195\n",
      "(Validation) Loss: 1159315.9873, MAE: 4348.0386, R2: 0.0231\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1284/5000] | Time: 0.33s\n",
      "(Training) Loss: 1122985.8909\n",
      "(Validation) Loss: 1159085.4197, MAE: 4344.9390, R2: 0.0233\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1285/5000] | Time: 0.35s\n",
      "(Training) Loss: 1116485.0799\n",
      "(Validation) Loss: 1158886.9994, MAE: 4346.5557, R2: 0.0235\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1286/5000] | Time: 0.42s\n",
      "(Training) Loss: 1137603.7386\n",
      "(Validation) Loss: 1158668.7492, MAE: 4345.9292, R2: 0.0236\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1287/5000] | Time: 0.31s\n",
      "(Training) Loss: 1122531.4619\n",
      "(Validation) Loss: 1159348.4902, MAE: 4356.3633, R2: 0.0230\n",
      "==========================================================================================\n",
      "Epoch [1288/5000] | Time: 0.31s\n",
      "(Training) Loss: 1107278.2379\n",
      "(Validation) Loss: 1158242.6159, MAE: 4342.4517, R2: 0.0240\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1289/5000] | Time: 0.32s\n",
      "(Training) Loss: 1110115.1910\n",
      "(Validation) Loss: 1158029.7702, MAE: 4340.8491, R2: 0.0242\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1290/5000] | Time: 0.30s\n",
      "(Training) Loss: 1118826.3395\n",
      "(Validation) Loss: 1157803.0578, MAE: 4340.5654, R2: 0.0244\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1291/5000] | Time: 0.32s\n",
      "(Training) Loss: 1136898.6640\n",
      "(Validation) Loss: 1157597.4806, MAE: 4340.9321, R2: 0.0245\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1292/5000] | Time: 0.38s\n",
      "(Training) Loss: 1118225.1123\n",
      "(Validation) Loss: 1157376.2590, MAE: 4336.6382, R2: 0.0247\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1293/5000] | Time: 0.34s\n",
      "(Training) Loss: 1111353.1992\n",
      "(Validation) Loss: 1157171.8248, MAE: 4337.7974, R2: 0.0249\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1294/5000] | Time: 0.24s\n",
      "(Training) Loss: 1113365.5520\n",
      "(Validation) Loss: 1156956.6273, MAE: 4336.4624, R2: 0.0251\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1295/5000] | Time: 0.35s\n",
      "(Training) Loss: 1109972.0895\n",
      "(Validation) Loss: 1156778.7581, MAE: 4339.7095, R2: 0.0252\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1296/5000] | Time: 0.32s\n",
      "(Training) Loss: 1112524.6256\n",
      "(Validation) Loss: 1156532.1651, MAE: 4333.1714, R2: 0.0254\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1297/5000] | Time: 0.35s\n",
      "(Training) Loss: 1121680.7056\n",
      "(Validation) Loss: 1156339.1543, MAE: 4334.3696, R2: 0.0256\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1298/5000] | Time: 0.26s\n",
      "(Training) Loss: 1109101.6174\n",
      "(Validation) Loss: 1156125.8413, MAE: 4333.4155, R2: 0.0258\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1299/5000] | Time: 0.26s\n",
      "(Training) Loss: 1114089.3414\n",
      "(Validation) Loss: 1155904.2844, MAE: 4332.1294, R2: 0.0259\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1300/5000] | Time: 0.35s\n",
      "(Training) Loss: 1108251.4365\n",
      "(Validation) Loss: 1155692.2159, MAE: 4331.9307, R2: 0.0261\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1301/5000] | Time: 0.33s\n",
      "(Training) Loss: 1107942.7253\n",
      "(Validation) Loss: 1155483.4032, MAE: 4329.3940, R2: 0.0263\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1302/5000] | Time: 0.26s\n",
      "(Training) Loss: 1117626.7462\n",
      "(Validation) Loss: 1155289.1073, MAE: 4332.2153, R2: 0.0265\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1303/5000] | Time: 0.26s\n",
      "(Training) Loss: 1125027.2925\n",
      "(Validation) Loss: 1155094.1003, MAE: 4334.0688, R2: 0.0266\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1304/5000] | Time: 0.23s\n",
      "(Training) Loss: 1107235.2056\n",
      "(Validation) Loss: 1164133.3537, MAE: 4375.0903, R2: 0.0191\n",
      "==========================================================================================\n",
      "Epoch [1305/5000] | Time: 0.28s\n",
      "(Training) Loss: 1125118.8217\n",
      "(Validation) Loss: 1163903.3498, MAE: 4368.8950, R2: 0.0193\n",
      "==========================================================================================\n",
      "Epoch [1306/5000] | Time: 0.49s\n",
      "(Training) Loss: 1122177.4740\n",
      "(Validation) Loss: 1163665.4679, MAE: 4363.2964, R2: 0.0195\n",
      "==========================================================================================\n",
      "Epoch [1307/5000] | Time: 0.39s\n",
      "(Training) Loss: 1147971.4074\n",
      "(Validation) Loss: 1163441.1632, MAE: 4360.2407, R2: 0.0197\n",
      "==========================================================================================\n",
      "Epoch [1308/5000] | Time: 0.80s\n",
      "(Training) Loss: 1115123.3871\n",
      "(Validation) Loss: 1163222.2476, MAE: 4357.7432, R2: 0.0199\n",
      "==========================================================================================\n",
      "Epoch [1309/5000] | Time: 0.70s\n",
      "(Training) Loss: 1130495.2348\n",
      "(Validation) Loss: 1163017.3206, MAE: 4359.5479, R2: 0.0200\n",
      "==========================================================================================\n",
      "Epoch [1310/5000] | Time: 0.69s\n",
      "(Training) Loss: 1120360.9937\n",
      "(Validation) Loss: 1162820.8965, MAE: 4359.7202, R2: 0.0202\n",
      "==========================================================================================\n",
      "Epoch [1311/5000] | Time: 0.32s\n",
      "(Training) Loss: 1114267.7487\n",
      "(Validation) Loss: 1162607.2330, MAE: 4358.4932, R2: 0.0204\n",
      "==========================================================================================\n",
      "Epoch [1312/5000] | Time: 0.34s\n",
      "(Training) Loss: 1136830.1853\n",
      "(Validation) Loss: 1162377.4730, MAE: 4357.5620, R2: 0.0206\n",
      "==========================================================================================\n",
      "Epoch [1313/5000] | Time: 0.80s\n",
      "(Training) Loss: 1138572.0387\n",
      "(Validation) Loss: 1162162.5295, MAE: 4357.6338, R2: 0.0207\n",
      "==========================================================================================\n",
      "Epoch [1314/5000] | Time: 0.90s\n",
      "(Training) Loss: 1125370.9860\n",
      "(Validation) Loss: 1161943.6648, MAE: 4353.5293, R2: 0.0209\n",
      "==========================================================================================\n",
      "Epoch [1315/5000] | Time: 1.04s\n",
      "(Training) Loss: 1123673.5774\n",
      "(Validation) Loss: 1161738.1435, MAE: 4354.7456, R2: 0.0211\n",
      "==========================================================================================\n",
      "Epoch [1316/5000] | Time: 0.90s\n",
      "(Training) Loss: 1131075.3718\n",
      "(Validation) Loss: 1161517.4654, MAE: 4352.3960, R2: 0.0213\n",
      "==========================================================================================\n",
      "Epoch [1317/5000] | Time: 0.66s\n",
      "(Training) Loss: 1113478.6390\n",
      "(Validation) Loss: 1161305.6914, MAE: 4352.2622, R2: 0.0214\n",
      "==========================================================================================\n",
      "Epoch [1318/5000] | Time: 0.26s\n",
      "(Training) Loss: 1124005.5266\n",
      "(Validation) Loss: 1161090.9511, MAE: 4351.0420, R2: 0.0216\n",
      "==========================================================================================\n",
      "Epoch [1319/5000] | Time: 0.29s\n",
      "(Training) Loss: 1120268.4010\n",
      "(Validation) Loss: 1160877.1911, MAE: 4349.0332, R2: 0.0218\n",
      "==========================================================================================\n",
      "Epoch [1320/5000] | Time: 0.29s\n",
      "(Training) Loss: 1125598.0019\n",
      "(Validation) Loss: 1160667.7841, MAE: 4349.0942, R2: 0.0220\n",
      "==========================================================================================\n",
      "Epoch [1321/5000] | Time: 0.29s\n",
      "(Training) Loss: 1127309.5952\n",
      "(Validation) Loss: 1160464.1270, MAE: 4351.2866, R2: 0.0221\n",
      "==========================================================================================\n",
      "Epoch [1322/5000] | Time: 0.25s\n",
      "(Training) Loss: 1122973.5768\n",
      "(Validation) Loss: 1160257.4476, MAE: 4353.5400, R2: 0.0223\n",
      "==========================================================================================\n",
      "Epoch [1323/5000] | Time: 0.29s\n",
      "(Training) Loss: 1133707.3858\n",
      "(Validation) Loss: 1160051.6114, MAE: 4350.0405, R2: 0.0225\n",
      "==========================================================================================\n",
      "Epoch [1324/5000] | Time: 0.26s\n",
      "(Training) Loss: 1128325.3135\n",
      "(Validation) Loss: 1159821.2927, MAE: 4346.9502, R2: 0.0227\n",
      "==========================================================================================\n",
      "Epoch [1325/5000] | Time: 0.33s\n",
      "(Training) Loss: 1136391.8794\n",
      "(Validation) Loss: 1159612.8813, MAE: 4346.8916, R2: 0.0229\n",
      "==========================================================================================\n",
      "Epoch [1326/5000] | Time: 0.26s\n",
      "(Training) Loss: 1126956.7456\n",
      "(Validation) Loss: 1159418.3010, MAE: 4347.4644, R2: 0.0230\n",
      "==========================================================================================\n",
      "Epoch [1327/5000] | Time: 0.25s\n",
      "(Training) Loss: 1117090.2221\n",
      "(Validation) Loss: 1159196.3073, MAE: 4349.8164, R2: 0.0232\n",
      "==========================================================================================\n",
      "Epoch [1328/5000] | Time: 0.32s\n",
      "(Training) Loss: 1130787.4981\n",
      "(Validation) Loss: 1158990.5879, MAE: 4344.1587, R2: 0.0234\n",
      "==========================================================================================\n",
      "Epoch [1329/5000] | Time: 0.23s\n",
      "(Training) Loss: 1154320.1155\n",
      "(Validation) Loss: 1158781.4857, MAE: 4344.2671, R2: 0.0235\n",
      "==========================================================================================\n",
      "Epoch [1330/5000] | Time: 0.26s\n",
      "(Training) Loss: 1110553.5190\n",
      "(Validation) Loss: 1158580.6070, MAE: 4345.2827, R2: 0.0237\n",
      "==========================================================================================\n",
      "Epoch [1331/5000] | Time: 0.28s\n",
      "(Training) Loss: 1127846.0292\n",
      "(Validation) Loss: 1158360.3759, MAE: 4344.5747, R2: 0.0239\n",
      "==========================================================================================\n",
      "Epoch [1332/5000] | Time: 0.24s\n",
      "(Training) Loss: 1112123.0266\n",
      "(Validation) Loss: 1158144.3098, MAE: 4342.5649, R2: 0.0241\n",
      "==========================================================================================\n",
      "Epoch [1333/5000] | Time: 0.32s\n",
      "(Training) Loss: 1128680.0381\n",
      "(Validation) Loss: 1157960.7060, MAE: 4344.6118, R2: 0.0242\n",
      "==========================================================================================\n",
      "Epoch [1334/5000] | Time: 0.36s\n",
      "(Training) Loss: 1109894.4898\n",
      "(Validation) Loss: 1157744.6806, MAE: 4342.1660, R2: 0.0244\n",
      "==========================================================================================\n",
      "Epoch [1335/5000] | Time: 0.28s\n",
      "(Training) Loss: 1119764.6447\n",
      "(Validation) Loss: 1157571.5556, MAE: 4354.2217, R2: 0.0246\n",
      "==========================================================================================\n",
      "Epoch [1336/5000] | Time: 0.27s\n",
      "(Training) Loss: 1124869.8839\n",
      "(Validation) Loss: 1157318.1816, MAE: 4341.7988, R2: 0.0248\n",
      "==========================================================================================\n",
      "Epoch [1337/5000] | Time: 0.34s\n",
      "(Training) Loss: 1112902.3464\n",
      "(Validation) Loss: 1157084.6171, MAE: 4337.6445, R2: 0.0250\n",
      "==========================================================================================\n",
      "Epoch [1338/5000] | Time: 0.31s\n",
      "(Training) Loss: 1104951.4502\n",
      "(Validation) Loss: 1156869.9530, MAE: 4337.5342, R2: 0.0251\n",
      "==========================================================================================\n",
      "Epoch [1339/5000] | Time: 0.28s\n",
      "(Training) Loss: 1127311.5241\n",
      "(Validation) Loss: 1156670.1562, MAE: 4338.5957, R2: 0.0253\n",
      "==========================================================================================\n",
      "Epoch [1340/5000] | Time: 0.39s\n",
      "(Training) Loss: 1126673.9277\n",
      "(Validation) Loss: 1156451.0070, MAE: 4336.2275, R2: 0.0255\n",
      "==========================================================================================\n",
      "Epoch [1341/5000] | Time: 0.32s\n",
      "(Training) Loss: 1132629.1777\n",
      "(Validation) Loss: 1156254.5016, MAE: 4336.4614, R2: 0.0257\n",
      "==========================================================================================\n",
      "Epoch [1342/5000] | Time: 0.28s\n",
      "(Training) Loss: 1134262.7735\n",
      "(Validation) Loss: 1156031.4463, MAE: 4336.4189, R2: 0.0258\n",
      "==========================================================================================\n",
      "Epoch [1343/5000] | Time: 0.28s\n",
      "(Training) Loss: 1103550.6152\n",
      "(Validation) Loss: 1155818.4025, MAE: 4335.1118, R2: 0.0260\n",
      "==========================================================================================\n",
      "Epoch [1344/5000] | Time: 0.38s\n",
      "(Training) Loss: 1104980.6967\n",
      "(Validation) Loss: 1155607.0400, MAE: 4333.5913, R2: 0.0262\n",
      "==========================================================================================\n",
      "Epoch [1345/5000] | Time: 0.27s\n",
      "(Training) Loss: 1120016.2475\n",
      "(Validation) Loss: 1155395.6724, MAE: 4331.7153, R2: 0.0264\n",
      "==========================================================================================\n",
      "Epoch [1346/5000] | Time: 0.33s\n",
      "(Training) Loss: 1109730.5463\n",
      "(Validation) Loss: 1155183.2990, MAE: 4330.1641, R2: 0.0265\n",
      "==========================================================================================\n",
      "Epoch [1347/5000] | Time: 0.27s\n",
      "(Training) Loss: 1110554.2563\n",
      "(Validation) Loss: 1154975.7867, MAE: 4330.6284, R2: 0.0267\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1348/5000] | Time: 0.22s\n",
      "(Training) Loss: 1115711.3572\n",
      "(Validation) Loss: 1154772.3886, MAE: 4332.4619, R2: 0.0269\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1349/5000] | Time: 0.21s\n",
      "(Training) Loss: 1137061.1104\n",
      "(Validation) Loss: 1154549.0032, MAE: 4328.5835, R2: 0.0271\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1350/5000] | Time: 0.23s\n",
      "(Training) Loss: 1122586.8458\n",
      "(Validation) Loss: 1154369.3460, MAE: 4331.4243, R2: 0.0272\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1351/5000] | Time: 0.28s\n",
      "(Training) Loss: 1106685.2437\n",
      "(Validation) Loss: 1154157.7702, MAE: 4332.2490, R2: 0.0274\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1352/5000] | Time: 0.25s\n",
      "(Training) Loss: 1117458.0457\n",
      "(Validation) Loss: 1153946.1181, MAE: 4329.5273, R2: 0.0276\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1353/5000] | Time: 0.25s\n",
      "(Training) Loss: 1111802.7418\n",
      "(Validation) Loss: 1153732.6019, MAE: 4327.7017, R2: 0.0278\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1354/5000] | Time: 0.26s\n",
      "(Training) Loss: 1116638.4226\n",
      "(Validation) Loss: 1153549.0540, MAE: 4329.1582, R2: 0.0279\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1355/5000] | Time: 0.22s\n",
      "(Training) Loss: 1122292.3807\n",
      "(Validation) Loss: 1153340.7797, MAE: 4330.2656, R2: 0.0281\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1356/5000] | Time: 0.23s\n",
      "(Training) Loss: 1113698.5914\n",
      "(Validation) Loss: 1153126.0038, MAE: 4328.4346, R2: 0.0283\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1357/5000] | Time: 0.24s\n",
      "(Training) Loss: 1129655.8249\n",
      "(Validation) Loss: 1152913.0311, MAE: 4326.4653, R2: 0.0284\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1358/5000] | Time: 0.22s\n",
      "(Training) Loss: 1122667.6015\n",
      "(Validation) Loss: 1152751.3905, MAE: 4329.7822, R2: 0.0286\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1359/5000] | Time: 0.23s\n",
      "(Training) Loss: 1116842.7018\n",
      "(Validation) Loss: 1152501.1911, MAE: 4327.3159, R2: 0.0288\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1360/5000] | Time: 0.22s\n",
      "(Training) Loss: 1112540.2925\n",
      "(Validation) Loss: 1152281.9657, MAE: 4326.2837, R2: 0.0290\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1361/5000] | Time: 0.26s\n",
      "(Training) Loss: 1119538.4385\n",
      "(Validation) Loss: 1152080.2946, MAE: 4327.1997, R2: 0.0291\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1362/5000] | Time: 0.21s\n",
      "(Training) Loss: 1109341.8471\n",
      "(Validation) Loss: 1151862.4559, MAE: 4324.4888, R2: 0.0293\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1363/5000] | Time: 0.22s\n",
      "(Training) Loss: 1102277.6218\n",
      "(Validation) Loss: 1151686.7606, MAE: 4326.6411, R2: 0.0295\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1364/5000] | Time: 0.25s\n",
      "(Training) Loss: 1113244.3217\n",
      "(Validation) Loss: 1151478.5575, MAE: 4324.6294, R2: 0.0296\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1365/5000] | Time: 0.21s\n",
      "(Training) Loss: 1134712.5825\n",
      "(Validation) Loss: 1151279.1162, MAE: 4327.4019, R2: 0.0298\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1366/5000] | Time: 0.27s\n",
      "(Training) Loss: 1098733.8049\n",
      "(Validation) Loss: 1151063.9898, MAE: 4327.1802, R2: 0.0300\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1367/5000] | Time: 0.25s\n",
      "(Training) Loss: 1122160.1586\n",
      "(Validation) Loss: 1150848.5994, MAE: 4323.1924, R2: 0.0302\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1368/5000] | Time: 0.23s\n",
      "(Training) Loss: 1101840.7944\n",
      "(Validation) Loss: 1150641.6102, MAE: 4323.6421, R2: 0.0303\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1369/5000] | Time: 0.27s\n",
      "(Training) Loss: 1108945.2354\n",
      "(Validation) Loss: 1150431.6038, MAE: 4323.6709, R2: 0.0305\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1370/5000] | Time: 0.24s\n",
      "(Training) Loss: 1121912.5952\n",
      "(Validation) Loss: 1150221.9835, MAE: 4322.3369, R2: 0.0307\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1371/5000] | Time: 0.26s\n",
      "(Training) Loss: 1122700.7272\n",
      "(Validation) Loss: 1150004.6730, MAE: 4320.5396, R2: 0.0309\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1372/5000] | Time: 0.22s\n",
      "(Training) Loss: 1110982.9099\n",
      "(Validation) Loss: 1149805.6990, MAE: 4324.5879, R2: 0.0310\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1373/5000] | Time: 0.23s\n",
      "(Training) Loss: 1098171.8139\n",
      "(Validation) Loss: 1149595.3016, MAE: 4322.3662, R2: 0.0312\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1374/5000] | Time: 0.25s\n",
      "(Training) Loss: 1101700.7373\n",
      "(Validation) Loss: 1149419.5200, MAE: 4322.5039, R2: 0.0313\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1375/5000] | Time: 0.23s\n",
      "(Training) Loss: 1119378.8779\n",
      "(Validation) Loss: 1149206.6946, MAE: 4319.0186, R2: 0.0315\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1376/5000] | Time: 0.29s\n",
      "(Training) Loss: 1112437.9657\n",
      "(Validation) Loss: 1148997.6889, MAE: 4319.3125, R2: 0.0317\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1377/5000] | Time: 0.26s\n",
      "(Training) Loss: 1099554.9943\n",
      "(Validation) Loss: 1148834.1435, MAE: 4321.5684, R2: 0.0318\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1378/5000] | Time: 0.30s\n",
      "(Training) Loss: 1120286.7893\n",
      "(Validation) Loss: 1148574.8673, MAE: 4317.5317, R2: 0.0320\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1379/5000] | Time: 0.35s\n",
      "(Training) Loss: 1124233.3769\n",
      "(Validation) Loss: 1148372.6832, MAE: 4319.5024, R2: 0.0322\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1380/5000] | Time: 0.31s\n",
      "(Training) Loss: 1111031.9975\n",
      "(Validation) Loss: 1148160.8990, MAE: 4318.4443, R2: 0.0324\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1381/5000] | Time: 0.35s\n",
      "(Training) Loss: 1128778.2912\n",
      "(Validation) Loss: 1147949.9479, MAE: 4315.0889, R2: 0.0326\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1382/5000] | Time: 0.28s\n",
      "(Training) Loss: 1114631.6275\n",
      "(Validation) Loss: 1147736.4368, MAE: 4314.1538, R2: 0.0327\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1383/5000] | Time: 0.31s\n",
      "(Training) Loss: 1105060.4004\n",
      "(Validation) Loss: 1147523.2203, MAE: 4313.3770, R2: 0.0329\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1384/5000] | Time: 0.28s\n",
      "(Training) Loss: 1097722.1098\n",
      "(Validation) Loss: 1147322.3670, MAE: 4314.1240, R2: 0.0331\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1385/5000] | Time: 0.29s\n",
      "(Training) Loss: 1136217.9004\n",
      "(Validation) Loss: 1147138.2095, MAE: 4320.3809, R2: 0.0332\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1386/5000] | Time: 0.28s\n",
      "(Training) Loss: 1120131.8363\n",
      "(Validation) Loss: 1146903.9390, MAE: 4313.4858, R2: 0.0334\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1387/5000] | Time: 0.30s\n",
      "(Training) Loss: 1105114.8096\n",
      "(Validation) Loss: 1146686.7911, MAE: 4311.1060, R2: 0.0336\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1388/5000] | Time: 0.30s\n",
      "(Training) Loss: 1117082.9181\n",
      "(Validation) Loss: 1146482.0317, MAE: 4311.4678, R2: 0.0338\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1389/5000] | Time: 0.27s\n",
      "(Training) Loss: 1114283.2424\n",
      "(Validation) Loss: 1146272.3149, MAE: 4311.7988, R2: 0.0340\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1390/5000] | Time: 0.28s\n",
      "(Training) Loss: 1125199.7398\n",
      "(Validation) Loss: 1146062.5879, MAE: 4310.0562, R2: 0.0341\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1391/5000] | Time: 0.30s\n",
      "(Training) Loss: 1143811.4619\n",
      "(Validation) Loss: 1145852.7289, MAE: 4310.4092, R2: 0.0343\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1392/5000] | Time: 0.29s\n",
      "(Training) Loss: 1117315.8331\n",
      "(Validation) Loss: 1145631.1060, MAE: 4306.7104, R2: 0.0345\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1393/5000] | Time: 0.33s\n",
      "(Training) Loss: 1106709.3820\n",
      "(Validation) Loss: 1145421.3740, MAE: 4305.5796, R2: 0.0347\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1394/5000] | Time: 0.28s\n",
      "(Training) Loss: 1125070.1923\n",
      "(Validation) Loss: 1145217.6406, MAE: 4306.1465, R2: 0.0348\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1395/5000] | Time: 0.30s\n",
      "(Training) Loss: 1100897.2259\n",
      "(Validation) Loss: 1145005.4451, MAE: 4305.8413, R2: 0.0350\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1396/5000] | Time: 0.32s\n",
      "(Training) Loss: 1107590.2697\n",
      "(Validation) Loss: 1144794.2146, MAE: 4304.1675, R2: 0.0352\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1397/5000] | Time: 0.33s\n",
      "(Training) Loss: 1099786.4914\n",
      "(Validation) Loss: 1144590.8775, MAE: 4305.3398, R2: 0.0354\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1398/5000] | Time: 0.27s\n",
      "(Training) Loss: 1107939.6466\n",
      "(Validation) Loss: 1144379.7384, MAE: 4302.5215, R2: 0.0355\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1399/5000] | Time: 0.41s\n",
      "(Training) Loss: 1105459.3014\n",
      "(Validation) Loss: 1144171.1238, MAE: 4301.5737, R2: 0.0357\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1400/5000] | Time: 0.27s\n",
      "(Training) Loss: 1096602.2633\n",
      "(Validation) Loss: 1143961.4527, MAE: 4300.9175, R2: 0.0359\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1401/5000] | Time: 0.30s\n",
      "(Training) Loss: 1106768.3788\n",
      "(Validation) Loss: 1143756.9473, MAE: 4301.0825, R2: 0.0361\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1402/5000] | Time: 0.27s\n",
      "(Training) Loss: 1103467.2329\n",
      "(Validation) Loss: 1143549.8921, MAE: 4300.9731, R2: 0.0362\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1403/5000] | Time: 0.26s\n",
      "(Training) Loss: 1094220.5879\n",
      "(Validation) Loss: 1143336.5384, MAE: 4300.5757, R2: 0.0364\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1404/5000] | Time: 0.28s\n",
      "(Training) Loss: 1105615.3090\n",
      "(Validation) Loss: 1143100.3073, MAE: 4304.4072, R2: 0.0366\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1405/5000] | Time: 0.28s\n",
      "(Training) Loss: 1109749.3794\n",
      "(Validation) Loss: 1142876.6781, MAE: 4299.1455, R2: 0.0368\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1406/5000] | Time: 0.28s\n",
      "(Training) Loss: 1115418.5711\n",
      "(Validation) Loss: 1142634.0063, MAE: 4289.7944, R2: 0.0370\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1407/5000] | Time: 0.36s\n",
      "(Training) Loss: 1119640.8591\n",
      "(Validation) Loss: 1142430.9181, MAE: 4294.0459, R2: 0.0372\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1408/5000] | Time: 0.39s\n",
      "(Training) Loss: 1105672.3731\n",
      "(Validation) Loss: 1142235.0832, MAE: 4296.9780, R2: 0.0373\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1409/5000] | Time: 0.26s\n",
      "(Training) Loss: 1096030.2525\n",
      "(Validation) Loss: 1142007.8883, MAE: 4291.3818, R2: 0.0375\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1410/5000] | Time: 0.26s\n",
      "(Training) Loss: 1092513.9004\n",
      "(Validation) Loss: 1141789.3994, MAE: 4286.6890, R2: 0.0377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1411/5000] | Time: 0.25s\n",
      "(Training) Loss: 1127812.6282\n",
      "(Validation) Loss: 1141618.6413, MAE: 4291.6050, R2: 0.0378\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1412/5000] | Time: 0.29s\n",
      "(Training) Loss: 1103447.2989\n",
      "(Validation) Loss: 1141365.1048, MAE: 4283.3711, R2: 0.0381\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1413/5000] | Time: 0.25s\n",
      "(Training) Loss: 1101425.6358\n",
      "(Validation) Loss: 1141164.0787, MAE: 4285.3125, R2: 0.0382\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1414/5000] | Time: 0.24s\n",
      "(Training) Loss: 1090937.4702\n",
      "(Validation) Loss: 1140952.4317, MAE: 4282.5205, R2: 0.0384\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1415/5000] | Time: 0.22s\n",
      "(Training) Loss: 1105510.1028\n",
      "(Validation) Loss: 1140734.5321, MAE: 4282.0898, R2: 0.0386\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1416/5000] | Time: 0.22s\n",
      "(Training) Loss: 1097726.7418\n",
      "(Validation) Loss: 1140518.6590, MAE: 4279.9185, R2: 0.0388\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1417/5000] | Time: 0.23s\n",
      "(Training) Loss: 1088352.3425\n",
      "(Validation) Loss: 1140333.8514, MAE: 4286.1924, R2: 0.0389\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1418/5000] | Time: 0.23s\n",
      "(Training) Loss: 1118210.1383\n",
      "(Validation) Loss: 1140138.7632, MAE: 4283.9683, R2: 0.0391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1419/5000] | Time: 0.20s\n",
      "(Training) Loss: 1103318.0057\n",
      "(Validation) Loss: 1139952.8432, MAE: 4284.9087, R2: 0.0392\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1420/5000] | Time: 0.21s\n",
      "(Training) Loss: 1098142.6548\n",
      "(Validation) Loss: 1139715.0222, MAE: 4280.4458, R2: 0.0394\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1421/5000] | Time: 0.21s\n",
      "(Training) Loss: 1098074.0730\n",
      "(Validation) Loss: 1139520.9194, MAE: 4283.9268, R2: 0.0396\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1422/5000] | Time: 0.24s\n",
      "(Training) Loss: 1088383.5630\n",
      "(Validation) Loss: 1139297.9606, MAE: 4276.9121, R2: 0.0398\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1423/5000] | Time: 0.24s\n",
      "(Training) Loss: 1130504.8909\n",
      "(Validation) Loss: 1139092.1600, MAE: 4275.1719, R2: 0.0400\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1424/5000] | Time: 0.22s\n",
      "(Training) Loss: 1104842.5869\n",
      "(Validation) Loss: 1138882.1537, MAE: 4276.1401, R2: 0.0401\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1425/5000] | Time: 0.24s\n",
      "(Training) Loss: 1100621.0381\n",
      "(Validation) Loss: 1138710.3695, MAE: 4281.9707, R2: 0.0403\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1426/5000] | Time: 0.22s\n",
      "(Training) Loss: 1098538.5463\n",
      "(Validation) Loss: 1138465.8997, MAE: 4274.6411, R2: 0.0405\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1427/5000] | Time: 0.24s\n",
      "(Training) Loss: 1119332.0054\n",
      "(Validation) Loss: 1138292.5003, MAE: 4274.8232, R2: 0.0406\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1428/5000] | Time: 0.21s\n",
      "(Training) Loss: 1098510.2221\n",
      "(Validation) Loss: 1138102.2476, MAE: 4278.3291, R2: 0.0408\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1429/5000] | Time: 0.22s\n",
      "(Training) Loss: 1102860.9518\n",
      "(Validation) Loss: 1137922.2298, MAE: 4286.6621, R2: 0.0409\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1430/5000] | Time: 0.22s\n",
      "(Training) Loss: 1119108.6656\n",
      "(Validation) Loss: 1137671.8984, MAE: 4274.0469, R2: 0.0411\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1431/5000] | Time: 0.24s\n",
      "(Training) Loss: 1104384.3122\n",
      "(Validation) Loss: 1137458.5346, MAE: 4271.7026, R2: 0.0413\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1432/5000] | Time: 0.28s\n",
      "(Training) Loss: 1095076.4029\n",
      "(Validation) Loss: 1137256.6349, MAE: 4271.8936, R2: 0.0415\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1433/5000] | Time: 0.25s\n",
      "(Training) Loss: 1099371.5850\n",
      "(Validation) Loss: 1137058.2502, MAE: 4273.6709, R2: 0.0416\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1434/5000] | Time: 0.25s\n",
      "(Training) Loss: 1105196.8287\n",
      "(Validation) Loss: 1136839.4159, MAE: 4269.8374, R2: 0.0418\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1435/5000] | Time: 0.31s\n",
      "(Training) Loss: 1098561.0926\n",
      "(Validation) Loss: 1136630.2883, MAE: 4269.3374, R2: 0.0420\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1436/5000] | Time: 0.29s\n",
      "(Training) Loss: 1111116.4829\n",
      "(Validation) Loss: 1136433.3765, MAE: 4271.5205, R2: 0.0422\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1437/5000] | Time: 0.24s\n",
      "(Training) Loss: 1087300.9898\n",
      "(Validation) Loss: 1136219.5352, MAE: 4268.8442, R2: 0.0423\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1438/5000] | Time: 0.28s\n",
      "(Training) Loss: 1087746.5355\n",
      "(Validation) Loss: 1136014.8470, MAE: 4267.7935, R2: 0.0425\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1439/5000] | Time: 0.27s\n",
      "(Training) Loss: 1126985.5977\n",
      "(Validation) Loss: 1135815.1771, MAE: 4267.1123, R2: 0.0427\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1440/5000] | Time: 0.25s\n",
      "(Training) Loss: 1109304.7081\n",
      "(Validation) Loss: 1135605.1098, MAE: 4266.4775, R2: 0.0429\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1441/5000] | Time: 0.27s\n",
      "(Training) Loss: 1094397.7951\n",
      "(Validation) Loss: 1135393.2952, MAE: 4267.4141, R2: 0.0430\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1442/5000] | Time: 0.30s\n",
      "(Training) Loss: 1091567.7234\n",
      "(Validation) Loss: 1135184.9702, MAE: 4264.1953, R2: 0.0432\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1443/5000] | Time: 0.32s\n",
      "(Training) Loss: 1090765.0159\n",
      "(Validation) Loss: 1134984.3708, MAE: 4265.0742, R2: 0.0434\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1444/5000] | Time: 0.33s\n",
      "(Training) Loss: 1085863.4851\n",
      "(Validation) Loss: 1134810.5244, MAE: 4270.5557, R2: 0.0435\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1445/5000] | Time: 0.26s\n",
      "(Training) Loss: 1084151.1886\n",
      "(Validation) Loss: 1134596.9778, MAE: 4264.8979, R2: 0.0437\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1446/5000] | Time: 0.26s\n",
      "(Training) Loss: 1094808.5355\n",
      "(Validation) Loss: 1134390.3441, MAE: 4263.5889, R2: 0.0439\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1447/5000] | Time: 0.23s\n",
      "(Training) Loss: 1106823.2836\n",
      "(Validation) Loss: 1134186.1537, MAE: 4262.3057, R2: 0.0440\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1448/5000] | Time: 0.26s\n",
      "(Training) Loss: 1090297.0838\n",
      "(Validation) Loss: 1133981.7498, MAE: 4263.5933, R2: 0.0442\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1449/5000] | Time: 0.32s\n",
      "(Training) Loss: 1094629.6656\n",
      "(Validation) Loss: 1133773.5111, MAE: 4261.6504, R2: 0.0444\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1450/5000] | Time: 0.27s\n",
      "(Training) Loss: 1088944.1390\n",
      "(Validation) Loss: 1133566.5778, MAE: 4260.0054, R2: 0.0446\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1451/5000] | Time: 0.28s\n",
      "(Training) Loss: 1083620.4562\n",
      "(Validation) Loss: 1133365.7905, MAE: 4260.8550, R2: 0.0447\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1452/5000] | Time: 0.34s\n",
      "(Training) Loss: 1083613.8718\n",
      "(Validation) Loss: 1133155.9771, MAE: 4259.5630, R2: 0.0449\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1453/5000] | Time: 0.30s\n",
      "(Training) Loss: 1102635.0761\n",
      "(Validation) Loss: 1132990.9892, MAE: 4264.3110, R2: 0.0450\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1454/5000] | Time: 0.33s\n",
      "(Training) Loss: 1088878.6713\n",
      "(Validation) Loss: 1132755.2000, MAE: 4260.5693, R2: 0.0452\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1455/5000] | Time: 0.32s\n",
      "(Training) Loss: 1093606.4886\n",
      "(Validation) Loss: 1132543.3702, MAE: 4259.6865, R2: 0.0454\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1456/5000] | Time: 0.25s\n",
      "(Training) Loss: 1108540.7985\n",
      "(Validation) Loss: 1132335.4311, MAE: 4257.7949, R2: 0.0456\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1457/5000] | Time: 0.30s\n",
      "(Training) Loss: 1087735.8890\n",
      "(Validation) Loss: 1132130.3416, MAE: 4257.8916, R2: 0.0457\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1458/5000] | Time: 0.25s\n",
      "(Training) Loss: 1080541.1416\n",
      "(Validation) Loss: 1131920.9194, MAE: 4256.9897, R2: 0.0459\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1459/5000] | Time: 0.27s\n",
      "(Training) Loss: 1110676.8388\n",
      "(Validation) Loss: 1131716.1498, MAE: 4255.3384, R2: 0.0461\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1460/5000] | Time: 0.28s\n",
      "(Training) Loss: 1101015.9315\n",
      "(Validation) Loss: 1131508.4190, MAE: 4253.7085, R2: 0.0463\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1461/5000] | Time: 0.25s\n",
      "(Training) Loss: 1112234.9683\n",
      "(Validation) Loss: 1131300.7898, MAE: 4253.0806, R2: 0.0464\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1462/5000] | Time: 0.39s\n",
      "(Training) Loss: 1093646.6542\n",
      "(Validation) Loss: 1131094.1359, MAE: 4254.6084, R2: 0.0466\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1463/5000] | Time: 0.30s\n",
      "(Training) Loss: 1102605.7062\n",
      "(Validation) Loss: 1130834.5600, MAE: 4249.1357, R2: 0.0468\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1464/5000] | Time: 0.31s\n",
      "(Training) Loss: 1086668.4302\n",
      "(Validation) Loss: 1130644.0990, MAE: 4249.1460, R2: 0.0470\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1465/5000] | Time: 0.31s\n",
      "(Training) Loss: 1090505.5888\n",
      "(Validation) Loss: 1134948.2006, MAE: 4273.5034, R2: 0.0435\n",
      "==========================================================================================\n",
      "Epoch [1466/5000] | Time: 0.21s\n",
      "(Training) Loss: 1107050.2043\n",
      "(Validation) Loss: 1130234.5448, MAE: 4248.3462, R2: 0.0473\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1467/5000] | Time: 0.29s\n",
      "(Training) Loss: 1088430.9626\n",
      "(Validation) Loss: 1130029.7295, MAE: 4248.0171, R2: 0.0475\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1468/5000] | Time: 0.26s\n",
      "(Training) Loss: 1094300.9524\n",
      "(Validation) Loss: 1129856.2692, MAE: 4249.6455, R2: 0.0476\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1469/5000] | Time: 0.24s\n",
      "(Training) Loss: 1077962.7688\n",
      "(Validation) Loss: 1129659.9213, MAE: 4250.0996, R2: 0.0478\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1470/5000] | Time: 0.23s\n",
      "(Training) Loss: 1099151.8445\n",
      "(Validation) Loss: 1129454.4152, MAE: 4248.1538, R2: 0.0480\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1471/5000] | Time: 0.22s\n",
      "(Training) Loss: 1098946.2005\n",
      "(Validation) Loss: 1129274.3619, MAE: 4249.4614, R2: 0.0481\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1472/5000] | Time: 0.24s\n",
      "(Training) Loss: 1084233.2468\n",
      "(Validation) Loss: 1129042.7276, MAE: 4248.6011, R2: 0.0483\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1473/5000] | Time: 0.22s\n",
      "(Training) Loss: 1092503.2602\n",
      "(Validation) Loss: 1128825.8337, MAE: 4244.4053, R2: 0.0485\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1474/5000] | Time: 0.22s\n",
      "(Training) Loss: 1088602.5184\n",
      "(Validation) Loss: 1128628.5105, MAE: 4246.5112, R2: 0.0487\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1475/5000] | Time: 0.21s\n",
      "(Training) Loss: 1108472.7779\n",
      "(Validation) Loss: 1128423.4819, MAE: 4244.5659, R2: 0.0488\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1476/5000] | Time: 0.20s\n",
      "(Training) Loss: 1084503.8585\n",
      "(Validation) Loss: 1128211.3575, MAE: 4243.6450, R2: 0.0490\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1477/5000] | Time: 0.23s\n",
      "(Training) Loss: 1094342.9772\n",
      "(Validation) Loss: 1128009.3206, MAE: 4243.4746, R2: 0.0492\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1478/5000] | Time: 0.21s\n",
      "(Training) Loss: 1094492.3192\n",
      "(Validation) Loss: 1127809.7778, MAE: 4244.5342, R2: 0.0493\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1479/5000] | Time: 0.33s\n",
      "(Training) Loss: 1094350.5102\n",
      "(Validation) Loss: 1127603.8298, MAE: 4243.4116, R2: 0.0495\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1480/5000] | Time: 0.23s\n",
      "(Training) Loss: 1097176.2494\n",
      "(Validation) Loss: 1127388.1651, MAE: 4239.5928, R2: 0.0497\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1481/5000] | Time: 0.19s\n",
      "(Training) Loss: 1087592.4131\n",
      "(Validation) Loss: 1127212.5308, MAE: 4242.7827, R2: 0.0498\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1482/5000] | Time: 0.19s\n",
      "(Training) Loss: 1114357.2145\n",
      "(Validation) Loss: 1127000.7467, MAE: 4243.0610, R2: 0.0500\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1483/5000] | Time: 0.70s\n",
      "(Training) Loss: 1085518.7246\n",
      "(Validation) Loss: 1126804.0838, MAE: 4241.2329, R2: 0.0502\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1484/5000] | Time: 0.28s\n",
      "(Training) Loss: 1089516.2132\n",
      "(Validation) Loss: 1126568.1575, MAE: 4239.5103, R2: 0.0504\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1485/5000] | Time: 0.39s\n",
      "(Training) Loss: 1075412.6161\n",
      "(Validation) Loss: 1126362.0724, MAE: 4237.8242, R2: 0.0506\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1486/5000] | Time: 0.73s\n",
      "(Training) Loss: 1079296.7132\n",
      "(Validation) Loss: 1126159.1111, MAE: 4237.1094, R2: 0.0507\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1487/5000] | Time: 0.76s\n",
      "(Training) Loss: 1087928.0133\n",
      "(Validation) Loss: 1125957.7397, MAE: 4236.9697, R2: 0.0509\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1488/5000] | Time: 0.76s\n",
      "(Training) Loss: 1084036.2684\n",
      "(Validation) Loss: 1125751.5022, MAE: 4235.1333, R2: 0.0511\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1489/5000] | Time: 0.82s\n",
      "(Training) Loss: 1086394.7678\n",
      "(Validation) Loss: 1125544.6044, MAE: 4233.5117, R2: 0.0512\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1490/5000] | Time: 0.80s\n",
      "(Training) Loss: 1074950.5539\n",
      "(Validation) Loss: 1125342.2476, MAE: 4234.2202, R2: 0.0514\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1491/5000] | Time: 0.70s\n",
      "(Training) Loss: 1083574.7944\n",
      "(Validation) Loss: 1125177.3511, MAE: 4234.6377, R2: 0.0515\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1492/5000] | Time: 0.41s\n",
      "(Training) Loss: 1100903.0051\n",
      "(Validation) Loss: 1124931.8502, MAE: 4231.9331, R2: 0.0517\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1493/5000] | Time: 0.73s\n",
      "(Training) Loss: 1079134.3357\n",
      "(Validation) Loss: 1124737.2800, MAE: 4235.1973, R2: 0.0519\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1494/5000] | Time: 0.70s\n",
      "(Training) Loss: 1089899.0812\n",
      "(Validation) Loss: 1124527.3092, MAE: 4233.4170, R2: 0.0521\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1495/5000] | Time: 0.80s\n",
      "(Training) Loss: 1086899.9778\n",
      "(Validation) Loss: 1124313.9708, MAE: 4228.8081, R2: 0.0523\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1496/5000] | Time: 0.74s\n",
      "(Training) Loss: 1082032.5793\n",
      "(Validation) Loss: 1124107.4184, MAE: 4228.7461, R2: 0.0524\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1497/5000] | Time: 0.72s\n",
      "(Training) Loss: 1079855.9879\n",
      "(Validation) Loss: 1123906.7632, MAE: 4229.0781, R2: 0.0526\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1498/5000] | Time: 0.72s\n",
      "(Training) Loss: 1087179.3350\n",
      "(Validation) Loss: 1123703.2381, MAE: 4227.2012, R2: 0.0528\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1499/5000] | Time: 0.75s\n",
      "(Training) Loss: 1084422.6066\n",
      "(Validation) Loss: 1123497.4273, MAE: 4228.8833, R2: 0.0529\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1500/5000] | Time: 0.76s\n",
      "(Training) Loss: 1093096.3452\n",
      "(Validation) Loss: 1123303.7308, MAE: 4229.0049, R2: 0.0531\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch1500.pth\n",
      "==========================================================================================\n",
      "Epoch [1501/5000] | Time: 0.84s\n",
      "(Training) Loss: 1090860.5552\n",
      "(Validation) Loss: 1123055.8933, MAE: 4224.3110, R2: 0.0533\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1502/5000] | Time: 0.91s\n",
      "(Training) Loss: 1103392.8344\n",
      "(Validation) Loss: 1122878.2425, MAE: 4225.6528, R2: 0.0535\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1503/5000] | Time: 0.81s\n",
      "(Training) Loss: 1082002.0431\n",
      "(Validation) Loss: 1122635.7943, MAE: 4224.0142, R2: 0.0537\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1504/5000] | Time: 0.78s\n",
      "(Training) Loss: 1096387.2341\n",
      "(Validation) Loss: 1122452.8000, MAE: 4226.2524, R2: 0.0538\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1505/5000] | Time: 0.73s\n",
      "(Training) Loss: 1075406.7259\n",
      "(Validation) Loss: 1122233.1327, MAE: 4220.7690, R2: 0.0540\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1506/5000] | Time: 0.80s\n",
      "(Training) Loss: 1080978.0324\n",
      "(Validation) Loss: 1122018.5346, MAE: 4222.8433, R2: 0.0542\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1507/5000] | Time: 0.71s\n",
      "(Training) Loss: 1078957.2107\n",
      "(Validation) Loss: 1121810.5244, MAE: 4218.8667, R2: 0.0543\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1508/5000] | Time: 0.67s\n",
      "(Training) Loss: 1098736.7164\n",
      "(Validation) Loss: 1121606.3340, MAE: 4217.0596, R2: 0.0545\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1509/5000] | Time: 0.72s\n",
      "(Training) Loss: 1088778.2595\n",
      "(Validation) Loss: 1121403.3321, MAE: 4218.2778, R2: 0.0547\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1510/5000] | Time: 0.78s\n",
      "(Training) Loss: 1082628.8109\n",
      "(Validation) Loss: 1121191.7816, MAE: 4214.6348, R2: 0.0549\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1511/5000] | Time: 0.61s\n",
      "(Training) Loss: 1076725.3534\n",
      "(Validation) Loss: 1120994.2908, MAE: 4216.5356, R2: 0.0550\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1512/5000] | Time: 0.33s\n",
      "(Training) Loss: 1110800.2075\n",
      "(Validation) Loss: 1120790.0952, MAE: 4214.0596, R2: 0.0552\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1513/5000] | Time: 0.28s\n",
      "(Training) Loss: 1084078.3985\n",
      "(Validation) Loss: 1120598.2375, MAE: 4216.0400, R2: 0.0554\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1514/5000] | Time: 0.28s\n",
      "(Training) Loss: 1092144.7110\n",
      "(Validation) Loss: 1120375.3651, MAE: 4213.5386, R2: 0.0555\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1515/5000] | Time: 0.36s\n",
      "(Training) Loss: 1082678.0673\n",
      "(Validation) Loss: 1120166.4254, MAE: 4211.2998, R2: 0.0557\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1516/5000] | Time: 0.28s\n",
      "(Training) Loss: 1086910.7944\n",
      "(Validation) Loss: 1119965.9987, MAE: 4212.6821, R2: 0.0559\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1517/5000] | Time: 0.78s\n",
      "(Training) Loss: 1076982.0990\n",
      "(Validation) Loss: 1119773.5975, MAE: 4210.9688, R2: 0.0560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1518/5000] | Time: 0.82s\n",
      "(Training) Loss: 1096553.3344\n",
      "(Validation) Loss: 1119573.0438, MAE: 4211.5127, R2: 0.0562\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1519/5000] | Time: 0.92s\n",
      "(Training) Loss: 1076396.7811\n",
      "(Validation) Loss: 1119370.4025, MAE: 4211.2607, R2: 0.0564\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1520/5000] | Time: 0.63s\n",
      "(Training) Loss: 1068672.7148\n",
      "(Validation) Loss: 1119181.9479, MAE: 4211.7710, R2: 0.0565\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1521/5000] | Time: 0.31s\n",
      "(Training) Loss: 1068357.9761\n",
      "(Validation) Loss: 1119007.8476, MAE: 4213.3950, R2: 0.0567\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1522/5000] | Time: 0.28s\n",
      "(Training) Loss: 1078020.4714\n",
      "(Validation) Loss: 1118808.3149, MAE: 4213.8481, R2: 0.0568\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1523/5000] | Time: 0.29s\n",
      "(Training) Loss: 1090601.8883\n",
      "(Validation) Loss: 1118609.8692, MAE: 4215.1401, R2: 0.0570\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1524/5000] | Time: 0.26s\n",
      "(Training) Loss: 1086330.8832\n",
      "(Validation) Loss: 1118426.9917, MAE: 4213.5171, R2: 0.0572\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1525/5000] | Time: 0.29s\n",
      "(Training) Loss: 1075102.3541\n",
      "(Validation) Loss: 1118237.3130, MAE: 4216.6602, R2: 0.0573\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1526/5000] | Time: 0.30s\n",
      "(Training) Loss: 1078959.4816\n",
      "(Validation) Loss: 1118024.1321, MAE: 4213.8594, R2: 0.0575\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1527/5000] | Time: 0.28s\n",
      "(Training) Loss: 1097412.6529\n",
      "(Validation) Loss: 1117817.8946, MAE: 4212.7437, R2: 0.0577\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1528/5000] | Time: 0.27s\n",
      "(Training) Loss: 1079265.2398\n",
      "(Validation) Loss: 1117610.5448, MAE: 4212.1763, R2: 0.0578\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1529/5000] | Time: 0.30s\n",
      "(Training) Loss: 1074013.6377\n",
      "(Validation) Loss: 1117411.4083, MAE: 4211.8164, R2: 0.0580\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1530/5000] | Time: 0.30s\n",
      "(Training) Loss: 1075065.5400\n",
      "(Validation) Loss: 1117204.2768, MAE: 4211.0669, R2: 0.0582\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1531/5000] | Time: 0.30s\n",
      "(Training) Loss: 1066742.9095\n",
      "(Validation) Loss: 1117002.8241, MAE: 4209.4141, R2: 0.0583\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1532/5000] | Time: 0.28s\n",
      "(Training) Loss: 1087256.1789\n",
      "(Validation) Loss: 1116797.4603, MAE: 4208.4458, R2: 0.0585\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1533/5000] | Time: 0.30s\n",
      "(Training) Loss: 1077022.6599\n",
      "(Validation) Loss: 1116592.8076, MAE: 4209.2456, R2: 0.0587\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1534/5000] | Time: 0.29s\n",
      "(Training) Loss: 1094027.2817\n",
      "(Validation) Loss: 1116389.0844, MAE: 4207.6753, R2: 0.0589\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1535/5000] | Time: 0.31s\n",
      "(Training) Loss: 1079542.2982\n",
      "(Validation) Loss: 1116182.3187, MAE: 4206.5098, R2: 0.0590\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1536/5000] | Time: 0.32s\n",
      "(Training) Loss: 1088954.3744\n",
      "(Validation) Loss: 1115997.2978, MAE: 4210.3369, R2: 0.0592\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1537/5000] | Time: 0.28s\n",
      "(Training) Loss: 1075858.7411\n",
      "(Validation) Loss: 1115806.9638, MAE: 4206.8164, R2: 0.0593\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1538/5000] | Time: 0.28s\n",
      "(Training) Loss: 1101736.6669\n",
      "(Validation) Loss: 1115599.1568, MAE: 4207.3833, R2: 0.0595\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1539/5000] | Time: 0.27s\n",
      "(Training) Loss: 1078368.1548\n",
      "(Validation) Loss: 1115375.2076, MAE: 4206.3940, R2: 0.0597\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1540/5000] | Time: 0.30s\n",
      "(Training) Loss: 1092375.5590\n",
      "(Validation) Loss: 1115163.8857, MAE: 4203.5225, R2: 0.0599\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1541/5000] | Time: 0.33s\n",
      "(Training) Loss: 1083695.5184\n",
      "(Validation) Loss: 1114958.2578, MAE: 4202.7627, R2: 0.0601\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1542/5000] | Time: 0.31s\n",
      "(Training) Loss: 1070888.1009\n",
      "(Validation) Loss: 1114755.5454, MAE: 4203.0449, R2: 0.0602\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1543/5000] | Time: 0.25s\n",
      "(Training) Loss: 1074518.1332\n",
      "(Validation) Loss: 1114560.1727, MAE: 4203.4912, R2: 0.0604\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1544/5000] | Time: 0.26s\n",
      "(Training) Loss: 1085578.9220\n",
      "(Validation) Loss: 1114355.7841, MAE: 4203.1782, R2: 0.0606\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1545/5000] | Time: 0.26s\n",
      "(Training) Loss: 1078512.7221\n",
      "(Validation) Loss: 1114109.7498, MAE: 4196.5879, R2: 0.0608\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1546/5000] | Time: 0.28s\n",
      "(Training) Loss: 1084766.1751\n",
      "(Validation) Loss: 1113964.5816, MAE: 4201.4639, R2: 0.0609\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1547/5000] | Time: 0.25s\n",
      "(Training) Loss: 1081665.4505\n",
      "(Validation) Loss: 1113739.5759, MAE: 4200.0928, R2: 0.0611\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1548/5000] | Time: 0.30s\n",
      "(Training) Loss: 1073995.2310\n",
      "(Validation) Loss: 1113537.2190, MAE: 4199.4624, R2: 0.0612\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1549/5000] | Time: 0.26s\n",
      "(Training) Loss: 1076155.0235\n",
      "(Validation) Loss: 1113327.4210, MAE: 4197.3599, R2: 0.0614\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1550/5000] | Time: 0.26s\n",
      "(Training) Loss: 1071245.2373\n",
      "(Validation) Loss: 1113128.6248, MAE: 4197.8452, R2: 0.0616\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1551/5000] | Time: 0.26s\n",
      "(Training) Loss: 1072633.5025\n",
      "(Validation) Loss: 1112924.5511, MAE: 4196.3843, R2: 0.0617\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1552/5000] | Time: 0.25s\n",
      "(Training) Loss: 1080710.2690\n",
      "(Validation) Loss: 1112721.9657, MAE: 4195.5073, R2: 0.0619\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1553/5000] | Time: 0.26s\n",
      "(Training) Loss: 1093755.0831\n",
      "(Validation) Loss: 1112517.6990, MAE: 4194.4185, R2: 0.0621\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1554/5000] | Time: 0.32s\n",
      "(Training) Loss: 1070593.1612\n",
      "(Validation) Loss: 1112319.3092, MAE: 4194.5322, R2: 0.0622\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1555/5000] | Time: 0.28s\n",
      "(Training) Loss: 1064978.6846\n",
      "(Validation) Loss: 1112129.3663, MAE: 4198.8599, R2: 0.0624\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1556/5000] | Time: 0.27s\n",
      "(Training) Loss: 1083409.9492\n",
      "(Validation) Loss: 1111950.0190, MAE: 4196.4087, R2: 0.0626\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1557/5000] | Time: 0.31s\n",
      "(Training) Loss: 1073170.8426\n",
      "(Validation) Loss: 1111745.5543, MAE: 4195.1465, R2: 0.0627\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1558/5000] | Time: 0.30s\n",
      "(Training) Loss: 1086663.9131\n",
      "(Validation) Loss: 1111538.7073, MAE: 4194.9404, R2: 0.0629\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1559/5000] | Time: 0.27s\n",
      "(Training) Loss: 1070182.4829\n",
      "(Validation) Loss: 1111338.1029, MAE: 4194.7290, R2: 0.0631\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1560/5000] | Time: 0.28s\n",
      "(Training) Loss: 1072852.6701\n",
      "(Validation) Loss: 1111136.7060, MAE: 4194.1938, R2: 0.0632\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1561/5000] | Time: 0.28s\n",
      "(Training) Loss: 1061809.1948\n",
      "(Validation) Loss: 1110936.0711, MAE: 4193.8965, R2: 0.0634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1562/5000] | Time: 0.43s\n",
      "(Training) Loss: 1103787.0558\n",
      "(Validation) Loss: 1116061.1149, MAE: 4214.7109, R2: 0.0591\n",
      "==========================================================================================\n",
      "Epoch [1563/5000] | Time: 0.26s\n",
      "(Training) Loss: 1088751.8471\n",
      "(Validation) Loss: 1110532.5054, MAE: 4193.5430, R2: 0.0637\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1564/5000] | Time: 0.25s\n",
      "(Training) Loss: 1082150.8109\n",
      "(Validation) Loss: 1110324.5460, MAE: 4193.0342, R2: 0.0639\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1565/5000] | Time: 0.28s\n",
      "(Training) Loss: 1085227.9213\n",
      "(Validation) Loss: 1110123.1898, MAE: 4191.1201, R2: 0.0641\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1566/5000] | Time: 0.28s\n",
      "(Training) Loss: 1084643.6136\n",
      "(Validation) Loss: 1109921.2749, MAE: 4190.6230, R2: 0.0642\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1567/5000] | Time: 0.38s\n",
      "(Training) Loss: 1063757.7900\n",
      "(Validation) Loss: 1109718.1663, MAE: 4189.1665, R2: 0.0644\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1568/5000] | Time: 0.24s\n",
      "(Training) Loss: 1080334.3953\n",
      "(Validation) Loss: 1109516.9168, MAE: 4189.0645, R2: 0.0646\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1569/5000] | Time: 0.27s\n",
      "(Training) Loss: 1102706.0013\n",
      "(Validation) Loss: 1109308.5156, MAE: 4187.3057, R2: 0.0648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1570/5000] | Time: 0.25s\n",
      "(Training) Loss: 1080677.7944\n",
      "(Validation) Loss: 1109104.0508, MAE: 4186.2432, R2: 0.0649\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1571/5000] | Time: 0.24s\n",
      "(Training) Loss: 1064622.5876\n",
      "(Validation) Loss: 1108904.8229, MAE: 4186.7065, R2: 0.0651\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1572/5000] | Time: 0.26s\n",
      "(Training) Loss: 1069181.0374\n",
      "(Validation) Loss: 1108702.6844, MAE: 4186.0913, R2: 0.0653\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1573/5000] | Time: 0.23s\n",
      "(Training) Loss: 1068235.2246\n",
      "(Validation) Loss: 1108520.2083, MAE: 4193.2021, R2: 0.0654\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1574/5000] | Time: 0.24s\n",
      "(Training) Loss: 1059477.0823\n",
      "(Validation) Loss: 1108298.7530, MAE: 4185.8926, R2: 0.0656\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1575/5000] | Time: 0.31s\n",
      "(Training) Loss: 1076598.4461\n",
      "(Validation) Loss: 1108102.8419, MAE: 4184.9600, R2: 0.0658\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1576/5000] | Time: 0.31s\n",
      "(Training) Loss: 1064064.3179\n",
      "(Validation) Loss: 1107902.3898, MAE: 4183.2471, R2: 0.0659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1577/5000] | Time: 0.25s\n",
      "(Training) Loss: 1058564.7070\n",
      "(Validation) Loss: 1107698.2705, MAE: 4182.9438, R2: 0.0661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1578/5000] | Time: 0.26s\n",
      "(Training) Loss: 1064444.9277\n",
      "(Validation) Loss: 1107490.1892, MAE: 4180.5576, R2: 0.0663\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1579/5000] | Time: 0.26s\n",
      "(Training) Loss: 1070517.0774\n",
      "(Validation) Loss: 1107337.7473, MAE: 4183.8794, R2: 0.0664\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1580/5000] | Time: 0.54s\n",
      "(Training) Loss: 1085410.7576\n",
      "(Validation) Loss: 1107103.3346, MAE: 4183.3989, R2: 0.0666\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1581/5000] | Time: 0.35s\n",
      "(Training) Loss: 1059202.8997\n",
      "(Validation) Loss: 1106889.8184, MAE: 4180.2358, R2: 0.0668\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1582/5000] | Time: 0.31s\n",
      "(Training) Loss: 1074582.1345\n",
      "(Validation) Loss: 1106683.5606, MAE: 4177.7837, R2: 0.0669\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1583/5000] | Time: 0.29s\n",
      "(Training) Loss: 1062683.7208\n",
      "(Validation) Loss: 1106482.2857, MAE: 4177.0693, R2: 0.0671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1584/5000] | Time: 0.29s\n",
      "(Training) Loss: 1072598.4010\n",
      "(Validation) Loss: 1106284.8102, MAE: 4178.1357, R2: 0.0673\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1585/5000] | Time: 0.37s\n",
      "(Training) Loss: 1081450.4340\n",
      "(Validation) Loss: 1106076.3175, MAE: 4175.5195, R2: 0.0674\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1586/5000] | Time: 0.74s\n",
      "(Training) Loss: 1065692.5806\n",
      "(Validation) Loss: 1105878.3695, MAE: 4175.5312, R2: 0.0676\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1587/5000] | Time: 0.57s\n",
      "(Training) Loss: 1059370.9695\n",
      "(Validation) Loss: 1105671.7460, MAE: 4172.8955, R2: 0.0678\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1588/5000] | Time: 0.83s\n",
      "(Training) Loss: 1079549.8211\n",
      "(Validation) Loss: 1105474.7530, MAE: 4174.6631, R2: 0.0680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1589/5000] | Time: 0.84s\n",
      "(Training) Loss: 1062761.1935\n",
      "(Validation) Loss: 1105282.1283, MAE: 4174.8174, R2: 0.0681\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1590/5000] | Time: 0.92s\n",
      "(Training) Loss: 1061671.8217\n",
      "(Validation) Loss: 1105083.8298, MAE: 4177.3589, R2: 0.0683\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1591/5000] | Time: 0.91s\n",
      "(Training) Loss: 1057275.2088\n",
      "(Validation) Loss: 1104909.4603, MAE: 4174.3345, R2: 0.0684\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1592/5000] | Time: 0.77s\n",
      "(Training) Loss: 1058522.2747\n",
      "(Validation) Loss: 1104712.8432, MAE: 4174.3516, R2: 0.0686\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1593/5000] | Time: 0.32s\n",
      "(Training) Loss: 1063965.0999\n",
      "(Validation) Loss: 1104529.2089, MAE: 4177.0811, R2: 0.0687\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1594/5000] | Time: 0.25s\n",
      "(Training) Loss: 1076059.6916\n",
      "(Validation) Loss: 1104305.9403, MAE: 4172.0679, R2: 0.0689\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1595/5000] | Time: 0.21s\n",
      "(Training) Loss: 1074608.3077\n",
      "(Validation) Loss: 1104102.8521, MAE: 4170.8711, R2: 0.0691\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1596/5000] | Time: 0.27s\n",
      "(Training) Loss: 1059442.5787\n",
      "(Validation) Loss: 1103900.0229, MAE: 4170.4985, R2: 0.0693\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1597/5000] | Time: 0.25s\n",
      "(Training) Loss: 1055144.5025\n",
      "(Validation) Loss: 1103702.6641, MAE: 4170.6548, R2: 0.0694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1598/5000] | Time: 0.24s\n",
      "(Training) Loss: 1062223.4549\n",
      "(Validation) Loss: 1103504.7670, MAE: 4170.0640, R2: 0.0696\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1599/5000] | Time: 0.23s\n",
      "(Training) Loss: 1064575.2481\n",
      "(Validation) Loss: 1103301.1454, MAE: 4170.1064, R2: 0.0698\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1600/5000] | Time: 0.26s\n",
      "(Training) Loss: 1058956.6567\n",
      "(Validation) Loss: 1103094.8419, MAE: 4167.2456, R2: 0.0699\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1601/5000] | Time: 0.23s\n",
      "(Training) Loss: 1058580.6060\n",
      "(Validation) Loss: 1102893.7600, MAE: 4166.6431, R2: 0.0701\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1602/5000] | Time: 0.30s\n",
      "(Training) Loss: 1057546.3668\n",
      "(Validation) Loss: 1102696.0610, MAE: 4167.0640, R2: 0.0703\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1603/5000] | Time: 0.31s\n",
      "(Training) Loss: 1067266.7088\n",
      "(Validation) Loss: 1102492.7238, MAE: 4165.3276, R2: 0.0704\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1604/5000] | Time: 0.30s\n",
      "(Training) Loss: 1077826.5711\n",
      "(Validation) Loss: 1102289.4781, MAE: 4165.4106, R2: 0.0706\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1605/5000] | Time: 0.26s\n",
      "(Training) Loss: 1070981.2931\n",
      "(Validation) Loss: 1102089.0159, MAE: 4165.4175, R2: 0.0708\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1606/5000] | Time: 0.25s\n",
      "(Training) Loss: 1076523.1999\n",
      "(Validation) Loss: 1098503.3498, MAE: 4155.3467, R2: 0.0738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1607/5000] | Time: 0.27s\n",
      "(Training) Loss: 1052028.0089\n",
      "(Validation) Loss: 1098300.3073, MAE: 4152.9043, R2: 0.0739\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1608/5000] | Time: 0.23s\n",
      "(Training) Loss: 1053026.8420\n",
      "(Validation) Loss: 1098076.3886, MAE: 4152.4053, R2: 0.0741\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1609/5000] | Time: 0.22s\n",
      "(Training) Loss: 1056028.1662\n",
      "(Validation) Loss: 1097877.9378, MAE: 4150.9053, R2: 0.0743\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1610/5000] | Time: 0.22s\n",
      "(Training) Loss: 1076868.3598\n",
      "(Validation) Loss: 1097680.3810, MAE: 4150.0269, R2: 0.0744\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1611/5000] | Time: 0.22s\n",
      "(Training) Loss: 1079908.3033\n",
      "(Validation) Loss: 1097452.7238, MAE: 4145.5225, R2: 0.0746\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1612/5000] | Time: 0.48s\n",
      "(Training) Loss: 1054088.9334\n",
      "(Validation) Loss: 1097253.4400, MAE: 4145.4775, R2: 0.0748\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1613/5000] | Time: 0.24s\n",
      "(Training) Loss: 1054091.9657\n",
      "(Validation) Loss: 1097064.1930, MAE: 4152.8726, R2: 0.0750\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1614/5000] | Time: 0.25s\n",
      "(Training) Loss: 1058278.7931\n",
      "(Validation) Loss: 1096897.0108, MAE: 4148.6357, R2: 0.0751\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1615/5000] | Time: 0.24s\n",
      "(Training) Loss: 1049138.0068\n",
      "(Validation) Loss: 1096690.0063, MAE: 4144.3330, R2: 0.0753\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1616/5000] | Time: 0.24s\n",
      "(Training) Loss: 1051801.1206\n",
      "(Validation) Loss: 1096493.9683, MAE: 4144.0903, R2: 0.0754\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1617/5000] | Time: 0.22s\n",
      "(Training) Loss: 1048605.6196\n",
      "(Validation) Loss: 1096298.5549, MAE: 4143.5400, R2: 0.0756\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1618/5000] | Time: 0.23s\n",
      "(Training) Loss: 1060625.0533\n",
      "(Validation) Loss: 1096118.5930, MAE: 4145.8823, R2: 0.0757\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1619/5000] | Time: 0.22s\n",
      "(Training) Loss: 1053392.3115\n",
      "(Validation) Loss: 1095906.9714, MAE: 4140.7783, R2: 0.0759\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1620/5000] | Time: 0.23s\n",
      "(Training) Loss: 1053555.4359\n",
      "(Validation) Loss: 1095712.7010, MAE: 4140.3506, R2: 0.0761\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1621/5000] | Time: 0.22s\n",
      "(Training) Loss: 1056444.6402\n",
      "(Validation) Loss: 1095516.2971, MAE: 4139.1792, R2: 0.0762\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1622/5000] | Time: 0.25s\n",
      "(Training) Loss: 1058056.7525\n",
      "(Validation) Loss: 1095321.8286, MAE: 4139.7554, R2: 0.0764\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1623/5000] | Time: 0.23s\n",
      "(Training) Loss: 1052126.5108\n",
      "(Validation) Loss: 1095149.1962, MAE: 4145.5356, R2: 0.0766\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1624/5000] | Time: 0.21s\n",
      "(Training) Loss: 1059804.8871\n",
      "(Validation) Loss: 1094927.6648, MAE: 4137.9419, R2: 0.0767\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1625/5000] | Time: 0.27s\n",
      "(Training) Loss: 1056813.8585\n",
      "(Validation) Loss: 1094732.7340, MAE: 4138.2373, R2: 0.0769\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1626/5000] | Time: 0.25s\n",
      "(Training) Loss: 1059753.3338\n",
      "(Validation) Loss: 1094532.7695, MAE: 4135.5430, R2: 0.0771\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1627/5000] | Time: 0.26s\n",
      "(Training) Loss: 1057660.6434\n",
      "(Validation) Loss: 1094348.9575, MAE: 4138.5161, R2: 0.0772\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1628/5000] | Time: 0.29s\n",
      "(Training) Loss: 1048486.0121\n",
      "(Validation) Loss: 1094167.2178, MAE: 4143.4790, R2: 0.0774\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1629/5000] | Time: 0.27s\n",
      "(Training) Loss: 1065396.0133\n",
      "(Validation) Loss: 1093948.0838, MAE: 4135.0225, R2: 0.0776\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1630/5000] | Time: 0.26s\n",
      "(Training) Loss: 1079637.9708\n",
      "(Validation) Loss: 1093746.2197, MAE: 4131.4805, R2: 0.0777\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1631/5000] | Time: 0.29s\n",
      "(Training) Loss: 1056915.2113\n",
      "(Validation) Loss: 1093555.0222, MAE: 4133.5293, R2: 0.0779\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1632/5000] | Time: 0.27s\n",
      "(Training) Loss: 1047637.2611\n",
      "(Validation) Loss: 1093360.5079, MAE: 4133.2759, R2: 0.0780\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1633/5000] | Time: 0.25s\n",
      "(Training) Loss: 1052036.2081\n",
      "(Validation) Loss: 1093156.8356, MAE: 4130.8101, R2: 0.0782\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1634/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046300.9689\n",
      "(Validation) Loss: 1092963.0781, MAE: 4130.3809, R2: 0.0784\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1635/5000] | Time: 0.30s\n",
      "(Training) Loss: 1071628.2963\n",
      "(Validation) Loss: 1092777.4070, MAE: 4130.8608, R2: 0.0785\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1636/5000] | Time: 0.24s\n",
      "(Training) Loss: 1065259.8668\n",
      "(Validation) Loss: 1092569.9860, MAE: 4129.0083, R2: 0.0787\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1637/5000] | Time: 0.23s\n",
      "(Training) Loss: 1043851.2635\n",
      "(Validation) Loss: 1092375.8425, MAE: 4129.0698, R2: 0.0789\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1638/5000] | Time: 0.24s\n",
      "(Training) Loss: 1083980.1802\n",
      "(Validation) Loss: 1092184.8990, MAE: 4128.1890, R2: 0.0790\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1639/5000] | Time: 0.24s\n",
      "(Training) Loss: 1085105.3991\n",
      "(Validation) Loss: 1091983.9644, MAE: 4127.1685, R2: 0.0792\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1640/5000] | Time: 0.24s\n",
      "(Training) Loss: 1044324.3717\n",
      "(Validation) Loss: 1091790.2629, MAE: 4127.6899, R2: 0.0794\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1641/5000] | Time: 0.22s\n",
      "(Training) Loss: 1050804.2868\n",
      "(Validation) Loss: 1091610.7632, MAE: 4129.1924, R2: 0.0795\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1642/5000] | Time: 0.20s\n",
      "(Training) Loss: 1059759.2970\n",
      "(Validation) Loss: 1091396.0330, MAE: 4126.0542, R2: 0.0797\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1643/5000] | Time: 0.22s\n",
      "(Training) Loss: 1045309.7011\n",
      "(Validation) Loss: 1091207.3143, MAE: 4126.6230, R2: 0.0798\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1644/5000] | Time: 0.23s\n",
      "(Training) Loss: 1082557.8769\n",
      "(Validation) Loss: 1090998.6387, MAE: 4124.0840, R2: 0.0800\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1645/5000] | Time: 0.26s\n",
      "(Training) Loss: 1059373.7329\n",
      "(Validation) Loss: 1090807.8679, MAE: 4123.8052, R2: 0.0802\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1646/5000] | Time: 0.22s\n",
      "(Training) Loss: 1066021.8915\n",
      "(Validation) Loss: 1090606.1359, MAE: 4121.9907, R2: 0.0803\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1647/5000] | Time: 0.24s\n",
      "(Training) Loss: 1052370.4708\n",
      "(Validation) Loss: 1090413.9225, MAE: 4121.6494, R2: 0.0805\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1648/5000] | Time: 0.23s\n",
      "(Training) Loss: 1047176.6015\n",
      "(Validation) Loss: 1090219.9010, MAE: 4122.0527, R2: 0.0807\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1649/5000] | Time: 0.28s\n",
      "(Training) Loss: 1064939.7189\n",
      "(Validation) Loss: 1090022.7911, MAE: 4120.1938, R2: 0.0808\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1650/5000] | Time: 0.27s\n",
      "(Training) Loss: 1068905.7716\n",
      "(Validation) Loss: 1089826.1638, MAE: 4119.6152, R2: 0.0810\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1651/5000] | Time: 0.32s\n",
      "(Training) Loss: 1053079.2176\n",
      "(Validation) Loss: 1089631.8425, MAE: 4119.7744, R2: 0.0812\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1652/5000] | Time: 0.30s\n",
      "(Training) Loss: 1054549.0831\n",
      "(Validation) Loss: 1089428.7797, MAE: 4117.2383, R2: 0.0813\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1653/5000] | Time: 0.28s\n",
      "(Training) Loss: 1050464.1345\n",
      "(Validation) Loss: 1089240.2540, MAE: 4118.2051, R2: 0.0815\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1654/5000] | Time: 0.28s\n",
      "(Training) Loss: 1052278.8008\n",
      "(Validation) Loss: 1089040.8229, MAE: 4116.8135, R2: 0.0816\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1655/5000] | Time: 0.32s\n",
      "(Training) Loss: 1045607.8490\n",
      "(Validation) Loss: 1088848.5638, MAE: 4116.7344, R2: 0.0818\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1656/5000] | Time: 0.33s\n",
      "(Training) Loss: 1041921.3093\n",
      "(Validation) Loss: 1088652.3581, MAE: 4116.7173, R2: 0.0820\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1657/5000] | Time: 0.31s\n",
      "(Training) Loss: 1046528.8750\n",
      "(Validation) Loss: 1088459.5352, MAE: 4114.4023, R2: 0.0821\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1658/5000] | Time: 0.31s\n",
      "(Training) Loss: 1052295.8484\n",
      "(Validation) Loss: 1088271.8171, MAE: 4116.3813, R2: 0.0823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1659/5000] | Time: 0.30s\n",
      "(Training) Loss: 1058208.1935\n",
      "(Validation) Loss: 1093628.8762, MAE: 4140.9165, R2: 0.0778\n",
      "==========================================================================================\n",
      "Epoch [1660/5000] | Time: 0.29s\n",
      "(Training) Loss: 1066530.4302\n",
      "(Validation) Loss: 1093438.7098, MAE: 4139.1201, R2: 0.0780\n",
      "==========================================================================================\n",
      "Epoch [1661/5000] | Time: 0.26s\n",
      "(Training) Loss: 1058105.5584\n",
      "(Validation) Loss: 1093232.0813, MAE: 4133.0107, R2: 0.0782\n",
      "==========================================================================================\n",
      "Epoch [1662/5000] | Time: 0.26s\n",
      "(Training) Loss: 1062501.1478\n",
      "(Validation) Loss: 1093043.5708, MAE: 4132.2412, R2: 0.0783\n",
      "==========================================================================================\n",
      "Epoch [1663/5000] | Time: 0.36s\n",
      "(Training) Loss: 1043807.5523\n",
      "(Validation) Loss: 1092845.0489, MAE: 4129.9678, R2: 0.0785\n",
      "==========================================================================================\n",
      "Epoch [1664/5000] | Time: 0.29s\n",
      "(Training) Loss: 1050696.0945\n",
      "(Validation) Loss: 1092653.4349, MAE: 4129.3643, R2: 0.0786\n",
      "==========================================================================================\n",
      "Epoch [1665/5000] | Time: 0.30s\n",
      "(Training) Loss: 1050471.0368\n",
      "(Validation) Loss: 1092462.6997, MAE: 4129.1509, R2: 0.0788\n",
      "==========================================================================================\n",
      "Epoch [1666/5000] | Time: 0.30s\n",
      "(Training) Loss: 1066503.0501\n",
      "(Validation) Loss: 1092271.2787, MAE: 4128.9263, R2: 0.0790\n",
      "==========================================================================================\n",
      "Epoch [1667/5000] | Time: 0.31s\n",
      "(Training) Loss: 1064573.9867\n",
      "(Validation) Loss: 1092074.3771, MAE: 4127.9854, R2: 0.0791\n",
      "==========================================================================================\n",
      "Epoch [1668/5000] | Time: 0.26s\n",
      "(Training) Loss: 1068010.4619\n",
      "(Validation) Loss: 1091918.2883, MAE: 4130.2671, R2: 0.0792\n",
      "==========================================================================================\n",
      "Epoch [1669/5000] | Time: 0.28s\n",
      "(Training) Loss: 1051450.9975\n",
      "(Validation) Loss: 1091722.4889, MAE: 4129.1348, R2: 0.0794\n",
      "==========================================================================================\n",
      "Epoch [1670/5000] | Time: 0.26s\n",
      "(Training) Loss: 1053108.1802\n",
      "(Validation) Loss: 1091530.0165, MAE: 4129.4883, R2: 0.0796\n",
      "==========================================================================================\n",
      "Epoch [1671/5000] | Time: 0.26s\n",
      "(Training) Loss: 1055263.3845\n",
      "(Validation) Loss: 1091339.0832, MAE: 4127.8076, R2: 0.0797\n",
      "==========================================================================================\n",
      "Epoch [1672/5000] | Time: 0.26s\n",
      "(Training) Loss: 1064875.8274\n",
      "(Validation) Loss: 1091150.3594, MAE: 4128.3589, R2: 0.0799\n",
      "==========================================================================================\n",
      "Epoch [1673/5000] | Time: 0.26s\n",
      "(Training) Loss: 1071894.3173\n",
      "(Validation) Loss: 1090959.1619, MAE: 4130.2153, R2: 0.0800\n",
      "==========================================================================================\n",
      "Epoch [1674/5000] | Time: 0.29s\n",
      "(Training) Loss: 1055960.3147\n",
      "(Validation) Loss: 1090759.3092, MAE: 4127.5132, R2: 0.0802\n",
      "==========================================================================================\n",
      "Epoch [1675/5000] | Time: 0.26s\n",
      "(Training) Loss: 1046470.9004\n",
      "(Validation) Loss: 1090563.5098, MAE: 4127.4927, R2: 0.0804\n",
      "==========================================================================================\n",
      "Epoch [1676/5000] | Time: 0.26s\n",
      "(Training) Loss: 1055442.4105\n",
      "(Validation) Loss: 1090370.3467, MAE: 4126.0273, R2: 0.0805\n",
      "==========================================================================================\n",
      "Epoch [1677/5000] | Time: 0.31s\n",
      "(Training) Loss: 1047393.5286\n",
      "(Validation) Loss: 1090186.7479, MAE: 4125.8398, R2: 0.0807\n",
      "==========================================================================================\n",
      "Epoch [1678/5000] | Time: 0.33s\n",
      "(Training) Loss: 1048141.9416\n",
      "(Validation) Loss: 1089981.1860, MAE: 4123.6357, R2: 0.0809\n",
      "==========================================================================================\n",
      "Epoch [1679/5000] | Time: 0.28s\n",
      "(Training) Loss: 1066193.7906\n",
      "(Validation) Loss: 1089793.7422, MAE: 4123.1304, R2: 0.0810\n",
      "==========================================================================================\n",
      "Epoch [1680/5000] | Time: 0.31s\n",
      "(Training) Loss: 1051672.0546\n",
      "(Validation) Loss: 1089604.3733, MAE: 4123.1509, R2: 0.0812\n",
      "==========================================================================================\n",
      "Epoch [1681/5000] | Time: 0.30s\n",
      "(Training) Loss: 1053964.9175\n",
      "(Validation) Loss: 1089403.8857, MAE: 4122.3018, R2: 0.0813\n",
      "==========================================================================================\n",
      "Epoch [1682/5000] | Time: 0.31s\n",
      "(Training) Loss: 1059777.5977\n",
      "(Validation) Loss: 1089210.7987, MAE: 4120.4653, R2: 0.0815\n",
      "==========================================================================================\n",
      "Epoch [1683/5000] | Time: 0.28s\n",
      "(Training) Loss: 1057925.7272\n",
      "(Validation) Loss: 1089019.2203, MAE: 4120.0195, R2: 0.0817\n",
      "==========================================================================================\n",
      "Epoch [1684/5000] | Time: 0.27s\n",
      "(Training) Loss: 1064605.5076\n",
      "(Validation) Loss: 1088824.5790, MAE: 4118.4224, R2: 0.0818\n",
      "==========================================================================================\n",
      "Epoch [1685/5000] | Time: 0.34s\n",
      "(Training) Loss: 1042426.7437\n",
      "(Validation) Loss: 1088630.7200, MAE: 4118.5605, R2: 0.0820\n",
      "==========================================================================================\n",
      "Epoch [1686/5000] | Time: 0.23s\n",
      "(Training) Loss: 1072340.9134\n",
      "(Validation) Loss: 1088440.8076, MAE: 4117.6216, R2: 0.0821\n",
      "==========================================================================================\n",
      "Epoch [1687/5000] | Time: 0.24s\n",
      "(Training) Loss: 1059678.6929\n",
      "(Validation) Loss: 1088245.0286, MAE: 4117.1582, R2: 0.0823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1688/5000] | Time: 0.35s\n",
      "(Training) Loss: 1083025.9708\n",
      "(Validation) Loss: 1088051.3829, MAE: 4115.9507, R2: 0.0825\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1689/5000] | Time: 0.34s\n",
      "(Training) Loss: 1055900.2468\n",
      "(Validation) Loss: 1087865.7219, MAE: 4118.6948, R2: 0.0826\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1690/5000] | Time: 0.22s\n",
      "(Training) Loss: 1061456.7652\n",
      "(Validation) Loss: 1087665.4171, MAE: 4116.1865, R2: 0.0828\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1691/5000] | Time: 0.21s\n",
      "(Training) Loss: 1069939.0546\n",
      "(Validation) Loss: 1087475.0222, MAE: 4114.9131, R2: 0.0829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1692/5000] | Time: 0.20s\n",
      "(Training) Loss: 1063734.1028\n",
      "(Validation) Loss: 1087287.4565, MAE: 4116.2661, R2: 0.0831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1693/5000] | Time: 0.18s\n",
      "(Training) Loss: 1064402.6942\n",
      "(Validation) Loss: 1087084.9321, MAE: 4112.9526, R2: 0.0833\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1694/5000] | Time: 0.20s\n",
      "(Training) Loss: 1054094.5057\n",
      "(Validation) Loss: 1086889.6711, MAE: 4113.2817, R2: 0.0834\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1695/5000] | Time: 0.20s\n",
      "(Training) Loss: 1052194.2640\n",
      "(Validation) Loss: 1086702.1257, MAE: 4112.7593, R2: 0.0836\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1696/5000] | Time: 0.20s\n",
      "(Training) Loss: 1070255.7005\n",
      "(Validation) Loss: 1086506.3771, MAE: 4110.5376, R2: 0.0838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1697/5000] | Time: 0.19s\n",
      "(Training) Loss: 1038295.8636\n",
      "(Validation) Loss: 1086312.3098, MAE: 4110.3232, R2: 0.0839\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1698/5000] | Time: 0.19s\n",
      "(Training) Loss: 1049533.6409\n",
      "(Validation) Loss: 1086129.5441, MAE: 4110.9995, R2: 0.0841\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1699/5000] | Time: 0.21s\n",
      "(Training) Loss: 1041639.3274\n",
      "(Validation) Loss: 1085934.7556, MAE: 4109.9678, R2: 0.0842\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1700/5000] | Time: 0.19s\n",
      "(Training) Loss: 1044825.2703\n",
      "(Validation) Loss: 1085756.7797, MAE: 4113.1992, R2: 0.0844\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1701/5000] | Time: 0.18s\n",
      "(Training) Loss: 1056347.8065\n",
      "(Validation) Loss: 1085554.7987, MAE: 4109.2139, R2: 0.0845\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1702/5000] | Time: 0.26s\n",
      "(Training) Loss: 1042535.8598\n",
      "(Validation) Loss: 1085425.0413, MAE: 4116.6650, R2: 0.0847\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1703/5000] | Time: 0.27s\n",
      "(Training) Loss: 1047689.5666\n",
      "(Validation) Loss: 1085213.8159, MAE: 4109.3125, R2: 0.0848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1704/5000] | Time: 0.18s\n",
      "(Training) Loss: 1055960.4099\n",
      "(Validation) Loss: 1085024.2794, MAE: 4109.1167, R2: 0.0850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1705/5000] | Time: 0.20s\n",
      "(Training) Loss: 1049029.1022\n",
      "(Validation) Loss: 1084836.8406, MAE: 4109.8462, R2: 0.0851\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1706/5000] | Time: 0.21s\n",
      "(Training) Loss: 1041493.7874\n",
      "(Validation) Loss: 1084641.8438, MAE: 4108.5864, R2: 0.0853\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1707/5000] | Time: 0.23s\n",
      "(Training) Loss: 1052454.4442\n",
      "(Validation) Loss: 1084450.7835, MAE: 4106.7383, R2: 0.0855\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1708/5000] | Time: 0.66s\n",
      "(Training) Loss: 1041124.8334\n",
      "(Validation) Loss: 1084261.2013, MAE: 4107.8398, R2: 0.0856\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1709/5000] | Time: 0.31s\n",
      "(Training) Loss: 1059541.0419\n",
      "(Validation) Loss: 1084069.6889, MAE: 4107.0874, R2: 0.0858\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1710/5000] | Time: 0.40s\n",
      "(Training) Loss: 1055826.2189\n",
      "(Validation) Loss: 1083873.2851, MAE: 4104.9722, R2: 0.0859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1711/5000] | Time: 0.94s\n",
      "(Training) Loss: 1068462.5565\n",
      "(Validation) Loss: 1083683.3981, MAE: 4104.8965, R2: 0.0861\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1712/5000] | Time: 0.80s\n",
      "(Training) Loss: 1062979.5095\n",
      "(Validation) Loss: 1083486.9841, MAE: 4103.3535, R2: 0.0863\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1713/5000] | Time: 0.77s\n",
      "(Training) Loss: 1053549.8096\n",
      "(Validation) Loss: 1083304.3149, MAE: 4106.1675, R2: 0.0864\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1714/5000] | Time: 0.87s\n",
      "(Training) Loss: 1036262.6004\n",
      "(Validation) Loss: 1083105.1632, MAE: 4103.0977, R2: 0.0866\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1715/5000] | Time: 0.99s\n",
      "(Training) Loss: 1074669.9826\n",
      "(Validation) Loss: 1082917.8108, MAE: 4103.8726, R2: 0.0867\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1716/5000] | Time: 0.87s\n",
      "(Training) Loss: 1068617.6294\n",
      "(Validation) Loss: 1082777.9962, MAE: 4106.0381, R2: 0.0869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1717/5000] | Time: 0.80s\n",
      "(Training) Loss: 1051310.3591\n",
      "(Validation) Loss: 1082583.3448, MAE: 4105.5586, R2: 0.0870\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1718/5000] | Time: 0.87s\n",
      "(Training) Loss: 1040402.3642\n",
      "(Validation) Loss: 1082390.6692, MAE: 4104.0352, R2: 0.0872\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1719/5000] | Time: 0.86s\n",
      "(Training) Loss: 1039836.1853\n",
      "(Validation) Loss: 1082203.3981, MAE: 4104.2119, R2: 0.0873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1720/5000] | Time: 0.84s\n",
      "(Training) Loss: 1046713.6599\n",
      "(Validation) Loss: 1082012.4597, MAE: 4103.0151, R2: 0.0875\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1721/5000] | Time: 0.73s\n",
      "(Training) Loss: 1052597.2982\n",
      "(Validation) Loss: 1081824.4622, MAE: 4102.6675, R2: 0.0877\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1722/5000] | Time: 0.78s\n",
      "(Training) Loss: 1051105.4886\n",
      "(Validation) Loss: 1081634.2248, MAE: 4103.1924, R2: 0.0878\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1723/5000] | Time: 0.83s\n",
      "(Training) Loss: 1056517.6371\n",
      "(Validation) Loss: 1081439.5276, MAE: 4101.3672, R2: 0.0880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1724/5000] | Time: 0.83s\n",
      "(Training) Loss: 1035352.8658\n",
      "(Validation) Loss: 1081245.8565, MAE: 4100.3457, R2: 0.0881\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1725/5000] | Time: 0.82s\n",
      "(Training) Loss: 1039240.9918\n",
      "(Validation) Loss: 1081056.7060, MAE: 4099.2437, R2: 0.0883\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1726/5000] | Time: 0.91s\n",
      "(Training) Loss: 1037363.4258\n",
      "(Validation) Loss: 1080866.2248, MAE: 4098.0850, R2: 0.0884\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1727/5000] | Time: 0.98s\n",
      "(Training) Loss: 1042517.8020\n",
      "(Validation) Loss: 1080678.8267, MAE: 4097.7510, R2: 0.0886\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1728/5000] | Time: 0.81s\n",
      "(Training) Loss: 1045820.0590\n",
      "(Validation) Loss: 1080486.8825, MAE: 4097.0415, R2: 0.0888\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1729/5000] | Time: 1.04s\n",
      "(Training) Loss: 1056024.7525\n",
      "(Validation) Loss: 1080298.5041, MAE: 4096.7559, R2: 0.0889\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1730/5000] | Time: 0.83s\n",
      "(Training) Loss: 1040466.0317\n",
      "(Validation) Loss: 1080106.4483, MAE: 4096.4526, R2: 0.0891\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1731/5000] | Time: 0.92s\n",
      "(Training) Loss: 1045890.3934\n",
      "(Validation) Loss: 1079913.2038, MAE: 4095.4124, R2: 0.0892\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1732/5000] | Time: 1.01s\n",
      "(Training) Loss: 1040765.9283\n",
      "(Validation) Loss: 1079728.0610, MAE: 4096.2935, R2: 0.0894\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1733/5000] | Time: 1.02s\n",
      "(Training) Loss: 1043188.4359\n",
      "(Validation) Loss: 1079534.0394, MAE: 4095.2200, R2: 0.0896\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1734/5000] | Time: 0.94s\n",
      "(Training) Loss: 1051305.9036\n",
      "(Validation) Loss: 1079360.3149, MAE: 4096.4380, R2: 0.0897\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1735/5000] | Time: 1.03s\n",
      "(Training) Loss: 1042199.2303\n",
      "(Validation) Loss: 1079154.7632, MAE: 4092.9951, R2: 0.0899\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1736/5000] | Time: 1.05s\n",
      "(Training) Loss: 1061269.8027\n",
      "(Validation) Loss: 1078966.8419, MAE: 4092.5437, R2: 0.0900\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1737/5000] | Time: 1.04s\n",
      "(Training) Loss: 1032434.2838\n",
      "(Validation) Loss: 1078770.8800, MAE: 4091.2515, R2: 0.0902\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1738/5000] | Time: 0.99s\n",
      "(Training) Loss: 1071854.6732\n",
      "(Validation) Loss: 1078588.4495, MAE: 4092.5032, R2: 0.0903\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1739/5000] | Time: 0.97s\n",
      "(Training) Loss: 1042091.5577\n",
      "(Validation) Loss: 1078395.4184, MAE: 4091.9238, R2: 0.0905\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1740/5000] | Time: 0.78s\n",
      "(Training) Loss: 1041544.2773\n",
      "(Validation) Loss: 1078205.0286, MAE: 4092.3247, R2: 0.0907\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1741/5000] | Time: 0.78s\n",
      "(Training) Loss: 1054729.3299\n",
      "(Validation) Loss: 1078015.7156, MAE: 4091.1113, R2: 0.0908\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1742/5000] | Time: 0.87s\n",
      "(Training) Loss: 1046063.6777\n",
      "(Validation) Loss: 1077816.0762, MAE: 4088.8701, R2: 0.0910\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1743/5000] | Time: 1.14s\n",
      "(Training) Loss: 1059439.5451\n",
      "(Validation) Loss: 1077663.0857, MAE: 4090.3308, R2: 0.0911\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1744/5000] | Time: 1.18s\n",
      "(Training) Loss: 1038616.9162\n",
      "(Validation) Loss: 1077442.3822, MAE: 4088.8518, R2: 0.0913\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1745/5000] | Time: 0.98s\n",
      "(Training) Loss: 1034714.7684\n",
      "(Validation) Loss: 1077246.2476, MAE: 4087.7029, R2: 0.0915\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1746/5000] | Time: 0.90s\n",
      "(Training) Loss: 1050290.8280\n",
      "(Validation) Loss: 1077118.2375, MAE: 4090.9958, R2: 0.0916\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1747/5000] | Time: 1.07s\n",
      "(Training) Loss: 1039504.8185\n",
      "(Validation) Loss: 1076930.0724, MAE: 4089.5588, R2: 0.0917\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1748/5000] | Time: 1.07s\n",
      "(Training) Loss: 1051188.1612\n",
      "(Validation) Loss: 1076742.0038, MAE: 4087.7229, R2: 0.0919\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1749/5000] | Time: 1.12s\n",
      "(Training) Loss: 1047057.8274\n",
      "(Validation) Loss: 1076550.6946, MAE: 4087.6609, R2: 0.0920\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1750/5000] | Time: 0.85s\n",
      "(Training) Loss: 1052790.7792\n",
      "(Validation) Loss: 1076368.9549, MAE: 4089.3838, R2: 0.0922\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1751/5000] | Time: 0.67s\n",
      "(Training) Loss: 1039244.6650\n",
      "(Validation) Loss: 1076179.8248, MAE: 4091.4387, R2: 0.0924\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1752/5000] | Time: 0.61s\n",
      "(Training) Loss: 1044286.9137\n",
      "(Validation) Loss: 1075985.8946, MAE: 4087.5837, R2: 0.0925\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1753/5000] | Time: 0.86s\n",
      "(Training) Loss: 1046014.9784\n",
      "(Validation) Loss: 1075791.7156, MAE: 4085.4595, R2: 0.0927\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1754/5000] | Time: 0.75s\n",
      "(Training) Loss: 1059908.7589\n",
      "(Validation) Loss: 1075600.2946, MAE: 4083.2449, R2: 0.0928\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1755/5000] | Time: 1.04s\n",
      "(Training) Loss: 1031499.6923\n",
      "(Validation) Loss: 1075404.0381, MAE: 4082.9670, R2: 0.0930\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1756/5000] | Time: 0.84s\n",
      "(Training) Loss: 1040883.0216\n",
      "(Validation) Loss: 1075217.3359, MAE: 4083.2217, R2: 0.0932\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1757/5000] | Time: 0.75s\n",
      "(Training) Loss: 1040887.0711\n",
      "(Validation) Loss: 1075031.0044, MAE: 4083.2603, R2: 0.0933\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1758/5000] | Time: 0.77s\n",
      "(Training) Loss: 1036369.8953\n",
      "(Validation) Loss: 1074841.5086, MAE: 4082.4575, R2: 0.0935\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1759/5000] | Time: 0.88s\n",
      "(Training) Loss: 1027254.6749\n",
      "(Validation) Loss: 1074651.3676, MAE: 4081.8201, R2: 0.0936\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1760/5000] | Time: 0.87s\n",
      "(Training) Loss: 1044585.0311\n",
      "(Validation) Loss: 1074465.1784, MAE: 4080.8130, R2: 0.0938\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1761/5000] | Time: 0.89s\n",
      "(Training) Loss: 1053892.2113\n",
      "(Validation) Loss: 1074273.4679, MAE: 4079.8552, R2: 0.0939\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1762/5000] | Time: 0.91s\n",
      "(Training) Loss: 1045936.1282\n",
      "(Validation) Loss: 1074091.1340, MAE: 4083.5085, R2: 0.0941\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1763/5000] | Time: 0.74s\n",
      "(Training) Loss: 1028416.5993\n",
      "(Validation) Loss: 1073897.0667, MAE: 4081.8286, R2: 0.0943\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1764/5000] | Time: 0.47s\n",
      "(Training) Loss: 1028219.4134\n",
      "(Validation) Loss: 1073720.6552, MAE: 4083.7834, R2: 0.0944\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1765/5000] | Time: 0.98s\n",
      "(Training) Loss: 1037141.6935\n",
      "(Validation) Loss: 1073522.1486, MAE: 4079.4475, R2: 0.0946\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1766/5000] | Time: 1.06s\n",
      "(Training) Loss: 1032788.9746\n",
      "(Validation) Loss: 1073328.7975, MAE: 4076.3428, R2: 0.0947\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1767/5000] | Time: 0.96s\n",
      "(Training) Loss: 1043544.0635\n",
      "(Validation) Loss: 1073136.2387, MAE: 4075.5024, R2: 0.0949\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1768/5000] | Time: 1.01s\n",
      "(Training) Loss: 1040454.7303\n",
      "(Validation) Loss: 1072944.7619, MAE: 4074.0493, R2: 0.0950\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1769/5000] | Time: 0.50s\n",
      "(Training) Loss: 1031505.3947\n",
      "(Validation) Loss: 1072757.2978, MAE: 4074.2163, R2: 0.0952\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1770/5000] | Time: 0.24s\n",
      "(Training) Loss: 1049426.5799\n",
      "(Validation) Loss: 1072572.1041, MAE: 4075.9163, R2: 0.0954\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1771/5000] | Time: 0.22s\n",
      "(Training) Loss: 1030603.4258\n",
      "(Validation) Loss: 1072373.2521, MAE: 4071.9199, R2: 0.0955\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1772/5000] | Time: 0.27s\n",
      "(Training) Loss: 1047956.6091\n",
      "(Validation) Loss: 1072189.1911, MAE: 4071.8474, R2: 0.0957\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1773/5000] | Time: 0.24s\n",
      "(Training) Loss: 1055861.9708\n",
      "(Validation) Loss: 1071999.8933, MAE: 4071.5938, R2: 0.0958\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1774/5000] | Time: 0.25s\n",
      "(Training) Loss: 1034759.1935\n",
      "(Validation) Loss: 1071809.9556, MAE: 4072.6658, R2: 0.0960\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1775/5000] | Time: 0.25s\n",
      "(Training) Loss: 1043326.3832\n",
      "(Validation) Loss: 1071625.5390, MAE: 4073.2505, R2: 0.0961\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1776/5000] | Time: 0.22s\n",
      "(Training) Loss: 1036698.9626\n",
      "(Validation) Loss: 1071433.9352, MAE: 4072.7258, R2: 0.0963\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1777/5000] | Time: 0.24s\n",
      "(Training) Loss: 1025208.8298\n",
      "(Validation) Loss: 1071248.1168, MAE: 4071.0950, R2: 0.0965\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1778/5000] | Time: 0.23s\n",
      "(Training) Loss: 1041293.1631\n",
      "(Validation) Loss: 1071056.5587, MAE: 4070.7615, R2: 0.0966\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1779/5000] | Time: 0.19s\n",
      "(Training) Loss: 1041936.5679\n",
      "(Validation) Loss: 1070864.3708, MAE: 4067.9102, R2: 0.0968\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1780/5000] | Time: 0.21s\n",
      "(Training) Loss: 1029923.7582\n",
      "(Validation) Loss: 1070675.1848, MAE: 4067.9004, R2: 0.0969\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1781/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046218.3617\n",
      "(Validation) Loss: 1070492.0127, MAE: 4070.6089, R2: 0.0971\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1782/5000] | Time: 0.24s\n",
      "(Training) Loss: 1039567.0584\n",
      "(Validation) Loss: 1070298.0267, MAE: 4066.6292, R2: 0.0973\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1783/5000] | Time: 0.23s\n",
      "(Training) Loss: 1038610.4334\n",
      "(Validation) Loss: 1070113.9454, MAE: 4068.5298, R2: 0.0974\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1784/5000] | Time: 0.22s\n",
      "(Training) Loss: 1035638.7849\n",
      "(Validation) Loss: 1069921.1327, MAE: 4065.1250, R2: 0.0976\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1785/5000] | Time: 0.24s\n",
      "(Training) Loss: 1043762.2189\n",
      "(Validation) Loss: 1069728.1676, MAE: 4064.7832, R2: 0.0977\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1786/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023458.3369\n",
      "(Validation) Loss: 1069537.4324, MAE: 4063.3926, R2: 0.0979\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1787/5000] | Time: 0.24s\n",
      "(Training) Loss: 1033523.6555\n",
      "(Validation) Loss: 1069348.7644, MAE: 4061.9163, R2: 0.0980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1788/5000] | Time: 0.24s\n",
      "(Training) Loss: 1029893.1453\n",
      "(Validation) Loss: 1069165.7651, MAE: 4064.0103, R2: 0.0982\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1789/5000] | Time: 0.24s\n",
      "(Training) Loss: 1028620.6187\n",
      "(Validation) Loss: 1068977.5441, MAE: 4064.0420, R2: 0.0984\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1790/5000] | Time: 0.25s\n",
      "(Training) Loss: 1041615.9810\n",
      "(Validation) Loss: 1068799.8324, MAE: 4065.6716, R2: 0.0985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1791/5000] | Time: 0.34s\n",
      "(Training) Loss: 1033448.7887\n",
      "(Validation) Loss: 1068598.0698, MAE: 4060.5493, R2: 0.0987\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1792/5000] | Time: 0.26s\n",
      "(Training) Loss: 1028038.1501\n",
      "(Validation) Loss: 1068409.6051, MAE: 4059.5562, R2: 0.0988\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1793/5000] | Time: 0.25s\n",
      "(Training) Loss: 1022839.4507\n",
      "(Validation) Loss: 1068217.7219, MAE: 4058.6023, R2: 0.0990\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1794/5000] | Time: 0.28s\n",
      "(Training) Loss: 1041575.0558\n",
      "(Validation) Loss: 1068031.9035, MAE: 4058.6926, R2: 0.0991\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1795/5000] | Time: 0.32s\n",
      "(Training) Loss: 1037963.7183\n",
      "(Validation) Loss: 1067846.5422, MAE: 4060.7671, R2: 0.0993\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1796/5000] | Time: 0.29s\n",
      "(Training) Loss: 1043920.1599\n",
      "(Validation) Loss: 1067653.7854, MAE: 4055.8318, R2: 0.0995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1797/5000] | Time: 0.26s\n",
      "(Training) Loss: 1027544.9803\n",
      "(Validation) Loss: 1067468.9371, MAE: 4057.9050, R2: 0.0996\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1798/5000] | Time: 0.25s\n",
      "(Training) Loss: 1033393.7075\n",
      "(Validation) Loss: 1067275.5149, MAE: 4055.4888, R2: 0.0998\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1799/5000] | Time: 0.26s\n",
      "(Training) Loss: 1050028.1074\n",
      "(Validation) Loss: 1067093.0540, MAE: 4056.5720, R2: 0.0999\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1800/5000] | Time: 0.27s\n",
      "(Training) Loss: 1021748.2909\n",
      "(Validation) Loss: 1066897.6762, MAE: 4054.1975, R2: 0.1001\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1801/5000] | Time: 0.26s\n",
      "(Training) Loss: 1046511.5996\n",
      "(Validation) Loss: 1066708.2311, MAE: 4052.4653, R2: 0.1002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1802/5000] | Time: 0.27s\n",
      "(Training) Loss: 1032234.8769\n",
      "(Validation) Loss: 1066533.5873, MAE: 4057.3279, R2: 0.1004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1803/5000] | Time: 0.27s\n",
      "(Training) Loss: 1050738.1434\n",
      "(Validation) Loss: 1066336.0457, MAE: 4052.8276, R2: 0.1006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1804/5000] | Time: 0.27s\n",
      "(Training) Loss: 1032217.2291\n",
      "(Validation) Loss: 1066140.5003, MAE: 4050.2090, R2: 0.1007\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1805/5000] | Time: 0.27s\n",
      "(Training) Loss: 1021477.7234\n",
      "(Validation) Loss: 1065951.4971, MAE: 4049.8901, R2: 0.1009\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1806/5000] | Time: 0.29s\n",
      "(Training) Loss: 1021701.1463\n",
      "(Validation) Loss: 1065780.1194, MAE: 4054.5422, R2: 0.1010\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1807/5000] | Time: 0.37s\n",
      "(Training) Loss: 1029336.4410\n",
      "(Validation) Loss: 1065580.9727, MAE: 4047.9094, R2: 0.1012\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1808/5000] | Time: 0.37s\n",
      "(Training) Loss: 1019007.5581\n",
      "(Validation) Loss: 1065387.1898, MAE: 4057.5442, R2: 0.1013\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1809/5000] | Time: 0.27s\n",
      "(Training) Loss: 1040004.9042\n",
      "(Validation) Loss: 1065152.6857, MAE: 4044.6938, R2: 0.1015\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1810/5000] | Time: 0.24s\n",
      "(Training) Loss: 1030200.1015\n",
      "(Validation) Loss: 1065102.5321, MAE: 4056.2334, R2: 0.1016\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1811/5000] | Time: 0.24s\n",
      "(Training) Loss: 1021420.7443\n",
      "(Validation) Loss: 1064933.0337, MAE: 4059.3403, R2: 0.1017\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1812/5000] | Time: 0.28s\n",
      "(Training) Loss: 1023562.5964\n",
      "(Validation) Loss: 1064734.9283, MAE: 4057.1851, R2: 0.1019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1813/5000] | Time: 0.26s\n",
      "(Training) Loss: 1037925.4232\n",
      "(Validation) Loss: 1064542.5676, MAE: 4051.8562, R2: 0.1020\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1814/5000] | Time: 0.20s\n",
      "(Training) Loss: 1025916.2544\n",
      "(Validation) Loss: 1064347.6419, MAE: 4051.3835, R2: 0.1022\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1815/5000] | Time: 0.20s\n",
      "(Training) Loss: 1028617.1091\n",
      "(Validation) Loss: 1064155.3321, MAE: 4048.8818, R2: 0.1024\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1816/5000] | Time: 0.20s\n",
      "(Training) Loss: 1053611.4048\n",
      "(Validation) Loss: 1063965.9886, MAE: 4048.1143, R2: 0.1025\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1817/5000] | Time: 0.20s\n",
      "(Training) Loss: 1038507.7830\n",
      "(Validation) Loss: 1063775.0248, MAE: 4047.1113, R2: 0.1027\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1818/5000] | Time: 0.23s\n",
      "(Training) Loss: 1026689.6199\n",
      "(Validation) Loss: 1063593.9708, MAE: 4050.5144, R2: 0.1028\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1819/5000] | Time: 0.25s\n",
      "(Training) Loss: 1041986.8426\n",
      "(Validation) Loss: 1075245.6279, MAE: 4084.6963, R2: 0.0931\n",
      "==========================================================================================\n",
      "Epoch [1820/5000] | Time: 0.21s\n",
      "(Training) Loss: 1053184.6859\n",
      "(Validation) Loss: 1075076.5206, MAE: 4103.2593, R2: 0.0933\n",
      "==========================================================================================\n",
      "Epoch [1821/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046752.2246\n",
      "(Validation) Loss: 1074800.8483, MAE: 4084.0654, R2: 0.0935\n",
      "==========================================================================================\n",
      "Epoch [1822/5000] | Time: 0.22s\n",
      "(Training) Loss: 1036746.6053\n",
      "(Validation) Loss: 1074611.5556, MAE: 4084.5981, R2: 0.0937\n",
      "==========================================================================================\n",
      "Epoch [1823/5000] | Time: 0.21s\n",
      "(Training) Loss: 1056611.3065\n",
      "(Validation) Loss: 1074418.2044, MAE: 4082.2673, R2: 0.0938\n",
      "==========================================================================================\n",
      "Epoch [1824/5000] | Time: 0.29s\n",
      "(Training) Loss: 1038589.4467\n",
      "(Validation) Loss: 1074215.7460, MAE: 4078.7107, R2: 0.0940\n",
      "==========================================================================================\n",
      "Epoch [1825/5000] | Time: 0.23s\n",
      "(Training) Loss: 1029464.3277\n",
      "(Validation) Loss: 1074027.1898, MAE: 4077.7488, R2: 0.0941\n",
      "==========================================================================================\n",
      "Epoch [1826/5000] | Time: 0.23s\n",
      "(Training) Loss: 1039206.6821\n",
      "(Validation) Loss: 1073834.5143, MAE: 4077.2991, R2: 0.0943\n",
      "==========================================================================================\n",
      "Epoch [1827/5000] | Time: 0.28s\n",
      "(Training) Loss: 1038965.5349\n",
      "(Validation) Loss: 1073640.4013, MAE: 4073.9189, R2: 0.0945\n",
      "==========================================================================================\n",
      "Epoch [1828/5000] | Time: 0.32s\n",
      "(Training) Loss: 1030689.7535\n",
      "(Validation) Loss: 1073447.4768, MAE: 4073.5552, R2: 0.0946\n",
      "==========================================================================================\n",
      "Epoch [1829/5000] | Time: 0.30s\n",
      "(Training) Loss: 1028497.3553\n",
      "(Validation) Loss: 1073264.8025, MAE: 4073.8015, R2: 0.0948\n",
      "==========================================================================================\n",
      "Epoch [1830/5000] | Time: 0.33s\n",
      "(Training) Loss: 1038278.1561\n",
      "(Validation) Loss: 1073141.5162, MAE: 4076.3840, R2: 0.0949\n",
      "==========================================================================================\n",
      "Epoch [1831/5000] | Time: 0.27s\n",
      "(Training) Loss: 1057006.8896\n",
      "(Validation) Loss: 1072885.2622, MAE: 4072.3235, R2: 0.0951\n",
      "==========================================================================================\n",
      "Epoch [1832/5000] | Time: 0.33s\n",
      "(Training) Loss: 1038862.2322\n",
      "(Validation) Loss: 1072691.6521, MAE: 4071.6948, R2: 0.0953\n",
      "==========================================================================================\n",
      "Epoch [1833/5000] | Time: 0.31s\n",
      "(Training) Loss: 1054910.8553\n",
      "(Validation) Loss: 1072505.4222, MAE: 4073.0571, R2: 0.0954\n",
      "==========================================================================================\n",
      "Epoch [1834/5000] | Time: 0.36s\n",
      "(Training) Loss: 1041660.9543\n",
      "(Validation) Loss: 1072310.3543, MAE: 4072.0156, R2: 0.0956\n",
      "==========================================================================================\n",
      "Epoch [1835/5000] | Time: 0.33s\n",
      "(Training) Loss: 1048803.8852\n",
      "(Validation) Loss: 1072120.5587, MAE: 4070.1584, R2: 0.0957\n",
      "==========================================================================================\n",
      "Epoch [1836/5000] | Time: 0.29s\n",
      "(Training) Loss: 1039183.9365\n",
      "(Validation) Loss: 1071937.2648, MAE: 4071.4536, R2: 0.0959\n",
      "==========================================================================================\n",
      "Epoch [1837/5000] | Time: 0.30s\n",
      "(Training) Loss: 1052576.5704\n",
      "(Validation) Loss: 1071742.8622, MAE: 4069.8237, R2: 0.0961\n",
      "==========================================================================================\n",
      "Epoch [1838/5000] | Time: 0.28s\n",
      "(Training) Loss: 1038530.4708\n",
      "(Validation) Loss: 1071547.2152, MAE: 4068.7544, R2: 0.0962\n",
      "==========================================================================================\n",
      "Epoch [1839/5000] | Time: 0.31s\n",
      "(Training) Loss: 1035530.5241\n",
      "(Validation) Loss: 1071364.9371, MAE: 4070.7959, R2: 0.0964\n",
      "==========================================================================================\n",
      "Epoch [1840/5000] | Time: 0.29s\n",
      "(Training) Loss: 1035362.7551\n",
      "(Validation) Loss: 1071168.1321, MAE: 4066.6460, R2: 0.0965\n",
      "==========================================================================================\n",
      "Epoch [1841/5000] | Time: 0.30s\n",
      "(Training) Loss: 1023563.7767\n",
      "(Validation) Loss: 1070980.6679, MAE: 4066.8330, R2: 0.0967\n",
      "==========================================================================================\n",
      "Epoch [1842/5000] | Time: 0.27s\n",
      "(Training) Loss: 1040332.4258\n",
      "(Validation) Loss: 1070791.1924, MAE: 4065.1311, R2: 0.0968\n",
      "==========================================================================================\n",
      "Epoch [1843/5000] | Time: 0.28s\n",
      "(Training) Loss: 1026889.8858\n",
      "(Validation) Loss: 1070606.7352, MAE: 4067.1667, R2: 0.0970\n",
      "==========================================================================================\n",
      "Epoch [1844/5000] | Time: 0.33s\n",
      "(Training) Loss: 1024300.4445\n",
      "(Validation) Loss: 1070420.4698, MAE: 4066.7517, R2: 0.0972\n",
      "==========================================================================================\n",
      "Epoch [1845/5000] | Time: 0.33s\n",
      "(Training) Loss: 1022941.5634\n",
      "(Validation) Loss: 1070224.7416, MAE: 4064.3088, R2: 0.0973\n",
      "==========================================================================================\n",
      "Epoch [1846/5000] | Time: 0.29s\n",
      "(Training) Loss: 1047866.5127\n",
      "(Validation) Loss: 1070035.5302, MAE: 4062.9580, R2: 0.0975\n",
      "==========================================================================================\n",
      "Epoch [1847/5000] | Time: 0.32s\n",
      "(Training) Loss: 1045222.1656\n",
      "(Validation) Loss: 1069846.9232, MAE: 4062.1804, R2: 0.0976\n",
      "==========================================================================================\n",
      "Epoch [1848/5000] | Time: 0.30s\n",
      "(Training) Loss: 1022285.6213\n",
      "(Validation) Loss: 1069651.9162, MAE: 4061.8291, R2: 0.0978\n",
      "==========================================================================================\n",
      "Epoch [1849/5000] | Time: 0.29s\n",
      "(Training) Loss: 1029406.4283\n",
      "(Validation) Loss: 1069478.8775, MAE: 4064.9714, R2: 0.0979\n",
      "==========================================================================================\n",
      "Epoch [1850/5000] | Time: 0.35s\n",
      "(Training) Loss: 1046196.6510\n",
      "(Validation) Loss: 1069279.4717, MAE: 4059.6523, R2: 0.0981\n",
      "==========================================================================================\n",
      "Epoch [1851/5000] | Time: 0.31s\n",
      "(Training) Loss: 1038481.5311\n",
      "(Validation) Loss: 1069087.2127, MAE: 4059.1912, R2: 0.0983\n",
      "==========================================================================================\n",
      "Epoch [1852/5000] | Time: 0.31s\n",
      "(Training) Loss: 1065680.8699\n",
      "(Validation) Loss: 1068895.2127, MAE: 4058.2407, R2: 0.0984\n",
      "==========================================================================================\n",
      "Epoch [1853/5000] | Time: 0.25s\n",
      "(Training) Loss: 1059412.9829\n",
      "(Validation) Loss: 1068712.4724, MAE: 4059.0261, R2: 0.0986\n",
      "==========================================================================================\n",
      "Epoch [1854/5000] | Time: 0.30s\n",
      "(Training) Loss: 1033523.0806\n",
      "(Validation) Loss: 1080743.6089, MAE: 4111.2012, R2: 0.0885\n",
      "==========================================================================================\n",
      "Epoch [1855/5000] | Time: 0.33s\n",
      "(Training) Loss: 1043970.9378\n",
      "(Validation) Loss: 1076485.0946, MAE: 4091.0645, R2: 0.0921\n",
      "==========================================================================================\n",
      "Epoch [1856/5000] | Time: 0.28s\n",
      "(Training) Loss: 1044102.6244\n",
      "(Validation) Loss: 1076276.5257, MAE: 4089.0288, R2: 0.0923\n",
      "==========================================================================================\n",
      "Epoch [1857/5000] | Time: 0.31s\n",
      "(Training) Loss: 1046770.2088\n",
      "(Validation) Loss: 1076070.1206, MAE: 4085.9563, R2: 0.0924\n",
      "==========================================================================================\n",
      "Epoch [1858/5000] | Time: 0.26s\n",
      "(Training) Loss: 1066215.8065\n",
      "(Validation) Loss: 1075868.3429, MAE: 4084.3701, R2: 0.0926\n",
      "==========================================================================================\n",
      "Epoch [1859/5000] | Time: 0.36s\n",
      "(Training) Loss: 1036839.2208\n",
      "(Validation) Loss: 1075665.7930, MAE: 4084.4419, R2: 0.0928\n",
      "==========================================================================================\n",
      "Epoch [1860/5000] | Time: 0.33s\n",
      "(Training) Loss: 1042201.1358\n",
      "(Validation) Loss: 1075464.3708, MAE: 4082.2485, R2: 0.0929\n",
      "==========================================================================================\n",
      "Epoch [1861/5000] | Time: 0.36s\n",
      "(Training) Loss: 1055070.3972\n",
      "(Validation) Loss: 1075266.7733, MAE: 4083.1245, R2: 0.0931\n",
      "==========================================================================================\n",
      "Epoch [1862/5000] | Time: 0.28s\n",
      "(Training) Loss: 1032335.8959\n",
      "(Validation) Loss: 1075069.1302, MAE: 4083.0151, R2: 0.0933\n",
      "==========================================================================================\n",
      "Epoch [1863/5000] | Time: 0.29s\n",
      "(Training) Loss: 1048130.4467\n",
      "(Validation) Loss: 1074874.9105, MAE: 4081.6204, R2: 0.0934\n",
      "==========================================================================================\n",
      "Epoch [1864/5000] | Time: 0.34s\n",
      "(Training) Loss: 1062230.8261\n",
      "(Validation) Loss: 1074680.4216, MAE: 4081.4685, R2: 0.0936\n",
      "==========================================================================================\n",
      "Epoch [1865/5000] | Time: 0.25s\n",
      "(Training) Loss: 1031433.8877\n",
      "(Validation) Loss: 1074493.0184, MAE: 4082.2734, R2: 0.0938\n",
      "==========================================================================================\n",
      "Epoch [1866/5000] | Time: 0.35s\n",
      "(Training) Loss: 1030589.7107\n",
      "(Validation) Loss: 1074283.7435, MAE: 4078.8074, R2: 0.0939\n",
      "==========================================================================================\n",
      "Epoch [1867/5000] | Time: 0.29s\n",
      "(Training) Loss: 1046517.8788\n",
      "(Validation) Loss: 1074088.1067, MAE: 4078.0295, R2: 0.0941\n",
      "==========================================================================================\n",
      "Epoch [1868/5000] | Time: 0.31s\n",
      "(Training) Loss: 1028961.1494\n",
      "(Validation) Loss: 1073895.0806, MAE: 4078.3157, R2: 0.0943\n",
      "==========================================================================================\n",
      "Epoch [1869/5000] | Time: 0.27s\n",
      "(Training) Loss: 1050691.4905\n",
      "(Validation) Loss: 1073703.2584, MAE: 4077.5610, R2: 0.0944\n",
      "==========================================================================================\n",
      "Epoch [1870/5000] | Time: 0.31s\n",
      "(Training) Loss: 1039023.0013\n",
      "(Validation) Loss: 1073446.8521, MAE: 4076.6895, R2: 0.0946\n",
      "==========================================================================================\n",
      "Epoch [1871/5000] | Time: 0.31s\n",
      "(Training) Loss: 1052864.2570\n",
      "(Validation) Loss: 1067241.6305, MAE: 4062.9482, R2: 0.0998\n",
      "==========================================================================================\n",
      "Epoch [1872/5000] | Time: 0.34s\n",
      "(Training) Loss: 1037462.0622\n",
      "(Validation) Loss: 1067008.9702, MAE: 4053.1870, R2: 0.1000\n",
      "==========================================================================================\n",
      "Epoch [1873/5000] | Time: 0.30s\n",
      "(Training) Loss: 1033800.5279\n",
      "(Validation) Loss: 1072864.4673, MAE: 4068.9282, R2: 0.0951\n",
      "==========================================================================================\n",
      "Epoch [1874/5000] | Time: 0.33s\n",
      "(Training) Loss: 1029026.6428\n",
      "(Validation) Loss: 1072685.1251, MAE: 4063.7083, R2: 0.0953\n",
      "==========================================================================================\n",
      "Epoch [1875/5000] | Time: 0.29s\n",
      "(Training) Loss: 1045809.7379\n",
      "(Validation) Loss: 1084822.5879, MAE: 4103.1001, R2: 0.0852\n",
      "==========================================================================================\n",
      "Epoch [1876/5000] | Time: 0.31s\n",
      "(Training) Loss: 1040374.4359\n",
      "(Validation) Loss: 1084623.8121, MAE: 4099.2295, R2: 0.0853\n",
      "==========================================================================================\n",
      "Epoch [1877/5000] | Time: 0.26s\n",
      "(Training) Loss: 1049168.1231\n",
      "(Validation) Loss: 1084431.6241, MAE: 4099.6377, R2: 0.0855\n",
      "==========================================================================================\n",
      "Epoch [1878/5000] | Time: 0.27s\n",
      "(Training) Loss: 1037300.3417\n",
      "(Validation) Loss: 1084247.4006, MAE: 4100.6812, R2: 0.0856\n",
      "==========================================================================================\n",
      "Epoch [1879/5000] | Time: 0.30s\n",
      "(Training) Loss: 1035953.2833\n",
      "(Validation) Loss: 1084056.8127, MAE: 4099.6538, R2: 0.0858\n",
      "==========================================================================================\n",
      "Epoch [1880/5000] | Time: 0.29s\n",
      "(Training) Loss: 1045450.5527\n",
      "(Validation) Loss: 1083858.5803, MAE: 4095.6753, R2: 0.0860\n",
      "==========================================================================================\n",
      "Epoch [1881/5000] | Time: 0.35s\n",
      "(Training) Loss: 1050571.0964\n",
      "(Validation) Loss: 1083660.8914, MAE: 4093.1067, R2: 0.0861\n",
      "==========================================================================================\n",
      "Epoch [1882/5000] | Time: 0.30s\n",
      "(Training) Loss: 1043761.5254\n",
      "(Validation) Loss: 1083492.8711, MAE: 4098.8203, R2: 0.0863\n",
      "==========================================================================================\n",
      "Epoch [1883/5000] | Time: 0.34s\n",
      "(Training) Loss: 1037030.4873\n",
      "(Validation) Loss: 1083305.7879, MAE: 4092.8489, R2: 0.0864\n",
      "==========================================================================================\n",
      "Epoch [1884/5000] | Time: 0.30s\n",
      "(Training) Loss: 1067719.3934\n",
      "(Validation) Loss: 1095593.2749, MAE: 4131.4473, R2: 0.0762\n",
      "==========================================================================================\n",
      "Epoch [1885/5000] | Time: 0.28s\n",
      "(Training) Loss: 1053764.5825\n",
      "(Validation) Loss: 1095410.7581, MAE: 4133.8335, R2: 0.0763\n",
      "==========================================================================================\n",
      "Epoch [1886/5000] | Time: 0.33s\n",
      "(Training) Loss: 1067899.0025\n",
      "(Validation) Loss: 1095269.4451, MAE: 4145.3662, R2: 0.0765\n",
      "==========================================================================================\n",
      "Epoch [1887/5000] | Time: 0.28s\n",
      "(Training) Loss: 1060781.1624\n",
      "(Validation) Loss: 1095040.6603, MAE: 4138.2808, R2: 0.0766\n",
      "==========================================================================================\n",
      "Epoch [1888/5000] | Time: 0.31s\n",
      "(Training) Loss: 1074970.2011\n",
      "(Validation) Loss: 1094840.0000, MAE: 4132.8306, R2: 0.0768\n",
      "==========================================================================================\n",
      "Epoch [1889/5000] | Time: 0.30s\n",
      "(Training) Loss: 1065089.7322\n",
      "(Validation) Loss: 1094639.3752, MAE: 4131.8926, R2: 0.0770\n",
      "==========================================================================================\n",
      "Epoch [1890/5000] | Time: 0.26s\n",
      "(Training) Loss: 1051339.4803\n",
      "(Validation) Loss: 1094458.9308, MAE: 4132.2876, R2: 0.0771\n",
      "==========================================================================================\n",
      "Epoch [1891/5000] | Time: 0.28s\n",
      "(Training) Loss: 1072993.0603\n",
      "(Validation) Loss: 1094268.0990, MAE: 4129.8364, R2: 0.0773\n",
      "==========================================================================================\n",
      "Epoch [1892/5000] | Time: 0.27s\n",
      "(Training) Loss: 1046978.3515\n",
      "(Validation) Loss: 1094073.6559, MAE: 4128.8315, R2: 0.0775\n",
      "==========================================================================================\n",
      "Epoch [1893/5000] | Time: 0.30s\n",
      "(Training) Loss: 1061124.9860\n",
      "(Validation) Loss: 1093888.0762, MAE: 4129.5415, R2: 0.0776\n",
      "==========================================================================================\n",
      "Epoch [1894/5000] | Time: 0.27s\n",
      "(Training) Loss: 1054773.6688\n",
      "(Validation) Loss: 1093674.6260, MAE: 4126.5078, R2: 0.0778\n",
      "==========================================================================================\n",
      "Epoch [1895/5000] | Time: 0.27s\n",
      "(Training) Loss: 1058405.9232\n",
      "(Validation) Loss: 1093484.3632, MAE: 4126.0264, R2: 0.0779\n",
      "==========================================================================================\n",
      "Epoch [1896/5000] | Time: 0.31s\n",
      "(Training) Loss: 1089499.6942\n",
      "(Validation) Loss: 1093298.5295, MAE: 4125.9043, R2: 0.0781\n",
      "==========================================================================================\n",
      "Epoch [1897/5000] | Time: 0.32s\n",
      "(Training) Loss: 1054964.5082\n",
      "(Validation) Loss: 1093101.6279, MAE: 4125.1494, R2: 0.0783\n",
      "==========================================================================================\n",
      "Epoch [1898/5000] | Time: 0.30s\n",
      "(Training) Loss: 1053602.2487\n",
      "(Validation) Loss: 1092914.3822, MAE: 4125.4116, R2: 0.0784\n",
      "==========================================================================================\n",
      "Epoch [1899/5000] | Time: 0.32s\n",
      "(Training) Loss: 1061498.7456\n",
      "(Validation) Loss: 1092721.4730, MAE: 4123.6963, R2: 0.0786\n",
      "==========================================================================================\n",
      "Epoch [1900/5000] | Time: 0.30s\n",
      "(Training) Loss: 1049406.9162\n",
      "(Validation) Loss: 1092522.2552, MAE: 4122.9404, R2: 0.0787\n",
      "==========================================================================================\n",
      "Epoch [1901/5000] | Time: 0.33s\n",
      "(Training) Loss: 1055104.2690\n",
      "(Validation) Loss: 1092346.0571, MAE: 4124.6431, R2: 0.0789\n",
      "==========================================================================================\n",
      "Epoch [1902/5000] | Time: 0.27s\n",
      "(Training) Loss: 1053570.6821\n",
      "(Validation) Loss: 1092135.2889, MAE: 4119.9014, R2: 0.0791\n",
      "==========================================================================================\n",
      "Epoch [1903/5000] | Time: 0.26s\n",
      "(Training) Loss: 1068634.7646\n",
      "(Validation) Loss: 1091955.2711, MAE: 4119.5791, R2: 0.0792\n",
      "==========================================================================================\n",
      "Epoch [1904/5000] | Time: 0.30s\n",
      "(Training) Loss: 1045545.9204\n",
      "(Validation) Loss: 1091777.6102, MAE: 4122.6191, R2: 0.0794\n",
      "==========================================================================================\n",
      "Epoch [1905/5000] | Time: 0.33s\n",
      "(Training) Loss: 1046841.3693\n",
      "(Validation) Loss: 1091574.4152, MAE: 4118.9238, R2: 0.0795\n",
      "==========================================================================================\n",
      "Epoch [1906/5000] | Time: 0.25s\n",
      "(Training) Loss: 1077818.1168\n",
      "(Validation) Loss: 1091389.9429, MAE: 4119.2466, R2: 0.0797\n",
      "==========================================================================================\n",
      "Epoch [1907/5000] | Time: 0.25s\n",
      "(Training) Loss: 1055240.9797\n",
      "(Validation) Loss: 1091195.2356, MAE: 4119.4668, R2: 0.0799\n",
      "==========================================================================================\n",
      "Epoch [1908/5000] | Time: 0.26s\n",
      "(Training) Loss: 1057941.3712\n",
      "(Validation) Loss: 1091030.1816, MAE: 4124.7617, R2: 0.0800\n",
      "==========================================================================================\n",
      "Epoch [1909/5000] | Time: 0.28s\n",
      "(Training) Loss: 1053252.5203\n",
      "(Validation) Loss: 1090835.1035, MAE: 4121.0430, R2: 0.0802\n",
      "==========================================================================================\n",
      "Epoch [1910/5000] | Time: 0.21s\n",
      "(Training) Loss: 1045998.5704\n",
      "(Validation) Loss: 1090640.3860, MAE: 4118.0278, R2: 0.0803\n",
      "==========================================================================================\n",
      "Epoch [1911/5000] | Time: 0.22s\n",
      "(Training) Loss: 1057241.7075\n",
      "(Validation) Loss: 1090458.6260, MAE: 4120.0947, R2: 0.0805\n",
      "==========================================================================================\n",
      "Epoch [1912/5000] | Time: 0.26s\n",
      "(Training) Loss: 1068621.0546\n",
      "(Validation) Loss: 1103077.3486, MAE: 4164.3828, R2: 0.0700\n",
      "==========================================================================================\n",
      "Epoch [1913/5000] | Time: 0.27s\n",
      "(Training) Loss: 1072936.8065\n",
      "(Validation) Loss: 1102869.7143, MAE: 4159.3706, R2: 0.0701\n",
      "==========================================================================================\n",
      "Epoch [1914/5000] | Time: 0.23s\n",
      "(Training) Loss: 1061203.3350\n",
      "(Validation) Loss: 1102675.1086, MAE: 4159.2710, R2: 0.0703\n",
      "==========================================================================================\n",
      "Epoch [1915/5000] | Time: 0.28s\n",
      "(Training) Loss: 1063763.6523\n",
      "(Validation) Loss: 1102496.1879, MAE: 4164.3335, R2: 0.0704\n",
      "==========================================================================================\n",
      "Epoch [1916/5000] | Time: 0.23s\n",
      "(Training) Loss: 1065477.4791\n",
      "(Validation) Loss: 1102290.9714, MAE: 4158.1079, R2: 0.0706\n",
      "==========================================================================================\n",
      "Epoch [1917/5000] | Time: 0.26s\n",
      "(Training) Loss: 1069730.8794\n",
      "(Validation) Loss: 1102093.2521, MAE: 4156.5518, R2: 0.0708\n",
      "==========================================================================================\n",
      "Epoch [1918/5000] | Time: 0.27s\n",
      "(Training) Loss: 1076580.0819\n",
      "(Validation) Loss: 1101897.6965, MAE: 4154.9487, R2: 0.0709\n",
      "==========================================================================================\n",
      "Epoch [1919/5000] | Time: 0.26s\n",
      "(Training) Loss: 1087443.0939\n",
      "(Validation) Loss: 1101706.7124, MAE: 4155.0532, R2: 0.0711\n",
      "==========================================================================================\n",
      "Epoch [1920/5000] | Time: 0.24s\n",
      "(Training) Loss: 1068951.4937\n",
      "(Validation) Loss: 1101514.2756, MAE: 4157.2363, R2: 0.0713\n",
      "==========================================================================================\n",
      "Epoch [1921/5000] | Time: 0.21s\n",
      "(Training) Loss: 1069573.3997\n",
      "(Validation) Loss: 1101319.9441, MAE: 4154.9141, R2: 0.0714\n",
      "==========================================================================================\n",
      "Epoch [1922/5000] | Time: 0.23s\n",
      "(Training) Loss: 1075670.5006\n",
      "(Validation) Loss: 1101129.4933, MAE: 4154.5190, R2: 0.0716\n",
      "==========================================================================================\n",
      "Epoch [1923/5000] | Time: 0.25s\n",
      "(Training) Loss: 1063816.0181\n",
      "(Validation) Loss: 1100931.1187, MAE: 4153.6084, R2: 0.0717\n",
      "==========================================================================================\n",
      "Epoch [1924/5000] | Time: 0.23s\n",
      "(Training) Loss: 1078528.0438\n",
      "(Validation) Loss: 1100740.4190, MAE: 4153.8159, R2: 0.0719\n",
      "==========================================================================================\n",
      "Epoch [1925/5000] | Time: 0.23s\n",
      "(Training) Loss: 1068877.4549\n",
      "(Validation) Loss: 1100547.6978, MAE: 4153.0303, R2: 0.0721\n",
      "==========================================================================================\n",
      "Epoch [1926/5000] | Time: 0.22s\n",
      "(Training) Loss: 1064272.4524\n",
      "(Validation) Loss: 1100359.7714, MAE: 4153.7700, R2: 0.0722\n",
      "==========================================================================================\n",
      "Epoch [1927/5000] | Time: 0.27s\n",
      "(Training) Loss: 1103303.1447\n",
      "(Validation) Loss: 1100161.0362, MAE: 4150.3965, R2: 0.0724\n",
      "==========================================================================================\n",
      "Epoch [1928/5000] | Time: 0.21s\n",
      "(Training) Loss: 1060183.9556\n",
      "(Validation) Loss: 1099969.2749, MAE: 4151.0132, R2: 0.0725\n",
      "==========================================================================================\n",
      "Epoch [1929/5000] | Time: 0.27s\n",
      "(Training) Loss: 1068714.2398\n",
      "(Validation) Loss: 1099799.6495, MAE: 4151.2129, R2: 0.0727\n",
      "==========================================================================================\n",
      "Epoch [1930/5000] | Time: 0.26s\n",
      "(Training) Loss: 1067611.3503\n",
      "(Validation) Loss: 1099621.7041, MAE: 4153.3711, R2: 0.0728\n",
      "==========================================================================================\n",
      "Epoch [1931/5000] | Time: 0.25s\n",
      "(Training) Loss: 1060484.0444\n",
      "(Validation) Loss: 1099419.4641, MAE: 4151.6548, R2: 0.0730\n",
      "==========================================================================================\n",
      "Epoch [1932/5000] | Time: 0.23s\n",
      "(Training) Loss: 1056491.9721\n",
      "(Validation) Loss: 1099237.7092, MAE: 4152.5112, R2: 0.0731\n",
      "==========================================================================================\n",
      "Epoch [1933/5000] | Time: 0.32s\n",
      "(Training) Loss: 1065869.9327\n",
      "(Validation) Loss: 1099080.3657, MAE: 4152.8960, R2: 0.0733\n",
      "==========================================================================================\n",
      "Epoch [1934/5000] | Time: 0.27s\n",
      "(Training) Loss: 1068347.4949\n",
      "(Validation) Loss: 1098889.9759, MAE: 4153.5293, R2: 0.0734\n",
      "==========================================================================================\n",
      "Epoch [1935/5000] | Time: 0.22s\n",
      "(Training) Loss: 1070109.2259\n",
      "(Validation) Loss: 1098690.5600, MAE: 4150.3115, R2: 0.0736\n",
      "==========================================================================================\n",
      "Epoch [1936/5000] | Time: 0.21s\n",
      "(Training) Loss: 1056234.9695\n",
      "(Validation) Loss: 1098501.2216, MAE: 4150.4883, R2: 0.0738\n",
      "==========================================================================================\n",
      "Epoch [1937/5000] | Time: 0.27s\n",
      "(Training) Loss: 1056222.2189\n",
      "(Validation) Loss: 1098309.7803, MAE: 4149.8989, R2: 0.0739\n",
      "==========================================================================================\n",
      "Epoch [1938/5000] | Time: 0.23s\n",
      "(Training) Loss: 1056312.2240\n",
      "(Validation) Loss: 1098118.9384, MAE: 4149.3403, R2: 0.0741\n",
      "==========================================================================================\n",
      "Epoch [1939/5000] | Time: 0.22s\n",
      "(Training) Loss: 1059922.7240\n",
      "(Validation) Loss: 1097927.5581, MAE: 4148.1069, R2: 0.0742\n",
      "==========================================================================================\n",
      "Epoch [1940/5000] | Time: 0.24s\n",
      "(Training) Loss: 1063488.6263\n",
      "(Validation) Loss: 1097747.0578, MAE: 4149.4111, R2: 0.0744\n",
      "==========================================================================================\n",
      "Epoch [1941/5000] | Time: 0.25s\n",
      "(Training) Loss: 1059306.3452\n",
      "(Validation) Loss: 1097554.1638, MAE: 4150.0278, R2: 0.0745\n",
      "==========================================================================================\n",
      "Epoch [1942/5000] | Time: 0.27s\n",
      "(Training) Loss: 1073472.4499\n",
      "(Validation) Loss: 1097359.4717, MAE: 4147.5195, R2: 0.0747\n",
      "==========================================================================================\n",
      "Epoch [1943/5000] | Time: 0.27s\n",
      "(Training) Loss: 1063487.9473\n",
      "(Validation) Loss: 1097164.5562, MAE: 4147.5659, R2: 0.0749\n",
      "==========================================================================================\n",
      "Epoch [1944/5000] | Time: 0.30s\n",
      "(Training) Loss: 1053757.5057\n",
      "(Validation) Loss: 1096975.3549, MAE: 4146.2505, R2: 0.0750\n",
      "==========================================================================================\n",
      "Epoch [1945/5000] | Time: 0.28s\n",
      "(Training) Loss: 1064644.3135\n",
      "(Validation) Loss: 1096782.6184, MAE: 4144.6924, R2: 0.0752\n",
      "==========================================================================================\n",
      "Epoch [1946/5000] | Time: 0.26s\n",
      "(Training) Loss: 1053742.3382\n",
      "(Validation) Loss: 1096592.2337, MAE: 4144.8057, R2: 0.0754\n",
      "==========================================================================================\n",
      "Epoch [1947/5000] | Time: 0.22s\n",
      "(Training) Loss: 1088181.7684\n",
      "(Validation) Loss: 1096405.2267, MAE: 4144.4189, R2: 0.0755\n",
      "==========================================================================================\n",
      "Epoch [1948/5000] | Time: 0.24s\n",
      "(Training) Loss: 1067177.0495\n",
      "(Validation) Loss: 1096212.1143, MAE: 4144.2236, R2: 0.0757\n",
      "==========================================================================================\n",
      "Epoch [1949/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046714.1964\n",
      "(Validation) Loss: 1096020.6222, MAE: 4143.1353, R2: 0.0758\n",
      "==========================================================================================\n",
      "Epoch [1950/5000] | Time: 0.25s\n",
      "(Training) Loss: 1068154.6180\n",
      "(Validation) Loss: 1095829.2368, MAE: 4141.0049, R2: 0.0760\n",
      "==========================================================================================\n",
      "Epoch [1951/5000] | Time: 0.28s\n",
      "(Training) Loss: 1063014.1117\n",
      "(Validation) Loss: 1095640.8838, MAE: 4142.0127, R2: 0.0761\n",
      "==========================================================================================\n",
      "Epoch [1952/5000] | Time: 0.27s\n",
      "(Training) Loss: 1062545.7582\n",
      "(Validation) Loss: 1095449.0057, MAE: 4140.6152, R2: 0.0763\n",
      "==========================================================================================\n",
      "Epoch [1953/5000] | Time: 0.23s\n",
      "(Training) Loss: 1046141.5948\n",
      "(Validation) Loss: 1095262.9435, MAE: 4140.4136, R2: 0.0765\n",
      "==========================================================================================\n",
      "Epoch [1954/5000] | Time: 0.24s\n",
      "(Training) Loss: 1074285.7595\n",
      "(Validation) Loss: 1095069.2165, MAE: 4138.3516, R2: 0.0766\n",
      "==========================================================================================\n",
      "Epoch [1955/5000] | Time: 0.25s\n",
      "(Training) Loss: 1070746.2722\n",
      "(Validation) Loss: 1094878.6235, MAE: 4138.3433, R2: 0.0768\n",
      "==========================================================================================\n",
      "Epoch [1956/5000] | Time: 0.25s\n",
      "(Training) Loss: 1057069.7303\n",
      "(Validation) Loss: 1094689.1886, MAE: 4138.9224, R2: 0.0769\n",
      "==========================================================================================\n",
      "Epoch [1957/5000] | Time: 0.23s\n",
      "(Training) Loss: 1070389.9327\n",
      "(Validation) Loss: 1094499.9975, MAE: 4138.6294, R2: 0.0771\n",
      "==========================================================================================\n",
      "Epoch [1958/5000] | Time: 0.29s\n",
      "(Training) Loss: 1058219.9981\n",
      "(Validation) Loss: 1094319.2127, MAE: 4139.6445, R2: 0.0772\n",
      "==========================================================================================\n",
      "Epoch [1959/5000] | Time: 0.29s\n",
      "(Training) Loss: 1079369.4816\n",
      "(Validation) Loss: 1094118.2019, MAE: 4135.5732, R2: 0.0774\n",
      "==========================================================================================\n",
      "Epoch [1960/5000] | Time: 0.27s\n",
      "(Training) Loss: 1067513.0159\n",
      "(Validation) Loss: 1093927.4565, MAE: 4135.2881, R2: 0.0776\n",
      "==========================================================================================\n",
      "Epoch [1961/5000] | Time: 0.27s\n",
      "(Training) Loss: 1054679.2234\n",
      "(Validation) Loss: 1093737.3257, MAE: 4136.8872, R2: 0.0777\n",
      "==========================================================================================\n",
      "Epoch [1962/5000] | Time: 0.27s\n",
      "(Training) Loss: 1049313.2970\n",
      "(Validation) Loss: 1093547.6673, MAE: 4135.4531, R2: 0.0779\n",
      "==========================================================================================\n",
      "Epoch [1963/5000] | Time: 0.29s\n",
      "(Training) Loss: 1063163.9695\n",
      "(Validation) Loss: 1093362.2502, MAE: 4134.4136, R2: 0.0780\n",
      "==========================================================================================\n",
      "Epoch [1964/5000] | Time: 0.24s\n",
      "(Training) Loss: 1062922.8832\n",
      "(Validation) Loss: 1093170.1486, MAE: 4132.7764, R2: 0.0782\n",
      "==========================================================================================\n",
      "Epoch [1965/5000] | Time: 0.25s\n",
      "(Training) Loss: 1059695.2557\n",
      "(Validation) Loss: 1092980.1143, MAE: 4132.0337, R2: 0.0784\n",
      "==========================================================================================\n",
      "Epoch [1966/5000] | Time: 0.26s\n",
      "(Training) Loss: 1068137.9778\n",
      "(Validation) Loss: 1092821.5010, MAE: 4140.0029, R2: 0.0785\n",
      "==========================================================================================\n",
      "Epoch [1967/5000] | Time: 0.28s\n",
      "(Training) Loss: 1043724.6633\n",
      "(Validation) Loss: 1092607.5683, MAE: 4134.4712, R2: 0.0787\n",
      "==========================================================================================\n",
      "Epoch [1968/5000] | Time: 0.23s\n",
      "(Training) Loss: 1046880.0320\n",
      "(Validation) Loss: 1092416.5079, MAE: 4132.1318, R2: 0.0788\n",
      "==========================================================================================\n",
      "Epoch [1969/5000] | Time: 0.22s\n",
      "(Training) Loss: 1057606.1339\n",
      "(Validation) Loss: 1092227.9721, MAE: 4130.8154, R2: 0.0790\n",
      "==========================================================================================\n",
      "Epoch [1970/5000] | Time: 0.23s\n",
      "(Training) Loss: 1071809.0565\n",
      "(Validation) Loss: 1092034.9968, MAE: 4129.8970, R2: 0.0791\n",
      "==========================================================================================\n",
      "Epoch [1971/5000] | Time: 0.28s\n",
      "(Training) Loss: 1072238.1916\n",
      "(Validation) Loss: 1091843.5657, MAE: 4129.0703, R2: 0.0793\n",
      "==========================================================================================\n",
      "Epoch [1972/5000] | Time: 0.23s\n",
      "(Training) Loss: 1065009.9226\n",
      "(Validation) Loss: 1091671.9695, MAE: 4132.6138, R2: 0.0794\n",
      "==========================================================================================\n",
      "Epoch [1973/5000] | Time: 0.26s\n",
      "(Training) Loss: 1057872.9860\n",
      "(Validation) Loss: 1091463.5378, MAE: 4127.5420, R2: 0.0796\n",
      "==========================================================================================\n",
      "Epoch [1974/5000] | Time: 0.28s\n",
      "(Training) Loss: 1052090.4137\n",
      "(Validation) Loss: 1091273.8235, MAE: 4127.9780, R2: 0.0798\n",
      "==========================================================================================\n",
      "Epoch [1975/5000] | Time: 0.31s\n",
      "(Training) Loss: 1066216.6840\n",
      "(Validation) Loss: 1091085.0692, MAE: 4129.4243, R2: 0.0799\n",
      "==========================================================================================\n",
      "Epoch [1976/5000] | Time: 0.30s\n",
      "(Training) Loss: 1062734.7684\n",
      "(Validation) Loss: 1090891.4895, MAE: 4125.1187, R2: 0.0801\n",
      "==========================================================================================\n",
      "Epoch [1977/5000] | Time: 0.29s\n",
      "(Training) Loss: 1044147.2411\n",
      "(Validation) Loss: 1090700.8508, MAE: 4124.3281, R2: 0.0803\n",
      "==========================================================================================\n",
      "Epoch [1978/5000] | Time: 0.28s\n",
      "(Training) Loss: 1054376.5438\n",
      "(Validation) Loss: 1090518.0800, MAE: 4124.9824, R2: 0.0804\n",
      "==========================================================================================\n",
      "Epoch [1979/5000] | Time: 0.26s\n",
      "(Training) Loss: 1043568.7449\n",
      "(Validation) Loss: 1090332.8406, MAE: 4123.9668, R2: 0.0806\n",
      "==========================================================================================\n",
      "Epoch [1980/5000] | Time: 0.28s\n",
      "(Training) Loss: 1063103.2113\n",
      "(Validation) Loss: 1090139.5962, MAE: 4122.4922, R2: 0.0807\n",
      "==========================================================================================\n",
      "Epoch [1981/5000] | Time: 0.29s\n",
      "(Training) Loss: 1045994.8813\n",
      "(Validation) Loss: 1089957.1200, MAE: 4124.8188, R2: 0.0809\n",
      "==========================================================================================\n",
      "Epoch [1982/5000] | Time: 0.27s\n",
      "(Training) Loss: 1059616.9772\n",
      "(Validation) Loss: 1089762.6057, MAE: 4121.4370, R2: 0.0810\n",
      "==========================================================================================\n",
      "Epoch [1983/5000] | Time: 0.27s\n",
      "(Training) Loss: 1051388.7354\n",
      "(Validation) Loss: 1089619.8349, MAE: 4123.5825, R2: 0.0812\n",
      "==========================================================================================\n",
      "Epoch [1984/5000] | Time: 0.31s\n",
      "(Training) Loss: 1050853.0241\n",
      "(Validation) Loss: 1089434.8343, MAE: 4124.5142, R2: 0.0813\n",
      "==========================================================================================\n",
      "Epoch [1985/5000] | Time: 0.25s\n",
      "(Training) Loss: 1065649.5311\n",
      "(Validation) Loss: 1089243.6013, MAE: 4122.8643, R2: 0.0815\n",
      "==========================================================================================\n",
      "Epoch [1986/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046321.4524\n",
      "(Validation) Loss: 1089061.7346, MAE: 4124.3003, R2: 0.0816\n",
      "==========================================================================================\n",
      "Epoch [1987/5000] | Time: 0.28s\n",
      "(Training) Loss: 1061434.1117\n",
      "(Validation) Loss: 1088870.7606, MAE: 4123.8286, R2: 0.0818\n",
      "==========================================================================================\n",
      "Epoch [1988/5000] | Time: 0.27s\n",
      "(Training) Loss: 1052047.5768\n",
      "(Validation) Loss: 1088678.2476, MAE: 4121.5586, R2: 0.0819\n",
      "==========================================================================================\n",
      "Epoch [1989/5000] | Time: 0.30s\n",
      "(Training) Loss: 1046746.2500\n",
      "(Validation) Loss: 1088488.2794, MAE: 4121.4927, R2: 0.0821\n",
      "==========================================================================================\n",
      "Epoch [1990/5000] | Time: 0.32s\n",
      "(Training) Loss: 1067312.2145\n",
      "(Validation) Loss: 1088308.6476, MAE: 4121.5918, R2: 0.0823\n",
      "==========================================================================================\n",
      "Epoch [1991/5000] | Time: 0.34s\n",
      "(Training) Loss: 1053393.6459\n",
      "(Validation) Loss: 1088108.0787, MAE: 4119.2095, R2: 0.0824\n",
      "==========================================================================================\n",
      "Epoch [1992/5000] | Time: 0.32s\n",
      "(Training) Loss: 1054618.0914\n",
      "(Validation) Loss: 1087918.3746, MAE: 4118.5566, R2: 0.0826\n",
      "==========================================================================================\n",
      "Epoch [1993/5000] | Time: 0.27s\n",
      "(Training) Loss: 1062319.4626\n",
      "(Validation) Loss: 1087727.7410, MAE: 4117.5078, R2: 0.0827\n",
      "==========================================================================================\n",
      "Epoch [1994/5000] | Time: 0.28s\n",
      "(Training) Loss: 1067588.1707\n",
      "(Validation) Loss: 1087564.9117, MAE: 4121.8628, R2: 0.0829\n",
      "==========================================================================================\n",
      "Epoch [1995/5000] | Time: 0.27s\n",
      "(Training) Loss: 1065099.5603\n",
      "(Validation) Loss: 1087351.5073, MAE: 4116.5879, R2: 0.0830\n",
      "==========================================================================================\n",
      "Epoch [1996/5000] | Time: 0.26s\n",
      "(Training) Loss: 1064029.1168\n",
      "(Validation) Loss: 1087160.0660, MAE: 4116.1030, R2: 0.0832\n",
      "==========================================================================================\n",
      "Epoch [1997/5000] | Time: 0.24s\n",
      "(Training) Loss: 1062481.0933\n",
      "(Validation) Loss: 1086967.3397, MAE: 4113.8540, R2: 0.0834\n",
      "==========================================================================================\n",
      "Epoch [1998/5000] | Time: 0.23s\n",
      "(Training) Loss: 1057239.3940\n",
      "(Validation) Loss: 1086781.9124, MAE: 4114.6582, R2: 0.0835\n",
      "==========================================================================================\n",
      "Epoch [1999/5000] | Time: 0.23s\n",
      "(Training) Loss: 1050075.5025\n",
      "(Validation) Loss: 1086590.5473, MAE: 4112.5503, R2: 0.0837\n",
      "==========================================================================================\n",
      "Epoch [2000/5000] | Time: 0.26s\n",
      "(Training) Loss: 1040678.9810\n",
      "(Validation) Loss: 1086403.2152, MAE: 4112.7358, R2: 0.0838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch2000.pth\n",
      "==========================================================================================\n",
      "Epoch [2001/5000] | Time: 0.31s\n",
      "(Training) Loss: 1047548.1041\n",
      "(Validation) Loss: 1086221.5010, MAE: 4113.9199, R2: 0.0840\n",
      "==========================================================================================\n",
      "Epoch [2002/5000] | Time: 0.29s\n",
      "(Training) Loss: 1076514.6104\n",
      "(Validation) Loss: 1086029.5517, MAE: 4112.0522, R2: 0.0841\n",
      "==========================================================================================\n",
      "Epoch [2003/5000] | Time: 0.32s\n",
      "(Training) Loss: 1054481.2621\n",
      "(Validation) Loss: 1085839.4565, MAE: 4112.1802, R2: 0.0843\n",
      "==========================================================================================\n",
      "Epoch [2004/5000] | Time: 0.36s\n",
      "(Training) Loss: 1057840.7843\n",
      "(Validation) Loss: 1085656.0813, MAE: 4113.1631, R2: 0.0845\n",
      "==========================================================================================\n",
      "Epoch [2005/5000] | Time: 0.29s\n",
      "(Training) Loss: 1049493.9860\n",
      "(Validation) Loss: 1085462.5016, MAE: 4110.5098, R2: 0.0846\n",
      "==========================================================================================\n",
      "Epoch [2006/5000] | Time: 0.30s\n",
      "(Training) Loss: 1044038.1834\n",
      "(Validation) Loss: 1085273.2140, MAE: 4109.3149, R2: 0.0848\n",
      "==========================================================================================\n",
      "Epoch [2007/5000] | Time: 0.29s\n",
      "(Training) Loss: 1053494.5070\n",
      "(Validation) Loss: 1085083.4235, MAE: 4108.4297, R2: 0.0849\n",
      "==========================================================================================\n",
      "Epoch [2008/5000] | Time: 0.28s\n",
      "(Training) Loss: 1039069.3004\n",
      "(Validation) Loss: 1084896.9651, MAE: 4107.4170, R2: 0.0851\n",
      "==========================================================================================\n",
      "Epoch [2009/5000] | Time: 0.27s\n",
      "(Training) Loss: 1046649.9968\n",
      "(Validation) Loss: 1084720.0457, MAE: 4112.0352, R2: 0.0852\n",
      "==========================================================================================\n",
      "Epoch [2010/5000] | Time: 0.30s\n",
      "(Training) Loss: 1045747.0076\n",
      "(Validation) Loss: 1084530.7632, MAE: 4110.0088, R2: 0.0854\n",
      "==========================================================================================\n",
      "Epoch [2011/5000] | Time: 0.28s\n",
      "(Training) Loss: 1044922.9010\n",
      "(Validation) Loss: 1084336.2946, MAE: 4105.8057, R2: 0.0856\n",
      "==========================================================================================\n",
      "Epoch [2012/5000] | Time: 0.32s\n",
      "(Training) Loss: 1052375.9594\n",
      "(Validation) Loss: 1084149.5771, MAE: 4105.4492, R2: 0.0857\n",
      "==========================================================================================\n",
      "Epoch [2013/5000] | Time: 0.32s\n",
      "(Training) Loss: 1041081.9987\n",
      "(Validation) Loss: 1083958.3797, MAE: 4104.3120, R2: 0.0859\n",
      "==========================================================================================\n",
      "Epoch [2014/5000] | Time: 0.27s\n",
      "(Training) Loss: 1046699.8084\n",
      "(Validation) Loss: 1083776.3098, MAE: 4105.4189, R2: 0.0860\n",
      "==========================================================================================\n",
      "Epoch [2015/5000] | Time: 0.37s\n",
      "(Training) Loss: 1040959.6301\n",
      "(Validation) Loss: 1083587.1289, MAE: 4103.1685, R2: 0.0862\n",
      "==========================================================================================\n",
      "Epoch [2016/5000] | Time: 0.31s\n",
      "(Training) Loss: 1044739.8642\n",
      "(Validation) Loss: 1083399.5022, MAE: 4103.2832, R2: 0.0863\n",
      "==========================================================================================\n",
      "Epoch [2017/5000] | Time: 0.23s\n",
      "(Training) Loss: 1047441.2272\n",
      "(Validation) Loss: 1083211.4692, MAE: 4102.6499, R2: 0.0865\n",
      "==========================================================================================\n",
      "Epoch [2018/5000] | Time: 0.23s\n",
      "(Training) Loss: 1049563.4664\n",
      "(Validation) Loss: 1083022.0394, MAE: 4101.1021, R2: 0.0867\n",
      "==========================================================================================\n",
      "Epoch [2019/5000] | Time: 0.21s\n",
      "(Training) Loss: 1059893.4632\n",
      "(Validation) Loss: 1082842.9156, MAE: 4101.6860, R2: 0.0868\n",
      "==========================================================================================\n",
      "Epoch [2020/5000] | Time: 0.19s\n",
      "(Training) Loss: 1056141.7297\n",
      "(Validation) Loss: 1082654.7708, MAE: 4103.5620, R2: 0.0870\n",
      "==========================================================================================\n",
      "Epoch [2021/5000] | Time: 0.20s\n",
      "(Training) Loss: 1054012.6440\n",
      "(Validation) Loss: 1082474.2705, MAE: 4102.0703, R2: 0.0871\n",
      "==========================================================================================\n",
      "Epoch [2022/5000] | Time: 0.20s\n",
      "(Training) Loss: 1035961.6805\n",
      "(Validation) Loss: 1082334.7911, MAE: 4105.2407, R2: 0.0872\n",
      "==========================================================================================\n",
      "Epoch [2023/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046568.1523\n",
      "(Validation) Loss: 1082140.9422, MAE: 4102.3115, R2: 0.0874\n",
      "==========================================================================================\n",
      "Epoch [2024/5000] | Time: 0.21s\n",
      "(Training) Loss: 1050515.9201\n",
      "(Validation) Loss: 1081978.0216, MAE: 4110.8989, R2: 0.0875\n",
      "==========================================================================================\n",
      "Epoch [2025/5000] | Time: 0.25s\n",
      "(Training) Loss: 1043481.8242\n",
      "(Validation) Loss: 1081769.5289, MAE: 4101.5034, R2: 0.0877\n",
      "==========================================================================================\n",
      "Epoch [2026/5000] | Time: 0.22s\n",
      "(Training) Loss: 1054454.1840\n",
      "(Validation) Loss: 1081582.6133, MAE: 4101.8052, R2: 0.0879\n",
      "==========================================================================================\n",
      "Epoch [2027/5000] | Time: 0.21s\n",
      "(Training) Loss: 1038419.6390\n",
      "(Validation) Loss: 1081394.0927, MAE: 4101.7090, R2: 0.0880\n",
      "==========================================================================================\n",
      "Epoch [2028/5000] | Time: 0.21s\n",
      "(Training) Loss: 1049268.7830\n",
      "(Validation) Loss: 1081200.8838, MAE: 4098.1885, R2: 0.0882\n",
      "==========================================================================================\n",
      "Epoch [2029/5000] | Time: 0.28s\n",
      "(Training) Loss: 1051582.1973\n",
      "(Validation) Loss: 1081015.7460, MAE: 4098.6636, R2: 0.0883\n",
      "==========================================================================================\n",
      "Epoch [2030/5000] | Time: 0.22s\n",
      "(Training) Loss: 1038798.5787\n",
      "(Validation) Loss: 1080829.3943, MAE: 4098.1655, R2: 0.0885\n",
      "==========================================================================================\n",
      "Epoch [2031/5000] | Time: 0.22s\n",
      "(Training) Loss: 1041534.1523\n",
      "(Validation) Loss: 1087395.1543, MAE: 4126.4839, R2: 0.0830\n",
      "==========================================================================================\n",
      "Epoch [2032/5000] | Time: 0.21s\n",
      "(Training) Loss: 1042880.5444\n",
      "(Validation) Loss: 1087207.3956, MAE: 4123.6768, R2: 0.0832\n",
      "==========================================================================================\n",
      "Epoch [2033/5000] | Time: 0.21s\n",
      "(Training) Loss: 1054908.5102\n",
      "(Validation) Loss: 1087016.4521, MAE: 4121.3101, R2: 0.0833\n",
      "==========================================================================================\n",
      "Epoch [2034/5000] | Time: 0.23s\n",
      "(Training) Loss: 1050616.4181\n",
      "(Validation) Loss: 1086838.3644, MAE: 4121.8745, R2: 0.0835\n",
      "==========================================================================================\n",
      "Epoch [2035/5000] | Time: 0.25s\n",
      "(Training) Loss: 1056087.4321\n",
      "(Validation) Loss: 1086651.1086, MAE: 4121.2153, R2: 0.0836\n",
      "==========================================================================================\n",
      "Epoch [2036/5000] | Time: 0.22s\n",
      "(Training) Loss: 1053687.0565\n",
      "(Validation) Loss: 1086465.7422, MAE: 4121.4507, R2: 0.0838\n",
      "==========================================================================================\n",
      "Epoch [2037/5000] | Time: 0.35s\n",
      "(Training) Loss: 1072949.8997\n",
      "(Validation) Loss: 1086277.0844, MAE: 4120.4033, R2: 0.0839\n",
      "==========================================================================================\n",
      "Epoch [2038/5000] | Time: 0.69s\n",
      "(Training) Loss: 1050351.6970\n",
      "(Validation) Loss: 1086085.1454, MAE: 4120.3882, R2: 0.0841\n",
      "==========================================================================================\n",
      "Epoch [2039/5000] | Time: 0.32s\n",
      "(Training) Loss: 1066598.1060\n",
      "(Validation) Loss: 1085895.9187, MAE: 4117.1782, R2: 0.0843\n",
      "==========================================================================================\n",
      "Epoch [2040/5000] | Time: 0.68s\n",
      "(Training) Loss: 1039725.5904\n",
      "(Validation) Loss: 1085708.1803, MAE: 4116.1685, R2: 0.0844\n",
      "==========================================================================================\n",
      "Epoch [2041/5000] | Time: 0.78s\n",
      "(Training) Loss: 1041763.0082\n",
      "(Validation) Loss: 1085527.0857, MAE: 4116.9800, R2: 0.0846\n",
      "==========================================================================================\n",
      "Epoch [2042/5000] | Time: 0.72s\n",
      "(Training) Loss: 1051698.6136\n",
      "(Validation) Loss: 1085347.3829, MAE: 4116.7256, R2: 0.0847\n",
      "==========================================================================================\n",
      "Epoch [2043/5000] | Time: 0.87s\n",
      "(Training) Loss: 1053382.8065\n",
      "(Validation) Loss: 1085169.3359, MAE: 4117.5312, R2: 0.0849\n",
      "==========================================================================================\n",
      "Epoch [2044/5000] | Time: 0.76s\n",
      "(Training) Loss: 1074892.4454\n",
      "(Validation) Loss: 1084972.0229, MAE: 4115.6128, R2: 0.0850\n",
      "==========================================================================================\n",
      "Epoch [2045/5000] | Time: 0.71s\n",
      "(Training) Loss: 1067021.4987\n",
      "(Validation) Loss: 1084788.8863, MAE: 4114.7681, R2: 0.0852\n",
      "==========================================================================================\n",
      "Epoch [2046/5000] | Time: 0.86s\n",
      "(Training) Loss: 1045959.3433\n",
      "(Validation) Loss: 1084595.6317, MAE: 4113.0503, R2: 0.0853\n",
      "==========================================================================================\n",
      "Epoch [2047/5000] | Time: 0.81s\n",
      "(Training) Loss: 1050661.9334\n",
      "(Validation) Loss: 1084412.2921, MAE: 4113.3818, R2: 0.0855\n",
      "==========================================================================================\n",
      "Epoch [2048/5000] | Time: 0.73s\n",
      "(Training) Loss: 1050098.7284\n",
      "(Validation) Loss: 1084226.3416, MAE: 4112.3496, R2: 0.0856\n",
      "==========================================================================================\n",
      "Epoch [2049/5000] | Time: 0.74s\n",
      "(Training) Loss: 1036944.0235\n",
      "(Validation) Loss: 1084039.1314, MAE: 4110.6245, R2: 0.0858\n",
      "==========================================================================================\n",
      "Epoch [2050/5000] | Time: 0.96s\n",
      "(Training) Loss: 1042442.4543\n",
      "(Validation) Loss: 1083864.5537, MAE: 4112.6777, R2: 0.0860\n",
      "==========================================================================================\n",
      "Epoch [2051/5000] | Time: 0.82s\n",
      "(Training) Loss: 1037120.5308\n",
      "(Validation) Loss: 1083678.1410, MAE: 4113.2910, R2: 0.0861\n",
      "==========================================================================================\n",
      "Epoch [2052/5000] | Time: 0.90s\n",
      "(Training) Loss: 1042107.7449\n",
      "(Validation) Loss: 1083503.4768, MAE: 4113.6011, R2: 0.0863\n",
      "==========================================================================================\n",
      "Epoch [2053/5000] | Time: 0.78s\n",
      "(Training) Loss: 1042002.8712\n",
      "(Validation) Loss: 1083309.3029, MAE: 4110.8823, R2: 0.0864\n",
      "==========================================================================================\n",
      "Epoch [2054/5000] | Time: 0.76s\n",
      "(Training) Loss: 1051843.3141\n",
      "(Validation) Loss: 1083122.0825, MAE: 4109.3262, R2: 0.0866\n",
      "==========================================================================================\n",
      "Epoch [2055/5000] | Time: 0.59s\n",
      "(Training) Loss: 1057296.5742\n",
      "(Validation) Loss: 1082936.4419, MAE: 4108.4092, R2: 0.0867\n",
      "==========================================================================================\n",
      "Epoch [2056/5000] | Time: 0.27s\n",
      "(Training) Loss: 1044456.0279\n",
      "(Validation) Loss: 1082747.4032, MAE: 4105.9414, R2: 0.0869\n",
      "==========================================================================================\n",
      "Epoch [2057/5000] | Time: 0.26s\n",
      "(Training) Loss: 1036139.4645\n",
      "(Validation) Loss: 1082561.0260, MAE: 4105.2134, R2: 0.0870\n",
      "==========================================================================================\n",
      "Epoch [2058/5000] | Time: 0.24s\n",
      "(Training) Loss: 1050055.2792\n",
      "(Validation) Loss: 1082376.7822, MAE: 4103.6260, R2: 0.0872\n",
      "==========================================================================================\n",
      "Epoch [2059/5000] | Time: 0.23s\n",
      "(Training) Loss: 1037999.9499\n",
      "(Validation) Loss: 1082196.0584, MAE: 4105.9985, R2: 0.0873\n",
      "==========================================================================================\n",
      "Epoch [2060/5000] | Time: 0.24s\n",
      "(Training) Loss: 1045188.2418\n",
      "(Validation) Loss: 1082010.0368, MAE: 4104.6035, R2: 0.0875\n",
      "==========================================================================================\n",
      "Epoch [2061/5000] | Time: 0.71s\n",
      "(Training) Loss: 1066174.2297\n",
      "(Validation) Loss: 1081827.0933, MAE: 4103.8677, R2: 0.0876\n",
      "==========================================================================================\n",
      "Epoch [2062/5000] | Time: 0.51s\n",
      "(Training) Loss: 1064515.9201\n",
      "(Validation) Loss: 1081636.8254, MAE: 4102.6182, R2: 0.0878\n",
      "==========================================================================================\n",
      "Epoch [2063/5000] | Time: 0.58s\n",
      "(Training) Loss: 1059194.1434\n",
      "(Validation) Loss: 1081453.4654, MAE: 4102.4976, R2: 0.0880\n",
      "==========================================================================================\n",
      "Epoch [2064/5000] | Time: 0.74s\n",
      "(Training) Loss: 1048178.3490\n",
      "(Validation) Loss: 1081262.4508, MAE: 4100.7300, R2: 0.0881\n",
      "==========================================================================================\n",
      "Epoch [2065/5000] | Time: 0.88s\n",
      "(Training) Loss: 1043521.8280\n",
      "(Validation) Loss: 1081088.6502, MAE: 4103.1152, R2: 0.0883\n",
      "==========================================================================================\n",
      "Epoch [2066/5000] | Time: 0.34s\n",
      "(Training) Loss: 1045884.7874\n",
      "(Validation) Loss: 1080896.6959, MAE: 4100.5703, R2: 0.0884\n",
      "==========================================================================================\n",
      "Epoch [2067/5000] | Time: 0.28s\n",
      "(Training) Loss: 1048940.6802\n",
      "(Validation) Loss: 1080717.7854, MAE: 4101.9263, R2: 0.0886\n",
      "==========================================================================================\n",
      "Epoch [2068/5000] | Time: 0.28s\n",
      "(Training) Loss: 1043896.6827\n",
      "(Validation) Loss: 1080532.4444, MAE: 4100.5088, R2: 0.0887\n",
      "==========================================================================================\n",
      "Epoch [2069/5000] | Time: 0.28s\n",
      "(Training) Loss: 1041058.4892\n",
      "(Validation) Loss: 1080342.0800, MAE: 4098.9297, R2: 0.0889\n",
      "==========================================================================================\n",
      "Epoch [2070/5000] | Time: 0.31s\n",
      "(Training) Loss: 1041584.6364\n",
      "(Validation) Loss: 1080155.9314, MAE: 4097.0156, R2: 0.0890\n",
      "==========================================================================================\n",
      "Epoch [2071/5000] | Time: 0.31s\n",
      "(Training) Loss: 1059817.4810\n",
      "(Validation) Loss: 1079974.3492, MAE: 4097.5967, R2: 0.0892\n",
      "==========================================================================================\n",
      "Epoch [2072/5000] | Time: 0.30s\n",
      "(Training) Loss: 1032129.3069\n",
      "(Validation) Loss: 1079792.2895, MAE: 4100.2183, R2: 0.0893\n",
      "==========================================================================================\n",
      "Epoch [2073/5000] | Time: 0.31s\n",
      "(Training) Loss: 1042142.2043\n",
      "(Validation) Loss: 1079605.7498, MAE: 4095.2378, R2: 0.0895\n",
      "==========================================================================================\n",
      "Epoch [2074/5000] | Time: 0.26s\n",
      "(Training) Loss: 1032925.0336\n",
      "(Validation) Loss: 1079434.3822, MAE: 4100.0693, R2: 0.0896\n",
      "==========================================================================================\n",
      "Epoch [2075/5000] | Time: 0.24s\n",
      "(Training) Loss: 1037904.4467\n",
      "(Validation) Loss: 1079236.9625, MAE: 4095.2747, R2: 0.0898\n",
      "==========================================================================================\n",
      "Epoch [2076/5000] | Time: 0.25s\n",
      "(Training) Loss: 1061684.4784\n",
      "(Validation) Loss: 1079054.4356, MAE: 4094.9524, R2: 0.0900\n",
      "==========================================================================================\n",
      "Epoch [2077/5000] | Time: 0.28s\n",
      "(Training) Loss: 1034811.3553\n",
      "(Validation) Loss: 1078866.5956, MAE: 4092.6187, R2: 0.0901\n",
      "==========================================================================================\n",
      "Epoch [2078/5000] | Time: 0.29s\n",
      "(Training) Loss: 1056058.6970\n",
      "(Validation) Loss: 1078688.6959, MAE: 4093.8982, R2: 0.0903\n",
      "==========================================================================================\n",
      "Epoch [2079/5000] | Time: 0.27s\n",
      "(Training) Loss: 1042301.1155\n",
      "(Validation) Loss: 1078509.9378, MAE: 4097.2383, R2: 0.0904\n",
      "==========================================================================================\n",
      "Epoch [2080/5000] | Time: 0.34s\n",
      "(Training) Loss: 1045839.2982\n",
      "(Validation) Loss: 1078333.2368, MAE: 4097.4277, R2: 0.0906\n",
      "==========================================================================================\n",
      "Epoch [2081/5000] | Time: 0.34s\n",
      "(Training) Loss: 1032014.4681\n",
      "(Validation) Loss: 1078129.9200, MAE: 4090.6558, R2: 0.0907\n",
      "==========================================================================================\n",
      "Epoch [2082/5000] | Time: 0.29s\n",
      "(Training) Loss: 1044369.1992\n",
      "(Validation) Loss: 1077959.3651, MAE: 4094.3342, R2: 0.0909\n",
      "==========================================================================================\n",
      "Epoch [2083/5000] | Time: 0.27s\n",
      "(Training) Loss: 1055003.3921\n",
      "(Validation) Loss: 1077764.4089, MAE: 4089.3994, R2: 0.0910\n",
      "==========================================================================================\n",
      "Epoch [2084/5000] | Time: 0.26s\n",
      "(Training) Loss: 1041301.8826\n",
      "(Validation) Loss: 1077578.2857, MAE: 4087.6863, R2: 0.0912\n",
      "==========================================================================================\n",
      "Epoch [2085/5000] | Time: 0.24s\n",
      "(Training) Loss: 1033851.4036\n",
      "(Validation) Loss: 1077394.0825, MAE: 4087.4841, R2: 0.0913\n",
      "==========================================================================================\n",
      "Epoch [2086/5000] | Time: 0.26s\n",
      "(Training) Loss: 1033164.2865\n",
      "(Validation) Loss: 1077218.1181, MAE: 4087.0215, R2: 0.0915\n",
      "==========================================================================================\n",
      "Epoch [2087/5000] | Time: 0.26s\n",
      "(Training) Loss: 1044205.3261\n",
      "(Validation) Loss: 1077028.1752, MAE: 4085.7915, R2: 0.0916\n",
      "==========================================================================================\n",
      "Epoch [2088/5000] | Time: 0.26s\n",
      "(Training) Loss: 1036181.7516\n",
      "(Validation) Loss: 1076846.6083, MAE: 4084.0410, R2: 0.0918\n",
      "==========================================================================================\n",
      "Epoch [2089/5000] | Time: 0.27s\n",
      "(Training) Loss: 1033209.1402\n",
      "(Validation) Loss: 1076662.1308, MAE: 4084.4094, R2: 0.0920\n",
      "==========================================================================================\n",
      "Epoch [2090/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046884.1053\n",
      "(Validation) Loss: 1076482.3568, MAE: 4085.3994, R2: 0.0921\n",
      "==========================================================================================\n",
      "Epoch [2091/5000] | Time: 0.25s\n",
      "(Training) Loss: 1042025.6358\n",
      "(Validation) Loss: 1076302.9384, MAE: 4084.5208, R2: 0.0923\n",
      "==========================================================================================\n",
      "Epoch [2092/5000] | Time: 0.23s\n",
      "(Training) Loss: 1042570.5615\n",
      "(Validation) Loss: 1076115.5911, MAE: 4083.3210, R2: 0.0924\n",
      "==========================================================================================\n",
      "Epoch [2093/5000] | Time: 0.27s\n",
      "(Training) Loss: 1039010.0393\n",
      "(Validation) Loss: 1075928.6502, MAE: 4082.2229, R2: 0.0926\n",
      "==========================================================================================\n",
      "Epoch [2094/5000] | Time: 0.27s\n",
      "(Training) Loss: 1050483.1466\n",
      "(Validation) Loss: 1075746.0521, MAE: 4080.8813, R2: 0.0927\n",
      "==========================================================================================\n",
      "Epoch [2095/5000] | Time: 0.24s\n",
      "(Training) Loss: 1056499.0654\n",
      "(Validation) Loss: 1075566.4152, MAE: 4082.8933, R2: 0.0929\n",
      "==========================================================================================\n",
      "Epoch [2096/5000] | Time: 0.25s\n",
      "(Training) Loss: 1040195.9981\n",
      "(Validation) Loss: 1075384.3251, MAE: 4082.4622, R2: 0.0930\n",
      "==========================================================================================\n",
      "Epoch [2097/5000] | Time: 0.27s\n",
      "(Training) Loss: 1037127.8579\n",
      "(Validation) Loss: 1075199.3549, MAE: 4082.7017, R2: 0.0932\n",
      "==========================================================================================\n",
      "Epoch [2098/5000] | Time: 0.25s\n",
      "(Training) Loss: 1036239.8109\n",
      "(Validation) Loss: 1075010.4076, MAE: 4079.5488, R2: 0.0933\n",
      "==========================================================================================\n",
      "Epoch [2099/5000] | Time: 0.25s\n",
      "(Training) Loss: 1052295.5114\n",
      "(Validation) Loss: 1074828.3581, MAE: 4078.0393, R2: 0.0935\n",
      "==========================================================================================\n",
      "Epoch [2100/5000] | Time: 0.24s\n",
      "(Training) Loss: 1060730.5863\n",
      "(Validation) Loss: 1074642.4533, MAE: 4077.5093, R2: 0.0936\n",
      "==========================================================================================\n",
      "Epoch [2101/5000] | Time: 0.24s\n",
      "(Training) Loss: 1027941.2467\n",
      "(Validation) Loss: 1074457.5746, MAE: 4076.5791, R2: 0.0938\n",
      "==========================================================================================\n",
      "Epoch [2102/5000] | Time: 0.22s\n",
      "(Training) Loss: 1056325.8712\n",
      "(Validation) Loss: 1074273.4578, MAE: 4074.6226, R2: 0.0939\n",
      "==========================================================================================\n",
      "Epoch [2103/5000] | Time: 0.22s\n",
      "(Training) Loss: 1035642.8401\n",
      "(Validation) Loss: 1074088.7619, MAE: 4074.2937, R2: 0.0941\n",
      "==========================================================================================\n",
      "Epoch [2104/5000] | Time: 0.21s\n",
      "(Training) Loss: 1037859.0247\n",
      "(Validation) Loss: 1073908.2463, MAE: 4074.1218, R2: 0.0942\n",
      "==========================================================================================\n",
      "Epoch [2105/5000] | Time: 0.19s\n",
      "(Training) Loss: 1042064.0381\n",
      "(Validation) Loss: 1073726.5981, MAE: 4074.0049, R2: 0.0944\n",
      "==========================================================================================\n",
      "Epoch [2106/5000] | Time: 0.20s\n",
      "(Training) Loss: 1038972.6808\n",
      "(Validation) Loss: 1073537.9606, MAE: 4072.8267, R2: 0.0946\n",
      "==========================================================================================\n",
      "Epoch [2107/5000] | Time: 0.24s\n",
      "(Training) Loss: 1054457.6713\n",
      "(Validation) Loss: 1073369.9556, MAE: 4076.0730, R2: 0.0947\n",
      "==========================================================================================\n",
      "Epoch [2108/5000] | Time: 0.21s\n",
      "(Training) Loss: 1044376.8959\n",
      "(Validation) Loss: 1073179.6165, MAE: 4074.2051, R2: 0.0949\n",
      "==========================================================================================\n",
      "Epoch [2109/5000] | Time: 0.19s\n",
      "(Training) Loss: 1026755.7197\n",
      "(Validation) Loss: 1072995.1390, MAE: 4072.2771, R2: 0.0950\n",
      "==========================================================================================\n",
      "Epoch [2110/5000] | Time: 0.19s\n",
      "(Training) Loss: 1042826.9778\n",
      "(Validation) Loss: 1072810.2502, MAE: 4070.9893, R2: 0.0952\n",
      "==========================================================================================\n",
      "Epoch [2111/5000] | Time: 0.19s\n",
      "(Training) Loss: 1025888.8406\n",
      "(Validation) Loss: 1072626.5549, MAE: 4070.3469, R2: 0.0953\n",
      "==========================================================================================\n",
      "Epoch [2112/5000] | Time: 0.19s\n",
      "(Training) Loss: 1037899.6618\n",
      "(Validation) Loss: 1072461.8057, MAE: 4073.7290, R2: 0.0955\n",
      "==========================================================================================\n",
      "Epoch [2113/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046108.4086\n",
      "(Validation) Loss: 1072265.5543, MAE: 4069.1155, R2: 0.0956\n",
      "==========================================================================================\n",
      "Epoch [2114/5000] | Time: 0.21s\n",
      "(Training) Loss: 1028050.1482\n",
      "(Validation) Loss: 1072077.8463, MAE: 4067.8682, R2: 0.0958\n",
      "==========================================================================================\n",
      "Epoch [2115/5000] | Time: 0.20s\n",
      "(Training) Loss: 1047107.2500\n",
      "(Validation) Loss: 1071901.6940, MAE: 4067.8079, R2: 0.0959\n",
      "==========================================================================================\n",
      "Epoch [2116/5000] | Time: 0.21s\n",
      "(Training) Loss: 1064279.1992\n",
      "(Validation) Loss: 1071713.0565, MAE: 4066.1460, R2: 0.0961\n",
      "==========================================================================================\n",
      "Epoch [2117/5000] | Time: 0.19s\n",
      "(Training) Loss: 1039339.2170\n",
      "(Validation) Loss: 1071529.1581, MAE: 4067.1201, R2: 0.0962\n",
      "==========================================================================================\n",
      "Epoch [2118/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023901.1330\n",
      "(Validation) Loss: 1071349.0032, MAE: 4067.5049, R2: 0.0964\n",
      "==========================================================================================\n",
      "Epoch [2119/5000] | Time: 0.23s\n",
      "(Training) Loss: 1055773.7259\n",
      "(Validation) Loss: 1071165.2267, MAE: 4065.6819, R2: 0.0965\n",
      "==========================================================================================\n",
      "Epoch [2120/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046717.5933\n",
      "(Validation) Loss: 1070985.4679, MAE: 4067.3274, R2: 0.0967\n",
      "==========================================================================================\n",
      "Epoch [2121/5000] | Time: 0.23s\n",
      "(Training) Loss: 1035153.8230\n",
      "(Validation) Loss: 1070803.7994, MAE: 4065.1577, R2: 0.0968\n",
      "==========================================================================================\n",
      "Epoch [2122/5000] | Time: 0.21s\n",
      "(Training) Loss: 1062410.9277\n",
      "(Validation) Loss: 1070623.6241, MAE: 4068.5293, R2: 0.0970\n",
      "==========================================================================================\n",
      "Epoch [2123/5000] | Time: 0.24s\n",
      "(Training) Loss: 1029021.7849\n",
      "(Validation) Loss: 1070435.4438, MAE: 4063.6123, R2: 0.0971\n",
      "==========================================================================================\n",
      "Epoch [2124/5000] | Time: 0.23s\n",
      "(Training) Loss: 1031872.9404\n",
      "(Validation) Loss: 1070253.4298, MAE: 4063.7314, R2: 0.0973\n",
      "==========================================================================================\n",
      "Epoch [2125/5000] | Time: 0.20s\n",
      "(Training) Loss: 1037306.3198\n",
      "(Validation) Loss: 1070137.7524, MAE: 4065.2705, R2: 0.0974\n",
      "==========================================================================================\n",
      "Epoch [2126/5000] | Time: 0.20s\n",
      "(Training) Loss: 1025397.2535\n",
      "(Validation) Loss: 1069956.1752, MAE: 4065.6150, R2: 0.0975\n",
      "==========================================================================================\n",
      "Epoch [2127/5000] | Time: 0.20s\n",
      "(Training) Loss: 1039629.9175\n",
      "(Validation) Loss: 1069773.3841, MAE: 4063.9844, R2: 0.0977\n",
      "==========================================================================================\n",
      "Epoch [2128/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046076.3445\n",
      "(Validation) Loss: 1069596.1651, MAE: 4066.0359, R2: 0.0978\n",
      "==========================================================================================\n",
      "Epoch [2129/5000] | Time: 0.23s\n",
      "(Training) Loss: 1031255.3014\n",
      "(Validation) Loss: 1069409.1124, MAE: 4063.5410, R2: 0.0980\n",
      "==========================================================================================\n",
      "Epoch [2130/5000] | Time: 0.25s\n",
      "(Training) Loss: 1031031.6060\n",
      "(Validation) Loss: 1069232.1676, MAE: 4063.4089, R2: 0.0981\n",
      "==========================================================================================\n",
      "Epoch [2131/5000] | Time: 0.22s\n",
      "(Training) Loss: 1037082.8966\n",
      "(Validation) Loss: 1069143.2889, MAE: 4070.0918, R2: 0.0982\n",
      "==========================================================================================\n",
      "Epoch [2132/5000] | Time: 0.20s\n",
      "(Training) Loss: 1038707.7716\n",
      "(Validation) Loss: 1068890.2705, MAE: 4068.1265, R2: 0.0984\n",
      "==========================================================================================\n",
      "Epoch [2133/5000] | Time: 0.24s\n",
      "(Training) Loss: 1067009.5622\n",
      "(Validation) Loss: 1068685.2063, MAE: 4061.6555, R2: 0.0986\n",
      "==========================================================================================\n",
      "Epoch [2134/5000] | Time: 0.24s\n",
      "(Training) Loss: 1036096.4594\n",
      "(Validation) Loss: 1068494.3746, MAE: 4060.2039, R2: 0.0988\n",
      "==========================================================================================\n",
      "Epoch [2135/5000] | Time: 0.22s\n",
      "(Training) Loss: 1029496.4315\n",
      "(Validation) Loss: 1068321.3765, MAE: 4061.1868, R2: 0.0989\n",
      "==========================================================================================\n",
      "Epoch [2136/5000] | Time: 0.21s\n",
      "(Training) Loss: 1028994.4283\n",
      "(Validation) Loss: 1068131.2305, MAE: 4058.7407, R2: 0.0991\n",
      "==========================================================================================\n",
      "Epoch [2137/5000] | Time: 0.20s\n",
      "(Training) Loss: 1043583.2652\n",
      "(Validation) Loss: 1067953.4222, MAE: 4058.2271, R2: 0.0992\n",
      "==========================================================================================\n",
      "Epoch [2138/5000] | Time: 0.25s\n",
      "(Training) Loss: 1032949.7665\n",
      "(Validation) Loss: 1067771.7994, MAE: 4059.7166, R2: 0.0994\n",
      "==========================================================================================\n",
      "Epoch [2139/5000] | Time: 0.21s\n",
      "(Training) Loss: 1044906.0876\n",
      "(Validation) Loss: 1067590.2222, MAE: 4057.5833, R2: 0.0995\n",
      "==========================================================================================\n",
      "Epoch [2140/5000] | Time: 0.20s\n",
      "(Training) Loss: 1053297.2843\n",
      "(Validation) Loss: 1067408.8127, MAE: 4058.0796, R2: 0.0997\n",
      "==========================================================================================\n",
      "Epoch [2141/5000] | Time: 0.20s\n",
      "(Training) Loss: 1022710.0286\n",
      "(Validation) Loss: 1067223.6698, MAE: 4056.1304, R2: 0.0998\n",
      "==========================================================================================\n",
      "Epoch [2142/5000] | Time: 0.22s\n",
      "(Training) Loss: 1026461.4810\n",
      "(Validation) Loss: 1067040.0305, MAE: 4055.6858, R2: 0.1000\n",
      "==========================================================================================\n",
      "Epoch [2143/5000] | Time: 0.24s\n",
      "(Training) Loss: 1041924.1177\n",
      "(Validation) Loss: 1066880.1422, MAE: 4061.2566, R2: 0.1001\n",
      "==========================================================================================\n",
      "Epoch [2144/5000] | Time: 0.20s\n",
      "(Training) Loss: 1028658.6206\n",
      "(Validation) Loss: 1066674.9156, MAE: 4053.2642, R2: 0.1003\n",
      "==========================================================================================\n",
      "Epoch [2145/5000] | Time: 0.23s\n",
      "(Training) Loss: 1026420.7373\n",
      "(Validation) Loss: 1066495.8781, MAE: 4052.5542, R2: 0.1004\n",
      "==========================================================================================\n",
      "Epoch [2146/5000] | Time: 0.21s\n",
      "(Training) Loss: 1030674.1574\n",
      "(Validation) Loss: 1066318.3340, MAE: 4054.3518, R2: 0.1006\n",
      "==========================================================================================\n",
      "Epoch [2147/5000] | Time: 0.21s\n",
      "(Training) Loss: 1021613.6954\n",
      "(Validation) Loss: 1066130.8444, MAE: 4051.7083, R2: 0.1007\n",
      "==========================================================================================\n",
      "Epoch [2148/5000] | Time: 0.23s\n",
      "(Training) Loss: 1027023.7354\n",
      "(Validation) Loss: 1065950.9841, MAE: 4050.8025, R2: 0.1009\n",
      "==========================================================================================\n",
      "Epoch [2149/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023505.7367\n",
      "(Validation) Loss: 1065772.3530, MAE: 4050.8894, R2: 0.1010\n",
      "==========================================================================================\n",
      "Epoch [2150/5000] | Time: 0.23s\n",
      "(Training) Loss: 1040080.4581\n",
      "(Validation) Loss: 1065589.9276, MAE: 4049.4924, R2: 0.1012\n",
      "==========================================================================================\n",
      "Epoch [2151/5000] | Time: 0.24s\n",
      "(Training) Loss: 1033410.4112\n",
      "(Validation) Loss: 1065412.4851, MAE: 4050.2988, R2: 0.1013\n",
      "==========================================================================================\n",
      "Epoch [2152/5000] | Time: 0.26s\n",
      "(Training) Loss: 1044013.2881\n",
      "(Validation) Loss: 1065246.2476, MAE: 4052.7664, R2: 0.1015\n",
      "==========================================================================================\n",
      "Epoch [2153/5000] | Time: 0.20s\n",
      "(Training) Loss: 1039010.9797\n",
      "(Validation) Loss: 1065046.6235, MAE: 4049.9199, R2: 0.1016\n",
      "==========================================================================================\n",
      "Epoch [2154/5000] | Time: 0.22s\n",
      "(Training) Loss: 1025169.7951\n",
      "(Validation) Loss: 1064865.3003, MAE: 4048.4915, R2: 0.1018\n",
      "==========================================================================================\n",
      "Epoch [2155/5000] | Time: 0.21s\n",
      "(Training) Loss: 1022195.6339\n",
      "(Validation) Loss: 1064678.6997, MAE: 4046.1133, R2: 0.1019\n",
      "==========================================================================================\n",
      "Epoch [2156/5000] | Time: 0.20s\n",
      "(Training) Loss: 1034121.8756\n",
      "(Validation) Loss: 1064497.6660, MAE: 4045.6536, R2: 0.1021\n",
      "==========================================================================================\n",
      "Epoch [2157/5000] | Time: 0.19s\n",
      "(Training) Loss: 1027204.6180\n",
      "(Validation) Loss: 1064320.2489, MAE: 4046.2053, R2: 0.1022\n",
      "==========================================================================================\n",
      "Epoch [2158/5000] | Time: 0.23s\n",
      "(Training) Loss: 1028450.7992\n",
      "(Validation) Loss: 1064139.9975, MAE: 4046.9558, R2: 0.1024\n",
      "==========================================================================================\n",
      "Epoch [2159/5000] | Time: 0.23s\n",
      "(Training) Loss: 1024153.9835\n",
      "(Validation) Loss: 1063956.4190, MAE: 4044.6423, R2: 0.1025\n",
      "==========================================================================================\n",
      "Epoch [2160/5000] | Time: 0.22s\n",
      "(Training) Loss: 1044598.3338\n",
      "(Validation) Loss: 1063777.4070, MAE: 4043.4036, R2: 0.1027\n",
      "==========================================================================================\n",
      "Epoch [2161/5000] | Time: 0.24s\n",
      "(Training) Loss: 1024950.4695\n",
      "(Validation) Loss: 1063534.8724, MAE: 4048.4363, R2: 0.1029\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2162/5000] | Time: 0.21s\n",
      "(Training) Loss: 1016549.8165\n",
      "(Validation) Loss: 1063298.2044, MAE: 4035.7480, R2: 0.1031\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2163/5000] | Time: 0.23s\n",
      "(Training) Loss: 1022115.3598\n",
      "(Validation) Loss: 1063117.5924, MAE: 4033.9727, R2: 0.1032\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2164/5000] | Time: 0.22s\n",
      "(Training) Loss: 1034692.4289\n",
      "(Validation) Loss: 1062938.9410, MAE: 4033.1289, R2: 0.1034\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2165/5000] | Time: 0.20s\n",
      "(Training) Loss: 1020063.2468\n",
      "(Validation) Loss: 1062759.0451, MAE: 4032.1682, R2: 0.1035\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2166/5000] | Time: 0.20s\n",
      "(Training) Loss: 1025945.5076\n",
      "(Validation) Loss: 1062581.4146, MAE: 4031.9849, R2: 0.1037\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2167/5000] | Time: 0.20s\n",
      "(Training) Loss: 1025967.1751\n",
      "(Validation) Loss: 1062399.3651, MAE: 4031.1160, R2: 0.1038\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2168/5000] | Time: 0.21s\n",
      "(Training) Loss: 1034185.8858\n",
      "(Validation) Loss: 1062269.0743, MAE: 4034.6455, R2: 0.1039\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2169/5000] | Time: 0.24s\n",
      "(Training) Loss: 1027909.9937\n",
      "(Validation) Loss: 1062092.3327, MAE: 4035.4504, R2: 0.1041\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2170/5000] | Time: 0.21s\n",
      "(Training) Loss: 1023576.1707\n",
      "(Validation) Loss: 1061903.9695, MAE: 4033.0315, R2: 0.1043\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2171/5000] | Time: 0.20s\n",
      "(Training) Loss: 1046451.2208\n",
      "(Validation) Loss: 1061722.3111, MAE: 4032.4263, R2: 0.1044\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2172/5000] | Time: 0.20s\n",
      "(Training) Loss: 1027935.5482\n",
      "(Validation) Loss: 1061538.0165, MAE: 4029.9253, R2: 0.1046\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2173/5000] | Time: 0.20s\n",
      "(Training) Loss: 1027018.7430\n",
      "(Validation) Loss: 1061364.9168, MAE: 4032.2402, R2: 0.1047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2174/5000] | Time: 0.20s\n",
      "(Training) Loss: 1019549.2563\n",
      "(Validation) Loss: 1061173.8006, MAE: 4029.6196, R2: 0.1049\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2175/5000] | Time: 0.20s\n",
      "(Training) Loss: 1027026.7646\n",
      "(Validation) Loss: 1061001.4730, MAE: 4029.3735, R2: 0.1050\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2176/5000] | Time: 0.22s\n",
      "(Training) Loss: 1043328.6504\n",
      "(Validation) Loss: 1060749.6127, MAE: 4026.7676, R2: 0.1052\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2177/5000] | Time: 0.19s\n",
      "(Training) Loss: 1026332.7227\n",
      "(Validation) Loss: 1060550.5321, MAE: 4021.1758, R2: 0.1054\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2178/5000] | Time: 0.20s\n",
      "(Training) Loss: 1017374.5631\n",
      "(Validation) Loss: 1060421.1302, MAE: 4030.3257, R2: 0.1055\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2179/5000] | Time: 0.22s\n",
      "(Training) Loss: 1023362.7405\n",
      "(Validation) Loss: 1060230.7403, MAE: 4024.2227, R2: 0.1056\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2180/5000] | Time: 0.22s\n",
      "(Training) Loss: 1042672.5362\n",
      "(Validation) Loss: 1060028.9930, MAE: 4023.1204, R2: 0.1058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2181/5000] | Time: 0.21s\n",
      "(Training) Loss: 1028004.6675\n",
      "(Validation) Loss: 1059873.3816, MAE: 4024.2971, R2: 0.1059\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2182/5000] | Time: 0.25s\n",
      "(Training) Loss: 1052907.7900\n",
      "(Validation) Loss: 1059683.0578, MAE: 4020.4856, R2: 0.1061\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2183/5000] | Time: 0.21s\n",
      "(Training) Loss: 1033246.2893\n",
      "(Validation) Loss: 1059501.9632, MAE: 4020.1206, R2: 0.1063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2184/5000] | Time: 0.20s\n",
      "(Training) Loss: 1036956.9239\n",
      "(Validation) Loss: 1059322.5448, MAE: 4019.8894, R2: 0.1064\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2185/5000] | Time: 0.21s\n",
      "(Training) Loss: 1034362.7214\n",
      "(Validation) Loss: 1059176.1575, MAE: 4023.9802, R2: 0.1065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2186/5000] | Time: 0.20s\n",
      "(Training) Loss: 1020160.9937\n",
      "(Validation) Loss: 1059011.9721, MAE: 4023.7949, R2: 0.1067\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2187/5000] | Time: 0.20s\n",
      "(Training) Loss: 1015771.7040\n",
      "(Validation) Loss: 1058830.4457, MAE: 4023.2957, R2: 0.1068\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2188/5000] | Time: 0.22s\n",
      "(Training) Loss: 1024282.7805\n",
      "(Validation) Loss: 1058648.7467, MAE: 4020.9358, R2: 0.1070\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2189/5000] | Time: 0.22s\n",
      "(Training) Loss: 1030676.3580\n",
      "(Validation) Loss: 1058464.6756, MAE: 4019.7932, R2: 0.1071\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2190/5000] | Time: 0.25s\n",
      "(Training) Loss: 1017071.0044\n",
      "(Validation) Loss: 1058283.2406, MAE: 4019.4968, R2: 0.1073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2191/5000] | Time: 0.22s\n",
      "(Training) Loss: 1020225.7059\n",
      "(Validation) Loss: 1058100.5105, MAE: 4018.3889, R2: 0.1074\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2192/5000] | Time: 0.22s\n",
      "(Training) Loss: 1023917.2995\n",
      "(Validation) Loss: 1057928.1778, MAE: 4018.6035, R2: 0.1076\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2193/5000] | Time: 0.22s\n",
      "(Training) Loss: 1016500.6713\n",
      "(Validation) Loss: 1057750.7302, MAE: 4020.2422, R2: 0.1077\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2194/5000] | Time: 0.25s\n",
      "(Training) Loss: 1024313.5038\n",
      "(Validation) Loss: 1057565.4959, MAE: 4017.0239, R2: 0.1079\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2195/5000] | Time: 0.23s\n",
      "(Training) Loss: 1037344.3706\n",
      "(Validation) Loss: 1057382.7048, MAE: 4014.8228, R2: 0.1080\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2196/5000] | Time: 0.31s\n",
      "(Training) Loss: 1018783.0844\n",
      "(Validation) Loss: 1057209.8844, MAE: 4017.0156, R2: 0.1082\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2197/5000] | Time: 0.22s\n",
      "(Training) Loss: 1027907.5539\n",
      "(Validation) Loss: 1057022.9435, MAE: 4015.0049, R2: 0.1083\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2198/5000] | Time: 0.20s\n",
      "(Training) Loss: 1019705.2697\n",
      "(Validation) Loss: 1056841.5543, MAE: 4013.6089, R2: 0.1085\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2199/5000] | Time: 0.21s\n",
      "(Training) Loss: 1020700.5070\n",
      "(Validation) Loss: 1056665.4832, MAE: 4014.4050, R2: 0.1086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2200/5000] | Time: 0.23s\n",
      "(Training) Loss: 1021121.2462\n",
      "(Validation) Loss: 1056488.1473, MAE: 4015.4429, R2: 0.1088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2201/5000] | Time: 0.23s\n",
      "(Training) Loss: 1020219.1662\n",
      "(Validation) Loss: 1056301.3283, MAE: 4013.4775, R2: 0.1089\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2202/5000] | Time: 0.21s\n",
      "(Training) Loss: 1032085.1980\n",
      "(Validation) Loss: 1056132.8965, MAE: 4014.6716, R2: 0.1091\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2203/5000] | Time: 0.22s\n",
      "(Training) Loss: 1022771.8769\n",
      "(Validation) Loss: 1055943.7359, MAE: 4012.1353, R2: 0.1092\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2204/5000] | Time: 0.24s\n",
      "(Training) Loss: 1017876.6840\n",
      "(Validation) Loss: 1055759.5987, MAE: 4011.4546, R2: 0.1094\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2205/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023036.8204\n",
      "(Validation) Loss: 1055586.6311, MAE: 4012.7593, R2: 0.1095\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2206/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012821.9952\n",
      "(Validation) Loss: 1055404.5867, MAE: 4010.2346, R2: 0.1097\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2207/5000] | Time: 0.23s\n",
      "(Training) Loss: 1018319.7081\n",
      "(Validation) Loss: 1055223.4210, MAE: 4009.2322, R2: 0.1098\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2208/5000] | Time: 0.24s\n",
      "(Training) Loss: 1049368.7887\n",
      "(Validation) Loss: 1055093.7346, MAE: 4014.0220, R2: 0.1099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2209/5000] | Time: 0.24s\n",
      "(Training) Loss: 1020851.0527\n",
      "(Validation) Loss: 1054858.3263, MAE: 4007.8416, R2: 0.1101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2210/5000] | Time: 0.20s\n",
      "(Training) Loss: 1057692.0596\n",
      "(Validation) Loss: 1054689.3765, MAE: 4009.1492, R2: 0.1103\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2211/5000] | Time: 0.22s\n",
      "(Training) Loss: 1017049.8794\n",
      "(Validation) Loss: 1054492.5867, MAE: 4006.1758, R2: 0.1104\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2212/5000] | Time: 0.22s\n",
      "(Training) Loss: 1040725.6402\n",
      "(Validation) Loss: 1054312.4317, MAE: 4004.9399, R2: 0.1106\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2213/5000] | Time: 0.22s\n",
      "(Training) Loss: 1021644.2030\n",
      "(Validation) Loss: 1049208.6806, MAE: 3997.7793, R2: 0.1148\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2214/5000] | Time: 0.24s\n",
      "(Training) Loss: 1021399.6028\n",
      "(Validation) Loss: 1051585.5898, MAE: 4001.7197, R2: 0.1128\n",
      "==========================================================================================\n",
      "Epoch [2215/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006991.3207\n",
      "(Validation) Loss: 1051398.4914, MAE: 3999.5515, R2: 0.1130\n",
      "==========================================================================================\n",
      "Epoch [2216/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010707.5159\n",
      "(Validation) Loss: 1051230.0394, MAE: 3997.7302, R2: 0.1131\n",
      "==========================================================================================\n",
      "Epoch [2217/5000] | Time: 0.22s\n",
      "(Training) Loss: 1018353.9410\n",
      "(Validation) Loss: 1051063.0552, MAE: 3997.6829, R2: 0.1133\n",
      "==========================================================================================\n",
      "Epoch [2218/5000] | Time: 0.23s\n",
      "(Training) Loss: 1035023.2329\n",
      "(Validation) Loss: 1050894.1511, MAE: 3996.7131, R2: 0.1134\n",
      "==========================================================================================\n",
      "Epoch [2219/5000] | Time: 0.28s\n",
      "(Training) Loss: 1009967.9397\n",
      "(Validation) Loss: 1050723.0984, MAE: 3995.8735, R2: 0.1136\n",
      "==========================================================================================\n",
      "Epoch [2220/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014753.2421\n",
      "(Validation) Loss: 1050554.8089, MAE: 3993.2517, R2: 0.1137\n",
      "==========================================================================================\n",
      "Epoch [2221/5000] | Time: 0.22s\n",
      "(Training) Loss: 1052744.3480\n",
      "(Validation) Loss: 1050382.0902, MAE: 3992.4102, R2: 0.1139\n",
      "==========================================================================================\n",
      "Epoch [2222/5000] | Time: 0.25s\n",
      "(Training) Loss: 1013887.0984\n",
      "(Validation) Loss: 1050210.0724, MAE: 3991.5349, R2: 0.1140\n",
      "==========================================================================================\n",
      "Epoch [2223/5000] | Time: 0.25s\n",
      "(Training) Loss: 1047980.9797\n",
      "(Validation) Loss: 1050038.0902, MAE: 3989.6311, R2: 0.1141\n",
      "==========================================================================================\n",
      "Epoch [2224/5000] | Time: 0.25s\n",
      "(Training) Loss: 1006129.6878\n",
      "(Validation) Loss: 1049868.1803, MAE: 3990.9207, R2: 0.1143\n",
      "==========================================================================================\n",
      "Epoch [2225/5000] | Time: 0.26s\n",
      "(Training) Loss: 1018471.6104\n",
      "(Validation) Loss: 1049699.9010, MAE: 3988.9844, R2: 0.1144\n",
      "==========================================================================================\n",
      "Epoch [2226/5000] | Time: 0.22s\n",
      "(Training) Loss: 1018827.1859\n",
      "(Validation) Loss: 1049539.7841, MAE: 3997.5588, R2: 0.1146\n",
      "==========================================================================================\n",
      "Epoch [2227/5000] | Time: 0.22s\n",
      "(Training) Loss: 1018939.4740\n",
      "(Validation) Loss: 1049343.9187, MAE: 3990.3096, R2: 0.1147\n",
      "==========================================================================================\n",
      "Epoch [2228/5000] | Time: 0.25s\n",
      "(Training) Loss: 1015222.2570\n",
      "(Validation) Loss: 1049231.4260, MAE: 3999.3157, R2: 0.1148\n",
      "==========================================================================================\n",
      "Epoch [2229/5000] | Time: 0.22s\n",
      "(Training) Loss: 1025879.3617\n",
      "(Validation) Loss: 1049001.3308, MAE: 3987.1509, R2: 0.1150\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2230/5000] | Time: 0.24s\n",
      "(Training) Loss: 1033017.1110\n",
      "(Validation) Loss: 1048865.5035, MAE: 3989.0701, R2: 0.1151\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2231/5000] | Time: 0.24s\n",
      "(Training) Loss: 1030254.2944\n",
      "(Validation) Loss: 1048690.2248, MAE: 3985.6885, R2: 0.1153\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2232/5000] | Time: 0.27s\n",
      "(Training) Loss: 1018143.9467\n",
      "(Validation) Loss: 1048525.2114, MAE: 3986.7234, R2: 0.1154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2233/5000] | Time: 0.23s\n",
      "(Training) Loss: 1030078.5901\n",
      "(Validation) Loss: 1048352.9498, MAE: 3984.0886, R2: 0.1155\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2234/5000] | Time: 0.22s\n",
      "(Training) Loss: 1014195.0266\n",
      "(Validation) Loss: 1048183.0705, MAE: 3984.5315, R2: 0.1157\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2235/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007693.6523\n",
      "(Validation) Loss: 1048013.2368, MAE: 3983.1060, R2: 0.1158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2236/5000] | Time: 0.26s\n",
      "(Training) Loss: 1020471.3877\n",
      "(Validation) Loss: 1041871.8984, MAE: 3966.3435, R2: 0.1209\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2237/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009096.6478\n",
      "(Validation) Loss: 1048834.6159, MAE: 3997.7263, R2: 0.1151\n",
      "==========================================================================================\n",
      "Epoch [2238/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012619.4524\n",
      "(Validation) Loss: 1043326.7657, MAE: 3967.6978, R2: 0.1197\n",
      "==========================================================================================\n",
      "Epoch [2239/5000] | Time: 0.22s\n",
      "(Training) Loss: 1038611.5761\n",
      "(Validation) Loss: 1043142.5473, MAE: 3966.8647, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [2240/5000] | Time: 0.23s\n",
      "(Training) Loss: 1002749.7938\n",
      "(Validation) Loss: 1042964.7797, MAE: 3968.0996, R2: 0.1200\n",
      "==========================================================================================\n",
      "Epoch [2241/5000] | Time: 0.22s\n",
      "(Training) Loss: 1025008.0444\n",
      "(Validation) Loss: 1042791.6343, MAE: 3968.0337, R2: 0.1202\n",
      "==========================================================================================\n",
      "Epoch [2242/5000] | Time: 0.27s\n",
      "(Training) Loss: 1013035.3629\n",
      "(Validation) Loss: 1042600.8381, MAE: 3964.7676, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [2243/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010459.8471\n",
      "(Validation) Loss: 1042426.8902, MAE: 3964.4451, R2: 0.1205\n",
      "==========================================================================================\n",
      "Epoch [2244/5000] | Time: 0.23s\n",
      "(Training) Loss: 1022468.2310\n",
      "(Validation) Loss: 1042252.4292, MAE: 3963.8711, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [2245/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005324.7563\n",
      "(Validation) Loss: 1042072.7111, MAE: 3962.8020, R2: 0.1208\n",
      "==========================================================================================\n",
      "Epoch [2246/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014307.9886\n",
      "(Validation) Loss: 1041922.9917, MAE: 3969.3149, R2: 0.1209\n",
      "==========================================================================================\n",
      "Epoch [2247/5000] | Time: 0.25s\n",
      "(Training) Loss: 1031797.7881\n",
      "(Validation) Loss: 1041745.0057, MAE: 3967.7781, R2: 0.1211\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2248/5000] | Time: 0.25s\n",
      "(Training) Loss: 1013816.8382\n",
      "(Validation) Loss: 1041589.9124, MAE: 3973.7380, R2: 0.1212\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2249/5000] | Time: 0.23s\n",
      "(Training) Loss: 1029200.9365\n",
      "(Validation) Loss: 1041384.1524, MAE: 3963.0845, R2: 0.1214\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2250/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008312.4937\n",
      "(Validation) Loss: 1041206.0343, MAE: 3961.2314, R2: 0.1215\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2251/5000] | Time: 0.27s\n",
      "(Training) Loss: 1000619.4791\n",
      "(Validation) Loss: 1041044.2311, MAE: 3962.2507, R2: 0.1216\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2252/5000] | Time: 0.25s\n",
      "(Training) Loss: 996874.1735\n",
      "(Validation) Loss: 1040868.5308, MAE: 3960.5200, R2: 0.1218\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2253/5000] | Time: 0.26s\n",
      "(Training) Loss: 1007108.9429\n",
      "(Validation) Loss: 1040700.8965, MAE: 3962.1016, R2: 0.1219\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2254/5000] | Time: 0.27s\n",
      "(Training) Loss: 1045107.7411\n",
      "(Validation) Loss: 1040527.1263, MAE: 3961.1621, R2: 0.1221\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2255/5000] | Time: 0.27s\n",
      "(Training) Loss: 1006861.8731\n",
      "(Validation) Loss: 1044174.6032, MAE: 3974.5000, R2: 0.1192\n",
      "==========================================================================================\n",
      "Epoch [2256/5000] | Time: 0.27s\n",
      "(Training) Loss: 1014775.9391\n",
      "(Validation) Loss: 1040188.2971, MAE: 3962.3196, R2: 0.1223\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2257/5000] | Time: 0.29s\n",
      "(Training) Loss: 996611.2766\n",
      "(Validation) Loss: 1040002.0368, MAE: 3961.0596, R2: 0.1225\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2258/5000] | Time: 0.27s\n",
      "(Training) Loss: 1014809.2037\n",
      "(Validation) Loss: 1039875.5860, MAE: 3967.9771, R2: 0.1226\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2259/5000] | Time: 0.28s\n",
      "(Training) Loss: 1015270.2881\n",
      "(Validation) Loss: 1054096.3505, MAE: 4008.9644, R2: 0.1108\n",
      "==========================================================================================\n",
      "Epoch [2260/5000] | Time: 0.24s\n",
      "(Training) Loss: 1028026.7088\n",
      "(Validation) Loss: 1053904.3505, MAE: 4002.0198, R2: 0.1109\n",
      "==========================================================================================\n",
      "Epoch [2261/5000] | Time: 0.26s\n",
      "(Training) Loss: 1030756.6954\n",
      "(Validation) Loss: 1053731.6927, MAE: 4003.6736, R2: 0.1111\n",
      "==========================================================================================\n",
      "Epoch [2262/5000] | Time: 0.29s\n",
      "(Training) Loss: 1018279.1104\n",
      "(Validation) Loss: 1053555.6825, MAE: 4002.0178, R2: 0.1112\n",
      "==========================================================================================\n",
      "Epoch [2263/5000] | Time: 0.32s\n",
      "(Training) Loss: 1046095.5514\n",
      "(Validation) Loss: 1053420.1346, MAE: 4004.0518, R2: 0.1113\n",
      "==========================================================================================\n",
      "Epoch [2264/5000] | Time: 0.30s\n",
      "(Training) Loss: 1033403.8591\n",
      "(Validation) Loss: 1053244.1905, MAE: 4002.8982, R2: 0.1115\n",
      "==========================================================================================\n",
      "Epoch [2265/5000] | Time: 0.26s\n",
      "(Training) Loss: 1007552.0335\n",
      "(Validation) Loss: 1053068.6679, MAE: 4003.8159, R2: 0.1116\n",
      "==========================================================================================\n",
      "Epoch [2266/5000] | Time: 0.25s\n",
      "(Training) Loss: 1027631.7621\n",
      "(Validation) Loss: 1052900.4800, MAE: 4003.4521, R2: 0.1118\n",
      "==========================================================================================\n",
      "Epoch [2267/5000] | Time: 0.28s\n",
      "(Training) Loss: 1014519.1758\n",
      "(Validation) Loss: 1052700.6730, MAE: 4007.0032, R2: 0.1119\n",
      "==========================================================================================\n",
      "Epoch [2268/5000] | Time: 0.26s\n",
      "(Training) Loss: 1021854.0089\n",
      "(Validation) Loss: 1052513.7371, MAE: 4002.0469, R2: 0.1121\n",
      "==========================================================================================\n",
      "Epoch [2269/5000] | Time: 0.29s\n",
      "(Training) Loss: 1029113.6720\n",
      "(Validation) Loss: 1047526.9537, MAE: 3985.7092, R2: 0.1162\n",
      "==========================================================================================\n",
      "Epoch [2270/5000] | Time: 0.28s\n",
      "(Training) Loss: 1025107.0514\n",
      "(Validation) Loss: 1047367.5479, MAE: 3981.7092, R2: 0.1164\n",
      "==========================================================================================\n",
      "Epoch [2271/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019579.9822\n",
      "(Validation) Loss: 1047235.8603, MAE: 3986.8804, R2: 0.1165\n",
      "==========================================================================================\n",
      "Epoch [2272/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010431.0996\n",
      "(Validation) Loss: 1047055.2686, MAE: 3984.0906, R2: 0.1166\n",
      "==========================================================================================\n",
      "Epoch [2273/5000] | Time: 0.23s\n",
      "(Training) Loss: 1015194.8706\n",
      "(Validation) Loss: 1046893.9327, MAE: 3984.5129, R2: 0.1168\n",
      "==========================================================================================\n",
      "Epoch [2274/5000] | Time: 0.22s\n",
      "(Training) Loss: 1025603.1218\n",
      "(Validation) Loss: 1046712.3962, MAE: 3980.5835, R2: 0.1169\n",
      "==========================================================================================\n",
      "Epoch [2275/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010357.1929\n",
      "(Validation) Loss: 1046543.7511, MAE: 3980.0950, R2: 0.1171\n",
      "==========================================================================================\n",
      "Epoch [2276/5000] | Time: 0.22s\n",
      "(Training) Loss: 1017917.1079\n",
      "(Validation) Loss: 1046376.7365, MAE: 3980.6831, R2: 0.1172\n",
      "==========================================================================================\n",
      "Epoch [2277/5000] | Time: 0.22s\n",
      "(Training) Loss: 1003236.3008\n",
      "(Validation) Loss: 1046236.2159, MAE: 3981.4153, R2: 0.1173\n",
      "==========================================================================================\n",
      "Epoch [2278/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008954.1085\n",
      "(Validation) Loss: 1046039.8425, MAE: 3979.1545, R2: 0.1175\n",
      "==========================================================================================\n",
      "Epoch [2279/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009055.2481\n",
      "(Validation) Loss: 1045886.6489, MAE: 3983.6267, R2: 0.1176\n",
      "==========================================================================================\n",
      "Epoch [2280/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012981.7881\n",
      "(Validation) Loss: 1045697.1835, MAE: 3976.0151, R2: 0.1178\n",
      "==========================================================================================\n",
      "Epoch [2281/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002833.0955\n",
      "(Validation) Loss: 1045528.9346, MAE: 3975.5881, R2: 0.1179\n",
      "==========================================================================================\n",
      "Epoch [2282/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007653.2893\n",
      "(Validation) Loss: 1045363.1340, MAE: 3975.4680, R2: 0.1180\n",
      "==========================================================================================\n",
      "Epoch [2283/5000] | Time: 0.29s\n",
      "(Training) Loss: 1012506.3407\n",
      "(Validation) Loss: 1045251.5200, MAE: 3979.1155, R2: 0.1181\n",
      "==========================================================================================\n",
      "Epoch [2284/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007594.9892\n",
      "(Validation) Loss: 1045041.1429, MAE: 3980.1343, R2: 0.1183\n",
      "==========================================================================================\n",
      "Epoch [2285/5000] | Time: 0.23s\n",
      "(Training) Loss: 1020052.3319\n",
      "(Validation) Loss: 1044870.5727, MAE: 3978.5442, R2: 0.1184\n",
      "==========================================================================================\n",
      "Epoch [2286/5000] | Time: 0.25s\n",
      "(Training) Loss: 1007884.8147\n",
      "(Validation) Loss: 1044700.2921, MAE: 3977.7378, R2: 0.1186\n",
      "==========================================================================================\n",
      "Epoch [2287/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010145.3192\n",
      "(Validation) Loss: 1044528.0711, MAE: 3975.6060, R2: 0.1187\n",
      "==========================================================================================\n",
      "Epoch [2288/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010740.9854\n",
      "(Validation) Loss: 1044422.6438, MAE: 3976.9756, R2: 0.1188\n",
      "==========================================================================================\n",
      "Epoch [2289/5000] | Time: 0.22s\n",
      "(Training) Loss: 1006817.8344\n",
      "(Validation) Loss: 1044185.7727, MAE: 3971.7683, R2: 0.1190\n",
      "==========================================================================================\n",
      "Epoch [2290/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004511.2678\n",
      "(Validation) Loss: 1044032.5689, MAE: 3974.7317, R2: 0.1191\n",
      "==========================================================================================\n",
      "Epoch [2291/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014332.7912\n",
      "(Validation) Loss: 1043863.0756, MAE: 3973.5701, R2: 0.1193\n",
      "==========================================================================================\n",
      "Epoch [2292/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009107.0263\n",
      "(Validation) Loss: 1043685.9581, MAE: 3972.7766, R2: 0.1194\n",
      "==========================================================================================\n",
      "Epoch [2293/5000] | Time: 0.25s\n",
      "(Training) Loss: 1007564.1507\n",
      "(Validation) Loss: 1043521.6863, MAE: 3971.5115, R2: 0.1196\n",
      "==========================================================================================\n",
      "Epoch [2294/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007089.6079\n",
      "(Validation) Loss: 1043365.9835, MAE: 3974.2661, R2: 0.1197\n",
      "==========================================================================================\n",
      "Epoch [2295/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019380.3515\n",
      "(Validation) Loss: 1043173.1606, MAE: 3966.5239, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [2296/5000] | Time: 0.23s\n",
      "(Training) Loss: 1006837.2690\n",
      "(Validation) Loss: 1043004.9575, MAE: 3966.4915, R2: 0.1200\n",
      "==========================================================================================\n",
      "Epoch [2297/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010105.9905\n",
      "(Validation) Loss: 1042839.4159, MAE: 3966.2927, R2: 0.1201\n",
      "==========================================================================================\n",
      "Epoch [2298/5000] | Time: 0.23s\n",
      "(Training) Loss: 1002092.2995\n",
      "(Validation) Loss: 1042668.2870, MAE: 3965.0632, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [2299/5000] | Time: 0.23s\n",
      "(Training) Loss: 1019322.1897\n",
      "(Validation) Loss: 1042497.6863, MAE: 3963.7546, R2: 0.1204\n",
      "==========================================================================================\n",
      "Epoch [2300/5000] | Time: 0.22s\n",
      "(Training) Loss: 997848.1783\n",
      "(Validation) Loss: 1042329.4121, MAE: 3964.5137, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [2301/5000] | Time: 0.21s\n",
      "(Training) Loss: 1009354.1802\n",
      "(Validation) Loss: 1042167.7562, MAE: 3963.2058, R2: 0.1207\n",
      "==========================================================================================\n",
      "Epoch [2302/5000] | Time: 0.25s\n",
      "(Training) Loss: 1004842.3426\n",
      "(Validation) Loss: 1041999.6089, MAE: 3963.2292, R2: 0.1208\n",
      "==========================================================================================\n",
      "Epoch [2303/5000] | Time: 0.24s\n",
      "(Training) Loss: 1009033.2195\n",
      "(Validation) Loss: 1041830.7860, MAE: 3961.8369, R2: 0.1210\n",
      "==========================================================================================\n",
      "Epoch [2304/5000] | Time: 0.23s\n",
      "(Training) Loss: 1011585.2722\n",
      "(Validation) Loss: 1041660.5105, MAE: 3961.1013, R2: 0.1211\n",
      "==========================================================================================\n",
      "Epoch [2305/5000] | Time: 0.22s\n",
      "(Training) Loss: 1017259.1269\n",
      "(Validation) Loss: 1041497.3714, MAE: 3961.7451, R2: 0.1213\n",
      "==========================================================================================\n",
      "Epoch [2306/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010836.3414\n",
      "(Validation) Loss: 1041324.0990, MAE: 3960.6426, R2: 0.1214\n",
      "==========================================================================================\n",
      "Epoch [2307/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007885.8020\n",
      "(Validation) Loss: 1041158.9435, MAE: 3960.5750, R2: 0.1215\n",
      "==========================================================================================\n",
      "Epoch [2308/5000] | Time: 0.23s\n",
      "(Training) Loss: 1003663.6180\n",
      "(Validation) Loss: 1040989.6330, MAE: 3959.3076, R2: 0.1217\n",
      "==========================================================================================\n",
      "Epoch [2309/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000634.1669\n",
      "(Validation) Loss: 1040817.8286, MAE: 3957.9399, R2: 0.1218\n",
      "==========================================================================================\n",
      "Epoch [2310/5000] | Time: 0.23s\n",
      "(Training) Loss: 1032181.2259\n",
      "(Validation) Loss: 1040657.1886, MAE: 3958.8147, R2: 0.1220\n",
      "==========================================================================================\n",
      "Epoch [2311/5000] | Time: 0.25s\n",
      "(Training) Loss: 1013895.6662\n",
      "(Validation) Loss: 1040486.6743, MAE: 3959.3318, R2: 0.1221\n",
      "==========================================================================================\n",
      "Epoch [2312/5000] | Time: 0.24s\n",
      "(Training) Loss: 1032846.9429\n",
      "(Validation) Loss: 1040322.5143, MAE: 3958.0229, R2: 0.1222\n",
      "==========================================================================================\n",
      "Epoch [2313/5000] | Time: 0.24s\n",
      "(Training) Loss: 1003774.6412\n",
      "(Validation) Loss: 1040158.9587, MAE: 3960.5859, R2: 0.1224\n",
      "==========================================================================================\n",
      "Epoch [2314/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001188.0343\n",
      "(Validation) Loss: 1040030.1359, MAE: 3959.3818, R2: 0.1225\n",
      "==========================================================================================\n",
      "Epoch [2315/5000] | Time: 0.21s\n",
      "(Training) Loss: 1011029.0755\n",
      "(Validation) Loss: 1039866.4686, MAE: 3960.4797, R2: 0.1226\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2316/5000] | Time: 0.22s\n",
      "(Training) Loss: 1020369.2855\n",
      "(Validation) Loss: 1039696.0711, MAE: 3958.7830, R2: 0.1228\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2317/5000] | Time: 0.25s\n",
      "(Training) Loss: 1008616.2088\n",
      "(Validation) Loss: 1039528.8838, MAE: 3958.9927, R2: 0.1229\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2318/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005202.2570\n",
      "(Validation) Loss: 1039375.3092, MAE: 3963.8940, R2: 0.1230\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2319/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004363.4848\n",
      "(Validation) Loss: 1039195.4946, MAE: 3958.3577, R2: 0.1232\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2320/5000] | Time: 0.23s\n",
      "(Training) Loss: 1006110.2011\n",
      "(Validation) Loss: 1039029.5975, MAE: 3958.1677, R2: 0.1233\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2321/5000] | Time: 0.21s\n",
      "(Training) Loss: 1022553.2056\n",
      "(Validation) Loss: 1038862.4152, MAE: 3956.4602, R2: 0.1234\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2322/5000] | Time: 0.25s\n",
      "(Training) Loss: 1013460.7081\n",
      "(Validation) Loss: 1038687.0603, MAE: 3954.4607, R2: 0.1236\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2323/5000] | Time: 0.25s\n",
      "(Training) Loss: 993577.8275\n",
      "(Validation) Loss: 1038524.1244, MAE: 3955.4946, R2: 0.1237\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2324/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004831.1459\n",
      "(Validation) Loss: 1038358.2273, MAE: 3954.9041, R2: 0.1239\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2325/5000] | Time: 0.24s\n",
      "(Training) Loss: 1000878.5051\n",
      "(Validation) Loss: 1038196.1092, MAE: 3955.0229, R2: 0.1240\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2326/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010075.1250\n",
      "(Validation) Loss: 1038024.7010, MAE: 3954.2092, R2: 0.1241\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2327/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014475.6307\n",
      "(Validation) Loss: 1037856.0762, MAE: 3952.4460, R2: 0.1243\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2328/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001133.7030\n",
      "(Validation) Loss: 1037692.6578, MAE: 3954.5256, R2: 0.1244\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2329/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000768.6313\n",
      "(Validation) Loss: 1037522.0114, MAE: 3951.6099, R2: 0.1246\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2330/5000] | Time: 0.24s\n",
      "(Training) Loss: 1014390.6269\n",
      "(Validation) Loss: 1037353.8844, MAE: 3950.8950, R2: 0.1247\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2331/5000] | Time: 0.23s\n",
      "(Training) Loss: 998185.4632\n",
      "(Validation) Loss: 1037186.6108, MAE: 3949.8782, R2: 0.1248\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2332/5000] | Time: 0.24s\n",
      "(Training) Loss: 1009364.0812\n",
      "(Validation) Loss: 1037022.5625, MAE: 3950.4102, R2: 0.1250\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2333/5000] | Time: 0.21s\n",
      "(Training) Loss: 997802.8128\n",
      "(Validation) Loss: 1036862.9638, MAE: 3951.3247, R2: 0.1251\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2334/5000] | Time: 0.21s\n",
      "(Training) Loss: 998380.4004\n",
      "(Validation) Loss: 1036754.4737, MAE: 3953.5532, R2: 0.1252\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2335/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002103.7570\n",
      "(Validation) Loss: 1036530.9105, MAE: 3951.0063, R2: 0.1254\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2336/5000] | Time: 0.20s\n",
      "(Training) Loss: 991747.8398\n",
      "(Validation) Loss: 1036353.9200, MAE: 3948.0088, R2: 0.1255\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2337/5000] | Time: 0.22s\n",
      "(Training) Loss: 1021914.6789\n",
      "(Validation) Loss: 1036187.0273, MAE: 3946.1614, R2: 0.1257\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2338/5000] | Time: 0.22s\n",
      "(Training) Loss: 996521.4702\n",
      "(Validation) Loss: 1036021.2521, MAE: 3948.0811, R2: 0.1258\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2339/5000] | Time: 0.22s\n",
      "(Training) Loss: 1014710.2494\n",
      "(Validation) Loss: 1035851.9568, MAE: 3945.9707, R2: 0.1260\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2340/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019519.5952\n",
      "(Validation) Loss: 1035684.1854, MAE: 3945.5688, R2: 0.1261\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2341/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014212.0070\n",
      "(Validation) Loss: 1035516.7746, MAE: 3945.3521, R2: 0.1262\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2342/5000] | Time: 0.24s\n",
      "(Training) Loss: 995577.1694\n",
      "(Validation) Loss: 1035361.5594, MAE: 3947.4080, R2: 0.1264\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2343/5000] | Time: 0.20s\n",
      "(Training) Loss: 1009615.7024\n",
      "(Validation) Loss: 1035212.2463, MAE: 3951.7239, R2: 0.1265\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2344/5000] | Time: 0.20s\n",
      "(Training) Loss: 1002390.8319\n",
      "(Validation) Loss: 1035027.6622, MAE: 3945.8311, R2: 0.1266\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2345/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004219.4473\n",
      "(Validation) Loss: 1034851.3930, MAE: 3942.7410, R2: 0.1268\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2346/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019586.1015\n",
      "(Validation) Loss: 1034682.9003, MAE: 3941.7488, R2: 0.1269\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2347/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004750.1459\n",
      "(Validation) Loss: 1034526.0800, MAE: 3943.0972, R2: 0.1271\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2348/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002097.2881\n",
      "(Validation) Loss: 1034353.0514, MAE: 3941.2126, R2: 0.1272\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2349/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008752.8909\n",
      "(Validation) Loss: 1034179.5200, MAE: 3938.4136, R2: 0.1274\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2350/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004593.8357\n",
      "(Validation) Loss: 1034014.6641, MAE: 3939.3237, R2: 0.1275\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2351/5000] | Time: 0.21s\n",
      "(Training) Loss: 998288.0197\n",
      "(Validation) Loss: 1033852.0483, MAE: 3940.3435, R2: 0.1276\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2352/5000] | Time: 0.27s\n",
      "(Training) Loss: 1006483.3610\n",
      "(Validation) Loss: 1033717.5568, MAE: 3943.0759, R2: 0.1277\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2353/5000] | Time: 0.21s\n",
      "(Training) Loss: 1018917.7500\n",
      "(Validation) Loss: 1033530.4686, MAE: 3942.4341, R2: 0.1279\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2354/5000] | Time: 0.19s\n",
      "(Training) Loss: 1026611.3249\n",
      "(Validation) Loss: 1033351.9746, MAE: 3938.4854, R2: 0.1280\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2355/5000] | Time: 0.27s\n",
      "(Training) Loss: 1008844.0013\n",
      "(Validation) Loss: 1033175.1111, MAE: 3935.7305, R2: 0.1282\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2356/5000] | Time: 0.24s\n",
      "(Training) Loss: 1009238.2690\n",
      "(Validation) Loss: 1033010.9359, MAE: 3935.6799, R2: 0.1283\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2357/5000] | Time: 0.24s\n",
      "(Training) Loss: 1000301.1003\n",
      "(Validation) Loss: 1032852.2362, MAE: 3937.9829, R2: 0.1285\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2358/5000] | Time: 0.22s\n",
      "(Training) Loss: 1032465.3122\n",
      "(Validation) Loss: 1032673.7625, MAE: 3933.4978, R2: 0.1286\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2359/5000] | Time: 0.22s\n",
      "(Training) Loss: 995733.2443\n",
      "(Validation) Loss: 1032505.8540, MAE: 3933.1011, R2: 0.1287\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2360/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007747.6688\n",
      "(Validation) Loss: 1032339.6267, MAE: 3933.0007, R2: 0.1289\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2361/5000] | Time: 0.20s\n",
      "(Training) Loss: 996261.3985\n",
      "(Validation) Loss: 1032176.2743, MAE: 3932.6311, R2: 0.1290\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2362/5000] | Time: 0.21s\n",
      "(Training) Loss: 1010676.7437\n",
      "(Validation) Loss: 1032024.8229, MAE: 3934.5825, R2: 0.1291\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2363/5000] | Time: 0.23s\n",
      "(Training) Loss: 996431.3071\n",
      "(Validation) Loss: 1031911.1314, MAE: 3936.5137, R2: 0.1292\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2364/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002775.6123\n",
      "(Validation) Loss: 1031745.7067, MAE: 3935.9714, R2: 0.1294\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2365/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001110.7259\n",
      "(Validation) Loss: 1031583.4210, MAE: 3936.1245, R2: 0.1295\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2366/5000] | Time: 0.23s\n",
      "(Training) Loss: 991569.8490\n",
      "(Validation) Loss: 1031417.5543, MAE: 3936.6775, R2: 0.1297\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2367/5000] | Time: 0.24s\n",
      "(Training) Loss: 995598.7912\n",
      "(Validation) Loss: 1031249.6152, MAE: 3935.7832, R2: 0.1298\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2368/5000] | Time: 0.23s\n",
      "(Training) Loss: 1007622.3947\n",
      "(Validation) Loss: 1031076.2006, MAE: 3932.3323, R2: 0.1299\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2369/5000] | Time: 0.20s\n",
      "(Training) Loss: 1013674.7081\n",
      "(Validation) Loss: 1030911.5378, MAE: 3933.3562, R2: 0.1301\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2370/5000] | Time: 0.20s\n",
      "(Training) Loss: 999486.5723\n",
      "(Validation) Loss: 1030746.1638, MAE: 3932.8723, R2: 0.1302\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2371/5000] | Time: 0.19s\n",
      "(Training) Loss: 1001662.1926\n",
      "(Validation) Loss: 1030581.9022, MAE: 3932.4980, R2: 0.1303\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2372/5000] | Time: 0.21s\n",
      "(Training) Loss: 992165.1453\n",
      "(Validation) Loss: 1030423.2940, MAE: 3933.8306, R2: 0.1305\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2373/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011929.8896\n",
      "(Validation) Loss: 1030254.2730, MAE: 3933.3474, R2: 0.1306\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2374/5000] | Time: 0.19s\n",
      "(Training) Loss: 1001211.7722\n",
      "(Validation) Loss: 1030080.8990, MAE: 3931.0525, R2: 0.1308\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2375/5000] | Time: 0.19s\n",
      "(Training) Loss: 1023576.7843\n",
      "(Validation) Loss: 1029913.5340, MAE: 3929.1572, R2: 0.1309\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2376/5000] | Time: 0.19s\n",
      "(Training) Loss: 993874.3503\n",
      "(Validation) Loss: 1029743.4717, MAE: 3928.7400, R2: 0.1310\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2377/5000] | Time: 0.23s\n",
      "(Training) Loss: 997154.1358\n",
      "(Validation) Loss: 1029580.8914, MAE: 3929.2336, R2: 0.1312\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2378/5000] | Time: 0.23s\n",
      "(Training) Loss: 1013093.3230\n",
      "(Validation) Loss: 1029417.8692, MAE: 3928.6621, R2: 0.1313\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2379/5000] | Time: 0.19s\n",
      "(Training) Loss: 1004935.8978\n",
      "(Validation) Loss: 1029250.0775, MAE: 3927.9204, R2: 0.1315\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2380/5000] | Time: 0.19s\n",
      "(Training) Loss: 1002163.7234\n",
      "(Validation) Loss: 1029083.6876, MAE: 3926.7632, R2: 0.1316\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2381/5000] | Time: 0.19s\n",
      "(Training) Loss: 992587.1028\n",
      "(Validation) Loss: 1028920.4978, MAE: 3927.9131, R2: 0.1317\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2382/5000] | Time: 0.20s\n",
      "(Training) Loss: 991670.3074\n",
      "(Validation) Loss: 1028785.7422, MAE: 3936.5933, R2: 0.1318\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2383/5000] | Time: 0.22s\n",
      "(Training) Loss: 994229.9036\n",
      "(Validation) Loss: 1028586.8952, MAE: 3923.7959, R2: 0.1320\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2384/5000] | Time: 0.21s\n",
      "(Training) Loss: 1006816.1244\n",
      "(Validation) Loss: 1028423.0197, MAE: 3924.9426, R2: 0.1321\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2385/5000] | Time: 0.20s\n",
      "(Training) Loss: 999608.2430\n",
      "(Validation) Loss: 1028256.0863, MAE: 3925.8433, R2: 0.1323\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2386/5000] | Time: 0.20s\n",
      "(Training) Loss: 1007260.5286\n",
      "(Validation) Loss: 1028089.9251, MAE: 3923.0583, R2: 0.1324\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2387/5000] | Time: 0.19s\n",
      "(Training) Loss: 1026495.4657\n",
      "(Validation) Loss: 1027926.5016, MAE: 3923.5437, R2: 0.1326\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2388/5000] | Time: 0.20s\n",
      "(Training) Loss: 989208.8242\n",
      "(Validation) Loss: 1027767.3651, MAE: 3925.9253, R2: 0.1327\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2389/5000] | Time: 0.19s\n",
      "(Training) Loss: 998374.9334\n",
      "(Validation) Loss: 1027597.8057, MAE: 3928.0881, R2: 0.1328\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2390/5000] | Time: 0.22s\n",
      "(Training) Loss: 996969.0057\n",
      "(Validation) Loss: 1027424.0356, MAE: 3921.5303, R2: 0.1330\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2391/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000088.3090\n",
      "(Validation) Loss: 1027261.3079, MAE: 3922.0137, R2: 0.1331\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2392/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007206.8706\n",
      "(Validation) Loss: 1027095.5429, MAE: 3920.3533, R2: 0.1333\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2393/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010346.6802\n",
      "(Validation) Loss: 1026931.9314, MAE: 3919.6384, R2: 0.1334\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2394/5000] | Time: 0.24s\n",
      "(Training) Loss: 983303.3073\n",
      "(Validation) Loss: 1026773.3333, MAE: 3922.7517, R2: 0.1335\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2395/5000] | Time: 0.20s\n",
      "(Training) Loss: 1007379.8871\n",
      "(Validation) Loss: 1026606.0394, MAE: 3921.6042, R2: 0.1337\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2396/5000] | Time: 0.18s\n",
      "(Training) Loss: 1026506.3049\n",
      "(Validation) Loss: 1026433.1378, MAE: 3917.9207, R2: 0.1338\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2397/5000] | Time: 0.19s\n",
      "(Training) Loss: 1013714.5381\n",
      "(Validation) Loss: 1026265.6660, MAE: 3917.0603, R2: 0.1339\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2398/5000] | Time: 0.20s\n",
      "(Training) Loss: 1010929.8731\n",
      "(Validation) Loss: 1026099.3625, MAE: 3917.2708, R2: 0.1341\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2399/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004776.3629\n",
      "(Validation) Loss: 1025963.2610, MAE: 3925.2473, R2: 0.1342\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2400/5000] | Time: 0.23s\n",
      "(Training) Loss: 986749.8598\n",
      "(Validation) Loss: 1025762.3416, MAE: 3915.1245, R2: 0.1344\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2401/5000] | Time: 0.22s\n",
      "(Training) Loss: 986374.0355\n",
      "(Validation) Loss: 1025601.2140, MAE: 3915.4048, R2: 0.1345\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2402/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009259.8550\n",
      "(Validation) Loss: 1025439.1060, MAE: 3914.4785, R2: 0.1346\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2403/5000] | Time: 0.20s\n",
      "(Training) Loss: 1017826.0076\n",
      "(Validation) Loss: 1025273.0463, MAE: 3913.6511, R2: 0.1348\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2404/5000] | Time: 0.21s\n",
      "(Training) Loss: 981794.7956\n",
      "(Validation) Loss: 1025142.2883, MAE: 3925.2305, R2: 0.1349\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2405/5000] | Time: 0.23s\n",
      "(Training) Loss: 1003746.3737\n",
      "(Validation) Loss: 1024945.8895, MAE: 3915.3464, R2: 0.1350\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2406/5000] | Time: 0.20s\n",
      "(Training) Loss: 989644.0920\n",
      "(Validation) Loss: 1024775.3956, MAE: 3912.0081, R2: 0.1352\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2407/5000] | Time: 0.23s\n",
      "(Training) Loss: 992717.8176\n",
      "(Validation) Loss: 1024612.6832, MAE: 3912.0559, R2: 0.1353\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2408/5000] | Time: 0.20s\n",
      "(Training) Loss: 995293.3236\n",
      "(Validation) Loss: 1024453.3333, MAE: 3912.4460, R2: 0.1355\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2409/5000] | Time: 0.20s\n",
      "(Training) Loss: 985109.9975\n",
      "(Validation) Loss: 1024286.8978, MAE: 3911.0149, R2: 0.1356\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2410/5000] | Time: 0.21s\n",
      "(Training) Loss: 996245.7843\n",
      "(Validation) Loss: 1024125.9937, MAE: 3911.4436, R2: 0.1357\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2411/5000] | Time: 0.23s\n",
      "(Training) Loss: 991492.3071\n",
      "(Validation) Loss: 1023980.3683, MAE: 3911.7927, R2: 0.1359\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2412/5000] | Time: 0.23s\n",
      "(Training) Loss: 983443.7110\n",
      "(Validation) Loss: 1023797.0387, MAE: 3909.8862, R2: 0.1360\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2413/5000] | Time: 0.24s\n",
      "(Training) Loss: 999864.7373\n",
      "(Validation) Loss: 1023640.1016, MAE: 3909.9429, R2: 0.1361\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2414/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001739.5489\n",
      "(Validation) Loss: 1023494.3441, MAE: 3912.3691, R2: 0.1363\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2415/5000] | Time: 0.23s\n",
      "(Training) Loss: 997274.8363\n",
      "(Validation) Loss: 1023303.0451, MAE: 3907.0210, R2: 0.1364\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2416/5000] | Time: 0.20s\n",
      "(Training) Loss: 999058.4905\n",
      "(Validation) Loss: 1023087.1162, MAE: 3904.7656, R2: 0.1366\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2417/5000] | Time: 0.21s\n",
      "(Training) Loss: 997057.4632\n",
      "(Validation) Loss: 1022975.3092, MAE: 3906.3982, R2: 0.1367\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2418/5000] | Time: 0.21s\n",
      "(Training) Loss: 996163.6231\n",
      "(Validation) Loss: 1022805.1251, MAE: 3904.4119, R2: 0.1368\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2419/5000] | Time: 0.22s\n",
      "(Training) Loss: 987803.7253\n",
      "(Validation) Loss: 1022645.3384, MAE: 3904.5525, R2: 0.1370\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2420/5000] | Time: 0.20s\n",
      "(Training) Loss: 1000003.9759\n",
      "(Validation) Loss: 1022477.9581, MAE: 3903.5286, R2: 0.1371\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2421/5000] | Time: 0.20s\n",
      "(Training) Loss: 995391.1110\n",
      "(Validation) Loss: 1022315.2813, MAE: 3903.4390, R2: 0.1372\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2422/5000] | Time: 0.22s\n",
      "(Training) Loss: 983380.5489\n",
      "(Validation) Loss: 1022153.3359, MAE: 3905.2451, R2: 0.1374\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2423/5000] | Time: 0.20s\n",
      "(Training) Loss: 994468.8255\n",
      "(Validation) Loss: 1021989.1352, MAE: 3903.3752, R2: 0.1375\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2424/5000] | Time: 0.22s\n",
      "(Training) Loss: 985649.7792\n",
      "(Validation) Loss: 1021820.0737, MAE: 3900.7837, R2: 0.1377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2425/5000] | Time: 0.23s\n",
      "(Training) Loss: 982396.7538\n",
      "(Validation) Loss: 1021663.4006, MAE: 3903.3623, R2: 0.1378\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2426/5000] | Time: 0.21s\n",
      "(Training) Loss: 997172.4131\n",
      "(Validation) Loss: 1021507.9517, MAE: 3906.5098, R2: 0.1379\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2427/5000] | Time: 0.19s\n",
      "(Training) Loss: 994689.2868\n",
      "(Validation) Loss: 1021333.6940, MAE: 3901.4961, R2: 0.1381\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2428/5000] | Time: 0.24s\n",
      "(Training) Loss: 977910.1133\n",
      "(Validation) Loss: 1021169.6102, MAE: 3899.6589, R2: 0.1382\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2429/5000] | Time: 0.23s\n",
      "(Training) Loss: 999606.6009\n",
      "(Validation) Loss: 1021083.9619, MAE: 3904.0918, R2: 0.1383\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2430/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005441.2989\n",
      "(Validation) Loss: 1020921.1530, MAE: 3904.3108, R2: 0.1384\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2431/5000] | Time: 0.27s\n",
      "(Training) Loss: 993764.0755\n",
      "(Validation) Loss: 1020757.4248, MAE: 3906.5125, R2: 0.1385\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2432/5000] | Time: 0.26s\n",
      "(Training) Loss: 979149.1504\n",
      "(Validation) Loss: 1020588.1549, MAE: 3903.5718, R2: 0.1387\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2433/5000] | Time: 0.23s\n",
      "(Training) Loss: 992061.5114\n",
      "(Validation) Loss: 1020435.0883, MAE: 3905.7104, R2: 0.1388\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2434/5000] | Time: 0.25s\n",
      "(Training) Loss: 991246.4616\n",
      "(Validation) Loss: 1020259.7740, MAE: 3901.1174, R2: 0.1389\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2435/5000] | Time: 0.23s\n",
      "(Training) Loss: 978881.1361\n",
      "(Validation) Loss: 1020100.2667, MAE: 3902.4585, R2: 0.1391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2436/5000] | Time: 0.24s\n",
      "(Training) Loss: 979878.0441\n",
      "(Validation) Loss: 1019952.1067, MAE: 3905.0349, R2: 0.1392\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2437/5000] | Time: 0.21s\n",
      "(Training) Loss: 980926.1459\n",
      "(Validation) Loss: 1019772.6781, MAE: 3900.3604, R2: 0.1394\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2438/5000] | Time: 0.20s\n",
      "(Training) Loss: 986522.3192\n",
      "(Validation) Loss: 1019608.2184, MAE: 3898.1604, R2: 0.1395\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2439/5000] | Time: 0.19s\n",
      "(Training) Loss: 993949.9626\n",
      "(Validation) Loss: 1019443.9619, MAE: 3898.1353, R2: 0.1396\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2440/5000] | Time: 0.19s\n",
      "(Training) Loss: 985074.5381\n",
      "(Validation) Loss: 1019284.4038, MAE: 3898.1438, R2: 0.1398\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2441/5000] | Time: 0.19s\n",
      "(Training) Loss: 979515.1269\n",
      "(Validation) Loss: 1019118.3644, MAE: 3897.3215, R2: 0.1399\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2442/5000] | Time: 0.22s\n",
      "(Training) Loss: 996749.9794\n",
      "(Validation) Loss: 1018953.2698, MAE: 3896.3152, R2: 0.1400\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2443/5000] | Time: 0.22s\n",
      "(Training) Loss: 990690.0330\n",
      "(Validation) Loss: 1018793.5594, MAE: 3896.4390, R2: 0.1402\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2444/5000] | Time: 0.19s\n",
      "(Training) Loss: 994989.3338\n",
      "(Validation) Loss: 1018564.3987, MAE: 3896.6746, R2: 0.1404\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2445/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002751.5076\n",
      "(Validation) Loss: 1018387.9924, MAE: 3892.6328, R2: 0.1405\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2446/5000] | Time: 0.21s\n",
      "(Training) Loss: 1000689.4816\n",
      "(Validation) Loss: 1018213.4857, MAE: 3888.1301, R2: 0.1407\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2447/5000] | Time: 0.20s\n",
      "(Training) Loss: 980732.3953\n",
      "(Validation) Loss: 1018055.2279, MAE: 3889.2598, R2: 0.1408\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2448/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012668.3185\n",
      "(Validation) Loss: 1017894.7251, MAE: 3890.4407, R2: 0.1409\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2449/5000] | Time: 0.23s\n",
      "(Training) Loss: 978538.2551\n",
      "(Validation) Loss: 1017721.7879, MAE: 3886.8386, R2: 0.1411\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2450/5000] | Time: 0.22s\n",
      "(Training) Loss: 985863.1720\n",
      "(Validation) Loss: 1017565.8971, MAE: 3888.8311, R2: 0.1412\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2451/5000] | Time: 0.23s\n",
      "(Training) Loss: 990464.1180\n",
      "(Validation) Loss: 1017393.7016, MAE: 3884.9844, R2: 0.1413\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2452/5000] | Time: 0.23s\n",
      "(Training) Loss: 978163.5470\n",
      "(Validation) Loss: 1017231.4565, MAE: 3885.4504, R2: 0.1415\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2453/5000] | Time: 0.20s\n",
      "(Training) Loss: 981631.2925\n",
      "(Validation) Loss: 1017067.9568, MAE: 3885.2969, R2: 0.1416\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2454/5000] | Time: 0.23s\n",
      "(Training) Loss: 986451.4251\n",
      "(Validation) Loss: 1016906.5397, MAE: 3883.6096, R2: 0.1417\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2455/5000] | Time: 0.23s\n",
      "(Training) Loss: 982936.1364\n",
      "(Validation) Loss: 1016743.2381, MAE: 3881.9558, R2: 0.1419\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2456/5000] | Time: 0.22s\n",
      "(Training) Loss: 973875.2267\n",
      "(Validation) Loss: 1016578.8241, MAE: 3881.8584, R2: 0.1420\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2457/5000] | Time: 0.23s\n",
      "(Training) Loss: 999348.5723\n",
      "(Validation) Loss: 1016429.1810, MAE: 3884.0159, R2: 0.1421\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2458/5000] | Time: 0.22s\n",
      "(Training) Loss: 987733.9575\n",
      "(Validation) Loss: 1016257.2698, MAE: 3881.3601, R2: 0.1423\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2459/5000] | Time: 0.24s\n",
      "(Training) Loss: 977613.9315\n",
      "(Validation) Loss: 1016093.8565, MAE: 3881.1899, R2: 0.1424\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2460/5000] | Time: 0.21s\n",
      "(Training) Loss: 1000191.5133\n",
      "(Validation) Loss: 1015932.3530, MAE: 3880.9546, R2: 0.1426\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2461/5000] | Time: 0.25s\n",
      "(Training) Loss: 992411.1650\n",
      "(Validation) Loss: 1015764.6984, MAE: 3880.0774, R2: 0.1427\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2462/5000] | Time: 0.26s\n",
      "(Training) Loss: 996615.8693\n",
      "(Validation) Loss: 1015599.5581, MAE: 3878.7773, R2: 0.1428\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2463/5000] | Time: 0.20s\n",
      "(Training) Loss: 976867.2310\n",
      "(Validation) Loss: 1015439.3448, MAE: 3878.6809, R2: 0.1430\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2464/5000] | Time: 0.21s\n",
      "(Training) Loss: 999449.3477\n",
      "(Validation) Loss: 1015278.9943, MAE: 3880.2366, R2: 0.1431\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2465/5000] | Time: 0.23s\n",
      "(Training) Loss: 986952.7240\n",
      "(Validation) Loss: 1015113.3917, MAE: 3878.2234, R2: 0.1432\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2466/5000] | Time: 0.22s\n",
      "(Training) Loss: 982399.7551\n",
      "(Validation) Loss: 1014943.9746, MAE: 3876.2949, R2: 0.1434\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2467/5000] | Time: 0.41s\n",
      "(Training) Loss: 974087.9584\n",
      "(Validation) Loss: 1014781.4248, MAE: 3875.9009, R2: 0.1435\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2468/5000] | Time: 0.24s\n",
      "(Training) Loss: 978545.0838\n",
      "(Validation) Loss: 1014627.9060, MAE: 3878.3982, R2: 0.1436\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2469/5000] | Time: 0.22s\n",
      "(Training) Loss: 996209.0673\n",
      "(Validation) Loss: 1014461.5162, MAE: 3876.2092, R2: 0.1438\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2470/5000] | Time: 0.21s\n",
      "(Training) Loss: 981263.1022\n",
      "(Validation) Loss: 1014295.7257, MAE: 3875.4104, R2: 0.1439\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2471/5000] | Time: 0.20s\n",
      "(Training) Loss: 977227.1815\n",
      "(Validation) Loss: 1014134.8724, MAE: 3875.3555, R2: 0.1441\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2472/5000] | Time: 0.20s\n",
      "(Training) Loss: 983555.1015\n",
      "(Validation) Loss: 1013967.1822, MAE: 3872.6028, R2: 0.1442\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2473/5000] | Time: 0.19s\n",
      "(Training) Loss: 998388.0774\n",
      "(Validation) Loss: 1013806.6997, MAE: 3872.7593, R2: 0.1443\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2474/5000] | Time: 0.20s\n",
      "(Training) Loss: 982356.7462\n",
      "(Validation) Loss: 1013644.5613, MAE: 3873.0422, R2: 0.1445\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2475/5000] | Time: 0.31s\n",
      "(Training) Loss: 975404.4841\n",
      "(Validation) Loss: 1013482.9410, MAE: 3872.8225, R2: 0.1446\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2476/5000] | Time: 0.26s\n",
      "(Training) Loss: 988884.0254\n",
      "(Validation) Loss: 1013315.1137, MAE: 3869.6360, R2: 0.1447\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2477/5000] | Time: 0.19s\n",
      "(Training) Loss: 971933.1377\n",
      "(Validation) Loss: 1013155.1644, MAE: 3870.0537, R2: 0.1449\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2478/5000] | Time: 0.20s\n",
      "(Training) Loss: 977401.0298\n",
      "(Validation) Loss: 1013003.9822, MAE: 3871.6658, R2: 0.1450\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2479/5000] | Time: 0.19s\n",
      "(Training) Loss: 984925.7291\n",
      "(Validation) Loss: 1012828.0737, MAE: 3868.3901, R2: 0.1451\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2480/5000] | Time: 0.21s\n",
      "(Training) Loss: 973018.4013\n",
      "(Validation) Loss: 1012616.4114, MAE: 3864.4880, R2: 0.1453\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2481/5000] | Time: 0.20s\n",
      "(Training) Loss: 986126.5489\n",
      "(Validation) Loss: 1012478.2324, MAE: 3871.0737, R2: 0.1454\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2482/5000] | Time: 0.23s\n",
      "(Training) Loss: 984582.3198\n",
      "(Validation) Loss: 1012341.5975, MAE: 3867.4343, R2: 0.1456\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2483/5000] | Time: 0.20s\n",
      "(Training) Loss: 976889.6263\n",
      "(Validation) Loss: 1012203.0070, MAE: 3871.0183, R2: 0.1457\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2484/5000] | Time: 0.20s\n",
      "(Training) Loss: 972594.5984\n",
      "(Validation) Loss: 1012029.0997, MAE: 3869.7747, R2: 0.1458\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2485/5000] | Time: 0.24s\n",
      "(Training) Loss: 982426.9429\n",
      "(Validation) Loss: 1011823.7613, MAE: 3866.8232, R2: 0.1460\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2486/5000] | Time: 0.39s\n",
      "(Training) Loss: 979907.5216\n",
      "(Validation) Loss: 1011656.1016, MAE: 3863.2124, R2: 0.1461\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2487/5000] | Time: 0.21s\n",
      "(Training) Loss: 992101.5203\n",
      "(Validation) Loss: 1011501.9124, MAE: 3865.6350, R2: 0.1463\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2488/5000] | Time: 0.19s\n",
      "(Training) Loss: 981588.7602\n",
      "(Validation) Loss: 1011333.0692, MAE: 3865.0996, R2: 0.1464\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2489/5000] | Time: 0.53s\n",
      "(Training) Loss: 984469.7227\n",
      "(Validation) Loss: 1011164.2971, MAE: 3862.4153, R2: 0.1465\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2490/5000] | Time: 0.29s\n",
      "(Training) Loss: 987377.0222\n",
      "(Validation) Loss: 1010993.4883, MAE: 3859.4346, R2: 0.1467\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2491/5000] | Time: 0.33s\n",
      "(Training) Loss: 984891.4734\n",
      "(Validation) Loss: 1010846.7149, MAE: 3863.4539, R2: 0.1468\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2492/5000] | Time: 0.79s\n",
      "(Training) Loss: 970403.9746\n",
      "(Validation) Loss: 1010671.9492, MAE: 3859.6716, R2: 0.1469\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2493/5000] | Time: 0.88s\n",
      "(Training) Loss: 972685.9029\n",
      "(Validation) Loss: 1010506.3060, MAE: 3857.5952, R2: 0.1471\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2494/5000] | Time: 1.03s\n",
      "(Training) Loss: 983800.6510\n",
      "(Validation) Loss: 1010319.4921, MAE: 3857.1470, R2: 0.1472\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2495/5000] | Time: 1.06s\n",
      "(Training) Loss: 981485.2265\n",
      "(Validation) Loss: 1010146.9816, MAE: 3852.7803, R2: 0.1474\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2496/5000] | Time: 0.96s\n",
      "(Training) Loss: 987539.2652\n",
      "(Validation) Loss: 1010132.0483, MAE: 3857.7729, R2: 0.1474\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2497/5000] | Time: 0.88s\n",
      "(Training) Loss: 982907.9911\n",
      "(Validation) Loss: 1009824.7517, MAE: 3852.3904, R2: 0.1477\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2498/5000] | Time: 1.18s\n",
      "(Training) Loss: 998110.2329\n",
      "(Validation) Loss: 1009691.3219, MAE: 3854.0371, R2: 0.1478\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2499/5000] | Time: 1.04s\n",
      "(Training) Loss: 983813.4797\n",
      "(Validation) Loss: 1009530.3162, MAE: 3854.3491, R2: 0.1479\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2500/5000] | Time: 0.83s\n",
      "(Training) Loss: 984439.4023\n",
      "(Validation) Loss: 1009368.3454, MAE: 3853.6638, R2: 0.1480\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch2500.pth\n",
      "==========================================================================================\n",
      "Epoch [2501/5000] | Time: 0.89s\n",
      "(Training) Loss: 968954.1923\n",
      "(Validation) Loss: 1009213.0590, MAE: 3857.4880, R2: 0.1482\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2502/5000] | Time: 1.11s\n",
      "(Training) Loss: 984171.8522\n",
      "(Validation) Loss: 1009050.9105, MAE: 3853.0276, R2: 0.1483\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2503/5000] | Time: 0.80s\n",
      "(Training) Loss: 968691.5476\n",
      "(Validation) Loss: 1008878.9943, MAE: 3851.2312, R2: 0.1484\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2504/5000] | Time: 0.87s\n",
      "(Training) Loss: 973498.1472\n",
      "(Validation) Loss: 1008721.6356, MAE: 3850.6165, R2: 0.1486\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2505/5000] | Time: 0.82s\n",
      "(Training) Loss: 979329.3858\n",
      "(Validation) Loss: 1008557.3892, MAE: 3849.3308, R2: 0.1487\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2506/5000] | Time: 0.80s\n",
      "(Training) Loss: 990135.1948\n",
      "(Validation) Loss: 1008394.6463, MAE: 3848.2126, R2: 0.1488\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2507/5000] | Time: 0.80s\n",
      "(Training) Loss: 975054.0254\n",
      "(Validation) Loss: 1008236.9067, MAE: 3850.1343, R2: 0.1490\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2508/5000] | Time: 0.78s\n",
      "(Training) Loss: 994165.7963\n",
      "(Validation) Loss: 1008068.4902, MAE: 3850.6934, R2: 0.1491\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2509/5000] | Time: 0.67s\n",
      "(Training) Loss: 969562.7418\n",
      "(Validation) Loss: 1007919.7663, MAE: 3853.7080, R2: 0.1492\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2510/5000] | Time: 0.75s\n",
      "(Training) Loss: 971697.0546\n",
      "(Validation) Loss: 1007744.2844, MAE: 3853.2800, R2: 0.1494\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2511/5000] | Time: 1.03s\n",
      "(Training) Loss: 980093.1808\n",
      "(Validation) Loss: 1007567.9238, MAE: 3848.8457, R2: 0.1495\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2512/5000] | Time: 0.98s\n",
      "(Training) Loss: 974878.2931\n",
      "(Validation) Loss: 1007403.7486, MAE: 3846.9673, R2: 0.1497\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2513/5000] | Time: 0.83s\n",
      "(Training) Loss: 974417.5822\n",
      "(Validation) Loss: 1007239.1060, MAE: 3845.1277, R2: 0.1498\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2514/5000] | Time: 0.79s\n",
      "(Training) Loss: 978651.8566\n",
      "(Validation) Loss: 1007066.6159, MAE: 3841.7070, R2: 0.1500\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2515/5000] | Time: 0.77s\n",
      "(Training) Loss: 972582.1694\n",
      "(Validation) Loss: 1006904.8990, MAE: 3840.7537, R2: 0.1501\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2516/5000] | Time: 0.92s\n",
      "(Training) Loss: 975987.5901\n",
      "(Validation) Loss: 1006766.3238, MAE: 3844.7842, R2: 0.1502\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2517/5000] | Time: 0.36s\n",
      "(Training) Loss: 976887.6529\n",
      "(Validation) Loss: 1006582.9841, MAE: 3840.1299, R2: 0.1504\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2518/5000] | Time: 0.35s\n",
      "(Training) Loss: 974203.3280\n",
      "(Validation) Loss: 1006420.5816, MAE: 3839.3110, R2: 0.1505\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2519/5000] | Time: 0.62s\n",
      "(Training) Loss: 963661.5349\n",
      "(Validation) Loss: 1006258.8648, MAE: 3838.6355, R2: 0.1506\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2520/5000] | Time: 0.94s\n",
      "(Training) Loss: 979877.5971\n",
      "(Validation) Loss: 1006134.1765, MAE: 3840.6541, R2: 0.1507\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2521/5000] | Time: 1.00s\n",
      "(Training) Loss: 965664.4156\n",
      "(Validation) Loss: 1005974.2781, MAE: 3841.1946, R2: 0.1509\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2522/5000] | Time: 0.99s\n",
      "(Training) Loss: 979558.2766\n",
      "(Validation) Loss: 1005825.8032, MAE: 3846.0718, R2: 0.1510\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2523/5000] | Time: 0.77s\n",
      "(Training) Loss: 970041.9695\n",
      "(Validation) Loss: 1005651.7892, MAE: 3841.2507, R2: 0.1511\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2524/5000] | Time: 0.38s\n",
      "(Training) Loss: 982825.8610\n",
      "(Validation) Loss: 1005488.4978, MAE: 3840.0574, R2: 0.1513\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2525/5000] | Time: 0.28s\n",
      "(Training) Loss: 967668.2747\n",
      "(Validation) Loss: 1005344.6197, MAE: 3843.0500, R2: 0.1514\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2526/5000] | Time: 0.34s\n",
      "(Training) Loss: 984445.0197\n",
      "(Validation) Loss: 1005175.6292, MAE: 3840.7537, R2: 0.1515\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2527/5000] | Time: 0.35s\n",
      "(Training) Loss: 979237.3737\n",
      "(Validation) Loss: 1005002.0775, MAE: 3837.4790, R2: 0.1517\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2528/5000] | Time: 0.34s\n",
      "(Training) Loss: 987835.1313\n",
      "(Validation) Loss: 1004851.8044, MAE: 3840.8723, R2: 0.1518\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2529/5000] | Time: 0.29s\n",
      "(Training) Loss: 975431.5736\n",
      "(Validation) Loss: 1004684.2006, MAE: 3840.0308, R2: 0.1519\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2530/5000] | Time: 0.31s\n",
      "(Training) Loss: 985103.2659\n",
      "(Validation) Loss: 1012314.9054, MAE: 3866.9702, R2: 0.1456\n",
      "==========================================================================================\n",
      "Epoch [2531/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005376.9864\n",
      "(Validation) Loss: 1012156.0584, MAE: 3866.6926, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [2532/5000] | Time: 0.24s\n",
      "(Training) Loss: 980120.4416\n",
      "(Validation) Loss: 1011994.5194, MAE: 3865.4104, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [2533/5000] | Time: 0.33s\n",
      "(Training) Loss: 998151.4467\n",
      "(Validation) Loss: 1011836.1143, MAE: 3865.7622, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [2534/5000] | Time: 0.29s\n",
      "(Training) Loss: 993271.7716\n",
      "(Validation) Loss: 1011673.8946, MAE: 3863.8164, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [2535/5000] | Time: 0.27s\n",
      "(Training) Loss: 976537.9105\n",
      "(Validation) Loss: 1011512.4216, MAE: 3864.3337, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [2536/5000] | Time: 0.23s\n",
      "(Training) Loss: 972425.4645\n",
      "(Validation) Loss: 1011345.6965, MAE: 3863.8521, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [2537/5000] | Time: 0.27s\n",
      "(Training) Loss: 973132.8858\n",
      "(Validation) Loss: 1011189.4451, MAE: 3861.6362, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [2538/5000] | Time: 0.35s\n",
      "(Training) Loss: 972603.7075\n",
      "(Validation) Loss: 1011038.6743, MAE: 3864.6204, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [2539/5000] | Time: 0.31s\n",
      "(Training) Loss: 993352.3553\n",
      "(Validation) Loss: 1010879.5784, MAE: 3862.6790, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [2540/5000] | Time: 0.33s\n",
      "(Training) Loss: 978491.9924\n",
      "(Validation) Loss: 1010706.8597, MAE: 3860.1226, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [2541/5000] | Time: 0.37s\n",
      "(Training) Loss: 972999.3388\n",
      "(Validation) Loss: 1004479.9543, MAE: 3845.2996, R2: 0.1521\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2542/5000] | Time: 0.31s\n",
      "(Training) Loss: 988315.1770\n",
      "(Validation) Loss: 1012165.0438, MAE: 3881.5569, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [2543/5000] | Time: 0.24s\n",
      "(Training) Loss: 1000103.3579\n",
      "(Validation) Loss: 1011986.9714, MAE: 3868.3782, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [2544/5000] | Time: 0.21s\n",
      "(Training) Loss: 1001148.0939\n",
      "(Validation) Loss: 1011828.0483, MAE: 3867.0266, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [2545/5000] | Time: 0.24s\n",
      "(Training) Loss: 986656.6339\n",
      "(Validation) Loss: 1011669.7651, MAE: 3865.8574, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [2546/5000] | Time: 0.26s\n",
      "(Training) Loss: 993900.4695\n",
      "(Validation) Loss: 1011521.0463, MAE: 3866.3372, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [2547/5000] | Time: 0.25s\n",
      "(Training) Loss: 970365.2881\n",
      "(Validation) Loss: 1011375.1721, MAE: 3868.5603, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [2548/5000] | Time: 0.27s\n",
      "(Training) Loss: 983770.3477\n",
      "(Validation) Loss: 1011212.5765, MAE: 3864.4639, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [2549/5000] | Time: 0.32s\n",
      "(Training) Loss: 989212.4112\n",
      "(Validation) Loss: 1011055.9289, MAE: 3863.0596, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [2550/5000] | Time: 0.30s\n",
      "(Training) Loss: 996342.6643\n",
      "(Validation) Loss: 1010904.2997, MAE: 3863.7188, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [2551/5000] | Time: 0.26s\n",
      "(Training) Loss: 973978.3071\n",
      "(Validation) Loss: 1010750.7911, MAE: 3863.2534, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [2552/5000] | Time: 0.26s\n",
      "(Training) Loss: 976957.8585\n",
      "(Validation) Loss: 1010611.9010, MAE: 3865.2393, R2: 0.1470\n",
      "==========================================================================================\n",
      "Epoch [2553/5000] | Time: 0.24s\n",
      "(Training) Loss: 969160.0430\n",
      "(Validation) Loss: 1010453.7651, MAE: 3864.4155, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [2554/5000] | Time: 0.22s\n",
      "(Training) Loss: 975399.1815\n",
      "(Validation) Loss: 1010294.6641, MAE: 3861.0352, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [2555/5000] | Time: 0.19s\n",
      "(Training) Loss: 990064.4949\n",
      "(Validation) Loss: 1010137.4883, MAE: 3860.2473, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [2556/5000] | Time: 0.23s\n",
      "(Training) Loss: 981046.6345\n",
      "(Validation) Loss: 1009979.1492, MAE: 3858.0891, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [2557/5000] | Time: 0.21s\n",
      "(Training) Loss: 986863.1701\n",
      "(Validation) Loss: 1009824.7771, MAE: 3857.9207, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [2558/5000] | Time: 0.24s\n",
      "(Training) Loss: 976473.0130\n",
      "(Validation) Loss: 1009672.8889, MAE: 3857.4155, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [2559/5000] | Time: 0.27s\n",
      "(Training) Loss: 973742.7265\n",
      "(Validation) Loss: 1009523.6825, MAE: 3857.8215, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [2560/5000] | Time: 0.27s\n",
      "(Training) Loss: 982884.5984\n",
      "(Validation) Loss: 1009389.4502, MAE: 3861.5469, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [2561/5000] | Time: 0.34s\n",
      "(Training) Loss: 983960.4334\n",
      "(Validation) Loss: 1009223.6597, MAE: 3860.3149, R2: 0.1482\n",
      "==========================================================================================\n",
      "Epoch [2562/5000] | Time: 0.25s\n",
      "(Training) Loss: 976100.5647\n",
      "(Validation) Loss: 1009045.0032, MAE: 3857.0710, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [2563/5000] | Time: 0.28s\n",
      "(Training) Loss: 975977.7589\n",
      "(Validation) Loss: 1008885.3537, MAE: 3852.9285, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [2564/5000] | Time: 0.21s\n",
      "(Training) Loss: 978913.3027\n",
      "(Validation) Loss: 1008726.3390, MAE: 3851.7195, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [2565/5000] | Time: 0.21s\n",
      "(Training) Loss: 971442.6599\n",
      "(Validation) Loss: 1008568.7924, MAE: 3850.8254, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [2566/5000] | Time: 0.24s\n",
      "(Training) Loss: 988870.1758\n",
      "(Validation) Loss: 1008458.3517, MAE: 3854.3909, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [2567/5000] | Time: 0.25s\n",
      "(Training) Loss: 971447.3407\n",
      "(Validation) Loss: 1008271.3346, MAE: 3850.6362, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [2568/5000] | Time: 0.21s\n",
      "(Training) Loss: 967520.3506\n",
      "(Validation) Loss: 1008145.2444, MAE: 3851.4570, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [2569/5000] | Time: 0.20s\n",
      "(Training) Loss: 974127.9562\n",
      "(Validation) Loss: 1007998.8571, MAE: 3851.4089, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [2570/5000] | Time: 0.20s\n",
      "(Training) Loss: 984623.9518\n",
      "(Validation) Loss: 1007846.6489, MAE: 3851.2937, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [2571/5000] | Time: 0.20s\n",
      "(Training) Loss: 970264.2119\n",
      "(Validation) Loss: 1007696.6248, MAE: 3851.6287, R2: 0.1494\n",
      "==========================================================================================\n",
      "Epoch [2572/5000] | Time: 0.20s\n",
      "(Training) Loss: 988144.4860\n",
      "(Validation) Loss: 1007535.7156, MAE: 3848.8162, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [2573/5000] | Time: 0.19s\n",
      "(Training) Loss: 970379.9765\n",
      "(Validation) Loss: 1007383.6190, MAE: 3849.4888, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [2574/5000] | Time: 0.19s\n",
      "(Training) Loss: 980552.2849\n",
      "(Validation) Loss: 1007233.5238, MAE: 3848.3259, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [2575/5000] | Time: 0.22s\n",
      "(Training) Loss: 971881.6599\n",
      "(Validation) Loss: 1007085.5060, MAE: 3848.8140, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [2576/5000] | Time: 0.21s\n",
      "(Training) Loss: 977318.1117\n",
      "(Validation) Loss: 1006930.2400, MAE: 3848.1350, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [2577/5000] | Time: 0.27s\n",
      "(Training) Loss: 967101.3115\n",
      "(Validation) Loss: 1006771.6317, MAE: 3846.0950, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [2578/5000] | Time: 0.29s\n",
      "(Training) Loss: 965563.6288\n",
      "(Validation) Loss: 1006628.0889, MAE: 3847.9485, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [2579/5000] | Time: 0.23s\n",
      "(Training) Loss: 989371.1637\n",
      "(Validation) Loss: 1006500.6019, MAE: 3852.1309, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [2580/5000] | Time: 0.24s\n",
      "(Training) Loss: 965850.2792\n",
      "(Validation) Loss: 1006320.7975, MAE: 3846.3096, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [2581/5000] | Time: 0.32s\n",
      "(Training) Loss: 980241.3065\n",
      "(Validation) Loss: 1006168.2184, MAE: 3845.7144, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [2582/5000] | Time: 0.29s\n",
      "(Training) Loss: 965227.5909\n",
      "(Validation) Loss: 1006011.9213, MAE: 3843.9685, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [2583/5000] | Time: 0.42s\n",
      "(Training) Loss: 1001697.6263\n",
      "(Validation) Loss: 1005862.6286, MAE: 3842.8872, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [2584/5000] | Time: 0.37s\n",
      "(Training) Loss: 967880.3344\n",
      "(Validation) Loss: 1005712.2438, MAE: 3844.7102, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [2585/5000] | Time: 0.31s\n",
      "(Training) Loss: 969024.6701\n",
      "(Validation) Loss: 1005557.7244, MAE: 3842.7837, R2: 0.1512\n",
      "==========================================================================================\n",
      "Epoch [2586/5000] | Time: 0.26s\n",
      "(Training) Loss: 993141.7570\n",
      "(Validation) Loss: 1005402.4076, MAE: 3841.5647, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [2587/5000] | Time: 0.24s\n",
      "(Training) Loss: 991417.1199\n",
      "(Validation) Loss: 1005248.9041, MAE: 3841.1426, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [2588/5000] | Time: 0.32s\n",
      "(Training) Loss: 972110.1897\n",
      "(Validation) Loss: 1005101.8362, MAE: 3841.9937, R2: 0.1516\n",
      "==========================================================================================\n",
      "Epoch [2589/5000] | Time: 0.28s\n",
      "(Training) Loss: 962516.6270\n",
      "(Validation) Loss: 1004941.7956, MAE: 3840.0942, R2: 0.1517\n",
      "==========================================================================================\n",
      "Epoch [2590/5000] | Time: 0.23s\n",
      "(Training) Loss: 980244.9803\n",
      "(Validation) Loss: 1004793.3613, MAE: 3840.0615, R2: 0.1518\n",
      "==========================================================================================\n",
      "Epoch [2591/5000] | Time: 0.20s\n",
      "(Training) Loss: 969151.6472\n",
      "(Validation) Loss: 1004641.4832, MAE: 3839.5183, R2: 0.1520\n",
      "==========================================================================================\n",
      "Epoch [2592/5000] | Time: 0.21s\n",
      "(Training) Loss: 968626.6916\n",
      "(Validation) Loss: 1004492.4648, MAE: 3841.1082, R2: 0.1521\n",
      "==========================================================================================\n",
      "Epoch [2593/5000] | Time: 0.24s\n",
      "(Training) Loss: 961919.5706\n",
      "(Validation) Loss: 1004342.3492, MAE: 3839.9229, R2: 0.1522\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2594/5000] | Time: 0.21s\n",
      "(Training) Loss: 972491.5114\n",
      "(Validation) Loss: 1004190.5625, MAE: 3838.2107, R2: 0.1523\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2595/5000] | Time: 0.21s\n",
      "(Training) Loss: 981063.7538\n",
      "(Validation) Loss: 1004033.7778, MAE: 3837.5906, R2: 0.1525\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2596/5000] | Time: 0.32s\n",
      "(Training) Loss: 971968.3877\n",
      "(Validation) Loss: 1003919.9390, MAE: 3840.0088, R2: 0.1526\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2597/5000] | Time: 0.20s\n",
      "(Training) Loss: 972688.5933\n",
      "(Validation) Loss: 1003786.0419, MAE: 3842.3428, R2: 0.1527\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2598/5000] | Time: 0.31s\n",
      "(Training) Loss: 970521.8693\n",
      "(Validation) Loss: 1003632.0356, MAE: 3840.8191, R2: 0.1528\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2599/5000] | Time: 0.21s\n",
      "(Training) Loss: 974490.2690\n",
      "(Validation) Loss: 1003428.1600, MAE: 3836.5010, R2: 0.1530\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2600/5000] | Time: 0.21s\n",
      "(Training) Loss: 965943.0311\n",
      "(Validation) Loss: 1003281.3917, MAE: 3836.3728, R2: 0.1531\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2601/5000] | Time: 0.23s\n",
      "(Training) Loss: 981127.0019\n",
      "(Validation) Loss: 1003147.1695, MAE: 3840.4761, R2: 0.1532\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2602/5000] | Time: 0.23s\n",
      "(Training) Loss: 971011.2208\n",
      "(Validation) Loss: 1002982.8114, MAE: 3837.7917, R2: 0.1534\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2603/5000] | Time: 0.27s\n",
      "(Training) Loss: 980772.6193\n",
      "(Validation) Loss: 1002873.0768, MAE: 3837.8818, R2: 0.1534\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2604/5000] | Time: 0.21s\n",
      "(Training) Loss: 977878.9575\n",
      "(Validation) Loss: 1002725.3283, MAE: 3837.4824, R2: 0.1536\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2605/5000] | Time: 0.20s\n",
      "(Training) Loss: 967341.0977\n",
      "(Validation) Loss: 1002570.1029, MAE: 3837.6477, R2: 0.1537\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2606/5000] | Time: 0.20s\n",
      "(Training) Loss: 965265.1999\n",
      "(Validation) Loss: 1002411.4946, MAE: 3835.7683, R2: 0.1538\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2607/5000] | Time: 0.27s\n",
      "(Training) Loss: 991892.3046\n",
      "(Validation) Loss: 1002266.7073, MAE: 3836.6958, R2: 0.1539\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2608/5000] | Time: 0.25s\n",
      "(Training) Loss: 978528.5603\n",
      "(Validation) Loss: 1002111.7257, MAE: 3836.0952, R2: 0.1541\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2609/5000] | Time: 0.36s\n",
      "(Training) Loss: 965159.6980\n",
      "(Validation) Loss: 1001961.9403, MAE: 3835.5930, R2: 0.1542\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2610/5000] | Time: 0.28s\n",
      "(Training) Loss: 987019.8585\n",
      "(Validation) Loss: 1001806.9790, MAE: 3833.8523, R2: 0.1543\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2611/5000] | Time: 0.34s\n",
      "(Training) Loss: 971819.5996\n",
      "(Validation) Loss: 1001653.2165, MAE: 3833.5750, R2: 0.1545\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2612/5000] | Time: 0.33s\n",
      "(Training) Loss: 967221.2576\n",
      "(Validation) Loss: 1001507.6673, MAE: 3833.9331, R2: 0.1546\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2613/5000] | Time: 0.27s\n",
      "(Training) Loss: 980024.7424\n",
      "(Validation) Loss: 1001348.4800, MAE: 3831.2017, R2: 0.1547\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2614/5000] | Time: 0.24s\n",
      "(Training) Loss: 961816.7716\n",
      "(Validation) Loss: 1001197.3130, MAE: 3831.0530, R2: 0.1548\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2615/5000] | Time: 0.25s\n",
      "(Training) Loss: 973662.1174\n",
      "(Validation) Loss: 1001054.5016, MAE: 3833.5876, R2: 0.1550\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2616/5000] | Time: 0.22s\n",
      "(Training) Loss: 979842.1910\n",
      "(Validation) Loss: 1000897.8083, MAE: 3831.2209, R2: 0.1551\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2617/5000] | Time: 0.22s\n",
      "(Training) Loss: 963668.4283\n",
      "(Validation) Loss: 1000746.5295, MAE: 3831.9746, R2: 0.1552\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2618/5000] | Time: 0.23s\n",
      "(Training) Loss: 981650.3931\n",
      "(Validation) Loss: 1000596.6019, MAE: 3830.8982, R2: 0.1553\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2619/5000] | Time: 0.24s\n",
      "(Training) Loss: 971804.3233\n",
      "(Validation) Loss: 1000459.5149, MAE: 3833.8982, R2: 0.1555\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2620/5000] | Time: 0.28s\n",
      "(Training) Loss: 992736.9315\n",
      "(Validation) Loss: 1000287.2635, MAE: 3828.8228, R2: 0.1556\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2621/5000] | Time: 0.25s\n",
      "(Training) Loss: 959923.7056\n",
      "(Validation) Loss: 1000146.1587, MAE: 3830.1257, R2: 0.1557\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2622/5000] | Time: 0.37s\n",
      "(Training) Loss: 968749.2272\n",
      "(Validation) Loss: 999986.6514, MAE: 3828.0242, R2: 0.1558\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2623/5000] | Time: 0.27s\n",
      "(Training) Loss: 971525.4055\n",
      "(Validation) Loss: 999836.7340, MAE: 3826.9958, R2: 0.1560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2624/5000] | Time: 0.25s\n",
      "(Training) Loss: 996924.2075\n",
      "(Validation) Loss: 1015870.4660, MAE: 3891.5527, R2: 0.1426\n",
      "==========================================================================================\n",
      "Epoch [2625/5000] | Time: 0.22s\n",
      "(Training) Loss: 979774.6187\n",
      "(Validation) Loss: 1015685.3994, MAE: 3885.8118, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [2626/5000] | Time: 0.21s\n",
      "(Training) Loss: 984982.3515\n",
      "(Validation) Loss: 1015535.1873, MAE: 3882.9822, R2: 0.1429\n",
      "==========================================================================================\n",
      "Epoch [2627/5000] | Time: 0.20s\n",
      "(Training) Loss: 987489.3902\n",
      "(Validation) Loss: 1015379.2356, MAE: 3883.3025, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [2628/5000] | Time: 0.21s\n",
      "(Training) Loss: 990747.8274\n",
      "(Validation) Loss: 1015226.1283, MAE: 3884.8098, R2: 0.1431\n",
      "==========================================================================================\n",
      "Epoch [2629/5000] | Time: 0.23s\n",
      "(Training) Loss: 981761.9353\n",
      "(Validation) Loss: 1015070.7403, MAE: 3882.0632, R2: 0.1433\n",
      "==========================================================================================\n",
      "Epoch [2630/5000] | Time: 0.22s\n",
      "(Training) Loss: 997746.7849\n",
      "(Validation) Loss: 1014923.7537, MAE: 3884.8699, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [2631/5000] | Time: 0.22s\n",
      "(Training) Loss: 986327.2310\n",
      "(Validation) Loss: 1014749.2724, MAE: 3879.8792, R2: 0.1435\n",
      "==========================================================================================\n",
      "Epoch [2632/5000] | Time: 0.21s\n",
      "(Training) Loss: 990704.9137\n",
      "(Validation) Loss: 1014594.2654, MAE: 3879.0635, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [2633/5000] | Time: 0.35s\n",
      "(Training) Loss: 980656.4613\n",
      "(Validation) Loss: 1014437.3740, MAE: 3879.6248, R2: 0.1438\n",
      "==========================================================================================\n",
      "Epoch [2634/5000] | Time: 0.27s\n",
      "(Training) Loss: 985346.6758\n",
      "(Validation) Loss: 1014283.2152, MAE: 3877.9746, R2: 0.1439\n",
      "==========================================================================================\n",
      "Epoch [2635/5000] | Time: 0.25s\n",
      "(Training) Loss: 979513.2487\n",
      "(Validation) Loss: 1014128.9194, MAE: 3877.8616, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [2636/5000] | Time: 0.21s\n",
      "(Training) Loss: 1008052.0368\n",
      "(Validation) Loss: 1013971.2711, MAE: 3876.6926, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [2637/5000] | Time: 0.31s\n",
      "(Training) Loss: 978792.9074\n",
      "(Validation) Loss: 1013817.8590, MAE: 3878.3118, R2: 0.1443\n",
      "==========================================================================================\n",
      "Epoch [2638/5000] | Time: 0.30s\n",
      "(Training) Loss: 992328.2773\n",
      "(Validation) Loss: 1013662.5270, MAE: 3878.0115, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [2639/5000] | Time: 0.31s\n",
      "(Training) Loss: 975107.4086\n",
      "(Validation) Loss: 1006602.4483, MAE: 3858.0063, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [2640/5000] | Time: 0.31s\n",
      "(Training) Loss: 974431.7887\n",
      "(Validation) Loss: 1006438.7657, MAE: 3857.1609, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [2641/5000] | Time: 0.25s\n",
      "(Training) Loss: 968965.1155\n",
      "(Validation) Loss: 1006395.4337, MAE: 3860.6172, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [2642/5000] | Time: 0.26s\n",
      "(Training) Loss: 982090.7449\n",
      "(Validation) Loss: 1006155.6165, MAE: 3865.5652, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [2643/5000] | Time: 0.26s\n",
      "(Training) Loss: 978782.2830\n",
      "(Validation) Loss: 1005948.5613, MAE: 3850.6714, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [2644/5000] | Time: 0.26s\n",
      "(Training) Loss: 965106.9051\n",
      "(Validation) Loss: 1005788.2362, MAE: 3849.8279, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [2645/5000] | Time: 0.26s\n",
      "(Training) Loss: 987756.5742\n",
      "(Validation) Loss: 1005635.5810, MAE: 3851.1907, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [2646/5000] | Time: 0.28s\n",
      "(Training) Loss: 989538.1586\n",
      "(Validation) Loss: 1005471.4870, MAE: 3847.8433, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [2647/5000] | Time: 0.26s\n",
      "(Training) Loss: 982702.3484\n",
      "(Validation) Loss: 1005313.7422, MAE: 3846.6448, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [2648/5000] | Time: 0.24s\n",
      "(Training) Loss: 978319.3204\n",
      "(Validation) Loss: 1005151.8578, MAE: 3845.7432, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [2649/5000] | Time: 0.25s\n",
      "(Training) Loss: 983901.6992\n",
      "(Validation) Loss: 1005003.0781, MAE: 3847.5276, R2: 0.1517\n",
      "==========================================================================================\n",
      "Epoch [2650/5000] | Time: 0.25s\n",
      "(Training) Loss: 1001835.9791\n",
      "(Validation) Loss: 1004848.5181, MAE: 3846.9734, R2: 0.1518\n",
      "==========================================================================================\n",
      "Epoch [2651/5000] | Time: 0.34s\n",
      "(Training) Loss: 971527.9600\n",
      "(Validation) Loss: 1004687.8375, MAE: 3847.3464, R2: 0.1519\n",
      "==========================================================================================\n",
      "Epoch [2652/5000] | Time: 0.20s\n",
      "(Training) Loss: 967813.0717\n",
      "(Validation) Loss: 1004529.0971, MAE: 3845.5908, R2: 0.1521\n",
      "==========================================================================================\n",
      "Epoch [2653/5000] | Time: 0.24s\n",
      "(Training) Loss: 982165.3185\n",
      "(Validation) Loss: 1004377.3156, MAE: 3845.6394, R2: 0.1522\n",
      "==========================================================================================\n",
      "Epoch [2654/5000] | Time: 0.21s\n",
      "(Training) Loss: 986541.4118\n",
      "(Validation) Loss: 1004212.5410, MAE: 3843.1882, R2: 0.1523\n",
      "==========================================================================================\n",
      "Epoch [2655/5000] | Time: 0.24s\n",
      "(Training) Loss: 962459.4374\n",
      "(Validation) Loss: 1004053.2876, MAE: 3842.7148, R2: 0.1525\n",
      "==========================================================================================\n",
      "Epoch [2656/5000] | Time: 0.25s\n",
      "(Training) Loss: 983767.9657\n",
      "(Validation) Loss: 1003906.7683, MAE: 3844.2515, R2: 0.1526\n",
      "==========================================================================================\n",
      "Epoch [2657/5000] | Time: 0.35s\n",
      "(Training) Loss: 964365.0311\n",
      "(Validation) Loss: 1003812.8203, MAE: 3842.8044, R2: 0.1527\n",
      "==========================================================================================\n",
      "Epoch [2658/5000] | Time: 0.23s\n",
      "(Training) Loss: 983554.4162\n",
      "(Validation) Loss: 1003588.3175, MAE: 3841.2568, R2: 0.1528\n",
      "==========================================================================================\n",
      "Epoch [2659/5000] | Time: 0.21s\n",
      "(Training) Loss: 979422.7335\n",
      "(Validation) Loss: 1003437.0895, MAE: 3842.1680, R2: 0.1530\n",
      "==========================================================================================\n",
      "Epoch [2660/5000] | Time: 0.21s\n",
      "(Training) Loss: 969943.0279\n",
      "(Validation) Loss: 1003277.4044, MAE: 3840.9902, R2: 0.1531\n",
      "==========================================================================================\n",
      "Epoch [2661/5000] | Time: 0.21s\n",
      "(Training) Loss: 974022.4099\n",
      "(Validation) Loss: 1003119.6749, MAE: 3839.9373, R2: 0.1532\n",
      "==========================================================================================\n",
      "Epoch [2662/5000] | Time: 0.21s\n",
      "(Training) Loss: 979411.7544\n",
      "(Validation) Loss: 1002968.4368, MAE: 3840.2939, R2: 0.1534\n",
      "==========================================================================================\n",
      "Epoch [2663/5000] | Time: 0.21s\n",
      "(Training) Loss: 974615.9061\n",
      "(Validation) Loss: 1002810.0775, MAE: 3838.3528, R2: 0.1535\n",
      "==========================================================================================\n",
      "Epoch [2664/5000] | Time: 0.21s\n",
      "(Training) Loss: 970237.2475\n",
      "(Validation) Loss: 1002652.6425, MAE: 3838.4512, R2: 0.1536\n",
      "==========================================================================================\n",
      "Epoch [2665/5000] | Time: 0.25s\n",
      "(Training) Loss: 977291.0419\n",
      "(Validation) Loss: 1002507.0375, MAE: 3840.9395, R2: 0.1537\n",
      "==========================================================================================\n",
      "Epoch [2666/5000] | Time: 0.22s\n",
      "(Training) Loss: 960021.3735\n",
      "(Validation) Loss: 1002343.9695, MAE: 3836.8333, R2: 0.1539\n",
      "==========================================================================================\n",
      "Epoch [2667/5000] | Time: 0.28s\n",
      "(Training) Loss: 965140.3737\n",
      "(Validation) Loss: 1002197.9073, MAE: 3837.5896, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [2668/5000] | Time: 0.34s\n",
      "(Training) Loss: 985459.1732\n",
      "(Validation) Loss: 1002045.4603, MAE: 3837.2407, R2: 0.1541\n",
      "==========================================================================================\n",
      "Epoch [2669/5000] | Time: 0.24s\n",
      "(Training) Loss: 985615.3915\n",
      "(Validation) Loss: 1001877.9835, MAE: 3834.9629, R2: 0.1543\n",
      "==========================================================================================\n",
      "Epoch [2670/5000] | Time: 0.35s\n",
      "(Training) Loss: 968879.4150\n",
      "(Validation) Loss: 1001730.2806, MAE: 3837.7361, R2: 0.1544\n",
      "==========================================================================================\n",
      "Epoch [2671/5000] | Time: 0.34s\n",
      "(Training) Loss: 960132.9099\n",
      "(Validation) Loss: 1001573.4349, MAE: 3836.2058, R2: 0.1545\n",
      "==========================================================================================\n",
      "Epoch [2672/5000] | Time: 0.33s\n",
      "(Training) Loss: 974093.1583\n",
      "(Validation) Loss: 1001500.5917, MAE: 3840.5083, R2: 0.1546\n",
      "==========================================================================================\n",
      "Epoch [2673/5000] | Time: 0.27s\n",
      "(Training) Loss: 960498.4572\n",
      "(Validation) Loss: 1001343.7308, MAE: 3839.0593, R2: 0.1547\n",
      "==========================================================================================\n",
      "Epoch [2674/5000] | Time: 0.31s\n",
      "(Training) Loss: 985374.0952\n",
      "(Validation) Loss: 1013814.6641, MAE: 3878.6206, R2: 0.1443\n",
      "==========================================================================================\n",
      "Epoch [2675/5000] | Time: 0.36s\n",
      "(Training) Loss: 1002389.4632\n",
      "(Validation) Loss: 1030223.3956, MAE: 3935.1980, R2: 0.1306\n",
      "==========================================================================================\n",
      "Epoch [2676/5000] | Time: 0.32s\n",
      "(Training) Loss: 1002787.6612\n",
      "(Validation) Loss: 1030047.2279, MAE: 3932.8406, R2: 0.1308\n",
      "==========================================================================================\n",
      "Epoch [2677/5000] | Time: 0.24s\n",
      "(Training) Loss: 1010562.2544\n",
      "(Validation) Loss: 1046799.0908, MAE: 3988.7512, R2: 0.1168\n",
      "==========================================================================================\n",
      "Epoch [2678/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002809.6786\n",
      "(Validation) Loss: 1050544.6248, MAE: 4005.4336, R2: 0.1137\n",
      "==========================================================================================\n",
      "Epoch [2679/5000] | Time: 0.25s\n",
      "(Training) Loss: 1009846.1529\n",
      "(Validation) Loss: 1050344.8889, MAE: 4000.8713, R2: 0.1139\n",
      "==========================================================================================\n",
      "Epoch [2680/5000] | Time: 0.33s\n",
      "(Training) Loss: 1025311.6301\n",
      "(Validation) Loss: 1050161.6152, MAE: 4000.6460, R2: 0.1140\n",
      "==========================================================================================\n",
      "Epoch [2681/5000] | Time: 0.29s\n",
      "(Training) Loss: 1022534.5381\n",
      "(Validation) Loss: 1049978.1283, MAE: 3999.8701, R2: 0.1142\n",
      "==========================================================================================\n",
      "Epoch [2682/5000] | Time: 0.23s\n",
      "(Training) Loss: 1016354.7088\n",
      "(Validation) Loss: 1049798.1105, MAE: 3999.1980, R2: 0.1143\n",
      "==========================================================================================\n",
      "Epoch [2683/5000] | Time: 0.24s\n",
      "(Training) Loss: 1020200.8185\n",
      "(Validation) Loss: 1049624.1625, MAE: 4000.5732, R2: 0.1145\n",
      "==========================================================================================\n",
      "Epoch [2684/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012259.2665\n",
      "(Validation) Loss: 1049446.8775, MAE: 3999.6953, R2: 0.1146\n",
      "==========================================================================================\n",
      "Epoch [2685/5000] | Time: 0.27s\n",
      "(Training) Loss: 1023847.9930\n",
      "(Validation) Loss: 1049282.4737, MAE: 4002.8914, R2: 0.1148\n",
      "==========================================================================================\n",
      "Epoch [2686/5000] | Time: 0.22s\n",
      "(Training) Loss: 1016644.8255\n",
      "(Validation) Loss: 1040639.7968, MAE: 3972.4729, R2: 0.1220\n",
      "==========================================================================================\n",
      "Epoch [2687/5000] | Time: 0.27s\n",
      "(Training) Loss: 1016558.7627\n",
      "(Validation) Loss: 1040461.1708, MAE: 3971.4580, R2: 0.1221\n",
      "==========================================================================================\n",
      "Epoch [2688/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002651.6961\n",
      "(Validation) Loss: 1040279.8832, MAE: 3969.3540, R2: 0.1223\n",
      "==========================================================================================\n",
      "Epoch [2689/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000080.3166\n",
      "(Validation) Loss: 1040109.4705, MAE: 3969.7495, R2: 0.1224\n",
      "==========================================================================================\n",
      "Epoch [2690/5000] | Time: 0.31s\n",
      "(Training) Loss: 1012875.4385\n",
      "(Validation) Loss: 1039933.6229, MAE: 3967.4058, R2: 0.1226\n",
      "==========================================================================================\n",
      "Epoch [2691/5000] | Time: 0.24s\n",
      "(Training) Loss: 998713.4873\n",
      "(Validation) Loss: 1039758.2578, MAE: 3967.8474, R2: 0.1227\n",
      "==========================================================================================\n",
      "Epoch [2692/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019450.5444\n",
      "(Validation) Loss: 1039592.7060, MAE: 3968.7063, R2: 0.1228\n",
      "==========================================================================================\n",
      "Epoch [2693/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010317.3319\n",
      "(Validation) Loss: 1039423.5937, MAE: 3968.8730, R2: 0.1230\n",
      "==========================================================================================\n",
      "Epoch [2694/5000] | Time: 0.23s\n",
      "(Training) Loss: 999687.9023\n",
      "(Validation) Loss: 1039241.3105, MAE: 3965.8384, R2: 0.1231\n",
      "==========================================================================================\n",
      "Epoch [2695/5000] | Time: 0.28s\n",
      "(Training) Loss: 1031938.2398\n",
      "(Validation) Loss: 1039072.4724, MAE: 3967.8162, R2: 0.1233\n",
      "==========================================================================================\n",
      "Epoch [2696/5000] | Time: 0.26s\n",
      "(Training) Loss: 1013484.2386\n",
      "(Validation) Loss: 1038894.2679, MAE: 3965.5823, R2: 0.1234\n",
      "==========================================================================================\n",
      "Epoch [2697/5000] | Time: 0.27s\n",
      "(Training) Loss: 1001701.6701\n",
      "(Validation) Loss: 1038717.4451, MAE: 3963.9214, R2: 0.1236\n",
      "==========================================================================================\n",
      "Epoch [2698/5000] | Time: 0.29s\n",
      "(Training) Loss: 1023107.2544\n",
      "(Validation) Loss: 1038546.8292, MAE: 3962.9807, R2: 0.1237\n",
      "==========================================================================================\n",
      "Epoch [2699/5000] | Time: 0.33s\n",
      "(Training) Loss: 996865.5647\n",
      "(Validation) Loss: 1038375.5581, MAE: 3963.1646, R2: 0.1239\n",
      "==========================================================================================\n",
      "Epoch [2700/5000] | Time: 0.30s\n",
      "(Training) Loss: 1031142.6574\n",
      "(Validation) Loss: 1038208.0660, MAE: 3962.7629, R2: 0.1240\n",
      "==========================================================================================\n",
      "Epoch [2701/5000] | Time: 0.27s\n",
      "(Training) Loss: 1014628.9321\n",
      "(Validation) Loss: 1038043.1340, MAE: 3966.0422, R2: 0.1241\n",
      "==========================================================================================\n",
      "Epoch [2702/5000] | Time: 0.22s\n",
      "(Training) Loss: 998419.6472\n",
      "(Validation) Loss: 1037861.3029, MAE: 3960.7307, R2: 0.1243\n",
      "==========================================================================================\n",
      "Epoch [2703/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001569.8338\n",
      "(Validation) Loss: 1037701.4756, MAE: 3964.1553, R2: 0.1244\n",
      "==========================================================================================\n",
      "Epoch [2704/5000] | Time: 0.30s\n",
      "(Training) Loss: 996961.3445\n",
      "(Validation) Loss: 1037524.2667, MAE: 3960.2925, R2: 0.1246\n",
      "==========================================================================================\n",
      "Epoch [2705/5000] | Time: 0.25s\n",
      "(Training) Loss: 994590.7072\n",
      "(Validation) Loss: 1037358.9537, MAE: 3960.5071, R2: 0.1247\n",
      "==========================================================================================\n",
      "Epoch [2706/5000] | Time: 0.23s\n",
      "(Training) Loss: 1017048.4753\n",
      "(Validation) Loss: 1037195.1187, MAE: 3960.9163, R2: 0.1248\n",
      "==========================================================================================\n",
      "Epoch [2707/5000] | Time: 0.25s\n",
      "(Training) Loss: 1002372.5812\n",
      "(Validation) Loss: 1037013.4248, MAE: 3957.7390, R2: 0.1250\n",
      "==========================================================================================\n",
      "Epoch [2708/5000] | Time: 0.25s\n",
      "(Training) Loss: 1020909.6973\n",
      "(Validation) Loss: 1036852.3886, MAE: 3959.4907, R2: 0.1251\n",
      "==========================================================================================\n",
      "Epoch [2709/5000] | Time: 0.25s\n",
      "(Training) Loss: 1017863.7462\n",
      "(Validation) Loss: 1036675.3625, MAE: 3956.3330, R2: 0.1253\n",
      "==========================================================================================\n",
      "Epoch [2710/5000] | Time: 0.23s\n",
      "(Training) Loss: 997568.4331\n",
      "(Validation) Loss: 1036540.8762, MAE: 3967.4675, R2: 0.1254\n",
      "==========================================================================================\n",
      "Epoch [2711/5000] | Time: 0.24s\n",
      "(Training) Loss: 1026378.7976\n",
      "(Validation) Loss: 1036339.8959, MAE: 3956.3823, R2: 0.1255\n",
      "==========================================================================================\n",
      "Epoch [2712/5000] | Time: 0.26s\n",
      "(Training) Loss: 1024618.3832\n",
      "(Validation) Loss: 1036166.5727, MAE: 3954.7820, R2: 0.1257\n",
      "==========================================================================================\n",
      "Epoch [2713/5000] | Time: 0.26s\n",
      "(Training) Loss: 1010497.8395\n",
      "(Validation) Loss: 1036011.3524, MAE: 3960.0310, R2: 0.1258\n",
      "==========================================================================================\n",
      "Epoch [2714/5000] | Time: 0.27s\n",
      "(Training) Loss: 1009794.6643\n",
      "(Validation) Loss: 1035833.5390, MAE: 3956.7271, R2: 0.1260\n",
      "==========================================================================================\n",
      "Epoch [2715/5000] | Time: 0.56s\n",
      "(Training) Loss: 1010890.3591\n",
      "(Validation) Loss: 1035662.1765, MAE: 3954.7498, R2: 0.1261\n",
      "==========================================================================================\n",
      "Epoch [2716/5000] | Time: 0.28s\n",
      "(Training) Loss: 1005752.6691\n",
      "(Validation) Loss: 1035492.9981, MAE: 3953.6460, R2: 0.1263\n",
      "==========================================================================================\n",
      "Epoch [2717/5000] | Time: 0.32s\n",
      "(Training) Loss: 1000952.0964\n",
      "(Validation) Loss: 1035324.3886, MAE: 3952.7644, R2: 0.1264\n",
      "==========================================================================================\n",
      "Epoch [2718/5000] | Time: 0.31s\n",
      "(Training) Loss: 1004268.6326\n",
      "(Validation) Loss: 1035156.1600, MAE: 3951.3096, R2: 0.1265\n",
      "==========================================================================================\n",
      "Epoch [2719/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009746.5552\n",
      "(Validation) Loss: 1034986.2502, MAE: 3950.6521, R2: 0.1267\n",
      "==========================================================================================\n",
      "Epoch [2720/5000] | Time: 0.21s\n",
      "(Training) Loss: 1005764.7868\n",
      "(Validation) Loss: 1034823.3194, MAE: 3951.3416, R2: 0.1268\n",
      "==========================================================================================\n",
      "Epoch [2721/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012083.4416\n",
      "(Validation) Loss: 1034655.2787, MAE: 3950.5867, R2: 0.1270\n",
      "==========================================================================================\n",
      "Epoch [2722/5000] | Time: 0.21s\n",
      "(Training) Loss: 999832.4645\n",
      "(Validation) Loss: 1034484.0330, MAE: 3949.2930, R2: 0.1271\n",
      "==========================================================================================\n",
      "Epoch [2723/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010888.2963\n",
      "(Validation) Loss: 1034328.6451, MAE: 3957.2866, R2: 0.1272\n",
      "==========================================================================================\n",
      "Epoch [2724/5000] | Time: 0.36s\n",
      "(Training) Loss: 1020764.2202\n",
      "(Validation) Loss: 1034153.1835, MAE: 3952.1699, R2: 0.1274\n",
      "==========================================================================================\n",
      "Epoch [2725/5000] | Time: 0.24s\n",
      "(Training) Loss: 1007397.4454\n",
      "(Validation) Loss: 1033988.9371, MAE: 3954.9500, R2: 0.1275\n",
      "==========================================================================================\n",
      "Epoch [2726/5000] | Time: 0.23s\n",
      "(Training) Loss: 995813.2602\n",
      "(Validation) Loss: 1033810.7733, MAE: 3948.8904, R2: 0.1277\n",
      "==========================================================================================\n",
      "Epoch [2727/5000] | Time: 0.23s\n",
      "(Training) Loss: 996548.3813\n",
      "(Validation) Loss: 1033640.3098, MAE: 3946.7581, R2: 0.1278\n",
      "==========================================================================================\n",
      "Epoch [2728/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003307.7037\n",
      "(Validation) Loss: 1033475.2000, MAE: 3946.2556, R2: 0.1279\n",
      "==========================================================================================\n",
      "Epoch [2729/5000] | Time: 0.22s\n",
      "(Training) Loss: 1016255.9543\n",
      "(Validation) Loss: 1033314.8597, MAE: 3946.9214, R2: 0.1281\n",
      "==========================================================================================\n",
      "Epoch [2730/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012966.0305\n",
      "(Validation) Loss: 1033150.4102, MAE: 3947.6958, R2: 0.1282\n",
      "==========================================================================================\n",
      "Epoch [2731/5000] | Time: 0.26s\n",
      "(Training) Loss: 991820.2490\n",
      "(Validation) Loss: 1032985.5746, MAE: 3949.1228, R2: 0.1283\n",
      "==========================================================================================\n",
      "Epoch [2732/5000] | Time: 0.30s\n",
      "(Training) Loss: 1002332.8204\n",
      "(Validation) Loss: 1032818.7987, MAE: 3947.2085, R2: 0.1285\n",
      "==========================================================================================\n",
      "Epoch [2733/5000] | Time: 0.27s\n",
      "(Training) Loss: 1007149.4454\n",
      "(Validation) Loss: 1032643.5759, MAE: 3943.5334, R2: 0.1286\n",
      "==========================================================================================\n",
      "Epoch [2734/5000] | Time: 0.29s\n",
      "(Training) Loss: 995659.1878\n",
      "(Validation) Loss: 1032480.8279, MAE: 3945.2488, R2: 0.1288\n",
      "==========================================================================================\n",
      "Epoch [2735/5000] | Time: 0.24s\n",
      "(Training) Loss: 988498.9657\n",
      "(Validation) Loss: 1032310.9994, MAE: 3942.4849, R2: 0.1289\n",
      "==========================================================================================\n",
      "Epoch [2736/5000] | Time: 0.21s\n",
      "(Training) Loss: 1023720.7633\n",
      "(Validation) Loss: 1032155.6470, MAE: 3944.4790, R2: 0.1290\n",
      "==========================================================================================\n",
      "Epoch [2737/5000] | Time: 0.23s\n",
      "(Training) Loss: 991253.2008\n",
      "(Validation) Loss: 1031974.2933, MAE: 3940.6863, R2: 0.1292\n",
      "==========================================================================================\n",
      "Epoch [2738/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004403.1536\n",
      "(Validation) Loss: 1031814.7657, MAE: 3941.2612, R2: 0.1293\n",
      "==========================================================================================\n",
      "Epoch [2739/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008646.1523\n",
      "(Validation) Loss: 1031647.3194, MAE: 3940.2483, R2: 0.1295\n",
      "==========================================================================================\n",
      "Epoch [2740/5000] | Time: 0.24s\n",
      "(Training) Loss: 1001543.8027\n",
      "(Validation) Loss: 1031476.6984, MAE: 3939.1533, R2: 0.1296\n",
      "==========================================================================================\n",
      "Epoch [2741/5000] | Time: 0.24s\n",
      "(Training) Loss: 999758.8820\n",
      "(Validation) Loss: 1031313.2698, MAE: 3938.0425, R2: 0.1297\n",
      "==========================================================================================\n",
      "Epoch [2742/5000] | Time: 0.24s\n",
      "(Training) Loss: 990106.5473\n",
      "(Validation) Loss: 1031146.5905, MAE: 3937.6533, R2: 0.1299\n",
      "==========================================================================================\n",
      "Epoch [2743/5000] | Time: 0.26s\n",
      "(Training) Loss: 993359.6060\n",
      "(Validation) Loss: 1030978.8851, MAE: 3936.4849, R2: 0.1300\n",
      "==========================================================================================\n",
      "Epoch [2744/5000] | Time: 0.24s\n",
      "(Training) Loss: 1016050.7805\n",
      "(Validation) Loss: 1030818.5143, MAE: 3937.4766, R2: 0.1301\n",
      "==========================================================================================\n",
      "Epoch [2745/5000] | Time: 0.29s\n",
      "(Training) Loss: 997951.9848\n",
      "(Validation) Loss: 1030654.9892, MAE: 3939.2039, R2: 0.1303\n",
      "==========================================================================================\n",
      "Epoch [2746/5000] | Time: 0.35s\n",
      "(Training) Loss: 996604.8598\n",
      "(Validation) Loss: 1030488.8025, MAE: 3938.3096, R2: 0.1304\n",
      "==========================================================================================\n",
      "Epoch [2747/5000] | Time: 0.31s\n",
      "(Training) Loss: 996253.1954\n",
      "(Validation) Loss: 1030318.2578, MAE: 3935.3125, R2: 0.1306\n",
      "==========================================================================================\n",
      "Epoch [2748/5000] | Time: 0.28s\n",
      "(Training) Loss: 992433.1539\n",
      "(Validation) Loss: 1030180.7390, MAE: 3944.1248, R2: 0.1307\n",
      "==========================================================================================\n",
      "Epoch [2749/5000] | Time: 0.30s\n",
      "(Training) Loss: 1010126.4074\n",
      "(Validation) Loss: 1033204.3175, MAE: 3948.5474, R2: 0.1282\n",
      "==========================================================================================\n",
      "Epoch [2750/5000] | Time: 0.31s\n",
      "(Training) Loss: 994422.6383\n",
      "(Validation) Loss: 1029821.5213, MAE: 3933.7810, R2: 0.1310\n",
      "==========================================================================================\n",
      "Epoch [2751/5000] | Time: 0.25s\n",
      "(Training) Loss: 990384.5584\n",
      "(Validation) Loss: 1029657.3257, MAE: 3934.4546, R2: 0.1311\n",
      "==========================================================================================\n",
      "Epoch [2752/5000] | Time: 0.26s\n",
      "(Training) Loss: 993558.6942\n",
      "(Validation) Loss: 1029488.8330, MAE: 3932.2307, R2: 0.1313\n",
      "==========================================================================================\n",
      "Epoch [2753/5000] | Time: 0.27s\n",
      "(Training) Loss: 989311.0933\n",
      "(Validation) Loss: 1029332.9524, MAE: 3933.4895, R2: 0.1314\n",
      "==========================================================================================\n",
      "Epoch [2754/5000] | Time: 0.29s\n",
      "(Training) Loss: 985463.2657\n",
      "(Validation) Loss: 1029157.2419, MAE: 3929.9268, R2: 0.1315\n",
      "==========================================================================================\n",
      "Epoch [2755/5000] | Time: 0.27s\n",
      "(Training) Loss: 1005561.4055\n",
      "(Validation) Loss: 1029134.3137, MAE: 3942.7412, R2: 0.1315\n",
      "==========================================================================================\n",
      "Epoch [2756/5000] | Time: 0.28s\n",
      "(Training) Loss: 1004028.2157\n",
      "(Validation) Loss: 1028968.1473, MAE: 3942.7861, R2: 0.1317\n",
      "==========================================================================================\n",
      "Epoch [2757/5000] | Time: 0.28s\n",
      "(Training) Loss: 987323.3807\n",
      "(Validation) Loss: 1028797.8971, MAE: 3941.8562, R2: 0.1318\n",
      "==========================================================================================\n",
      "Epoch [2758/5000] | Time: 0.34s\n",
      "(Training) Loss: 1003201.3598\n",
      "(Validation) Loss: 1028623.3854, MAE: 3937.8572, R2: 0.1320\n",
      "==========================================================================================\n",
      "Epoch [2759/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016899.5971\n",
      "(Validation) Loss: 1028450.5651, MAE: 3935.0393, R2: 0.1321\n",
      "==========================================================================================\n",
      "Epoch [2760/5000] | Time: 0.27s\n",
      "(Training) Loss: 991875.7316\n",
      "(Validation) Loss: 1028291.0984, MAE: 3938.1670, R2: 0.1323\n",
      "==========================================================================================\n",
      "Epoch [2761/5000] | Time: 0.31s\n",
      "(Training) Loss: 996095.5476\n",
      "(Validation) Loss: 1028127.8425, MAE: 3937.0330, R2: 0.1324\n",
      "==========================================================================================\n",
      "Epoch [2762/5000] | Time: 0.32s\n",
      "(Training) Loss: 997691.0590\n",
      "(Validation) Loss: 1027961.8133, MAE: 3937.4788, R2: 0.1325\n",
      "==========================================================================================\n",
      "Epoch [2763/5000] | Time: 0.26s\n",
      "(Training) Loss: 989060.4023\n",
      "(Validation) Loss: 1027786.6463, MAE: 3932.3455, R2: 0.1327\n",
      "==========================================================================================\n",
      "Epoch [2764/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005652.5552\n",
      "(Validation) Loss: 1027620.0381, MAE: 3932.2134, R2: 0.1328\n",
      "==========================================================================================\n",
      "Epoch [2765/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000560.1701\n",
      "(Validation) Loss: 1027462.3137, MAE: 3933.7593, R2: 0.1329\n",
      "==========================================================================================\n",
      "Epoch [2766/5000] | Time: 0.23s\n",
      "(Training) Loss: 997480.3249\n",
      "(Validation) Loss: 1027294.9384, MAE: 3933.5247, R2: 0.1331\n",
      "==========================================================================================\n",
      "Epoch [2767/5000] | Time: 0.28s\n",
      "(Training) Loss: 990151.6034\n",
      "(Validation) Loss: 1027122.3111, MAE: 3930.3433, R2: 0.1332\n",
      "==========================================================================================\n",
      "Epoch [2768/5000] | Time: 0.31s\n",
      "(Training) Loss: 1005556.4645\n",
      "(Validation) Loss: 1026957.1302, MAE: 3929.2524, R2: 0.1334\n",
      "==========================================================================================\n",
      "Epoch [2769/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001463.3084\n",
      "(Validation) Loss: 1026793.7117, MAE: 3930.9502, R2: 0.1335\n",
      "==========================================================================================\n",
      "Epoch [2770/5000] | Time: 0.28s\n",
      "(Training) Loss: 990668.5596\n",
      "(Validation) Loss: 1026620.8356, MAE: 3928.4385, R2: 0.1336\n",
      "==========================================================================================\n",
      "Epoch [2771/5000] | Time: 0.29s\n",
      "(Training) Loss: 989710.8636\n",
      "(Validation) Loss: 1026464.2083, MAE: 3930.0032, R2: 0.1338\n",
      "==========================================================================================\n",
      "Epoch [2772/5000] | Time: 0.28s\n",
      "(Training) Loss: 996482.4734\n",
      "(Validation) Loss: 1026304.3098, MAE: 3930.5815, R2: 0.1339\n",
      "==========================================================================================\n",
      "Epoch [2773/5000] | Time: 0.30s\n",
      "(Training) Loss: 1013221.0051\n",
      "(Validation) Loss: 1026129.5187, MAE: 3927.2388, R2: 0.1341\n",
      "==========================================================================================\n",
      "Epoch [2774/5000] | Time: 0.35s\n",
      "(Training) Loss: 987961.0622\n",
      "(Validation) Loss: 1025965.4349, MAE: 3928.2803, R2: 0.1342\n",
      "==========================================================================================\n",
      "Epoch [2775/5000] | Time: 0.25s\n",
      "(Training) Loss: 992165.3319\n",
      "(Validation) Loss: 1025693.3333, MAE: 3923.9331, R2: 0.1344\n",
      "==========================================================================================\n",
      "Epoch [2776/5000] | Time: 0.27s\n",
      "(Training) Loss: 986120.1364\n",
      "(Validation) Loss: 1025524.2819, MAE: 3920.0579, R2: 0.1346\n",
      "==========================================================================================\n",
      "Epoch [2777/5000] | Time: 0.26s\n",
      "(Training) Loss: 983074.8504\n",
      "(Validation) Loss: 1025366.5879, MAE: 3923.6013, R2: 0.1347\n",
      "==========================================================================================\n",
      "Epoch [2778/5000] | Time: 0.28s\n",
      "(Training) Loss: 998122.5977\n",
      "(Validation) Loss: 1025247.4870, MAE: 3922.3108, R2: 0.1348\n",
      "==========================================================================================\n",
      "Epoch [2779/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002933.4010\n",
      "(Validation) Loss: 1025138.3721, MAE: 3924.2197, R2: 0.1349\n",
      "==========================================================================================\n",
      "Epoch [2780/5000] | Time: 0.22s\n",
      "(Training) Loss: 991934.5622\n",
      "(Validation) Loss: 1024972.3479, MAE: 3923.9512, R2: 0.1350\n",
      "==========================================================================================\n",
      "Epoch [2781/5000] | Time: 0.22s\n",
      "(Training) Loss: 1006207.2392\n",
      "(Validation) Loss: 1024809.4070, MAE: 3923.5864, R2: 0.1352\n",
      "==========================================================================================\n",
      "Epoch [2782/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016511.9683\n",
      "(Validation) Loss: 1024639.9137, MAE: 3922.0647, R2: 0.1353\n",
      "==========================================================================================\n",
      "Epoch [2783/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001992.9448\n",
      "(Validation) Loss: 1024472.9194, MAE: 3920.8569, R2: 0.1354\n",
      "==========================================================================================\n",
      "Epoch [2784/5000] | Time: 0.29s\n",
      "(Training) Loss: 1009387.5863\n",
      "(Validation) Loss: 1024307.4286, MAE: 3921.5527, R2: 0.1356\n",
      "==========================================================================================\n",
      "Epoch [2785/5000] | Time: 0.29s\n",
      "(Training) Loss: 986816.0479\n",
      "(Validation) Loss: 1024141.7854, MAE: 3921.1755, R2: 0.1357\n",
      "==========================================================================================\n",
      "Epoch [2786/5000] | Time: 0.28s\n",
      "(Training) Loss: 999769.4048\n",
      "(Validation) Loss: 1023976.6502, MAE: 3919.5764, R2: 0.1358\n",
      "==========================================================================================\n",
      "Epoch [2787/5000] | Time: 0.35s\n",
      "(Training) Loss: 994026.4391\n",
      "(Validation) Loss: 1023813.4502, MAE: 3919.9409, R2: 0.1360\n",
      "==========================================================================================\n",
      "Epoch [2788/5000] | Time: 0.32s\n",
      "(Training) Loss: 996420.1180\n",
      "(Validation) Loss: 1023647.3346, MAE: 3919.5593, R2: 0.1361\n",
      "==========================================================================================\n",
      "Epoch [2789/5000] | Time: 0.35s\n",
      "(Training) Loss: 990014.4277\n",
      "(Validation) Loss: 1023477.0083, MAE: 3917.4089, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [2790/5000] | Time: 0.30s\n",
      "(Training) Loss: 985318.0305\n",
      "(Validation) Loss: 1023312.3860, MAE: 3916.5149, R2: 0.1364\n",
      "==========================================================================================\n",
      "Epoch [2791/5000] | Time: 0.31s\n",
      "(Training) Loss: 996424.2056\n",
      "(Validation) Loss: 1023149.6533, MAE: 3916.7324, R2: 0.1365\n",
      "==========================================================================================\n",
      "Epoch [2792/5000] | Time: 0.35s\n",
      "(Training) Loss: 1010230.7652\n",
      "(Validation) Loss: 1022988.3683, MAE: 3916.1133, R2: 0.1367\n",
      "==========================================================================================\n",
      "Epoch [2793/5000] | Time: 0.26s\n",
      "(Training) Loss: 1002328.4968\n",
      "(Validation) Loss: 1022827.4946, MAE: 3916.8132, R2: 0.1368\n",
      "==========================================================================================\n",
      "Epoch [2794/5000] | Time: 0.26s\n",
      "(Training) Loss: 993248.2030\n",
      "(Validation) Loss: 1022659.2000, MAE: 3916.5857, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [2795/5000] | Time: 0.28s\n",
      "(Training) Loss: 991646.7602\n",
      "(Validation) Loss: 1022488.2337, MAE: 3915.7920, R2: 0.1371\n",
      "==========================================================================================\n",
      "Epoch [2796/5000] | Time: 0.25s\n",
      "(Training) Loss: 987974.4308\n",
      "(Validation) Loss: 1022326.8470, MAE: 3914.5908, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [2797/5000] | Time: 0.29s\n",
      "(Training) Loss: 994877.7113\n",
      "(Validation) Loss: 1022161.4375, MAE: 3914.0508, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [2798/5000] | Time: 0.25s\n",
      "(Training) Loss: 1003974.9524\n",
      "(Validation) Loss: 1021994.3975, MAE: 3911.7632, R2: 0.1375\n",
      "==========================================================================================\n",
      "Epoch [2799/5000] | Time: 0.31s\n",
      "(Training) Loss: 981450.4312\n",
      "(Validation) Loss: 1021833.4578, MAE: 3913.0359, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [2800/5000] | Time: 0.31s\n",
      "(Training) Loss: 982242.3940\n",
      "(Validation) Loss: 1021669.2927, MAE: 3912.3184, R2: 0.1378\n",
      "==========================================================================================\n",
      "Epoch [2801/5000] | Time: 0.29s\n",
      "(Training) Loss: 993478.4346\n",
      "(Validation) Loss: 1021533.8768, MAE: 3917.7048, R2: 0.1379\n",
      "==========================================================================================\n",
      "Epoch [2802/5000] | Time: 0.25s\n",
      "(Training) Loss: 991957.8953\n",
      "(Validation) Loss: 1021346.1740, MAE: 3913.3936, R2: 0.1380\n",
      "==========================================================================================\n",
      "Epoch [2803/5000] | Time: 0.39s\n",
      "(Training) Loss: 989109.4074\n",
      "(Validation) Loss: 1021200.2133, MAE: 3916.5454, R2: 0.1382\n",
      "==========================================================================================\n",
      "Epoch [2804/5000] | Time: 0.51s\n",
      "(Training) Loss: 984583.4010\n",
      "(Validation) Loss: 1021014.5473, MAE: 3910.5430, R2: 0.1383\n",
      "==========================================================================================\n",
      "Epoch [2805/5000] | Time: 0.30s\n",
      "(Training) Loss: 1013114.1129\n",
      "(Validation) Loss: 1020843.8197, MAE: 3909.9775, R2: 0.1385\n",
      "==========================================================================================\n",
      "Epoch [2806/5000] | Time: 0.26s\n",
      "(Training) Loss: 991008.3166\n",
      "(Validation) Loss: 1020684.6629, MAE: 3909.5791, R2: 0.1386\n",
      "==========================================================================================\n",
      "Epoch [2807/5000] | Time: 0.23s\n",
      "(Training) Loss: 987201.3864\n",
      "(Validation) Loss: 1020521.0921, MAE: 3908.5422, R2: 0.1387\n",
      "==========================================================================================\n",
      "Epoch [2808/5000] | Time: 0.24s\n",
      "(Training) Loss: 997296.1193\n",
      "(Validation) Loss: 1020357.3283, MAE: 3909.4023, R2: 0.1389\n",
      "==========================================================================================\n",
      "Epoch [2809/5000] | Time: 0.25s\n",
      "(Training) Loss: 998522.9816\n",
      "(Validation) Loss: 1020190.8978, MAE: 3907.8201, R2: 0.1390\n",
      "==========================================================================================\n",
      "Epoch [2810/5000] | Time: 0.35s\n",
      "(Training) Loss: 1021735.5070\n",
      "(Validation) Loss: 1020022.1410, MAE: 3905.7646, R2: 0.1391\n",
      "==========================================================================================\n",
      "Epoch [2811/5000] | Time: 0.25s\n",
      "(Training) Loss: 1009574.8185\n",
      "(Validation) Loss: 1019853.9886, MAE: 3904.0266, R2: 0.1393\n",
      "==========================================================================================\n",
      "Epoch [2812/5000] | Time: 0.28s\n",
      "(Training) Loss: 989593.0162\n",
      "(Validation) Loss: 1019695.8324, MAE: 3905.5437, R2: 0.1394\n",
      "==========================================================================================\n",
      "Epoch [2813/5000] | Time: 0.28s\n",
      "(Training) Loss: 1000157.5698\n",
      "(Validation) Loss: 1019524.6070, MAE: 3903.8918, R2: 0.1396\n",
      "==========================================================================================\n",
      "Epoch [2814/5000] | Time: 0.29s\n",
      "(Training) Loss: 987214.0571\n",
      "(Validation) Loss: 1019359.4819, MAE: 3902.5461, R2: 0.1397\n",
      "==========================================================================================\n",
      "Epoch [2815/5000] | Time: 0.28s\n",
      "(Training) Loss: 980595.7519\n",
      "(Validation) Loss: 1019198.6286, MAE: 3903.6267, R2: 0.1398\n",
      "==========================================================================================\n",
      "Epoch [2816/5000] | Time: 0.37s\n",
      "(Training) Loss: 985042.4327\n",
      "(Validation) Loss: 1019042.9054, MAE: 3906.2593, R2: 0.1400\n",
      "==========================================================================================\n",
      "Epoch [2817/5000] | Time: 0.36s\n",
      "(Training) Loss: 979530.6136\n",
      "(Validation) Loss: 1018872.3454, MAE: 3902.1838, R2: 0.1401\n",
      "==========================================================================================\n",
      "Epoch [2818/5000] | Time: 0.32s\n",
      "(Training) Loss: 980279.5926\n",
      "(Validation) Loss: 1018716.3479, MAE: 3904.5056, R2: 0.1402\n",
      "==========================================================================================\n",
      "Epoch [2819/5000] | Time: 0.61s\n",
      "(Training) Loss: 979782.7538\n",
      "(Validation) Loss: 1018552.9549, MAE: 3902.8765, R2: 0.1404\n",
      "==========================================================================================\n",
      "Epoch [2820/5000] | Time: 0.96s\n",
      "(Training) Loss: 986419.9930\n",
      "(Validation) Loss: 1018287.2483, MAE: 3896.9431, R2: 0.1406\n",
      "==========================================================================================\n",
      "Epoch [2821/5000] | Time: 0.97s\n",
      "(Training) Loss: 988614.2614\n",
      "(Validation) Loss: 1018124.6629, MAE: 3897.5076, R2: 0.1407\n",
      "==========================================================================================\n",
      "Epoch [2822/5000] | Time: 0.89s\n",
      "(Training) Loss: 1007685.1904\n",
      "(Validation) Loss: 1017952.8635, MAE: 3892.4143, R2: 0.1409\n",
      "==========================================================================================\n",
      "Epoch [2823/5000] | Time: 0.78s\n",
      "(Training) Loss: 988455.8547\n",
      "(Validation) Loss: 1017712.2590, MAE: 3887.2432, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [2824/5000] | Time: 0.96s\n",
      "(Training) Loss: 975489.3839\n",
      "(Validation) Loss: 1017731.4032, MAE: 3898.2061, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [2825/5000] | Time: 0.98s\n",
      "(Training) Loss: 976846.0292\n",
      "(Validation) Loss: 1017567.1060, MAE: 3897.2483, R2: 0.1412\n",
      "==========================================================================================\n",
      "Epoch [2826/5000] | Time: 1.03s\n",
      "(Training) Loss: 985417.5114\n",
      "(Validation) Loss: 1017407.7714, MAE: 3897.2915, R2: 0.1413\n",
      "==========================================================================================\n",
      "Epoch [2827/5000] | Time: 0.88s\n",
      "(Training) Loss: 987018.3788\n",
      "(Validation) Loss: 1017244.5105, MAE: 3897.3691, R2: 0.1415\n",
      "==========================================================================================\n",
      "Epoch [2828/5000] | Time: 0.84s\n",
      "(Training) Loss: 991570.1662\n",
      "(Validation) Loss: 1017079.6749, MAE: 3895.6826, R2: 0.1416\n",
      "==========================================================================================\n",
      "Epoch [2829/5000] | Time: 0.83s\n",
      "(Training) Loss: 974743.8204\n",
      "(Validation) Loss: 1016915.7181, MAE: 3895.1628, R2: 0.1417\n",
      "==========================================================================================\n",
      "Epoch [2830/5000] | Time: 0.47s\n",
      "(Training) Loss: 997813.6935\n",
      "(Validation) Loss: 1016753.3206, MAE: 3894.5918, R2: 0.1419\n",
      "==========================================================================================\n",
      "Epoch [2831/5000] | Time: 0.33s\n",
      "(Training) Loss: 981658.4797\n",
      "(Validation) Loss: 1016583.3448, MAE: 3892.8655, R2: 0.1420\n",
      "==========================================================================================\n",
      "Epoch [2832/5000] | Time: 0.31s\n",
      "(Training) Loss: 976313.2589\n",
      "(Validation) Loss: 1016425.7524, MAE: 3893.5627, R2: 0.1421\n",
      "==========================================================================================\n",
      "Epoch [2833/5000] | Time: 0.28s\n",
      "(Training) Loss: 981506.9702\n",
      "(Validation) Loss: 1016265.9302, MAE: 3893.6504, R2: 0.1423\n",
      "==========================================================================================\n",
      "Epoch [2834/5000] | Time: 0.88s\n",
      "(Training) Loss: 977980.6263\n",
      "(Validation) Loss: 1016103.9390, MAE: 3893.7957, R2: 0.1424\n",
      "==========================================================================================\n",
      "Epoch [2835/5000] | Time: 0.77s\n",
      "(Training) Loss: 985042.0457\n",
      "(Validation) Loss: 1015935.9797, MAE: 3891.4155, R2: 0.1425\n",
      "==========================================================================================\n",
      "Epoch [2836/5000] | Time: 0.90s\n",
      "(Training) Loss: 987216.9016\n",
      "(Validation) Loss: 1015776.1219, MAE: 3891.8845, R2: 0.1427\n",
      "==========================================================================================\n",
      "Epoch [2837/5000] | Time: 0.82s\n",
      "(Training) Loss: 983675.7703\n",
      "(Validation) Loss: 1015618.1689, MAE: 3892.4734, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [2838/5000] | Time: 0.38s\n",
      "(Training) Loss: 980778.8198\n",
      "(Validation) Loss: 1015447.2686, MAE: 3891.1299, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [2839/5000] | Time: 0.33s\n",
      "(Training) Loss: 978178.4410\n",
      "(Validation) Loss: 1015293.3130, MAE: 3892.6597, R2: 0.1431\n",
      "==========================================================================================\n",
      "Epoch [2840/5000] | Time: 0.34s\n",
      "(Training) Loss: 986152.9296\n",
      "(Validation) Loss: 1015120.3657, MAE: 3888.8965, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [2841/5000] | Time: 0.27s\n",
      "(Training) Loss: 979660.8858\n",
      "(Validation) Loss: 1014958.2273, MAE: 3889.6226, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [2842/5000] | Time: 0.27s\n",
      "(Training) Loss: 1010719.9270\n",
      "(Validation) Loss: 1014793.9048, MAE: 3888.1128, R2: 0.1435\n",
      "==========================================================================================\n",
      "Epoch [2843/5000] | Time: 0.25s\n",
      "(Training) Loss: 991600.1536\n",
      "(Validation) Loss: 1014627.5251, MAE: 3887.8594, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [2844/5000] | Time: 0.25s\n",
      "(Training) Loss: 981617.8553\n",
      "(Validation) Loss: 1014463.4006, MAE: 3887.7759, R2: 0.1438\n",
      "==========================================================================================\n",
      "Epoch [2845/5000] | Time: 0.29s\n",
      "(Training) Loss: 994112.0165\n",
      "(Validation) Loss: 1014297.2902, MAE: 3885.5874, R2: 0.1439\n",
      "==========================================================================================\n",
      "Epoch [2846/5000] | Time: 0.25s\n",
      "(Training) Loss: 996069.8709\n",
      "(Validation) Loss: 1014140.5308, MAE: 3886.4155, R2: 0.1440\n",
      "==========================================================================================\n",
      "Epoch [2847/5000] | Time: 0.30s\n",
      "(Training) Loss: 992155.7640\n",
      "(Validation) Loss: 1013971.0832, MAE: 3884.8955, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [2848/5000] | Time: 0.31s\n",
      "(Training) Loss: 988332.6405\n",
      "(Validation) Loss: 1013809.1429, MAE: 3884.9358, R2: 0.1443\n",
      "==========================================================================================\n",
      "Epoch [2849/5000] | Time: 0.26s\n",
      "(Training) Loss: 989744.1954\n",
      "(Validation) Loss: 1013644.3429, MAE: 3884.0000, R2: 0.1445\n",
      "==========================================================================================\n",
      "Epoch [2850/5000] | Time: 0.26s\n",
      "(Training) Loss: 988065.4569\n",
      "(Validation) Loss: 1008665.4730, MAE: 3866.8635, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [2851/5000] | Time: 0.29s\n",
      "(Training) Loss: 980637.5470\n",
      "(Validation) Loss: 1008489.1987, MAE: 3865.2498, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [2852/5000] | Time: 0.33s\n",
      "(Training) Loss: 965784.6557\n",
      "(Validation) Loss: 1008309.4959, MAE: 3861.7612, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [2853/5000] | Time: 0.29s\n",
      "(Training) Loss: 969026.9987\n",
      "(Validation) Loss: 1008158.6540, MAE: 3867.2163, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [2854/5000] | Time: 0.30s\n",
      "(Training) Loss: 979332.2621\n",
      "(Validation) Loss: 1007982.6844, MAE: 3863.5769, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [2855/5000] | Time: 0.30s\n",
      "(Training) Loss: 965166.1193\n",
      "(Validation) Loss: 1007815.7816, MAE: 3863.6082, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [2856/5000] | Time: 0.26s\n",
      "(Training) Loss: 991242.4708\n",
      "(Validation) Loss: 1007642.8394, MAE: 3859.9238, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [2857/5000] | Time: 0.27s\n",
      "(Training) Loss: 971902.7272\n",
      "(Validation) Loss: 1007475.1543, MAE: 3860.4695, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [2858/5000] | Time: 0.31s\n",
      "(Training) Loss: 974587.5577\n",
      "(Validation) Loss: 1007312.3149, MAE: 3860.2463, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [2859/5000] | Time: 0.25s\n",
      "(Training) Loss: 966971.9829\n",
      "(Validation) Loss: 1007152.1524, MAE: 3861.9426, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [2860/5000] | Time: 0.38s\n",
      "(Training) Loss: 978553.4664\n",
      "(Validation) Loss: 1006979.7892, MAE: 3858.4023, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [2861/5000] | Time: 0.39s\n",
      "(Training) Loss: 971724.6263\n",
      "(Validation) Loss: 1006808.2337, MAE: 3856.8308, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [2862/5000] | Time: 0.26s\n",
      "(Training) Loss: 986828.5761\n",
      "(Validation) Loss: 1006652.6375, MAE: 3860.0317, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [2863/5000] | Time: 0.26s\n",
      "(Training) Loss: 978493.9175\n",
      "(Validation) Loss: 1006476.3632, MAE: 3855.4380, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [2864/5000] | Time: 0.28s\n",
      "(Training) Loss: 985434.4334\n",
      "(Validation) Loss: 1006311.8629, MAE: 3856.2908, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [2865/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001434.0819\n",
      "(Validation) Loss: 1006146.6006, MAE: 3855.2444, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [2866/5000] | Time: 0.26s\n",
      "(Training) Loss: 973363.9848\n",
      "(Validation) Loss: 1005978.1435, MAE: 3854.8276, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [2867/5000] | Time: 0.24s\n",
      "(Training) Loss: 965835.5514\n",
      "(Validation) Loss: 998188.8813, MAE: 3831.7063, R2: 0.1573\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2868/5000] | Time: 0.27s\n",
      "(Training) Loss: 964501.7589\n",
      "(Validation) Loss: 998026.8902, MAE: 3828.3550, R2: 0.1575\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2869/5000] | Time: 0.45s\n",
      "(Training) Loss: 956905.4521\n",
      "(Validation) Loss: 997872.9854, MAE: 3828.2854, R2: 0.1576\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2870/5000] | Time: 0.34s\n",
      "(Training) Loss: 964326.5787\n",
      "(Validation) Loss: 997710.9689, MAE: 3827.5081, R2: 0.1577\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2871/5000] | Time: 0.25s\n",
      "(Training) Loss: 966875.8509\n",
      "(Validation) Loss: 997551.0502, MAE: 3826.0029, R2: 0.1579\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2872/5000] | Time: 0.31s\n",
      "(Training) Loss: 956152.3026\n",
      "(Validation) Loss: 997401.5086, MAE: 3827.1038, R2: 0.1580\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2873/5000] | Time: 0.27s\n",
      "(Training) Loss: 982835.0324\n",
      "(Validation) Loss: 997240.1473, MAE: 3825.3088, R2: 0.1581\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2874/5000] | Time: 0.34s\n",
      "(Training) Loss: 976965.7081\n",
      "(Validation) Loss: 997075.4489, MAE: 3823.9802, R2: 0.1583\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2875/5000] | Time: 0.26s\n",
      "(Training) Loss: 980464.5926\n",
      "(Validation) Loss: 996916.7340, MAE: 3823.4194, R2: 0.1584\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2876/5000] | Time: 0.29s\n",
      "(Training) Loss: 959231.6808\n",
      "(Validation) Loss: 996770.5905, MAE: 3825.7502, R2: 0.1585\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2877/5000] | Time: 0.28s\n",
      "(Training) Loss: 981548.8940\n",
      "(Validation) Loss: 996596.8813, MAE: 3820.6406, R2: 0.1587\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2878/5000] | Time: 0.26s\n",
      "(Training) Loss: 972455.9524\n",
      "(Validation) Loss: 996433.6152, MAE: 3819.7227, R2: 0.1588\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2879/5000] | Time: 0.29s\n",
      "(Training) Loss: 968421.8680\n",
      "(Validation) Loss: 996279.4717, MAE: 3821.0103, R2: 0.1589\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2880/5000] | Time: 0.33s\n",
      "(Training) Loss: 955729.6701\n",
      "(Validation) Loss: 996117.9784, MAE: 3819.4331, R2: 0.1591\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2881/5000] | Time: 0.25s\n",
      "(Training) Loss: 960133.0057\n",
      "(Validation) Loss: 995960.8686, MAE: 3818.9172, R2: 0.1592\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2882/5000] | Time: 0.26s\n",
      "(Training) Loss: 961027.6466\n",
      "(Validation) Loss: 995800.1219, MAE: 3817.2869, R2: 0.1593\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2883/5000] | Time: 0.26s\n",
      "(Training) Loss: 964159.0457\n",
      "(Validation) Loss: 995642.5194, MAE: 3818.1558, R2: 0.1595\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2884/5000] | Time: 0.31s\n",
      "(Training) Loss: 960775.2049\n",
      "(Validation) Loss: 995413.6381, MAE: 3814.5955, R2: 0.1597\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2885/5000] | Time: 0.29s\n",
      "(Training) Loss: 955891.0225\n",
      "(Validation) Loss: 995258.5346, MAE: 3814.9504, R2: 0.1598\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2886/5000] | Time: 0.42s\n",
      "(Training) Loss: 964096.6028\n",
      "(Validation) Loss: 995091.4794, MAE: 3811.4780, R2: 0.1599\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2887/5000] | Time: 0.28s\n",
      "(Training) Loss: 960660.0717\n",
      "(Validation) Loss: 994934.2324, MAE: 3810.5615, R2: 0.1601\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2888/5000] | Time: 0.26s\n",
      "(Training) Loss: 955877.8087\n",
      "(Validation) Loss: 994769.5797, MAE: 3808.9355, R2: 0.1602\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2889/5000] | Time: 0.26s\n",
      "(Training) Loss: 977742.7989\n",
      "(Validation) Loss: 994610.6768, MAE: 3807.8247, R2: 0.1603\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2890/5000] | Time: 0.26s\n",
      "(Training) Loss: 960371.0742\n",
      "(Validation) Loss: 994456.2133, MAE: 3809.0525, R2: 0.1605\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2891/5000] | Time: 0.26s\n",
      "(Training) Loss: 955607.4743\n",
      "(Validation) Loss: 994297.2952, MAE: 3808.7493, R2: 0.1606\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2892/5000] | Time: 0.28s\n",
      "(Training) Loss: 967706.0089\n",
      "(Validation) Loss: 994137.8692, MAE: 3807.4526, R2: 0.1607\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2893/5000] | Time: 0.30s\n",
      "(Training) Loss: 956681.9892\n",
      "(Validation) Loss: 993976.6349, MAE: 3806.2847, R2: 0.1609\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2894/5000] | Time: 0.26s\n",
      "(Training) Loss: 955113.1313\n",
      "(Validation) Loss: 993818.8749, MAE: 3806.4229, R2: 0.1610\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2895/5000] | Time: 0.33s\n",
      "(Training) Loss: 953582.5485\n",
      "(Validation) Loss: 993677.8971, MAE: 3809.8000, R2: 0.1611\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2896/5000] | Time: 0.28s\n",
      "(Training) Loss: 962856.1916\n",
      "(Validation) Loss: 993524.5156, MAE: 3807.1033, R2: 0.1612\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2897/5000] | Time: 0.28s\n",
      "(Training) Loss: 955999.3801\n",
      "(Validation) Loss: 993349.5314, MAE: 3805.2686, R2: 0.1614\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2898/5000] | Time: 0.29s\n",
      "(Training) Loss: 975462.4283\n",
      "(Validation) Loss: 993186.0317, MAE: 3803.9863, R2: 0.1615\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2899/5000] | Time: 0.26s\n",
      "(Training) Loss: 963284.7443\n",
      "(Validation) Loss: 993031.1975, MAE: 3804.9324, R2: 0.1616\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2900/5000] | Time: 0.30s\n",
      "(Training) Loss: 980643.1567\n",
      "(Validation) Loss: 992864.1117, MAE: 3801.8074, R2: 0.1618\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2901/5000] | Time: 0.29s\n",
      "(Training) Loss: 964487.9137\n",
      "(Validation) Loss: 992709.7143, MAE: 3802.3096, R2: 0.1619\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2902/5000] | Time: 0.30s\n",
      "(Training) Loss: 951270.8125\n",
      "(Validation) Loss: 992540.3835, MAE: 3799.6216, R2: 0.1621\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2903/5000] | Time: 0.32s\n",
      "(Training) Loss: 975349.9949\n",
      "(Validation) Loss: 992387.3727, MAE: 3799.5212, R2: 0.1622\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2904/5000] | Time: 0.27s\n",
      "(Training) Loss: 1000682.9232\n",
      "(Validation) Loss: 992241.8184, MAE: 3802.9409, R2: 0.1623\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2905/5000] | Time: 0.27s\n",
      "(Training) Loss: 975908.2373\n",
      "(Validation) Loss: 992064.2844, MAE: 3798.8191, R2: 0.1625\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2906/5000] | Time: 0.28s\n",
      "(Training) Loss: 968657.8452\n",
      "(Validation) Loss: 991904.5943, MAE: 3798.7661, R2: 0.1626\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2907/5000] | Time: 0.30s\n",
      "(Training) Loss: 962175.4898\n",
      "(Validation) Loss: 991745.4679, MAE: 3797.9993, R2: 0.1627\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2908/5000] | Time: 0.27s\n",
      "(Training) Loss: 971525.4956\n",
      "(Validation) Loss: 991588.6222, MAE: 3798.3022, R2: 0.1628\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2909/5000] | Time: 0.26s\n",
      "(Training) Loss: 953663.4388\n",
      "(Validation) Loss: 991427.6470, MAE: 3797.4897, R2: 0.1630\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2910/5000] | Time: 0.25s\n",
      "(Training) Loss: 973136.8807\n",
      "(Validation) Loss: 991276.9067, MAE: 3798.0452, R2: 0.1631\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2911/5000] | Time: 0.27s\n",
      "(Training) Loss: 950406.5995\n",
      "(Validation) Loss: 991107.3676, MAE: 3794.3845, R2: 0.1632\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2912/5000] | Time: 0.27s\n",
      "(Training) Loss: 960161.4797\n",
      "(Validation) Loss: 990955.8756, MAE: 3795.3677, R2: 0.1634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2913/5000] | Time: 0.24s\n",
      "(Training) Loss: 955400.7912\n",
      "(Validation) Loss: 990816.9803, MAE: 3796.2949, R2: 0.1635\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2914/5000] | Time: 0.23s\n",
      "(Training) Loss: 953219.1485\n",
      "(Validation) Loss: 990695.1314, MAE: 3808.8298, R2: 0.1636\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2915/5000] | Time: 0.28s\n",
      "(Training) Loss: 950194.5363\n",
      "(Validation) Loss: 999327.1517, MAE: 3829.4060, R2: 0.1564\n",
      "==========================================================================================\n",
      "Epoch [2916/5000] | Time: 0.25s\n",
      "(Training) Loss: 984748.8204\n",
      "(Validation) Loss: 999169.0057, MAE: 3827.4268, R2: 0.1565\n",
      "==========================================================================================\n",
      "Epoch [2917/5000] | Time: 0.26s\n",
      "(Training) Loss: 976739.7963\n",
      "(Validation) Loss: 999004.7695, MAE: 3825.4663, R2: 0.1567\n",
      "==========================================================================================\n",
      "Epoch [2918/5000] | Time: 0.27s\n",
      "(Training) Loss: 973926.4810\n",
      "(Validation) Loss: 998844.0584, MAE: 3823.7031, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [2919/5000] | Time: 0.25s\n",
      "(Training) Loss: 997841.2253\n",
      "(Validation) Loss: 998683.8095, MAE: 3822.8750, R2: 0.1569\n",
      "==========================================================================================\n",
      "Epoch [2920/5000] | Time: 0.22s\n",
      "(Training) Loss: 962264.9575\n",
      "(Validation) Loss: 998525.1505, MAE: 3822.7397, R2: 0.1571\n",
      "==========================================================================================\n",
      "Epoch [2921/5000] | Time: 0.26s\n",
      "(Training) Loss: 972459.6180\n",
      "(Validation) Loss: 998367.5022, MAE: 3822.0176, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [2922/5000] | Time: 0.25s\n",
      "(Training) Loss: 979811.4645\n",
      "(Validation) Loss: 1003147.7638, MAE: 3839.2412, R2: 0.1532\n",
      "==========================================================================================\n",
      "Epoch [2923/5000] | Time: 0.24s\n",
      "(Training) Loss: 958155.6424\n",
      "(Validation) Loss: 998048.3454, MAE: 3820.6362, R2: 0.1575\n",
      "==========================================================================================\n",
      "Epoch [2924/5000] | Time: 0.27s\n",
      "(Training) Loss: 970883.0152\n",
      "(Validation) Loss: 997889.8540, MAE: 3819.4956, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [2925/5000] | Time: 0.27s\n",
      "(Training) Loss: 992547.7881\n",
      "(Validation) Loss: 997737.8946, MAE: 3820.4314, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [2926/5000] | Time: 0.26s\n",
      "(Training) Loss: 975589.0102\n",
      "(Validation) Loss: 997576.0762, MAE: 3819.4431, R2: 0.1579\n",
      "==========================================================================================\n",
      "Epoch [2927/5000] | Time: 0.29s\n",
      "(Training) Loss: 984467.5343\n",
      "(Validation) Loss: 997417.1733, MAE: 3818.3406, R2: 0.1580\n",
      "==========================================================================================\n",
      "Epoch [2928/5000] | Time: 0.25s\n",
      "(Training) Loss: 979842.8109\n",
      "(Validation) Loss: 997264.4063, MAE: 3819.6575, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [2929/5000] | Time: 0.24s\n",
      "(Training) Loss: 958045.3671\n",
      "(Validation) Loss: 997132.7543, MAE: 3827.7747, R2: 0.1582\n",
      "==========================================================================================\n",
      "Epoch [2930/5000] | Time: 0.25s\n",
      "(Training) Loss: 967055.3249\n",
      "(Validation) Loss: 996942.4457, MAE: 3816.6685, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [2931/5000] | Time: 0.28s\n",
      "(Training) Loss: 970375.3706\n",
      "(Validation) Loss: 996805.7244, MAE: 3821.4785, R2: 0.1585\n",
      "==========================================================================================\n",
      "Epoch [2932/5000] | Time: 0.26s\n",
      "(Training) Loss: 957038.4492\n",
      "(Validation) Loss: 996625.0565, MAE: 3815.6489, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [2933/5000] | Time: 0.27s\n",
      "(Training) Loss: 956466.4925\n",
      "(Validation) Loss: 996469.1098, MAE: 3814.9023, R2: 0.1588\n",
      "==========================================================================================\n",
      "Epoch [2934/5000] | Time: 0.28s\n",
      "(Training) Loss: 969066.5609\n",
      "(Validation) Loss: 996317.0133, MAE: 3814.9407, R2: 0.1589\n",
      "==========================================================================================\n",
      "Epoch [2935/5000] | Time: 0.25s\n",
      "(Training) Loss: 967384.9759\n",
      "(Validation) Loss: 996162.3111, MAE: 3815.5391, R2: 0.1590\n",
      "==========================================================================================\n",
      "Epoch [2936/5000] | Time: 0.30s\n",
      "(Training) Loss: 981638.1415\n",
      "(Validation) Loss: 995999.9746, MAE: 3813.8818, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [2937/5000] | Time: 0.30s\n",
      "(Training) Loss: 977103.5095\n",
      "(Validation) Loss: 995843.8705, MAE: 3813.3191, R2: 0.1593\n",
      "==========================================================================================\n",
      "Epoch [2938/5000] | Time: 0.27s\n",
      "(Training) Loss: 971620.3261\n",
      "(Validation) Loss: 995681.7727, MAE: 3811.7588, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [2939/5000] | Time: 0.29s\n",
      "(Training) Loss: 978981.5508\n",
      "(Validation) Loss: 995527.9898, MAE: 3812.2026, R2: 0.1596\n",
      "==========================================================================================\n",
      "Epoch [2940/5000] | Time: 0.25s\n",
      "(Training) Loss: 972534.9873\n",
      "(Validation) Loss: 995368.9498, MAE: 3811.8088, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [2941/5000] | Time: 0.29s\n",
      "(Training) Loss: 963998.8306\n",
      "(Validation) Loss: 995211.7130, MAE: 3811.6985, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [2942/5000] | Time: 0.27s\n",
      "(Training) Loss: 954991.0917\n",
      "(Validation) Loss: 995056.2743, MAE: 3811.4524, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [2943/5000] | Time: 0.29s\n",
      "(Training) Loss: 972171.8458\n",
      "(Validation) Loss: 994900.7137, MAE: 3810.4578, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [2944/5000] | Time: 0.25s\n",
      "(Training) Loss: 954832.1279\n",
      "(Validation) Loss: 994758.0851, MAE: 3809.8069, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [2945/5000] | Time: 0.29s\n",
      "(Training) Loss: 956004.5990\n",
      "(Validation) Loss: 994585.2597, MAE: 3808.7026, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [2946/5000] | Time: 0.31s\n",
      "(Training) Loss: 975859.3756\n",
      "(Validation) Loss: 994428.9930, MAE: 3807.5706, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [2947/5000] | Time: 0.29s\n",
      "(Training) Loss: 963729.6034\n",
      "(Validation) Loss: 994278.9943, MAE: 3809.3066, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [2948/5000] | Time: 0.26s\n",
      "(Training) Loss: 969934.3287\n",
      "(Validation) Loss: 994120.4063, MAE: 3807.9844, R2: 0.1607\n",
      "==========================================================================================\n",
      "Epoch [2949/5000] | Time: 0.26s\n",
      "(Training) Loss: 969512.5914\n",
      "(Validation) Loss: 993960.7721, MAE: 3807.3013, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [2950/5000] | Time: 0.26s\n",
      "(Training) Loss: 967021.3553\n",
      "(Validation) Loss: 993802.4737, MAE: 3805.8232, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [2951/5000] | Time: 0.23s\n",
      "(Training) Loss: 972263.3445\n",
      "(Validation) Loss: 993646.6489, MAE: 3805.8499, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [2952/5000] | Time: 0.25s\n",
      "(Training) Loss: 966977.3909\n",
      "(Validation) Loss: 993491.8298, MAE: 3805.3657, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [2953/5000] | Time: 0.25s\n",
      "(Training) Loss: 956019.7925\n",
      "(Validation) Loss: 993329.1225, MAE: 3804.0933, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [2954/5000] | Time: 0.26s\n",
      "(Training) Loss: 978291.2605\n",
      "(Validation) Loss: 993181.6330, MAE: 3805.5225, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [2955/5000] | Time: 0.26s\n",
      "(Training) Loss: 951514.7758\n",
      "(Validation) Loss: 993018.4381, MAE: 3803.7178, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [2956/5000] | Time: 0.24s\n",
      "(Training) Loss: 965538.7373\n",
      "(Validation) Loss: 992865.5137, MAE: 3802.6748, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [2957/5000] | Time: 0.21s\n",
      "(Training) Loss: 972624.5641\n",
      "(Validation) Loss: 992707.6114, MAE: 3801.6694, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [2958/5000] | Time: 0.20s\n",
      "(Training) Loss: 965982.3744\n",
      "(Validation) Loss: 992547.8705, MAE: 3800.6829, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [2959/5000] | Time: 0.26s\n",
      "(Training) Loss: 957348.0635\n",
      "(Validation) Loss: 992396.0178, MAE: 3802.1023, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [2960/5000] | Time: 0.22s\n",
      "(Training) Loss: 971336.3725\n",
      "(Validation) Loss: 992245.7702, MAE: 3801.9702, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [2961/5000] | Time: 0.32s\n",
      "(Training) Loss: 981431.3128\n",
      "(Validation) Loss: 992079.4616, MAE: 3800.4343, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [2962/5000] | Time: 0.34s\n",
      "(Training) Loss: 958938.0533\n",
      "(Validation) Loss: 991923.7283, MAE: 3800.3538, R2: 0.1626\n",
      "==========================================================================================\n",
      "Epoch [2963/5000] | Time: 0.34s\n",
      "(Training) Loss: 971585.9975\n",
      "(Validation) Loss: 991768.1067, MAE: 3799.3901, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [2964/5000] | Time: 0.33s\n",
      "(Training) Loss: 983515.0400\n",
      "(Validation) Loss: 991610.3721, MAE: 3799.0398, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [2965/5000] | Time: 0.28s\n",
      "(Training) Loss: 960005.0362\n",
      "(Validation) Loss: 991466.5143, MAE: 3803.2815, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [2966/5000] | Time: 0.29s\n",
      "(Training) Loss: 960054.1726\n",
      "(Validation) Loss: 991315.1390, MAE: 3798.1248, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [2967/5000] | Time: 0.29s\n",
      "(Training) Loss: 971937.2360\n",
      "(Validation) Loss: 991161.1175, MAE: 3798.5701, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [2968/5000] | Time: 0.30s\n",
      "(Training) Loss: 957319.0159\n",
      "(Validation) Loss: 991000.9956, MAE: 3797.4961, R2: 0.1633\n",
      "==========================================================================================\n",
      "Epoch [2969/5000] | Time: 0.31s\n",
      "(Training) Loss: 952183.9045\n",
      "(Validation) Loss: 990844.9981, MAE: 3796.0413, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [2970/5000] | Time: 0.30s\n",
      "(Training) Loss: 962935.9340\n",
      "(Validation) Loss: 990690.7429, MAE: 3796.4817, R2: 0.1636\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2971/5000] | Time: 0.32s\n",
      "(Training) Loss: 981727.7056\n",
      "(Validation) Loss: 990537.6965, MAE: 3795.3127, R2: 0.1637\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2972/5000] | Time: 0.33s\n",
      "(Training) Loss: 955455.0799\n",
      "(Validation) Loss: 990373.5771, MAE: 3793.9800, R2: 0.1639\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2973/5000] | Time: 0.28s\n",
      "(Training) Loss: 956394.7963\n",
      "(Validation) Loss: 990229.0235, MAE: 3796.7949, R2: 0.1640\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2974/5000] | Time: 0.30s\n",
      "(Training) Loss: 956061.5235\n",
      "(Validation) Loss: 990148.6019, MAE: 3799.8210, R2: 0.1640\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2975/5000] | Time: 0.33s\n",
      "(Training) Loss: 955440.4816\n",
      "(Validation) Loss: 989913.6559, MAE: 3794.5034, R2: 0.1642\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2976/5000] | Time: 0.30s\n",
      "(Training) Loss: 958973.3407\n",
      "(Validation) Loss: 989749.8210, MAE: 3791.9272, R2: 0.1644\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2977/5000] | Time: 0.35s\n",
      "(Training) Loss: 965359.6485\n",
      "(Validation) Loss: 989600.3454, MAE: 3792.5151, R2: 0.1645\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2978/5000] | Time: 0.34s\n",
      "(Training) Loss: 974021.2348\n",
      "(Validation) Loss: 989441.6305, MAE: 3791.3323, R2: 0.1646\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2979/5000] | Time: 0.31s\n",
      "(Training) Loss: 951500.6072\n",
      "(Validation) Loss: 989287.6241, MAE: 3792.5986, R2: 0.1648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2980/5000] | Time: 0.32s\n",
      "(Training) Loss: 956357.9803\n",
      "(Validation) Loss: 989128.9905, MAE: 3789.5032, R2: 0.1649\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2981/5000] | Time: 0.35s\n",
      "(Training) Loss: 993610.9207\n",
      "(Validation) Loss: 988973.1048, MAE: 3789.4299, R2: 0.1650\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2982/5000] | Time: 0.38s\n",
      "(Training) Loss: 965821.6117\n",
      "(Validation) Loss: 988815.0959, MAE: 3788.8069, R2: 0.1652\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2983/5000] | Time: 0.41s\n",
      "(Training) Loss: 959830.9454\n",
      "(Validation) Loss: 988674.1232, MAE: 3791.5718, R2: 0.1653\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2984/5000] | Time: 0.37s\n",
      "(Training) Loss: 988211.0082\n",
      "(Validation) Loss: 988502.8470, MAE: 3788.0410, R2: 0.1654\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2985/5000] | Time: 0.35s\n",
      "(Training) Loss: 968593.7551\n",
      "(Validation) Loss: 988348.2667, MAE: 3787.7778, R2: 0.1655\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2986/5000] | Time: 0.42s\n",
      "(Training) Loss: 950521.2322\n",
      "(Validation) Loss: 988196.4546, MAE: 3789.5845, R2: 0.1657\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2987/5000] | Time: 0.33s\n",
      "(Training) Loss: 959128.1352\n",
      "(Validation) Loss: 988037.3892, MAE: 3787.9404, R2: 0.1658\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2988/5000] | Time: 0.33s\n",
      "(Training) Loss: 949415.3217\n",
      "(Validation) Loss: 987887.5987, MAE: 3786.7290, R2: 0.1659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2989/5000] | Time: 0.34s\n",
      "(Training) Loss: 962422.0070\n",
      "(Validation) Loss: 987725.9784, MAE: 3785.0347, R2: 0.1661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2990/5000] | Time: 0.37s\n",
      "(Training) Loss: 955494.7424\n",
      "(Validation) Loss: 987573.9530, MAE: 3784.6902, R2: 0.1662\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2991/5000] | Time: 0.29s\n",
      "(Training) Loss: 967626.3382\n",
      "(Validation) Loss: 987415.2330, MAE: 3783.6091, R2: 0.1663\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2992/5000] | Time: 0.35s\n",
      "(Training) Loss: 950648.0958\n",
      "(Validation) Loss: 987263.2584, MAE: 3783.8247, R2: 0.1665\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2993/5000] | Time: 0.40s\n",
      "(Training) Loss: 961160.9131\n",
      "(Validation) Loss: 987101.3130, MAE: 3781.3845, R2: 0.1666\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2994/5000] | Time: 0.39s\n",
      "(Training) Loss: 955095.6339\n",
      "(Validation) Loss: 986955.6622, MAE: 3783.1809, R2: 0.1667\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2995/5000] | Time: 0.27s\n",
      "(Training) Loss: 952241.4848\n",
      "(Validation) Loss: 986795.6165, MAE: 3780.8396, R2: 0.1668\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2996/5000] | Time: 0.28s\n",
      "(Training) Loss: 958991.0793\n",
      "(Validation) Loss: 986643.5454, MAE: 3781.1829, R2: 0.1670\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2997/5000] | Time: 0.30s\n",
      "(Training) Loss: 954160.5644\n",
      "(Validation) Loss: 986494.2273, MAE: 3782.6299, R2: 0.1671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2998/5000] | Time: 0.36s\n",
      "(Training) Loss: 971800.6662\n",
      "(Validation) Loss: 986328.3251, MAE: 3779.2852, R2: 0.1672\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2999/5000] | Time: 0.29s\n",
      "(Training) Loss: 971064.1935\n",
      "(Validation) Loss: 986174.7302, MAE: 3780.1431, R2: 0.1674\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3000/5000] | Time: 0.29s\n",
      "(Training) Loss: 954452.3572\n",
      "(Validation) Loss: 986017.4476, MAE: 3778.7502, R2: 0.1675\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch3000.pth\n",
      "==========================================================================================\n",
      "Epoch [3001/5000] | Time: 0.29s\n",
      "(Training) Loss: 962411.4166\n",
      "(Validation) Loss: 985872.7771, MAE: 3781.9368, R2: 0.1676\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3002/5000] | Time: 0.31s\n",
      "(Training) Loss: 957111.0235\n",
      "(Validation) Loss: 985713.1378, MAE: 3779.5645, R2: 0.1677\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3003/5000] | Time: 0.26s\n",
      "(Training) Loss: 976223.3756\n",
      "(Validation) Loss: 985548.3124, MAE: 3776.0000, R2: 0.1679\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3004/5000] | Time: 0.30s\n",
      "(Training) Loss: 963511.5362\n",
      "(Validation) Loss: 985427.0679, MAE: 3785.7075, R2: 0.1680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3005/5000] | Time: 0.28s\n",
      "(Training) Loss: 965133.1967\n",
      "(Validation) Loss: 985240.7670, MAE: 3776.5024, R2: 0.1681\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3006/5000] | Time: 0.28s\n",
      "(Training) Loss: 962135.2849\n",
      "(Validation) Loss: 985081.9098, MAE: 3774.1853, R2: 0.1683\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3007/5000] | Time: 0.33s\n",
      "(Training) Loss: 950293.3712\n",
      "(Validation) Loss: 984926.8825, MAE: 3774.0139, R2: 0.1684\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3008/5000] | Time: 0.37s\n",
      "(Training) Loss: 952050.7119\n",
      "(Validation) Loss: 984786.0368, MAE: 3776.3127, R2: 0.1685\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3009/5000] | Time: 0.22s\n",
      "(Training) Loss: 963651.5552\n",
      "(Validation) Loss: 984633.3054, MAE: 3776.8677, R2: 0.1686\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3010/5000] | Time: 0.21s\n",
      "(Training) Loss: 945348.1071\n",
      "(Validation) Loss: 984470.8216, MAE: 3775.0422, R2: 0.1688\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3011/5000] | Time: 0.25s\n",
      "(Training) Loss: 961787.5895\n",
      "(Validation) Loss: 984313.2902, MAE: 3773.2686, R2: 0.1689\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3012/5000] | Time: 0.21s\n",
      "(Training) Loss: 948203.9727\n",
      "(Validation) Loss: 984155.6470, MAE: 3771.5730, R2: 0.1690\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3013/5000] | Time: 0.19s\n",
      "(Training) Loss: 959147.0584\n",
      "(Validation) Loss: 984006.3949, MAE: 3772.4124, R2: 0.1692\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3014/5000] | Time: 0.23s\n",
      "(Training) Loss: 943477.5220\n",
      "(Validation) Loss: 983846.0800, MAE: 3770.3364, R2: 0.1693\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3015/5000] | Time: 0.23s\n",
      "(Training) Loss: 963918.6421\n",
      "(Validation) Loss: 983701.9124, MAE: 3770.7810, R2: 0.1694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3016/5000] | Time: 0.23s\n",
      "(Training) Loss: 948934.7938\n",
      "(Validation) Loss: 983552.8889, MAE: 3768.7346, R2: 0.1695\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3017/5000] | Time: 0.22s\n",
      "(Training) Loss: 952868.8173\n",
      "(Validation) Loss: 983409.7321, MAE: 3771.2727, R2: 0.1697\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3018/5000] | Time: 0.25s\n",
      "(Training) Loss: 959982.0955\n",
      "(Validation) Loss: 983248.6959, MAE: 3768.3826, R2: 0.1698\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3019/5000] | Time: 0.28s\n",
      "(Training) Loss: 952004.0863\n",
      "(Validation) Loss: 983104.0863, MAE: 3771.8369, R2: 0.1699\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3020/5000] | Time: 0.34s\n",
      "(Training) Loss: 962262.1478\n",
      "(Validation) Loss: 982938.2705, MAE: 3768.5474, R2: 0.1701\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3021/5000] | Time: 0.35s\n",
      "(Training) Loss: 958103.8744\n",
      "(Validation) Loss: 982786.6159, MAE: 3768.6313, R2: 0.1702\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3022/5000] | Time: 0.32s\n",
      "(Training) Loss: 972141.4803\n",
      "(Validation) Loss: 982638.2629, MAE: 3769.5786, R2: 0.1703\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3023/5000] | Time: 0.35s\n",
      "(Training) Loss: 945620.0857\n",
      "(Validation) Loss: 982474.2298, MAE: 3767.6599, R2: 0.1704\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3024/5000] | Time: 0.32s\n",
      "(Training) Loss: 958828.5666\n",
      "(Validation) Loss: 982321.3359, MAE: 3766.9775, R2: 0.1706\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3025/5000] | Time: 0.30s\n",
      "(Training) Loss: 956773.0178\n",
      "(Validation) Loss: 982171.0121, MAE: 3767.5720, R2: 0.1707\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3026/5000] | Time: 0.28s\n",
      "(Training) Loss: 945686.9854\n",
      "(Validation) Loss: 982015.9848, MAE: 3768.0232, R2: 0.1708\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3027/5000] | Time: 0.28s\n",
      "(Training) Loss: 962083.3046\n",
      "(Validation) Loss: 981868.2159, MAE: 3767.9504, R2: 0.1709\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3028/5000] | Time: 0.27s\n",
      "(Training) Loss: 962870.1174\n",
      "(Validation) Loss: 981703.8476, MAE: 3764.6292, R2: 0.1711\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3029/5000] | Time: 0.27s\n",
      "(Training) Loss: 943242.0923\n",
      "(Validation) Loss: 981562.4432, MAE: 3766.0039, R2: 0.1712\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3030/5000] | Time: 0.29s\n",
      "(Training) Loss: 960568.2792\n",
      "(Validation) Loss: 981392.7213, MAE: 3763.7175, R2: 0.1713\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3031/5000] | Time: 0.32s\n",
      "(Training) Loss: 946342.4137\n",
      "(Validation) Loss: 981246.5575, MAE: 3764.1343, R2: 0.1715\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3032/5000] | Time: 0.27s\n",
      "(Training) Loss: 941334.4091\n",
      "(Validation) Loss: 981084.8051, MAE: 3762.0056, R2: 0.1716\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3033/5000] | Time: 0.33s\n",
      "(Training) Loss: 966173.5393\n",
      "(Validation) Loss: 980933.3232, MAE: 3761.1799, R2: 0.1717\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3034/5000] | Time: 0.35s\n",
      "(Training) Loss: 942846.4128\n",
      "(Validation) Loss: 980779.5606, MAE: 3762.0496, R2: 0.1719\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3035/5000] | Time: 0.35s\n",
      "(Training) Loss: 958011.2659\n",
      "(Validation) Loss: 980627.1848, MAE: 3760.4124, R2: 0.1720\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3036/5000] | Time: 0.38s\n",
      "(Training) Loss: 952601.9784\n",
      "(Validation) Loss: 980456.0711, MAE: 3762.0381, R2: 0.1721\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3037/5000] | Time: 0.34s\n",
      "(Training) Loss: 976594.0717\n",
      "(Validation) Loss: 983462.3594, MAE: 3775.6550, R2: 0.1696\n",
      "==========================================================================================\n",
      "Epoch [3038/5000] | Time: 0.33s\n",
      "(Training) Loss: 957673.9848\n",
      "(Validation) Loss: 983287.9797, MAE: 3774.8665, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3039/5000] | Time: 0.33s\n",
      "(Training) Loss: 950794.8173\n",
      "(Validation) Loss: 983126.5067, MAE: 3774.1733, R2: 0.1699\n",
      "==========================================================================================\n",
      "Epoch [3040/5000] | Time: 0.35s\n",
      "(Training) Loss: 949249.3115\n",
      "(Validation) Loss: 982961.2292, MAE: 3773.1101, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3041/5000] | Time: 0.47s\n",
      "(Training) Loss: 949959.5514\n",
      "(Validation) Loss: 982804.8152, MAE: 3773.4272, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [3042/5000] | Time: 0.32s\n",
      "(Training) Loss: 957903.7018\n",
      "(Validation) Loss: 982646.1511, MAE: 3773.0669, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [3043/5000] | Time: 0.25s\n",
      "(Training) Loss: 970536.9549\n",
      "(Validation) Loss: 991661.2216, MAE: 3807.5359, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [3044/5000] | Time: 0.27s\n",
      "(Training) Loss: 973827.2728\n",
      "(Validation) Loss: 991504.3962, MAE: 3806.2180, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [3045/5000] | Time: 0.41s\n",
      "(Training) Loss: 961474.6206\n",
      "(Validation) Loss: 991335.5124, MAE: 3803.8115, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [3046/5000] | Time: 0.29s\n",
      "(Training) Loss: 957523.3826\n",
      "(Validation) Loss: 991175.3702, MAE: 3803.6780, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [3047/5000] | Time: 0.28s\n",
      "(Training) Loss: 959259.9778\n",
      "(Validation) Loss: 988524.0635, MAE: 3793.1907, R2: 0.1654\n",
      "==========================================================================================\n",
      "Epoch [3048/5000] | Time: 0.25s\n",
      "(Training) Loss: 952462.6288\n",
      "(Validation) Loss: 988288.5283, MAE: 3792.2275, R2: 0.1656\n",
      "==========================================================================================\n",
      "Epoch [3049/5000] | Time: 0.27s\n",
      "(Training) Loss: 959540.6206\n",
      "(Validation) Loss: 988113.2089, MAE: 3788.4587, R2: 0.1657\n",
      "==========================================================================================\n",
      "Epoch [3050/5000] | Time: 0.29s\n",
      "(Training) Loss: 947527.8315\n",
      "(Validation) Loss: 987953.7524, MAE: 3788.9207, R2: 0.1659\n",
      "==========================================================================================\n",
      "Epoch [3051/5000] | Time: 0.40s\n",
      "(Training) Loss: 948255.1263\n",
      "(Validation) Loss: 987785.7067, MAE: 3787.8086, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3052/5000] | Time: 0.32s\n",
      "(Training) Loss: 946874.0254\n",
      "(Validation) Loss: 987715.8552, MAE: 3795.2988, R2: 0.1661\n",
      "==========================================================================================\n",
      "Epoch [3053/5000] | Time: 0.30s\n",
      "(Training) Loss: 949202.8871\n",
      "(Validation) Loss: 987538.5448, MAE: 3789.3679, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3054/5000] | Time: 0.29s\n",
      "(Training) Loss: 949410.8804\n",
      "(Validation) Loss: 987386.6514, MAE: 3791.5044, R2: 0.1663\n",
      "==========================================================================================\n",
      "Epoch [3055/5000] | Time: 0.25s\n",
      "(Training) Loss: 969941.9911\n",
      "(Validation) Loss: 987217.0819, MAE: 3788.1609, R2: 0.1665\n",
      "==========================================================================================\n",
      "Epoch [3056/5000] | Time: 0.29s\n",
      "(Training) Loss: 946465.7138\n",
      "(Validation) Loss: 987056.8483, MAE: 3788.7114, R2: 0.1666\n",
      "==========================================================================================\n",
      "Epoch [3057/5000] | Time: 0.31s\n",
      "(Training) Loss: 954131.0324\n",
      "(Validation) Loss: 986893.1403, MAE: 3787.2869, R2: 0.1668\n",
      "==========================================================================================\n",
      "Epoch [3058/5000] | Time: 0.27s\n",
      "(Training) Loss: 960489.3579\n",
      "(Validation) Loss: 986733.6432, MAE: 3787.3582, R2: 0.1669\n",
      "==========================================================================================\n",
      "Epoch [3059/5000] | Time: 0.32s\n",
      "(Training) Loss: 952842.9975\n",
      "(Validation) Loss: 986572.4241, MAE: 3786.9597, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3060/5000] | Time: 0.30s\n",
      "(Training) Loss: 957795.7481\n",
      "(Validation) Loss: 986412.7848, MAE: 3787.6558, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3061/5000] | Time: 0.32s\n",
      "(Training) Loss: 970634.3192\n",
      "(Validation) Loss: 986374.1867, MAE: 3793.8035, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3062/5000] | Time: 0.29s\n",
      "(Training) Loss: 948652.6754\n",
      "(Validation) Loss: 986212.3581, MAE: 3794.8877, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3063/5000] | Time: 0.28s\n",
      "(Training) Loss: 960810.5374\n",
      "(Validation) Loss: 986051.4743, MAE: 3794.0247, R2: 0.1675\n",
      "==========================================================================================\n",
      "Epoch [3064/5000] | Time: 0.29s\n",
      "(Training) Loss: 947978.2684\n",
      "(Validation) Loss: 985894.4813, MAE: 3794.3613, R2: 0.1676\n",
      "==========================================================================================\n",
      "Epoch [3065/5000] | Time: 0.28s\n",
      "(Training) Loss: 958545.6574\n",
      "(Validation) Loss: 985731.6470, MAE: 3792.2085, R2: 0.1677\n",
      "==========================================================================================\n",
      "Epoch [3066/5000] | Time: 0.40s\n",
      "(Training) Loss: 956976.6332\n",
      "(Validation) Loss: 985568.5181, MAE: 3790.8792, R2: 0.1679\n",
      "==========================================================================================\n",
      "Epoch [3067/5000] | Time: 0.42s\n",
      "(Training) Loss: 964958.8947\n",
      "(Validation) Loss: 985419.5556, MAE: 3792.3848, R2: 0.1680\n",
      "==========================================================================================\n",
      "Epoch [3068/5000] | Time: 0.45s\n",
      "(Training) Loss: 955201.5730\n",
      "(Validation) Loss: 985248.6298, MAE: 3789.1536, R2: 0.1681\n",
      "==========================================================================================\n",
      "Epoch [3069/5000] | Time: 0.30s\n",
      "(Training) Loss: 958874.1161\n",
      "(Validation) Loss: 985090.7479, MAE: 3788.6423, R2: 0.1683\n",
      "==========================================================================================\n",
      "Epoch [3070/5000] | Time: 0.30s\n",
      "(Training) Loss: 983225.6326\n",
      "(Validation) Loss: 984931.8349, MAE: 3788.1536, R2: 0.1684\n",
      "==========================================================================================\n",
      "Epoch [3071/5000] | Time: 0.27s\n",
      "(Training) Loss: 945170.2414\n",
      "(Validation) Loss: 984779.5556, MAE: 3792.5657, R2: 0.1685\n",
      "==========================================================================================\n",
      "Epoch [3072/5000] | Time: 0.29s\n",
      "(Training) Loss: 965196.3629\n",
      "(Validation) Loss: 984610.3619, MAE: 3787.4119, R2: 0.1687\n",
      "==========================================================================================\n",
      "Epoch [3073/5000] | Time: 0.27s\n",
      "(Training) Loss: 946035.5907\n",
      "(Validation) Loss: 984451.2254, MAE: 3787.0039, R2: 0.1688\n",
      "==========================================================================================\n",
      "Epoch [3074/5000] | Time: 0.26s\n",
      "(Training) Loss: 956864.3769\n",
      "(Validation) Loss: 984292.9117, MAE: 3785.7244, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [3075/5000] | Time: 0.36s\n",
      "(Training) Loss: 966625.5495\n",
      "(Validation) Loss: 984134.1968, MAE: 3785.3550, R2: 0.1691\n",
      "==========================================================================================\n",
      "Epoch [3076/5000] | Time: 0.35s\n",
      "(Training) Loss: 956580.9952\n",
      "(Validation) Loss: 983973.2470, MAE: 3784.9426, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [3077/5000] | Time: 0.29s\n",
      "(Training) Loss: 970817.2690\n",
      "(Validation) Loss: 983816.5029, MAE: 3785.6018, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [3078/5000] | Time: 0.28s\n",
      "(Training) Loss: 965028.7938\n",
      "(Validation) Loss: 983654.9435, MAE: 3785.1892, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [3079/5000] | Time: 0.45s\n",
      "(Training) Loss: 945205.8287\n",
      "(Validation) Loss: 983498.1994, MAE: 3785.4182, R2: 0.1696\n",
      "==========================================================================================\n",
      "Epoch [3080/5000] | Time: 0.37s\n",
      "(Training) Loss: 956498.6072\n",
      "(Validation) Loss: 983338.1435, MAE: 3784.4468, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [3081/5000] | Time: 0.41s\n",
      "(Training) Loss: 945092.5463\n",
      "(Validation) Loss: 983168.0610, MAE: 3784.5264, R2: 0.1699\n",
      "==========================================================================================\n",
      "Epoch [3082/5000] | Time: 0.31s\n",
      "(Training) Loss: 951721.8464\n",
      "(Validation) Loss: 983029.0438, MAE: 3784.9121, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3083/5000] | Time: 0.27s\n",
      "(Training) Loss: 970257.0692\n",
      "(Validation) Loss: 1001438.7962, MAE: 3845.3511, R2: 0.1546\n",
      "==========================================================================================\n",
      "Epoch [3084/5000] | Time: 0.25s\n",
      "(Training) Loss: 961557.2557\n",
      "(Validation) Loss: 1001266.1486, MAE: 3847.1899, R2: 0.1548\n",
      "==========================================================================================\n",
      "Epoch [3085/5000] | Time: 0.28s\n",
      "(Training) Loss: 962886.6101\n",
      "(Validation) Loss: 1001098.2197, MAE: 3844.2737, R2: 0.1549\n",
      "==========================================================================================\n",
      "Epoch [3086/5000] | Time: 0.26s\n",
      "(Training) Loss: 984835.0838\n",
      "(Validation) Loss: 1000923.6571, MAE: 3842.0435, R2: 0.1551\n",
      "==========================================================================================\n",
      "Epoch [3087/5000] | Time: 0.29s\n",
      "(Training) Loss: 961521.0933\n",
      "(Validation) Loss: 1000757.5670, MAE: 3840.4534, R2: 0.1552\n",
      "==========================================================================================\n",
      "Epoch [3088/5000] | Time: 0.39s\n",
      "(Training) Loss: 972751.7170\n",
      "(Validation) Loss: 1000614.9689, MAE: 3846.4072, R2: 0.1553\n",
      "==========================================================================================\n",
      "Epoch [3089/5000] | Time: 0.41s\n",
      "(Training) Loss: 982466.0495\n",
      "(Validation) Loss: 1000437.9225, MAE: 3841.3755, R2: 0.1555\n",
      "==========================================================================================\n",
      "Epoch [3090/5000] | Time: 0.22s\n",
      "(Training) Loss: 970949.0330\n",
      "(Validation) Loss: 1000264.8686, MAE: 3838.5088, R2: 0.1556\n",
      "==========================================================================================\n",
      "Epoch [3091/5000] | Time: 0.24s\n",
      "(Training) Loss: 964019.3039\n",
      "(Validation) Loss: 1000120.2794, MAE: 3843.4250, R2: 0.1557\n",
      "==========================================================================================\n",
      "Epoch [3092/5000] | Time: 0.22s\n",
      "(Training) Loss: 967235.2595\n",
      "(Validation) Loss: 999943.0146, MAE: 3838.3818, R2: 0.1559\n",
      "==========================================================================================\n",
      "Epoch [3093/5000] | Time: 0.20s\n",
      "(Training) Loss: 969554.0895\n",
      "(Validation) Loss: 999786.8800, MAE: 3840.5117, R2: 0.1560\n",
      "==========================================================================================\n",
      "Epoch [3094/5000] | Time: 0.20s\n",
      "(Training) Loss: 970312.0635\n",
      "(Validation) Loss: 999620.4241, MAE: 3843.5125, R2: 0.1561\n",
      "==========================================================================================\n",
      "Epoch [3095/5000] | Time: 0.20s\n",
      "(Training) Loss: 973402.4708\n",
      "(Validation) Loss: 999459.8400, MAE: 3839.9619, R2: 0.1563\n",
      "==========================================================================================\n",
      "Epoch [3096/5000] | Time: 0.37s\n",
      "(Training) Loss: 958475.3379\n",
      "(Validation) Loss: 999288.7314, MAE: 3837.2546, R2: 0.1564\n",
      "==========================================================================================\n",
      "Epoch [3097/5000] | Time: 0.41s\n",
      "(Training) Loss: 970988.7805\n",
      "(Validation) Loss: 999127.5378, MAE: 3836.5083, R2: 0.1566\n",
      "==========================================================================================\n",
      "Epoch [3098/5000] | Time: 0.26s\n",
      "(Training) Loss: 964301.2563\n",
      "(Validation) Loss: 998966.4051, MAE: 3836.1995, R2: 0.1567\n",
      "==========================================================================================\n",
      "Epoch [3099/5000] | Time: 0.29s\n",
      "(Training) Loss: 980099.6015\n",
      "(Validation) Loss: 998808.9854, MAE: 3836.4182, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [3100/5000] | Time: 0.32s\n",
      "(Training) Loss: 961476.0996\n",
      "(Validation) Loss: 995658.5600, MAE: 3826.9829, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [3101/5000] | Time: 0.35s\n",
      "(Training) Loss: 964253.1139\n",
      "(Validation) Loss: 995496.2083, MAE: 3824.1160, R2: 0.1596\n",
      "==========================================================================================\n",
      "Epoch [3102/5000] | Time: 0.47s\n",
      "(Training) Loss: 961250.8572\n",
      "(Validation) Loss: 995341.1200, MAE: 3823.9517, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [3103/5000] | Time: 0.24s\n",
      "(Training) Loss: 980253.0679\n",
      "(Validation) Loss: 995185.3663, MAE: 3822.8691, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [3104/5000] | Time: 0.30s\n",
      "(Training) Loss: 959612.5577\n",
      "(Validation) Loss: 995031.0908, MAE: 3824.8425, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [3105/5000] | Time: 0.39s\n",
      "(Training) Loss: 996747.6294\n",
      "(Validation) Loss: 994867.8146, MAE: 3821.6467, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [3106/5000] | Time: 0.22s\n",
      "(Training) Loss: 964769.2614\n",
      "(Validation) Loss: 994704.3098, MAE: 3820.1013, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [3107/5000] | Time: 0.24s\n",
      "(Training) Loss: 977002.4949\n",
      "(Validation) Loss: 994549.4806, MAE: 3820.6133, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [3108/5000] | Time: 0.22s\n",
      "(Training) Loss: 970358.2608\n",
      "(Validation) Loss: 994388.4597, MAE: 3818.8477, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [3109/5000] | Time: 0.24s\n",
      "(Training) Loss: 957914.2595\n",
      "(Validation) Loss: 994231.6241, MAE: 3818.6584, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [3110/5000] | Time: 0.22s\n",
      "(Training) Loss: 970454.7253\n",
      "(Validation) Loss: 994078.0140, MAE: 3819.7476, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [3111/5000] | Time: 0.21s\n",
      "(Training) Loss: 977441.8680\n",
      "(Validation) Loss: 993924.3378, MAE: 3819.1934, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [3112/5000] | Time: 0.23s\n",
      "(Training) Loss: 961582.1954\n",
      "(Validation) Loss: 993774.7251, MAE: 3817.1328, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [3113/5000] | Time: 0.23s\n",
      "(Training) Loss: 961316.0038\n",
      "(Validation) Loss: 993602.4076, MAE: 3816.6184, R2: 0.1612\n",
      "==========================================================================================\n",
      "Epoch [3114/5000] | Time: 0.26s\n",
      "(Training) Loss: 955642.6846\n",
      "(Validation) Loss: 993447.7206, MAE: 3816.8206, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [3115/5000] | Time: 0.24s\n",
      "(Training) Loss: 967630.5165\n",
      "(Validation) Loss: 993286.8013, MAE: 3813.9182, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [3116/5000] | Time: 0.23s\n",
      "(Training) Loss: 964931.4765\n",
      "(Validation) Loss: 993139.9771, MAE: 3816.6067, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [3117/5000] | Time: 0.34s\n",
      "(Training) Loss: 961550.4714\n",
      "(Validation) Loss: 992974.8419, MAE: 3813.1731, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [3118/5000] | Time: 0.25s\n",
      "(Training) Loss: 952164.3609\n",
      "(Validation) Loss: 992821.4451, MAE: 3814.6108, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [3119/5000] | Time: 0.25s\n",
      "(Training) Loss: 963101.2703\n",
      "(Validation) Loss: 992671.8730, MAE: 3814.3577, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [3120/5000] | Time: 0.21s\n",
      "(Training) Loss: 973370.6631\n",
      "(Validation) Loss: 992504.5689, MAE: 3812.3962, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [3121/5000] | Time: 0.20s\n",
      "(Training) Loss: 981240.4327\n",
      "(Validation) Loss: 992349.9225, MAE: 3811.9023, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [3122/5000] | Time: 0.31s\n",
      "(Training) Loss: 979316.0203\n",
      "(Validation) Loss: 992194.1689, MAE: 3812.2793, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [3123/5000] | Time: 0.26s\n",
      "(Training) Loss: 951331.5077\n",
      "(Validation) Loss: 992036.8254, MAE: 3811.6399, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [3124/5000] | Time: 0.31s\n",
      "(Training) Loss: 965625.2912\n",
      "(Validation) Loss: 991883.7587, MAE: 3810.7844, R2: 0.1626\n",
      "==========================================================================================\n",
      "Epoch [3125/5000] | Time: 0.19s\n",
      "(Training) Loss: 972144.7462\n",
      "(Validation) Loss: 991734.7098, MAE: 3814.2417, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [3126/5000] | Time: 0.19s\n",
      "(Training) Loss: 992273.7043\n",
      "(Validation) Loss: 991562.1333, MAE: 3808.6521, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [3127/5000] | Time: 0.20s\n",
      "(Training) Loss: 970003.4860\n",
      "(Validation) Loss: 989281.3663, MAE: 3801.4182, R2: 0.1648\n",
      "==========================================================================================\n",
      "Epoch [3128/5000] | Time: 0.29s\n",
      "(Training) Loss: 961275.5679\n",
      "(Validation) Loss: 989127.6140, MAE: 3799.3315, R2: 0.1649\n",
      "==========================================================================================\n",
      "Epoch [3129/5000] | Time: 0.29s\n",
      "(Training) Loss: 947841.3773\n",
      "(Validation) Loss: 988975.6546, MAE: 3799.9568, R2: 0.1650\n",
      "==========================================================================================\n",
      "Epoch [3130/5000] | Time: 0.21s\n",
      "(Training) Loss: 962542.1129\n",
      "(Validation) Loss: 988823.8425, MAE: 3799.2708, R2: 0.1651\n",
      "==========================================================================================\n",
      "Epoch [3131/5000] | Time: 0.21s\n",
      "(Training) Loss: 947634.0409\n",
      "(Validation) Loss: 988714.0724, MAE: 3802.0879, R2: 0.1652\n",
      "==========================================================================================\n",
      "Epoch [3132/5000] | Time: 0.19s\n",
      "(Training) Loss: 950721.0374\n",
      "(Validation) Loss: 988548.8508, MAE: 3806.1709, R2: 0.1654\n",
      "==========================================================================================\n",
      "Epoch [3133/5000] | Time: 0.23s\n",
      "(Training) Loss: 954588.1034\n",
      "(Validation) Loss: 988366.4863, MAE: 3796.6511, R2: 0.1655\n",
      "==========================================================================================\n",
      "Epoch [3134/5000] | Time: 0.22s\n",
      "(Training) Loss: 953076.9283\n",
      "(Validation) Loss: 988232.4267, MAE: 3800.9473, R2: 0.1656\n",
      "==========================================================================================\n",
      "Epoch [3135/5000] | Time: 0.21s\n",
      "(Training) Loss: 951873.9594\n",
      "(Validation) Loss: 988065.9454, MAE: 3795.7710, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [3136/5000] | Time: 0.21s\n",
      "(Training) Loss: 956665.5533\n",
      "(Validation) Loss: 987911.8171, MAE: 3794.8315, R2: 0.1659\n",
      "==========================================================================================\n",
      "Epoch [3137/5000] | Time: 0.21s\n",
      "(Training) Loss: 971701.5939\n",
      "(Validation) Loss: 987759.2279, MAE: 3793.6045, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3138/5000] | Time: 0.21s\n",
      "(Training) Loss: 953888.2576\n",
      "(Validation) Loss: 987605.7854, MAE: 3793.0867, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3139/5000] | Time: 0.26s\n",
      "(Training) Loss: 963402.9594\n",
      "(Validation) Loss: 987455.8324, MAE: 3793.3069, R2: 0.1663\n",
      "==========================================================================================\n",
      "Epoch [3140/5000] | Time: 0.23s\n",
      "(Training) Loss: 958347.9346\n",
      "(Validation) Loss: 987318.6590, MAE: 3797.3203, R2: 0.1664\n",
      "==========================================================================================\n",
      "Epoch [3141/5000] | Time: 0.19s\n",
      "(Training) Loss: 967786.5152\n",
      "(Validation) Loss: 987153.9860, MAE: 3794.6799, R2: 0.1665\n",
      "==========================================================================================\n",
      "Epoch [3142/5000] | Time: 0.19s\n",
      "(Training) Loss: 955100.5209\n",
      "(Validation) Loss: 986994.1181, MAE: 3791.5178, R2: 0.1667\n",
      "==========================================================================================\n",
      "Epoch [3143/5000] | Time: 0.20s\n",
      "(Training) Loss: 958857.6561\n",
      "(Validation) Loss: 986843.7587, MAE: 3790.5818, R2: 0.1668\n",
      "==========================================================================================\n",
      "Epoch [3144/5000] | Time: 0.23s\n",
      "(Training) Loss: 948238.2573\n",
      "(Validation) Loss: 986689.5797, MAE: 3789.7312, R2: 0.1669\n",
      "==========================================================================================\n",
      "Epoch [3145/5000] | Time: 0.21s\n",
      "(Training) Loss: 951236.7088\n",
      "(Validation) Loss: 986540.9219, MAE: 3789.5420, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3146/5000] | Time: 0.26s\n",
      "(Training) Loss: 952453.6789\n",
      "(Validation) Loss: 986385.2648, MAE: 3788.3669, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3147/5000] | Time: 0.27s\n",
      "(Training) Loss: 957945.8325\n",
      "(Validation) Loss: 986243.6825, MAE: 3791.9309, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3148/5000] | Time: 0.40s\n",
      "(Training) Loss: 949199.4886\n",
      "(Validation) Loss: 986095.3803, MAE: 3792.3877, R2: 0.1674\n",
      "==========================================================================================\n",
      "Epoch [3149/5000] | Time: 0.22s\n",
      "(Training) Loss: 964587.3503\n",
      "(Validation) Loss: 985943.1924, MAE: 3792.2915, R2: 0.1675\n",
      "==========================================================================================\n",
      "Epoch [3150/5000] | Time: 0.19s\n",
      "(Training) Loss: 962510.6840\n",
      "(Validation) Loss: 985782.9486, MAE: 3791.0620, R2: 0.1677\n",
      "==========================================================================================\n",
      "Epoch [3151/5000] | Time: 0.22s\n",
      "(Training) Loss: 955523.3058\n",
      "(Validation) Loss: 985628.0229, MAE: 3789.7104, R2: 0.1678\n",
      "==========================================================================================\n",
      "Epoch [3152/5000] | Time: 0.22s\n",
      "(Training) Loss: 965784.9911\n",
      "(Validation) Loss: 985474.0114, MAE: 3788.1091, R2: 0.1679\n",
      "==========================================================================================\n",
      "Epoch [3153/5000] | Time: 0.26s\n",
      "(Training) Loss: 961030.3832\n",
      "(Validation) Loss: 985328.5435, MAE: 3788.7883, R2: 0.1681\n",
      "==========================================================================================\n",
      "Epoch [3154/5000] | Time: 0.31s\n",
      "(Training) Loss: 960372.8211\n",
      "(Validation) Loss: 985169.1530, MAE: 3786.8816, R2: 0.1682\n",
      "==========================================================================================\n",
      "Epoch [3155/5000] | Time: 0.25s\n",
      "(Training) Loss: 950456.2506\n",
      "(Validation) Loss: 985014.9638, MAE: 3786.2969, R2: 0.1683\n",
      "==========================================================================================\n",
      "Epoch [3156/5000] | Time: 0.18s\n",
      "(Training) Loss: 963432.2138\n",
      "(Validation) Loss: 984866.8089, MAE: 3785.8201, R2: 0.1684\n",
      "==========================================================================================\n",
      "Epoch [3157/5000] | Time: 0.20s\n",
      "(Training) Loss: 945028.2689\n",
      "(Validation) Loss: 984727.1010, MAE: 3788.2800, R2: 0.1686\n",
      "==========================================================================================\n",
      "Epoch [3158/5000] | Time: 0.19s\n",
      "(Training) Loss: 952950.5232\n",
      "(Validation) Loss: 984562.1587, MAE: 3785.0063, R2: 0.1687\n",
      "==========================================================================================\n",
      "Epoch [3159/5000] | Time: 0.24s\n",
      "(Training) Loss: 969246.2614\n",
      "(Validation) Loss: 984415.6038, MAE: 3784.3608, R2: 0.1688\n",
      "==========================================================================================\n",
      "Epoch [3160/5000] | Time: 0.22s\n",
      "(Training) Loss: 967991.8065\n",
      "(Validation) Loss: 984272.7771, MAE: 3789.0234, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [3161/5000] | Time: 0.22s\n",
      "(Training) Loss: 958446.0343\n",
      "(Validation) Loss: 984102.4102, MAE: 3782.5347, R2: 0.1691\n",
      "==========================================================================================\n",
      "Epoch [3162/5000] | Time: 0.23s\n",
      "(Training) Loss: 962077.7741\n",
      "(Validation) Loss: 983949.3841, MAE: 3780.7080, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [3163/5000] | Time: 0.22s\n",
      "(Training) Loss: 965766.1022\n",
      "(Validation) Loss: 983804.5257, MAE: 3782.7676, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [3164/5000] | Time: 0.19s\n",
      "(Training) Loss: 948779.3572\n",
      "(Validation) Loss: 983639.5987, MAE: 3778.9946, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [3165/5000] | Time: 0.24s\n",
      "(Training) Loss: 954012.2836\n",
      "(Validation) Loss: 983491.0476, MAE: 3778.3062, R2: 0.1696\n",
      "==========================================================================================\n",
      "Epoch [3166/5000] | Time: 0.24s\n",
      "(Training) Loss: 951689.4645\n",
      "(Validation) Loss: 983338.8394, MAE: 3777.6812, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [3167/5000] | Time: 0.20s\n",
      "(Training) Loss: 987247.2741\n",
      "(Validation) Loss: 983191.7714, MAE: 3778.4031, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3168/5000] | Time: 0.22s\n",
      "(Training) Loss: 949078.9962\n",
      "(Validation) Loss: 983034.2756, MAE: 3776.7837, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3169/5000] | Time: 0.23s\n",
      "(Training) Loss: 967293.4727\n",
      "(Validation) Loss: 982884.0635, MAE: 3777.4246, R2: 0.1701\n",
      "==========================================================================================\n",
      "Epoch [3170/5000] | Time: 0.22s\n",
      "(Training) Loss: 971325.1720\n",
      "(Validation) Loss: 982741.1200, MAE: 3780.2598, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [3171/5000] | Time: 0.21s\n",
      "(Training) Loss: 956840.8864\n",
      "(Validation) Loss: 982580.5206, MAE: 3776.6016, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [3172/5000] | Time: 0.20s\n",
      "(Training) Loss: 943285.0763\n",
      "(Validation) Loss: 982345.6610, MAE: 3772.3352, R2: 0.1705\n",
      "==========================================================================================\n",
      "Epoch [3173/5000] | Time: 0.24s\n",
      "(Training) Loss: 956336.8077\n",
      "(Validation) Loss: 982189.2216, MAE: 3769.8142, R2: 0.1707\n",
      "==========================================================================================\n",
      "Epoch [3174/5000] | Time: 0.20s\n",
      "(Training) Loss: 965721.9048\n",
      "(Validation) Loss: 982038.9029, MAE: 3769.3640, R2: 0.1708\n",
      "==========================================================================================\n",
      "Epoch [3175/5000] | Time: 0.21s\n",
      "(Training) Loss: 960900.2348\n",
      "(Validation) Loss: 981880.7060, MAE: 3766.8879, R2: 0.1709\n",
      "==========================================================================================\n",
      "Epoch [3176/5000] | Time: 0.23s\n",
      "(Training) Loss: 954586.9619\n",
      "(Validation) Loss: 981744.7365, MAE: 3772.2610, R2: 0.1711\n",
      "==========================================================================================\n",
      "Epoch [3177/5000] | Time: 0.21s\n",
      "(Training) Loss: 942825.1669\n",
      "(Validation) Loss: 981586.0622, MAE: 3768.8613, R2: 0.1712\n",
      "==========================================================================================\n",
      "Epoch [3178/5000] | Time: 0.25s\n",
      "(Training) Loss: 955737.9080\n",
      "(Validation) Loss: 981428.2159, MAE: 3765.2031, R2: 0.1713\n",
      "==========================================================================================\n",
      "Epoch [3179/5000] | Time: 0.22s\n",
      "(Training) Loss: 944126.9283\n",
      "(Validation) Loss: 981291.6876, MAE: 3769.9480, R2: 0.1714\n",
      "==========================================================================================\n",
      "Epoch [3180/5000] | Time: 0.20s\n",
      "(Training) Loss: 942189.3125\n",
      "(Validation) Loss: 981134.0648, MAE: 3764.9248, R2: 0.1716\n",
      "==========================================================================================\n",
      "Epoch [3181/5000] | Time: 0.22s\n",
      "(Training) Loss: 953887.7621\n",
      "(Validation) Loss: 980984.0000, MAE: 3765.5115, R2: 0.1717\n",
      "==========================================================================================\n",
      "Epoch [3182/5000] | Time: 0.21s\n",
      "(Training) Loss: 965973.8173\n",
      "(Validation) Loss: 980844.5359, MAE: 3772.0374, R2: 0.1718\n",
      "==========================================================================================\n",
      "Epoch [3183/5000] | Time: 0.24s\n",
      "(Training) Loss: 944262.3775\n",
      "(Validation) Loss: 980681.9302, MAE: 3766.2361, R2: 0.1719\n",
      "==========================================================================================\n",
      "Epoch [3184/5000] | Time: 0.23s\n",
      "(Training) Loss: 952806.9327\n",
      "(Validation) Loss: 980527.3448, MAE: 3764.2485, R2: 0.1721\n",
      "==========================================================================================\n",
      "Epoch [3185/5000] | Time: 0.21s\n",
      "(Training) Loss: 942313.4937\n",
      "(Validation) Loss: 980378.8394, MAE: 3763.7847, R2: 0.1722\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3186/5000] | Time: 0.20s\n",
      "(Training) Loss: 952740.1821\n",
      "(Validation) Loss: 980238.9892, MAE: 3765.5146, R2: 0.1723\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3187/5000] | Time: 0.29s\n",
      "(Training) Loss: 956481.7589\n",
      "(Validation) Loss: 980092.7492, MAE: 3766.5654, R2: 0.1724\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3188/5000] | Time: 0.20s\n",
      "(Training) Loss: 957265.1948\n",
      "(Validation) Loss: 979921.3054, MAE: 3761.1204, R2: 0.1726\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3189/5000] | Time: 0.20s\n",
      "(Training) Loss: 964898.8966\n",
      "(Validation) Loss: 979772.7390, MAE: 3759.5928, R2: 0.1727\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3190/5000] | Time: 0.20s\n",
      "(Training) Loss: 943878.3325\n",
      "(Validation) Loss: 979623.7460, MAE: 3760.4792, R2: 0.1728\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3191/5000] | Time: 0.20s\n",
      "(Training) Loss: 945460.0876\n",
      "(Validation) Loss: 979481.3054, MAE: 3760.3000, R2: 0.1729\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3192/5000] | Time: 0.22s\n",
      "(Training) Loss: 940704.8499\n",
      "(Validation) Loss: 979322.9613, MAE: 3758.8591, R2: 0.1731\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3193/5000] | Time: 0.33s\n",
      "(Training) Loss: 954477.4981\n",
      "(Validation) Loss: 998355.3727, MAE: 3824.0479, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [3194/5000] | Time: 0.26s\n",
      "(Training) Loss: 968752.9981\n",
      "(Validation) Loss: 998187.5962, MAE: 3821.2515, R2: 0.1573\n",
      "==========================================================================================\n",
      "Epoch [3195/5000] | Time: 0.24s\n",
      "(Training) Loss: 959796.5698\n",
      "(Validation) Loss: 998032.3657, MAE: 3821.6333, R2: 0.1575\n",
      "==========================================================================================\n",
      "Epoch [3196/5000] | Time: 0.19s\n",
      "(Training) Loss: 962150.7671\n",
      "(Validation) Loss: 997884.0889, MAE: 3822.2996, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [3197/5000] | Time: 0.24s\n",
      "(Training) Loss: 974932.4194\n",
      "(Validation) Loss: 997813.1556, MAE: 3826.5986, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [3198/5000] | Time: 0.23s\n",
      "(Training) Loss: 966839.9264\n",
      "(Validation) Loss: 997667.0375, MAE: 3831.3403, R2: 0.1578\n",
      "==========================================================================================\n",
      "Epoch [3199/5000] | Time: 0.22s\n",
      "(Training) Loss: 966597.3274\n",
      "(Validation) Loss: 997497.5187, MAE: 3825.8506, R2: 0.1579\n",
      "==========================================================================================\n",
      "Epoch [3200/5000] | Time: 0.26s\n",
      "(Training) Loss: 978046.6193\n",
      "(Validation) Loss: 997338.9054, MAE: 3824.4109, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [3201/5000] | Time: 0.21s\n",
      "(Training) Loss: 969455.7766\n",
      "(Validation) Loss: 997180.9778, MAE: 3823.6355, R2: 0.1582\n",
      "==========================================================================================\n",
      "Epoch [3202/5000] | Time: 0.21s\n",
      "(Training) Loss: 959776.6129\n",
      "(Validation) Loss: 997023.0908, MAE: 3823.5874, R2: 0.1583\n",
      "==========================================================================================\n",
      "Epoch [3203/5000] | Time: 0.29s\n",
      "(Training) Loss: 976530.6453\n",
      "(Validation) Loss: 996867.5911, MAE: 3821.9631, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [3204/5000] | Time: 0.22s\n",
      "(Training) Loss: 978034.4105\n",
      "(Validation) Loss: 996725.2673, MAE: 3824.3545, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [3205/5000] | Time: 0.20s\n",
      "(Training) Loss: 978936.9369\n",
      "(Validation) Loss: 996567.0349, MAE: 3826.0496, R2: 0.1587\n",
      "==========================================================================================\n",
      "Epoch [3206/5000] | Time: 0.23s\n",
      "(Training) Loss: 980178.8052\n",
      "(Validation) Loss: 996406.8927, MAE: 3823.0203, R2: 0.1588\n",
      "==========================================================================================\n",
      "Epoch [3207/5000] | Time: 0.22s\n",
      "(Training) Loss: 969497.0812\n",
      "(Validation) Loss: 996248.4521, MAE: 3823.0686, R2: 0.1590\n",
      "==========================================================================================\n",
      "Epoch [3208/5000] | Time: 0.26s\n",
      "(Training) Loss: 980501.5806\n",
      "(Validation) Loss: 996086.6743, MAE: 3819.6880, R2: 0.1591\n",
      "==========================================================================================\n",
      "Epoch [3209/5000] | Time: 0.26s\n",
      "(Training) Loss: 976153.1897\n",
      "(Validation) Loss: 995930.0317, MAE: 3819.2739, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [3210/5000] | Time: 0.26s\n",
      "(Training) Loss: 978341.5019\n",
      "(Validation) Loss: 995774.4102, MAE: 3819.0002, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [3211/5000] | Time: 0.21s\n",
      "(Training) Loss: 965321.0292\n",
      "(Validation) Loss: 995627.2914, MAE: 3819.7949, R2: 0.1595\n",
      "==========================================================================================\n",
      "Epoch [3212/5000] | Time: 0.35s\n",
      "(Training) Loss: 957733.6942\n",
      "(Validation) Loss: 989335.4108, MAE: 3812.1018, R2: 0.1647\n",
      "==========================================================================================\n",
      "Epoch [3213/5000] | Time: 0.22s\n",
      "(Training) Loss: 976427.9816\n",
      "(Validation) Loss: 995211.5810, MAE: 3825.8101, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [3214/5000] | Time: 0.20s\n",
      "(Training) Loss: 957819.2846\n",
      "(Validation) Loss: 995031.8070, MAE: 3819.7212, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [3215/5000] | Time: 0.24s\n",
      "(Training) Loss: 958677.0971\n",
      "(Validation) Loss: 994876.8356, MAE: 3819.6416, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [3216/5000] | Time: 0.24s\n",
      "(Training) Loss: 961976.8547\n",
      "(Validation) Loss: 994712.6451, MAE: 3818.1248, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [3217/5000] | Time: 0.22s\n",
      "(Training) Loss: 972560.3985\n",
      "(Validation) Loss: 994546.2959, MAE: 3814.8623, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [3218/5000] | Time: 0.23s\n",
      "(Training) Loss: 972470.4451\n",
      "(Validation) Loss: 994394.1435, MAE: 3814.6841, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [3219/5000] | Time: 0.20s\n",
      "(Training) Loss: 957269.5577\n",
      "(Validation) Loss: 994241.2698, MAE: 3818.8223, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [3220/5000] | Time: 0.20s\n",
      "(Training) Loss: 967472.4181\n",
      "(Validation) Loss: 994076.9321, MAE: 3813.4590, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [3221/5000] | Time: 0.22s\n",
      "(Training) Loss: 958672.4258\n",
      "(Validation) Loss: 993920.2337, MAE: 3813.8667, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [3222/5000] | Time: 0.21s\n",
      "(Training) Loss: 956646.6516\n",
      "(Validation) Loss: 993762.6921, MAE: 3812.2524, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [3223/5000] | Time: 0.23s\n",
      "(Training) Loss: 995300.1510\n",
      "(Validation) Loss: 993609.3460, MAE: 3812.4399, R2: 0.1612\n",
      "==========================================================================================\n",
      "Epoch [3224/5000] | Time: 0.29s\n",
      "(Training) Loss: 963427.2798\n",
      "(Validation) Loss: 993684.8711, MAE: 3814.6150, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [3225/5000] | Time: 0.23s\n",
      "(Training) Loss: 970183.3534\n",
      "(Validation) Loss: 993296.3556, MAE: 3810.6924, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [3226/5000] | Time: 0.26s\n",
      "(Training) Loss: 953381.7237\n",
      "(Validation) Loss: 993141.2571, MAE: 3811.4143, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [3227/5000] | Time: 0.22s\n",
      "(Training) Loss: 959078.6231\n",
      "(Validation) Loss: 992984.4114, MAE: 3809.3625, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [3228/5000] | Time: 0.23s\n",
      "(Training) Loss: 980445.2878\n",
      "(Validation) Loss: 992829.1352, MAE: 3809.9207, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [3229/5000] | Time: 0.20s\n",
      "(Training) Loss: 972159.3369\n",
      "(Validation) Loss: 992674.8597, MAE: 3809.6597, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [3230/5000] | Time: 0.23s\n",
      "(Training) Loss: 957195.0006\n",
      "(Validation) Loss: 992516.0330, MAE: 3807.2126, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [3231/5000] | Time: 0.24s\n",
      "(Training) Loss: 963212.5647\n",
      "(Validation) Loss: 992370.3517, MAE: 3809.2866, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [3232/5000] | Time: 0.25s\n",
      "(Training) Loss: 980014.7043\n",
      "(Validation) Loss: 992207.0400, MAE: 3805.9407, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [3233/5000] | Time: 0.25s\n",
      "(Training) Loss: 959319.8913\n",
      "(Validation) Loss: 992048.7873, MAE: 3804.8372, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [3234/5000] | Time: 0.28s\n",
      "(Training) Loss: 966347.5279\n",
      "(Validation) Loss: 991906.5702, MAE: 3808.5254, R2: 0.1626\n",
      "==========================================================================================\n",
      "Epoch [3235/5000] | Time: 0.27s\n",
      "(Training) Loss: 960120.5635\n",
      "(Validation) Loss: 991745.6102, MAE: 3806.0696, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [3236/5000] | Time: 0.21s\n",
      "(Training) Loss: 963251.3223\n",
      "(Validation) Loss: 991588.5206, MAE: 3803.6028, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [3237/5000] | Time: 0.25s\n",
      "(Training) Loss: 962935.4124\n",
      "(Validation) Loss: 991435.7435, MAE: 3803.8540, R2: 0.1630\n",
      "==========================================================================================\n",
      "Epoch [3238/5000] | Time: 0.31s\n",
      "(Training) Loss: 963522.1865\n",
      "(Validation) Loss: 991283.0476, MAE: 3803.3406, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [3239/5000] | Time: 0.27s\n",
      "(Training) Loss: 964457.1098\n",
      "(Validation) Loss: 991130.5448, MAE: 3803.0796, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [3240/5000] | Time: 0.26s\n",
      "(Training) Loss: 963587.5444\n",
      "(Validation) Loss: 990971.2711, MAE: 3800.5740, R2: 0.1634\n",
      "==========================================================================================\n",
      "Epoch [3241/5000] | Time: 0.26s\n",
      "(Training) Loss: 960286.5152\n",
      "(Validation) Loss: 990823.3956, MAE: 3807.6902, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [3242/5000] | Time: 0.22s\n",
      "(Training) Loss: 978603.7024\n",
      "(Validation) Loss: 990669.2317, MAE: 3804.0679, R2: 0.1636\n",
      "==========================================================================================\n",
      "Epoch [3243/5000] | Time: 0.26s\n",
      "(Training) Loss: 960706.3585\n",
      "(Validation) Loss: 990515.0375, MAE: 3802.8374, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [3244/5000] | Time: 0.25s\n",
      "(Training) Loss: 955416.4181\n",
      "(Validation) Loss: 990362.5956, MAE: 3802.5061, R2: 0.1639\n",
      "==========================================================================================\n",
      "Epoch [3245/5000] | Time: 0.24s\n",
      "(Training) Loss: 959492.7513\n",
      "(Validation) Loss: 990211.7740, MAE: 3802.4150, R2: 0.1640\n",
      "==========================================================================================\n",
      "Epoch [3246/5000] | Time: 0.26s\n",
      "(Training) Loss: 953885.0577\n",
      "(Validation) Loss: 990053.9581, MAE: 3800.5410, R2: 0.1641\n",
      "==========================================================================================\n",
      "Epoch [3247/5000] | Time: 0.25s\n",
      "(Training) Loss: 968097.7678\n",
      "(Validation) Loss: 989900.9676, MAE: 3798.8374, R2: 0.1643\n",
      "==========================================================================================\n",
      "Epoch [3248/5000] | Time: 0.26s\n",
      "(Training) Loss: 964835.4803\n",
      "(Validation) Loss: 989749.1556, MAE: 3799.4609, R2: 0.1644\n",
      "==========================================================================================\n",
      "Epoch [3249/5000] | Time: 0.33s\n",
      "(Training) Loss: 966114.8541\n",
      "(Validation) Loss: 989591.3244, MAE: 3797.2380, R2: 0.1645\n",
      "==========================================================================================\n",
      "Epoch [3250/5000] | Time: 0.30s\n",
      "(Training) Loss: 960967.7348\n",
      "(Validation) Loss: 989441.3206, MAE: 3798.3054, R2: 0.1646\n",
      "==========================================================================================\n",
      "Epoch [3251/5000] | Time: 0.29s\n",
      "(Training) Loss: 950233.7998\n",
      "(Validation) Loss: 989284.4698, MAE: 3796.6296, R2: 0.1648\n",
      "==========================================================================================\n",
      "Epoch [3252/5000] | Time: 0.24s\n",
      "(Training) Loss: 976183.1973\n",
      "(Validation) Loss: 989135.0756, MAE: 3796.8201, R2: 0.1649\n",
      "==========================================================================================\n",
      "Epoch [3253/5000] | Time: 0.28s\n",
      "(Training) Loss: 993591.3718\n",
      "(Validation) Loss: 988976.4876, MAE: 3795.5679, R2: 0.1650\n",
      "==========================================================================================\n",
      "Epoch [3254/5000] | Time: 0.27s\n",
      "(Training) Loss: 973680.9086\n",
      "(Validation) Loss: 988828.6121, MAE: 3796.1743, R2: 0.1651\n",
      "==========================================================================================\n",
      "Epoch [3255/5000] | Time: 0.24s\n",
      "(Training) Loss: 962164.4378\n",
      "(Validation) Loss: 988670.1867, MAE: 3794.7432, R2: 0.1653\n",
      "==========================================================================================\n",
      "Epoch [3256/5000] | Time: 0.24s\n",
      "(Training) Loss: 953505.1199\n",
      "(Validation) Loss: 988515.5048, MAE: 3794.6096, R2: 0.1654\n",
      "==========================================================================================\n",
      "Epoch [3257/5000] | Time: 0.26s\n",
      "(Training) Loss: 948652.4794\n",
      "(Validation) Loss: 988359.1162, MAE: 3791.6016, R2: 0.1655\n",
      "==========================================================================================\n",
      "Epoch [3258/5000] | Time: 0.33s\n",
      "(Training) Loss: 955303.9968\n",
      "(Validation) Loss: 988219.6622, MAE: 3795.5676, R2: 0.1657\n",
      "==========================================================================================\n",
      "Epoch [3259/5000] | Time: 0.21s\n",
      "(Training) Loss: 951786.6453\n",
      "(Validation) Loss: 988086.9130, MAE: 3797.6851, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [3260/5000] | Time: 0.25s\n",
      "(Training) Loss: 964308.2792\n",
      "(Validation) Loss: 987916.9727, MAE: 3795.0496, R2: 0.1659\n",
      "==========================================================================================\n",
      "Epoch [3261/5000] | Time: 0.19s\n",
      "(Training) Loss: 952861.6701\n",
      "(Validation) Loss: 987760.2286, MAE: 3793.4141, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3262/5000] | Time: 0.20s\n",
      "(Training) Loss: 967209.1872\n",
      "(Validation) Loss: 987604.1752, MAE: 3790.4531, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3263/5000] | Time: 0.26s\n",
      "(Training) Loss: 971655.0901\n",
      "(Validation) Loss: 987454.7454, MAE: 3790.4739, R2: 0.1663\n",
      "==========================================================================================\n",
      "Epoch [3264/5000] | Time: 0.30s\n",
      "(Training) Loss: 954524.8274\n",
      "(Validation) Loss: 987299.7943, MAE: 3790.0105, R2: 0.1664\n",
      "==========================================================================================\n",
      "Epoch [3265/5000] | Time: 0.29s\n",
      "(Training) Loss: 953174.1662\n",
      "(Validation) Loss: 987145.1581, MAE: 3788.2737, R2: 0.1665\n",
      "==========================================================================================\n",
      "Epoch [3266/5000] | Time: 0.27s\n",
      "(Training) Loss: 958038.2018\n",
      "(Validation) Loss: 986997.5010, MAE: 3789.5891, R2: 0.1667\n",
      "==========================================================================================\n",
      "Epoch [3267/5000] | Time: 0.22s\n",
      "(Training) Loss: 958606.8046\n",
      "(Validation) Loss: 986842.5854, MAE: 3790.6267, R2: 0.1668\n",
      "==========================================================================================\n",
      "Epoch [3268/5000] | Time: 0.28s\n",
      "(Training) Loss: 962766.4683\n",
      "(Validation) Loss: 986709.3079, MAE: 3793.8899, R2: 0.1669\n",
      "==========================================================================================\n",
      "Epoch [3269/5000] | Time: 0.29s\n",
      "(Training) Loss: 953149.9613\n",
      "(Validation) Loss: 986564.0787, MAE: 3793.8701, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3270/5000] | Time: 0.19s\n",
      "(Training) Loss: 949473.7367\n",
      "(Validation) Loss: 986388.4343, MAE: 3789.1606, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3271/5000] | Time: 0.18s\n",
      "(Training) Loss: 952005.7306\n",
      "(Validation) Loss: 986240.5079, MAE: 3787.5625, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3272/5000] | Time: 0.18s\n",
      "(Training) Loss: 951916.2398\n",
      "(Validation) Loss: 986094.6844, MAE: 3788.4473, R2: 0.1674\n",
      "==========================================================================================\n",
      "Epoch [3273/5000] | Time: 0.21s\n",
      "(Training) Loss: 952269.5990\n",
      "(Validation) Loss: 985938.6362, MAE: 3788.2952, R2: 0.1676\n",
      "==========================================================================================\n",
      "Epoch [3274/5000] | Time: 0.19s\n",
      "(Training) Loss: 963629.2481\n",
      "(Validation) Loss: 985795.4337, MAE: 3787.7893, R2: 0.1677\n",
      "==========================================================================================\n",
      "Epoch [3275/5000] | Time: 0.20s\n",
      "(Training) Loss: 969961.6180\n",
      "(Validation) Loss: 985640.6654, MAE: 3787.3918, R2: 0.1678\n",
      "==========================================================================================\n",
      "Epoch [3276/5000] | Time: 0.22s\n",
      "(Training) Loss: 953127.4549\n",
      "(Validation) Loss: 986644.9575, MAE: 3797.5933, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3277/5000] | Time: 0.24s\n",
      "(Training) Loss: 957209.2214\n",
      "(Validation) Loss: 986492.1295, MAE: 3795.1785, R2: 0.1671\n",
      "==========================================================================================\n",
      "Epoch [3278/5000] | Time: 0.27s\n",
      "(Training) Loss: 970153.6897\n",
      "(Validation) Loss: 986348.8711, MAE: 3792.3096, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3279/5000] | Time: 0.20s\n",
      "(Training) Loss: 952959.5723\n",
      "(Validation) Loss: 986204.0635, MAE: 3791.2678, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3280/5000] | Time: 0.25s\n",
      "(Training) Loss: 950043.4543\n",
      "(Validation) Loss: 986058.7225, MAE: 3791.7678, R2: 0.1675\n",
      "==========================================================================================\n",
      "Epoch [3281/5000] | Time: 0.23s\n",
      "(Training) Loss: 954059.1618\n",
      "(Validation) Loss: 985905.3105, MAE: 3788.9475, R2: 0.1676\n",
      "==========================================================================================\n",
      "Epoch [3282/5000] | Time: 0.30s\n",
      "(Training) Loss: 953752.3503\n",
      "(Validation) Loss: 985795.1441, MAE: 3796.9619, R2: 0.1677\n",
      "==========================================================================================\n",
      "Epoch [3283/5000] | Time: 0.28s\n",
      "(Training) Loss: 956728.5266\n",
      "(Validation) Loss: 985608.6298, MAE: 3786.4778, R2: 0.1678\n",
      "==========================================================================================\n",
      "Epoch [3284/5000] | Time: 0.33s\n",
      "(Training) Loss: 961948.4162\n",
      "(Validation) Loss: 985471.8375, MAE: 3788.9919, R2: 0.1679\n",
      "==========================================================================================\n",
      "Epoch [3285/5000] | Time: 0.36s\n",
      "(Training) Loss: 948711.4803\n",
      "(Validation) Loss: 985315.3625, MAE: 3785.0220, R2: 0.1681\n",
      "==========================================================================================\n",
      "Epoch [3286/5000] | Time: 0.34s\n",
      "(Training) Loss: 947787.7925\n",
      "(Validation) Loss: 985172.1295, MAE: 3784.9600, R2: 0.1682\n",
      "==========================================================================================\n",
      "Epoch [3287/5000] | Time: 0.30s\n",
      "(Training) Loss: 948843.3801\n",
      "(Validation) Loss: 985022.7505, MAE: 3782.8911, R2: 0.1683\n",
      "==========================================================================================\n",
      "Epoch [3288/5000] | Time: 0.28s\n",
      "(Training) Loss: 955182.7722\n",
      "(Validation) Loss: 984891.5048, MAE: 3784.9082, R2: 0.1684\n",
      "==========================================================================================\n",
      "Epoch [3289/5000] | Time: 0.29s\n",
      "(Training) Loss: 947998.2418\n",
      "(Validation) Loss: 984732.2260, MAE: 3782.3069, R2: 0.1686\n",
      "==========================================================================================\n",
      "Epoch [3290/5000] | Time: 0.29s\n",
      "(Training) Loss: 973249.2430\n",
      "(Validation) Loss: 984593.8438, MAE: 3783.7439, R2: 0.1687\n",
      "==========================================================================================\n",
      "Epoch [3291/5000] | Time: 0.25s\n",
      "(Training) Loss: 957454.8464\n",
      "(Validation) Loss: 984475.3829, MAE: 3787.3110, R2: 0.1688\n",
      "==========================================================================================\n",
      "Epoch [3292/5000] | Time: 0.36s\n",
      "(Training) Loss: 943488.5869\n",
      "(Validation) Loss: 984305.2038, MAE: 3784.5168, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [3293/5000] | Time: 0.35s\n",
      "(Training) Loss: 972540.3953\n",
      "(Validation) Loss: 984160.3403, MAE: 3783.9600, R2: 0.1690\n",
      "==========================================================================================\n",
      "Epoch [3294/5000] | Time: 0.32s\n",
      "(Training) Loss: 973314.9797\n",
      "(Validation) Loss: 984000.3810, MAE: 3779.4790, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [3295/5000] | Time: 0.26s\n",
      "(Training) Loss: 955287.8934\n",
      "(Validation) Loss: 983852.1448, MAE: 3779.2705, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [3296/5000] | Time: 0.24s\n",
      "(Training) Loss: 965485.9924\n",
      "(Validation) Loss: 983709.0895, MAE: 3779.4761, R2: 0.1694\n",
      "==========================================================================================\n",
      "Epoch [3297/5000] | Time: 0.28s\n",
      "(Training) Loss: 947240.2614\n",
      "(Validation) Loss: 983564.2514, MAE: 3779.3870, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [3298/5000] | Time: 0.28s\n",
      "(Training) Loss: 942638.7125\n",
      "(Validation) Loss: 983415.6648, MAE: 3779.0342, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [3299/5000] | Time: 0.23s\n",
      "(Training) Loss: 954180.0157\n",
      "(Validation) Loss: 983267.2152, MAE: 3775.2305, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3300/5000] | Time: 0.26s\n",
      "(Training) Loss: 949478.5171\n",
      "(Validation) Loss: 983129.9556, MAE: 3777.8733, R2: 0.1699\n",
      "==========================================================================================\n",
      "Epoch [3301/5000] | Time: 0.30s\n",
      "(Training) Loss: 952583.0907\n",
      "(Validation) Loss: 982982.9537, MAE: 3776.0562, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3302/5000] | Time: 0.28s\n",
      "(Training) Loss: 959906.3947\n",
      "(Validation) Loss: 982837.4603, MAE: 3776.7104, R2: 0.1701\n",
      "==========================================================================================\n",
      "Epoch [3303/5000] | Time: 0.27s\n",
      "(Training) Loss: 953740.5990\n",
      "(Validation) Loss: 982697.8337, MAE: 3777.5286, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [3304/5000] | Time: 0.27s\n",
      "(Training) Loss: 967564.4416\n",
      "(Validation) Loss: 982545.5695, MAE: 3775.9473, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [3305/5000] | Time: 0.25s\n",
      "(Training) Loss: 959178.4232\n",
      "(Validation) Loss: 982395.8146, MAE: 3773.9463, R2: 0.1705\n",
      "==========================================================================================\n",
      "Epoch [3306/5000] | Time: 0.23s\n",
      "(Training) Loss: 958286.6041\n",
      "(Validation) Loss: 982259.5048, MAE: 3775.0242, R2: 0.1706\n",
      "==========================================================================================\n",
      "Epoch [3307/5000] | Time: 0.23s\n",
      "(Training) Loss: 956138.7513\n",
      "(Validation) Loss: 982105.6660, MAE: 3774.5803, R2: 0.1707\n",
      "==========================================================================================\n",
      "Epoch [3308/5000] | Time: 0.23s\n",
      "(Training) Loss: 960860.0044\n",
      "(Validation) Loss: 988084.6578, MAE: 3795.1841, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [3309/5000] | Time: 0.24s\n",
      "(Training) Loss: 965348.1713\n",
      "(Validation) Loss: 987914.5651, MAE: 3791.3032, R2: 0.1659\n",
      "==========================================================================================\n",
      "Epoch [3310/5000] | Time: 0.20s\n",
      "(Training) Loss: 963123.2849\n",
      "(Validation) Loss: 987760.2286, MAE: 3791.1843, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3311/5000] | Time: 0.20s\n",
      "(Training) Loss: 962969.5964\n",
      "(Validation) Loss: 987608.9752, MAE: 3792.3806, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3312/5000] | Time: 0.19s\n",
      "(Training) Loss: 958729.0397\n",
      "(Validation) Loss: 987448.4013, MAE: 3790.3977, R2: 0.1663\n",
      "==========================================================================================\n",
      "Epoch [3313/5000] | Time: 0.25s\n",
      "(Training) Loss: 965322.2519\n",
      "(Validation) Loss: 987311.3397, MAE: 3797.3193, R2: 0.1664\n",
      "==========================================================================================\n",
      "Epoch [3314/5000] | Time: 0.24s\n",
      "(Training) Loss: 950565.4746\n",
      "(Validation) Loss: 992775.9187, MAE: 3813.8147, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [3315/5000] | Time: 0.24s\n",
      "(Training) Loss: 964412.0736\n",
      "(Validation) Loss: 992597.9937, MAE: 3809.9548, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [3316/5000] | Time: 0.22s\n",
      "(Training) Loss: 957224.1637\n",
      "(Validation) Loss: 992435.2914, MAE: 3810.5479, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [3317/5000] | Time: 0.26s\n",
      "(Training) Loss: 976713.0381\n",
      "(Validation) Loss: 992270.3797, MAE: 3808.0225, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [3318/5000] | Time: 0.32s\n",
      "(Training) Loss: 961128.8014\n",
      "(Validation) Loss: 992110.6184, MAE: 3808.1133, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [3319/5000] | Time: 0.29s\n",
      "(Training) Loss: 957419.3807\n",
      "(Validation) Loss: 991947.6673, MAE: 3807.5208, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [3320/5000] | Time: 0.25s\n",
      "(Training) Loss: 967200.3972\n",
      "(Validation) Loss: 991791.0044, MAE: 3808.2607, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [3321/5000] | Time: 0.25s\n",
      "(Training) Loss: 954834.4365\n",
      "(Validation) Loss: 991634.5244, MAE: 3807.2800, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [3322/5000] | Time: 0.25s\n",
      "(Training) Loss: 991141.9067\n",
      "(Validation) Loss: 991471.9746, MAE: 3805.8735, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [3323/5000] | Time: 0.23s\n",
      "(Training) Loss: 955156.2379\n",
      "(Validation) Loss: 991311.8933, MAE: 3805.8755, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [3324/5000] | Time: 0.27s\n",
      "(Training) Loss: 969216.9105\n",
      "(Validation) Loss: 991160.1676, MAE: 3805.9207, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [3325/5000] | Time: 0.23s\n",
      "(Training) Loss: 969629.6421\n",
      "(Validation) Loss: 990997.2114, MAE: 3803.3723, R2: 0.1633\n",
      "==========================================================================================\n",
      "Epoch [3326/5000] | Time: 0.23s\n",
      "(Training) Loss: 975759.7132\n",
      "(Validation) Loss: 990845.6584, MAE: 3803.4058, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [3327/5000] | Time: 0.24s\n",
      "(Training) Loss: 960009.6396\n",
      "(Validation) Loss: 990685.5162, MAE: 3802.6765, R2: 0.1636\n",
      "==========================================================================================\n",
      "Epoch [3328/5000] | Time: 0.27s\n",
      "(Training) Loss: 963447.8668\n",
      "(Validation) Loss: 990530.4178, MAE: 3802.1511, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [3329/5000] | Time: 0.23s\n",
      "(Training) Loss: 951454.0558\n",
      "(Validation) Loss: 990370.8292, MAE: 3801.0469, R2: 0.1639\n",
      "==========================================================================================\n",
      "Epoch [3330/5000] | Time: 0.25s\n",
      "(Training) Loss: 961095.8439\n",
      "(Validation) Loss: 990218.4838, MAE: 3801.0178, R2: 0.1640\n",
      "==========================================================================================\n",
      "Epoch [3331/5000] | Time: 0.25s\n",
      "(Training) Loss: 951707.5644\n",
      "(Validation) Loss: 990064.6095, MAE: 3800.8184, R2: 0.1641\n",
      "==========================================================================================\n",
      "Epoch [3332/5000] | Time: 0.24s\n",
      "(Training) Loss: 964301.3033\n",
      "(Validation) Loss: 989911.2178, MAE: 3800.8064, R2: 0.1642\n",
      "==========================================================================================\n",
      "Epoch [3333/5000] | Time: 0.25s\n",
      "(Training) Loss: 962325.8566\n",
      "(Validation) Loss: 989757.1200, MAE: 3800.1787, R2: 0.1644\n",
      "==========================================================================================\n",
      "Epoch [3334/5000] | Time: 0.26s\n",
      "(Training) Loss: 960141.4093\n",
      "(Validation) Loss: 989598.4356, MAE: 3798.5613, R2: 0.1645\n",
      "==========================================================================================\n",
      "Epoch [3335/5000] | Time: 0.29s\n",
      "(Training) Loss: 958778.5533\n",
      "(Validation) Loss: 989449.2190, MAE: 3799.0256, R2: 0.1646\n",
      "==========================================================================================\n",
      "Epoch [3336/5000] | Time: 0.23s\n",
      "(Training) Loss: 965977.6739\n",
      "(Validation) Loss: 989292.9422, MAE: 3798.4314, R2: 0.1648\n",
      "==========================================================================================\n",
      "Epoch [3337/5000] | Time: 0.28s\n",
      "(Training) Loss: 951755.1386\n",
      "(Validation) Loss: 989137.5797, MAE: 3799.0383, R2: 0.1649\n",
      "==========================================================================================\n",
      "Epoch [3338/5000] | Time: 0.23s\n",
      "(Training) Loss: 965021.3230\n",
      "(Validation) Loss: 988986.4229, MAE: 3796.9768, R2: 0.1650\n",
      "==========================================================================================\n",
      "Epoch [3339/5000] | Time: 0.27s\n",
      "(Training) Loss: 963283.9277\n",
      "(Validation) Loss: 988832.4927, MAE: 3796.9958, R2: 0.1651\n",
      "==========================================================================================\n",
      "Epoch [3340/5000] | Time: 0.26s\n",
      "(Training) Loss: 961281.5489\n",
      "(Validation) Loss: 988683.4489, MAE: 3797.6477, R2: 0.1653\n",
      "==========================================================================================\n",
      "Epoch [3341/5000] | Time: 0.27s\n",
      "(Training) Loss: 975143.8604\n",
      "(Validation) Loss: 988598.8317, MAE: 3799.9309, R2: 0.1653\n",
      "==========================================================================================\n",
      "Epoch [3342/5000] | Time: 0.25s\n",
      "(Training) Loss: 954814.8572\n",
      "(Validation) Loss: 988447.7257, MAE: 3801.0337, R2: 0.1655\n",
      "==========================================================================================\n",
      "Epoch [3343/5000] | Time: 0.30s\n",
      "(Training) Loss: 961762.9829\n",
      "(Validation) Loss: 988291.8400, MAE: 3798.8179, R2: 0.1656\n",
      "==========================================================================================\n",
      "Epoch [3344/5000] | Time: 0.28s\n",
      "(Training) Loss: 961126.1079\n",
      "(Validation) Loss: 988141.0489, MAE: 3799.9019, R2: 0.1657\n",
      "==========================================================================================\n",
      "Epoch [3345/5000] | Time: 0.26s\n",
      "(Training) Loss: 948680.4756\n",
      "(Validation) Loss: 987987.8197, MAE: 3798.7639, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [3346/5000] | Time: 0.25s\n",
      "(Training) Loss: 955208.0381\n",
      "(Validation) Loss: 987829.5568, MAE: 3796.9199, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3347/5000] | Time: 0.24s\n",
      "(Training) Loss: 968734.5723\n",
      "(Validation) Loss: 987690.2806, MAE: 3806.6343, R2: 0.1661\n",
      "==========================================================================================\n",
      "Epoch [3348/5000] | Time: 0.27s\n",
      "(Training) Loss: 985426.9419\n",
      "(Validation) Loss: 987524.9117, MAE: 3798.0557, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3349/5000] | Time: 0.26s\n",
      "(Training) Loss: 952872.2335\n",
      "(Validation) Loss: 987373.6178, MAE: 3798.4114, R2: 0.1664\n",
      "==========================================================================================\n",
      "Epoch [3350/5000] | Time: 0.25s\n",
      "(Training) Loss: 964269.0025\n",
      "(Validation) Loss: 987222.2578, MAE: 3798.2190, R2: 0.1665\n",
      "==========================================================================================\n",
      "Epoch [3351/5000] | Time: 0.33s\n",
      "(Training) Loss: 955981.4727\n",
      "(Validation) Loss: 987061.8870, MAE: 3794.9189, R2: 0.1666\n",
      "==========================================================================================\n",
      "Epoch [3352/5000] | Time: 0.29s\n",
      "(Training) Loss: 953480.1681\n",
      "(Validation) Loss: 986908.2413, MAE: 3793.9666, R2: 0.1667\n",
      "==========================================================================================\n",
      "Epoch [3353/5000] | Time: 0.24s\n",
      "(Training) Loss: 972983.2893\n",
      "(Validation) Loss: 986760.0813, MAE: 3795.1987, R2: 0.1669\n",
      "==========================================================================================\n",
      "Epoch [3354/5000] | Time: 0.29s\n",
      "(Training) Loss: 960619.3515\n",
      "(Validation) Loss: 986608.4876, MAE: 3794.6489, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3355/5000] | Time: 0.31s\n",
      "(Training) Loss: 963798.5044\n",
      "(Validation) Loss: 986448.5384, MAE: 3793.0891, R2: 0.1671\n",
      "==========================================================================================\n",
      "Epoch [3356/5000] | Time: 0.28s\n",
      "(Training) Loss: 958847.0381\n",
      "(Validation) Loss: 986294.1867, MAE: 3792.3577, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3357/5000] | Time: 0.27s\n",
      "(Training) Loss: 956802.9905\n",
      "(Validation) Loss: 986137.3917, MAE: 3790.4829, R2: 0.1674\n",
      "==========================================================================================\n",
      "Epoch [3358/5000] | Time: 0.27s\n",
      "(Training) Loss: 956112.3991\n",
      "(Validation) Loss: 985986.2044, MAE: 3790.2200, R2: 0.1675\n",
      "==========================================================================================\n",
      "Epoch [3359/5000] | Time: 0.25s\n",
      "(Training) Loss: 978716.3813\n",
      "(Validation) Loss: 985836.8762, MAE: 3790.3911, R2: 0.1676\n",
      "==========================================================================================\n",
      "Epoch [3360/5000] | Time: 0.23s\n",
      "(Training) Loss: 949068.7655\n",
      "(Validation) Loss: 985681.8997, MAE: 3789.9822, R2: 0.1678\n",
      "==========================================================================================\n",
      "Epoch [3361/5000] | Time: 0.27s\n",
      "(Training) Loss: 953332.1161\n",
      "(Validation) Loss: 985532.3378, MAE: 3790.5920, R2: 0.1679\n",
      "==========================================================================================\n",
      "Epoch [3362/5000] | Time: 0.21s\n",
      "(Training) Loss: 984272.4594\n",
      "(Validation) Loss: 985374.8063, MAE: 3787.7202, R2: 0.1680\n",
      "==========================================================================================\n",
      "Epoch [3363/5000] | Time: 0.22s\n",
      "(Training) Loss: 957944.6463\n",
      "(Validation) Loss: 985220.4495, MAE: 3787.2336, R2: 0.1681\n",
      "==========================================================================================\n",
      "Epoch [3364/5000] | Time: 0.22s\n",
      "(Training) Loss: 962912.3160\n",
      "(Validation) Loss: 985070.7911, MAE: 3787.3137, R2: 0.1683\n",
      "==========================================================================================\n",
      "Epoch [3365/5000] | Time: 0.20s\n",
      "(Training) Loss: 956649.3280\n",
      "(Validation) Loss: 984914.0470, MAE: 3785.9353, R2: 0.1684\n",
      "==========================================================================================\n",
      "Epoch [3366/5000] | Time: 0.21s\n",
      "(Training) Loss: 957076.6304\n",
      "(Validation) Loss: 984761.7117, MAE: 3785.3074, R2: 0.1685\n",
      "==========================================================================================\n",
      "Epoch [3367/5000] | Time: 0.23s\n",
      "(Training) Loss: 957427.4607\n",
      "(Validation) Loss: 984609.3613, MAE: 3784.7314, R2: 0.1687\n",
      "==========================================================================================\n",
      "Epoch [3368/5000] | Time: 0.21s\n",
      "(Training) Loss: 963634.0412\n",
      "(Validation) Loss: 984458.9308, MAE: 3785.1160, R2: 0.1688\n",
      "==========================================================================================\n",
      "Epoch [3369/5000] | Time: 0.20s\n",
      "(Training) Loss: 953284.3756\n",
      "(Validation) Loss: 984307.8654, MAE: 3784.9983, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [3370/5000] | Time: 0.22s\n",
      "(Training) Loss: 950247.3883\n",
      "(Validation) Loss: 984152.1676, MAE: 3785.1501, R2: 0.1690\n",
      "==========================================================================================\n",
      "Epoch [3371/5000] | Time: 0.30s\n",
      "(Training) Loss: 950141.2747\n",
      "(Validation) Loss: 984002.8241, MAE: 3783.5476, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [3372/5000] | Time: 0.29s\n",
      "(Training) Loss: 944219.2919\n",
      "(Validation) Loss: 983860.9117, MAE: 3785.3564, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [3373/5000] | Time: 0.27s\n",
      "(Training) Loss: 997510.3496\n",
      "(Validation) Loss: 983722.2146, MAE: 3787.0500, R2: 0.1694\n",
      "==========================================================================================\n",
      "Epoch [3374/5000] | Time: 0.24s\n",
      "(Training) Loss: 952616.8369\n",
      "(Validation) Loss: 983544.4978, MAE: 3782.0139, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [3375/5000] | Time: 0.29s\n",
      "(Training) Loss: 950823.3978\n",
      "(Validation) Loss: 983417.0260, MAE: 3787.4717, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [3376/5000] | Time: 0.25s\n",
      "(Training) Loss: 965387.4213\n",
      "(Validation) Loss: 983238.6997, MAE: 3780.6555, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3377/5000] | Time: 0.21s\n",
      "(Training) Loss: 957737.6003\n",
      "(Validation) Loss: 983268.6375, MAE: 3792.7366, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3378/5000] | Time: 0.22s\n",
      "(Training) Loss: 951764.5451\n",
      "(Validation) Loss: 982968.6197, MAE: 3787.7009, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3379/5000] | Time: 0.24s\n",
      "(Training) Loss: 948027.6853\n",
      "(Validation) Loss: 982787.7790, MAE: 3780.3953, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [3380/5000] | Time: 0.24s\n",
      "(Training) Loss: 949321.6034\n",
      "(Validation) Loss: 982635.7283, MAE: 3779.9055, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [3381/5000] | Time: 0.26s\n",
      "(Training) Loss: 955047.0311\n",
      "(Validation) Loss: 982488.4216, MAE: 3782.0579, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [3382/5000] | Time: 0.23s\n",
      "(Training) Loss: 970323.9588\n",
      "(Validation) Loss: 1023544.8178, MAE: 3916.1255, R2: 0.1362\n",
      "==========================================================================================\n",
      "Epoch [3383/5000] | Time: 0.21s\n",
      "(Training) Loss: 987835.8921\n",
      "(Validation) Loss: 1023377.0514, MAE: 3913.6826, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [3384/5000] | Time: 0.27s\n",
      "(Training) Loss: 1002439.6256\n",
      "(Validation) Loss: 1023213.3994, MAE: 3914.2615, R2: 0.1365\n",
      "==========================================================================================\n",
      "Epoch [3385/5000] | Time: 0.31s\n",
      "(Training) Loss: 997628.8211\n",
      "(Validation) Loss: 1023041.3359, MAE: 3911.9546, R2: 0.1366\n",
      "==========================================================================================\n",
      "Epoch [3386/5000] | Time: 0.27s\n",
      "(Training) Loss: 986761.4708\n",
      "(Validation) Loss: 1022880.5638, MAE: 3912.3223, R2: 0.1368\n",
      "==========================================================================================\n",
      "Epoch [3387/5000] | Time: 0.25s\n",
      "(Training) Loss: 979376.5262\n",
      "(Validation) Loss: 1022717.7803, MAE: 3913.5234, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [3388/5000] | Time: 0.28s\n",
      "(Training) Loss: 991285.0641\n",
      "(Validation) Loss: 1022555.6063, MAE: 3911.4785, R2: 0.1370\n",
      "==========================================================================================\n",
      "Epoch [3389/5000] | Time: 0.28s\n",
      "(Training) Loss: 980668.2668\n",
      "(Validation) Loss: 1022406.8165, MAE: 3914.8962, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [3390/5000] | Time: 0.28s\n",
      "(Training) Loss: 1012980.6948\n",
      "(Validation) Loss: 1022228.5917, MAE: 3909.9644, R2: 0.1373\n",
      "==========================================================================================\n",
      "Epoch [3391/5000] | Time: 0.31s\n",
      "(Training) Loss: 982806.6187\n",
      "(Validation) Loss: 1022065.7117, MAE: 3909.5234, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [3392/5000] | Time: 0.29s\n",
      "(Training) Loss: 979249.5955\n",
      "(Validation) Loss: 1021910.0546, MAE: 3910.3784, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [3393/5000] | Time: 0.23s\n",
      "(Training) Loss: 994347.0374\n",
      "(Validation) Loss: 1021753.5390, MAE: 3912.0442, R2: 0.1377\n",
      "==========================================================================================\n",
      "Epoch [3394/5000] | Time: 0.27s\n",
      "(Training) Loss: 978734.2333\n",
      "(Validation) Loss: 1021576.8533, MAE: 3908.2017, R2: 0.1378\n",
      "==========================================================================================\n",
      "Epoch [3395/5000] | Time: 0.31s\n",
      "(Training) Loss: 984745.9289\n",
      "(Validation) Loss: 1021422.7302, MAE: 3907.7996, R2: 0.1380\n",
      "==========================================================================================\n",
      "Epoch [3396/5000] | Time: 0.29s\n",
      "(Training) Loss: 999681.5895\n",
      "(Validation) Loss: 1021257.9911, MAE: 3906.6521, R2: 0.1381\n",
      "==========================================================================================\n",
      "Epoch [3397/5000] | Time: 0.29s\n",
      "(Training) Loss: 981645.4353\n",
      "(Validation) Loss: 1021089.0971, MAE: 3904.4504, R2: 0.1383\n",
      "==========================================================================================\n",
      "Epoch [3398/5000] | Time: 0.33s\n",
      "(Training) Loss: 989493.2906\n",
      "(Validation) Loss: 1020934.6540, MAE: 3905.1587, R2: 0.1384\n",
      "==========================================================================================\n",
      "Epoch [3399/5000] | Time: 0.34s\n",
      "(Training) Loss: 999735.3794\n",
      "(Validation) Loss: 1020768.3098, MAE: 3903.3220, R2: 0.1385\n",
      "==========================================================================================\n",
      "Epoch [3400/5000] | Time: 0.32s\n",
      "(Training) Loss: 1002668.3712\n",
      "(Validation) Loss: 1020611.6165, MAE: 3904.3120, R2: 0.1387\n",
      "==========================================================================================\n",
      "Epoch [3401/5000] | Time: 0.27s\n",
      "(Training) Loss: 985359.7145\n",
      "(Validation) Loss: 1020445.2419, MAE: 3902.8887, R2: 0.1388\n",
      "==========================================================================================\n",
      "Epoch [3402/5000] | Time: 0.33s\n",
      "(Training) Loss: 998578.5850\n",
      "(Validation) Loss: 1020292.9575, MAE: 3903.6099, R2: 0.1389\n",
      "==========================================================================================\n",
      "Epoch [3403/5000] | Time: 0.38s\n",
      "(Training) Loss: 983359.3039\n",
      "(Validation) Loss: 1020131.5606, MAE: 3903.4263, R2: 0.1391\n",
      "==========================================================================================\n",
      "Epoch [3404/5000] | Time: 0.37s\n",
      "(Training) Loss: 980259.6688\n",
      "(Validation) Loss: 1019965.8159, MAE: 3901.4521, R2: 0.1392\n",
      "==========================================================================================\n",
      "Epoch [3405/5000] | Time: 0.31s\n",
      "(Training) Loss: 993190.0089\n",
      "(Validation) Loss: 1019802.8495, MAE: 3899.7053, R2: 0.1393\n",
      "==========================================================================================\n",
      "Epoch [3406/5000] | Time: 0.28s\n",
      "(Training) Loss: 979292.4559\n",
      "(Validation) Loss: 1019641.8692, MAE: 3899.7170, R2: 0.1395\n",
      "==========================================================================================\n",
      "Epoch [3407/5000] | Time: 0.25s\n",
      "(Training) Loss: 995870.9727\n",
      "(Validation) Loss: 1019490.6362, MAE: 3901.2061, R2: 0.1396\n",
      "==========================================================================================\n",
      "Epoch [3408/5000] | Time: 0.25s\n",
      "(Training) Loss: 981436.8978\n",
      "(Validation) Loss: 1019321.1378, MAE: 3898.5193, R2: 0.1397\n",
      "==========================================================================================\n",
      "Epoch [3409/5000] | Time: 0.22s\n",
      "(Training) Loss: 983803.1967\n",
      "(Validation) Loss: 1019170.1333, MAE: 3900.6318, R2: 0.1399\n",
      "==========================================================================================\n",
      "Epoch [3410/5000] | Time: 0.23s\n",
      "(Training) Loss: 976584.9010\n",
      "(Validation) Loss: 1019002.2502, MAE: 3897.7336, R2: 0.1400\n",
      "==========================================================================================\n",
      "Epoch [3411/5000] | Time: 0.20s\n",
      "(Training) Loss: 984061.5641\n",
      "(Validation) Loss: 1018847.8222, MAE: 3898.2432, R2: 0.1401\n",
      "==========================================================================================\n",
      "Epoch [3412/5000] | Time: 0.23s\n",
      "(Training) Loss: 982563.0301\n",
      "(Validation) Loss: 1018700.8254, MAE: 3900.9810, R2: 0.1402\n",
      "==========================================================================================\n",
      "Epoch [3413/5000] | Time: 0.22s\n",
      "(Training) Loss: 979793.8585\n",
      "(Validation) Loss: 1018529.0362, MAE: 3898.6914, R2: 0.1404\n",
      "==========================================================================================\n",
      "Epoch [3414/5000] | Time: 0.28s\n",
      "(Training) Loss: 994095.2659\n",
      "(Validation) Loss: 1018371.3270, MAE: 3895.7092, R2: 0.1405\n",
      "==========================================================================================\n",
      "Epoch [3415/5000] | Time: 0.27s\n",
      "(Training) Loss: 989614.8020\n",
      "(Validation) Loss: 1018209.0260, MAE: 3894.8132, R2: 0.1407\n",
      "==========================================================================================\n",
      "Epoch [3416/5000] | Time: 0.28s\n",
      "(Training) Loss: 989540.2157\n",
      "(Validation) Loss: 1018052.7187, MAE: 3895.3899, R2: 0.1408\n",
      "==========================================================================================\n",
      "Epoch [3417/5000] | Time: 0.30s\n",
      "(Training) Loss: 988084.0470\n",
      "(Validation) Loss: 1017889.2140, MAE: 3893.9331, R2: 0.1409\n",
      "==========================================================================================\n",
      "Epoch [3418/5000] | Time: 0.33s\n",
      "(Training) Loss: 994154.4721\n",
      "(Validation) Loss: 1017728.7263, MAE: 3893.0117, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [3419/5000] | Time: 0.31s\n",
      "(Training) Loss: 981236.8890\n",
      "(Validation) Loss: 1017565.9022, MAE: 3891.7815, R2: 0.1412\n",
      "==========================================================================================\n",
      "Epoch [3420/5000] | Time: 0.31s\n",
      "(Training) Loss: 996784.4378\n",
      "(Validation) Loss: 1017409.2343, MAE: 3891.5095, R2: 0.1413\n",
      "==========================================================================================\n",
      "Epoch [3421/5000] | Time: 0.34s\n",
      "(Training) Loss: 1010407.4873\n",
      "(Validation) Loss: 1017250.7987, MAE: 3892.0056, R2: 0.1415\n",
      "==========================================================================================\n",
      "Epoch [3422/5000] | Time: 0.34s\n",
      "(Training) Loss: 993859.5895\n",
      "(Validation) Loss: 1017092.0076, MAE: 3891.9651, R2: 0.1416\n",
      "==========================================================================================\n",
      "Epoch [3423/5000] | Time: 0.31s\n",
      "(Training) Loss: 996077.8458\n",
      "(Validation) Loss: 1016937.7829, MAE: 3892.4443, R2: 0.1417\n",
      "==========================================================================================\n",
      "Epoch [3424/5000] | Time: 0.30s\n",
      "(Training) Loss: 994689.7449\n",
      "(Validation) Loss: 1016778.0063, MAE: 3891.9514, R2: 0.1418\n",
      "==========================================================================================\n",
      "Epoch [3425/5000] | Time: 0.28s\n",
      "(Training) Loss: 987178.7563\n",
      "(Validation) Loss: 1016610.5549, MAE: 3889.3149, R2: 0.1420\n",
      "==========================================================================================\n",
      "Epoch [3426/5000] | Time: 0.25s\n",
      "(Training) Loss: 992367.5635\n",
      "(Validation) Loss: 1016453.1860, MAE: 3888.3245, R2: 0.1421\n",
      "==========================================================================================\n",
      "Epoch [3427/5000] | Time: 0.25s\n",
      "(Training) Loss: 984108.9340\n",
      "(Validation) Loss: 1016295.7917, MAE: 3889.4819, R2: 0.1423\n",
      "==========================================================================================\n",
      "Epoch [3428/5000] | Time: 0.28s\n",
      "(Training) Loss: 982555.8839\n",
      "(Validation) Loss: 1016133.7956, MAE: 3887.6118, R2: 0.1424\n",
      "==========================================================================================\n",
      "Epoch [3429/5000] | Time: 0.36s\n",
      "(Training) Loss: 1002992.6999\n",
      "(Validation) Loss: 1015974.8876, MAE: 3886.6489, R2: 0.1425\n",
      "==========================================================================================\n",
      "Epoch [3430/5000] | Time: 0.29s\n",
      "(Training) Loss: 994070.9949\n",
      "(Validation) Loss: 1015820.7340, MAE: 3887.5215, R2: 0.1426\n",
      "==========================================================================================\n",
      "Epoch [3431/5000] | Time: 0.28s\n",
      "(Training) Loss: 996057.7513\n",
      "(Validation) Loss: 1015664.4724, MAE: 3887.8413, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [3432/5000] | Time: 0.35s\n",
      "(Training) Loss: 994978.1770\n",
      "(Validation) Loss: 1015496.9397, MAE: 3885.2578, R2: 0.1429\n",
      "==========================================================================================\n",
      "Epoch [3433/5000] | Time: 0.31s\n",
      "(Training) Loss: 990017.6453\n",
      "(Validation) Loss: 1015338.7479, MAE: 3884.6504, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [3434/5000] | Time: 0.29s\n",
      "(Training) Loss: 981945.2538\n",
      "(Validation) Loss: 1015181.8971, MAE: 3883.8149, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [3435/5000] | Time: 0.32s\n",
      "(Training) Loss: 993375.8852\n",
      "(Validation) Loss: 1015025.5492, MAE: 3885.0732, R2: 0.1433\n",
      "==========================================================================================\n",
      "Epoch [3436/5000] | Time: 0.26s\n",
      "(Training) Loss: 980431.7595\n",
      "(Validation) Loss: 1014864.6654, MAE: 3882.6177, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [3437/5000] | Time: 0.30s\n",
      "(Training) Loss: 982446.4378\n",
      "(Validation) Loss: 1014717.1606, MAE: 3885.9912, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [3438/5000] | Time: 0.30s\n",
      "(Training) Loss: 1006447.8604\n",
      "(Validation) Loss: 1014551.4311, MAE: 3882.0781, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [3439/5000] | Time: 0.35s\n",
      "(Training) Loss: 980590.4841\n",
      "(Validation) Loss: 1014394.1283, MAE: 3881.0051, R2: 0.1438\n",
      "==========================================================================================\n",
      "Epoch [3440/5000] | Time: 0.29s\n",
      "(Training) Loss: 971663.0649\n",
      "(Validation) Loss: 1014246.5371, MAE: 3883.2041, R2: 0.1440\n",
      "==========================================================================================\n",
      "Epoch [3441/5000] | Time: 0.32s\n",
      "(Training) Loss: 980920.2551\n",
      "(Validation) Loss: 1014085.0794, MAE: 3881.8645, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [3442/5000] | Time: 0.31s\n",
      "(Training) Loss: 975238.2893\n",
      "(Validation) Loss: 1013930.6159, MAE: 3881.2854, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [3443/5000] | Time: 0.29s\n",
      "(Training) Loss: 982174.4753\n",
      "(Validation) Loss: 1013767.0095, MAE: 3879.0342, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [3444/5000] | Time: 0.29s\n",
      "(Training) Loss: 986030.3306\n",
      "(Validation) Loss: 1013611.3575, MAE: 3879.2180, R2: 0.1445\n",
      "==========================================================================================\n",
      "Epoch [3445/5000] | Time: 0.34s\n",
      "(Training) Loss: 972693.1174\n",
      "(Validation) Loss: 1013461.6686, MAE: 3880.1226, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [3446/5000] | Time: 0.38s\n",
      "(Training) Loss: 983974.7138\n",
      "(Validation) Loss: 1013299.0070, MAE: 3878.0510, R2: 0.1447\n",
      "==========================================================================================\n",
      "Epoch [3447/5000] | Time: 0.40s\n",
      "(Training) Loss: 985523.7030\n",
      "(Validation) Loss: 1013142.4457, MAE: 3878.5813, R2: 0.1449\n",
      "==========================================================================================\n",
      "Epoch [3448/5000] | Time: 0.42s\n",
      "(Training) Loss: 1028512.7126\n",
      "(Validation) Loss: 1012988.9727, MAE: 3878.7366, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [3449/5000] | Time: 0.35s\n",
      "(Training) Loss: 981984.6053\n",
      "(Validation) Loss: 1012835.2305, MAE: 3880.1277, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [3450/5000] | Time: 0.39s\n",
      "(Training) Loss: 970487.6418\n",
      "(Validation) Loss: 1012666.1384, MAE: 3877.8152, R2: 0.1453\n",
      "==========================================================================================\n",
      "Epoch [3451/5000] | Time: 0.39s\n",
      "(Training) Loss: 995708.7735\n",
      "(Validation) Loss: 1012510.0800, MAE: 3875.4548, R2: 0.1454\n",
      "==========================================================================================\n",
      "Epoch [3452/5000] | Time: 0.38s\n",
      "(Training) Loss: 983602.6580\n",
      "(Validation) Loss: 1012352.4165, MAE: 3875.8572, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [3453/5000] | Time: 0.39s\n",
      "(Training) Loss: 980817.9721\n",
      "(Validation) Loss: 1012194.3822, MAE: 3873.4312, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [3454/5000] | Time: 0.41s\n",
      "(Training) Loss: 988626.3763\n",
      "(Validation) Loss: 1012044.6324, MAE: 3875.3438, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [3455/5000] | Time: 0.35s\n",
      "(Training) Loss: 975237.1599\n",
      "(Validation) Loss: 1011881.7879, MAE: 3874.5017, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [3456/5000] | Time: 0.42s\n",
      "(Training) Loss: 970092.7051\n",
      "(Validation) Loss: 1011725.4146, MAE: 3873.9502, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [3457/5000] | Time: 0.36s\n",
      "(Training) Loss: 978195.1409\n",
      "(Validation) Loss: 1011576.4876, MAE: 3873.5784, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [3458/5000] | Time: 0.41s\n",
      "(Training) Loss: 980111.3801\n",
      "(Validation) Loss: 1011423.1060, MAE: 3873.9849, R2: 0.1463\n",
      "==========================================================================================\n",
      "Epoch [3459/5000] | Time: 0.36s\n",
      "(Training) Loss: 980225.5799\n",
      "(Validation) Loss: 1011259.3270, MAE: 3871.6343, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [3460/5000] | Time: 0.36s\n",
      "(Training) Loss: 989008.4169\n",
      "(Validation) Loss: 1011107.5505, MAE: 3872.8977, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [3461/5000] | Time: 0.35s\n",
      "(Training) Loss: 992778.3674\n",
      "(Validation) Loss: 1010946.4279, MAE: 3869.9736, R2: 0.1467\n",
      "==========================================================================================\n",
      "Epoch [3462/5000] | Time: 0.29s\n",
      "(Training) Loss: 978479.5539\n",
      "(Validation) Loss: 1010791.6597, MAE: 3871.1926, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [3463/5000] | Time: 0.33s\n",
      "(Training) Loss: 981155.8541\n",
      "(Validation) Loss: 1010632.7568, MAE: 3870.1694, R2: 0.1470\n",
      "==========================================================================================\n",
      "Epoch [3464/5000] | Time: 0.38s\n",
      "(Training) Loss: 996384.4841\n",
      "(Validation) Loss: 1010477.9429, MAE: 3869.9468, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [3465/5000] | Time: 0.45s\n",
      "(Training) Loss: 982801.3464\n",
      "(Validation) Loss: 1010318.8622, MAE: 3869.6152, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [3466/5000] | Time: 0.34s\n",
      "(Training) Loss: 972407.1047\n",
      "(Validation) Loss: 1010163.6876, MAE: 3868.6187, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [3467/5000] | Time: 0.32s\n",
      "(Training) Loss: 967904.1025\n",
      "(Validation) Loss: 1010005.9378, MAE: 3866.4031, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [3468/5000] | Time: 0.30s\n",
      "(Training) Loss: 975644.1770\n",
      "(Validation) Loss: 1009853.5162, MAE: 3865.6201, R2: 0.1476\n",
      "==========================================================================================\n",
      "Epoch [3469/5000] | Time: 0.40s\n",
      "(Training) Loss: 975142.7189\n",
      "(Validation) Loss: 1009690.3771, MAE: 3864.1836, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [3470/5000] | Time: 0.48s\n",
      "(Training) Loss: 967455.5676\n",
      "(Validation) Loss: 1009538.1333, MAE: 3863.8225, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [3471/5000] | Time: 0.47s\n",
      "(Training) Loss: 977473.1536\n",
      "(Validation) Loss: 1009387.2254, MAE: 3864.0183, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [3472/5000] | Time: 0.36s\n",
      "(Training) Loss: 970461.9841\n",
      "(Validation) Loss: 1009231.9390, MAE: 3863.9290, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [3473/5000] | Time: 0.27s\n",
      "(Training) Loss: 975031.4048\n",
      "(Validation) Loss: 1009041.5492, MAE: 3867.5483, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [3474/5000] | Time: 0.27s\n",
      "(Training) Loss: 988094.9061\n",
      "(Validation) Loss: 1008828.5308, MAE: 3857.3015, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [3475/5000] | Time: 0.30s\n",
      "(Training) Loss: 980600.5343\n",
      "(Validation) Loss: 1008689.5289, MAE: 3860.4968, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [3476/5000] | Time: 0.26s\n",
      "(Training) Loss: 995696.0441\n",
      "(Validation) Loss: 1008539.9263, MAE: 3861.9463, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [3477/5000] | Time: 0.23s\n",
      "(Training) Loss: 993643.0733\n",
      "(Validation) Loss: 1008410.3314, MAE: 3867.5244, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [3478/5000] | Time: 0.23s\n",
      "(Training) Loss: 974986.0996\n",
      "(Validation) Loss: 1008204.9168, MAE: 3855.6335, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [3479/5000] | Time: 0.26s\n",
      "(Training) Loss: 994487.4302\n",
      "(Validation) Loss: 1008046.1511, MAE: 3854.4629, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [3480/5000] | Time: 0.21s\n",
      "(Training) Loss: 969608.7138\n",
      "(Validation) Loss: 1007890.3060, MAE: 3853.5127, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [3481/5000] | Time: 0.21s\n",
      "(Training) Loss: 992952.5165\n",
      "(Validation) Loss: 1007738.7683, MAE: 3854.1582, R2: 0.1494\n",
      "==========================================================================================\n",
      "Epoch [3482/5000] | Time: 0.23s\n",
      "(Training) Loss: 986937.8065\n",
      "(Validation) Loss: 1007577.9302, MAE: 3852.3982, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [3483/5000] | Time: 0.21s\n",
      "(Training) Loss: 968329.9927\n",
      "(Validation) Loss: 1007423.3905, MAE: 3852.4214, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [3484/5000] | Time: 0.34s\n",
      "(Training) Loss: 971144.9029\n",
      "(Validation) Loss: 1007298.6210, MAE: 3859.8606, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [3485/5000] | Time: 0.32s\n",
      "(Training) Loss: 968178.2881\n",
      "(Validation) Loss: 1007122.6311, MAE: 3853.5532, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [3486/5000] | Time: 0.25s\n",
      "(Training) Loss: 983850.0470\n",
      "(Validation) Loss: 1006957.1302, MAE: 3849.0361, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [3487/5000] | Time: 0.25s\n",
      "(Training) Loss: 971207.8043\n",
      "(Validation) Loss: 1006801.0311, MAE: 3849.9385, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [3488/5000] | Time: 0.22s\n",
      "(Training) Loss: 966554.6390\n",
      "(Validation) Loss: 1006644.1041, MAE: 3848.1265, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [3489/5000] | Time: 0.24s\n",
      "(Training) Loss: 976928.5857\n",
      "(Validation) Loss: 1006497.6305, MAE: 3849.1396, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [3490/5000] | Time: 0.22s\n",
      "(Training) Loss: 972272.6491\n",
      "(Validation) Loss: 1006430.5371, MAE: 3854.4902, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [3491/5000] | Time: 0.25s\n",
      "(Training) Loss: 981223.8331\n",
      "(Validation) Loss: 1006279.7003, MAE: 3855.0562, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [3492/5000] | Time: 0.25s\n",
      "(Training) Loss: 980334.7627\n",
      "(Validation) Loss: 1006123.7181, MAE: 3854.3079, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [3493/5000] | Time: 0.29s\n",
      "(Training) Loss: 984899.3579\n",
      "(Validation) Loss: 1005961.7625, MAE: 3852.3721, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [3494/5000] | Time: 0.24s\n",
      "(Training) Loss: 968892.9873\n",
      "(Validation) Loss: 1005806.4102, MAE: 3850.9778, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [3495/5000] | Time: 0.26s\n",
      "(Training) Loss: 986311.7081\n",
      "(Validation) Loss: 1005650.4737, MAE: 3850.7703, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [3496/5000] | Time: 0.26s\n",
      "(Training) Loss: 970871.7335\n",
      "(Validation) Loss: 1005497.1225, MAE: 3852.1313, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [3497/5000] | Time: 0.24s\n",
      "(Training) Loss: 981655.2348\n",
      "(Validation) Loss: 1005343.0502, MAE: 3850.2896, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [3498/5000] | Time: 0.29s\n",
      "(Training) Loss: 987963.2354\n",
      "(Validation) Loss: 1005197.2876, MAE: 3853.6069, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [3499/5000] | Time: 0.22s\n",
      "(Training) Loss: 978539.9467\n",
      "(Validation) Loss: 1005031.1975, MAE: 3851.1123, R2: 0.1516\n",
      "==========================================================================================\n",
      "Epoch [3500/5000] | Time: 0.20s\n",
      "(Training) Loss: 976061.7722\n",
      "(Validation) Loss: 1004876.4394, MAE: 3851.3965, R2: 0.1518\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch3500.pth\n",
      "==========================================================================================\n",
      "Epoch [3501/5000] | Time: 0.24s\n",
      "(Training) Loss: 967989.8204\n",
      "(Validation) Loss: 1004720.8533, MAE: 3849.6772, R2: 0.1519\n",
      "==========================================================================================\n",
      "Epoch [3502/5000] | Time: 0.24s\n",
      "(Training) Loss: 985254.8680\n",
      "(Validation) Loss: 1004563.9568, MAE: 3848.3354, R2: 0.1520\n",
      "==========================================================================================\n",
      "Epoch [3503/5000] | Time: 0.23s\n",
      "(Training) Loss: 972290.8334\n",
      "(Validation) Loss: 1004406.0292, MAE: 3847.5720, R2: 0.1522\n",
      "==========================================================================================\n",
      "Epoch [3504/5000] | Time: 0.32s\n",
      "(Training) Loss: 983413.3579\n",
      "(Validation) Loss: 1004256.4470, MAE: 3848.8845, R2: 0.1523\n",
      "==========================================================================================\n",
      "Epoch [3505/5000] | Time: 0.31s\n",
      "(Training) Loss: 964532.9353\n",
      "(Validation) Loss: 1004096.4216, MAE: 3846.2937, R2: 0.1524\n",
      "==========================================================================================\n",
      "Epoch [3506/5000] | Time: 0.26s\n",
      "(Training) Loss: 962688.8144\n",
      "(Validation) Loss: 1003953.4781, MAE: 3849.6755, R2: 0.1525\n",
      "==========================================================================================\n",
      "Epoch [3507/5000] | Time: 0.26s\n",
      "(Training) Loss: 974787.5546\n",
      "(Validation) Loss: 1003797.8768, MAE: 3849.6069, R2: 0.1527\n",
      "==========================================================================================\n",
      "Epoch [3508/5000] | Time: 0.26s\n",
      "(Training) Loss: 987021.4232\n",
      "(Validation) Loss: 1025359.4108, MAE: 3935.9585, R2: 0.1347\n",
      "==========================================================================================\n",
      "Epoch [3509/5000] | Time: 0.30s\n",
      "(Training) Loss: 997651.5872\n",
      "(Validation) Loss: 1025108.6629, MAE: 3917.9062, R2: 0.1349\n",
      "==========================================================================================\n",
      "Epoch [3510/5000] | Time: 0.30s\n",
      "(Training) Loss: 985187.1732\n",
      "(Validation) Loss: 1024968.0610, MAE: 3922.5051, R2: 0.1350\n",
      "==========================================================================================\n",
      "Epoch [3511/5000] | Time: 0.32s\n",
      "(Training) Loss: 992403.7418\n",
      "(Validation) Loss: 1024780.0076, MAE: 3916.1609, R2: 0.1352\n",
      "==========================================================================================\n",
      "Epoch [3512/5000] | Time: 0.27s\n",
      "(Training) Loss: 980968.7787\n",
      "(Validation) Loss: 1024615.1467, MAE: 3915.2769, R2: 0.1353\n",
      "==========================================================================================\n",
      "Epoch [3513/5000] | Time: 0.32s\n",
      "(Training) Loss: 1004139.9632\n",
      "(Validation) Loss: 1046589.3486, MAE: 3987.4133, R2: 0.1170\n",
      "==========================================================================================\n",
      "Epoch [3514/5000] | Time: 0.28s\n",
      "(Training) Loss: 1015424.1885\n",
      "(Validation) Loss: 1046493.1606, MAE: 4003.7651, R2: 0.1171\n",
      "==========================================================================================\n",
      "Epoch [3515/5000] | Time: 0.30s\n",
      "(Training) Loss: 1012810.9055\n",
      "(Validation) Loss: 1046256.6806, MAE: 3986.7507, R2: 0.1173\n",
      "==========================================================================================\n",
      "Epoch [3516/5000] | Time: 0.23s\n",
      "(Training) Loss: 1037628.1599\n",
      "(Validation) Loss: 1046085.9479, MAE: 3986.5225, R2: 0.1174\n",
      "==========================================================================================\n",
      "Epoch [3517/5000] | Time: 0.26s\n",
      "(Training) Loss: 1029278.5730\n",
      "(Validation) Loss: 1045918.0140, MAE: 3985.1841, R2: 0.1176\n",
      "==========================================================================================\n",
      "Epoch [3518/5000] | Time: 0.32s\n",
      "(Training) Loss: 1031754.5013\n",
      "(Validation) Loss: 1045761.2190, MAE: 3988.7856, R2: 0.1177\n",
      "==========================================================================================\n",
      "Epoch [3519/5000] | Time: 0.29s\n",
      "(Training) Loss: 1025854.5393\n",
      "(Validation) Loss: 1045574.7149, MAE: 3982.6060, R2: 0.1179\n",
      "==========================================================================================\n",
      "Epoch [3520/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006301.6916\n",
      "(Validation) Loss: 1045407.8984, MAE: 3982.4365, R2: 0.1180\n",
      "==========================================================================================\n",
      "Epoch [3521/5000] | Time: 0.29s\n",
      "(Training) Loss: 1006023.6377\n",
      "(Validation) Loss: 1064117.7397, MAE: 4064.4517, R2: 0.1024\n",
      "==========================================================================================\n",
      "Epoch [3522/5000] | Time: 0.29s\n",
      "(Training) Loss: 1036789.7614\n",
      "(Validation) Loss: 1052557.4197, MAE: 4011.4177, R2: 0.1120\n",
      "==========================================================================================\n",
      "Epoch [3523/5000] | Time: 0.32s\n",
      "(Training) Loss: 1027401.7018\n",
      "(Validation) Loss: 1052383.8781, MAE: 4009.1562, R2: 0.1122\n",
      "==========================================================================================\n",
      "Epoch [3524/5000] | Time: 0.34s\n",
      "(Training) Loss: 1027536.5476\n",
      "(Validation) Loss: 1052220.0381, MAE: 4008.6155, R2: 0.1123\n",
      "==========================================================================================\n",
      "Epoch [3525/5000] | Time: 0.32s\n",
      "(Training) Loss: 1016584.6677\n",
      "(Validation) Loss: 1052050.9613, MAE: 4007.2146, R2: 0.1125\n",
      "==========================================================================================\n",
      "Epoch [3526/5000] | Time: 0.30s\n",
      "(Training) Loss: 1017644.8039\n",
      "(Validation) Loss: 1051891.6978, MAE: 4008.1279, R2: 0.1126\n",
      "==========================================================================================\n",
      "Epoch [3527/5000] | Time: 0.27s\n",
      "(Training) Loss: 1029344.3312\n",
      "(Validation) Loss: 1051725.7143, MAE: 4006.8445, R2: 0.1127\n",
      "==========================================================================================\n",
      "Epoch [3528/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008563.2766\n",
      "(Validation) Loss: 1051567.1010, MAE: 4006.2778, R2: 0.1129\n",
      "==========================================================================================\n",
      "Epoch [3529/5000] | Time: 0.27s\n",
      "(Training) Loss: 1005627.8650\n",
      "(Validation) Loss: 1051399.0451, MAE: 4005.4883, R2: 0.1130\n",
      "==========================================================================================\n",
      "Epoch [3530/5000] | Time: 0.41s\n",
      "(Training) Loss: 1027399.4448\n",
      "(Validation) Loss: 1051247.4565, MAE: 4007.5405, R2: 0.1131\n",
      "==========================================================================================\n",
      "Epoch [3531/5000] | Time: 0.29s\n",
      "(Training) Loss: 1015536.0647\n",
      "(Validation) Loss: 1051078.8876, MAE: 4005.7039, R2: 0.1133\n",
      "==========================================================================================\n",
      "Epoch [3532/5000] | Time: 0.28s\n",
      "(Training) Loss: 1013815.9442\n",
      "(Validation) Loss: 1050914.1130, MAE: 4004.4006, R2: 0.1134\n",
      "==========================================================================================\n",
      "Epoch [3533/5000] | Time: 0.27s\n",
      "(Training) Loss: 1010160.9404\n",
      "(Validation) Loss: 1050753.6203, MAE: 4004.0032, R2: 0.1135\n",
      "==========================================================================================\n",
      "Epoch [3534/5000] | Time: 0.30s\n",
      "(Training) Loss: 1026186.9594\n",
      "(Validation) Loss: 1050589.7397, MAE: 4002.7886, R2: 0.1137\n",
      "==========================================================================================\n",
      "Epoch [3535/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016714.8414\n",
      "(Validation) Loss: 1050427.3727, MAE: 4002.4216, R2: 0.1138\n",
      "==========================================================================================\n",
      "Epoch [3536/5000] | Time: 0.29s\n",
      "(Training) Loss: 1024656.0203\n",
      "(Validation) Loss: 1050265.2952, MAE: 4001.6646, R2: 0.1139\n",
      "==========================================================================================\n",
      "Epoch [3537/5000] | Time: 0.27s\n",
      "(Training) Loss: 1032821.4543\n",
      "(Validation) Loss: 1050103.2279, MAE: 4001.1003, R2: 0.1141\n",
      "==========================================================================================\n",
      "Epoch [3538/5000] | Time: 0.26s\n",
      "(Training) Loss: 1022392.8433\n",
      "(Validation) Loss: 1049942.7657, MAE: 4000.9778, R2: 0.1142\n",
      "==========================================================================================\n",
      "Epoch [3539/5000] | Time: 0.29s\n",
      "(Training) Loss: 1019831.1332\n",
      "(Validation) Loss: 1049774.5067, MAE: 3999.5657, R2: 0.1144\n",
      "==========================================================================================\n",
      "Epoch [3540/5000] | Time: 0.26s\n",
      "(Training) Loss: 1010224.5857\n",
      "(Validation) Loss: 1049611.0883, MAE: 3997.9792, R2: 0.1145\n",
      "==========================================================================================\n",
      "Epoch [3541/5000] | Time: 0.42s\n",
      "(Training) Loss: 1043637.4575\n",
      "(Validation) Loss: 1049455.5835, MAE: 3999.4407, R2: 0.1146\n",
      "==========================================================================================\n",
      "Epoch [3542/5000] | Time: 0.26s\n",
      "(Training) Loss: 1014710.9702\n",
      "(Validation) Loss: 1049291.7232, MAE: 3997.6296, R2: 0.1148\n",
      "==========================================================================================\n",
      "Epoch [3543/5000] | Time: 0.28s\n",
      "(Training) Loss: 1005335.9622\n",
      "(Validation) Loss: 1049129.3917, MAE: 3997.5605, R2: 0.1149\n",
      "==========================================================================================\n",
      "Epoch [3544/5000] | Time: 0.33s\n",
      "(Training) Loss: 1020629.1523\n",
      "(Validation) Loss: 1048970.3162, MAE: 3996.4133, R2: 0.1150\n",
      "==========================================================================================\n",
      "Epoch [3545/5000] | Time: 0.35s\n",
      "(Training) Loss: 1038907.2322\n",
      "(Validation) Loss: 1048807.6292, MAE: 3995.7305, R2: 0.1152\n",
      "==========================================================================================\n",
      "Epoch [3546/5000] | Time: 0.33s\n",
      "(Training) Loss: 1024882.8439\n",
      "(Validation) Loss: 1048641.9606, MAE: 3994.0208, R2: 0.1153\n",
      "==========================================================================================\n",
      "Epoch [3547/5000] | Time: 0.24s\n",
      "(Training) Loss: 1015325.8794\n",
      "(Validation) Loss: 1048487.5733, MAE: 3995.9683, R2: 0.1154\n",
      "==========================================================================================\n",
      "Epoch [3548/5000] | Time: 0.24s\n",
      "(Training) Loss: 1011195.7532\n",
      "(Validation) Loss: 1048321.3206, MAE: 3993.8872, R2: 0.1156\n",
      "==========================================================================================\n",
      "Epoch [3549/5000] | Time: 0.25s\n",
      "(Training) Loss: 1022510.9181\n",
      "(Validation) Loss: 1048162.2197, MAE: 3993.5024, R2: 0.1157\n",
      "==========================================================================================\n",
      "Epoch [3550/5000] | Time: 0.23s\n",
      "(Training) Loss: 1026324.3363\n",
      "(Validation) Loss: 1048015.2025, MAE: 3998.7576, R2: 0.1158\n",
      "==========================================================================================\n",
      "Epoch [3551/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023662.6098\n",
      "(Validation) Loss: 1047849.8083, MAE: 3995.2476, R2: 0.1160\n",
      "==========================================================================================\n",
      "Epoch [3552/5000] | Time: 0.27s\n",
      "(Training) Loss: 1002031.6928\n",
      "(Validation) Loss: 1047705.7016, MAE: 3993.5508, R2: 0.1161\n",
      "==========================================================================================\n",
      "Epoch [3553/5000] | Time: 0.24s\n",
      "(Training) Loss: 1001841.3134\n",
      "(Validation) Loss: 1047543.2940, MAE: 3991.5679, R2: 0.1162\n",
      "==========================================================================================\n",
      "Epoch [3554/5000] | Time: 0.27s\n",
      "(Training) Loss: 1027390.7735\n",
      "(Validation) Loss: 1047387.7892, MAE: 3991.8608, R2: 0.1163\n",
      "==========================================================================================\n",
      "Epoch [3555/5000] | Time: 0.26s\n",
      "(Training) Loss: 1010474.1244\n",
      "(Validation) Loss: 1047239.4768, MAE: 3995.7888, R2: 0.1165\n",
      "==========================================================================================\n",
      "Epoch [3556/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014516.9010\n",
      "(Validation) Loss: 1047072.5029, MAE: 3992.5667, R2: 0.1166\n",
      "==========================================================================================\n",
      "Epoch [3557/5000] | Time: 0.23s\n",
      "(Training) Loss: 1013693.3642\n",
      "(Validation) Loss: 1046913.7981, MAE: 3992.1218, R2: 0.1167\n",
      "==========================================================================================\n",
      "Epoch [3558/5000] | Time: 0.29s\n",
      "(Training) Loss: 1026473.1161\n",
      "(Validation) Loss: 1046748.9168, MAE: 3990.2869, R2: 0.1169\n",
      "==========================================================================================\n",
      "Epoch [3559/5000] | Time: 0.27s\n",
      "(Training) Loss: 1003621.6123\n",
      "(Validation) Loss: 1046587.2610, MAE: 3989.5342, R2: 0.1170\n",
      "==========================================================================================\n",
      "Epoch [3560/5000] | Time: 0.27s\n",
      "(Training) Loss: 1030332.8363\n",
      "(Validation) Loss: 1046445.3181, MAE: 3992.3069, R2: 0.1171\n",
      "==========================================================================================\n",
      "Epoch [3561/5000] | Time: 0.37s\n",
      "(Training) Loss: 1038056.1447\n",
      "(Validation) Loss: 1046268.2057, MAE: 3988.2661, R2: 0.1173\n",
      "==========================================================================================\n",
      "Epoch [3562/5000] | Time: 0.32s\n",
      "(Training) Loss: 1012031.6352\n",
      "(Validation) Loss: 1046102.8876, MAE: 3987.6006, R2: 0.1174\n",
      "==========================================================================================\n",
      "Epoch [3563/5000] | Time: 0.38s\n",
      "(Training) Loss: 1019259.7703\n",
      "(Validation) Loss: 1045958.0241, MAE: 3991.0828, R2: 0.1175\n",
      "==========================================================================================\n",
      "Epoch [3564/5000] | Time: 0.30s\n",
      "(Training) Loss: 1020130.9327\n",
      "(Validation) Loss: 1045787.5708, MAE: 3987.7725, R2: 0.1177\n",
      "==========================================================================================\n",
      "Epoch [3565/5000] | Time: 0.30s\n",
      "(Training) Loss: 1020448.5958\n",
      "(Validation) Loss: 1045623.0756, MAE: 3985.7759, R2: 0.1178\n",
      "==========================================================================================\n",
      "Epoch [3566/5000] | Time: 0.31s\n",
      "(Training) Loss: 1023903.8528\n",
      "(Validation) Loss: 1045469.0387, MAE: 3987.1763, R2: 0.1179\n",
      "==========================================================================================\n",
      "Epoch [3567/5000] | Time: 0.31s\n",
      "(Training) Loss: 1017549.5685\n",
      "(Validation) Loss: 1045308.9930, MAE: 3986.8582, R2: 0.1181\n",
      "==========================================================================================\n",
      "Epoch [3568/5000] | Time: 0.28s\n",
      "(Training) Loss: 1005830.6415\n",
      "(Validation) Loss: 1045143.2330, MAE: 3984.7593, R2: 0.1182\n",
      "==========================================================================================\n",
      "Epoch [3569/5000] | Time: 0.30s\n",
      "(Training) Loss: 1021197.5533\n",
      "(Validation) Loss: 1044987.8705, MAE: 3984.3894, R2: 0.1183\n",
      "==========================================================================================\n",
      "Epoch [3570/5000] | Time: 0.27s\n",
      "(Training) Loss: 1017995.1891\n",
      "(Validation) Loss: 1044824.2895, MAE: 3982.5886, R2: 0.1185\n",
      "==========================================================================================\n",
      "Epoch [3571/5000] | Time: 0.32s\n",
      "(Training) Loss: 1003087.2652\n",
      "(Validation) Loss: 1044691.8451, MAE: 3989.6279, R2: 0.1186\n",
      "==========================================================================================\n",
      "Epoch [3572/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008511.8534\n",
      "(Validation) Loss: 1044509.8667, MAE: 3982.4629, R2: 0.1187\n",
      "==========================================================================================\n",
      "Epoch [3573/5000] | Time: 0.28s\n",
      "(Training) Loss: 1010172.9518\n",
      "(Validation) Loss: 1044346.4483, MAE: 3980.9631, R2: 0.1189\n",
      "==========================================================================================\n",
      "Epoch [3574/5000] | Time: 0.25s\n",
      "(Training) Loss: 1008256.7951\n",
      "(Validation) Loss: 1044188.7340, MAE: 3980.7524, R2: 0.1190\n",
      "==========================================================================================\n",
      "Epoch [3575/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002865.8325\n",
      "(Validation) Loss: 1044027.8044, MAE: 3979.4263, R2: 0.1191\n",
      "==========================================================================================\n",
      "Epoch [3576/5000] | Time: 0.24s\n",
      "(Training) Loss: 1038720.9467\n",
      "(Validation) Loss: 1043882.9308, MAE: 3982.7578, R2: 0.1193\n",
      "==========================================================================================\n",
      "Epoch [3577/5000] | Time: 0.25s\n",
      "(Training) Loss: 1044269.5057\n",
      "(Validation) Loss: 1043719.3041, MAE: 3982.3298, R2: 0.1194\n",
      "==========================================================================================\n",
      "Epoch [3578/5000] | Time: 0.21s\n",
      "(Training) Loss: 1014197.4150\n",
      "(Validation) Loss: 1043547.5251, MAE: 3979.1523, R2: 0.1195\n",
      "==========================================================================================\n",
      "Epoch [3579/5000] | Time: 0.21s\n",
      "(Training) Loss: 997948.6713\n",
      "(Validation) Loss: 1043387.3168, MAE: 3977.4670, R2: 0.1197\n",
      "==========================================================================================\n",
      "Epoch [3580/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010987.0622\n",
      "(Validation) Loss: 1043235.7689, MAE: 3978.1616, R2: 0.1198\n",
      "==========================================================================================\n",
      "Epoch [3581/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011017.1624\n",
      "(Validation) Loss: 1043071.6089, MAE: 3976.0139, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [3582/5000] | Time: 0.25s\n",
      "(Training) Loss: 1026097.2246\n",
      "(Validation) Loss: 1042915.7435, MAE: 3976.3479, R2: 0.1201\n",
      "==========================================================================================\n",
      "Epoch [3583/5000] | Time: 0.24s\n",
      "(Training) Loss: 1014439.7538\n",
      "(Validation) Loss: 1042754.6159, MAE: 3975.2737, R2: 0.1202\n",
      "==========================================================================================\n",
      "Epoch [3584/5000] | Time: 0.26s\n",
      "(Training) Loss: 1011519.2227\n",
      "(Validation) Loss: 1042594.3314, MAE: 3974.6619, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [3585/5000] | Time: 0.25s\n",
      "(Training) Loss: 1029054.5685\n",
      "(Validation) Loss: 1042449.8997, MAE: 3977.0479, R2: 0.1205\n",
      "==========================================================================================\n",
      "Epoch [3586/5000] | Time: 0.27s\n",
      "(Training) Loss: 1023879.4987\n",
      "(Validation) Loss: 1042287.3498, MAE: 3976.8816, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [3587/5000] | Time: 0.27s\n",
      "(Training) Loss: 1001057.0412\n",
      "(Validation) Loss: 1042118.9994, MAE: 3974.4944, R2: 0.1207\n",
      "==========================================================================================\n",
      "Epoch [3588/5000] | Time: 0.27s\n",
      "(Training) Loss: 998633.2046\n",
      "(Validation) Loss: 1041964.4495, MAE: 3974.3584, R2: 0.1209\n",
      "==========================================================================================\n",
      "Epoch [3589/5000] | Time: 0.29s\n",
      "(Training) Loss: 996550.3646\n",
      "(Validation) Loss: 1041801.1835, MAE: 3971.0361, R2: 0.1210\n",
      "==========================================================================================\n",
      "Epoch [3590/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003327.0660\n",
      "(Validation) Loss: 1041646.3238, MAE: 3970.6584, R2: 0.1211\n",
      "==========================================================================================\n",
      "Epoch [3591/5000] | Time: 0.29s\n",
      "(Training) Loss: 1015375.9835\n",
      "(Validation) Loss: 1041490.7886, MAE: 3970.8655, R2: 0.1213\n",
      "==========================================================================================\n",
      "Epoch [3592/5000] | Time: 0.33s\n",
      "(Training) Loss: 1007285.7532\n",
      "(Validation) Loss: 1041332.3225, MAE: 3971.1667, R2: 0.1214\n",
      "==========================================================================================\n",
      "Epoch [3593/5000] | Time: 0.30s\n",
      "(Training) Loss: 1027147.2671\n",
      "(Validation) Loss: 1041178.2095, MAE: 3971.0500, R2: 0.1215\n",
      "==========================================================================================\n",
      "Epoch [3594/5000] | Time: 0.22s\n",
      "(Training) Loss: 1005782.6174\n",
      "(Validation) Loss: 1041017.0971, MAE: 3970.5942, R2: 0.1217\n",
      "==========================================================================================\n",
      "Epoch [3595/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007926.1812\n",
      "(Validation) Loss: 1040855.2990, MAE: 3967.9443, R2: 0.1218\n",
      "==========================================================================================\n",
      "Epoch [3596/5000] | Time: 0.21s\n",
      "(Training) Loss: 1005301.6294\n",
      "(Validation) Loss: 1040700.8762, MAE: 3969.2283, R2: 0.1219\n",
      "==========================================================================================\n",
      "Epoch [3597/5000] | Time: 0.21s\n",
      "(Training) Loss: 1009752.6110\n",
      "(Validation) Loss: 1040538.8444, MAE: 3967.4490, R2: 0.1221\n",
      "==========================================================================================\n",
      "Epoch [3598/5000] | Time: 0.21s\n",
      "(Training) Loss: 1012496.3439\n",
      "(Validation) Loss: 1040382.2832, MAE: 3966.2166, R2: 0.1222\n",
      "==========================================================================================\n",
      "Epoch [3599/5000] | Time: 0.29s\n",
      "(Training) Loss: 1014874.7906\n",
      "(Validation) Loss: 1040226.3721, MAE: 3966.9463, R2: 0.1223\n",
      "==========================================================================================\n",
      "Epoch [3600/5000] | Time: 0.29s\n",
      "(Training) Loss: 998035.9086\n",
      "(Validation) Loss: 1040068.8457, MAE: 3967.1733, R2: 0.1224\n",
      "==========================================================================================\n",
      "Epoch [3601/5000] | Time: 0.22s\n",
      "(Training) Loss: 1027806.3782\n",
      "(Validation) Loss: 1039908.8711, MAE: 3965.0303, R2: 0.1226\n",
      "==========================================================================================\n",
      "Epoch [3602/5000] | Time: 0.27s\n",
      "(Training) Loss: 1009677.4949\n",
      "(Validation) Loss: 1039754.1841, MAE: 3966.8005, R2: 0.1227\n",
      "==========================================================================================\n",
      "Epoch [3603/5000] | Time: 0.31s\n",
      "(Training) Loss: 1017541.4340\n",
      "(Validation) Loss: 1039590.7911, MAE: 3965.0239, R2: 0.1228\n",
      "==========================================================================================\n",
      "Epoch [3604/5000] | Time: 0.24s\n",
      "(Training) Loss: 1007819.0628\n",
      "(Validation) Loss: 1039433.8590, MAE: 3964.7419, R2: 0.1230\n",
      "==========================================================================================\n",
      "Epoch [3605/5000] | Time: 0.21s\n",
      "(Training) Loss: 1003356.3261\n",
      "(Validation) Loss: 1039275.5048, MAE: 3964.3274, R2: 0.1231\n",
      "==========================================================================================\n",
      "Epoch [3606/5000] | Time: 0.34s\n",
      "(Training) Loss: 993261.8194\n",
      "(Validation) Loss: 1036299.3727, MAE: 3951.9976, R2: 0.1256\n",
      "==========================================================================================\n",
      "Epoch [3607/5000] | Time: 0.26s\n",
      "(Training) Loss: 1014373.8287\n",
      "(Validation) Loss: 1036065.9708, MAE: 3946.0923, R2: 0.1258\n",
      "==========================================================================================\n",
      "Epoch [3608/5000] | Time: 0.23s\n",
      "(Training) Loss: 992952.6602\n",
      "(Validation) Loss: 1035904.8940, MAE: 3945.1882, R2: 0.1259\n",
      "==========================================================================================\n",
      "Epoch [3609/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000932.7640\n",
      "(Validation) Loss: 1035775.4159, MAE: 3949.0493, R2: 0.1260\n",
      "==========================================================================================\n",
      "Epoch [3610/5000] | Time: 0.30s\n",
      "(Training) Loss: 994546.0485\n",
      "(Validation) Loss: 1035681.0210, MAE: 3953.3213, R2: 0.1261\n",
      "==========================================================================================\n",
      "Epoch [3611/5000] | Time: 0.23s\n",
      "(Training) Loss: 994901.1003\n",
      "(Validation) Loss: 1035519.9187, MAE: 3949.9421, R2: 0.1262\n",
      "==========================================================================================\n",
      "Epoch [3612/5000] | Time: 0.20s\n",
      "(Training) Loss: 1027496.7608\n",
      "(Validation) Loss: 1054940.9727, MAE: 4037.6895, R2: 0.1100\n",
      "==========================================================================================\n",
      "Epoch [3613/5000] | Time: 0.20s\n",
      "(Training) Loss: 1016383.5977\n",
      "(Validation) Loss: 1049162.0165, MAE: 4013.3687, R2: 0.1149\n",
      "==========================================================================================\n",
      "Epoch [3614/5000] | Time: 0.21s\n",
      "(Training) Loss: 1013227.3280\n",
      "(Validation) Loss: 1048978.1130, MAE: 4006.3555, R2: 0.1150\n",
      "==========================================================================================\n",
      "Epoch [3615/5000] | Time: 0.28s\n",
      "(Training) Loss: 1033603.2786\n",
      "(Validation) Loss: 1048814.5879, MAE: 4004.6440, R2: 0.1152\n",
      "==========================================================================================\n",
      "Epoch [3616/5000] | Time: 0.21s\n",
      "(Training) Loss: 1003531.0368\n",
      "(Validation) Loss: 1037127.7359, MAE: 3961.9897, R2: 0.1249\n",
      "==========================================================================================\n",
      "Epoch [3617/5000] | Time: 0.22s\n",
      "(Training) Loss: 1018619.6288\n",
      "(Validation) Loss: 1036911.0857, MAE: 3960.2378, R2: 0.1251\n",
      "==========================================================================================\n",
      "Epoch [3618/5000] | Time: 0.27s\n",
      "(Training) Loss: 1001152.7652\n",
      "(Validation) Loss: 1036724.7848, MAE: 3955.0447, R2: 0.1252\n",
      "==========================================================================================\n",
      "Epoch [3619/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004636.1218\n",
      "(Validation) Loss: 1036542.0749, MAE: 3948.6479, R2: 0.1254\n",
      "==========================================================================================\n",
      "Epoch [3620/5000] | Time: 0.22s\n",
      "(Training) Loss: 1006281.8528\n",
      "(Validation) Loss: 1036383.0095, MAE: 3948.3696, R2: 0.1255\n",
      "==========================================================================================\n",
      "Epoch [3621/5000] | Time: 0.21s\n",
      "(Training) Loss: 1008793.4201\n",
      "(Validation) Loss: 1036235.4184, MAE: 3951.3264, R2: 0.1256\n",
      "==========================================================================================\n",
      "Epoch [3622/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005303.2411\n",
      "(Validation) Loss: 1036084.6476, MAE: 3953.1694, R2: 0.1258\n",
      "==========================================================================================\n",
      "Epoch [3623/5000] | Time: 0.21s\n",
      "(Training) Loss: 1032695.5787\n",
      "(Validation) Loss: 1035900.6476, MAE: 3945.4377, R2: 0.1259\n",
      "==========================================================================================\n",
      "Epoch [3624/5000] | Time: 0.21s\n",
      "(Training) Loss: 1011307.9074\n",
      "(Validation) Loss: 1035789.5517, MAE: 3955.2756, R2: 0.1260\n",
      "==========================================================================================\n",
      "Epoch [3625/5000] | Time: 0.25s\n",
      "(Training) Loss: 995798.3109\n",
      "(Validation) Loss: 1035589.5111, MAE: 3947.0488, R2: 0.1262\n",
      "==========================================================================================\n",
      "Epoch [3626/5000] | Time: 0.35s\n",
      "(Training) Loss: 1035101.2107\n",
      "(Validation) Loss: 1035424.7467, MAE: 3943.1682, R2: 0.1263\n",
      "==========================================================================================\n",
      "Epoch [3627/5000] | Time: 0.28s\n",
      "(Training) Loss: 999826.4613\n",
      "(Validation) Loss: 1035260.7086, MAE: 3942.0906, R2: 0.1265\n",
      "==========================================================================================\n",
      "Epoch [3628/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005602.4492\n",
      "(Validation) Loss: 1035106.8952, MAE: 3942.4758, R2: 0.1266\n",
      "==========================================================================================\n",
      "Epoch [3629/5000] | Time: 0.31s\n",
      "(Training) Loss: 1000737.4721\n",
      "(Validation) Loss: 1034957.7397, MAE: 3944.2869, R2: 0.1267\n",
      "==========================================================================================\n",
      "Epoch [3630/5000] | Time: 0.33s\n",
      "(Training) Loss: 998901.0063\n",
      "(Validation) Loss: 1034863.7562, MAE: 3946.4644, R2: 0.1268\n",
      "==========================================================================================\n",
      "Epoch [3631/5000] | Time: 0.31s\n",
      "(Training) Loss: 994628.3560\n",
      "(Validation) Loss: 1034717.2876, MAE: 3949.2100, R2: 0.1269\n",
      "==========================================================================================\n",
      "Epoch [3632/5000] | Time: 0.25s\n",
      "(Training) Loss: 1010569.9264\n",
      "(Validation) Loss: 1034555.9365, MAE: 3946.9463, R2: 0.1270\n",
      "==========================================================================================\n",
      "Epoch [3633/5000] | Time: 0.27s\n",
      "(Training) Loss: 1008714.7126\n",
      "(Validation) Loss: 1034395.0375, MAE: 3945.4988, R2: 0.1272\n",
      "==========================================================================================\n",
      "Epoch [3634/5000] | Time: 0.21s\n",
      "(Training) Loss: 992918.6624\n",
      "(Validation) Loss: 1034229.7651, MAE: 3943.2231, R2: 0.1273\n",
      "==========================================================================================\n",
      "Epoch [3635/5000] | Time: 0.25s\n",
      "(Training) Loss: 1002945.2824\n",
      "(Validation) Loss: 1034080.9752, MAE: 3944.5024, R2: 0.1274\n",
      "==========================================================================================\n",
      "Epoch [3636/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014986.6405\n",
      "(Validation) Loss: 1033919.9949, MAE: 3943.1902, R2: 0.1276\n",
      "==========================================================================================\n",
      "Epoch [3637/5000] | Time: 0.24s\n",
      "(Training) Loss: 995588.6383\n",
      "(Validation) Loss: 1033765.1911, MAE: 3944.0801, R2: 0.1277\n",
      "==========================================================================================\n",
      "Epoch [3638/5000] | Time: 0.28s\n",
      "(Training) Loss: 996850.8236\n",
      "(Validation) Loss: 1033609.1886, MAE: 3942.7781, R2: 0.1278\n",
      "==========================================================================================\n",
      "Epoch [3639/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001036.5482\n",
      "(Validation) Loss: 1033451.9771, MAE: 3943.0405, R2: 0.1280\n",
      "==========================================================================================\n",
      "Epoch [3640/5000] | Time: 0.22s\n",
      "(Training) Loss: 996957.5425\n",
      "(Validation) Loss: 1033291.3321, MAE: 3941.4443, R2: 0.1281\n",
      "==========================================================================================\n",
      "Epoch [3641/5000] | Time: 0.26s\n",
      "(Training) Loss: 1012391.5501\n",
      "(Validation) Loss: 1033138.5752, MAE: 3941.5400, R2: 0.1282\n",
      "==========================================================================================\n",
      "Epoch [3642/5000] | Time: 0.29s\n",
      "(Training) Loss: 1004652.7132\n",
      "(Validation) Loss: 1032973.6432, MAE: 3939.7371, R2: 0.1284\n",
      "==========================================================================================\n",
      "Epoch [3643/5000] | Time: 0.21s\n",
      "(Training) Loss: 990070.7744\n",
      "(Validation) Loss: 1032816.5384, MAE: 3938.9956, R2: 0.1285\n",
      "==========================================================================================\n",
      "Epoch [3644/5000] | Time: 0.24s\n",
      "(Training) Loss: 993864.4962\n",
      "(Validation) Loss: 1032660.4902, MAE: 3939.0076, R2: 0.1286\n",
      "==========================================================================================\n",
      "Epoch [3645/5000] | Time: 0.23s\n",
      "(Training) Loss: 1017002.3680\n",
      "(Validation) Loss: 1032503.4108, MAE: 3937.5032, R2: 0.1287\n",
      "==========================================================================================\n",
      "Epoch [3646/5000] | Time: 0.23s\n",
      "(Training) Loss: 1009557.8528\n",
      "(Validation) Loss: 1032353.8489, MAE: 3940.0918, R2: 0.1289\n",
      "==========================================================================================\n",
      "Epoch [3647/5000] | Time: 0.21s\n",
      "(Training) Loss: 1000079.7303\n",
      "(Validation) Loss: 1032189.2470, MAE: 3937.9102, R2: 0.1290\n",
      "==========================================================================================\n",
      "Epoch [3648/5000] | Time: 0.20s\n",
      "(Training) Loss: 1004963.6593\n",
      "(Validation) Loss: 1032062.1765, MAE: 3945.6699, R2: 0.1291\n",
      "==========================================================================================\n",
      "Epoch [3649/5000] | Time: 0.21s\n",
      "(Training) Loss: 1002413.3636\n",
      "(Validation) Loss: 1031880.5994, MAE: 3938.2175, R2: 0.1293\n",
      "==========================================================================================\n",
      "Epoch [3650/5000] | Time: 0.26s\n",
      "(Training) Loss: 995872.3369\n",
      "(Validation) Loss: 1031730.7327, MAE: 3938.5837, R2: 0.1294\n",
      "==========================================================================================\n",
      "Epoch [3651/5000] | Time: 0.24s\n",
      "(Training) Loss: 992546.3668\n",
      "(Validation) Loss: 1031556.6121, MAE: 3933.7512, R2: 0.1295\n",
      "==========================================================================================\n",
      "Epoch [3652/5000] | Time: 0.26s\n",
      "(Training) Loss: 1009628.6085\n",
      "(Validation) Loss: 1031405.1657, MAE: 3934.3735, R2: 0.1297\n",
      "==========================================================================================\n",
      "Epoch [3653/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010391.9105\n",
      "(Validation) Loss: 1031245.2114, MAE: 3934.1816, R2: 0.1298\n",
      "==========================================================================================\n",
      "Epoch [3654/5000] | Time: 0.29s\n",
      "(Training) Loss: 991063.1117\n",
      "(Validation) Loss: 1031087.9644, MAE: 3932.9045, R2: 0.1299\n",
      "==========================================================================================\n",
      "Epoch [3655/5000] | Time: 0.24s\n",
      "(Training) Loss: 997950.7373\n",
      "(Validation) Loss: 1030932.1803, MAE: 3931.9888, R2: 0.1301\n",
      "==========================================================================================\n",
      "Epoch [3656/5000] | Time: 0.24s\n",
      "(Training) Loss: 1001860.5279\n",
      "(Validation) Loss: 1030771.5200, MAE: 3930.9236, R2: 0.1302\n",
      "==========================================================================================\n",
      "Epoch [3657/5000] | Time: 0.27s\n",
      "(Training) Loss: 1003489.5114\n",
      "(Validation) Loss: 1030631.1517, MAE: 3934.9722, R2: 0.1303\n",
      "==========================================================================================\n",
      "Epoch [3658/5000] | Time: 0.25s\n",
      "(Training) Loss: 1006890.0235\n",
      "(Validation) Loss: 1030460.6984, MAE: 3930.8965, R2: 0.1305\n",
      "==========================================================================================\n",
      "Epoch [3659/5000] | Time: 0.25s\n",
      "(Training) Loss: 987908.5457\n",
      "(Validation) Loss: 1030296.6806, MAE: 3929.3359, R2: 0.1306\n",
      "==========================================================================================\n",
      "Epoch [3660/5000] | Time: 0.22s\n",
      "(Training) Loss: 986604.8192\n",
      "(Validation) Loss: 1030173.2673, MAE: 3939.4968, R2: 0.1307\n",
      "==========================================================================================\n",
      "Epoch [3661/5000] | Time: 0.26s\n",
      "(Training) Loss: 999000.3043\n",
      "(Validation) Loss: 1029951.2432, MAE: 3928.3760, R2: 0.1309\n",
      "==========================================================================================\n",
      "Epoch [3662/5000] | Time: 0.26s\n",
      "(Training) Loss: 998656.6656\n",
      "(Validation) Loss: 1029806.5219, MAE: 3928.3157, R2: 0.1310\n",
      "==========================================================================================\n",
      "Epoch [3663/5000] | Time: 0.27s\n",
      "(Training) Loss: 985686.9866\n",
      "(Validation) Loss: 1029635.3524, MAE: 3928.0120, R2: 0.1311\n",
      "==========================================================================================\n",
      "Epoch [3664/5000] | Time: 0.22s\n",
      "(Training) Loss: 995395.7157\n",
      "(Validation) Loss: 1029479.2635, MAE: 3926.6848, R2: 0.1313\n",
      "==========================================================================================\n",
      "Epoch [3665/5000] | Time: 0.21s\n",
      "(Training) Loss: 995492.4315\n",
      "(Validation) Loss: 1029319.4311, MAE: 3925.7112, R2: 0.1314\n",
      "==========================================================================================\n",
      "Epoch [3666/5000] | Time: 0.22s\n",
      "(Training) Loss: 994001.7779\n",
      "(Validation) Loss: 1029173.6076, MAE: 3927.1448, R2: 0.1315\n",
      "==========================================================================================\n",
      "Epoch [3667/5000] | Time: 0.22s\n",
      "(Training) Loss: 997285.5435\n",
      "(Validation) Loss: 1029009.3156, MAE: 3924.8096, R2: 0.1317\n",
      "==========================================================================================\n",
      "Epoch [3668/5000] | Time: 0.21s\n",
      "(Training) Loss: 984545.8703\n",
      "(Validation) Loss: 1028844.2667, MAE: 3921.4968, R2: 0.1318\n",
      "==========================================================================================\n",
      "Epoch [3669/5000] | Time: 0.21s\n",
      "(Training) Loss: 1006146.9112\n",
      "(Validation) Loss: 1028680.7010, MAE: 3919.0596, R2: 0.1319\n",
      "==========================================================================================\n",
      "Epoch [3670/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011953.4619\n",
      "(Validation) Loss: 1028617.7524, MAE: 3925.0149, R2: 0.1320\n",
      "==========================================================================================\n",
      "Epoch [3671/5000] | Time: 0.22s\n",
      "(Training) Loss: 985140.8745\n",
      "(Validation) Loss: 1028462.2070, MAE: 3925.6492, R2: 0.1321\n",
      "==========================================================================================\n",
      "Epoch [3672/5000] | Time: 0.21s\n",
      "(Training) Loss: 1004080.8147\n",
      "(Validation) Loss: 1028298.5956, MAE: 3922.9438, R2: 0.1323\n",
      "==========================================================================================\n",
      "Epoch [3673/5000] | Time: 0.24s\n",
      "(Training) Loss: 989197.8407\n",
      "(Validation) Loss: 1028140.7390, MAE: 3921.3855, R2: 0.1324\n",
      "==========================================================================================\n",
      "Epoch [3674/5000] | Time: 0.23s\n",
      "(Training) Loss: 1028931.5596\n",
      "(Validation) Loss: 1027985.3917, MAE: 3920.9119, R2: 0.1325\n",
      "==========================================================================================\n",
      "Epoch [3675/5000] | Time: 0.22s\n",
      "(Training) Loss: 1020122.0194\n",
      "(Validation) Loss: 1027825.4629, MAE: 3920.4390, R2: 0.1326\n",
      "==========================================================================================\n",
      "Epoch [3676/5000] | Time: 0.22s\n",
      "(Training) Loss: 988415.5406\n",
      "(Validation) Loss: 1027670.8114, MAE: 3920.9143, R2: 0.1328\n",
      "==========================================================================================\n",
      "Epoch [3677/5000] | Time: 0.23s\n",
      "(Training) Loss: 999314.0692\n",
      "(Validation) Loss: 1027512.7060, MAE: 3919.8044, R2: 0.1329\n",
      "==========================================================================================\n",
      "Epoch [3678/5000] | Time: 0.26s\n",
      "(Training) Loss: 995858.8959\n",
      "(Validation) Loss: 1027354.8749, MAE: 3918.8149, R2: 0.1330\n",
      "==========================================================================================\n",
      "Epoch [3679/5000] | Time: 0.23s\n",
      "(Training) Loss: 1011150.2170\n",
      "(Validation) Loss: 1027200.7975, MAE: 3918.0710, R2: 0.1332\n",
      "==========================================================================================\n",
      "Epoch [3680/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000527.1377\n",
      "(Validation) Loss: 1027047.7816, MAE: 3918.9966, R2: 0.1333\n",
      "==========================================================================================\n",
      "Epoch [3681/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001692.4486\n",
      "(Validation) Loss: 1026888.6197, MAE: 3917.5730, R2: 0.1334\n",
      "==========================================================================================\n",
      "Epoch [3682/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004512.1168\n",
      "(Validation) Loss: 1026726.9790, MAE: 3916.1133, R2: 0.1336\n",
      "==========================================================================================\n",
      "Epoch [3683/5000] | Time: 0.24s\n",
      "(Training) Loss: 987695.7183\n",
      "(Validation) Loss: 1026571.7435, MAE: 3915.5032, R2: 0.1337\n",
      "==========================================================================================\n",
      "Epoch [3684/5000] | Time: 0.23s\n",
      "(Training) Loss: 1022728.1967\n",
      "(Validation) Loss: 1026417.6660, MAE: 3914.7996, R2: 0.1338\n",
      "==========================================================================================\n",
      "Epoch [3685/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010017.2754\n",
      "(Validation) Loss: 1026258.6159, MAE: 3914.7517, R2: 0.1340\n",
      "==========================================================================================\n",
      "Epoch [3686/5000] | Time: 0.21s\n",
      "(Training) Loss: 994447.2792\n",
      "(Validation) Loss: 1026102.7708, MAE: 3914.7170, R2: 0.1341\n",
      "==========================================================================================\n",
      "Epoch [3687/5000] | Time: 0.22s\n",
      "(Training) Loss: 985783.9004\n",
      "(Validation) Loss: 1025953.0768, MAE: 3914.6904, R2: 0.1342\n",
      "==========================================================================================\n",
      "Epoch [3688/5000] | Time: 0.24s\n",
      "(Training) Loss: 983711.3347\n",
      "(Validation) Loss: 1025788.7898, MAE: 3912.6523, R2: 0.1343\n",
      "==========================================================================================\n",
      "Epoch [3689/5000] | Time: 0.28s\n",
      "(Training) Loss: 988940.2240\n",
      "(Validation) Loss: 1025639.6851, MAE: 3913.6223, R2: 0.1345\n",
      "==========================================================================================\n",
      "Epoch [3690/5000] | Time: 0.27s\n",
      "(Training) Loss: 983375.9651\n",
      "(Validation) Loss: 1025481.3460, MAE: 3911.8479, R2: 0.1346\n",
      "==========================================================================================\n",
      "Epoch [3691/5000] | Time: 0.25s\n",
      "(Training) Loss: 989754.0961\n",
      "(Validation) Loss: 1025327.1111, MAE: 3911.2112, R2: 0.1347\n",
      "==========================================================================================\n",
      "Epoch [3692/5000] | Time: 0.29s\n",
      "(Training) Loss: 985085.1180\n",
      "(Validation) Loss: 1025172.4241, MAE: 3911.0952, R2: 0.1349\n",
      "==========================================================================================\n",
      "Epoch [3693/5000] | Time: 0.32s\n",
      "(Training) Loss: 998880.5197\n",
      "(Validation) Loss: 1025056.6654, MAE: 3916.8132, R2: 0.1350\n",
      "==========================================================================================\n",
      "Epoch [3694/5000] | Time: 0.33s\n",
      "(Training) Loss: 985543.3458\n",
      "(Validation) Loss: 1024859.1644, MAE: 3909.8120, R2: 0.1351\n",
      "==========================================================================================\n",
      "Epoch [3695/5000] | Time: 0.32s\n",
      "(Training) Loss: 991937.9613\n",
      "(Validation) Loss: 1024708.7797, MAE: 3909.7290, R2: 0.1352\n",
      "==========================================================================================\n",
      "Epoch [3696/5000] | Time: 0.32s\n",
      "(Training) Loss: 1000502.1701\n",
      "(Validation) Loss: 1024554.7937, MAE: 3909.2371, R2: 0.1354\n",
      "==========================================================================================\n",
      "Epoch [3697/5000] | Time: 0.31s\n",
      "(Training) Loss: 985232.7741\n",
      "(Validation) Loss: 1024398.2984, MAE: 3909.0422, R2: 0.1355\n",
      "==========================================================================================\n",
      "Epoch [3698/5000] | Time: 0.32s\n",
      "(Training) Loss: 984587.1545\n",
      "(Validation) Loss: 1024247.5327, MAE: 3909.3704, R2: 0.1356\n",
      "==========================================================================================\n",
      "Epoch [3699/5000] | Time: 0.34s\n",
      "(Training) Loss: 991369.9137\n",
      "(Validation) Loss: 1024093.3130, MAE: 3908.4697, R2: 0.1358\n",
      "==========================================================================================\n",
      "Epoch [3700/5000] | Time: 0.28s\n",
      "(Training) Loss: 984677.4879\n",
      "(Validation) Loss: 1023931.6673, MAE: 3906.2773, R2: 0.1359\n",
      "==========================================================================================\n",
      "Epoch [3701/5000] | Time: 0.28s\n",
      "(Training) Loss: 985533.5451\n",
      "(Validation) Loss: 1023778.1537, MAE: 3906.1436, R2: 0.1360\n",
      "==========================================================================================\n",
      "Epoch [3702/5000] | Time: 0.26s\n",
      "(Training) Loss: 993674.3261\n",
      "(Validation) Loss: 1023626.7835, MAE: 3905.5466, R2: 0.1361\n",
      "==========================================================================================\n",
      "Epoch [3703/5000] | Time: 0.33s\n",
      "(Training) Loss: 991780.7297\n",
      "(Validation) Loss: 1023470.0952, MAE: 3904.9758, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [3704/5000] | Time: 0.31s\n",
      "(Training) Loss: 991033.3852\n",
      "(Validation) Loss: 1023325.5365, MAE: 3907.3042, R2: 0.1364\n",
      "==========================================================================================\n",
      "Epoch [3705/5000] | Time: 0.29s\n",
      "(Training) Loss: 997528.5666\n",
      "(Validation) Loss: 1023168.7975, MAE: 3907.2886, R2: 0.1365\n",
      "==========================================================================================\n",
      "Epoch [3706/5000] | Time: 0.31s\n",
      "(Training) Loss: 993464.8471\n",
      "(Validation) Loss: 1023000.1422, MAE: 3902.8582, R2: 0.1367\n",
      "==========================================================================================\n",
      "Epoch [3707/5000] | Time: 0.27s\n",
      "(Training) Loss: 995665.9816\n",
      "(Validation) Loss: 1022840.1676, MAE: 3901.8464, R2: 0.1368\n",
      "==========================================================================================\n",
      "Epoch [3708/5000] | Time: 0.31s\n",
      "(Training) Loss: 998827.1764\n",
      "(Validation) Loss: 1022689.8083, MAE: 3901.5339, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [3709/5000] | Time: 0.29s\n",
      "(Training) Loss: 999752.3623\n",
      "(Validation) Loss: 1022532.8711, MAE: 3901.7058, R2: 0.1371\n",
      "==========================================================================================\n",
      "Epoch [3710/5000] | Time: 0.30s\n",
      "(Training) Loss: 996562.0235\n",
      "(Validation) Loss: 1022374.9892, MAE: 3900.4746, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [3711/5000] | Time: 0.28s\n",
      "(Training) Loss: 1000274.9070\n",
      "(Validation) Loss: 1022222.6387, MAE: 3900.2883, R2: 0.1373\n",
      "==========================================================================================\n",
      "Epoch [3712/5000] | Time: 0.30s\n",
      "(Training) Loss: 988887.9273\n",
      "(Validation) Loss: 1022067.7029, MAE: 3901.6248, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [3713/5000] | Time: 0.30s\n",
      "(Training) Loss: 985442.9784\n",
      "(Validation) Loss: 1021860.2413, MAE: 3896.6963, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [3714/5000] | Time: 0.29s\n",
      "(Training) Loss: 1003098.5190\n",
      "(Validation) Loss: 1045058.4940, MAE: 3975.7095, R2: 0.1183\n",
      "==========================================================================================\n",
      "Epoch [3715/5000] | Time: 0.31s\n",
      "(Training) Loss: 1015166.5006\n",
      "(Validation) Loss: 1044895.3752, MAE: 3975.2039, R2: 0.1184\n",
      "==========================================================================================\n",
      "Epoch [3716/5000] | Time: 0.28s\n",
      "(Training) Loss: 1007873.9124\n",
      "(Validation) Loss: 1044753.3562, MAE: 3978.9873, R2: 0.1185\n",
      "==========================================================================================\n",
      "Epoch [3717/5000] | Time: 0.28s\n",
      "(Training) Loss: 1011270.1745\n",
      "(Validation) Loss: 1044592.4775, MAE: 3979.3196, R2: 0.1187\n",
      "==========================================================================================\n",
      "Epoch [3718/5000] | Time: 0.28s\n",
      "(Training) Loss: 1012829.9385\n",
      "(Validation) Loss: 1044423.2889, MAE: 3976.6177, R2: 0.1188\n",
      "==========================================================================================\n",
      "Epoch [3719/5000] | Time: 0.30s\n",
      "(Training) Loss: 1008567.7716\n",
      "(Validation) Loss: 1044257.6254, MAE: 3974.9839, R2: 0.1190\n",
      "==========================================================================================\n",
      "Epoch [3720/5000] | Time: 0.23s\n",
      "(Training) Loss: 1011216.2811\n",
      "(Validation) Loss: 1044086.5778, MAE: 3972.0945, R2: 0.1191\n",
      "==========================================================================================\n",
      "Epoch [3721/5000] | Time: 0.32s\n",
      "(Training) Loss: 1012395.1808\n",
      "(Validation) Loss: 1043931.4946, MAE: 3973.3247, R2: 0.1192\n",
      "==========================================================================================\n",
      "Epoch [3722/5000] | Time: 0.29s\n",
      "(Training) Loss: 1000204.9300\n",
      "(Validation) Loss: 1043769.1479, MAE: 3973.1948, R2: 0.1194\n",
      "==========================================================================================\n",
      "Epoch [3723/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000804.3706\n",
      "(Validation) Loss: 1043606.4051, MAE: 3971.7727, R2: 0.1195\n",
      "==========================================================================================\n",
      "Epoch [3724/5000] | Time: 0.22s\n",
      "(Training) Loss: 999092.8590\n",
      "(Validation) Loss: 1043457.7168, MAE: 3973.2495, R2: 0.1196\n",
      "==========================================================================================\n",
      "Epoch [3725/5000] | Time: 0.21s\n",
      "(Training) Loss: 1014532.5393\n",
      "(Validation) Loss: 1043290.3822, MAE: 3970.4517, R2: 0.1198\n",
      "==========================================================================================\n",
      "Epoch [3726/5000] | Time: 0.20s\n",
      "(Training) Loss: 1020940.4924\n",
      "(Validation) Loss: 1043135.6241, MAE: 3972.2620, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [3727/5000] | Time: 0.19s\n",
      "(Training) Loss: 1012958.0273\n",
      "(Validation) Loss: 1042964.6781, MAE: 3969.1089, R2: 0.1200\n",
      "==========================================================================================\n",
      "Epoch [3728/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002595.8496\n",
      "(Validation) Loss: 1042806.8063, MAE: 3968.8330, R2: 0.1202\n",
      "==========================================================================================\n",
      "Epoch [3729/5000] | Time: 0.22s\n",
      "(Training) Loss: 999120.5674\n",
      "(Validation) Loss: 1042642.1994, MAE: 3967.4321, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [3730/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007627.8883\n",
      "(Validation) Loss: 1042479.2635, MAE: 3966.9309, R2: 0.1204\n",
      "==========================================================================================\n",
      "Epoch [3731/5000] | Time: 0.21s\n",
      "(Training) Loss: 1008951.2786\n",
      "(Validation) Loss: 1042324.0279, MAE: 3967.2322, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [3732/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009445.6371\n",
      "(Validation) Loss: 1042172.0178, MAE: 3967.9785, R2: 0.1207\n",
      "==========================================================================================\n",
      "Epoch [3733/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001361.8642\n",
      "(Validation) Loss: 1042005.3029, MAE: 3966.2581, R2: 0.1208\n",
      "==========================================================================================\n",
      "Epoch [3734/5000] | Time: 0.25s\n",
      "(Training) Loss: 996751.4304\n",
      "(Validation) Loss: 1041859.5657, MAE: 3967.2974, R2: 0.1210\n",
      "==========================================================================================\n",
      "Epoch [3735/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007533.8509\n",
      "(Validation) Loss: 1046646.1105, MAE: 3984.5288, R2: 0.1170\n",
      "==========================================================================================\n",
      "Epoch [3736/5000] | Time: 0.24s\n",
      "(Training) Loss: 1023496.0428\n",
      "(Validation) Loss: 1046465.0717, MAE: 3982.7761, R2: 0.1171\n",
      "==========================================================================================\n",
      "Epoch [3737/5000] | Time: 0.21s\n",
      "(Training) Loss: 1023073.2931\n",
      "(Validation) Loss: 1046296.1473, MAE: 3983.6609, R2: 0.1173\n",
      "==========================================================================================\n",
      "Epoch [3738/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019761.2227\n",
      "(Validation) Loss: 1046120.5232, MAE: 3981.4758, R2: 0.1174\n",
      "==========================================================================================\n",
      "Epoch [3739/5000] | Time: 0.22s\n",
      "(Training) Loss: 1014877.9067\n",
      "(Validation) Loss: 1045946.4635, MAE: 3978.9373, R2: 0.1175\n",
      "==========================================================================================\n",
      "Epoch [3740/5000] | Time: 0.25s\n",
      "(Training) Loss: 1011163.0298\n",
      "(Validation) Loss: 1045794.2705, MAE: 3983.2229, R2: 0.1177\n",
      "==========================================================================================\n",
      "Epoch [3741/5000] | Time: 0.26s\n",
      "(Training) Loss: 1017143.2449\n",
      "(Validation) Loss: 1045614.8775, MAE: 3978.8564, R2: 0.1178\n",
      "==========================================================================================\n",
      "Epoch [3742/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023617.7011\n",
      "(Validation) Loss: 1045450.7225, MAE: 3978.0339, R2: 0.1180\n",
      "==========================================================================================\n",
      "Epoch [3743/5000] | Time: 0.25s\n",
      "(Training) Loss: 1004987.2608\n",
      "(Validation) Loss: 1045277.5010, MAE: 3976.5801, R2: 0.1181\n",
      "==========================================================================================\n",
      "Epoch [3744/5000] | Time: 0.23s\n",
      "(Training) Loss: 1027779.0044\n",
      "(Validation) Loss: 1045139.3829, MAE: 3982.2727, R2: 0.1182\n",
      "==========================================================================================\n",
      "Epoch [3745/5000] | Time: 0.34s\n",
      "(Training) Loss: 1017582.8299\n",
      "(Validation) Loss: 1044962.0775, MAE: 3979.2134, R2: 0.1184\n",
      "==========================================================================================\n",
      "Epoch [3746/5000] | Time: 0.21s\n",
      "(Training) Loss: 1031225.5828\n",
      "(Validation) Loss: 1044784.9651, MAE: 3976.7356, R2: 0.1185\n",
      "==========================================================================================\n",
      "Epoch [3747/5000] | Time: 0.23s\n",
      "(Training) Loss: 1024454.6339\n",
      "(Validation) Loss: 1044612.8051, MAE: 3973.1111, R2: 0.1187\n",
      "==========================================================================================\n",
      "Epoch [3748/5000] | Time: 0.28s\n",
      "(Training) Loss: 1026485.4949\n",
      "(Validation) Loss: 1044449.1225, MAE: 3973.4653, R2: 0.1188\n",
      "==========================================================================================\n",
      "Epoch [3749/5000] | Time: 0.25s\n",
      "(Training) Loss: 1029817.8058\n",
      "(Validation) Loss: 1044279.8425, MAE: 3971.9988, R2: 0.1189\n",
      "==========================================================================================\n",
      "Epoch [3750/5000] | Time: 0.21s\n",
      "(Training) Loss: 1010179.8198\n",
      "(Validation) Loss: 1044114.7886, MAE: 3972.9524, R2: 0.1191\n",
      "==========================================================================================\n",
      "Epoch [3751/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016814.9898\n",
      "(Validation) Loss: 1043950.8978, MAE: 3971.1250, R2: 0.1192\n",
      "==========================================================================================\n",
      "Epoch [3752/5000] | Time: 0.27s\n",
      "(Training) Loss: 1043392.0647\n",
      "(Validation) Loss: 1043807.6343, MAE: 3976.0261, R2: 0.1193\n",
      "==========================================================================================\n",
      "Epoch [3753/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007040.4829\n",
      "(Validation) Loss: 1043644.7594, MAE: 3975.3416, R2: 0.1195\n",
      "==========================================================================================\n",
      "Epoch [3754/5000] | Time: 0.23s\n",
      "(Training) Loss: 1036078.7157\n",
      "(Validation) Loss: 1043476.3429, MAE: 3972.7085, R2: 0.1196\n",
      "==========================================================================================\n",
      "Epoch [3755/5000] | Time: 0.27s\n",
      "(Training) Loss: 1019642.1675\n",
      "(Validation) Loss: 1043314.5244, MAE: 3972.9780, R2: 0.1197\n",
      "==========================================================================================\n",
      "Epoch [3756/5000] | Time: 0.20s\n",
      "(Training) Loss: 1001407.8947\n",
      "(Validation) Loss: 1043143.8425, MAE: 3971.7126, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [3757/5000] | Time: 0.25s\n",
      "(Training) Loss: 1007623.1231\n",
      "(Validation) Loss: 1042980.7797, MAE: 3969.0483, R2: 0.1200\n",
      "==========================================================================================\n",
      "Epoch [3758/5000] | Time: 0.28s\n",
      "(Training) Loss: 1006343.0190\n",
      "(Validation) Loss: 1042825.4375, MAE: 3969.9263, R2: 0.1201\n",
      "==========================================================================================\n",
      "Epoch [3759/5000] | Time: 0.26s\n",
      "(Training) Loss: 1027586.1003\n",
      "(Validation) Loss: 1042658.9003, MAE: 3968.4702, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [3760/5000] | Time: 0.21s\n",
      "(Training) Loss: 1002025.9721\n",
      "(Validation) Loss: 1042490.3822, MAE: 3966.8403, R2: 0.1204\n",
      "==========================================================================================\n",
      "Epoch [3761/5000] | Time: 0.23s\n",
      "(Training) Loss: 997600.1662\n",
      "(Validation) Loss: 1042328.4673, MAE: 3966.4580, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [3762/5000] | Time: 0.28s\n",
      "(Training) Loss: 1024692.7893\n",
      "(Validation) Loss: 1042171.8349, MAE: 3966.0271, R2: 0.1207\n",
      "==========================================================================================\n",
      "Epoch [3763/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008637.9530\n",
      "(Validation) Loss: 1042010.5498, MAE: 3966.7488, R2: 0.1208\n",
      "==========================================================================================\n",
      "Epoch [3764/5000] | Time: 0.26s\n",
      "(Training) Loss: 1013692.3522\n",
      "(Validation) Loss: 1041844.2108, MAE: 3964.0845, R2: 0.1210\n",
      "==========================================================================================\n",
      "Epoch [3765/5000] | Time: 0.23s\n",
      "(Training) Loss: 1015239.1237\n",
      "(Validation) Loss: 1041684.4241, MAE: 3965.7512, R2: 0.1211\n",
      "==========================================================================================\n",
      "Epoch [3766/5000] | Time: 0.22s\n",
      "(Training) Loss: 1015371.2525\n",
      "(Validation) Loss: 1041549.4705, MAE: 3970.4482, R2: 0.1212\n",
      "==========================================================================================\n",
      "Epoch [3767/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012592.2227\n",
      "(Validation) Loss: 1041366.4102, MAE: 3965.1206, R2: 0.1214\n",
      "==========================================================================================\n",
      "Epoch [3768/5000] | Time: 0.22s\n",
      "(Training) Loss: 1017730.2868\n",
      "(Validation) Loss: 1041201.2241, MAE: 3963.3718, R2: 0.1215\n",
      "==========================================================================================\n",
      "Epoch [3769/5000] | Time: 0.23s\n",
      "(Training) Loss: 996678.1307\n",
      "(Validation) Loss: 1041034.4533, MAE: 3961.8530, R2: 0.1216\n",
      "==========================================================================================\n",
      "Epoch [3770/5000] | Time: 0.25s\n",
      "(Training) Loss: 998591.1929\n",
      "(Validation) Loss: 1040878.0038, MAE: 3962.5845, R2: 0.1218\n",
      "==========================================================================================\n",
      "Epoch [3771/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009278.9194\n",
      "(Validation) Loss: 1040720.8584, MAE: 3964.3491, R2: 0.1219\n",
      "==========================================================================================\n",
      "Epoch [3772/5000] | Time: 0.23s\n",
      "(Training) Loss: 1030445.9454\n",
      "(Validation) Loss: 1040555.6267, MAE: 3961.2498, R2: 0.1220\n",
      "==========================================================================================\n",
      "Epoch [3773/5000] | Time: 0.35s\n",
      "(Training) Loss: 997788.7005\n",
      "(Validation) Loss: 1040395.8857, MAE: 3961.9260, R2: 0.1222\n",
      "==========================================================================================\n",
      "Epoch [3774/5000] | Time: 0.30s\n",
      "(Training) Loss: 1007900.8680\n",
      "(Validation) Loss: 1040238.4711, MAE: 3961.0784, R2: 0.1223\n",
      "==========================================================================================\n",
      "Epoch [3775/5000] | Time: 0.35s\n",
      "(Training) Loss: 1008957.0552\n",
      "(Validation) Loss: 1040074.8648, MAE: 3960.5781, R2: 0.1224\n",
      "==========================================================================================\n",
      "Epoch [3776/5000] | Time: 0.22s\n",
      "(Training) Loss: 1028809.0311\n",
      "(Validation) Loss: 1039913.6000, MAE: 3960.0559, R2: 0.1226\n",
      "==========================================================================================\n",
      "Epoch [3777/5000] | Time: 0.23s\n",
      "(Training) Loss: 1026569.9613\n",
      "(Validation) Loss: 1039742.2070, MAE: 3957.0500, R2: 0.1227\n",
      "==========================================================================================\n",
      "Epoch [3778/5000] | Time: 0.27s\n",
      "(Training) Loss: 1013126.0755\n",
      "(Validation) Loss: 1039589.4400, MAE: 3959.7195, R2: 0.1228\n",
      "==========================================================================================\n",
      "Epoch [3779/5000] | Time: 0.21s\n",
      "(Training) Loss: 1006983.1409\n",
      "(Validation) Loss: 1039428.0229, MAE: 3958.3264, R2: 0.1230\n",
      "==========================================================================================\n",
      "Epoch [3780/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004371.9867\n",
      "(Validation) Loss: 1039268.3429, MAE: 3958.4983, R2: 0.1231\n",
      "==========================================================================================\n",
      "Epoch [3781/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011764.4467\n",
      "(Validation) Loss: 1039102.3492, MAE: 3957.0540, R2: 0.1232\n",
      "==========================================================================================\n",
      "Epoch [3782/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002372.6929\n",
      "(Validation) Loss: 1038938.2349, MAE: 3955.7170, R2: 0.1234\n",
      "==========================================================================================\n",
      "Epoch [3783/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000373.2982\n",
      "(Validation) Loss: 1038776.8483, MAE: 3954.9419, R2: 0.1235\n",
      "==========================================================================================\n",
      "Epoch [3784/5000] | Time: 0.24s\n",
      "(Training) Loss: 998803.3544\n",
      "(Validation) Loss: 1038616.7365, MAE: 3955.9036, R2: 0.1237\n",
      "==========================================================================================\n",
      "Epoch [3785/5000] | Time: 0.24s\n",
      "(Training) Loss: 1014122.6536\n",
      "(Validation) Loss: 1038456.2235, MAE: 3953.3137, R2: 0.1238\n",
      "==========================================================================================\n",
      "Epoch [3786/5000] | Time: 0.24s\n",
      "(Training) Loss: 1007889.1637\n",
      "(Validation) Loss: 1038292.4343, MAE: 3952.8899, R2: 0.1239\n",
      "==========================================================================================\n",
      "Epoch [3787/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008916.0596\n",
      "(Validation) Loss: 1038143.4514, MAE: 3956.3074, R2: 0.1240\n",
      "==========================================================================================\n",
      "Epoch [3788/5000] | Time: 0.23s\n",
      "(Training) Loss: 1009800.7468\n",
      "(Validation) Loss: 1037979.8298, MAE: 3955.5022, R2: 0.1242\n",
      "==========================================================================================\n",
      "Epoch [3789/5000] | Time: 0.27s\n",
      "(Training) Loss: 1015074.9930\n",
      "(Validation) Loss: 1037808.3149, MAE: 3950.3369, R2: 0.1243\n",
      "==========================================================================================\n",
      "Epoch [3790/5000] | Time: 0.37s\n",
      "(Training) Loss: 1012242.8953\n",
      "(Validation) Loss: 1037648.0406, MAE: 3950.9580, R2: 0.1245\n",
      "==========================================================================================\n",
      "Epoch [3791/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006815.8046\n",
      "(Validation) Loss: 1037485.0743, MAE: 3950.1541, R2: 0.1246\n",
      "==========================================================================================\n",
      "Epoch [3792/5000] | Time: 0.21s\n",
      "(Training) Loss: 995649.9778\n",
      "(Validation) Loss: 1037328.3556, MAE: 3951.0298, R2: 0.1247\n",
      "==========================================================================================\n",
      "Epoch [3793/5000] | Time: 0.21s\n",
      "(Training) Loss: 1014412.3566\n",
      "(Validation) Loss: 1037170.9511, MAE: 3950.1880, R2: 0.1249\n",
      "==========================================================================================\n",
      "Epoch [3794/5000] | Time: 0.26s\n",
      "(Training) Loss: 998628.3014\n",
      "(Validation) Loss: 1037013.6940, MAE: 3950.5168, R2: 0.1250\n",
      "==========================================================================================\n",
      "Epoch [3795/5000] | Time: 0.26s\n",
      "(Training) Loss: 1002966.6142\n",
      "(Validation) Loss: 1036846.3543, MAE: 3948.6821, R2: 0.1251\n",
      "==========================================================================================\n",
      "Epoch [3796/5000] | Time: 0.25s\n",
      "(Training) Loss: 1009026.8788\n",
      "(Validation) Loss: 1036689.9454, MAE: 3948.8196, R2: 0.1253\n",
      "==========================================================================================\n",
      "Epoch [3797/5000] | Time: 0.26s\n",
      "(Training) Loss: 1017085.4162\n",
      "(Validation) Loss: 1036523.2559, MAE: 3947.5779, R2: 0.1254\n",
      "==========================================================================================\n",
      "Epoch [3798/5000] | Time: 0.23s\n",
      "(Training) Loss: 1019055.1142\n",
      "(Validation) Loss: 1036361.9708, MAE: 3946.4231, R2: 0.1255\n",
      "==========================================================================================\n",
      "Epoch [3799/5000] | Time: 0.27s\n",
      "(Training) Loss: 1034945.6681\n",
      "(Validation) Loss: 1036201.3308, MAE: 3947.0930, R2: 0.1257\n",
      "==========================================================================================\n",
      "Epoch [3800/5000] | Time: 0.22s\n",
      "(Training) Loss: 996687.7437\n",
      "(Validation) Loss: 1036038.1765, MAE: 3945.0847, R2: 0.1258\n",
      "==========================================================================================\n",
      "Epoch [3801/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012868.8915\n",
      "(Validation) Loss: 1035879.6546, MAE: 3945.2974, R2: 0.1259\n",
      "==========================================================================================\n",
      "Epoch [3802/5000] | Time: 0.22s\n",
      "(Training) Loss: 998929.3896\n",
      "(Validation) Loss: 1035714.8800, MAE: 3944.3713, R2: 0.1261\n",
      "==========================================================================================\n",
      "Epoch [3803/5000] | Time: 0.22s\n",
      "(Training) Loss: 1013588.5419\n",
      "(Validation) Loss: 1035561.6102, MAE: 3945.2529, R2: 0.1262\n",
      "==========================================================================================\n",
      "Epoch [3804/5000] | Time: 0.22s\n",
      "(Training) Loss: 1005573.0761\n",
      "(Validation) Loss: 1035398.6590, MAE: 3942.8066, R2: 0.1263\n",
      "==========================================================================================\n",
      "Epoch [3805/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001023.6440\n",
      "(Validation) Loss: 1035248.3048, MAE: 3946.4956, R2: 0.1265\n",
      "==========================================================================================\n",
      "Epoch [3806/5000] | Time: 0.24s\n",
      "(Training) Loss: 990276.1315\n",
      "(Validation) Loss: 1035078.4965, MAE: 3943.0876, R2: 0.1266\n",
      "==========================================================================================\n",
      "Epoch [3807/5000] | Time: 0.28s\n",
      "(Training) Loss: 998630.3058\n",
      "(Validation) Loss: 1034917.5517, MAE: 3941.2717, R2: 0.1267\n",
      "==========================================================================================\n",
      "Epoch [3808/5000] | Time: 0.34s\n",
      "(Training) Loss: 991481.8149\n",
      "(Validation) Loss: 1034755.4235, MAE: 3940.3191, R2: 0.1269\n",
      "==========================================================================================\n",
      "Epoch [3809/5000] | Time: 0.22s\n",
      "(Training) Loss: 1013694.0825\n",
      "(Validation) Loss: 1034604.6425, MAE: 3941.6392, R2: 0.1270\n",
      "==========================================================================================\n",
      "Epoch [3810/5000] | Time: 0.21s\n",
      "(Training) Loss: 1003243.6542\n",
      "(Validation) Loss: 1034436.4851, MAE: 3938.8887, R2: 0.1271\n",
      "==========================================================================================\n",
      "Epoch [3811/5000] | Time: 0.21s\n",
      "(Training) Loss: 991377.1079\n",
      "(Validation) Loss: 1034297.1632, MAE: 3942.8572, R2: 0.1273\n",
      "==========================================================================================\n",
      "Epoch [3812/5000] | Time: 0.24s\n",
      "(Training) Loss: 995550.9435\n",
      "(Validation) Loss: 1034128.6908, MAE: 3940.9294, R2: 0.1274\n",
      "==========================================================================================\n",
      "Epoch [3813/5000] | Time: 0.19s\n",
      "(Training) Loss: 1015297.6161\n",
      "(Validation) Loss: 1033961.2698, MAE: 3939.2896, R2: 0.1275\n",
      "==========================================================================================\n",
      "Epoch [3814/5000] | Time: 0.19s\n",
      "(Training) Loss: 1012828.2091\n",
      "(Validation) Loss: 1033802.1130, MAE: 3937.2209, R2: 0.1277\n",
      "==========================================================================================\n",
      "Epoch [3815/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011467.1256\n",
      "(Validation) Loss: 1033639.3346, MAE: 3937.3447, R2: 0.1278\n",
      "==========================================================================================\n",
      "Epoch [3816/5000] | Time: 0.21s\n",
      "(Training) Loss: 998004.5780\n",
      "(Validation) Loss: 1033479.7613, MAE: 3937.1155, R2: 0.1279\n",
      "==========================================================================================\n",
      "Epoch [3817/5000] | Time: 0.23s\n",
      "(Training) Loss: 990995.8249\n",
      "(Validation) Loss: 1033316.9067, MAE: 3935.9475, R2: 0.1281\n",
      "==========================================================================================\n",
      "Epoch [3818/5000] | Time: 0.24s\n",
      "(Training) Loss: 1004104.6878\n",
      "(Validation) Loss: 1033162.7733, MAE: 3936.3374, R2: 0.1282\n",
      "==========================================================================================\n",
      "Epoch [3819/5000] | Time: 0.24s\n",
      "(Training) Loss: 993815.0336\n",
      "(Validation) Loss: 1033003.3829, MAE: 3936.5117, R2: 0.1283\n",
      "==========================================================================================\n",
      "Epoch [3820/5000] | Time: 0.25s\n",
      "(Training) Loss: 992956.6897\n",
      "(Validation) Loss: 1032855.7460, MAE: 3938.0964, R2: 0.1285\n",
      "==========================================================================================\n",
      "Epoch [3821/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016104.7183\n",
      "(Validation) Loss: 1032686.7352, MAE: 3935.8252, R2: 0.1286\n",
      "==========================================================================================\n",
      "Epoch [3822/5000] | Time: 0.22s\n",
      "(Training) Loss: 995176.8921\n",
      "(Validation) Loss: 1032518.8825, MAE: 3933.5039, R2: 0.1287\n",
      "==========================================================================================\n",
      "Epoch [3823/5000] | Time: 0.21s\n",
      "(Training) Loss: 1008172.6555\n",
      "(Validation) Loss: 1032359.0400, MAE: 3932.4285, R2: 0.1289\n",
      "==========================================================================================\n",
      "Epoch [3824/5000] | Time: 0.20s\n",
      "(Training) Loss: 1000997.9461\n",
      "(Validation) Loss: 1032210.8698, MAE: 3935.1895, R2: 0.1290\n",
      "==========================================================================================\n",
      "Epoch [3825/5000] | Time: 0.22s\n",
      "(Training) Loss: 1005394.4613\n",
      "(Validation) Loss: 1032047.5073, MAE: 3937.8848, R2: 0.1291\n",
      "==========================================================================================\n",
      "Epoch [3826/5000] | Time: 0.24s\n",
      "(Training) Loss: 1021823.0552\n",
      "(Validation) Loss: 1031878.7098, MAE: 3931.1636, R2: 0.1293\n",
      "==========================================================================================\n",
      "Epoch [3827/5000] | Time: 0.24s\n",
      "(Training) Loss: 1005843.6745\n",
      "(Validation) Loss: 1031731.1746, MAE: 3934.7195, R2: 0.1294\n",
      "==========================================================================================\n",
      "Epoch [3828/5000] | Time: 0.22s\n",
      "(Training) Loss: 990880.1374\n",
      "(Validation) Loss: 1031555.8756, MAE: 3929.6001, R2: 0.1295\n",
      "==========================================================================================\n",
      "Epoch [3829/5000] | Time: 0.21s\n",
      "(Training) Loss: 987364.0209\n",
      "(Validation) Loss: 1031397.2622, MAE: 3930.0356, R2: 0.1297\n",
      "==========================================================================================\n",
      "Epoch [3830/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007687.9505\n",
      "(Validation) Loss: 1031262.3949, MAE: 3934.9602, R2: 0.1298\n",
      "==========================================================================================\n",
      "Epoch [3831/5000] | Time: 0.20s\n",
      "(Training) Loss: 1017453.5273\n",
      "(Validation) Loss: 1031077.2927, MAE: 3927.8289, R2: 0.1299\n",
      "==========================================================================================\n",
      "Epoch [3832/5000] | Time: 0.22s\n",
      "(Training) Loss: 991771.4695\n",
      "(Validation) Loss: 1030930.4889, MAE: 3931.7297, R2: 0.1301\n",
      "==========================================================================================\n",
      "Epoch [3833/5000] | Time: 0.22s\n",
      "(Training) Loss: 989184.8360\n",
      "(Validation) Loss: 1030767.1568, MAE: 3930.0049, R2: 0.1302\n",
      "==========================================================================================\n",
      "Epoch [3834/5000] | Time: 0.22s\n",
      "(Training) Loss: 986350.6263\n",
      "(Validation) Loss: 1023605.3130, MAE: 3958.8887, R2: 0.1362\n",
      "==========================================================================================\n",
      "Epoch [3835/5000] | Time: 0.23s\n",
      "(Training) Loss: 987192.8096\n",
      "(Validation) Loss: 1023404.2565, MAE: 3925.1523, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [3836/5000] | Time: 0.22s\n",
      "(Training) Loss: 986569.8306\n",
      "(Validation) Loss: 1023294.2171, MAE: 3930.3540, R2: 0.1364\n",
      "==========================================================================================\n",
      "Epoch [3837/5000] | Time: 0.23s\n",
      "(Training) Loss: 982062.1123\n",
      "(Validation) Loss: 1023093.8768, MAE: 3918.0156, R2: 0.1366\n",
      "==========================================================================================\n",
      "Epoch [3838/5000] | Time: 0.24s\n",
      "(Training) Loss: 983203.7735\n",
      "(Validation) Loss: 1022916.1448, MAE: 3910.9443, R2: 0.1367\n",
      "==========================================================================================\n",
      "Epoch [3839/5000] | Time: 0.27s\n",
      "(Training) Loss: 1003217.9499\n",
      "(Validation) Loss: 1022771.3676, MAE: 3913.6716, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [3840/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011769.7868\n",
      "(Validation) Loss: 1022614.7810, MAE: 3912.3550, R2: 0.1370\n",
      "==========================================================================================\n",
      "Epoch [3841/5000] | Time: 0.23s\n",
      "(Training) Loss: 993287.0159\n",
      "(Validation) Loss: 1022486.9740, MAE: 3916.1106, R2: 0.1371\n",
      "==========================================================================================\n",
      "Epoch [3842/5000] | Time: 0.23s\n",
      "(Training) Loss: 987549.8388\n",
      "(Validation) Loss: 1022308.8762, MAE: 3908.5500, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [3843/5000] | Time: 0.22s\n",
      "(Training) Loss: 986110.5482\n",
      "(Validation) Loss: 1022135.7613, MAE: 3904.4675, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [3844/5000] | Time: 0.22s\n",
      "(Training) Loss: 983125.6453\n",
      "(Validation) Loss: 1021997.1200, MAE: 3907.6003, R2: 0.1375\n",
      "==========================================================================================\n",
      "Epoch [3845/5000] | Time: 0.23s\n",
      "(Training) Loss: 1015903.4105\n",
      "(Validation) Loss: 1021841.1733, MAE: 3905.2908, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [3846/5000] | Time: 0.25s\n",
      "(Training) Loss: 991563.3179\n",
      "(Validation) Loss: 1021694.5219, MAE: 3906.8223, R2: 0.1378\n",
      "==========================================================================================\n",
      "Epoch [3847/5000] | Time: 0.23s\n",
      "(Training) Loss: 981476.2881\n",
      "(Validation) Loss: 1021528.1879, MAE: 3904.4521, R2: 0.1379\n",
      "==========================================================================================\n",
      "Epoch [3848/5000] | Time: 0.22s\n",
      "(Training) Loss: 998030.0006\n",
      "(Validation) Loss: 1021359.9390, MAE: 3900.7527, R2: 0.1380\n",
      "==========================================================================================\n",
      "Epoch [3849/5000] | Time: 0.23s\n",
      "(Training) Loss: 982013.5108\n",
      "(Validation) Loss: 1021229.6838, MAE: 3905.0647, R2: 0.1381\n",
      "==========================================================================================\n",
      "Epoch [3850/5000] | Time: 0.22s\n",
      "(Training) Loss: 992114.7887\n",
      "(Validation) Loss: 1021051.9568, MAE: 3899.4854, R2: 0.1383\n",
      "==========================================================================================\n",
      "Epoch [3851/5000] | Time: 0.21s\n",
      "(Training) Loss: 989525.1091\n",
      "(Validation) Loss: 1020898.7276, MAE: 3899.3069, R2: 0.1384\n",
      "==========================================================================================\n",
      "Epoch [3852/5000] | Time: 0.23s\n",
      "(Training) Loss: 993408.1523\n",
      "(Validation) Loss: 1020744.7975, MAE: 3898.6165, R2: 0.1385\n",
      "==========================================================================================\n",
      "Epoch [3853/5000] | Time: 0.25s\n",
      "(Training) Loss: 985398.4372\n",
      "(Validation) Loss: 1020592.0711, MAE: 3898.6926, R2: 0.1387\n",
      "==========================================================================================\n",
      "Epoch [3854/5000] | Time: 0.22s\n",
      "(Training) Loss: 991034.1840\n",
      "(Validation) Loss: 1020434.0470, MAE: 3896.7861, R2: 0.1388\n",
      "==========================================================================================\n",
      "Epoch [3855/5000] | Time: 0.23s\n",
      "(Training) Loss: 981981.2919\n",
      "(Validation) Loss: 1020300.4851, MAE: 3899.4993, R2: 0.1389\n",
      "==========================================================================================\n",
      "Epoch [3856/5000] | Time: 0.24s\n",
      "(Training) Loss: 983339.1466\n",
      "(Validation) Loss: 1020127.6851, MAE: 3895.9800, R2: 0.1391\n",
      "==========================================================================================\n",
      "Epoch [3857/5000] | Time: 0.24s\n",
      "(Training) Loss: 982295.6359\n",
      "(Validation) Loss: 1019975.3651, MAE: 3895.7529, R2: 0.1392\n",
      "==========================================================================================\n",
      "Epoch [3858/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023504.0241\n",
      "(Validation) Loss: 1019813.7549, MAE: 3893.3142, R2: 0.1393\n",
      "==========================================================================================\n",
      "Epoch [3859/5000] | Time: 0.22s\n",
      "(Training) Loss: 1003203.5152\n",
      "(Validation) Loss: 1019659.3829, MAE: 3894.3342, R2: 0.1395\n",
      "==========================================================================================\n",
      "Epoch [3860/5000] | Time: 0.23s\n",
      "(Training) Loss: 977220.6545\n",
      "(Validation) Loss: 1019511.8578, MAE: 3895.4163, R2: 0.1396\n",
      "==========================================================================================\n",
      "Epoch [3861/5000] | Time: 0.23s\n",
      "(Training) Loss: 990104.1891\n",
      "(Validation) Loss: 1019370.3314, MAE: 3896.0955, R2: 0.1397\n",
      "==========================================================================================\n",
      "Epoch [3862/5000] | Time: 0.22s\n",
      "(Training) Loss: 985012.9201\n",
      "(Validation) Loss: 1019231.3803, MAE: 3899.8528, R2: 0.1398\n",
      "==========================================================================================\n",
      "Epoch [3863/5000] | Time: 0.23s\n",
      "(Training) Loss: 999710.2728\n",
      "(Validation) Loss: 1019119.5937, MAE: 3897.7534, R2: 0.1399\n",
      "==========================================================================================\n",
      "Epoch [3864/5000] | Time: 0.22s\n",
      "(Training) Loss: 997276.7354\n",
      "(Validation) Loss: 1018958.0952, MAE: 3895.2244, R2: 0.1400\n",
      "==========================================================================================\n",
      "Epoch [3865/5000] | Time: 0.27s\n",
      "(Training) Loss: 985869.7075\n",
      "(Validation) Loss: 1018801.9606, MAE: 3894.6599, R2: 0.1402\n",
      "==========================================================================================\n",
      "Epoch [3866/5000] | Time: 0.39s\n",
      "(Training) Loss: 983918.7291\n",
      "(Validation) Loss: 1018650.5498, MAE: 3895.3342, R2: 0.1403\n",
      "==========================================================================================\n",
      "Epoch [3867/5000] | Time: 0.21s\n",
      "(Training) Loss: 980184.0558\n",
      "(Validation) Loss: 1018495.1416, MAE: 3894.3647, R2: 0.1404\n",
      "==========================================================================================\n",
      "Epoch [3868/5000] | Time: 0.25s\n",
      "(Training) Loss: 990554.4213\n",
      "(Validation) Loss: 1018340.7594, MAE: 3893.2751, R2: 0.1405\n",
      "==========================================================================================\n",
      "Epoch [3869/5000] | Time: 0.24s\n",
      "(Training) Loss: 985084.3268\n",
      "(Validation) Loss: 1018191.9492, MAE: 3893.5720, R2: 0.1407\n",
      "==========================================================================================\n",
      "Epoch [3870/5000] | Time: 0.23s\n",
      "(Training) Loss: 979635.0628\n",
      "(Validation) Loss: 1018029.7092, MAE: 3891.1521, R2: 0.1408\n",
      "==========================================================================================\n",
      "Epoch [3871/5000] | Time: 0.25s\n",
      "(Training) Loss: 1014582.6732\n",
      "(Validation) Loss: 1017883.7333, MAE: 3892.5645, R2: 0.1409\n",
      "==========================================================================================\n",
      "Epoch [3872/5000] | Time: 0.30s\n",
      "(Training) Loss: 991869.6485\n",
      "(Validation) Loss: 1017722.8800, MAE: 3891.8286, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [3873/5000] | Time: 0.30s\n",
      "(Training) Loss: 995023.8274\n",
      "(Validation) Loss: 1017564.5816, MAE: 3890.2893, R2: 0.1412\n",
      "==========================================================================================\n",
      "Epoch [3874/5000] | Time: 0.23s\n",
      "(Training) Loss: 978901.8001\n",
      "(Validation) Loss: 1017413.0083, MAE: 3889.9578, R2: 0.1413\n",
      "==========================================================================================\n",
      "Epoch [3875/5000] | Time: 0.21s\n",
      "(Training) Loss: 981598.9994\n",
      "(Validation) Loss: 1017260.7187, MAE: 3889.1621, R2: 0.1414\n",
      "==========================================================================================\n",
      "Epoch [3876/5000] | Time: 0.22s\n",
      "(Training) Loss: 976106.8855\n",
      "(Validation) Loss: 1017111.0806, MAE: 3890.8550, R2: 0.1416\n",
      "==========================================================================================\n",
      "Epoch [3877/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001720.5032\n",
      "(Validation) Loss: 1016952.6502, MAE: 3887.8054, R2: 0.1417\n",
      "==========================================================================================\n",
      "Epoch [3878/5000] | Time: 0.21s\n",
      "(Training) Loss: 997180.3135\n",
      "(Validation) Loss: 1016802.4889, MAE: 3888.4937, R2: 0.1418\n",
      "==========================================================================================\n",
      "Epoch [3879/5000] | Time: 0.19s\n",
      "(Training) Loss: 978069.6294\n",
      "(Validation) Loss: 1016657.2241, MAE: 3889.4761, R2: 0.1420\n",
      "==========================================================================================\n",
      "Epoch [3880/5000] | Time: 0.20s\n",
      "(Training) Loss: 1003968.3122\n",
      "(Validation) Loss: 1016487.7714, MAE: 3886.0151, R2: 0.1421\n",
      "==========================================================================================\n",
      "Epoch [3881/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007400.7627\n",
      "(Validation) Loss: 1016364.2260, MAE: 3891.7505, R2: 0.1422\n",
      "==========================================================================================\n",
      "Epoch [3882/5000] | Time: 0.20s\n",
      "(Training) Loss: 998927.8928\n",
      "(Validation) Loss: 1016173.9581, MAE: 3884.0161, R2: 0.1424\n",
      "==========================================================================================\n",
      "Epoch [3883/5000] | Time: 0.22s\n",
      "(Training) Loss: 979650.1466\n",
      "(Validation) Loss: 1016026.7683, MAE: 3885.1279, R2: 0.1425\n",
      "==========================================================================================\n",
      "Epoch [3884/5000] | Time: 0.20s\n",
      "(Training) Loss: 981915.7773\n",
      "(Validation) Loss: 1015871.5733, MAE: 3883.9675, R2: 0.1426\n",
      "==========================================================================================\n",
      "Epoch [3885/5000] | Time: 0.21s\n",
      "(Training) Loss: 991050.2957\n",
      "(Validation) Loss: 1015719.9797, MAE: 3884.1646, R2: 0.1427\n",
      "==========================================================================================\n",
      "Epoch [3886/5000] | Time: 0.21s\n",
      "(Training) Loss: 978741.6789\n",
      "(Validation) Loss: 1015621.2317, MAE: 3889.0002, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [3887/5000] | Time: 0.22s\n",
      "(Training) Loss: 989794.7418\n",
      "(Validation) Loss: 1015408.3556, MAE: 3881.4934, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [3888/5000] | Time: 0.29s\n",
      "(Training) Loss: 987492.2500\n",
      "(Validation) Loss: 1015261.7448, MAE: 3882.4946, R2: 0.1431\n",
      "==========================================================================================\n",
      "Epoch [3889/5000] | Time: 0.27s\n",
      "(Training) Loss: 983570.0406\n",
      "(Validation) Loss: 1015107.2965, MAE: 3881.8826, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [3890/5000] | Time: 0.23s\n",
      "(Training) Loss: 977439.0019\n",
      "(Validation) Loss: 1014941.7752, MAE: 3878.2134, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [3891/5000] | Time: 0.20s\n",
      "(Training) Loss: 995068.1624\n",
      "(Validation) Loss: 1014793.2902, MAE: 3878.0811, R2: 0.1435\n",
      "==========================================================================================\n",
      "Epoch [3892/5000] | Time: 0.25s\n",
      "(Training) Loss: 976266.4435\n",
      "(Validation) Loss: 1014644.9422, MAE: 3879.0625, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [3893/5000] | Time: 0.23s\n",
      "(Training) Loss: 994535.0184\n",
      "(Validation) Loss: 1014596.0686, MAE: 3886.6228, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [3894/5000] | Time: 0.24s\n",
      "(Training) Loss: 978140.8499\n",
      "(Validation) Loss: 1014349.6381, MAE: 3882.1694, R2: 0.1439\n",
      "==========================================================================================\n",
      "Epoch [3895/5000] | Time: 0.27s\n",
      "(Training) Loss: 973656.4016\n",
      "(Validation) Loss: 1014141.9632, MAE: 3876.0400, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [3896/5000] | Time: 0.29s\n",
      "(Training) Loss: 990098.6225\n",
      "(Validation) Loss: 1013986.4432, MAE: 3874.0112, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [3897/5000] | Time: 0.25s\n",
      "(Training) Loss: 994061.9232\n",
      "(Validation) Loss: 1013822.9486, MAE: 3872.6213, R2: 0.1443\n",
      "==========================================================================================\n",
      "Epoch [3898/5000] | Time: 0.28s\n",
      "(Training) Loss: 985274.1459\n",
      "(Validation) Loss: 1013715.8705, MAE: 3875.7947, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [3899/5000] | Time: 0.29s\n",
      "(Training) Loss: 970658.1258\n",
      "(Validation) Loss: 1013595.2711, MAE: 3876.3931, R2: 0.1445\n",
      "==========================================================================================\n",
      "Epoch [3900/5000] | Time: 0.31s\n",
      "(Training) Loss: 970299.2765\n",
      "(Validation) Loss: 1013443.6978, MAE: 3875.9155, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [3901/5000] | Time: 0.27s\n",
      "(Training) Loss: 996117.8299\n",
      "(Validation) Loss: 1013292.0584, MAE: 3875.3289, R2: 0.1448\n",
      "==========================================================================================\n",
      "Epoch [3902/5000] | Time: 0.28s\n",
      "(Training) Loss: 983064.6453\n",
      "(Validation) Loss: 1013138.4025, MAE: 3875.7600, R2: 0.1449\n",
      "==========================================================================================\n",
      "Epoch [3903/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003853.5812\n",
      "(Validation) Loss: 1012983.8222, MAE: 3874.4302, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [3904/5000] | Time: 0.30s\n",
      "(Training) Loss: 981319.3369\n",
      "(Validation) Loss: 1012826.9410, MAE: 3873.6797, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [3905/5000] | Time: 0.25s\n",
      "(Training) Loss: 976821.0082\n",
      "(Validation) Loss: 1012672.2844, MAE: 3872.5859, R2: 0.1453\n",
      "==========================================================================================\n",
      "Epoch [3906/5000] | Time: 0.27s\n",
      "(Training) Loss: 985564.4518\n",
      "(Validation) Loss: 1012522.0876, MAE: 3873.6304, R2: 0.1454\n",
      "==========================================================================================\n",
      "Epoch [3907/5000] | Time: 0.31s\n",
      "(Training) Loss: 992799.3217\n",
      "(Validation) Loss: 1012369.6660, MAE: 3873.3162, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [3908/5000] | Time: 0.30s\n",
      "(Training) Loss: 985639.3274\n",
      "(Validation) Loss: 1012213.6381, MAE: 3872.5850, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [3909/5000] | Time: 0.29s\n",
      "(Training) Loss: 978846.0013\n",
      "(Validation) Loss: 1012059.4641, MAE: 3871.7798, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [3910/5000] | Time: 0.29s\n",
      "(Training) Loss: 979767.0190\n",
      "(Validation) Loss: 1011902.6743, MAE: 3870.8115, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [3911/5000] | Time: 0.38s\n",
      "(Training) Loss: 995634.1129\n",
      "(Validation) Loss: 1011764.1651, MAE: 3872.9268, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [3912/5000] | Time: 0.27s\n",
      "(Training) Loss: 1002554.3775\n",
      "(Validation) Loss: 1011596.5156, MAE: 3869.9221, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [3913/5000] | Time: 0.34s\n",
      "(Training) Loss: 992973.7081\n",
      "(Validation) Loss: 1011442.7733, MAE: 3869.1875, R2: 0.1463\n",
      "==========================================================================================\n",
      "Epoch [3914/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005634.7506\n",
      "(Validation) Loss: 1011289.2597, MAE: 3868.9563, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [3915/5000] | Time: 0.27s\n",
      "(Training) Loss: 983396.7468\n",
      "(Validation) Loss: 1011134.8724, MAE: 3868.5347, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [3916/5000] | Time: 0.24s\n",
      "(Training) Loss: 988721.0343\n",
      "(Validation) Loss: 1010977.3359, MAE: 3867.2053, R2: 0.1467\n",
      "==========================================================================================\n",
      "Epoch [3917/5000] | Time: 0.38s\n",
      "(Training) Loss: 980605.5850\n",
      "(Validation) Loss: 1010822.6997, MAE: 3866.5320, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [3918/5000] | Time: 0.31s\n",
      "(Training) Loss: 984513.3274\n",
      "(Validation) Loss: 1010670.9790, MAE: 3866.1572, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [3919/5000] | Time: 0.27s\n",
      "(Training) Loss: 982810.1009\n",
      "(Validation) Loss: 1010515.8959, MAE: 3865.5435, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [3920/5000] | Time: 0.30s\n",
      "(Training) Loss: 977122.4061\n",
      "(Validation) Loss: 1010362.8698, MAE: 3865.1177, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [3921/5000] | Time: 0.31s\n",
      "(Training) Loss: 964303.2849\n",
      "(Validation) Loss: 1002644.9422, MAE: 3846.7793, R2: 0.1536\n",
      "==========================================================================================\n",
      "Epoch [3922/5000] | Time: 0.29s\n",
      "(Training) Loss: 990461.8687\n",
      "(Validation) Loss: 1002500.5359, MAE: 3843.5701, R2: 0.1538\n",
      "==========================================================================================\n",
      "Epoch [3923/5000] | Time: 0.28s\n",
      "(Training) Loss: 975448.0622\n",
      "(Validation) Loss: 1002340.2971, MAE: 3839.9717, R2: 0.1539\n",
      "==========================================================================================\n",
      "Epoch [3924/5000] | Time: 0.24s\n",
      "(Training) Loss: 970353.0812\n",
      "(Validation) Loss: 1002199.1568, MAE: 3841.5229, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [3925/5000] | Time: 0.27s\n",
      "(Training) Loss: 992165.2094\n",
      "(Validation) Loss: 1002057.4629, MAE: 3840.6584, R2: 0.1541\n",
      "==========================================================================================\n",
      "Epoch [3926/5000] | Time: 0.25s\n",
      "(Training) Loss: 984818.8915\n",
      "(Validation) Loss: 1001901.0387, MAE: 3839.4609, R2: 0.1543\n",
      "==========================================================================================\n",
      "Epoch [3927/5000] | Time: 0.28s\n",
      "(Training) Loss: 973456.2253\n",
      "(Validation) Loss: 1001751.5733, MAE: 3840.2168, R2: 0.1544\n",
      "==========================================================================================\n",
      "Epoch [3928/5000] | Time: 0.24s\n",
      "(Training) Loss: 987277.6954\n",
      "(Validation) Loss: 1001602.9105, MAE: 3837.6323, R2: 0.1545\n",
      "==========================================================================================\n",
      "Epoch [3929/5000] | Time: 0.24s\n",
      "(Training) Loss: 996674.1003\n",
      "(Validation) Loss: 1001456.5130, MAE: 3837.6101, R2: 0.1546\n",
      "==========================================================================================\n",
      "Epoch [3930/5000] | Time: 0.26s\n",
      "(Training) Loss: 973135.6599\n",
      "(Validation) Loss: 1001313.0006, MAE: 3842.3101, R2: 0.1547\n",
      "==========================================================================================\n",
      "Epoch [3931/5000] | Time: 0.30s\n",
      "(Training) Loss: 990387.8959\n",
      "(Validation) Loss: 1001156.9473, MAE: 3837.7825, R2: 0.1549\n",
      "==========================================================================================\n",
      "Epoch [3932/5000] | Time: 0.27s\n",
      "(Training) Loss: 965491.7481\n",
      "(Validation) Loss: 1001010.7276, MAE: 3836.0479, R2: 0.1550\n",
      "==========================================================================================\n",
      "Epoch [3933/5000] | Time: 0.32s\n",
      "(Training) Loss: 988541.5266\n",
      "(Validation) Loss: 1000859.1086, MAE: 3834.7185, R2: 0.1551\n",
      "==========================================================================================\n",
      "Epoch [3934/5000] | Time: 0.29s\n",
      "(Training) Loss: 963078.5749\n",
      "(Validation) Loss: 1000712.2946, MAE: 3833.9993, R2: 0.1552\n",
      "==========================================================================================\n",
      "Epoch [3935/5000] | Time: 0.26s\n",
      "(Training) Loss: 979710.5571\n",
      "(Validation) Loss: 1000576.1727, MAE: 3835.8184, R2: 0.1554\n",
      "==========================================================================================\n",
      "Epoch [3936/5000] | Time: 0.25s\n",
      "(Training) Loss: 960916.0711\n",
      "(Validation) Loss: 1000417.7879, MAE: 3834.8743, R2: 0.1555\n",
      "==========================================================================================\n",
      "Epoch [3937/5000] | Time: 0.32s\n",
      "(Training) Loss: 971869.7747\n",
      "(Validation) Loss: 1000270.4254, MAE: 3834.1001, R2: 0.1556\n",
      "==========================================================================================\n",
      "Epoch [3938/5000] | Time: 0.32s\n",
      "(Training) Loss: 982165.7367\n",
      "(Validation) Loss: 1000124.2413, MAE: 3834.2280, R2: 0.1557\n",
      "==========================================================================================\n",
      "Epoch [3939/5000] | Time: 0.24s\n",
      "(Training) Loss: 959994.9803\n",
      "(Validation) Loss: 999973.2165, MAE: 3833.0056, R2: 0.1559\n",
      "==========================================================================================\n",
      "Epoch [3940/5000] | Time: 0.23s\n",
      "(Training) Loss: 967626.0952\n",
      "(Validation) Loss: 999825.7930, MAE: 3832.0657, R2: 0.1560\n",
      "==========================================================================================\n",
      "Epoch [3941/5000] | Time: 0.28s\n",
      "(Training) Loss: 977254.7170\n",
      "(Validation) Loss: 999678.1816, MAE: 3830.4543, R2: 0.1561\n",
      "==========================================================================================\n",
      "Epoch [3942/5000] | Time: 0.27s\n",
      "(Training) Loss: 999554.7275\n",
      "(Validation) Loss: 999531.0019, MAE: 3831.1099, R2: 0.1562\n",
      "==========================================================================================\n",
      "Epoch [3943/5000] | Time: 0.26s\n",
      "(Training) Loss: 968496.6510\n",
      "(Validation) Loss: 999386.9359, MAE: 3832.2031, R2: 0.1563\n",
      "==========================================================================================\n",
      "Epoch [3944/5000] | Time: 0.28s\n",
      "(Training) Loss: 963687.8940\n",
      "(Validation) Loss: 999230.0444, MAE: 3829.8062, R2: 0.1565\n",
      "==========================================================================================\n",
      "Epoch [3945/5000] | Time: 0.28s\n",
      "(Training) Loss: 963453.5444\n",
      "(Validation) Loss: 999093.8870, MAE: 3831.7502, R2: 0.1566\n",
      "==========================================================================================\n",
      "Epoch [3946/5000] | Time: 0.32s\n",
      "(Training) Loss: 962457.7674\n",
      "(Validation) Loss: 998939.3676, MAE: 3828.8264, R2: 0.1567\n",
      "==========================================================================================\n",
      "Epoch [3947/5000] | Time: 0.33s\n",
      "(Training) Loss: 987710.1891\n",
      "(Validation) Loss: 998802.4889, MAE: 3829.9607, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [3948/5000] | Time: 0.38s\n",
      "(Training) Loss: 957893.7843\n",
      "(Validation) Loss: 998645.6533, MAE: 3828.4204, R2: 0.1570\n",
      "==========================================================================================\n",
      "Epoch [3949/5000] | Time: 0.32s\n",
      "(Training) Loss: 977170.6015\n",
      "(Validation) Loss: 998498.3721, MAE: 3826.8438, R2: 0.1571\n",
      "==========================================================================================\n",
      "Epoch [3950/5000] | Time: 0.27s\n",
      "(Training) Loss: 979711.7919\n",
      "(Validation) Loss: 998350.2527, MAE: 3826.0845, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [3951/5000] | Time: 0.24s\n",
      "(Training) Loss: 968763.7792\n",
      "(Validation) Loss: 998204.5613, MAE: 3826.4607, R2: 0.1573\n",
      "==========================================================================================\n",
      "Epoch [3952/5000] | Time: 0.26s\n",
      "(Training) Loss: 976940.4841\n",
      "(Validation) Loss: 998052.1143, MAE: 3824.2666, R2: 0.1575\n",
      "==========================================================================================\n",
      "Epoch [3953/5000] | Time: 0.24s\n",
      "(Training) Loss: 972039.7221\n",
      "(Validation) Loss: 997907.5098, MAE: 3825.0891, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [3954/5000] | Time: 0.24s\n",
      "(Training) Loss: 985263.9137\n",
      "(Validation) Loss: 997759.9441, MAE: 3824.1169, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [3955/5000] | Time: 0.27s\n",
      "(Training) Loss: 962064.1694\n",
      "(Validation) Loss: 997636.3429, MAE: 3830.6416, R2: 0.1578\n",
      "==========================================================================================\n",
      "Epoch [3956/5000] | Time: 0.33s\n",
      "(Training) Loss: 964797.8458\n",
      "(Validation) Loss: 997464.8838, MAE: 3823.9937, R2: 0.1579\n",
      "==========================================================================================\n",
      "Epoch [3957/5000] | Time: 0.29s\n",
      "(Training) Loss: 967470.4791\n",
      "(Validation) Loss: 997319.7003, MAE: 3823.1931, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [3958/5000] | Time: 0.33s\n",
      "(Training) Loss: 992508.4245\n",
      "(Validation) Loss: 997166.1460, MAE: 3821.0400, R2: 0.1582\n",
      "==========================================================================================\n",
      "Epoch [3959/5000] | Time: 0.32s\n",
      "(Training) Loss: 955506.8849\n",
      "(Validation) Loss: 997013.7397, MAE: 3820.1438, R2: 0.1583\n",
      "==========================================================================================\n",
      "Epoch [3960/5000] | Time: 0.27s\n",
      "(Training) Loss: 957670.8864\n",
      "(Validation) Loss: 996870.6438, MAE: 3820.0183, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [3961/5000] | Time: 0.26s\n",
      "(Training) Loss: 979983.2519\n",
      "(Validation) Loss: 996722.8902, MAE: 3818.9888, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [3962/5000] | Time: 0.25s\n",
      "(Training) Loss: 956136.7202\n",
      "(Validation) Loss: 996583.8984, MAE: 3821.0635, R2: 0.1587\n",
      "==========================================================================================\n",
      "Epoch [3963/5000] | Time: 0.25s\n",
      "(Training) Loss: 974790.5051\n",
      "(Validation) Loss: 996434.3162, MAE: 3819.2937, R2: 0.1588\n",
      "==========================================================================================\n",
      "Epoch [3964/5000] | Time: 0.26s\n",
      "(Training) Loss: 973312.9023\n",
      "(Validation) Loss: 996280.3251, MAE: 3817.3074, R2: 0.1589\n",
      "==========================================================================================\n",
      "Epoch [3965/5000] | Time: 0.32s\n",
      "(Training) Loss: 962492.4848\n",
      "(Validation) Loss: 996141.3181, MAE: 3819.8572, R2: 0.1591\n",
      "==========================================================================================\n",
      "Epoch [3966/5000] | Time: 0.30s\n",
      "(Training) Loss: 970708.8477\n",
      "(Validation) Loss: 995985.5340, MAE: 3816.0732, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [3967/5000] | Time: 0.28s\n",
      "(Training) Loss: 966001.8680\n",
      "(Validation) Loss: 995862.7708, MAE: 3820.4009, R2: 0.1593\n",
      "==========================================================================================\n",
      "Epoch [3968/5000] | Time: 0.28s\n",
      "(Training) Loss: 976637.9600\n",
      "(Validation) Loss: 995695.5022, MAE: 3815.9209, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [3969/5000] | Time: 0.27s\n",
      "(Training) Loss: 982954.1720\n",
      "(Validation) Loss: 995549.8159, MAE: 3816.0254, R2: 0.1595\n",
      "==========================================================================================\n",
      "Epoch [3970/5000] | Time: 0.26s\n",
      "(Training) Loss: 975626.7982\n",
      "(Validation) Loss: 995392.8279, MAE: 3813.2803, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [3971/5000] | Time: 0.25s\n",
      "(Training) Loss: 970481.1567\n",
      "(Validation) Loss: 995249.3054, MAE: 3814.9070, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [3972/5000] | Time: 0.28s\n",
      "(Training) Loss: 963170.0964\n",
      "(Validation) Loss: 995097.6762, MAE: 3813.1567, R2: 0.1599\n",
      "==========================================================================================\n",
      "Epoch [3973/5000] | Time: 0.31s\n",
      "(Training) Loss: 979659.1865\n",
      "(Validation) Loss: 994958.3035, MAE: 3814.5144, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [3974/5000] | Time: 0.32s\n",
      "(Training) Loss: 972055.7773\n",
      "(Validation) Loss: 994805.7651, MAE: 3813.3835, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [3975/5000] | Time: 0.29s\n",
      "(Training) Loss: 969062.5184\n",
      "(Validation) Loss: 994661.1708, MAE: 3813.3159, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [3976/5000] | Time: 0.27s\n",
      "(Training) Loss: 976071.8230\n",
      "(Validation) Loss: 994512.1981, MAE: 3812.0508, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [3977/5000] | Time: 0.28s\n",
      "(Training) Loss: 961440.2563\n",
      "(Validation) Loss: 994356.6425, MAE: 3810.1428, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [3978/5000] | Time: 0.30s\n",
      "(Training) Loss: 963292.0076\n",
      "(Validation) Loss: 994212.3378, MAE: 3809.8127, R2: 0.1607\n",
      "==========================================================================================\n",
      "Epoch [3979/5000] | Time: 0.30s\n",
      "(Training) Loss: 971625.5838\n",
      "(Validation) Loss: 994074.2959, MAE: 3812.0144, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [3980/5000] | Time: 0.26s\n",
      "(Training) Loss: 978697.3852\n",
      "(Validation) Loss: 993915.7181, MAE: 3808.8035, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [3981/5000] | Time: 0.28s\n",
      "(Training) Loss: 969039.4175\n",
      "(Validation) Loss: 993780.3784, MAE: 3811.6677, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [3982/5000] | Time: 0.28s\n",
      "(Training) Loss: 954086.4940\n",
      "(Validation) Loss: 993626.4889, MAE: 3810.0620, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [3983/5000] | Time: 0.27s\n",
      "(Training) Loss: 954280.4588\n",
      "(Validation) Loss: 993481.7422, MAE: 3809.6526, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [3984/5000] | Time: 0.28s\n",
      "(Training) Loss: 951902.0370\n",
      "(Validation) Loss: 993332.6984, MAE: 3807.7393, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [3985/5000] | Time: 0.31s\n",
      "(Training) Loss: 973263.1865\n",
      "(Validation) Loss: 993186.6768, MAE: 3806.7188, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [3986/5000] | Time: 0.26s\n",
      "(Training) Loss: 954276.4610\n",
      "(Validation) Loss: 993035.8298, MAE: 3806.2915, R2: 0.1616\n",
      "==========================================================================================\n",
      "Epoch [3987/5000] | Time: 0.25s\n",
      "(Training) Loss: 964144.8008\n",
      "(Validation) Loss: 992888.7111, MAE: 3805.2983, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [3988/5000] | Time: 0.22s\n",
      "(Training) Loss: 968827.3528\n",
      "(Validation) Loss: 992744.6857, MAE: 3805.8486, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [3989/5000] | Time: 0.24s\n",
      "(Training) Loss: 956215.7088\n",
      "(Validation) Loss: 992598.0241, MAE: 3805.2175, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [3990/5000] | Time: 0.23s\n",
      "(Training) Loss: 976191.3807\n",
      "(Validation) Loss: 992455.6648, MAE: 3805.1289, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [3991/5000] | Time: 0.25s\n",
      "(Training) Loss: 964725.3985\n",
      "(Validation) Loss: 992307.8248, MAE: 3804.8088, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [3992/5000] | Time: 0.26s\n",
      "(Training) Loss: 971579.9505\n",
      "(Validation) Loss: 992150.1867, MAE: 3800.5493, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [3993/5000] | Time: 0.28s\n",
      "(Training) Loss: 984071.9695\n",
      "(Validation) Loss: 992008.5790, MAE: 3802.8193, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [3994/5000] | Time: 0.26s\n",
      "(Training) Loss: 962543.7316\n",
      "(Validation) Loss: 991853.0743, MAE: 3800.1873, R2: 0.1626\n",
      "==========================================================================================\n",
      "Epoch [3995/5000] | Time: 0.28s\n",
      "(Training) Loss: 964013.1053\n",
      "(Validation) Loss: 991712.6705, MAE: 3801.6780, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [3996/5000] | Time: 0.27s\n",
      "(Training) Loss: 955671.3566\n",
      "(Validation) Loss: 991568.5943, MAE: 3800.7896, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [3997/5000] | Time: 0.32s\n",
      "(Training) Loss: 952838.3484\n",
      "(Validation) Loss: 991414.2273, MAE: 3798.7861, R2: 0.1630\n",
      "==========================================================================================\n",
      "Epoch [3998/5000] | Time: 0.29s\n",
      "(Training) Loss: 974520.5419\n",
      "(Validation) Loss: 991279.4921, MAE: 3801.3877, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [3999/5000] | Time: 0.29s\n",
      "(Training) Loss: 962957.6079\n",
      "(Validation) Loss: 991128.2133, MAE: 3799.7266, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [4000/5000] | Time: 0.30s\n",
      "(Training) Loss: 954546.5057\n",
      "(Validation) Loss: 990976.0914, MAE: 3798.6663, R2: 0.1634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch4000.pth\n",
      "==========================================================================================\n",
      "Epoch [4001/5000] | Time: 0.31s\n",
      "(Training) Loss: 958936.6263\n",
      "(Validation) Loss: 990827.9263, MAE: 3797.0366, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [4002/5000] | Time: 0.33s\n",
      "(Training) Loss: 963485.8931\n",
      "(Validation) Loss: 990685.6076, MAE: 3798.1768, R2: 0.1636\n",
      "==========================================================================================\n",
      "Epoch [4003/5000] | Time: 0.32s\n",
      "(Training) Loss: 955868.0019\n",
      "(Validation) Loss: 990532.4190, MAE: 3794.4590, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [4004/5000] | Time: 0.33s\n",
      "(Training) Loss: 950785.4941\n",
      "(Validation) Loss: 990388.8406, MAE: 3794.7139, R2: 0.1638\n",
      "==========================================================================================\n",
      "Epoch [4005/5000] | Time: 0.31s\n",
      "(Training) Loss: 953569.0793\n",
      "(Validation) Loss: 990250.8648, MAE: 3797.4258, R2: 0.1640\n",
      "==========================================================================================\n",
      "Epoch [4006/5000] | Time: 0.28s\n",
      "(Training) Loss: 952726.8668\n",
      "(Validation) Loss: 990094.7200, MAE: 3793.6606, R2: 0.1641\n",
      "==========================================================================================\n",
      "Epoch [4007/5000] | Time: 0.28s\n",
      "(Training) Loss: 949824.4910\n",
      "(Validation) Loss: 989951.5429, MAE: 3793.9863, R2: 0.1642\n",
      "==========================================================================================\n",
      "Epoch [4008/5000] | Time: 0.28s\n",
      "(Training) Loss: 954972.7005\n",
      "(Validation) Loss: 989804.6019, MAE: 3792.5229, R2: 0.1643\n",
      "==========================================================================================\n",
      "Epoch [4009/5000] | Time: 0.32s\n",
      "(Training) Loss: 968124.6212\n",
      "(Validation) Loss: 989665.7829, MAE: 3793.9038, R2: 0.1644\n",
      "==========================================================================================\n",
      "Epoch [4010/5000] | Time: 0.30s\n",
      "(Training) Loss: 957554.3287\n",
      "(Validation) Loss: 989511.3752, MAE: 3791.2327, R2: 0.1646\n",
      "==========================================================================================\n",
      "Epoch [4011/5000] | Time: 0.27s\n",
      "(Training) Loss: 967308.9569\n",
      "(Validation) Loss: 989366.9943, MAE: 3792.2673, R2: 0.1647\n",
      "==========================================================================================\n",
      "Epoch [4012/5000] | Time: 0.31s\n",
      "(Training) Loss: 981294.3515\n",
      "(Validation) Loss: 989219.7943, MAE: 3790.9150, R2: 0.1648\n",
      "==========================================================================================\n",
      "Epoch [4013/5000] | Time: 0.30s\n",
      "(Training) Loss: 957372.6992\n",
      "(Validation) Loss: 989068.6933, MAE: 3790.1726, R2: 0.1649\n",
      "==========================================================================================\n",
      "Epoch [4014/5000] | Time: 0.34s\n",
      "(Training) Loss: 977355.4734\n",
      "(Validation) Loss: 988929.1683, MAE: 3791.1841, R2: 0.1651\n",
      "==========================================================================================\n",
      "Epoch [4015/5000] | Time: 0.32s\n",
      "(Training) Loss: 986091.3909\n",
      "(Validation) Loss: 988784.8889, MAE: 3791.8584, R2: 0.1652\n",
      "==========================================================================================\n",
      "Epoch [4016/5000] | Time: 0.30s\n",
      "(Training) Loss: 981314.7855\n",
      "(Validation) Loss: 988584.7771, MAE: 3787.2512, R2: 0.1654\n",
      "==========================================================================================\n",
      "Epoch [4017/5000] | Time: 0.30s\n",
      "(Training) Loss: 965809.0025\n",
      "(Validation) Loss: 988441.4832, MAE: 3790.8254, R2: 0.1655\n",
      "==========================================================================================\n",
      "Epoch [4018/5000] | Time: 0.29s\n",
      "(Training) Loss: 952067.2462\n",
      "(Validation) Loss: 988337.3460, MAE: 3789.7043, R2: 0.1656\n",
      "==========================================================================================\n",
      "Epoch [4019/5000] | Time: 0.30s\n",
      "(Training) Loss: 956337.9045\n",
      "(Validation) Loss: 988187.6165, MAE: 3787.3447, R2: 0.1657\n",
      "==========================================================================================\n",
      "Epoch [4020/5000] | Time: 0.30s\n",
      "(Training) Loss: 951786.8236\n",
      "(Validation) Loss: 988064.9600, MAE: 3799.5845, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [4021/5000] | Time: 0.29s\n",
      "(Training) Loss: 975031.2893\n",
      "(Validation) Loss: 995345.1378, MAE: 3822.3242, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [4022/5000] | Time: 0.28s\n",
      "(Training) Loss: 970833.2219\n",
      "(Validation) Loss: 995221.0235, MAE: 3825.5959, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [4023/5000] | Time: 0.27s\n",
      "(Training) Loss: 959341.5774\n",
      "(Validation) Loss: 995016.6400, MAE: 3813.9087, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [4024/5000] | Time: 0.25s\n",
      "(Training) Loss: 980156.4898\n",
      "(Validation) Loss: 994867.4438, MAE: 3812.9822, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [4025/5000] | Time: 0.29s\n",
      "(Training) Loss: 958005.6072\n",
      "(Validation) Loss: 994700.1194, MAE: 3809.5320, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [4026/5000] | Time: 0.26s\n",
      "(Training) Loss: 975948.7887\n",
      "(Validation) Loss: 994551.5429, MAE: 3810.5088, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [4027/5000] | Time: 0.26s\n",
      "(Training) Loss: 973147.8718\n",
      "(Validation) Loss: 994407.9746, MAE: 3811.9919, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [4028/5000] | Time: 0.27s\n",
      "(Training) Loss: 976752.2544\n",
      "(Validation) Loss: 994244.0889, MAE: 3809.5125, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [4029/5000] | Time: 0.26s\n",
      "(Training) Loss: 972601.8642\n",
      "(Validation) Loss: 994090.6870, MAE: 3808.2422, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [4030/5000] | Time: 0.27s\n",
      "(Training) Loss: 976866.2760\n",
      "(Validation) Loss: 993938.3517, MAE: 3808.1597, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [4031/5000] | Time: 0.25s\n",
      "(Training) Loss: 965744.6910\n",
      "(Validation) Loss: 993786.4889, MAE: 3809.8447, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [4032/5000] | Time: 0.29s\n",
      "(Training) Loss: 971725.4150\n",
      "(Validation) Loss: 993633.8286, MAE: 3808.8455, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [4033/5000] | Time: 0.28s\n",
      "(Training) Loss: 970925.2005\n",
      "(Validation) Loss: 993476.1397, MAE: 3806.8733, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [4034/5000] | Time: 0.27s\n",
      "(Training) Loss: 964592.1104\n",
      "(Validation) Loss: 993323.2051, MAE: 3806.5964, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [4035/5000] | Time: 0.27s\n",
      "(Training) Loss: 964437.0723\n",
      "(Validation) Loss: 993178.1587, MAE: 3806.4866, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [4036/5000] | Time: 0.28s\n",
      "(Training) Loss: 962608.4689\n",
      "(Validation) Loss: 993018.9867, MAE: 3804.6609, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [4037/5000] | Time: 0.27s\n",
      "(Training) Loss: 955072.7836\n",
      "(Validation) Loss: 992872.3302, MAE: 3804.9214, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [4038/5000] | Time: 0.24s\n",
      "(Training) Loss: 968436.1612\n",
      "(Validation) Loss: 992717.3943, MAE: 3803.3174, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [4039/5000] | Time: 0.25s\n",
      "(Training) Loss: 954934.2779\n",
      "(Validation) Loss: 992575.1619, MAE: 3805.1436, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [4040/5000] | Time: 0.21s\n",
      "(Training) Loss: 968450.4207\n",
      "(Validation) Loss: 992413.2267, MAE: 3802.0369, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [4041/5000] | Time: 0.23s\n",
      "(Training) Loss: 961832.7963\n",
      "(Validation) Loss: 992263.8781, MAE: 3802.4126, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [4042/5000] | Time: 0.21s\n",
      "(Training) Loss: 976178.4124\n",
      "(Validation) Loss: 992110.4559, MAE: 3800.3955, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [4043/5000] | Time: 0.22s\n",
      "(Training) Loss: 951317.0479\n",
      "(Validation) Loss: 991959.2381, MAE: 3802.2483, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [4044/5000] | Time: 0.26s\n",
      "(Training) Loss: 955382.9385\n",
      "(Validation) Loss: 991817.2394, MAE: 3801.5549, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [4045/5000] | Time: 0.21s\n",
      "(Training) Loss: 962399.4369\n",
      "(Validation) Loss: 991671.1365, MAE: 3802.8792, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [4046/5000] | Time: 0.24s\n",
      "(Training) Loss: 985275.2738\n",
      "(Validation) Loss: 991517.5162, MAE: 3800.6621, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [4047/5000] | Time: 0.25s\n",
      "(Training) Loss: 984466.5197\n",
      "(Validation) Loss: 991368.2083, MAE: 3801.4966, R2: 0.1630\n",
      "==========================================================================================\n",
      "Epoch [4048/5000] | Time: 0.22s\n",
      "(Training) Loss: 957441.0451\n",
      "(Validation) Loss: 991206.2425, MAE: 3797.6416, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [4049/5000] | Time: 0.27s\n",
      "(Training) Loss: 961618.0571\n",
      "(Validation) Loss: 991056.4521, MAE: 3800.2793, R2: 0.1633\n",
      "==========================================================================================\n",
      "Epoch [4050/5000] | Time: 0.25s\n",
      "(Training) Loss: 959082.8020\n",
      "(Validation) Loss: 990905.2597, MAE: 3796.5857, R2: 0.1634\n",
      "==========================================================================================\n",
      "Epoch [4051/5000] | Time: 0.26s\n",
      "(Training) Loss: 952014.9661\n",
      "(Validation) Loss: 990765.2470, MAE: 3798.9348, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [4052/5000] | Time: 0.22s\n",
      "(Training) Loss: 972249.2741\n",
      "(Validation) Loss: 990604.4597, MAE: 3795.2556, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [4053/5000] | Time: 0.23s\n",
      "(Training) Loss: 973128.3661\n",
      "(Validation) Loss: 1013230.5016, MAE: 3913.4727, R2: 0.1448\n",
      "==========================================================================================\n",
      "Epoch [4054/5000] | Time: 0.23s\n",
      "(Training) Loss: 985822.8896\n",
      "(Validation) Loss: 1013028.0025, MAE: 3887.7878, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [4055/5000] | Time: 0.27s\n",
      "(Training) Loss: 977768.8426\n",
      "(Validation) Loss: 1012865.0667, MAE: 3881.8774, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [4056/5000] | Time: 0.30s\n",
      "(Training) Loss: 983234.6796\n",
      "(Validation) Loss: 1012705.0159, MAE: 3877.3428, R2: 0.1452\n",
      "==========================================================================================\n",
      "Epoch [4057/5000] | Time: 0.22s\n",
      "(Training) Loss: 982458.5584\n",
      "(Validation) Loss: 1012544.7111, MAE: 3876.9832, R2: 0.1454\n",
      "==========================================================================================\n",
      "Epoch [4058/5000] | Time: 0.25s\n",
      "(Training) Loss: 975586.1434\n",
      "(Validation) Loss: 1012388.4495, MAE: 3876.0837, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [4059/5000] | Time: 0.27s\n",
      "(Training) Loss: 976195.0355\n",
      "(Validation) Loss: 1012236.0737, MAE: 3876.1777, R2: 0.1456\n",
      "==========================================================================================\n",
      "Epoch [4060/5000] | Time: 0.25s\n",
      "(Training) Loss: 977243.2684\n",
      "(Validation) Loss: 1012072.8076, MAE: 3874.7996, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [4061/5000] | Time: 0.27s\n",
      "(Training) Loss: 990168.6136\n",
      "(Validation) Loss: 1011930.2806, MAE: 3876.7983, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [4062/5000] | Time: 0.24s\n",
      "(Training) Loss: 984089.6396\n",
      "(Validation) Loss: 1011763.5810, MAE: 3874.6362, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [4063/5000] | Time: 0.28s\n",
      "(Training) Loss: 980454.9013\n",
      "(Validation) Loss: 1011606.8775, MAE: 3873.0959, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [4064/5000] | Time: 0.26s\n",
      "(Training) Loss: 987978.9810\n",
      "(Validation) Loss: 1011450.6108, MAE: 3872.7769, R2: 0.1463\n",
      "==========================================================================================\n",
      "Epoch [4065/5000] | Time: 0.28s\n",
      "(Training) Loss: 971518.5799\n",
      "(Validation) Loss: 1011295.4159, MAE: 3874.3982, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [4066/5000] | Time: 0.29s\n",
      "(Training) Loss: 985276.9594\n",
      "(Validation) Loss: 1011139.6063, MAE: 3870.6890, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [4067/5000] | Time: 0.25s\n",
      "(Training) Loss: 973478.9353\n",
      "(Validation) Loss: 1010985.0463, MAE: 3871.4014, R2: 0.1467\n",
      "==========================================================================================\n",
      "Epoch [4068/5000] | Time: 0.27s\n",
      "(Training) Loss: 987210.3020\n",
      "(Validation) Loss: 1010830.4356, MAE: 3871.5452, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [4069/5000] | Time: 0.25s\n",
      "(Training) Loss: 967878.3257\n",
      "(Validation) Loss: 1010675.0070, MAE: 3872.9185, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [4070/5000] | Time: 0.26s\n",
      "(Training) Loss: 994739.7576\n",
      "(Validation) Loss: 1010517.9835, MAE: 3868.6038, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [4071/5000] | Time: 0.27s\n",
      "(Training) Loss: 976891.1110\n",
      "(Validation) Loss: 1010373.8413, MAE: 3870.9324, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [4072/5000] | Time: 0.26s\n",
      "(Training) Loss: 984576.9296\n",
      "(Validation) Loss: 1010207.2381, MAE: 3868.1140, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [4073/5000] | Time: 0.27s\n",
      "(Training) Loss: 996213.1739\n",
      "(Validation) Loss: 1010050.1435, MAE: 3867.3032, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4074/5000] | Time: 0.26s\n",
      "(Training) Loss: 977956.2824\n",
      "(Validation) Loss: 1009898.8495, MAE: 3866.9475, R2: 0.1476\n",
      "==========================================================================================\n",
      "Epoch [4075/5000] | Time: 0.29s\n",
      "(Training) Loss: 969944.9410\n",
      "(Validation) Loss: 1009741.3232, MAE: 3866.4299, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4076/5000] | Time: 0.25s\n",
      "(Training) Loss: 986697.3249\n",
      "(Validation) Loss: 1009606.3289, MAE: 3870.1641, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [4077/5000] | Time: 0.25s\n",
      "(Training) Loss: 987918.9629\n",
      "(Validation) Loss: 1009432.6095, MAE: 3866.7878, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4078/5000] | Time: 0.26s\n",
      "(Training) Loss: 980183.8921\n",
      "(Validation) Loss: 1009276.3378, MAE: 3863.4626, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4079/5000] | Time: 0.30s\n",
      "(Training) Loss: 979860.9530\n",
      "(Validation) Loss: 1009124.0533, MAE: 3863.4578, R2: 0.1482\n",
      "==========================================================================================\n",
      "Epoch [4080/5000] | Time: 0.28s\n",
      "(Training) Loss: 966713.9960\n",
      "(Validation) Loss: 1008974.0089, MAE: 3864.8423, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4081/5000] | Time: 0.27s\n",
      "(Training) Loss: 988266.5286\n",
      "(Validation) Loss: 1008817.0006, MAE: 3863.4390, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4082/5000] | Time: 0.24s\n",
      "(Training) Loss: 974179.3255\n",
      "(Validation) Loss: 1008661.1657, MAE: 3861.7568, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4083/5000] | Time: 0.25s\n",
      "(Training) Loss: 994729.9162\n",
      "(Validation) Loss: 1008511.0654, MAE: 3862.5476, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4084/5000] | Time: 0.27s\n",
      "(Training) Loss: 977122.0501\n",
      "(Validation) Loss: 1008355.5606, MAE: 3861.6875, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4085/5000] | Time: 0.29s\n",
      "(Training) Loss: 978379.4207\n",
      "(Validation) Loss: 1008199.0146, MAE: 3860.7429, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [4086/5000] | Time: 0.30s\n",
      "(Training) Loss: 977100.6228\n",
      "(Validation) Loss: 1008054.2730, MAE: 3862.4639, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4087/5000] | Time: 0.26s\n",
      "(Training) Loss: 985803.6707\n",
      "(Validation) Loss: 1007894.9079, MAE: 3859.1653, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4088/5000] | Time: 0.30s\n",
      "(Training) Loss: 980304.4651\n",
      "(Validation) Loss: 1007743.3092, MAE: 3859.9468, R2: 0.1494\n",
      "==========================================================================================\n",
      "Epoch [4089/5000] | Time: 0.27s\n",
      "(Training) Loss: 976023.7839\n",
      "(Validation) Loss: 1007589.1352, MAE: 3858.8274, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4090/5000] | Time: 0.31s\n",
      "(Training) Loss: 978536.4264\n",
      "(Validation) Loss: 1007439.0806, MAE: 3859.1572, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [4091/5000] | Time: 0.26s\n",
      "(Training) Loss: 972926.0463\n",
      "(Validation) Loss: 1007279.8527, MAE: 3857.8323, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [4092/5000] | Time: 0.26s\n",
      "(Training) Loss: 970044.3115\n",
      "(Validation) Loss: 1007131.8197, MAE: 3856.9399, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [4093/5000] | Time: 0.23s\n",
      "(Training) Loss: 993766.5286\n",
      "(Validation) Loss: 1006979.1289, MAE: 3860.2561, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4094/5000] | Time: 0.25s\n",
      "(Training) Loss: 967952.4540\n",
      "(Validation) Loss: 1006822.6438, MAE: 3855.0574, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4095/5000] | Time: 0.25s\n",
      "(Training) Loss: 985060.7392\n",
      "(Validation) Loss: 1006671.7613, MAE: 3855.6836, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [4096/5000] | Time: 0.25s\n",
      "(Training) Loss: 965515.3715\n",
      "(Validation) Loss: 1006517.0337, MAE: 3855.8132, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [4097/5000] | Time: 0.25s\n",
      "(Training) Loss: 969912.7370\n",
      "(Validation) Loss: 1006363.4946, MAE: 3854.4832, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [4098/5000] | Time: 0.27s\n",
      "(Training) Loss: 981606.2703\n",
      "(Validation) Loss: 1006214.1511, MAE: 3855.2461, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [4099/5000] | Time: 0.24s\n",
      "(Training) Loss: 979527.8204\n",
      "(Validation) Loss: 1006060.0381, MAE: 3853.5498, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [4100/5000] | Time: 0.27s\n",
      "(Training) Loss: 994746.9220\n",
      "(Validation) Loss: 1005902.6743, MAE: 3854.7283, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [4101/5000] | Time: 0.25s\n",
      "(Training) Loss: 977756.1643\n",
      "(Validation) Loss: 1005751.1721, MAE: 3853.2473, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [4102/5000] | Time: 0.27s\n",
      "(Training) Loss: 968392.3598\n",
      "(Validation) Loss: 1005594.9613, MAE: 3851.1843, R2: 0.1512\n",
      "==========================================================================================\n",
      "Epoch [4103/5000] | Time: 0.25s\n",
      "(Training) Loss: 966024.1402\n",
      "(Validation) Loss: 1005441.5086, MAE: 3850.2629, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [4104/5000] | Time: 0.27s\n",
      "(Training) Loss: 968580.9784\n",
      "(Validation) Loss: 1005291.6876, MAE: 3850.1704, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [4105/5000] | Time: 0.25s\n",
      "(Training) Loss: 999909.5127\n",
      "(Validation) Loss: 1005141.0641, MAE: 3851.0073, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [4106/5000] | Time: 0.27s\n",
      "(Training) Loss: 974734.3147\n",
      "(Validation) Loss: 1004990.2070, MAE: 3850.9026, R2: 0.1517\n",
      "==========================================================================================\n",
      "Epoch [4107/5000] | Time: 0.29s\n",
      "(Training) Loss: 964063.6831\n",
      "(Validation) Loss: 1004829.3029, MAE: 3849.9563, R2: 0.1518\n",
      "==========================================================================================\n",
      "Epoch [4108/5000] | Time: 0.27s\n",
      "(Training) Loss: 968768.9600\n",
      "(Validation) Loss: 1004681.7930, MAE: 3850.2207, R2: 0.1519\n",
      "==========================================================================================\n",
      "Epoch [4109/5000] | Time: 0.27s\n",
      "(Training) Loss: 971929.5895\n",
      "(Validation) Loss: 1004529.0514, MAE: 3848.9871, R2: 0.1521\n",
      "==========================================================================================\n",
      "Epoch [4110/5000] | Time: 0.24s\n",
      "(Training) Loss: 969026.0717\n",
      "(Validation) Loss: 1004376.2794, MAE: 3847.2927, R2: 0.1522\n",
      "==========================================================================================\n",
      "Epoch [4111/5000] | Time: 0.23s\n",
      "(Training) Loss: 969352.2094\n",
      "(Validation) Loss: 1004222.8775, MAE: 3846.8835, R2: 0.1523\n",
      "==========================================================================================\n",
      "Epoch [4112/5000] | Time: 0.26s\n",
      "(Training) Loss: 964172.6009\n",
      "(Validation) Loss: 1004075.9771, MAE: 3846.8354, R2: 0.1524\n",
      "==========================================================================================\n",
      "Epoch [4113/5000] | Time: 0.24s\n",
      "(Training) Loss: 975210.9651\n",
      "(Validation) Loss: 1003922.5448, MAE: 3846.3701, R2: 0.1526\n",
      "==========================================================================================\n",
      "Epoch [4114/5000] | Time: 0.22s\n",
      "(Training) Loss: 968240.8883\n",
      "(Validation) Loss: 1003771.2965, MAE: 3847.1494, R2: 0.1527\n",
      "==========================================================================================\n",
      "Epoch [4115/5000] | Time: 0.20s\n",
      "(Training) Loss: 980835.6485\n",
      "(Validation) Loss: 1003619.3981, MAE: 3849.9482, R2: 0.1528\n",
      "==========================================================================================\n",
      "Epoch [4116/5000] | Time: 0.23s\n",
      "(Training) Loss: 970961.5850\n",
      "(Validation) Loss: 1003473.4019, MAE: 3848.8020, R2: 0.1529\n",
      "==========================================================================================\n",
      "Epoch [4117/5000] | Time: 0.21s\n",
      "(Training) Loss: 961635.4067\n",
      "(Validation) Loss: 1003326.1765, MAE: 3848.3337, R2: 0.1531\n",
      "==========================================================================================\n",
      "Epoch [4118/5000] | Time: 0.25s\n",
      "(Training) Loss: 969043.7824\n",
      "(Validation) Loss: 1003170.5549, MAE: 3846.8147, R2: 0.1532\n",
      "==========================================================================================\n",
      "Epoch [4119/5000] | Time: 0.23s\n",
      "(Training) Loss: 978619.3852\n",
      "(Validation) Loss: 1003010.3517, MAE: 3843.8232, R2: 0.1533\n",
      "==========================================================================================\n",
      "Epoch [4120/5000] | Time: 0.21s\n",
      "(Training) Loss: 981111.1631\n",
      "(Validation) Loss: 1002861.0235, MAE: 3844.6968, R2: 0.1534\n",
      "==========================================================================================\n",
      "Epoch [4121/5000] | Time: 0.23s\n",
      "(Training) Loss: 963914.4359\n",
      "(Validation) Loss: 1002704.9498, MAE: 3842.2463, R2: 0.1536\n",
      "==========================================================================================\n",
      "Epoch [4122/5000] | Time: 0.22s\n",
      "(Training) Loss: 972506.5926\n",
      "(Validation) Loss: 1002563.9568, MAE: 3845.3596, R2: 0.1537\n",
      "==========================================================================================\n",
      "Epoch [4123/5000] | Time: 0.21s\n",
      "(Training) Loss: 977120.6681\n",
      "(Validation) Loss: 1002402.4584, MAE: 3842.3435, R2: 0.1538\n",
      "==========================================================================================\n",
      "Epoch [4124/5000] | Time: 0.29s\n",
      "(Training) Loss: 980199.0899\n",
      "(Validation) Loss: 1002250.1638, MAE: 3841.7234, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [4125/5000] | Time: 0.31s\n",
      "(Training) Loss: 968779.4023\n",
      "(Validation) Loss: 1002008.2286, MAE: 3834.0000, R2: 0.1542\n",
      "==========================================================================================\n",
      "Epoch [4126/5000] | Time: 0.27s\n",
      "(Training) Loss: 979877.8915\n",
      "(Validation) Loss: 1001850.8089, MAE: 3836.2683, R2: 0.1543\n",
      "==========================================================================================\n",
      "Epoch [4127/5000] | Time: 0.23s\n",
      "(Training) Loss: 973473.0952\n",
      "(Validation) Loss: 1010483.5251, MAE: 3862.4644, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [4128/5000] | Time: 0.27s\n",
      "(Training) Loss: 979436.2678\n",
      "(Validation) Loss: 1010357.3181, MAE: 3866.2979, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [4129/5000] | Time: 0.23s\n",
      "(Training) Loss: 970164.8426\n",
      "(Validation) Loss: 1010182.2578, MAE: 3862.7598, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [4130/5000] | Time: 0.27s\n",
      "(Training) Loss: 985010.2284\n",
      "(Validation) Loss: 1010029.5568, MAE: 3865.3269, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4131/5000] | Time: 0.28s\n",
      "(Training) Loss: 989487.2525\n",
      "(Validation) Loss: 1009907.4794, MAE: 3871.4187, R2: 0.1476\n",
      "==========================================================================================\n",
      "Epoch [4132/5000] | Time: 0.21s\n",
      "(Training) Loss: 993526.2018\n",
      "(Validation) Loss: 1009711.9390, MAE: 3864.3022, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4133/5000] | Time: 0.25s\n",
      "(Training) Loss: 984501.6840\n",
      "(Validation) Loss: 1009549.4044, MAE: 3863.7185, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [4134/5000] | Time: 0.23s\n",
      "(Training) Loss: 979747.4385\n",
      "(Validation) Loss: 1009392.6552, MAE: 3864.0361, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4135/5000] | Time: 0.28s\n",
      "(Training) Loss: 976921.9638\n",
      "(Validation) Loss: 1009223.0603, MAE: 3860.0193, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4136/5000] | Time: 0.22s\n",
      "(Training) Loss: 975199.4099\n",
      "(Validation) Loss: 1009069.6432, MAE: 3860.9832, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [4137/5000] | Time: 0.25s\n",
      "(Training) Loss: 980258.0882\n",
      "(Validation) Loss: 1008902.3390, MAE: 3857.3882, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4138/5000] | Time: 0.22s\n",
      "(Training) Loss: 985154.9594\n",
      "(Validation) Loss: 1008744.8229, MAE: 3857.4524, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4139/5000] | Time: 0.24s\n",
      "(Training) Loss: 966363.6408\n",
      "(Validation) Loss: 1008586.1689, MAE: 3857.4609, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4140/5000] | Time: 0.21s\n",
      "(Training) Loss: 1000103.9645\n",
      "(Validation) Loss: 1008510.2629, MAE: 3864.0022, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4141/5000] | Time: 0.21s\n",
      "(Training) Loss: 974721.4150\n",
      "(Validation) Loss: 1008268.7746, MAE: 3856.3381, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4142/5000] | Time: 0.24s\n",
      "(Training) Loss: 989252.9124\n",
      "(Validation) Loss: 1008117.7346, MAE: 3858.0410, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4143/5000] | Time: 0.21s\n",
      "(Training) Loss: 991145.4473\n",
      "(Validation) Loss: 1007954.1994, MAE: 3855.0732, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4144/5000] | Time: 0.25s\n",
      "(Training) Loss: 967962.0419\n",
      "(Validation) Loss: 1007800.3657, MAE: 3856.1423, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4145/5000] | Time: 0.23s\n",
      "(Training) Loss: 985740.4277\n",
      "(Validation) Loss: 1007641.8692, MAE: 3854.0256, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4146/5000] | Time: 0.24s\n",
      "(Training) Loss: 966951.5878\n",
      "(Validation) Loss: 1013513.4984, MAE: 3873.9844, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [4147/5000] | Time: 0.30s\n",
      "(Training) Loss: 995552.1421\n",
      "(Validation) Loss: 1013356.5308, MAE: 3873.7378, R2: 0.1447\n",
      "==========================================================================================\n",
      "Epoch [4148/5000] | Time: 0.21s\n",
      "(Training) Loss: 984427.1631\n",
      "(Validation) Loss: 1013199.7054, MAE: 3876.8862, R2: 0.1448\n",
      "==========================================================================================\n",
      "Epoch [4149/5000] | Time: 0.33s\n",
      "(Training) Loss: 987707.4188\n",
      "(Validation) Loss: 1013037.0641, MAE: 3873.2290, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [4150/5000] | Time: 0.23s\n",
      "(Training) Loss: 983703.5571\n",
      "(Validation) Loss: 1012881.9657, MAE: 3871.6968, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [4151/5000] | Time: 0.24s\n",
      "(Training) Loss: 988983.0200\n",
      "(Validation) Loss: 1012719.2432, MAE: 3870.4841, R2: 0.1452\n",
      "==========================================================================================\n",
      "Epoch [4152/5000] | Time: 0.23s\n",
      "(Training) Loss: 980263.3287\n",
      "(Validation) Loss: 1012564.5054, MAE: 3872.4626, R2: 0.1454\n",
      "==========================================================================================\n",
      "Epoch [4153/5000] | Time: 0.27s\n",
      "(Training) Loss: 976657.6168\n",
      "(Validation) Loss: 1012408.3098, MAE: 3869.3989, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [4154/5000] | Time: 0.22s\n",
      "(Training) Loss: 996887.9702\n",
      "(Validation) Loss: 1012247.5022, MAE: 3867.4390, R2: 0.1456\n",
      "==========================================================================================\n",
      "Epoch [4155/5000] | Time: 0.27s\n",
      "(Training) Loss: 985416.0993\n",
      "(Validation) Loss: 1012091.6775, MAE: 3869.0234, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [4156/5000] | Time: 0.34s\n",
      "(Training) Loss: 996590.6104\n",
      "(Validation) Loss: 1011929.2292, MAE: 3866.7368, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [4157/5000] | Time: 0.25s\n",
      "(Training) Loss: 970353.5376\n",
      "(Validation) Loss: 1011771.0375, MAE: 3866.8591, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [4158/5000] | Time: 0.28s\n",
      "(Training) Loss: 973312.8896\n",
      "(Validation) Loss: 1011638.0292, MAE: 3868.5012, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [4159/5000] | Time: 0.31s\n",
      "(Training) Loss: 997567.9055\n",
      "(Validation) Loss: 1011462.7708, MAE: 3866.6272, R2: 0.1463\n",
      "==========================================================================================\n",
      "Epoch [4160/5000] | Time: 0.24s\n",
      "(Training) Loss: 982844.6616\n",
      "(Validation) Loss: 1011300.6273, MAE: 3864.6809, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [4161/5000] | Time: 0.29s\n",
      "(Training) Loss: 982586.8610\n",
      "(Validation) Loss: 1011148.6121, MAE: 3867.0479, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [4162/5000] | Time: 0.24s\n",
      "(Training) Loss: 980682.0397\n",
      "(Validation) Loss: 1010991.1771, MAE: 3866.1606, R2: 0.1467\n",
      "==========================================================================================\n",
      "Epoch [4163/5000] | Time: 0.26s\n",
      "(Training) Loss: 997808.8395\n",
      "(Validation) Loss: 1010836.3835, MAE: 3865.7805, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [4164/5000] | Time: 0.25s\n",
      "(Training) Loss: 984549.9454\n",
      "(Validation) Loss: 1010756.6781, MAE: 3874.7275, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [4165/5000] | Time: 0.31s\n",
      "(Training) Loss: 993764.5305\n",
      "(Validation) Loss: 1010518.8114, MAE: 3865.7412, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [4166/5000] | Time: 0.28s\n",
      "(Training) Loss: 970024.3813\n",
      "(Validation) Loss: 1010356.3886, MAE: 3864.1975, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [4167/5000] | Time: 0.26s\n",
      "(Training) Loss: 994007.8128\n",
      "(Validation) Loss: 1010205.1251, MAE: 3864.8074, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [4168/5000] | Time: 0.27s\n",
      "(Training) Loss: 988734.4048\n",
      "(Validation) Loss: 1010044.8406, MAE: 3864.2136, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4169/5000] | Time: 0.31s\n",
      "(Training) Loss: 1001667.3071\n",
      "(Validation) Loss: 1009920.6451, MAE: 3870.4155, R2: 0.1476\n",
      "==========================================================================================\n",
      "Epoch [4170/5000] | Time: 0.30s\n",
      "(Training) Loss: 988064.4530\n",
      "(Validation) Loss: 1009728.7263, MAE: 3863.4260, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4171/5000] | Time: 0.29s\n",
      "(Training) Loss: 983588.9854\n",
      "(Validation) Loss: 1009570.6870, MAE: 3861.3381, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [4172/5000] | Time: 0.29s\n",
      "(Training) Loss: 969031.5533\n",
      "(Validation) Loss: 1009412.2870, MAE: 3860.7622, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4173/5000] | Time: 0.25s\n",
      "(Training) Loss: 983713.8027\n",
      "(Validation) Loss: 1009263.9594, MAE: 3861.5571, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4174/5000] | Time: 0.22s\n",
      "(Training) Loss: 974074.9499\n",
      "(Validation) Loss: 1009104.1575, MAE: 3861.2788, R2: 0.1482\n",
      "==========================================================================================\n",
      "Epoch [4175/5000] | Time: 0.22s\n",
      "(Training) Loss: 976285.8204\n",
      "(Validation) Loss: 1008947.8654, MAE: 3859.5435, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4176/5000] | Time: 0.21s\n",
      "(Training) Loss: 973133.6212\n",
      "(Validation) Loss: 1008802.1587, MAE: 3863.9626, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4177/5000] | Time: 0.20s\n",
      "(Training) Loss: 1026307.2614\n",
      "(Validation) Loss: 1008650.6210, MAE: 3861.6418, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4178/5000] | Time: 0.28s\n",
      "(Training) Loss: 974986.7608\n",
      "(Validation) Loss: 1008476.8508, MAE: 3859.3196, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [4179/5000] | Time: 0.23s\n",
      "(Training) Loss: 975995.8572\n",
      "(Validation) Loss: 1008351.2990, MAE: 3863.5505, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4180/5000] | Time: 0.23s\n",
      "(Training) Loss: 1006620.0463\n",
      "(Validation) Loss: 1008174.3390, MAE: 3859.4055, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [4181/5000] | Time: 0.22s\n",
      "(Training) Loss: 972181.5635\n",
      "(Validation) Loss: 1008014.8876, MAE: 3857.5823, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4182/5000] | Time: 0.29s\n",
      "(Training) Loss: 970982.2792\n",
      "(Validation) Loss: 1007861.4044, MAE: 3857.2451, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4183/5000] | Time: 0.26s\n",
      "(Training) Loss: 1000792.3464\n",
      "(Validation) Loss: 1007714.0470, MAE: 3860.7053, R2: 0.1494\n",
      "==========================================================================================\n",
      "Epoch [4184/5000] | Time: 0.24s\n",
      "(Training) Loss: 983344.5971\n",
      "(Validation) Loss: 1007553.0311, MAE: 3857.2456, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4185/5000] | Time: 0.26s\n",
      "(Training) Loss: 969069.3039\n",
      "(Validation) Loss: 1007403.2254, MAE: 3858.1309, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [4186/5000] | Time: 0.26s\n",
      "(Training) Loss: 971114.6694\n",
      "(Validation) Loss: 1007272.5790, MAE: 3862.2920, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [4187/5000] | Time: 0.33s\n",
      "(Training) Loss: 965072.9047\n",
      "(Validation) Loss: 1007176.6349, MAE: 3861.5854, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [4188/5000] | Time: 0.36s\n",
      "(Training) Loss: 967512.5155\n",
      "(Validation) Loss: 1007022.8317, MAE: 3861.0728, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4189/5000] | Time: 0.38s\n",
      "(Training) Loss: 993911.7494\n",
      "(Validation) Loss: 1006885.9378, MAE: 3863.4854, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4190/5000] | Time: 0.35s\n",
      "(Training) Loss: 968205.3674\n",
      "(Validation) Loss: 1006707.6165, MAE: 3859.0251, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [4191/5000] | Time: 0.32s\n",
      "(Training) Loss: 979608.3572\n",
      "(Validation) Loss: 1006559.4057, MAE: 3861.4099, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [4192/5000] | Time: 0.28s\n",
      "(Training) Loss: 964456.2542\n",
      "(Validation) Loss: 1006405.7448, MAE: 3861.8066, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [4193/5000] | Time: 0.28s\n",
      "(Training) Loss: 974225.8672\n",
      "(Validation) Loss: 1006247.3041, MAE: 3857.4221, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [4194/5000] | Time: 0.28s\n",
      "(Training) Loss: 978662.7811\n",
      "(Validation) Loss: 1006091.5657, MAE: 3858.7009, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [4195/5000] | Time: 0.25s\n",
      "(Training) Loss: 971387.4975\n",
      "(Validation) Loss: 1005936.1524, MAE: 3856.8447, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [4196/5000] | Time: 0.28s\n",
      "(Training) Loss: 969618.6631\n",
      "(Validation) Loss: 1005784.1575, MAE: 3856.5378, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [4197/5000] | Time: 0.31s\n",
      "(Training) Loss: 996409.7367\n",
      "(Validation) Loss: 1005702.6743, MAE: 3863.7537, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [4198/5000] | Time: 0.30s\n",
      "(Training) Loss: 974394.1129\n",
      "(Validation) Loss: 1005465.6254, MAE: 3853.8499, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [4199/5000] | Time: 0.30s\n",
      "(Training) Loss: 972796.8642\n",
      "(Validation) Loss: 1005305.4781, MAE: 3853.9983, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [4200/5000] | Time: 0.24s\n",
      "(Training) Loss: 973005.7170\n",
      "(Validation) Loss: 1005160.3708, MAE: 3854.1577, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [4201/5000] | Time: 0.27s\n",
      "(Training) Loss: 989531.1485\n",
      "(Validation) Loss: 1005008.1117, MAE: 3853.9832, R2: 0.1517\n",
      "==========================================================================================\n",
      "Epoch [4202/5000] | Time: 0.26s\n",
      "(Training) Loss: 980625.7170\n",
      "(Validation) Loss: 1004850.5803, MAE: 3854.5232, R2: 0.1518\n",
      "==========================================================================================\n",
      "Epoch [4203/5000] | Time: 0.32s\n",
      "(Training) Loss: 981424.1003\n",
      "(Validation) Loss: 1004700.3429, MAE: 3854.0728, R2: 0.1519\n",
      "==========================================================================================\n",
      "Epoch [4204/5000] | Time: 0.26s\n",
      "(Training) Loss: 970584.5990\n",
      "(Validation) Loss: 1004533.3384, MAE: 3853.2812, R2: 0.1521\n",
      "==========================================================================================\n",
      "Epoch [4205/5000] | Time: 0.26s\n",
      "(Training) Loss: 975157.3687\n",
      "(Validation) Loss: 1004376.1524, MAE: 3849.3259, R2: 0.1522\n",
      "==========================================================================================\n",
      "Epoch [4206/5000] | Time: 0.28s\n",
      "(Training) Loss: 969605.2126\n",
      "(Validation) Loss: 1004222.3340, MAE: 3850.7212, R2: 0.1523\n",
      "==========================================================================================\n",
      "Epoch [4207/5000] | Time: 0.27s\n",
      "(Training) Loss: 982373.4185\n",
      "(Validation) Loss: 1004069.3029, MAE: 3849.7664, R2: 0.1524\n",
      "==========================================================================================\n",
      "Epoch [4208/5000] | Time: 0.26s\n",
      "(Training) Loss: 974492.5964\n",
      "(Validation) Loss: 1003909.3333, MAE: 3847.1714, R2: 0.1526\n",
      "==========================================================================================\n",
      "Epoch [4209/5000] | Time: 0.30s\n",
      "(Training) Loss: 983918.2402\n",
      "(Validation) Loss: 1003754.8546, MAE: 3845.9729, R2: 0.1527\n",
      "==========================================================================================\n",
      "Epoch [4210/5000] | Time: 0.29s\n",
      "(Training) Loss: 1009631.0844\n",
      "(Validation) Loss: 1003599.3194, MAE: 3846.3179, R2: 0.1528\n",
      "==========================================================================================\n",
      "Epoch [4211/5000] | Time: 0.32s\n",
      "(Training) Loss: 970532.2773\n",
      "(Validation) Loss: 1003449.5492, MAE: 3848.6741, R2: 0.1530\n",
      "==========================================================================================\n",
      "Epoch [4212/5000] | Time: 0.31s\n",
      "(Training) Loss: 967130.1536\n",
      "(Validation) Loss: 1003289.3206, MAE: 3846.3940, R2: 0.1531\n",
      "==========================================================================================\n",
      "Epoch [4213/5000] | Time: 0.26s\n",
      "(Training) Loss: 972723.3610\n",
      "(Validation) Loss: 1003132.9422, MAE: 3845.4727, R2: 0.1532\n",
      "==========================================================================================\n",
      "Epoch [4214/5000] | Time: 0.26s\n",
      "(Training) Loss: 967355.5133\n",
      "(Validation) Loss: 1002980.0990, MAE: 3847.0476, R2: 0.1533\n",
      "==========================================================================================\n",
      "Epoch [4215/5000] | Time: 0.30s\n",
      "(Training) Loss: 967140.6079\n",
      "(Validation) Loss: 1002841.4222, MAE: 3843.1746, R2: 0.1535\n",
      "==========================================================================================\n",
      "Epoch [4216/5000] | Time: 0.28s\n",
      "(Training) Loss: 972809.8674\n",
      "(Validation) Loss: 1002682.0368, MAE: 3845.4548, R2: 0.1536\n",
      "==========================================================================================\n",
      "Epoch [4217/5000] | Time: 0.25s\n",
      "(Training) Loss: 980528.7874\n",
      "(Validation) Loss: 1002512.2337, MAE: 3842.8713, R2: 0.1537\n",
      "==========================================================================================\n",
      "Epoch [4218/5000] | Time: 0.34s\n",
      "(Training) Loss: 971402.2805\n",
      "(Validation) Loss: 1002362.0267, MAE: 3844.0024, R2: 0.1539\n",
      "==========================================================================================\n",
      "Epoch [4219/5000] | Time: 0.27s\n",
      "(Training) Loss: 976179.0336\n",
      "(Validation) Loss: 1002206.7657, MAE: 3845.4182, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [4220/5000] | Time: 0.32s\n",
      "(Training) Loss: 977843.2138\n",
      "(Validation) Loss: 1002054.4610, MAE: 3843.7910, R2: 0.1541\n",
      "==========================================================================================\n",
      "Epoch [4221/5000] | Time: 0.32s\n",
      "(Training) Loss: 964224.3154\n",
      "(Validation) Loss: 1001897.8489, MAE: 3842.5264, R2: 0.1543\n",
      "==========================================================================================\n",
      "Epoch [4222/5000] | Time: 0.27s\n",
      "(Training) Loss: 976161.9822\n",
      "(Validation) Loss: 1001745.0210, MAE: 3842.1682, R2: 0.1544\n",
      "==========================================================================================\n",
      "Epoch [4223/5000] | Time: 0.28s\n",
      "(Training) Loss: 973281.0539\n",
      "(Validation) Loss: 1001587.6013, MAE: 3841.3447, R2: 0.1545\n",
      "==========================================================================================\n",
      "Epoch [4224/5000] | Time: 0.27s\n",
      "(Training) Loss: 1006802.8395\n",
      "(Validation) Loss: 1001443.7283, MAE: 3843.7375, R2: 0.1546\n",
      "==========================================================================================\n",
      "Epoch [4225/5000] | Time: 0.26s\n",
      "(Training) Loss: 968260.8445\n",
      "(Validation) Loss: 1001270.5270, MAE: 3838.5571, R2: 0.1548\n",
      "==========================================================================================\n",
      "Epoch [4226/5000] | Time: 0.30s\n",
      "(Training) Loss: 989592.0971\n",
      "(Validation) Loss: 1001113.6610, MAE: 3837.2107, R2: 0.1549\n",
      "==========================================================================================\n",
      "Epoch [4227/5000] | Time: 0.28s\n",
      "(Training) Loss: 967630.7760\n",
      "(Validation) Loss: 1000954.3670, MAE: 3837.0447, R2: 0.1550\n",
      "==========================================================================================\n",
      "Epoch [4228/5000] | Time: 0.24s\n",
      "(Training) Loss: 991583.1383\n",
      "(Validation) Loss: 1000829.7041, MAE: 3837.1812, R2: 0.1551\n",
      "==========================================================================================\n",
      "Epoch [4229/5000] | Time: 0.27s\n",
      "(Training) Loss: 978979.2392\n",
      "(Validation) Loss: 1000653.2825, MAE: 3837.3079, R2: 0.1553\n",
      "==========================================================================================\n",
      "Epoch [4230/5000] | Time: 0.27s\n",
      "(Training) Loss: 972393.5888\n",
      "(Validation) Loss: 1015601.0159, MAE: 3900.9294, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [4231/5000] | Time: 0.28s\n",
      "(Training) Loss: 974359.3433\n",
      "(Validation) Loss: 1015452.6171, MAE: 3895.0083, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [4232/5000] | Time: 0.23s\n",
      "(Training) Loss: 986658.3655\n",
      "(Validation) Loss: 1015197.9479, MAE: 3887.1396, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [4233/5000] | Time: 0.24s\n",
      "(Training) Loss: 992130.1516\n",
      "(Validation) Loss: 1015077.4857, MAE: 3887.3247, R2: 0.1433\n",
      "==========================================================================================\n",
      "Epoch [4234/5000] | Time: 0.22s\n",
      "(Training) Loss: 977605.0584\n",
      "(Validation) Loss: 1014866.1486, MAE: 3883.4468, R2: 0.1435\n",
      "==========================================================================================\n",
      "Epoch [4235/5000] | Time: 0.24s\n",
      "(Training) Loss: 982005.3477\n",
      "(Validation) Loss: 1014700.8914, MAE: 3878.8901, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [4236/5000] | Time: 0.25s\n",
      "(Training) Loss: 985637.5254\n",
      "(Validation) Loss: 1014546.7175, MAE: 3877.8259, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [4237/5000] | Time: 0.23s\n",
      "(Training) Loss: 994915.0558\n",
      "(Validation) Loss: 1014394.3771, MAE: 3877.2322, R2: 0.1438\n",
      "==========================================================================================\n",
      "Epoch [4238/5000] | Time: 0.24s\n",
      "(Training) Loss: 993154.2297\n",
      "(Validation) Loss: 1014239.3295, MAE: 3876.5955, R2: 0.1440\n",
      "==========================================================================================\n",
      "Epoch [4239/5000] | Time: 0.26s\n",
      "(Training) Loss: 975085.4353\n",
      "(Validation) Loss: 1014077.5975, MAE: 3874.7209, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [4240/5000] | Time: 0.21s\n",
      "(Training) Loss: 984943.3436\n",
      "(Validation) Loss: 1013942.4356, MAE: 3878.9756, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [4241/5000] | Time: 0.22s\n",
      "(Training) Loss: 983398.6812\n",
      "(Validation) Loss: 1013776.5587, MAE: 3876.7317, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [4242/5000] | Time: 0.24s\n",
      "(Training) Loss: 988742.4099\n",
      "(Validation) Loss: 1013676.3937, MAE: 3879.6028, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [4243/5000] | Time: 0.24s\n",
      "(Training) Loss: 977045.0844\n",
      "(Validation) Loss: 1013521.6406, MAE: 3878.7349, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [4244/5000] | Time: 0.27s\n",
      "(Training) Loss: 986658.5812\n",
      "(Validation) Loss: 1013378.2959, MAE: 3880.4417, R2: 0.1447\n",
      "==========================================================================================\n",
      "Epoch [4245/5000] | Time: 0.29s\n",
      "(Training) Loss: 1001989.1041\n",
      "(Validation) Loss: 1013215.5175, MAE: 3877.9023, R2: 0.1448\n",
      "==========================================================================================\n",
      "Epoch [4246/5000] | Time: 0.26s\n",
      "(Training) Loss: 971956.6758\n",
      "(Validation) Loss: 1013053.9327, MAE: 3876.2295, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [4247/5000] | Time: 0.29s\n",
      "(Training) Loss: 979916.4074\n",
      "(Validation) Loss: 1012896.2235, MAE: 3874.4885, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [4248/5000] | Time: 0.28s\n",
      "(Training) Loss: 997363.9226\n",
      "(Validation) Loss: 1012743.0603, MAE: 3874.6692, R2: 0.1452\n",
      "==========================================================================================\n",
      "Epoch [4249/5000] | Time: 0.28s\n",
      "(Training) Loss: 1001623.6193\n",
      "(Validation) Loss: 1012601.9302, MAE: 3877.5420, R2: 0.1453\n",
      "==========================================================================================\n",
      "Epoch [4250/5000] | Time: 0.27s\n",
      "(Training) Loss: 998108.2113\n",
      "(Validation) Loss: 1012434.3416, MAE: 3873.7244, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [4251/5000] | Time: 0.24s\n",
      "(Training) Loss: 985662.1942\n",
      "(Validation) Loss: 1012279.3397, MAE: 3873.7493, R2: 0.1456\n",
      "==========================================================================================\n",
      "Epoch [4252/5000] | Time: 0.28s\n",
      "(Training) Loss: 990736.4397\n",
      "(Validation) Loss: 1012124.4597, MAE: 3872.8745, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [4253/5000] | Time: 0.31s\n",
      "(Training) Loss: 994496.6180\n",
      "(Validation) Loss: 1011977.4679, MAE: 3873.8477, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [4254/5000] | Time: 0.28s\n",
      "(Training) Loss: 974114.2265\n",
      "(Validation) Loss: 1011826.4483, MAE: 3874.8306, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [4255/5000] | Time: 0.26s\n",
      "(Training) Loss: 969670.1050\n",
      "(Validation) Loss: 1011663.1162, MAE: 3870.8416, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [4256/5000] | Time: 0.32s\n",
      "(Training) Loss: 1002903.7525\n",
      "(Validation) Loss: 1011517.7295, MAE: 3871.8274, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [4257/5000] | Time: 0.29s\n",
      "(Training) Loss: 999592.0571\n",
      "(Validation) Loss: 1011360.2895, MAE: 3872.0461, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [4258/5000] | Time: 0.27s\n",
      "(Training) Loss: 997058.0984\n",
      "(Validation) Loss: 1011209.3867, MAE: 3872.2463, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [4259/5000] | Time: 0.30s\n",
      "(Training) Loss: 977971.4651\n",
      "(Validation) Loss: 1011048.5638, MAE: 3870.4492, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [4260/5000] | Time: 0.27s\n",
      "(Training) Loss: 996585.7627\n",
      "(Validation) Loss: 1010892.5562, MAE: 3868.9517, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [4261/5000] | Time: 0.29s\n",
      "(Training) Loss: 986864.6434\n",
      "(Validation) Loss: 1010737.7879, MAE: 3869.0930, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [4262/5000] | Time: 0.30s\n",
      "(Training) Loss: 970797.7167\n",
      "(Validation) Loss: 1010597.7702, MAE: 3871.4038, R2: 0.1470\n",
      "==========================================================================================\n",
      "Epoch [4263/5000] | Time: 0.30s\n",
      "(Training) Loss: 982393.2069\n",
      "(Validation) Loss: 1010434.3365, MAE: 3867.6997, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [4264/5000] | Time: 0.27s\n",
      "(Training) Loss: 987392.2532\n",
      "(Validation) Loss: 1010292.5054, MAE: 3869.1650, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [4265/5000] | Time: 0.27s\n",
      "(Training) Loss: 973020.9575\n",
      "(Validation) Loss: 1010135.5581, MAE: 3868.5864, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [4266/5000] | Time: 0.32s\n",
      "(Training) Loss: 976147.9810\n",
      "(Validation) Loss: 1009974.3695, MAE: 3865.5984, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4267/5000] | Time: 0.32s\n",
      "(Training) Loss: 984126.0774\n",
      "(Validation) Loss: 1009816.0457, MAE: 3864.1558, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4268/5000] | Time: 0.33s\n",
      "(Training) Loss: 979352.9315\n",
      "(Validation) Loss: 1009676.7390, MAE: 3866.0334, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [4269/5000] | Time: 0.27s\n",
      "(Training) Loss: 1007181.4340\n",
      "(Validation) Loss: 1009532.3429, MAE: 3867.7063, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [4270/5000] | Time: 0.30s\n",
      "(Training) Loss: 990797.6681\n",
      "(Validation) Loss: 1009359.9238, MAE: 3863.3542, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4271/5000] | Time: 0.28s\n",
      "(Training) Loss: 991751.6129\n",
      "(Validation) Loss: 1009236.0990, MAE: 3867.5393, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4272/5000] | Time: 0.30s\n",
      "(Training) Loss: 972911.3388\n",
      "(Validation) Loss: 1009063.7562, MAE: 3866.6101, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [4273/5000] | Time: 0.28s\n",
      "(Training) Loss: 971879.3008\n",
      "(Validation) Loss: 1008912.8533, MAE: 3864.4717, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4274/5000] | Time: 0.27s\n",
      "(Training) Loss: 990445.6789\n",
      "(Validation) Loss: 1008749.6178, MAE: 3861.0952, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4275/5000] | Time: 0.28s\n",
      "(Training) Loss: 965844.2199\n",
      "(Validation) Loss: 1008604.4444, MAE: 3863.0139, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4276/5000] | Time: 0.30s\n",
      "(Training) Loss: 966903.4905\n",
      "(Validation) Loss: 1008457.2292, MAE: 3864.2197, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [4277/5000] | Time: 0.29s\n",
      "(Training) Loss: 980367.3642\n",
      "(Validation) Loss: 1008296.8533, MAE: 3860.9341, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4278/5000] | Time: 0.29s\n",
      "(Training) Loss: 973989.7234\n",
      "(Validation) Loss: 1008140.3429, MAE: 3859.2412, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4279/5000] | Time: 0.32s\n",
      "(Training) Loss: 983597.3154\n",
      "(Validation) Loss: 1008004.6121, MAE: 3862.6907, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4280/5000] | Time: 0.32s\n",
      "(Training) Loss: 978413.5368\n",
      "(Validation) Loss: 1007838.4914, MAE: 3859.0247, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4281/5000] | Time: 0.30s\n",
      "(Training) Loss: 971557.7253\n",
      "(Validation) Loss: 1007803.9416, MAE: 3870.8267, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4282/5000] | Time: 0.28s\n",
      "(Training) Loss: 970744.6301\n",
      "(Validation) Loss: 1007639.4260, MAE: 3866.5144, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4283/5000] | Time: 0.30s\n",
      "(Training) Loss: 972184.0044\n",
      "(Validation) Loss: 1007496.0610, MAE: 3870.1184, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [4284/5000] | Time: 0.32s\n",
      "(Training) Loss: 965618.3588\n",
      "(Validation) Loss: 1007362.8495, MAE: 3872.2393, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [4285/5000] | Time: 0.31s\n",
      "(Training) Loss: 969316.7310\n",
      "(Validation) Loss: 1007184.7111, MAE: 3864.7371, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [4286/5000] | Time: 0.34s\n",
      "(Training) Loss: 977455.3579\n",
      "(Validation) Loss: 1007045.1098, MAE: 3867.5457, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4287/5000] | Time: 0.29s\n",
      "(Training) Loss: 984080.2119\n",
      "(Validation) Loss: 1006889.1683, MAE: 3871.2725, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4288/5000] | Time: 0.30s\n",
      "(Training) Loss: 965671.6758\n",
      "(Validation) Loss: 1006728.9143, MAE: 3868.9094, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [4289/5000] | Time: 0.34s\n",
      "(Training) Loss: 998671.8261\n",
      "(Validation) Loss: 1006579.6063, MAE: 3866.3149, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [4290/5000] | Time: 0.31s\n",
      "(Training) Loss: 1001154.0958\n",
      "(Validation) Loss: 1006430.4610, MAE: 3865.2126, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [4291/5000] | Time: 0.35s\n",
      "(Training) Loss: 964437.2644\n",
      "(Validation) Loss: 1028938.2349, MAE: 3953.2920, R2: 0.1317\n",
      "==========================================================================================\n",
      "Epoch [4292/5000] | Time: 0.33s\n",
      "(Training) Loss: 1031357.1834\n",
      "(Validation) Loss: 1033547.1949, MAE: 3952.6174, R2: 0.1279\n",
      "==========================================================================================\n",
      "Epoch [4293/5000] | Time: 0.28s\n",
      "(Training) Loss: 996148.3598\n",
      "(Validation) Loss: 1033363.2356, MAE: 3949.0710, R2: 0.1280\n",
      "==========================================================================================\n",
      "Epoch [4294/5000] | Time: 0.36s\n",
      "(Training) Loss: 1010248.4258\n",
      "(Validation) Loss: 1033222.8825, MAE: 3954.7168, R2: 0.1281\n",
      "==========================================================================================\n",
      "Epoch [4295/5000] | Time: 0.34s\n",
      "(Training) Loss: 1013572.9784\n",
      "(Validation) Loss: 1033054.4203, MAE: 3952.5063, R2: 0.1283\n",
      "==========================================================================================\n",
      "Epoch [4296/5000] | Time: 0.31s\n",
      "(Training) Loss: 996762.6282\n",
      "(Validation) Loss: 1032876.8254, MAE: 3947.1165, R2: 0.1284\n",
      "==========================================================================================\n",
      "Epoch [4297/5000] | Time: 0.28s\n",
      "(Training) Loss: 997320.7322\n",
      "(Validation) Loss: 1032722.6768, MAE: 3948.5605, R2: 0.1286\n",
      "==========================================================================================\n",
      "Epoch [4298/5000] | Time: 0.30s\n",
      "(Training) Loss: 1002721.7500\n",
      "(Validation) Loss: 1032560.2946, MAE: 3947.1165, R2: 0.1287\n",
      "==========================================================================================\n",
      "Epoch [4299/5000] | Time: 0.34s\n",
      "(Training) Loss: 998356.9067\n",
      "(Validation) Loss: 1032399.4921, MAE: 3946.3423, R2: 0.1288\n",
      "==========================================================================================\n",
      "Epoch [4300/5000] | Time: 0.30s\n",
      "(Training) Loss: 1013324.1869\n",
      "(Validation) Loss: 1032230.9537, MAE: 3942.4861, R2: 0.1290\n",
      "==========================================================================================\n",
      "Epoch [4301/5000] | Time: 0.31s\n",
      "(Training) Loss: 1002676.7291\n",
      "(Validation) Loss: 1032071.4210, MAE: 3941.7761, R2: 0.1291\n",
      "==========================================================================================\n",
      "Epoch [4302/5000] | Time: 0.29s\n",
      "(Training) Loss: 999122.5463\n",
      "(Validation) Loss: 1031916.1448, MAE: 3942.8530, R2: 0.1292\n",
      "==========================================================================================\n",
      "Epoch [4303/5000] | Time: 0.32s\n",
      "(Training) Loss: 1003977.4105\n",
      "(Validation) Loss: 1031765.3283, MAE: 3942.8025, R2: 0.1294\n",
      "==========================================================================================\n",
      "Epoch [4304/5000] | Time: 0.30s\n",
      "(Training) Loss: 1009157.5590\n",
      "(Validation) Loss: 1031599.4870, MAE: 3941.6553, R2: 0.1295\n",
      "==========================================================================================\n",
      "Epoch [4305/5000] | Time: 0.33s\n",
      "(Training) Loss: 995890.4607\n",
      "(Validation) Loss: 1031451.4641, MAE: 3944.0327, R2: 0.1296\n",
      "==========================================================================================\n",
      "Epoch [4306/5000] | Time: 0.31s\n",
      "(Training) Loss: 1011295.6681\n",
      "(Validation) Loss: 1031287.6648, MAE: 3940.8101, R2: 0.1298\n",
      "==========================================================================================\n",
      "Epoch [4307/5000] | Time: 0.28s\n",
      "(Training) Loss: 1007550.3166\n",
      "(Validation) Loss: 1031129.3613, MAE: 3939.6968, R2: 0.1299\n",
      "==========================================================================================\n",
      "Epoch [4308/5000] | Time: 0.32s\n",
      "(Training) Loss: 993732.8331\n",
      "(Validation) Loss: 1030973.1403, MAE: 3939.8169, R2: 0.1300\n",
      "==========================================================================================\n",
      "Epoch [4309/5000] | Time: 0.32s\n",
      "(Training) Loss: 1009415.2636\n",
      "(Validation) Loss: 1030841.9606, MAE: 3944.8259, R2: 0.1301\n",
      "==========================================================================================\n",
      "Epoch [4310/5000] | Time: 0.31s\n",
      "(Training) Loss: 989204.0425\n",
      "(Validation) Loss: 1030660.2667, MAE: 3938.4304, R2: 0.1303\n",
      "==========================================================================================\n",
      "Epoch [4311/5000] | Time: 0.35s\n",
      "(Training) Loss: 986248.5031\n",
      "(Validation) Loss: 1030589.7448, MAE: 3950.2158, R2: 0.1303\n",
      "==========================================================================================\n",
      "Epoch [4312/5000] | Time: 0.33s\n",
      "(Training) Loss: 1017731.8617\n",
      "(Validation) Loss: 1030351.0248, MAE: 3937.0144, R2: 0.1305\n",
      "==========================================================================================\n",
      "Epoch [4313/5000] | Time: 0.30s\n",
      "(Training) Loss: 1001109.6028\n",
      "(Validation) Loss: 1030198.7352, MAE: 3937.0098, R2: 0.1307\n",
      "==========================================================================================\n",
      "Epoch [4314/5000] | Time: 0.29s\n",
      "(Training) Loss: 1004656.0666\n",
      "(Validation) Loss: 1030041.3410, MAE: 3936.5242, R2: 0.1308\n",
      "==========================================================================================\n",
      "Epoch [4315/5000] | Time: 0.28s\n",
      "(Training) Loss: 1008857.2589\n",
      "(Validation) Loss: 1029881.7575, MAE: 3934.3882, R2: 0.1309\n",
      "==========================================================================================\n",
      "Epoch [4316/5000] | Time: 0.33s\n",
      "(Training) Loss: 1009852.4937\n",
      "(Validation) Loss: 1029723.1390, MAE: 3933.6726, R2: 0.1311\n",
      "==========================================================================================\n",
      "Epoch [4317/5000] | Time: 0.38s\n",
      "(Training) Loss: 1001857.1980\n",
      "(Validation) Loss: 1029569.8387, MAE: 3933.7566, R2: 0.1312\n",
      "==========================================================================================\n",
      "Epoch [4318/5000] | Time: 0.33s\n",
      "(Training) Loss: 1002409.5825\n",
      "(Validation) Loss: 1029471.4006, MAE: 3944.3259, R2: 0.1313\n",
      "==========================================================================================\n",
      "Epoch [4319/5000] | Time: 0.48s\n",
      "(Training) Loss: 992817.0666\n",
      "(Validation) Loss: 1029270.8114, MAE: 3934.7476, R2: 0.1314\n",
      "==========================================================================================\n",
      "Epoch [4320/5000] | Time: 0.31s\n",
      "(Training) Loss: 984789.8417\n",
      "(Validation) Loss: 1029101.1251, MAE: 3931.9124, R2: 0.1316\n",
      "==========================================================================================\n",
      "Epoch [4321/5000] | Time: 0.28s\n",
      "(Training) Loss: 994702.3985\n",
      "(Validation) Loss: 1028950.0698, MAE: 3931.9009, R2: 0.1317\n",
      "==========================================================================================\n",
      "Epoch [4322/5000] | Time: 0.36s\n",
      "(Training) Loss: 989821.7132\n",
      "(Validation) Loss: 1028793.6051, MAE: 3930.2593, R2: 0.1318\n",
      "==========================================================================================\n",
      "Epoch [4323/5000] | Time: 0.30s\n",
      "(Training) Loss: 1000480.5330\n",
      "(Validation) Loss: 1028641.0819, MAE: 3929.2449, R2: 0.1320\n",
      "==========================================================================================\n",
      "Epoch [4324/5000] | Time: 0.20s\n",
      "(Training) Loss: 1003265.2836\n",
      "(Validation) Loss: 1028491.9365, MAE: 3931.3784, R2: 0.1321\n",
      "==========================================================================================\n",
      "Epoch [4325/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004949.7868\n",
      "(Validation) Loss: 1028333.9733, MAE: 3928.6240, R2: 0.1322\n",
      "==========================================================================================\n",
      "Epoch [4326/5000] | Time: 0.24s\n",
      "(Training) Loss: 1000120.8128\n",
      "(Validation) Loss: 1028178.0825, MAE: 3928.1248, R2: 0.1324\n",
      "==========================================================================================\n",
      "Epoch [4327/5000] | Time: 0.26s\n",
      "(Training) Loss: 1027847.7722\n",
      "(Validation) Loss: 1028024.3454, MAE: 3928.1470, R2: 0.1325\n",
      "==========================================================================================\n",
      "Epoch [4328/5000] | Time: 0.26s\n",
      "(Training) Loss: 1007169.6218\n",
      "(Validation) Loss: 1027866.4533, MAE: 3928.1362, R2: 0.1326\n",
      "==========================================================================================\n",
      "Epoch [4329/5000] | Time: 0.26s\n",
      "(Training) Loss: 986207.6466\n",
      "(Validation) Loss: 1027723.1187, MAE: 3931.1672, R2: 0.1327\n",
      "==========================================================================================\n",
      "Epoch [4330/5000] | Time: 0.28s\n",
      "(Training) Loss: 993385.8864\n",
      "(Validation) Loss: 1027555.4997, MAE: 3927.4812, R2: 0.1329\n",
      "==========================================================================================\n",
      "Epoch [4331/5000] | Time: 0.31s\n",
      "(Training) Loss: 991246.6789\n",
      "(Validation) Loss: 1027406.0952, MAE: 3926.2336, R2: 0.1330\n",
      "==========================================================================================\n",
      "Epoch [4332/5000] | Time: 0.27s\n",
      "(Training) Loss: 988452.6079\n",
      "(Validation) Loss: 1027250.5244, MAE: 3925.1416, R2: 0.1331\n",
      "==========================================================================================\n",
      "Epoch [4333/5000] | Time: 0.22s\n",
      "(Training) Loss: 991010.0723\n",
      "(Validation) Loss: 1027122.4076, MAE: 3930.8538, R2: 0.1332\n",
      "==========================================================================================\n",
      "Epoch [4334/5000] | Time: 0.25s\n",
      "(Training) Loss: 991068.6231\n",
      "(Validation) Loss: 1026948.3022, MAE: 3926.0549, R2: 0.1334\n",
      "==========================================================================================\n",
      "Epoch [4335/5000] | Time: 0.28s\n",
      "(Training) Loss: 993522.6675\n",
      "(Validation) Loss: 1026802.5498, MAE: 3926.7104, R2: 0.1335\n",
      "==========================================================================================\n",
      "Epoch [4336/5000] | Time: 0.23s\n",
      "(Training) Loss: 1002250.4365\n",
      "(Validation) Loss: 1026636.5663, MAE: 3923.6492, R2: 0.1336\n",
      "==========================================================================================\n",
      "Epoch [4337/5000] | Time: 0.24s\n",
      "(Training) Loss: 986367.1662\n",
      "(Validation) Loss: 1026482.2400, MAE: 3921.4717, R2: 0.1338\n",
      "==========================================================================================\n",
      "Epoch [4338/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001788.1171\n",
      "(Validation) Loss: 1026333.0794, MAE: 3925.8020, R2: 0.1339\n",
      "==========================================================================================\n",
      "Epoch [4339/5000] | Time: 0.26s\n",
      "(Training) Loss: 1000815.0431\n",
      "(Validation) Loss: 1026309.6940, MAE: 3931.4675, R2: 0.1339\n",
      "==========================================================================================\n",
      "Epoch [4340/5000] | Time: 0.27s\n",
      "(Training) Loss: 999576.7341\n",
      "(Validation) Loss: 1026241.0362, MAE: 3931.7646, R2: 0.1340\n",
      "==========================================================================================\n",
      "Epoch [4341/5000] | Time: 0.26s\n",
      "(Training) Loss: 991793.6206\n",
      "(Validation) Loss: 1026083.3727, MAE: 3930.0786, R2: 0.1341\n",
      "==========================================================================================\n",
      "Epoch [4342/5000] | Time: 0.27s\n",
      "(Training) Loss: 983851.2855\n",
      "(Validation) Loss: 1025931.4286, MAE: 3932.5295, R2: 0.1342\n",
      "==========================================================================================\n",
      "Epoch [4343/5000] | Time: 0.23s\n",
      "(Training) Loss: 1002429.5603\n",
      "(Validation) Loss: 1025777.9708, MAE: 3929.4546, R2: 0.1343\n",
      "==========================================================================================\n",
      "Epoch [4344/5000] | Time: 0.23s\n",
      "(Training) Loss: 999635.9435\n",
      "(Validation) Loss: 1025624.4825, MAE: 3928.8982, R2: 0.1345\n",
      "==========================================================================================\n",
      "Epoch [4345/5000] | Time: 0.27s\n",
      "(Training) Loss: 1005692.1739\n",
      "(Validation) Loss: 1025473.6152, MAE: 3931.9771, R2: 0.1346\n",
      "==========================================================================================\n",
      "Epoch [4346/5000] | Time: 0.24s\n",
      "(Training) Loss: 982069.5239\n",
      "(Validation) Loss: 1025314.3213, MAE: 3932.0161, R2: 0.1347\n",
      "==========================================================================================\n",
      "Epoch [4347/5000] | Time: 0.26s\n",
      "(Training) Loss: 996969.5628\n",
      "(Validation) Loss: 1025171.0781, MAE: 3931.3677, R2: 0.1348\n",
      "==========================================================================================\n",
      "Epoch [4348/5000] | Time: 0.24s\n",
      "(Training) Loss: 996822.0108\n",
      "(Validation) Loss: 1025011.7283, MAE: 3928.5920, R2: 0.1350\n",
      "==========================================================================================\n",
      "Epoch [4349/5000] | Time: 0.32s\n",
      "(Training) Loss: 994368.1117\n",
      "(Validation) Loss: 1024855.7917, MAE: 3926.7317, R2: 0.1351\n",
      "==========================================================================================\n",
      "Epoch [4350/5000] | Time: 0.29s\n",
      "(Training) Loss: 993625.9937\n",
      "(Validation) Loss: 1024704.5333, MAE: 3927.0859, R2: 0.1352\n",
      "==========================================================================================\n",
      "Epoch [4351/5000] | Time: 0.27s\n",
      "(Training) Loss: 1017170.6878\n",
      "(Validation) Loss: 1024548.4648, MAE: 3927.0505, R2: 0.1354\n",
      "==========================================================================================\n",
      "Epoch [4352/5000] | Time: 0.31s\n",
      "(Training) Loss: 1004272.2728\n",
      "(Validation) Loss: 1024396.0076, MAE: 3927.0698, R2: 0.1355\n",
      "==========================================================================================\n",
      "Epoch [4353/5000] | Time: 0.34s\n",
      "(Training) Loss: 991008.1244\n",
      "(Validation) Loss: 1024236.3530, MAE: 3923.8125, R2: 0.1356\n",
      "==========================================================================================\n",
      "Epoch [4354/5000] | Time: 0.30s\n",
      "(Training) Loss: 993829.5609\n",
      "(Validation) Loss: 1024083.8248, MAE: 3923.8857, R2: 0.1358\n",
      "==========================================================================================\n",
      "Epoch [4355/5000] | Time: 0.31s\n",
      "(Training) Loss: 1002393.2259\n",
      "(Validation) Loss: 1023943.8171, MAE: 3926.2026, R2: 0.1359\n",
      "==========================================================================================\n",
      "Epoch [4356/5000] | Time: 0.32s\n",
      "(Training) Loss: 982074.5879\n",
      "(Validation) Loss: 1023778.0317, MAE: 3923.7568, R2: 0.1360\n",
      "==========================================================================================\n",
      "Epoch [4357/5000] | Time: 0.27s\n",
      "(Training) Loss: 993568.8959\n",
      "(Validation) Loss: 1023647.6698, MAE: 3927.6978, R2: 0.1361\n",
      "==========================================================================================\n",
      "Epoch [4358/5000] | Time: 0.26s\n",
      "(Training) Loss: 993011.2360\n",
      "(Validation) Loss: 1023478.2883, MAE: 3924.1323, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [4359/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006790.7976\n",
      "(Validation) Loss: 1023328.2032, MAE: 3923.4978, R2: 0.1364\n",
      "==========================================================================================\n",
      "Epoch [4360/5000] | Time: 0.31s\n",
      "(Training) Loss: 992601.0711\n",
      "(Validation) Loss: 1023168.6400, MAE: 3921.6521, R2: 0.1365\n",
      "==========================================================================================\n",
      "Epoch [4361/5000] | Time: 0.34s\n",
      "(Training) Loss: 998834.9277\n",
      "(Validation) Loss: 1023015.3041, MAE: 3921.2397, R2: 0.1366\n",
      "==========================================================================================\n",
      "Epoch [4362/5000] | Time: 0.31s\n",
      "(Training) Loss: 999675.0279\n",
      "(Validation) Loss: 1022864.8483, MAE: 3921.4780, R2: 0.1368\n",
      "==========================================================================================\n",
      "Epoch [4363/5000] | Time: 0.30s\n",
      "(Training) Loss: 1016005.3744\n",
      "(Validation) Loss: 1022709.8311, MAE: 3920.6279, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [4364/5000] | Time: 0.28s\n",
      "(Training) Loss: 989990.2018\n",
      "(Validation) Loss: 1022556.8152, MAE: 3920.1636, R2: 0.1370\n",
      "==========================================================================================\n",
      "Epoch [4365/5000] | Time: 0.31s\n",
      "(Training) Loss: 992136.4937\n",
      "(Validation) Loss: 1022400.1067, MAE: 3918.7075, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [4366/5000] | Time: 0.31s\n",
      "(Training) Loss: 992110.4841\n",
      "(Validation) Loss: 1022262.1410, MAE: 3920.7898, R2: 0.1373\n",
      "==========================================================================================\n",
      "Epoch [4367/5000] | Time: 0.29s\n",
      "(Training) Loss: 982909.0761\n",
      "(Validation) Loss: 1022095.4362, MAE: 3917.3142, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [4368/5000] | Time: 0.28s\n",
      "(Training) Loss: 999115.5266\n",
      "(Validation) Loss: 1021948.2362, MAE: 3917.5342, R2: 0.1375\n",
      "==========================================================================================\n",
      "Epoch [4369/5000] | Time: 0.30s\n",
      "(Training) Loss: 990999.1358\n",
      "(Validation) Loss: 1021816.7670, MAE: 3923.6553, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [4370/5000] | Time: 0.32s\n",
      "(Training) Loss: 980189.1374\n",
      "(Validation) Loss: 1021644.6984, MAE: 3917.4536, R2: 0.1378\n",
      "==========================================================================================\n",
      "Epoch [4371/5000] | Time: 0.31s\n",
      "(Training) Loss: 999066.6770\n",
      "(Validation) Loss: 1021487.9543, MAE: 3915.2678, R2: 0.1379\n",
      "==========================================================================================\n",
      "Epoch [4372/5000] | Time: 0.30s\n",
      "(Training) Loss: 985474.2183\n",
      "(Validation) Loss: 1021342.4762, MAE: 3916.6431, R2: 0.1380\n",
      "==========================================================================================\n",
      "Epoch [4373/5000] | Time: 0.36s\n",
      "(Training) Loss: 999155.9784\n",
      "(Validation) Loss: 1021186.0419, MAE: 3914.3555, R2: 0.1382\n",
      "==========================================================================================\n",
      "Epoch [4374/5000] | Time: 0.31s\n",
      "(Training) Loss: 998614.3982\n",
      "(Validation) Loss: 1021040.3403, MAE: 3916.3823, R2: 0.1383\n",
      "==========================================================================================\n",
      "Epoch [4375/5000] | Time: 0.29s\n",
      "(Training) Loss: 984612.8655\n",
      "(Validation) Loss: 1020878.5727, MAE: 3912.4277, R2: 0.1384\n",
      "==========================================================================================\n",
      "Epoch [4376/5000] | Time: 0.28s\n",
      "(Training) Loss: 995677.5552\n",
      "(Validation) Loss: 1020733.8768, MAE: 3916.4839, R2: 0.1385\n",
      "==========================================================================================\n",
      "Epoch [4377/5000] | Time: 0.28s\n",
      "(Training) Loss: 992327.5140\n",
      "(Validation) Loss: 1020575.1010, MAE: 3913.4482, R2: 0.1387\n",
      "==========================================================================================\n",
      "Epoch [4378/5000] | Time: 0.34s\n",
      "(Training) Loss: 992705.1358\n",
      "(Validation) Loss: 1020423.9390, MAE: 3912.8269, R2: 0.1388\n",
      "==========================================================================================\n",
      "Epoch [4379/5000] | Time: 0.33s\n",
      "(Training) Loss: 978320.1326\n",
      "(Validation) Loss: 1020277.8260, MAE: 3914.0962, R2: 0.1389\n",
      "==========================================================================================\n",
      "Epoch [4380/5000] | Time: 0.31s\n",
      "(Training) Loss: 986201.4569\n",
      "(Validation) Loss: 1020119.0908, MAE: 3911.3733, R2: 0.1391\n",
      "==========================================================================================\n",
      "Epoch [4381/5000] | Time: 0.30s\n",
      "(Training) Loss: 1002132.7297\n",
      "(Validation) Loss: 1019968.7517, MAE: 3911.7671, R2: 0.1392\n",
      "==========================================================================================\n",
      "Epoch [4382/5000] | Time: 0.28s\n",
      "(Training) Loss: 986657.1574\n",
      "(Validation) Loss: 1019810.4178, MAE: 3910.0388, R2: 0.1393\n",
      "==========================================================================================\n",
      "Epoch [4383/5000] | Time: 0.29s\n",
      "(Training) Loss: 992418.4423\n",
      "(Validation) Loss: 1019661.3486, MAE: 3909.0161, R2: 0.1394\n",
      "==========================================================================================\n",
      "Epoch [4384/5000] | Time: 0.31s\n",
      "(Training) Loss: 1013382.7462\n",
      "(Validation) Loss: 1019509.6127, MAE: 3908.7036, R2: 0.1396\n",
      "==========================================================================================\n",
      "Epoch [4385/5000] | Time: 0.27s\n",
      "(Training) Loss: 990938.0105\n",
      "(Validation) Loss: 1019360.9549, MAE: 3912.0806, R2: 0.1397\n",
      "==========================================================================================\n",
      "Epoch [4386/5000] | Time: 0.28s\n",
      "(Training) Loss: 980195.8185\n",
      "(Validation) Loss: 1019203.5098, MAE: 3907.1809, R2: 0.1398\n",
      "==========================================================================================\n",
      "Epoch [4387/5000] | Time: 0.30s\n",
      "(Training) Loss: 1000641.4683\n",
      "(Validation) Loss: 1019050.6006, MAE: 3906.1482, R2: 0.1400\n",
      "==========================================================================================\n",
      "Epoch [4388/5000] | Time: 0.28s\n",
      "(Training) Loss: 983002.2024\n",
      "(Validation) Loss: 1018895.7003, MAE: 3906.0159, R2: 0.1401\n",
      "==========================================================================================\n",
      "Epoch [4389/5000] | Time: 0.28s\n",
      "(Training) Loss: 985155.2043\n",
      "(Validation) Loss: 1018755.4337, MAE: 3906.8337, R2: 0.1402\n",
      "==========================================================================================\n",
      "Epoch [4390/5000] | Time: 0.29s\n",
      "(Training) Loss: 1000687.2287\n",
      "(Validation) Loss: 1018599.0298, MAE: 3905.3689, R2: 0.1403\n",
      "==========================================================================================\n",
      "Epoch [4391/5000] | Time: 0.31s\n",
      "(Training) Loss: 990200.5165\n",
      "(Validation) Loss: 1018448.7010, MAE: 3906.9321, R2: 0.1405\n",
      "==========================================================================================\n",
      "Epoch [4392/5000] | Time: 0.29s\n",
      "(Training) Loss: 984572.7878\n",
      "(Validation) Loss: 1018302.3594, MAE: 3907.1404, R2: 0.1406\n",
      "==========================================================================================\n",
      "Epoch [4393/5000] | Time: 0.28s\n",
      "(Training) Loss: 979851.6345\n",
      "(Validation) Loss: 1018139.4692, MAE: 3902.6858, R2: 0.1407\n",
      "==========================================================================================\n",
      "Epoch [4394/5000] | Time: 0.30s\n",
      "(Training) Loss: 998469.1669\n",
      "(Validation) Loss: 1017988.2210, MAE: 3902.7085, R2: 0.1408\n",
      "==========================================================================================\n",
      "Epoch [4395/5000] | Time: 0.33s\n",
      "(Training) Loss: 990155.5635\n",
      "(Validation) Loss: 1017837.0794, MAE: 3901.8752, R2: 0.1410\n",
      "==========================================================================================\n",
      "Epoch [4396/5000] | Time: 0.31s\n",
      "(Training) Loss: 989030.2912\n",
      "(Validation) Loss: 1017683.6470, MAE: 3900.9185, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [4397/5000] | Time: 0.29s\n",
      "(Training) Loss: 993061.9664\n",
      "(Validation) Loss: 1017541.0489, MAE: 3903.6907, R2: 0.1412\n",
      "==========================================================================================\n",
      "Epoch [4398/5000] | Time: 0.29s\n",
      "(Training) Loss: 976049.0292\n",
      "(Validation) Loss: 1017386.9308, MAE: 3901.4580, R2: 0.1413\n",
      "==========================================================================================\n",
      "Epoch [4399/5000] | Time: 0.32s\n",
      "(Training) Loss: 1003200.4530\n",
      "(Validation) Loss: 1017231.6190, MAE: 3901.1587, R2: 0.1415\n",
      "==========================================================================================\n",
      "Epoch [4400/5000] | Time: 0.28s\n",
      "(Training) Loss: 1002688.2094\n",
      "(Validation) Loss: 1017076.9016, MAE: 3900.1162, R2: 0.1416\n",
      "==========================================================================================\n",
      "Epoch [4401/5000] | Time: 0.28s\n",
      "(Training) Loss: 976719.7141\n",
      "(Validation) Loss: 1016926.5676, MAE: 3899.4866, R2: 0.1417\n",
      "==========================================================================================\n",
      "Epoch [4402/5000] | Time: 0.29s\n",
      "(Training) Loss: 980413.3065\n",
      "(Validation) Loss: 1016773.0590, MAE: 3902.5564, R2: 0.1418\n",
      "==========================================================================================\n",
      "Epoch [4403/5000] | Time: 0.28s\n",
      "(Training) Loss: 977222.4454\n",
      "(Validation) Loss: 1016625.0717, MAE: 3899.0125, R2: 0.1420\n",
      "==========================================================================================\n",
      "Epoch [4404/5000] | Time: 0.27s\n",
      "(Training) Loss: 990318.6339\n",
      "(Validation) Loss: 1016475.5251, MAE: 3898.7334, R2: 0.1421\n",
      "==========================================================================================\n",
      "Epoch [4405/5000] | Time: 0.27s\n",
      "(Training) Loss: 979833.4740\n",
      "(Validation) Loss: 1016315.1390, MAE: 3895.4951, R2: 0.1422\n",
      "==========================================================================================\n",
      "Epoch [4406/5000] | Time: 0.24s\n",
      "(Training) Loss: 973392.7013\n",
      "(Validation) Loss: 1016184.7873, MAE: 3903.3994, R2: 0.1423\n",
      "==========================================================================================\n",
      "Epoch [4407/5000] | Time: 0.27s\n",
      "(Training) Loss: 993782.2982\n",
      "(Validation) Loss: 1016025.1530, MAE: 3897.9705, R2: 0.1425\n",
      "==========================================================================================\n",
      "Epoch [4408/5000] | Time: 0.29s\n",
      "(Training) Loss: 1010195.7506\n",
      "(Validation) Loss: 1015870.0597, MAE: 3895.9861, R2: 0.1426\n",
      "==========================================================================================\n",
      "Epoch [4409/5000] | Time: 0.30s\n",
      "(Training) Loss: 996666.6085\n",
      "(Validation) Loss: 1015712.0813, MAE: 3895.7610, R2: 0.1427\n",
      "==========================================================================================\n",
      "Epoch [4410/5000] | Time: 0.43s\n",
      "(Training) Loss: 983101.7728\n",
      "(Validation) Loss: 1015564.1448, MAE: 3895.9453, R2: 0.1429\n",
      "==========================================================================================\n",
      "Epoch [4411/5000] | Time: 0.31s\n",
      "(Training) Loss: 980742.9089\n",
      "(Validation) Loss: 1015426.0368, MAE: 3898.0781, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [4412/5000] | Time: 0.36s\n",
      "(Training) Loss: 984957.3655\n",
      "(Validation) Loss: 1015265.4273, MAE: 3895.0532, R2: 0.1431\n",
      "==========================================================================================\n",
      "Epoch [4413/5000] | Time: 0.34s\n",
      "(Training) Loss: 982315.1440\n",
      "(Validation) Loss: 1015108.5206, MAE: 3896.1487, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [4414/5000] | Time: 0.31s\n",
      "(Training) Loss: 974531.3924\n",
      "(Validation) Loss: 1014957.0895, MAE: 3892.4707, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [4415/5000] | Time: 0.32s\n",
      "(Training) Loss: 1001329.2062\n",
      "(Validation) Loss: 1014676.3175, MAE: 3884.9143, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [4416/5000] | Time: 0.28s\n",
      "(Training) Loss: 973240.7989\n",
      "(Validation) Loss: 1014653.8362, MAE: 3891.8301, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [4417/5000] | Time: 0.34s\n",
      "(Training) Loss: 983747.6548\n",
      "(Validation) Loss: 1014509.3994, MAE: 3893.7410, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [4418/5000] | Time: 0.28s\n",
      "(Training) Loss: 972851.2703\n",
      "(Validation) Loss: 1014351.1619, MAE: 3891.4670, R2: 0.1439\n",
      "==========================================================================================\n",
      "Epoch [4419/5000] | Time: 0.29s\n",
      "(Training) Loss: 983175.9619\n",
      "(Validation) Loss: 1014220.7644, MAE: 3893.1689, R2: 0.1440\n",
      "==========================================================================================\n",
      "Epoch [4420/5000] | Time: 0.29s\n",
      "(Training) Loss: 974634.8972\n",
      "(Validation) Loss: 1014058.7835, MAE: 3889.6152, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [4421/5000] | Time: 0.30s\n",
      "(Training) Loss: 986966.8287\n",
      "(Validation) Loss: 1013907.6013, MAE: 3888.0295, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [4422/5000] | Time: 0.33s\n",
      "(Training) Loss: 970783.0785\n",
      "(Validation) Loss: 1013749.8921, MAE: 3886.6365, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [4423/5000] | Time: 0.31s\n",
      "(Training) Loss: 979436.2836\n",
      "(Validation) Loss: 1013604.8559, MAE: 3888.6841, R2: 0.1445\n",
      "==========================================================================================\n",
      "Epoch [4424/5000] | Time: 0.32s\n",
      "(Training) Loss: 978994.9327\n",
      "(Validation) Loss: 1013445.5416, MAE: 3883.9622, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [4425/5000] | Time: 0.31s\n",
      "(Training) Loss: 978776.2671\n",
      "(Validation) Loss: 1013297.4070, MAE: 3886.1882, R2: 0.1447\n",
      "==========================================================================================\n",
      "Epoch [4426/5000] | Time: 0.30s\n",
      "(Training) Loss: 978120.2195\n",
      "(Validation) Loss: 1013157.3283, MAE: 3888.3962, R2: 0.1449\n",
      "==========================================================================================\n",
      "Epoch [4427/5000] | Time: 0.34s\n",
      "(Training) Loss: 989342.4283\n",
      "(Validation) Loss: 1012991.8781, MAE: 3881.7688, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [4428/5000] | Time: 0.28s\n",
      "(Training) Loss: 985088.0362\n",
      "(Validation) Loss: 1010250.5498, MAE: 3878.1223, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [4429/5000] | Time: 0.29s\n",
      "(Training) Loss: 972829.0964\n",
      "(Validation) Loss: 1010097.9606, MAE: 3875.0098, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [4430/5000] | Time: 0.28s\n",
      "(Training) Loss: 972194.1155\n",
      "(Validation) Loss: 1009950.0190, MAE: 3871.5278, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4431/5000] | Time: 0.30s\n",
      "(Training) Loss: 972650.6485\n",
      "(Validation) Loss: 1009809.6406, MAE: 3872.1519, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4432/5000] | Time: 0.30s\n",
      "(Training) Loss: 978775.5279\n",
      "(Validation) Loss: 1009669.8514, MAE: 3874.0042, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [4433/5000] | Time: 0.32s\n",
      "(Training) Loss: 985395.2379\n",
      "(Validation) Loss: 1009514.2603, MAE: 3871.7075, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [4434/5000] | Time: 0.34s\n",
      "(Training) Loss: 974251.7490\n",
      "(Validation) Loss: 1009364.5206, MAE: 3870.8372, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4435/5000] | Time: 0.31s\n",
      "(Training) Loss: 992704.2157\n",
      "(Validation) Loss: 1009231.7308, MAE: 3872.4602, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4436/5000] | Time: 0.33s\n",
      "(Training) Loss: 984773.6409\n",
      "(Validation) Loss: 1009074.6870, MAE: 3868.8120, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [4437/5000] | Time: 0.29s\n",
      "(Training) Loss: 986386.1675\n",
      "(Validation) Loss: 1008921.7473, MAE: 3867.0754, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4438/5000] | Time: 0.29s\n",
      "(Training) Loss: 977354.0812\n",
      "(Validation) Loss: 1008782.3797, MAE: 3868.9104, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4439/5000] | Time: 0.33s\n",
      "(Training) Loss: 969007.3823\n",
      "(Validation) Loss: 1008632.0813, MAE: 3868.5715, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4440/5000] | Time: 0.33s\n",
      "(Training) Loss: 988085.7030\n",
      "(Validation) Loss: 1008487.1517, MAE: 3870.5093, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [4441/5000] | Time: 0.33s\n",
      "(Training) Loss: 976896.9588\n",
      "(Validation) Loss: 1008339.4540, MAE: 3867.6721, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4442/5000] | Time: 0.38s\n",
      "(Training) Loss: 980988.8407\n",
      "(Validation) Loss: 1008076.5816, MAE: 3859.6870, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4443/5000] | Time: 0.37s\n",
      "(Training) Loss: 972477.5533\n",
      "(Validation) Loss: 1007922.0267, MAE: 3858.3699, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4444/5000] | Time: 0.34s\n",
      "(Training) Loss: 967107.8426\n",
      "(Validation) Loss: 1007780.3937, MAE: 3857.3350, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4445/5000] | Time: 0.32s\n",
      "(Training) Loss: 977614.0761\n",
      "(Validation) Loss: 1007643.3676, MAE: 3858.6121, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4446/5000] | Time: 0.32s\n",
      "(Training) Loss: 978661.0349\n",
      "(Validation) Loss: 1007586.5448, MAE: 3875.1489, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4447/5000] | Time: 0.31s\n",
      "(Training) Loss: 983697.3287\n",
      "(Validation) Loss: 1011022.7556, MAE: 3870.4819, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [4448/5000] | Time: 0.31s\n",
      "(Training) Loss: 980714.4397\n",
      "(Validation) Loss: 1008686.6032, MAE: 3860.4622, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4449/5000] | Time: 0.33s\n",
      "(Training) Loss: 979632.8801\n",
      "(Validation) Loss: 1008543.1924, MAE: 3863.6658, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4450/5000] | Time: 0.34s\n",
      "(Training) Loss: 984988.9848\n",
      "(Validation) Loss: 1008379.5556, MAE: 3858.4802, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4451/5000] | Time: 0.33s\n",
      "(Training) Loss: 969926.6637\n",
      "(Validation) Loss: 1008218.1181, MAE: 3855.4553, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [4452/5000] | Time: 0.34s\n",
      "(Training) Loss: 967035.5146\n",
      "(Validation) Loss: 1008078.9435, MAE: 3857.0723, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4453/5000] | Time: 0.29s\n",
      "(Training) Loss: 971589.9765\n",
      "(Validation) Loss: 1007927.2686, MAE: 3856.7441, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4454/5000] | Time: 0.35s\n",
      "(Training) Loss: 983081.3376\n",
      "(Validation) Loss: 1007909.8006, MAE: 3866.2576, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4455/5000] | Time: 0.29s\n",
      "(Training) Loss: 970131.9511\n",
      "(Validation) Loss: 1007791.2838, MAE: 3868.1216, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4456/5000] | Time: 0.33s\n",
      "(Training) Loss: 991808.0698\n",
      "(Validation) Loss: 1007610.0775, MAE: 3864.1182, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4457/5000] | Time: 0.33s\n",
      "(Training) Loss: 968943.6402\n",
      "(Validation) Loss: 1007456.2641, MAE: 3862.8718, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [4458/5000] | Time: 0.35s\n",
      "(Training) Loss: 997902.1371\n",
      "(Validation) Loss: 1007301.5213, MAE: 3861.4409, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [4459/5000] | Time: 0.36s\n",
      "(Training) Loss: 998413.4016\n",
      "(Validation) Loss: 1007158.2222, MAE: 3863.8108, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [4460/5000] | Time: 0.36s\n",
      "(Training) Loss: 976397.2170\n",
      "(Validation) Loss: 1007009.9657, MAE: 3864.0200, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4461/5000] | Time: 0.32s\n",
      "(Training) Loss: 1010893.1846\n",
      "(Validation) Loss: 1006857.3460, MAE: 3861.9536, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4462/5000] | Time: 0.28s\n",
      "(Training) Loss: 976528.8598\n",
      "(Validation) Loss: 1006709.4654, MAE: 3861.2463, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [4463/5000] | Time: 0.29s\n",
      "(Training) Loss: 979528.2690\n",
      "(Validation) Loss: 1006566.4051, MAE: 3862.8101, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [4464/5000] | Time: 0.36s\n",
      "(Training) Loss: 964588.8870\n",
      "(Validation) Loss: 1006410.0165, MAE: 3859.3140, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [4465/5000] | Time: 0.33s\n",
      "(Training) Loss: 982253.1516\n",
      "(Validation) Loss: 1006295.3803, MAE: 3861.7195, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [4466/5000] | Time: 0.33s\n",
      "(Training) Loss: 972524.0324\n",
      "(Validation) Loss: 1006115.6267, MAE: 3859.6807, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [4467/5000] | Time: 0.33s\n",
      "(Training) Loss: 971637.8020\n",
      "(Validation) Loss: 1005971.4794, MAE: 3858.6804, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [4468/5000] | Time: 0.27s\n",
      "(Training) Loss: 967942.4791\n",
      "(Validation) Loss: 1005820.7594, MAE: 3857.9155, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [4469/5000] | Time: 0.30s\n",
      "(Training) Loss: 966177.1815\n",
      "(Validation) Loss: 1005667.8400, MAE: 3854.5923, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [4470/5000] | Time: 0.31s\n",
      "(Training) Loss: 970351.0102\n",
      "(Validation) Loss: 1005524.4546, MAE: 3855.1013, R2: 0.1512\n",
      "==========================================================================================\n",
      "Epoch [4471/5000] | Time: 0.35s\n",
      "(Training) Loss: 973928.1904\n",
      "(Validation) Loss: 1005298.9206, MAE: 3858.5273, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [4472/5000] | Time: 0.31s\n",
      "(Training) Loss: 995624.6929\n",
      "(Validation) Loss: 1009168.3251, MAE: 3877.2354, R2: 0.1482\n",
      "==========================================================================================\n",
      "Epoch [4473/5000] | Time: 0.32s\n",
      "(Training) Loss: 986553.5159\n",
      "(Validation) Loss: 1009004.2006, MAE: 3872.4568, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [4474/5000] | Time: 0.31s\n",
      "(Training) Loss: 968521.5466\n",
      "(Validation) Loss: 1008848.8940, MAE: 3873.1204, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4475/5000] | Time: 0.30s\n",
      "(Training) Loss: 968535.8372\n",
      "(Validation) Loss: 1008698.0622, MAE: 3872.9927, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4476/5000] | Time: 0.28s\n",
      "(Training) Loss: 977978.3331\n",
      "(Validation) Loss: 1008546.1740, MAE: 3871.1025, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4477/5000] | Time: 0.31s\n",
      "(Training) Loss: 968090.1199\n",
      "(Validation) Loss: 1008396.3479, MAE: 3872.8831, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [4478/5000] | Time: 0.34s\n",
      "(Training) Loss: 966268.5331\n",
      "(Validation) Loss: 1008243.9568, MAE: 3870.6741, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [4479/5000] | Time: 0.30s\n",
      "(Training) Loss: 987893.8135\n",
      "(Validation) Loss: 1008094.3644, MAE: 3868.3108, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4480/5000] | Time: 0.32s\n",
      "(Training) Loss: 974276.1637\n",
      "(Validation) Loss: 1007947.9517, MAE: 3869.7200, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4481/5000] | Time: 0.31s\n",
      "(Training) Loss: 985166.1777\n",
      "(Validation) Loss: 1007793.6356, MAE: 3867.7830, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4482/5000] | Time: 0.31s\n",
      "(Training) Loss: 983012.5819\n",
      "(Validation) Loss: 1007646.9841, MAE: 3867.7195, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4483/5000] | Time: 0.29s\n",
      "(Training) Loss: 972529.1694\n",
      "(Validation) Loss: 1007499.6521, MAE: 3868.0310, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [4484/5000] | Time: 0.29s\n",
      "(Training) Loss: 980053.0349\n",
      "(Validation) Loss: 1007351.1263, MAE: 3867.5889, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [4485/5000] | Time: 0.29s\n",
      "(Training) Loss: 976933.5121\n",
      "(Validation) Loss: 1007201.2597, MAE: 3866.7620, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [4486/5000] | Time: 0.31s\n",
      "(Training) Loss: 971844.3991\n",
      "(Validation) Loss: 1007045.9429, MAE: 3864.8994, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4487/5000] | Time: 0.30s\n",
      "(Training) Loss: 978074.8128\n",
      "(Validation) Loss: 1006896.4622, MAE: 3864.0161, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4488/5000] | Time: 0.34s\n",
      "(Training) Loss: 982582.6301\n",
      "(Validation) Loss: 1006755.6165, MAE: 3864.7888, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [4489/5000] | Time: 0.32s\n",
      "(Training) Loss: 984811.3103\n",
      "(Validation) Loss: 1006606.2883, MAE: 3864.3220, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [4490/5000] | Time: 0.31s\n",
      "(Training) Loss: 982224.6586\n",
      "(Validation) Loss: 1006455.8578, MAE: 3863.9331, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [4491/5000] | Time: 0.33s\n",
      "(Training) Loss: 984795.2919\n",
      "(Validation) Loss: 1006235.5962, MAE: 3857.3975, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [4492/5000] | Time: 0.31s\n",
      "(Training) Loss: 975967.8312\n",
      "(Validation) Loss: 1006143.6698, MAE: 3866.0388, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [4493/5000] | Time: 0.32s\n",
      "(Training) Loss: 988482.0692\n",
      "(Validation) Loss: 1005891.1898, MAE: 3855.8555, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [4494/5000] | Time: 0.30s\n",
      "(Training) Loss: 973906.8261\n",
      "(Validation) Loss: 1005762.9917, MAE: 3857.2385, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [4495/5000] | Time: 0.30s\n",
      "(Training) Loss: 974869.5216\n",
      "(Validation) Loss: 998807.5429, MAE: 3849.6113, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [4496/5000] | Time: 0.31s\n",
      "(Training) Loss: 961304.9645\n",
      "(Validation) Loss: 998631.1010, MAE: 3836.1184, R2: 0.1570\n",
      "==========================================================================================\n",
      "Epoch [4497/5000] | Time: 0.31s\n",
      "(Training) Loss: 968367.3065\n",
      "(Validation) Loss: 998487.1314, MAE: 3834.4004, R2: 0.1571\n",
      "==========================================================================================\n",
      "Epoch [4498/5000] | Time: 0.36s\n",
      "(Training) Loss: 962700.3484\n",
      "(Validation) Loss: 998342.1714, MAE: 3833.4453, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [4499/5000] | Time: 0.35s\n",
      "(Training) Loss: 964960.2868\n",
      "(Validation) Loss: 998199.7206, MAE: 3832.4944, R2: 0.1573\n",
      "==========================================================================================\n",
      "Epoch [4500/5000] | Time: 0.35s\n",
      "(Training) Loss: 970573.3201\n",
      "(Validation) Loss: 998079.6648, MAE: 3836.2434, R2: 0.1574\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch4500.pth\n",
      "==========================================================================================\n",
      "Epoch [4501/5000] | Time: 0.32s\n",
      "(Training) Loss: 975235.3769\n",
      "(Validation) Loss: 997915.5657, MAE: 3831.4812, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [4502/5000] | Time: 0.27s\n",
      "(Training) Loss: 981840.0660\n",
      "(Validation) Loss: 997778.2908, MAE: 3832.7534, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [4503/5000] | Time: 0.34s\n",
      "(Training) Loss: 955849.7568\n",
      "(Validation) Loss: 997636.8305, MAE: 3832.1914, R2: 0.1578\n",
      "==========================================================================================\n",
      "Epoch [4504/5000] | Time: 0.30s\n",
      "(Training) Loss: 961190.8115\n",
      "(Validation) Loss: 997489.2292, MAE: 3829.3459, R2: 0.1579\n",
      "==========================================================================================\n",
      "Epoch [4505/5000] | Time: 0.32s\n",
      "(Training) Loss: 964117.5082\n",
      "(Validation) Loss: 997355.7333, MAE: 3830.8911, R2: 0.1580\n",
      "==========================================================================================\n",
      "Epoch [4506/5000] | Time: 0.32s\n",
      "(Training) Loss: 974434.6555\n",
      "(Validation) Loss: 997217.4578, MAE: 3831.0955, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [4507/5000] | Time: 0.32s\n",
      "(Training) Loss: 967241.1983\n",
      "(Validation) Loss: 997067.9416, MAE: 3830.4072, R2: 0.1583\n",
      "==========================================================================================\n",
      "Epoch [4508/5000] | Time: 0.34s\n",
      "(Training) Loss: 968812.7982\n",
      "(Validation) Loss: 996930.0876, MAE: 3832.9353, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [4509/5000] | Time: 0.36s\n",
      "(Training) Loss: 978026.4486\n",
      "(Validation) Loss: 996780.3479, MAE: 3827.1162, R2: 0.1585\n",
      "==========================================================================================\n",
      "Epoch [4510/5000] | Time: 0.36s\n",
      "(Training) Loss: 970834.4454\n",
      "(Validation) Loss: 996639.7917, MAE: 3827.9119, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [4511/5000] | Time: 0.32s\n",
      "(Training) Loss: 969563.3687\n",
      "(Validation) Loss: 996497.8337, MAE: 3828.3660, R2: 0.1587\n",
      "==========================================================================================\n",
      "Epoch [4512/5000] | Time: 0.38s\n",
      "(Training) Loss: 969533.8166\n",
      "(Validation) Loss: 996354.0114, MAE: 3826.8672, R2: 0.1589\n",
      "==========================================================================================\n",
      "Epoch [4513/5000] | Time: 0.32s\n",
      "(Training) Loss: 966821.9372\n",
      "(Validation) Loss: 996214.9384, MAE: 3827.5012, R2: 0.1590\n",
      "==========================================================================================\n",
      "Epoch [4514/5000] | Time: 0.28s\n",
      "(Training) Loss: 979071.3119\n",
      "(Validation) Loss: 996076.4597, MAE: 3826.9321, R2: 0.1591\n",
      "==========================================================================================\n",
      "Epoch [4515/5000] | Time: 0.27s\n",
      "(Training) Loss: 980133.1745\n",
      "(Validation) Loss: 995923.2813, MAE: 3824.6938, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [4516/5000] | Time: 0.22s\n",
      "(Training) Loss: 953937.0866\n",
      "(Validation) Loss: 995781.2267, MAE: 3824.9495, R2: 0.1593\n",
      "==========================================================================================\n",
      "Epoch [4517/5000] | Time: 0.24s\n",
      "(Training) Loss: 963659.4099\n",
      "(Validation) Loss: 995649.7524, MAE: 3825.8406, R2: 0.1595\n",
      "==========================================================================================\n",
      "Epoch [4518/5000] | Time: 0.24s\n",
      "(Training) Loss: 958792.3306\n",
      "(Validation) Loss: 995507.5759, MAE: 3826.3721, R2: 0.1596\n",
      "==========================================================================================\n",
      "Epoch [4519/5000] | Time: 0.22s\n",
      "(Training) Loss: 967487.1916\n",
      "(Validation) Loss: 995357.0387, MAE: 3821.5769, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [4520/5000] | Time: 0.28s\n",
      "(Training) Loss: 960797.7157\n",
      "(Validation) Loss: 995212.8863, MAE: 3820.2209, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [4521/5000] | Time: 0.28s\n",
      "(Training) Loss: 993470.8940\n",
      "(Validation) Loss: 995071.2686, MAE: 3818.3372, R2: 0.1599\n",
      "==========================================================================================\n",
      "Epoch [4522/5000] | Time: 0.28s\n",
      "(Training) Loss: 962086.4467\n",
      "(Validation) Loss: 994929.0971, MAE: 3820.0308, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [4523/5000] | Time: 0.25s\n",
      "(Training) Loss: 965668.4854\n",
      "(Validation) Loss: 994789.2825, MAE: 3819.6367, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [4524/5000] | Time: 0.29s\n",
      "(Training) Loss: 976581.0470\n",
      "(Validation) Loss: 994642.7276, MAE: 3819.4951, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [4525/5000] | Time: 0.32s\n",
      "(Training) Loss: 966122.7551\n",
      "(Validation) Loss: 994506.9867, MAE: 3818.9558, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [4526/5000] | Time: 0.29s\n",
      "(Training) Loss: 984095.5089\n",
      "(Validation) Loss: 994355.1289, MAE: 3815.5603, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [4527/5000] | Time: 0.29s\n",
      "(Training) Loss: 962276.4499\n",
      "(Validation) Loss: 994218.9410, MAE: 3817.7090, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [4528/5000] | Time: 0.31s\n",
      "(Training) Loss: 969572.1383\n",
      "(Validation) Loss: 994154.6667, MAE: 3829.4387, R2: 0.1607\n",
      "==========================================================================================\n",
      "Epoch [4529/5000] | Time: 0.28s\n",
      "(Training) Loss: 965921.0863\n",
      "(Validation) Loss: 993943.7206, MAE: 3819.6658, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [4530/5000] | Time: 0.25s\n",
      "(Training) Loss: 972937.0057\n",
      "(Validation) Loss: 993794.8444, MAE: 3815.7358, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [4531/5000] | Time: 0.27s\n",
      "(Training) Loss: 975754.1428\n",
      "(Validation) Loss: 993642.9511, MAE: 3813.0017, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [4532/5000] | Time: 0.24s\n",
      "(Training) Loss: 954115.9461\n",
      "(Validation) Loss: 993508.3733, MAE: 3814.3406, R2: 0.1612\n",
      "==========================================================================================\n",
      "Epoch [4533/5000] | Time: 0.24s\n",
      "(Training) Loss: 968316.7043\n",
      "(Validation) Loss: 993361.2343, MAE: 3811.9609, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [4534/5000] | Time: 0.29s\n",
      "(Training) Loss: 983177.5260\n",
      "(Validation) Loss: 993225.7270, MAE: 3814.8364, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [4535/5000] | Time: 0.29s\n",
      "(Training) Loss: 966234.8071\n",
      "(Validation) Loss: 993080.0102, MAE: 3812.3323, R2: 0.1616\n",
      "==========================================================================================\n",
      "Epoch [4536/5000] | Time: 0.30s\n",
      "(Training) Loss: 991835.7094\n",
      "(Validation) Loss: 992939.9822, MAE: 3812.0156, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [4537/5000] | Time: 0.30s\n",
      "(Training) Loss: 983346.8566\n",
      "(Validation) Loss: 992799.3244, MAE: 3812.1614, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [4538/5000] | Time: 0.37s\n",
      "(Training) Loss: 956515.5685\n",
      "(Validation) Loss: 992653.0946, MAE: 3811.2041, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [4539/5000] | Time: 0.37s\n",
      "(Training) Loss: 984081.3388\n",
      "(Validation) Loss: 992516.5867, MAE: 3810.6150, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [4540/5000] | Time: 0.31s\n",
      "(Training) Loss: 958405.0673\n",
      "(Validation) Loss: 992385.2902, MAE: 3815.5688, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [4541/5000] | Time: 0.31s\n",
      "(Training) Loss: 976757.5539\n",
      "(Validation) Loss: 992231.5124, MAE: 3810.8159, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [4542/5000] | Time: 0.27s\n",
      "(Training) Loss: 953777.6850\n",
      "(Validation) Loss: 992088.2032, MAE: 3809.8257, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [4543/5000] | Time: 0.30s\n",
      "(Training) Loss: 966159.5761\n",
      "(Validation) Loss: 1002609.9251, MAE: 3850.6387, R2: 0.1537\n",
      "==========================================================================================\n",
      "Epoch [4544/5000] | Time: 0.33s\n",
      "(Training) Loss: 960366.1798\n",
      "(Validation) Loss: 1002449.1479, MAE: 3847.2952, R2: 0.1538\n",
      "==========================================================================================\n",
      "Epoch [4545/5000] | Time: 0.30s\n",
      "(Training) Loss: 964438.2157\n",
      "(Validation) Loss: 1002304.7213, MAE: 3849.3838, R2: 0.1539\n",
      "==========================================================================================\n",
      "Epoch [4546/5000] | Time: 0.34s\n",
      "(Training) Loss: 972644.1326\n",
      "(Validation) Loss: 1002156.8254, MAE: 3849.5085, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [4547/5000] | Time: 0.32s\n",
      "(Training) Loss: 974061.5964\n",
      "(Validation) Loss: 999611.3321, MAE: 3836.8108, R2: 0.1562\n",
      "==========================================================================================\n",
      "Epoch [4548/5000] | Time: 0.33s\n",
      "(Training) Loss: 971851.7646\n",
      "(Validation) Loss: 999477.4806, MAE: 3838.0413, R2: 0.1563\n",
      "==========================================================================================\n",
      "Epoch [4549/5000] | Time: 0.32s\n",
      "(Training) Loss: 978592.3999\n",
      "(Validation) Loss: 999348.5308, MAE: 3846.0962, R2: 0.1564\n",
      "==========================================================================================\n",
      "Epoch [4550/5000] | Time: 0.28s\n",
      "(Training) Loss: 973047.6098\n",
      "(Validation) Loss: 999185.8743, MAE: 3839.3423, R2: 0.1565\n",
      "==========================================================================================\n",
      "Epoch [4551/5000] | Time: 0.32s\n",
      "(Training) Loss: 980720.7690\n",
      "(Validation) Loss: 999023.4921, MAE: 3834.9368, R2: 0.1566\n",
      "==========================================================================================\n",
      "Epoch [4552/5000] | Time: 0.28s\n",
      "(Training) Loss: 978823.0876\n",
      "(Validation) Loss: 998880.9448, MAE: 3835.6006, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [4553/5000] | Time: 0.28s\n",
      "(Training) Loss: 961323.4746\n",
      "(Validation) Loss: 998731.6317, MAE: 3833.6809, R2: 0.1569\n",
      "==========================================================================================\n",
      "Epoch [4554/5000] | Time: 0.31s\n",
      "(Training) Loss: 968390.2773\n",
      "(Validation) Loss: 998595.2863, MAE: 3835.3105, R2: 0.1570\n",
      "==========================================================================================\n",
      "Epoch [4555/5000] | Time: 0.38s\n",
      "(Training) Loss: 970460.5092\n",
      "(Validation) Loss: 998448.9905, MAE: 3833.8518, R2: 0.1571\n",
      "==========================================================================================\n",
      "Epoch [4556/5000] | Time: 0.33s\n",
      "(Training) Loss: 958073.8595\n",
      "(Validation) Loss: 998305.2190, MAE: 3834.9172, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [4557/5000] | Time: 0.29s\n",
      "(Training) Loss: 980184.0819\n",
      "(Validation) Loss: 998158.1359, MAE: 3832.3704, R2: 0.1574\n",
      "==========================================================================================\n",
      "Epoch [4558/5000] | Time: 0.28s\n",
      "(Training) Loss: 981968.1567\n",
      "(Validation) Loss: 998006.7098, MAE: 3828.8354, R2: 0.1575\n",
      "==========================================================================================\n",
      "Epoch [4559/5000] | Time: 0.28s\n",
      "(Training) Loss: 958493.1187\n",
      "(Validation) Loss: 997892.1600, MAE: 3838.2043, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [4560/5000] | Time: 0.33s\n",
      "(Training) Loss: 987551.8046\n",
      "(Validation) Loss: 997727.1060, MAE: 3830.5952, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [4561/5000] | Time: 0.33s\n",
      "(Training) Loss: 963332.7069\n",
      "(Validation) Loss: 997580.0533, MAE: 3829.5293, R2: 0.1578\n",
      "==========================================================================================\n",
      "Epoch [4562/5000] | Time: 0.33s\n",
      "(Training) Loss: 956225.7724\n",
      "(Validation) Loss: 997447.1060, MAE: 3830.3931, R2: 0.1580\n",
      "==========================================================================================\n",
      "Epoch [4563/5000] | Time: 0.34s\n",
      "(Training) Loss: 959351.4607\n",
      "(Validation) Loss: 997290.2248, MAE: 3828.4028, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [4564/5000] | Time: 0.29s\n",
      "(Training) Loss: 983640.9321\n",
      "(Validation) Loss: 997149.7295, MAE: 3827.4927, R2: 0.1582\n",
      "==========================================================================================\n",
      "Epoch [4565/5000] | Time: 0.31s\n",
      "(Training) Loss: 974991.4416\n",
      "(Validation) Loss: 997011.0527, MAE: 3828.4580, R2: 0.1583\n",
      "==========================================================================================\n",
      "Epoch [4566/5000] | Time: 0.29s\n",
      "(Training) Loss: 957130.0847\n",
      "(Validation) Loss: 996885.5619, MAE: 3832.8601, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [4567/5000] | Time: 0.28s\n",
      "(Training) Loss: 969030.2912\n",
      "(Validation) Loss: 996723.3829, MAE: 3826.7964, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [4568/5000] | Time: 0.30s\n",
      "(Training) Loss: 968916.0038\n",
      "(Validation) Loss: 996582.8978, MAE: 3827.3892, R2: 0.1587\n",
      "==========================================================================================\n",
      "Epoch [4569/5000] | Time: 0.33s\n",
      "(Training) Loss: 959872.1294\n",
      "(Validation) Loss: 996438.6083, MAE: 3826.9944, R2: 0.1588\n",
      "==========================================================================================\n",
      "Epoch [4570/5000] | Time: 0.26s\n",
      "(Training) Loss: 955463.6929\n",
      "(Validation) Loss: 996299.9975, MAE: 3827.2007, R2: 0.1589\n",
      "==========================================================================================\n",
      "Epoch [4571/5000] | Time: 0.33s\n",
      "(Training) Loss: 960275.9816\n",
      "(Validation) Loss: 996165.2317, MAE: 3827.8608, R2: 0.1590\n",
      "==========================================================================================\n",
      "Epoch [4572/5000] | Time: 0.31s\n",
      "(Training) Loss: 979070.6256\n",
      "(Validation) Loss: 996012.9473, MAE: 3823.8921, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [4573/5000] | Time: 0.35s\n",
      "(Training) Loss: 970021.8439\n",
      "(Validation) Loss: 995864.3606, MAE: 3822.5134, R2: 0.1593\n",
      "==========================================================================================\n",
      "Epoch [4574/5000] | Time: 0.28s\n",
      "(Training) Loss: 996445.6129\n",
      "(Validation) Loss: 995719.1162, MAE: 3820.3665, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [4575/5000] | Time: 0.30s\n",
      "(Training) Loss: 963395.1878\n",
      "(Validation) Loss: 995578.2654, MAE: 3822.4534, R2: 0.1595\n",
      "==========================================================================================\n",
      "Epoch [4576/5000] | Time: 0.28s\n",
      "(Training) Loss: 986441.8344\n",
      "(Validation) Loss: 995430.3238, MAE: 3818.9849, R2: 0.1596\n",
      "==========================================================================================\n",
      "Epoch [4577/5000] | Time: 0.32s\n",
      "(Training) Loss: 986658.3173\n",
      "(Validation) Loss: 995299.2965, MAE: 3822.9993, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [4578/5000] | Time: 0.31s\n",
      "(Training) Loss: 962411.7773\n",
      "(Validation) Loss: 995147.3879, MAE: 3820.4194, R2: 0.1599\n",
      "==========================================================================================\n",
      "Epoch [4579/5000] | Time: 0.36s\n",
      "(Training) Loss: 970644.8312\n",
      "(Validation) Loss: 995001.0565, MAE: 3817.6794, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [4580/5000] | Time: 0.34s\n",
      "(Training) Loss: 954288.5590\n",
      "(Validation) Loss: 1006114.5295, MAE: 3880.9666, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [4581/5000] | Time: 0.34s\n",
      "(Training) Loss: 953780.9126\n",
      "(Validation) Loss: 994714.7276, MAE: 3816.4119, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [4582/5000] | Time: 0.29s\n",
      "(Training) Loss: 973938.2766\n",
      "(Validation) Loss: 994578.7276, MAE: 3815.7759, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [4583/5000] | Time: 0.28s\n",
      "(Training) Loss: 979587.1263\n",
      "(Validation) Loss: 994431.1721, MAE: 3814.7583, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [4584/5000] | Time: 0.30s\n",
      "(Training) Loss: 953992.8468\n",
      "(Validation) Loss: 994300.5867, MAE: 3816.9182, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [4585/5000] | Time: 0.30s\n",
      "(Training) Loss: 965588.5102\n",
      "(Validation) Loss: 994154.8749, MAE: 3815.1985, R2: 0.1607\n",
      "==========================================================================================\n",
      "Epoch [4586/5000] | Time: 0.28s\n",
      "(Training) Loss: 966096.3445\n",
      "(Validation) Loss: 994042.2654, MAE: 3822.6384, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [4587/5000] | Time: 0.28s\n",
      "(Training) Loss: 979148.7011\n",
      "(Validation) Loss: 993872.5435, MAE: 3815.2041, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [4588/5000] | Time: 0.32s\n",
      "(Training) Loss: 956491.8014\n",
      "(Validation) Loss: 993729.7981, MAE: 3815.4231, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [4589/5000] | Time: 0.30s\n",
      "(Training) Loss: 961816.1977\n",
      "(Validation) Loss: 993582.5524, MAE: 3813.1003, R2: 0.1612\n",
      "==========================================================================================\n",
      "Epoch [4590/5000] | Time: 0.30s\n",
      "(Training) Loss: 952330.3488\n",
      "(Validation) Loss: 993450.0724, MAE: 3814.8416, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [4591/5000] | Time: 0.34s\n",
      "(Training) Loss: 976157.2544\n",
      "(Validation) Loss: 993303.0552, MAE: 3811.9548, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [4592/5000] | Time: 0.29s\n",
      "(Training) Loss: 968106.9841\n",
      "(Validation) Loss: 993157.0133, MAE: 3811.2949, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [4593/5000] | Time: 0.29s\n",
      "(Training) Loss: 971725.7138\n",
      "(Validation) Loss: 993010.5651, MAE: 3809.3799, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [4594/5000] | Time: 0.29s\n",
      "(Training) Loss: 968307.9632\n",
      "(Validation) Loss: 990987.5708, MAE: 3801.6587, R2: 0.1633\n",
      "==========================================================================================\n",
      "Epoch [4595/5000] | Time: 0.30s\n",
      "(Training) Loss: 968390.5679\n",
      "(Validation) Loss: 990828.0229, MAE: 3796.3809, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [4596/5000] | Time: 0.31s\n",
      "(Training) Loss: 972442.8255\n",
      "(Validation) Loss: 990780.8356, MAE: 3801.6082, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [4597/5000] | Time: 0.31s\n",
      "(Training) Loss: 949293.0913\n",
      "(Validation) Loss: 990649.7422, MAE: 3803.1140, R2: 0.1636\n",
      "==========================================================================================\n",
      "Epoch [4598/5000] | Time: 0.31s\n",
      "(Training) Loss: 991171.3325\n",
      "(Validation) Loss: 990505.1733, MAE: 3800.0811, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [4599/5000] | Time: 0.30s\n",
      "(Training) Loss: 988830.3661\n",
      "(Validation) Loss: 990364.6984, MAE: 3800.3486, R2: 0.1639\n",
      "==========================================================================================\n",
      "Epoch [4600/5000] | Time: 0.31s\n",
      "(Training) Loss: 954319.1396\n",
      "(Validation) Loss: 982967.9086, MAE: 3778.8191, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [4601/5000] | Time: 0.29s\n",
      "(Training) Loss: 975328.0086\n",
      "(Validation) Loss: 982753.9454, MAE: 3773.1860, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [4602/5000] | Time: 0.29s\n",
      "(Training) Loss: 979982.9074\n",
      "(Validation) Loss: 982625.4171, MAE: 3772.4006, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [4603/5000] | Time: 0.29s\n",
      "(Training) Loss: 944811.0891\n",
      "(Validation) Loss: 982522.1333, MAE: 3774.2498, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [4604/5000] | Time: 0.28s\n",
      "(Training) Loss: 966535.7113\n",
      "(Validation) Loss: 982375.0603, MAE: 3770.9905, R2: 0.1705\n",
      "==========================================================================================\n",
      "Epoch [4605/5000] | Time: 0.30s\n",
      "(Training) Loss: 957548.2354\n",
      "(Validation) Loss: 982242.9206, MAE: 3769.8953, R2: 0.1706\n",
      "==========================================================================================\n",
      "Epoch [4606/5000] | Time: 0.29s\n",
      "(Training) Loss: 962474.0936\n",
      "(Validation) Loss: 982146.3517, MAE: 3775.4473, R2: 0.1707\n",
      "==========================================================================================\n",
      "Epoch [4607/5000] | Time: 0.31s\n",
      "(Training) Loss: 971591.3813\n",
      "(Validation) Loss: 981989.7295, MAE: 3769.8130, R2: 0.1708\n",
      "==========================================================================================\n",
      "Epoch [4608/5000] | Time: 0.35s\n",
      "(Training) Loss: 954487.6678\n",
      "(Validation) Loss: 984352.8635, MAE: 3777.4136, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [4609/5000] | Time: 0.27s\n",
      "(Training) Loss: 970585.1840\n",
      "(Validation) Loss: 984213.9530, MAE: 3779.5708, R2: 0.1690\n",
      "==========================================================================================\n",
      "Epoch [4610/5000] | Time: 0.29s\n",
      "(Training) Loss: 957111.7544\n",
      "(Validation) Loss: 984057.5187, MAE: 3774.4673, R2: 0.1691\n",
      "==========================================================================================\n",
      "Epoch [4611/5000] | Time: 0.30s\n",
      "(Training) Loss: 965558.5006\n",
      "(Validation) Loss: 983927.8730, MAE: 3777.1704, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [4612/5000] | Time: 0.29s\n",
      "(Training) Loss: 943472.5353\n",
      "(Validation) Loss: 983815.0705, MAE: 3781.7197, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [4613/5000] | Time: 0.28s\n",
      "(Training) Loss: 973144.9429\n",
      "(Validation) Loss: 983648.8381, MAE: 3776.8044, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [4614/5000] | Time: 0.32s\n",
      "(Training) Loss: 947034.1104\n",
      "(Validation) Loss: 983558.9587, MAE: 3784.7727, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [4615/5000] | Time: 0.30s\n",
      "(Training) Loss: 974174.4055\n",
      "(Validation) Loss: 983417.8286, MAE: 3778.1016, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [4616/5000] | Time: 0.32s\n",
      "(Training) Loss: 977273.7931\n",
      "(Validation) Loss: 983237.3435, MAE: 3775.5791, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [4617/5000] | Time: 0.30s\n",
      "(Training) Loss: 959678.8674\n",
      "(Validation) Loss: 983123.6470, MAE: 3781.0447, R2: 0.1699\n",
      "==========================================================================================\n",
      "Epoch [4618/5000] | Time: 0.28s\n",
      "(Training) Loss: 956712.1783\n",
      "(Validation) Loss: 982953.2140, MAE: 3773.5730, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [4619/5000] | Time: 0.31s\n",
      "(Training) Loss: 958458.8915\n",
      "(Validation) Loss: 982811.7232, MAE: 3770.8767, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [4620/5000] | Time: 0.28s\n",
      "(Training) Loss: 983375.3890\n",
      "(Validation) Loss: 982668.9676, MAE: 3769.6621, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [4621/5000] | Time: 0.31s\n",
      "(Training) Loss: 942895.2648\n",
      "(Validation) Loss: 982528.2337, MAE: 3768.1082, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [4622/5000] | Time: 0.25s\n",
      "(Training) Loss: 956373.7665\n",
      "(Validation) Loss: 982436.7898, MAE: 3774.8499, R2: 0.1705\n",
      "==========================================================================================\n",
      "Epoch [4623/5000] | Time: 0.30s\n",
      "(Training) Loss: 951136.1732\n",
      "(Validation) Loss: 982264.1473, MAE: 3770.8132, R2: 0.1706\n",
      "==========================================================================================\n",
      "Epoch [4624/5000] | Time: 0.32s\n",
      "(Training) Loss: 945502.2373\n",
      "(Validation) Loss: 982123.6825, MAE: 3768.5737, R2: 0.1707\n",
      "==========================================================================================\n",
      "Epoch [4625/5000] | Time: 0.32s\n",
      "(Training) Loss: 942338.2397\n",
      "(Validation) Loss: 981987.0222, MAE: 3769.0515, R2: 0.1708\n",
      "==========================================================================================\n",
      "Epoch [4626/5000] | Time: 0.32s\n",
      "(Training) Loss: 947390.9055\n",
      "(Validation) Loss: 981876.4749, MAE: 3771.3093, R2: 0.1709\n",
      "==========================================================================================\n",
      "Epoch [4627/5000] | Time: 0.31s\n",
      "(Training) Loss: 960235.7563\n",
      "(Validation) Loss: 981718.4559, MAE: 3766.1399, R2: 0.1711\n",
      "==========================================================================================\n",
      "Epoch [4628/5000] | Time: 0.28s\n",
      "(Training) Loss: 942070.0766\n",
      "(Validation) Loss: 981581.2876, MAE: 3767.0442, R2: 0.1712\n",
      "==========================================================================================\n",
      "Epoch [4629/5000] | Time: 0.28s\n",
      "(Training) Loss: 959629.1701\n",
      "(Validation) Loss: 981442.5346, MAE: 3765.4578, R2: 0.1713\n",
      "==========================================================================================\n",
      "Epoch [4630/5000] | Time: 0.31s\n",
      "(Training) Loss: 944436.7855\n",
      "(Validation) Loss: 981305.9708, MAE: 3765.7893, R2: 0.1714\n",
      "==========================================================================================\n",
      "Epoch [4631/5000] | Time: 0.31s\n",
      "(Training) Loss: 941984.8314\n",
      "(Validation) Loss: 981177.2343, MAE: 3765.6414, R2: 0.1715\n",
      "==========================================================================================\n",
      "Epoch [4632/5000] | Time: 0.30s\n",
      "(Training) Loss: 945679.3433\n",
      "(Validation) Loss: 981041.7778, MAE: 3765.3354, R2: 0.1716\n",
      "==========================================================================================\n",
      "Epoch [4633/5000] | Time: 0.27s\n",
      "(Training) Loss: 970703.1231\n",
      "(Validation) Loss: 980895.1365, MAE: 3763.8340, R2: 0.1718\n",
      "==========================================================================================\n",
      "Epoch [4634/5000] | Time: 0.30s\n",
      "(Training) Loss: 966849.2640\n",
      "(Validation) Loss: 980754.9714, MAE: 3760.8701, R2: 0.1719\n",
      "==========================================================================================\n",
      "Epoch [4635/5000] | Time: 0.32s\n",
      "(Training) Loss: 956154.1846\n",
      "(Validation) Loss: 980618.7022, MAE: 3761.1206, R2: 0.1720\n",
      "==========================================================================================\n",
      "Epoch [4636/5000] | Time: 0.31s\n",
      "(Training) Loss: 957414.7069\n",
      "(Validation) Loss: 980481.4171, MAE: 3760.3318, R2: 0.1721\n",
      "==========================================================================================\n",
      "Epoch [4637/5000] | Time: 0.29s\n",
      "(Training) Loss: 943493.5504\n",
      "(Validation) Loss: 980347.9111, MAE: 3760.7571, R2: 0.1722\n",
      "==========================================================================================\n",
      "Epoch [4638/5000] | Time: 0.30s\n",
      "(Training) Loss: 959418.0590\n",
      "(Validation) Loss: 980223.6698, MAE: 3763.2834, R2: 0.1723\n",
      "==========================================================================================\n",
      "Epoch [4639/5000] | Time: 0.30s\n",
      "(Training) Loss: 945056.9239\n",
      "(Validation) Loss: 980085.3130, MAE: 3764.3406, R2: 0.1724\n",
      "==========================================================================================\n",
      "Epoch [4640/5000] | Time: 0.32s\n",
      "(Training) Loss: 976567.9638\n",
      "(Validation) Loss: 979947.2305, MAE: 3760.9556, R2: 0.1725\n",
      "==========================================================================================\n",
      "Epoch [4641/5000] | Time: 0.30s\n",
      "(Training) Loss: 948691.8680\n",
      "(Validation) Loss: 979803.6927, MAE: 3761.3362, R2: 0.1727\n",
      "==========================================================================================\n",
      "Epoch [4642/5000] | Time: 0.28s\n",
      "(Training) Loss: 953711.9892\n",
      "(Validation) Loss: 979673.6406, MAE: 3759.1394, R2: 0.1728\n",
      "==========================================================================================\n",
      "Epoch [4643/5000] | Time: 0.29s\n",
      "(Training) Loss: 948880.1472\n",
      "(Validation) Loss: 979538.8495, MAE: 3759.9163, R2: 0.1729\n",
      "==========================================================================================\n",
      "Epoch [4644/5000] | Time: 0.29s\n",
      "(Training) Loss: 951010.8173\n",
      "(Validation) Loss: 979407.1263, MAE: 3760.0879, R2: 0.1730\n",
      "==========================================================================================\n",
      "Epoch [4645/5000] | Time: 0.35s\n",
      "(Training) Loss: 948184.3128\n",
      "(Validation) Loss: 979258.0724, MAE: 3757.0371, R2: 0.1731\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4646/5000] | Time: 0.36s\n",
      "(Training) Loss: 963711.6015\n",
      "(Validation) Loss: 979130.7073, MAE: 3758.4817, R2: 0.1732\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4647/5000] | Time: 0.31s\n",
      "(Training) Loss: 940912.3677\n",
      "(Validation) Loss: 978996.7695, MAE: 3758.6975, R2: 0.1733\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4648/5000] | Time: 0.28s\n",
      "(Training) Loss: 947872.3439\n",
      "(Validation) Loss: 978866.4432, MAE: 3757.6409, R2: 0.1735\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4649/5000] | Time: 0.28s\n",
      "(Training) Loss: 951996.7284\n",
      "(Validation) Loss: 978729.8438, MAE: 3758.5400, R2: 0.1736\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4650/5000] | Time: 0.28s\n",
      "(Training) Loss: 950373.6853\n",
      "(Validation) Loss: 978577.0463, MAE: 3753.7422, R2: 0.1737\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4651/5000] | Time: 0.28s\n",
      "(Training) Loss: 955445.4213\n",
      "(Validation) Loss: 978476.5206, MAE: 3759.4653, R2: 0.1738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4652/5000] | Time: 0.27s\n",
      "(Training) Loss: 937742.1595\n",
      "(Validation) Loss: 978309.2165, MAE: 3755.5381, R2: 0.1739\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4653/5000] | Time: 0.30s\n",
      "(Training) Loss: 963257.8376\n",
      "(Validation) Loss: 978175.6038, MAE: 3754.5361, R2: 0.1740\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4654/5000] | Time: 0.28s\n",
      "(Training) Loss: 954883.8680\n",
      "(Validation) Loss: 978034.5905, MAE: 3752.0461, R2: 0.1741\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4655/5000] | Time: 0.30s\n",
      "(Training) Loss: 969271.8585\n",
      "(Validation) Loss: 977944.1829, MAE: 3765.1023, R2: 0.1742\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4656/5000] | Time: 0.30s\n",
      "(Training) Loss: 940203.1996\n",
      "(Validation) Loss: 977765.8971, MAE: 3752.0208, R2: 0.1744\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4657/5000] | Time: 0.28s\n",
      "(Training) Loss: 950647.4143\n",
      "(Validation) Loss: 977635.6927, MAE: 3752.8333, R2: 0.1745\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4658/5000] | Time: 0.30s\n",
      "(Training) Loss: 952432.7874\n",
      "(Validation) Loss: 968577.5543, MAE: 3722.3120, R2: 0.1820\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4659/5000] | Time: 0.28s\n",
      "(Training) Loss: 929621.0842\n",
      "(Validation) Loss: 968508.9930, MAE: 3726.3672, R2: 0.1821\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4660/5000] | Time: 0.29s\n",
      "(Training) Loss: 947863.2551\n",
      "(Validation) Loss: 968383.4159, MAE: 3730.5652, R2: 0.1822\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4661/5000] | Time: 0.30s\n",
      "(Training) Loss: 936837.5343\n",
      "(Validation) Loss: 968217.3003, MAE: 3724.8352, R2: 0.1823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4662/5000] | Time: 0.30s\n",
      "(Training) Loss: 936751.0470\n",
      "(Validation) Loss: 968084.8152, MAE: 3726.0864, R2: 0.1824\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4663/5000] | Time: 0.27s\n",
      "(Training) Loss: 941504.6789\n",
      "(Validation) Loss: 967938.7327, MAE: 3723.3010, R2: 0.1826\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4664/5000] | Time: 0.27s\n",
      "(Training) Loss: 930537.4454\n",
      "(Validation) Loss: 967803.9314, MAE: 3724.8149, R2: 0.1827\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4665/5000] | Time: 0.27s\n",
      "(Training) Loss: 928016.6696\n",
      "(Validation) Loss: 967707.8654, MAE: 3733.4165, R2: 0.1827\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4666/5000] | Time: 0.27s\n",
      "(Training) Loss: 951122.3115\n",
      "(Validation) Loss: 967547.7283, MAE: 3728.4438, R2: 0.1829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4667/5000] | Time: 0.24s\n",
      "(Training) Loss: 945514.5584\n",
      "(Validation) Loss: 967386.2146, MAE: 3722.3940, R2: 0.1830\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4668/5000] | Time: 0.29s\n",
      "(Training) Loss: 938567.7602\n",
      "(Validation) Loss: 967248.5994, MAE: 3721.6555, R2: 0.1831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4669/5000] | Time: 0.31s\n",
      "(Training) Loss: 937740.7532\n",
      "(Validation) Loss: 967115.1187, MAE: 3722.3252, R2: 0.1832\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4670/5000] | Time: 0.33s\n",
      "(Training) Loss: 943404.7221\n",
      "(Validation) Loss: 966967.4108, MAE: 3720.4280, R2: 0.1834\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4671/5000] | Time: 0.32s\n",
      "(Training) Loss: 937635.7170\n",
      "(Validation) Loss: 966829.9225, MAE: 3721.3542, R2: 0.1835\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4672/5000] | Time: 0.27s\n",
      "(Training) Loss: 952096.6079\n",
      "(Validation) Loss: 966696.7010, MAE: 3719.7942, R2: 0.1836\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4673/5000] | Time: 0.29s\n",
      "(Training) Loss: 931007.3598\n",
      "(Validation) Loss: 966558.5727, MAE: 3719.7778, R2: 0.1837\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4674/5000] | Time: 0.30s\n",
      "(Training) Loss: 950715.7246\n",
      "(Validation) Loss: 966423.9289, MAE: 3720.5083, R2: 0.1838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4675/5000] | Time: 0.32s\n",
      "(Training) Loss: 939779.1840\n",
      "(Validation) Loss: 966285.0235, MAE: 3720.8899, R2: 0.1839\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4676/5000] | Time: 0.30s\n",
      "(Training) Loss: 940172.6237\n",
      "(Validation) Loss: 966144.4775, MAE: 3721.3931, R2: 0.1841\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4677/5000] | Time: 0.30s\n",
      "(Training) Loss: 932595.2062\n",
      "(Validation) Loss: 966015.4514, MAE: 3723.8350, R2: 0.1842\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4678/5000] | Time: 0.29s\n",
      "(Training) Loss: 936044.5406\n",
      "(Validation) Loss: 965867.1441, MAE: 3717.0361, R2: 0.1843\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4679/5000] | Time: 0.27s\n",
      "(Training) Loss: 935769.1643\n",
      "(Validation) Loss: 965727.6698, MAE: 3716.0212, R2: 0.1844\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4680/5000] | Time: 0.27s\n",
      "(Training) Loss: 927538.2119\n",
      "(Validation) Loss: 965595.1238, MAE: 3715.8521, R2: 0.1845\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4681/5000] | Time: 0.32s\n",
      "(Training) Loss: 930646.1662\n",
      "(Validation) Loss: 965471.6495, MAE: 3718.7048, R2: 0.1846\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4682/5000] | Time: 0.26s\n",
      "(Training) Loss: 937965.8718\n",
      "(Validation) Loss: 965318.6641, MAE: 3713.8005, R2: 0.1847\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4683/5000] | Time: 0.27s\n",
      "(Training) Loss: 947672.6022\n",
      "(Validation) Loss: 965205.6990, MAE: 3719.6807, R2: 0.1848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4684/5000] | Time: 0.28s\n",
      "(Training) Loss: 935778.8173\n",
      "(Validation) Loss: 965048.6044, MAE: 3714.1870, R2: 0.1850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4685/5000] | Time: 0.27s\n",
      "(Training) Loss: 944882.2659\n",
      "(Validation) Loss: 964908.3987, MAE: 3713.4749, R2: 0.1851\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4686/5000] | Time: 0.28s\n",
      "(Training) Loss: 933095.3972\n",
      "(Validation) Loss: 964768.6552, MAE: 3712.1934, R2: 0.1852\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4687/5000] | Time: 0.29s\n",
      "(Training) Loss: 939091.6872\n",
      "(Validation) Loss: 964634.7124, MAE: 3712.1514, R2: 0.1853\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4688/5000] | Time: 0.28s\n",
      "(Training) Loss: 946240.3242\n",
      "(Validation) Loss: 964499.1390, MAE: 3713.7642, R2: 0.1854\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4689/5000] | Time: 0.29s\n",
      "(Training) Loss: 940217.9594\n",
      "(Validation) Loss: 964353.9810, MAE: 3710.8687, R2: 0.1855\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4690/5000] | Time: 0.27s\n",
      "(Training) Loss: 945247.1142\n",
      "(Validation) Loss: 964220.7441, MAE: 3716.3354, R2: 0.1857\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4691/5000] | Time: 0.26s\n",
      "(Training) Loss: 956661.5565\n",
      "(Validation) Loss: 964078.4559, MAE: 3709.8870, R2: 0.1858\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4692/5000] | Time: 0.28s\n",
      "(Training) Loss: 950890.4055\n",
      "(Validation) Loss: 963948.9727, MAE: 3709.9099, R2: 0.1859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4693/5000] | Time: 0.28s\n",
      "(Training) Loss: 940152.6377\n",
      "(Validation) Loss: 963809.4984, MAE: 3709.6733, R2: 0.1860\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4694/5000] | Time: 0.27s\n",
      "(Training) Loss: 935061.3135\n",
      "(Validation) Loss: 963664.8533, MAE: 3707.1848, R2: 0.1861\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4695/5000] | Time: 0.26s\n",
      "(Training) Loss: 948092.3230\n",
      "(Validation) Loss: 963534.5981, MAE: 3709.1257, R2: 0.1862\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4696/5000] | Time: 0.27s\n",
      "(Training) Loss: 928135.2938\n",
      "(Validation) Loss: 963388.9727, MAE: 3705.9929, R2: 0.1863\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4697/5000] | Time: 0.29s\n",
      "(Training) Loss: 931055.0489\n",
      "(Validation) Loss: 963255.5530, MAE: 3705.5032, R2: 0.1865\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4698/5000] | Time: 0.32s\n",
      "(Training) Loss: 941614.6529\n",
      "(Validation) Loss: 963117.2470, MAE: 3708.5403, R2: 0.1866\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4699/5000] | Time: 0.30s\n",
      "(Training) Loss: 942139.4235\n",
      "(Validation) Loss: 962991.6190, MAE: 3708.9585, R2: 0.1867\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4700/5000] | Time: 0.30s\n",
      "(Training) Loss: 923678.6908\n",
      "(Validation) Loss: 962846.4813, MAE: 3705.6321, R2: 0.1868\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4701/5000] | Time: 0.28s\n",
      "(Training) Loss: 932920.6415\n",
      "(Validation) Loss: 962715.9365, MAE: 3706.3618, R2: 0.1869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4702/5000] | Time: 0.26s\n",
      "(Training) Loss: 952211.2570\n",
      "(Validation) Loss: 962586.8648, MAE: 3707.0022, R2: 0.1870\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4703/5000] | Time: 0.27s\n",
      "(Training) Loss: 937271.8331\n",
      "(Validation) Loss: 962452.0229, MAE: 3706.1997, R2: 0.1871\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4704/5000] | Time: 0.31s\n",
      "(Training) Loss: 949130.8940\n",
      "(Validation) Loss: 962300.6476, MAE: 3702.8923, R2: 0.1873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4705/5000] | Time: 0.30s\n",
      "(Training) Loss: 947837.7868\n",
      "(Validation) Loss: 962163.8806, MAE: 3702.7217, R2: 0.1874\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4706/5000] | Time: 0.27s\n",
      "(Training) Loss: 944947.2735\n",
      "(Validation) Loss: 961962.6108, MAE: 3697.7258, R2: 0.1875\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4707/5000] | Time: 0.30s\n",
      "(Training) Loss: 930783.4074\n",
      "(Validation) Loss: 961858.9308, MAE: 3702.0498, R2: 0.1876\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4708/5000] | Time: 0.31s\n",
      "(Training) Loss: 945957.0914\n",
      "(Validation) Loss: 961735.7867, MAE: 3702.6079, R2: 0.1877\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4709/5000] | Time: 0.33s\n",
      "(Training) Loss: 930211.4569\n",
      "(Validation) Loss: 961607.2635, MAE: 3704.3340, R2: 0.1878\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4710/5000] | Time: 0.28s\n",
      "(Training) Loss: 944457.1447\n",
      "(Validation) Loss: 961421.3841, MAE: 3699.4321, R2: 0.1880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4711/5000] | Time: 0.31s\n",
      "(Training) Loss: 932194.4023\n",
      "(Validation) Loss: 961362.7886, MAE: 3702.8584, R2: 0.1880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4712/5000] | Time: 0.28s\n",
      "(Training) Loss: 936444.1234\n",
      "(Validation) Loss: 954613.5060, MAE: 3678.4221, R2: 0.1937\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4713/5000] | Time: 0.33s\n",
      "(Training) Loss: 932361.1942\n",
      "(Validation) Loss: 954485.3079, MAE: 3679.7739, R2: 0.1938\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4714/5000] | Time: 0.26s\n",
      "(Training) Loss: 924244.6796\n",
      "(Validation) Loss: 950009.7930, MAE: 3672.8989, R2: 0.1975\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4715/5000] | Time: 0.28s\n",
      "(Training) Loss: 928338.3261\n",
      "(Validation) Loss: 949872.0000, MAE: 3675.0203, R2: 0.1976\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4716/5000] | Time: 0.26s\n",
      "(Training) Loss: 928526.2602\n",
      "(Validation) Loss: 949722.5752, MAE: 3672.4714, R2: 0.1977\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4717/5000] | Time: 0.29s\n",
      "(Training) Loss: 928011.8395\n",
      "(Validation) Loss: 949581.5975, MAE: 3670.3777, R2: 0.1979\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4718/5000] | Time: 0.28s\n",
      "(Training) Loss: 921479.1225\n",
      "(Validation) Loss: 949443.0679, MAE: 3668.1948, R2: 0.1980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4719/5000] | Time: 0.28s\n",
      "(Training) Loss: 932440.1497\n",
      "(Validation) Loss: 949306.8190, MAE: 3666.4958, R2: 0.1981\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4720/5000] | Time: 0.26s\n",
      "(Training) Loss: 915299.6910\n",
      "(Validation) Loss: 949174.8571, MAE: 3667.5786, R2: 0.1982\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4721/5000] | Time: 0.27s\n",
      "(Training) Loss: 936846.4898\n",
      "(Validation) Loss: 949043.1949, MAE: 3667.5034, R2: 0.1983\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4722/5000] | Time: 0.26s\n",
      "(Training) Loss: 925384.8464\n",
      "(Validation) Loss: 948908.0533, MAE: 3666.0603, R2: 0.1984\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4723/5000] | Time: 0.31s\n",
      "(Training) Loss: 949713.7240\n",
      "(Validation) Loss: 948773.9581, MAE: 3665.0181, R2: 0.1985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4724/5000] | Time: 0.28s\n",
      "(Training) Loss: 937245.5006\n",
      "(Validation) Loss: 948644.7898, MAE: 3667.2070, R2: 0.1986\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4725/5000] | Time: 0.29s\n",
      "(Training) Loss: 931942.8731\n",
      "(Validation) Loss: 948506.4127, MAE: 3664.0623, R2: 0.1988\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4726/5000] | Time: 0.29s\n",
      "(Training) Loss: 914241.6180\n",
      "(Validation) Loss: 948384.2083, MAE: 3667.1667, R2: 0.1989\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4727/5000] | Time: 0.29s\n",
      "(Training) Loss: 921318.4549\n",
      "(Validation) Loss: 948248.5689, MAE: 3664.3140, R2: 0.1990\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4728/5000] | Time: 0.29s\n",
      "(Training) Loss: 931498.8141\n",
      "(Validation) Loss: 948126.1562, MAE: 3668.9082, R2: 0.1991\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4729/5000] | Time: 0.26s\n",
      "(Training) Loss: 931971.7253\n",
      "(Validation) Loss: 947985.8844, MAE: 3664.1238, R2: 0.1992\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4730/5000] | Time: 0.27s\n",
      "(Training) Loss: 920793.8687\n",
      "(Validation) Loss: 947856.2743, MAE: 3665.0786, R2: 0.1993\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4731/5000] | Time: 0.28s\n",
      "(Training) Loss: 931568.4734\n",
      "(Validation) Loss: 947718.6844, MAE: 3661.4216, R2: 0.1994\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4732/5000] | Time: 0.27s\n",
      "(Training) Loss: 917901.8845\n",
      "(Validation) Loss: 947589.9683, MAE: 3662.2610, R2: 0.1995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4733/5000] | Time: 0.30s\n",
      "(Training) Loss: 933040.1307\n",
      "(Validation) Loss: 947462.6895, MAE: 3662.8477, R2: 0.1996\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4734/5000] | Time: 0.29s\n",
      "(Training) Loss: 910774.2621\n",
      "(Validation) Loss: 947328.1524, MAE: 3661.6609, R2: 0.1997\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4735/5000] | Time: 0.28s\n",
      "(Training) Loss: 913899.6282\n",
      "(Validation) Loss: 947198.6032, MAE: 3662.9373, R2: 0.1998\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4736/5000] | Time: 0.29s\n",
      "(Training) Loss: 921830.4181\n",
      "(Validation) Loss: 947064.8990, MAE: 3660.8560, R2: 0.2000\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4737/5000] | Time: 0.27s\n",
      "(Training) Loss: 923829.7284\n",
      "(Validation) Loss: 946928.4419, MAE: 3659.1821, R2: 0.2001\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4738/5000] | Time: 0.29s\n",
      "(Training) Loss: 936815.8052\n",
      "(Validation) Loss: 946802.8444, MAE: 3659.9167, R2: 0.2002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4739/5000] | Time: 0.29s\n",
      "(Training) Loss: 914847.9765\n",
      "(Validation) Loss: 946665.7473, MAE: 3659.3604, R2: 0.2003\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4740/5000] | Time: 0.29s\n",
      "(Training) Loss: 928742.9036\n",
      "(Validation) Loss: 941667.7994, MAE: 3647.1816, R2: 0.2045\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4741/5000] | Time: 0.28s\n",
      "(Training) Loss: 907494.1935\n",
      "(Validation) Loss: 941546.1943, MAE: 3648.0845, R2: 0.2046\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4742/5000] | Time: 0.27s\n",
      "(Training) Loss: 917983.4181\n",
      "(Validation) Loss: 941405.7194, MAE: 3641.5908, R2: 0.2047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4743/5000] | Time: 0.28s\n",
      "(Training) Loss: 909959.4765\n",
      "(Validation) Loss: 941315.3981, MAE: 3642.3689, R2: 0.2047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4744/5000] | Time: 0.29s\n",
      "(Training) Loss: 926341.0463\n",
      "(Validation) Loss: 941140.2870, MAE: 3640.9324, R2: 0.2049\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4745/5000] | Time: 0.26s\n",
      "(Training) Loss: 918140.4397\n",
      "(Validation) Loss: 940992.1321, MAE: 3650.6489, R2: 0.2050\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4746/5000] | Time: 0.28s\n",
      "(Training) Loss: 908625.3249\n",
      "(Validation) Loss: 940788.0279, MAE: 3641.0342, R2: 0.2052\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4747/5000] | Time: 0.26s\n",
      "(Training) Loss: 916404.6783\n",
      "(Validation) Loss: 940660.4444, MAE: 3640.3713, R2: 0.2053\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4748/5000] | Time: 0.28s\n",
      "(Training) Loss: 926778.7310\n",
      "(Validation) Loss: 940531.6622, MAE: 3633.8982, R2: 0.2054\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4749/5000] | Time: 0.29s\n",
      "(Training) Loss: 912935.9086\n",
      "(Validation) Loss: 940390.9181, MAE: 3630.5020, R2: 0.2055\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4750/5000] | Time: 0.27s\n",
      "(Training) Loss: 927182.4175\n",
      "(Validation) Loss: 940272.7467, MAE: 3631.5112, R2: 0.2056\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4751/5000] | Time: 0.26s\n",
      "(Training) Loss: 915362.3782\n",
      "(Validation) Loss: 940138.7073, MAE: 3630.5415, R2: 0.2057\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4752/5000] | Time: 0.27s\n",
      "(Training) Loss: 911009.8058\n",
      "(Validation) Loss: 940083.0273, MAE: 3639.0310, R2: 0.2058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4753/5000] | Time: 0.27s\n",
      "(Training) Loss: 941161.5463\n",
      "(Validation) Loss: 939955.8502, MAE: 3636.1201, R2: 0.2059\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4754/5000] | Time: 0.26s\n",
      "(Training) Loss: 910764.6580\n",
      "(Validation) Loss: 939825.5441, MAE: 3634.9792, R2: 0.2060\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4755/5000] | Time: 0.28s\n",
      "(Training) Loss: 914912.4664\n",
      "(Validation) Loss: 939700.0990, MAE: 3634.1396, R2: 0.2061\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4756/5000] | Time: 0.27s\n",
      "(Training) Loss: 913840.8445\n",
      "(Validation) Loss: 939574.5168, MAE: 3635.3894, R2: 0.2062\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4757/5000] | Time: 0.30s\n",
      "(Training) Loss: 917424.2138\n",
      "(Validation) Loss: 939447.6800, MAE: 3633.6514, R2: 0.2063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4758/5000] | Time: 0.27s\n",
      "(Training) Loss: 916315.8687\n",
      "(Validation) Loss: 939323.3371, MAE: 3632.9189, R2: 0.2064\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4759/5000] | Time: 0.25s\n",
      "(Training) Loss: 921592.2081\n",
      "(Validation) Loss: 939194.4279, MAE: 3633.0771, R2: 0.2065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4760/5000] | Time: 0.27s\n",
      "(Training) Loss: 906549.9499\n",
      "(Validation) Loss: 939073.6000, MAE: 3632.9146, R2: 0.2066\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4761/5000] | Time: 0.28s\n",
      "(Training) Loss: 920239.5114\n",
      "(Validation) Loss: 938938.4584, MAE: 3631.0708, R2: 0.2067\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4762/5000] | Time: 0.26s\n",
      "(Training) Loss: 907962.3775\n",
      "(Validation) Loss: 938809.3562, MAE: 3630.6899, R2: 0.2068\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4763/5000] | Time: 0.25s\n",
      "(Training) Loss: 905067.3699\n",
      "(Validation) Loss: 938687.4565, MAE: 3629.7952, R2: 0.2069\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4764/5000] | Time: 0.27s\n",
      "(Training) Loss: 902597.4316\n",
      "(Validation) Loss: 938570.5143, MAE: 3631.5896, R2: 0.2070\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4765/5000] | Time: 0.29s\n",
      "(Training) Loss: 910615.6992\n",
      "(Validation) Loss: 938435.5556, MAE: 3630.5161, R2: 0.2072\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4766/5000] | Time: 0.27s\n",
      "(Training) Loss: 921305.8268\n",
      "(Validation) Loss: 938309.3689, MAE: 3630.1606, R2: 0.2073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4767/5000] | Time: 0.30s\n",
      "(Training) Loss: 909892.4721\n",
      "(Validation) Loss: 938180.3683, MAE: 3628.3406, R2: 0.2074\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4768/5000] | Time: 0.33s\n",
      "(Training) Loss: 913000.0266\n",
      "(Validation) Loss: 938054.0648, MAE: 3628.0129, R2: 0.2075\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4769/5000] | Time: 0.28s\n",
      "(Training) Loss: 911703.3122\n",
      "(Validation) Loss: 937927.3549, MAE: 3626.9375, R2: 0.2076\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4770/5000] | Time: 0.30s\n",
      "(Training) Loss: 903931.3106\n",
      "(Validation) Loss: 937803.5860, MAE: 3628.5208, R2: 0.2077\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4771/5000] | Time: 0.30s\n",
      "(Training) Loss: 900316.3227\n",
      "(Validation) Loss: 937681.4222, MAE: 3629.8254, R2: 0.2078\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4772/5000] | Time: 0.30s\n",
      "(Training) Loss: 908116.3956\n",
      "(Validation) Loss: 937564.8051, MAE: 3630.8130, R2: 0.2079\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4773/5000] | Time: 0.28s\n",
      "(Training) Loss: 935355.0362\n",
      "(Validation) Loss: 937437.1556, MAE: 3629.4473, R2: 0.2080\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4774/5000] | Time: 0.27s\n",
      "(Training) Loss: 923085.1548\n",
      "(Validation) Loss: 937308.4546, MAE: 3629.4304, R2: 0.2081\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4775/5000] | Time: 0.28s\n",
      "(Training) Loss: 913787.5603\n",
      "(Validation) Loss: 937177.4019, MAE: 3627.6892, R2: 0.2082\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4776/5000] | Time: 0.27s\n",
      "(Training) Loss: 905139.0330\n",
      "(Validation) Loss: 937053.5619, MAE: 3627.7207, R2: 0.2083\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4777/5000] | Time: 0.26s\n",
      "(Training) Loss: 919017.4708\n",
      "(Validation) Loss: 936928.1016, MAE: 3628.6765, R2: 0.2084\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4778/5000] | Time: 0.28s\n",
      "(Training) Loss: 915272.2836\n",
      "(Validation) Loss: 936806.6540, MAE: 3628.1536, R2: 0.2085\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4779/5000] | Time: 0.28s\n",
      "(Training) Loss: 908796.9645\n",
      "(Validation) Loss: 936681.0159, MAE: 3627.5315, R2: 0.2086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4780/5000] | Time: 0.28s\n",
      "(Training) Loss: 923487.4473\n",
      "(Validation) Loss: 936544.3302, MAE: 3625.6382, R2: 0.2087\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4781/5000] | Time: 0.30s\n",
      "(Training) Loss: 914588.5444\n",
      "(Validation) Loss: 936418.8546, MAE: 3625.5696, R2: 0.2088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4782/5000] | Time: 0.28s\n",
      "(Training) Loss: 906686.1758\n",
      "(Validation) Loss: 936312.6806, MAE: 3631.1807, R2: 0.2089\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4783/5000] | Time: 0.28s\n",
      "(Training) Loss: 911707.9283\n",
      "(Validation) Loss: 936160.7568, MAE: 3623.0637, R2: 0.2090\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4784/5000] | Time: 0.25s\n",
      "(Training) Loss: 906031.3407\n",
      "(Validation) Loss: 936027.8806, MAE: 3621.9165, R2: 0.2092\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4785/5000] | Time: 0.26s\n",
      "(Training) Loss: 928027.7494\n",
      "(Validation) Loss: 935902.5117, MAE: 3620.8386, R2: 0.2093\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4786/5000] | Time: 0.28s\n",
      "(Training) Loss: 921739.0895\n",
      "(Validation) Loss: 935779.7740, MAE: 3622.6724, R2: 0.2094\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4787/5000] | Time: 0.24s\n",
      "(Training) Loss: 925115.9918\n",
      "(Validation) Loss: 935647.1314, MAE: 3621.3501, R2: 0.2095\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4788/5000] | Time: 0.27s\n",
      "(Training) Loss: 910874.2145\n",
      "(Validation) Loss: 935520.4216, MAE: 3619.0298, R2: 0.2096\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4789/5000] | Time: 0.30s\n",
      "(Training) Loss: 923757.9353\n",
      "(Validation) Loss: 935395.5454, MAE: 3622.7769, R2: 0.2097\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4790/5000] | Time: 0.25s\n",
      "(Training) Loss: 909485.3972\n",
      "(Validation) Loss: 935267.3422, MAE: 3618.3455, R2: 0.2098\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4791/5000] | Time: 0.28s\n",
      "(Training) Loss: 907231.9746\n",
      "(Validation) Loss: 935142.6692, MAE: 3619.0085, R2: 0.2099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4792/5000] | Time: 0.28s\n",
      "(Training) Loss: 900913.2678\n",
      "(Validation) Loss: 935016.6044, MAE: 3618.7258, R2: 0.2100\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4793/5000] | Time: 0.28s\n",
      "(Training) Loss: 903561.2030\n",
      "(Validation) Loss: 934891.4794, MAE: 3617.4155, R2: 0.2101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4794/5000] | Time: 0.27s\n",
      "(Training) Loss: 905201.1371\n",
      "(Validation) Loss: 934770.6260, MAE: 3620.2737, R2: 0.2102\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4795/5000] | Time: 0.27s\n",
      "(Training) Loss: 914490.1497\n",
      "(Validation) Loss: 934643.6978, MAE: 3619.6460, R2: 0.2103\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4796/5000] | Time: 0.31s\n",
      "(Training) Loss: 920982.4029\n",
      "(Validation) Loss: 934521.8133, MAE: 3623.7170, R2: 0.2104\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4797/5000] | Time: 0.29s\n",
      "(Training) Loss: 920912.8794\n",
      "(Validation) Loss: 934384.4978, MAE: 3616.3635, R2: 0.2105\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4798/5000] | Time: 0.27s\n",
      "(Training) Loss: 916075.4607\n",
      "(Validation) Loss: 934271.7206, MAE: 3618.2581, R2: 0.2106\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4799/5000] | Time: 0.27s\n",
      "(Training) Loss: 916264.8109\n",
      "(Validation) Loss: 934138.2197, MAE: 3617.1748, R2: 0.2107\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4800/5000] | Time: 0.27s\n",
      "(Training) Loss: 897863.2219\n",
      "(Validation) Loss: 934003.9517, MAE: 3614.7527, R2: 0.2108\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4801/5000] | Time: 0.29s\n",
      "(Training) Loss: 904793.8869\n",
      "(Validation) Loss: 933886.7657, MAE: 3616.0393, R2: 0.2109\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4802/5000] | Time: 0.27s\n",
      "(Training) Loss: 899351.0352\n",
      "(Validation) Loss: 933757.1505, MAE: 3614.5347, R2: 0.2111\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4803/5000] | Time: 0.27s\n",
      "(Training) Loss: 908847.4442\n",
      "(Validation) Loss: 933633.6711, MAE: 3615.0317, R2: 0.2112\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4804/5000] | Time: 0.23s\n",
      "(Training) Loss: 902998.4537\n",
      "(Validation) Loss: 933509.3333, MAE: 3615.7622, R2: 0.2113\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4805/5000] | Time: 0.26s\n",
      "(Training) Loss: 906984.9093\n",
      "(Validation) Loss: 933400.7111, MAE: 3618.4373, R2: 0.2113\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4806/5000] | Time: 0.25s\n",
      "(Training) Loss: 905584.0755\n",
      "(Validation) Loss: 933273.5340, MAE: 3620.8110, R2: 0.2115\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4807/5000] | Time: 0.24s\n",
      "(Training) Loss: 911147.3115\n",
      "(Validation) Loss: 933128.7568, MAE: 3612.9429, R2: 0.2116\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4808/5000] | Time: 0.24s\n",
      "(Training) Loss: 914721.9753\n",
      "(Validation) Loss: 933004.6324, MAE: 3614.1519, R2: 0.2117\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4809/5000] | Time: 0.28s\n",
      "(Training) Loss: 900783.3610\n",
      "(Validation) Loss: 932877.1606, MAE: 3613.1025, R2: 0.2118\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4810/5000] | Time: 0.26s\n",
      "(Training) Loss: 908896.4791\n",
      "(Validation) Loss: 932756.1295, MAE: 3614.8284, R2: 0.2119\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4811/5000] | Time: 0.23s\n",
      "(Training) Loss: 911035.9848\n",
      "(Validation) Loss: 932631.7613, MAE: 3615.3032, R2: 0.2120\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4812/5000] | Time: 0.25s\n",
      "(Training) Loss: 904568.1504\n",
      "(Validation) Loss: 932507.2356, MAE: 3613.8247, R2: 0.2121\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4813/5000] | Time: 0.26s\n",
      "(Training) Loss: 912475.7557\n",
      "(Validation) Loss: 932376.1676, MAE: 3612.4482, R2: 0.2122\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4814/5000] | Time: 0.27s\n",
      "(Training) Loss: 934589.9342\n",
      "(Validation) Loss: 932244.6832, MAE: 3610.8118, R2: 0.2123\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4815/5000] | Time: 0.26s\n",
      "(Training) Loss: 903276.4162\n",
      "(Validation) Loss: 934584.6248, MAE: 3617.2412, R2: 0.2105\n",
      "==========================================================================================\n",
      "Epoch [4816/5000] | Time: 0.27s\n",
      "(Training) Loss: 909100.9864\n",
      "(Validation) Loss: 931989.9378, MAE: 3608.5088, R2: 0.2125\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4817/5000] | Time: 0.25s\n",
      "(Training) Loss: 916586.8991\n",
      "(Validation) Loss: 931867.4844, MAE: 3608.3818, R2: 0.2126\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4818/5000] | Time: 0.27s\n",
      "(Training) Loss: 907853.2671\n",
      "(Validation) Loss: 931739.7130, MAE: 3607.9980, R2: 0.2127\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4819/5000] | Time: 0.25s\n",
      "(Training) Loss: 899435.2966\n",
      "(Validation) Loss: 931617.1124, MAE: 3608.1934, R2: 0.2128\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4820/5000] | Time: 0.25s\n",
      "(Training) Loss: 910800.7582\n",
      "(Validation) Loss: 931494.4051, MAE: 3608.3792, R2: 0.2129\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4821/5000] | Time: 0.28s\n",
      "(Training) Loss: 916843.7722\n",
      "(Validation) Loss: 933057.9098, MAE: 3612.9734, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [4822/5000] | Time: 0.27s\n",
      "(Training) Loss: 901274.4486\n",
      "(Validation) Loss: 932913.5594, MAE: 3612.1423, R2: 0.2118\n",
      "==========================================================================================\n",
      "Epoch [4823/5000] | Time: 0.34s\n",
      "(Training) Loss: 914948.6954\n",
      "(Validation) Loss: 947182.1460, MAE: 3662.1638, R2: 0.1999\n",
      "==========================================================================================\n",
      "Epoch [4824/5000] | Time: 0.27s\n",
      "(Training) Loss: 916522.8591\n",
      "(Validation) Loss: 947100.9930, MAE: 3662.9622, R2: 0.1999\n",
      "==========================================================================================\n",
      "Epoch [4825/5000] | Time: 0.30s\n",
      "(Training) Loss: 917315.1345\n",
      "(Validation) Loss: 946960.2387, MAE: 3660.1223, R2: 0.2000\n",
      "==========================================================================================\n",
      "Epoch [4826/5000] | Time: 0.27s\n",
      "(Training) Loss: 915024.2779\n",
      "(Validation) Loss: 946825.3003, MAE: 3661.1360, R2: 0.2002\n",
      "==========================================================================================\n",
      "Epoch [4827/5000] | Time: 0.29s\n",
      "(Training) Loss: 912476.0102\n",
      "(Validation) Loss: 946689.6102, MAE: 3660.1318, R2: 0.2003\n",
      "==========================================================================================\n",
      "Epoch [4828/5000] | Time: 0.31s\n",
      "(Training) Loss: 928827.2411\n",
      "(Validation) Loss: 946556.8356, MAE: 3659.3289, R2: 0.2004\n",
      "==========================================================================================\n",
      "Epoch [4829/5000] | Time: 0.25s\n",
      "(Training) Loss: 933085.6539\n",
      "(Validation) Loss: 946417.0159, MAE: 3659.5403, R2: 0.2005\n",
      "==========================================================================================\n",
      "Epoch [4830/5000] | Time: 0.29s\n",
      "(Training) Loss: 946278.4549\n",
      "(Validation) Loss: 946285.2724, MAE: 3660.2441, R2: 0.2006\n",
      "==========================================================================================\n",
      "Epoch [4831/5000] | Time: 0.27s\n",
      "(Training) Loss: 928790.8718\n",
      "(Validation) Loss: 946149.6635, MAE: 3660.4094, R2: 0.2007\n",
      "==========================================================================================\n",
      "Epoch [4832/5000] | Time: 0.27s\n",
      "(Training) Loss: 909819.0628\n",
      "(Validation) Loss: 946013.8057, MAE: 3660.5723, R2: 0.2008\n",
      "==========================================================================================\n",
      "Epoch [4833/5000] | Time: 0.27s\n",
      "(Training) Loss: 947751.0857\n",
      "(Validation) Loss: 945879.9644, MAE: 3659.1240, R2: 0.2009\n",
      "==========================================================================================\n",
      "Epoch [4834/5000] | Time: 0.27s\n",
      "(Training) Loss: 922183.5831\n",
      "(Validation) Loss: 945746.1740, MAE: 3659.7710, R2: 0.2011\n",
      "==========================================================================================\n",
      "Epoch [4835/5000] | Time: 0.26s\n",
      "(Training) Loss: 969889.7081\n",
      "(Validation) Loss: 945616.9092, MAE: 3661.2244, R2: 0.2012\n",
      "==========================================================================================\n",
      "Epoch [4836/5000] | Time: 0.27s\n",
      "(Training) Loss: 921681.1126\n",
      "(Validation) Loss: 945471.8222, MAE: 3657.7380, R2: 0.2013\n",
      "==========================================================================================\n",
      "Epoch [4837/5000] | Time: 0.27s\n",
      "(Training) Loss: 932195.8236\n",
      "(Validation) Loss: 945341.2876, MAE: 3658.6726, R2: 0.2014\n",
      "==========================================================================================\n",
      "Epoch [4838/5000] | Time: 0.29s\n",
      "(Training) Loss: 919744.1872\n",
      "(Validation) Loss: 945212.7949, MAE: 3658.3909, R2: 0.2015\n",
      "==========================================================================================\n",
      "Epoch [4839/5000] | Time: 0.33s\n",
      "(Training) Loss: 916510.8845\n",
      "(Validation) Loss: 945082.3873, MAE: 3659.4619, R2: 0.2016\n",
      "==========================================================================================\n",
      "Epoch [4840/5000] | Time: 0.31s\n",
      "(Training) Loss: 921244.4981\n",
      "(Validation) Loss: 944941.9987, MAE: 3654.6353, R2: 0.2017\n",
      "==========================================================================================\n",
      "Epoch [4841/5000] | Time: 0.32s\n",
      "(Training) Loss: 909133.0076\n",
      "(Validation) Loss: 944811.2457, MAE: 3654.5676, R2: 0.2018\n",
      "==========================================================================================\n",
      "Epoch [4842/5000] | Time: 0.32s\n",
      "(Training) Loss: 906725.8625\n",
      "(Validation) Loss: 944682.8952, MAE: 3654.3901, R2: 0.2019\n",
      "==========================================================================================\n",
      "Epoch [4843/5000] | Time: 0.28s\n",
      "(Training) Loss: 920616.7671\n",
      "(Validation) Loss: 944552.2743, MAE: 3655.2073, R2: 0.2021\n",
      "==========================================================================================\n",
      "Epoch [4844/5000] | Time: 0.30s\n",
      "(Training) Loss: 931062.3192\n",
      "(Validation) Loss: 944424.3403, MAE: 3656.0747, R2: 0.2022\n",
      "==========================================================================================\n",
      "Epoch [4845/5000] | Time: 0.30s\n",
      "(Training) Loss: 919270.7195\n",
      "(Validation) Loss: 944291.1238, MAE: 3654.9082, R2: 0.2023\n",
      "==========================================================================================\n",
      "Epoch [4846/5000] | Time: 0.30s\n",
      "(Training) Loss: 935830.7912\n",
      "(Validation) Loss: 944162.3060, MAE: 3656.0347, R2: 0.2024\n",
      "==========================================================================================\n",
      "Epoch [4847/5000] | Time: 0.28s\n",
      "(Training) Loss: 917561.4695\n",
      "(Validation) Loss: 944025.3003, MAE: 3653.4207, R2: 0.2025\n",
      "==========================================================================================\n",
      "Epoch [4848/5000] | Time: 0.27s\n",
      "(Training) Loss: 907873.0197\n",
      "(Validation) Loss: 943901.6076, MAE: 3656.6218, R2: 0.2026\n",
      "==========================================================================================\n",
      "Epoch [4849/5000] | Time: 0.26s\n",
      "(Training) Loss: 937498.5216\n",
      "(Validation) Loss: 943765.3283, MAE: 3652.8340, R2: 0.2027\n",
      "==========================================================================================\n",
      "Epoch [4850/5000] | Time: 0.26s\n",
      "(Training) Loss: 907924.2195\n",
      "(Validation) Loss: 943631.4311, MAE: 3653.4236, R2: 0.2028\n",
      "==========================================================================================\n",
      "Epoch [4851/5000] | Time: 0.25s\n",
      "(Training) Loss: 921761.6834\n",
      "(Validation) Loss: 943507.0527, MAE: 3654.5156, R2: 0.2029\n",
      "==========================================================================================\n",
      "Epoch [4852/5000] | Time: 0.30s\n",
      "(Training) Loss: 910304.7094\n",
      "(Validation) Loss: 943367.1263, MAE: 3651.7878, R2: 0.2030\n",
      "==========================================================================================\n",
      "Epoch [4853/5000] | Time: 0.24s\n",
      "(Training) Loss: 907309.6523\n",
      "(Validation) Loss: 943235.6216, MAE: 3650.5955, R2: 0.2031\n",
      "==========================================================================================\n",
      "Epoch [4854/5000] | Time: 0.28s\n",
      "(Training) Loss: 935346.0533\n",
      "(Validation) Loss: 943111.3346, MAE: 3651.0627, R2: 0.2033\n",
      "==========================================================================================\n",
      "Epoch [4855/5000] | Time: 0.31s\n",
      "(Training) Loss: 928985.9426\n",
      "(Validation) Loss: 942977.3714, MAE: 3650.4453, R2: 0.2034\n",
      "==========================================================================================\n",
      "Epoch [4856/5000] | Time: 0.23s\n",
      "(Training) Loss: 905469.9116\n",
      "(Validation) Loss: 942842.0267, MAE: 3649.5659, R2: 0.2035\n",
      "==========================================================================================\n",
      "Epoch [4857/5000] | Time: 0.22s\n",
      "(Training) Loss: 919214.7795\n",
      "(Validation) Loss: 942719.9390, MAE: 3649.5215, R2: 0.2036\n",
      "==========================================================================================\n",
      "Epoch [4858/5000] | Time: 0.24s\n",
      "(Training) Loss: 908957.4778\n",
      "(Validation) Loss: 942585.0921, MAE: 3648.2307, R2: 0.2037\n",
      "==========================================================================================\n",
      "Epoch [4859/5000] | Time: 0.25s\n",
      "(Training) Loss: 932309.0178\n",
      "(Validation) Loss: 942468.1448, MAE: 3651.3823, R2: 0.2038\n",
      "==========================================================================================\n",
      "Epoch [4860/5000] | Time: 0.30s\n",
      "(Training) Loss: 919307.8699\n",
      "(Validation) Loss: 942363.9568, MAE: 3655.8813, R2: 0.2039\n",
      "==========================================================================================\n",
      "Epoch [4861/5000] | Time: 0.27s\n",
      "(Training) Loss: 914769.1034\n",
      "(Validation) Loss: 942189.5263, MAE: 3647.6108, R2: 0.2040\n",
      "==========================================================================================\n",
      "Epoch [4862/5000] | Time: 0.23s\n",
      "(Training) Loss: 913765.3452\n",
      "(Validation) Loss: 942063.3752, MAE: 3647.9475, R2: 0.2041\n",
      "==========================================================================================\n",
      "Epoch [4863/5000] | Time: 0.28s\n",
      "(Training) Loss: 908665.4686\n",
      "(Validation) Loss: 941931.4438, MAE: 3646.9248, R2: 0.2042\n",
      "==========================================================================================\n",
      "Epoch [4864/5000] | Time: 0.30s\n",
      "(Training) Loss: 920011.5063\n",
      "(Validation) Loss: 941804.7390, MAE: 3646.1482, R2: 0.2043\n",
      "==========================================================================================\n",
      "Epoch [4865/5000] | Time: 0.28s\n",
      "(Training) Loss: 931619.5273\n",
      "(Validation) Loss: 941673.6152, MAE: 3646.7102, R2: 0.2045\n",
      "==========================================================================================\n",
      "Epoch [4866/5000] | Time: 0.30s\n",
      "(Training) Loss: 927171.2754\n",
      "(Validation) Loss: 941541.3486, MAE: 3646.3799, R2: 0.2046\n",
      "==========================================================================================\n",
      "Epoch [4867/5000] | Time: 0.29s\n",
      "(Training) Loss: 911011.6555\n",
      "(Validation) Loss: 941410.2806, MAE: 3646.0527, R2: 0.2047\n",
      "==========================================================================================\n",
      "Epoch [4868/5000] | Time: 0.29s\n",
      "(Training) Loss: 903893.8823\n",
      "(Validation) Loss: 941281.5949, MAE: 3645.2683, R2: 0.2048\n",
      "==========================================================================================\n",
      "Epoch [4869/5000] | Time: 0.25s\n",
      "(Training) Loss: 910353.9454\n",
      "(Validation) Loss: 941153.6305, MAE: 3645.2131, R2: 0.2049\n",
      "==========================================================================================\n",
      "Epoch [4870/5000] | Time: 0.27s\n",
      "(Training) Loss: 924767.5888\n",
      "(Validation) Loss: 941023.3651, MAE: 3643.5454, R2: 0.2050\n",
      "==========================================================================================\n",
      "Epoch [4871/5000] | Time: 0.29s\n",
      "(Training) Loss: 907355.3648\n",
      "(Validation) Loss: 940887.9441, MAE: 3642.5920, R2: 0.2051\n",
      "==========================================================================================\n",
      "Epoch [4872/5000] | Time: 0.33s\n",
      "(Training) Loss: 913133.1237\n",
      "(Validation) Loss: 940759.6648, MAE: 3642.3423, R2: 0.2052\n",
      "==========================================================================================\n",
      "Epoch [4873/5000] | Time: 0.35s\n",
      "(Training) Loss: 929019.2481\n",
      "(Validation) Loss: 940632.3098, MAE: 3643.7261, R2: 0.2053\n",
      "==========================================================================================\n",
      "Epoch [4874/5000] | Time: 0.31s\n",
      "(Training) Loss: 915088.5590\n",
      "(Validation) Loss: 940500.1346, MAE: 3642.8711, R2: 0.2054\n",
      "==========================================================================================\n",
      "Epoch [4875/5000] | Time: 0.31s\n",
      "(Training) Loss: 906090.8918\n",
      "(Validation) Loss: 940371.2406, MAE: 3642.4333, R2: 0.2055\n",
      "==========================================================================================\n",
      "Epoch [4876/5000] | Time: 0.38s\n",
      "(Training) Loss: 917533.1999\n",
      "(Validation) Loss: 940235.3422, MAE: 3639.4514, R2: 0.2057\n",
      "==========================================================================================\n",
      "Epoch [4877/5000] | Time: 0.33s\n",
      "(Training) Loss: 926394.2671\n",
      "(Validation) Loss: 940113.4324, MAE: 3642.9368, R2: 0.2058\n",
      "==========================================================================================\n",
      "Epoch [4878/5000] | Time: 0.23s\n",
      "(Training) Loss: 914474.9753\n",
      "(Validation) Loss: 939981.6686, MAE: 3640.7344, R2: 0.2059\n",
      "==========================================================================================\n",
      "Epoch [4879/5000] | Time: 0.29s\n",
      "(Training) Loss: 916344.2373\n",
      "(Validation) Loss: 939850.6667, MAE: 3640.2153, R2: 0.2060\n",
      "==========================================================================================\n",
      "Epoch [4880/5000] | Time: 0.29s\n",
      "(Training) Loss: 909848.0457\n",
      "(Validation) Loss: 939717.9429, MAE: 3638.6038, R2: 0.2061\n",
      "==========================================================================================\n",
      "Epoch [4881/5000] | Time: 0.28s\n",
      "(Training) Loss: 927059.8731\n",
      "(Validation) Loss: 939598.5575, MAE: 3641.3159, R2: 0.2062\n",
      "==========================================================================================\n",
      "Epoch [4882/5000] | Time: 0.27s\n",
      "(Training) Loss: 921257.0964\n",
      "(Validation) Loss: 939467.8197, MAE: 3642.5869, R2: 0.2063\n",
      "==========================================================================================\n",
      "Epoch [4883/5000] | Time: 0.28s\n",
      "(Training) Loss: 903856.4486\n",
      "(Validation) Loss: 930461.5111, MAE: 3611.1196, R2: 0.2138\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4884/5000] | Time: 0.30s\n",
      "(Training) Loss: 912518.9169\n",
      "(Validation) Loss: 930326.5168, MAE: 3607.5029, R2: 0.2139\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4885/5000] | Time: 0.30s\n",
      "(Training) Loss: 901235.3750\n",
      "(Validation) Loss: 938626.3213, MAE: 3636.5715, R2: 0.2070\n",
      "==========================================================================================\n",
      "Epoch [4886/5000] | Time: 0.25s\n",
      "(Training) Loss: 914383.2170\n",
      "(Validation) Loss: 938476.2870, MAE: 3633.4771, R2: 0.2071\n",
      "==========================================================================================\n",
      "Epoch [4887/5000] | Time: 0.31s\n",
      "(Training) Loss: 929353.5742\n",
      "(Validation) Loss: 938338.6413, MAE: 3633.5400, R2: 0.2072\n",
      "==========================================================================================\n",
      "Epoch [4888/5000] | Time: 0.26s\n",
      "(Training) Loss: 919849.2589\n",
      "(Validation) Loss: 938195.6063, MAE: 3631.9810, R2: 0.2074\n",
      "==========================================================================================\n",
      "Epoch [4889/5000] | Time: 0.34s\n",
      "(Training) Loss: 910480.4892\n",
      "(Validation) Loss: 938059.3575, MAE: 3633.2471, R2: 0.2075\n",
      "==========================================================================================\n",
      "Epoch [4890/5000] | Time: 0.28s\n",
      "(Training) Loss: 909847.9201\n",
      "(Validation) Loss: 937925.6178, MAE: 3632.4331, R2: 0.2076\n",
      "==========================================================================================\n",
      "Epoch [4891/5000] | Time: 0.26s\n",
      "(Training) Loss: 932534.7291\n",
      "(Validation) Loss: 933331.2305, MAE: 3621.9221, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [4892/5000] | Time: 0.28s\n",
      "(Training) Loss: 918471.9264\n",
      "(Validation) Loss: 935254.4610, MAE: 3625.0271, R2: 0.2098\n",
      "==========================================================================================\n",
      "Epoch [4893/5000] | Time: 0.24s\n",
      "(Training) Loss: 916570.6485\n",
      "(Validation) Loss: 935114.1486, MAE: 3627.8350, R2: 0.2099\n",
      "==========================================================================================\n",
      "Epoch [4894/5000] | Time: 0.27s\n",
      "(Training) Loss: 929822.3845\n",
      "(Validation) Loss: 934974.2375, MAE: 3623.0923, R2: 0.2100\n",
      "==========================================================================================\n",
      "Epoch [4895/5000] | Time: 0.30s\n",
      "(Training) Loss: 909251.9918\n",
      "(Validation) Loss: 934833.2952, MAE: 3623.4207, R2: 0.2102\n",
      "==========================================================================================\n",
      "Epoch [4896/5000] | Time: 0.29s\n",
      "(Training) Loss: 898372.2774\n",
      "(Validation) Loss: 934700.9625, MAE: 3621.7480, R2: 0.2103\n",
      "==========================================================================================\n",
      "Epoch [4897/5000] | Time: 0.30s\n",
      "(Training) Loss: 902644.4797\n",
      "(Validation) Loss: 934567.8730, MAE: 3621.7380, R2: 0.2104\n",
      "==========================================================================================\n",
      "Epoch [4898/5000] | Time: 0.27s\n",
      "(Training) Loss: 918088.6339\n",
      "(Validation) Loss: 934437.4908, MAE: 3621.8574, R2: 0.2105\n",
      "==========================================================================================\n",
      "Epoch [4899/5000] | Time: 0.24s\n",
      "(Training) Loss: 903116.1954\n",
      "(Validation) Loss: 934312.7924, MAE: 3625.2590, R2: 0.2106\n",
      "==========================================================================================\n",
      "Epoch [4900/5000] | Time: 0.31s\n",
      "(Training) Loss: 923649.0260\n",
      "(Validation) Loss: 934165.7854, MAE: 3621.8669, R2: 0.2107\n",
      "==========================================================================================\n",
      "Epoch [4901/5000] | Time: 0.34s\n",
      "(Training) Loss: 915120.7786\n",
      "(Validation) Loss: 934028.0076, MAE: 3620.9121, R2: 0.2108\n",
      "==========================================================================================\n",
      "Epoch [4902/5000] | Time: 0.31s\n",
      "(Training) Loss: 925290.8629\n",
      "(Validation) Loss: 933899.1340, MAE: 3621.2644, R2: 0.2109\n",
      "==========================================================================================\n",
      "Epoch [4903/5000] | Time: 0.30s\n",
      "(Training) Loss: 899087.8782\n",
      "(Validation) Loss: 933764.9371, MAE: 3621.9629, R2: 0.2110\n",
      "==========================================================================================\n",
      "Epoch [4904/5000] | Time: 0.32s\n",
      "(Training) Loss: 899873.2779\n",
      "(Validation) Loss: 933631.2940, MAE: 3621.2974, R2: 0.2112\n",
      "==========================================================================================\n",
      "Epoch [4905/5000] | Time: 0.36s\n",
      "(Training) Loss: 909741.0013\n",
      "(Validation) Loss: 933495.9898, MAE: 3620.0762, R2: 0.2113\n",
      "==========================================================================================\n",
      "Epoch [4906/5000] | Time: 0.23s\n",
      "(Training) Loss: 904443.7297\n",
      "(Validation) Loss: 933367.7206, MAE: 3620.8967, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [4907/5000] | Time: 0.32s\n",
      "(Training) Loss: 911246.0451\n",
      "(Validation) Loss: 933229.4146, MAE: 3617.8066, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [4908/5000] | Time: 0.28s\n",
      "(Training) Loss: 904762.2214\n",
      "(Validation) Loss: 933275.8705, MAE: 3628.1096, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [4909/5000] | Time: 0.27s\n",
      "(Training) Loss: 906691.3553\n",
      "(Validation) Loss: 933143.1721, MAE: 3627.2708, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [4910/5000] | Time: 0.29s\n",
      "(Training) Loss: 896515.1169\n",
      "(Validation) Loss: 933007.9390, MAE: 3627.5315, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [4911/5000] | Time: 0.30s\n",
      "(Training) Loss: 909591.7728\n",
      "(Validation) Loss: 932878.7251, MAE: 3626.7407, R2: 0.2118\n",
      "==========================================================================================\n",
      "Epoch [4912/5000] | Time: 0.28s\n",
      "(Training) Loss: 897912.2065\n",
      "(Validation) Loss: 932744.4571, MAE: 3625.8669, R2: 0.2119\n",
      "==========================================================================================\n",
      "Epoch [4913/5000] | Time: 0.27s\n",
      "(Training) Loss: 905096.0784\n",
      "(Validation) Loss: 932616.8686, MAE: 3627.1741, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [4914/5000] | Time: 0.33s\n",
      "(Training) Loss: 900083.0628\n",
      "(Validation) Loss: 932483.9111, MAE: 3626.6328, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [4915/5000] | Time: 0.22s\n",
      "(Training) Loss: 899003.5508\n",
      "(Validation) Loss: 932361.7168, MAE: 3628.3347, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [4916/5000] | Time: 0.28s\n",
      "(Training) Loss: 895660.6253\n",
      "(Validation) Loss: 932223.5175, MAE: 3626.6077, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [4917/5000] | Time: 0.35s\n",
      "(Training) Loss: 895296.4802\n",
      "(Validation) Loss: 932090.7276, MAE: 3626.6892, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [4918/5000] | Time: 0.26s\n",
      "(Training) Loss: 928645.8566\n",
      "(Validation) Loss: 931953.5137, MAE: 3623.5444, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [4919/5000] | Time: 0.28s\n",
      "(Training) Loss: 915985.6142\n",
      "(Validation) Loss: 931824.3302, MAE: 3624.6301, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [4920/5000] | Time: 0.21s\n",
      "(Training) Loss: 936008.0850\n",
      "(Validation) Loss: 931690.2146, MAE: 3623.2883, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [4921/5000] | Time: 0.31s\n",
      "(Training) Loss: 896080.7132\n",
      "(Validation) Loss: 931552.8635, MAE: 3623.0325, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [4922/5000] | Time: 0.33s\n",
      "(Training) Loss: 911975.6161\n",
      "(Validation) Loss: 931427.5606, MAE: 3623.7051, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [4923/5000] | Time: 0.31s\n",
      "(Training) Loss: 899023.2170\n",
      "(Validation) Loss: 931291.5708, MAE: 3622.5684, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [4924/5000] | Time: 0.22s\n",
      "(Training) Loss: 925004.5279\n",
      "(Validation) Loss: 931165.4806, MAE: 3626.2273, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [4925/5000] | Time: 0.25s\n",
      "(Training) Loss: 919296.0273\n",
      "(Validation) Loss: 931030.0698, MAE: 3623.7175, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [4926/5000] | Time: 0.23s\n",
      "(Training) Loss: 897793.7360\n",
      "(Validation) Loss: 930894.1816, MAE: 3622.0596, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [4927/5000] | Time: 0.31s\n",
      "(Training) Loss: 907420.3585\n",
      "(Validation) Loss: 930762.9816, MAE: 3621.7009, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [4928/5000] | Time: 0.27s\n",
      "(Training) Loss: 920279.4480\n",
      "(Validation) Loss: 930631.5530, MAE: 3620.6550, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [4929/5000] | Time: 0.28s\n",
      "(Training) Loss: 924853.6339\n",
      "(Validation) Loss: 930499.3879, MAE: 3620.3020, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [4930/5000] | Time: 0.34s\n",
      "(Training) Loss: 911865.4816\n",
      "(Validation) Loss: 930390.1663, MAE: 3623.0024, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [4931/5000] | Time: 0.27s\n",
      "(Training) Loss: 905846.0539\n",
      "(Validation) Loss: 930231.1213, MAE: 3619.7915, R2: 0.2140\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4932/5000] | Time: 0.38s\n",
      "(Training) Loss: 898939.6472\n",
      "(Validation) Loss: 930103.9086, MAE: 3619.5095, R2: 0.2141\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4933/5000] | Time: 0.35s\n",
      "(Training) Loss: 902763.2557\n",
      "(Validation) Loss: 929974.2324, MAE: 3618.3813, R2: 0.2142\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4934/5000] | Time: 0.33s\n",
      "(Training) Loss: 901790.1079\n",
      "(Validation) Loss: 929848.0813, MAE: 3619.7961, R2: 0.2143\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4935/5000] | Time: 0.29s\n",
      "(Training) Loss: 909790.1022\n",
      "(Validation) Loss: 929712.5638, MAE: 3617.9526, R2: 0.2144\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4936/5000] | Time: 0.35s\n",
      "(Training) Loss: 900046.3661\n",
      "(Validation) Loss: 929582.2883, MAE: 3617.6938, R2: 0.2145\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4937/5000] | Time: 0.35s\n",
      "(Training) Loss: 923914.0086\n",
      "(Validation) Loss: 929450.8546, MAE: 3617.3538, R2: 0.2146\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4938/5000] | Time: 0.28s\n",
      "(Training) Loss: 895813.3096\n",
      "(Validation) Loss: 929315.4794, MAE: 3618.2512, R2: 0.2148\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4939/5000] | Time: 0.33s\n",
      "(Training) Loss: 913516.4803\n",
      "(Validation) Loss: 929186.2197, MAE: 3617.2334, R2: 0.2149\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4940/5000] | Time: 0.30s\n",
      "(Training) Loss: 903630.3782\n",
      "(Validation) Loss: 929051.5860, MAE: 3615.7615, R2: 0.2150\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4941/5000] | Time: 0.32s\n",
      "(Training) Loss: 899573.9981\n",
      "(Validation) Loss: 928922.0267, MAE: 3615.1912, R2: 0.2151\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4942/5000] | Time: 0.31s\n",
      "(Training) Loss: 901890.2230\n",
      "(Validation) Loss: 928792.8533, MAE: 3614.6360, R2: 0.2152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4943/5000] | Time: 0.35s\n",
      "(Training) Loss: 902031.5520\n",
      "(Validation) Loss: 928670.2425, MAE: 3617.8457, R2: 0.2153\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4944/5000] | Time: 0.31s\n",
      "(Training) Loss: 928329.8668\n",
      "(Validation) Loss: 928534.9689, MAE: 3615.6423, R2: 0.2154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4945/5000] | Time: 0.30s\n",
      "(Training) Loss: 899686.8052\n",
      "(Validation) Loss: 928398.6641, MAE: 3615.1641, R2: 0.2155\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4946/5000] | Time: 0.36s\n",
      "(Training) Loss: 898026.4004\n",
      "(Validation) Loss: 928269.1860, MAE: 3614.6289, R2: 0.2156\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4947/5000] | Time: 0.31s\n",
      "(Training) Loss: 900170.8723\n",
      "(Validation) Loss: 928138.9257, MAE: 3614.1978, R2: 0.2157\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4948/5000] | Time: 0.32s\n",
      "(Training) Loss: 902067.8090\n",
      "(Validation) Loss: 928027.0222, MAE: 3617.1396, R2: 0.2158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4949/5000] | Time: 0.33s\n",
      "(Training) Loss: 896476.5006\n",
      "(Validation) Loss: 933170.7378, MAE: 3632.7974, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [4950/5000] | Time: 0.28s\n",
      "(Training) Loss: 913113.8737\n",
      "(Validation) Loss: 933038.9790, MAE: 3630.2407, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [4951/5000] | Time: 0.28s\n",
      "(Training) Loss: 906635.0368\n",
      "(Validation) Loss: 932913.7676, MAE: 3630.8306, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [4952/5000] | Time: 0.24s\n",
      "(Training) Loss: 901003.4188\n",
      "(Validation) Loss: 932785.0667, MAE: 3629.7107, R2: 0.2119\n",
      "==========================================================================================\n",
      "Epoch [4953/5000] | Time: 0.36s\n",
      "(Training) Loss: 914846.5701\n",
      "(Validation) Loss: 932661.3079, MAE: 3630.7805, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [4954/5000] | Time: 0.32s\n",
      "(Training) Loss: 908490.0958\n",
      "(Validation) Loss: 932531.4794, MAE: 3628.8989, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [4955/5000] | Time: 0.27s\n",
      "(Training) Loss: 924645.6003\n",
      "(Validation) Loss: 932408.6756, MAE: 3629.0864, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [4956/5000] | Time: 0.29s\n",
      "(Training) Loss: 900350.3572\n",
      "(Validation) Loss: 932274.9663, MAE: 3628.4304, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [4957/5000] | Time: 0.28s\n",
      "(Training) Loss: 914442.6364\n",
      "(Validation) Loss: 932151.3143, MAE: 3627.0984, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [4958/5000] | Time: 0.29s\n",
      "(Training) Loss: 909754.7957\n",
      "(Validation) Loss: 932024.5384, MAE: 3627.1599, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [4959/5000] | Time: 0.29s\n",
      "(Training) Loss: 907932.2957\n",
      "(Validation) Loss: 931900.1600, MAE: 3628.0901, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [4960/5000] | Time: 0.25s\n",
      "(Training) Loss: 899733.4448\n",
      "(Validation) Loss: 931773.9378, MAE: 3627.2725, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [4961/5000] | Time: 0.26s\n",
      "(Training) Loss: 915833.0571\n",
      "(Validation) Loss: 931644.1295, MAE: 3625.4045, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [4962/5000] | Time: 0.30s\n",
      "(Training) Loss: 914381.7792\n",
      "(Validation) Loss: 931517.0997, MAE: 3624.7610, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [4963/5000] | Time: 0.28s\n",
      "(Training) Loss: 907836.4283\n",
      "(Validation) Loss: 931391.2483, MAE: 3625.5781, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [4964/5000] | Time: 0.23s\n",
      "(Training) Loss: 897722.9918\n",
      "(Validation) Loss: 931265.1683, MAE: 3624.4517, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [4965/5000] | Time: 0.24s\n",
      "(Training) Loss: 918469.6390\n",
      "(Validation) Loss: 931139.1390, MAE: 3624.3022, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [4966/5000] | Time: 0.24s\n",
      "(Training) Loss: 897602.7360\n",
      "(Validation) Loss: 931014.4559, MAE: 3624.3147, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [4967/5000] | Time: 0.26s\n",
      "(Training) Loss: 898460.6478\n",
      "(Validation) Loss: 930887.2025, MAE: 3623.8401, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [4968/5000] | Time: 0.28s\n",
      "(Training) Loss: 903826.6980\n",
      "(Validation) Loss: 930765.0590, MAE: 3623.7654, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [4969/5000] | Time: 0.21s\n",
      "(Training) Loss: 894585.2088\n",
      "(Validation) Loss: 930637.4756, MAE: 3623.5156, R2: 0.2136\n",
      "==========================================================================================\n",
      "Epoch [4970/5000] | Time: 0.25s\n",
      "(Training) Loss: 907767.1009\n",
      "(Validation) Loss: 930519.3549, MAE: 3624.1956, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [4971/5000] | Time: 0.22s\n",
      "(Training) Loss: 899446.0190\n",
      "(Validation) Loss: 930387.6165, MAE: 3622.8118, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [4972/5000] | Time: 0.21s\n",
      "(Training) Loss: 934721.8528\n",
      "(Validation) Loss: 930257.5898, MAE: 3621.6648, R2: 0.2140\n",
      "==========================================================================================\n",
      "Epoch [4973/5000] | Time: 0.23s\n",
      "(Training) Loss: 921003.8020\n",
      "(Validation) Loss: 930134.0089, MAE: 3621.9653, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [4974/5000] | Time: 0.24s\n",
      "(Training) Loss: 924118.7855\n",
      "(Validation) Loss: 930002.9816, MAE: 3619.6907, R2: 0.2142\n",
      "==========================================================================================\n",
      "Epoch [4975/5000] | Time: 0.21s\n",
      "(Training) Loss: 908226.0400\n",
      "(Validation) Loss: 929876.4698, MAE: 3621.1077, R2: 0.2143\n",
      "==========================================================================================\n",
      "Epoch [4976/5000] | Time: 0.30s\n",
      "(Training) Loss: 907683.6409\n",
      "(Validation) Loss: 929749.7295, MAE: 3620.2324, R2: 0.2144\n",
      "==========================================================================================\n",
      "Epoch [4977/5000] | Time: 0.34s\n",
      "(Training) Loss: 909691.2456\n",
      "(Validation) Loss: 929625.9657, MAE: 3619.9663, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [4978/5000] | Time: 0.33s\n",
      "(Training) Loss: 908717.7798\n",
      "(Validation) Loss: 929500.5003, MAE: 3619.8015, R2: 0.2146\n",
      "==========================================================================================\n",
      "Epoch [4979/5000] | Time: 0.27s\n",
      "(Training) Loss: 900745.1758\n",
      "(Validation) Loss: 929375.6597, MAE: 3620.3994, R2: 0.2147\n",
      "==========================================================================================\n",
      "Epoch [4980/5000] | Time: 0.27s\n",
      "(Training) Loss: 906422.1865\n",
      "(Validation) Loss: 929248.4775, MAE: 3619.1648, R2: 0.2148\n",
      "==========================================================================================\n",
      "Epoch [4981/5000] | Time: 0.27s\n",
      "(Training) Loss: 900669.4499\n",
      "(Validation) Loss: 929122.3670, MAE: 3618.7258, R2: 0.2149\n",
      "==========================================================================================\n",
      "Epoch [4982/5000] | Time: 0.25s\n",
      "(Training) Loss: 900377.6174\n",
      "(Validation) Loss: 928998.1054, MAE: 3618.5823, R2: 0.2150\n",
      "==========================================================================================\n",
      "Epoch [4983/5000] | Time: 0.26s\n",
      "(Training) Loss: 900170.4334\n",
      "(Validation) Loss: 928875.0933, MAE: 3619.3411, R2: 0.2151\n",
      "==========================================================================================\n",
      "Epoch [4984/5000] | Time: 0.35s\n",
      "(Training) Loss: 905375.6161\n",
      "(Validation) Loss: 928748.4597, MAE: 3617.0515, R2: 0.2152\n",
      "==========================================================================================\n",
      "Epoch [4985/5000] | Time: 0.23s\n",
      "(Training) Loss: 910225.4334\n",
      "(Validation) Loss: 928622.5016, MAE: 3616.3132, R2: 0.2153\n",
      "==========================================================================================\n",
      "Epoch [4986/5000] | Time: 0.29s\n",
      "(Training) Loss: 901422.9486\n",
      "(Validation) Loss: 928502.7098, MAE: 3617.6382, R2: 0.2154\n",
      "==========================================================================================\n",
      "Epoch [4987/5000] | Time: 0.28s\n",
      "(Training) Loss: 906157.7373\n",
      "(Validation) Loss: 928378.1079, MAE: 3618.0620, R2: 0.2155\n",
      "==========================================================================================\n",
      "Epoch [4988/5000] | Time: 0.29s\n",
      "(Training) Loss: 898556.8928\n",
      "(Validation) Loss: 928246.9892, MAE: 3615.9873, R2: 0.2156\n",
      "==========================================================================================\n",
      "Epoch [4989/5000] | Time: 0.30s\n",
      "(Training) Loss: 903107.3395\n",
      "(Validation) Loss: 928123.3371, MAE: 3616.3140, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [4990/5000] | Time: 0.34s\n",
      "(Training) Loss: 912771.5082\n",
      "(Validation) Loss: 927998.5219, MAE: 3615.8220, R2: 0.2158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4991/5000] | Time: 0.28s\n",
      "(Training) Loss: 902815.0971\n",
      "(Validation) Loss: 927873.9098, MAE: 3615.8174, R2: 0.2160\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4992/5000] | Time: 0.31s\n",
      "(Training) Loss: 911362.6732\n",
      "(Validation) Loss: 927746.3111, MAE: 3614.3481, R2: 0.2161\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4993/5000] | Time: 0.32s\n",
      "(Training) Loss: 918147.0349\n",
      "(Validation) Loss: 927619.5149, MAE: 3614.0500, R2: 0.2162\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4994/5000] | Time: 0.27s\n",
      "(Training) Loss: 895151.8268\n",
      "(Validation) Loss: 927498.1079, MAE: 3614.2053, R2: 0.2163\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4995/5000] | Time: 0.26s\n",
      "(Training) Loss: 897672.2532\n",
      "(Validation) Loss: 927366.5575, MAE: 3613.0942, R2: 0.2164\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4996/5000] | Time: 0.27s\n",
      "(Training) Loss: 912457.2595\n",
      "(Validation) Loss: 927245.9276, MAE: 3613.4893, R2: 0.2165\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4997/5000] | Time: 0.31s\n",
      "(Training) Loss: 914363.2773\n",
      "(Validation) Loss: 927129.8590, MAE: 3615.8118, R2: 0.2166\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4998/5000] | Time: 0.26s\n",
      "(Training) Loss: 891482.4421\n",
      "(Validation) Loss: 926994.3060, MAE: 3612.9744, R2: 0.2167\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4999/5000] | Time: 0.26s\n",
      "(Training) Loss: 893331.4699\n",
      "(Validation) Loss: 926870.8622, MAE: 3614.6006, R2: 0.2168\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [5000/5000] | Time: 0.27s\n",
      "(Training) Loss: 922948.1973\n",
      "(Validation) Loss: 926750.4152, MAE: 3613.6870, R2: 0.2169\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch5000.pth\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1390000.2125634518,\n",
       "  1372912.942893401,\n",
       "  1383858.975888325,\n",
       "  1386313.6700507614,\n",
       "  1407402.9137055837,\n",
       "  1380637.192893401,\n",
       "  1394004.1967005075,\n",
       "  1402521.0875634518,\n",
       "  1397204.423857868,\n",
       "  1376074.7093908628,\n",
       "  1372981.1802030457,\n",
       "  1399780.4441624365,\n",
       "  1373959.2842639594,\n",
       "  1385133.7055837563,\n",
       "  1405020.2538071065,\n",
       "  1382348.0456852792,\n",
       "  1374058.9124365482,\n",
       "  1398155.4111675126,\n",
       "  1367981.5888324874,\n",
       "  1367921.88071066,\n",
       "  1374171.7360406092,\n",
       "  1396919.109137056,\n",
       "  1417763.052030457,\n",
       "  1376429.3946700508,\n",
       "  1379502.2246192894,\n",
       "  1375520.4194162437,\n",
       "  1370036.9593908628,\n",
       "  1359882.9660532996,\n",
       "  1403071.521573604,\n",
       "  1363520.4365482233,\n",
       "  1375612.361675127,\n",
       "  1373295.5850253806,\n",
       "  1380863.6104060914,\n",
       "  1383416.7829949239,\n",
       "  1376395.5507614212,\n",
       "  1368165.3134517767,\n",
       "  1377616.6395939086,\n",
       "  1389057.8197969543,\n",
       "  1373566.7277918782,\n",
       "  1385580.1269035533,\n",
       "  1380766.2461928935,\n",
       "  1376945.8375634518,\n",
       "  1362950.519035533,\n",
       "  1372928.0996192894,\n",
       "  1364426.1243654822,\n",
       "  1362678.1763959392,\n",
       "  1358566.7817258884,\n",
       "  1385585.9149746194,\n",
       "  1355008.4441624365,\n",
       "  1370897.0139593908,\n",
       "  1372997.6675126904,\n",
       "  1371697.1611675126,\n",
       "  1365153.883248731,\n",
       "  1367314.8705583757,\n",
       "  1375507.668781726,\n",
       "  1365250.5736040608,\n",
       "  1396215.6040609137,\n",
       "  1375088.2664974618,\n",
       "  1367412.5710659898,\n",
       "  1399658.3210659898,\n",
       "  1356105.375,\n",
       "  1359355.752538071,\n",
       "  1400728.9289340102,\n",
       "  1351433.163388325,\n",
       "  1364400.697969543,\n",
       "  1381086.6065989847,\n",
       "  1377453.752538071,\n",
       "  1369955.5672588833,\n",
       "  1356492.6497461929,\n",
       "  1358834.7385786802,\n",
       "  1375968.583756345,\n",
       "  1366742.833756345,\n",
       "  1369968.755076142,\n",
       "  1363531.114213198,\n",
       "  1374840.6611675126,\n",
       "  1360812.5507614212,\n",
       "  1366754.9137055837,\n",
       "  1354860.4746192894,\n",
       "  1357469.062182741,\n",
       "  1387919.4987309645,\n",
       "  1381206.0012690355,\n",
       "  1368736.0406091372,\n",
       "  1357845.1472081218,\n",
       "  1348249.4352791877,\n",
       "  1349057.5279187816,\n",
       "  1349552.932106599,\n",
       "  1389521.4746192894,\n",
       "  1359637.758248731,\n",
       "  1351179.114213198,\n",
       "  1384593.4314720812,\n",
       "  1373219.024111675,\n",
       "  1370361.3629441625,\n",
       "  1351582.75,\n",
       "  1363623.1002538071,\n",
       "  1365774.728426396,\n",
       "  1366004.4276649747,\n",
       "  1362914.7246192894,\n",
       "  1344355.4815989847,\n",
       "  1366607.4657360406,\n",
       "  1341384.918781726,\n",
       "  1346446.5590101522,\n",
       "  1371656.75,\n",
       "  1359914.2411167512,\n",
       "  1355702.0558375635,\n",
       "  1359137.99428934,\n",
       "  1351335.866751269,\n",
       "  1338630.4470177665,\n",
       "  1378563.826142132,\n",
       "  1351618.1421319798,\n",
       "  1356855.1967005075,\n",
       "  1345104.9771573604,\n",
       "  1353349.6065989847,\n",
       "  1350869.8210659898,\n",
       "  1350225.4543147208,\n",
       "  1373356.804568528,\n",
       "  1355125.9720812184,\n",
       "  1357900.2322335024,\n",
       "  1358489.276649746,\n",
       "  1358553.6535532996,\n",
       "  1346215.7791878174,\n",
       "  1344448.7538071065,\n",
       "  1355915.8083756345,\n",
       "  1349015.9568527918,\n",
       "  1345385.6345177665,\n",
       "  1344253.095177665,\n",
       "  1352067.859137056,\n",
       "  1367691.6345177665,\n",
       "  1392000.502538071,\n",
       "  1340634.2398477157,\n",
       "  1359876.9822335024,\n",
       "  1337434.1656091372,\n",
       "  1341829.0431472082,\n",
       "  1337105.6732233502,\n",
       "  1348392.5818527918,\n",
       "  1346860.771573604,\n",
       "  1354833.7906091372,\n",
       "  1336041.3109137055,\n",
       "  1364589.9365482233,\n",
       "  1338515.109137056,\n",
       "  1354849.494923858,\n",
       "  1333826.6395939086,\n",
       "  1339928.975888325,\n",
       "  1368606.5939086294,\n",
       "  1369674.197969543,\n",
       "  1338044.2982233502,\n",
       "  1349378.7398477157,\n",
       "  1369842.3604060914,\n",
       "  1334559.0406091372,\n",
       "  1347921.513324873,\n",
       "  1329508.9003807106,\n",
       "  1343047.1097715737,\n",
       "  1346620.3318527918,\n",
       "  1357509.9098984771,\n",
       "  1338497.6053299492,\n",
       "  1361594.7576142133,\n",
       "  1342352.9695431471,\n",
       "  1377597.0469543147,\n",
       "  1340695.5989847716,\n",
       "  1347562.970177665,\n",
       "  1349213.9670050761,\n",
       "  1339643.8324873096,\n",
       "  1343203.5342639594,\n",
       "  1341816.2461928935,\n",
       "  1356177.5152284263,\n",
       "  1336938.1345177665,\n",
       "  1330208.6967005075,\n",
       "  1333741.5901015229,\n",
       "  1331863.6598984771,\n",
       "  1336956.997461929,\n",
       "  1341334.0710659898,\n",
       "  1332050.6789340102,\n",
       "  1335687.114213198,\n",
       "  1345313.973350254,\n",
       "  1347863.9961928935,\n",
       "  1341350.964467005,\n",
       "  1319773.7350095178,\n",
       "  1323952.1326142133,\n",
       "  1341253.4492385788,\n",
       "  1351039.7322335024,\n",
       "  1321112.1342005075,\n",
       "  1347007.494923858,\n",
       "  1340209.0393401014,\n",
       "  1326512.9593908628,\n",
       "  1346727.964467005,\n",
       "  1336541.9302030457,\n",
       "  1331033.361675127,\n",
       "  1320571.640862944,\n",
       "  1331949.923857868,\n",
       "  1326143.8769035533,\n",
       "  1350150.019035533,\n",
       "  1355813.4289340102,\n",
       "  1336314.9175126904,\n",
       "  1326090.0063451778,\n",
       "  1339058.5862944163,\n",
       "  1331884.081218274,\n",
       "  1343568.9593908628,\n",
       "  1330550.1700507614,\n",
       "  1353400.0926395939,\n",
       "  1349902.173857868,\n",
       "  1325442.6370558375,\n",
       "  1339691.2956852792,\n",
       "  1334638.578680203,\n",
       "  1321789.9200507614,\n",
       "  1325106.8718274112,\n",
       "  1375695.6890862945,\n",
       "  1359553.6472081218,\n",
       "  1330251.4517766498,\n",
       "  1336517.9492385788,\n",
       "  1313006.0701142133,\n",
       "  1336297.7576142133,\n",
       "  1328080.8864213198,\n",
       "  1335356.802030457,\n",
       "  1342013.8781725888,\n",
       "  1330565.9397208123,\n",
       "  1330670.1763959392,\n",
       "  1325055.1002538071,\n",
       "  1340704.752538071,\n",
       "  1320944.1294416243,\n",
       "  1348618.9352791877,\n",
       "  1329642.7842639594,\n",
       "  1318589.3343908628,\n",
       "  1331368.8109137055,\n",
       "  1334986.5926395939,\n",
       "  1315985.0184010153,\n",
       "  1328346.7868020304,\n",
       "  1320760.9441624365,\n",
       "  1354110.3864213198,\n",
       "  1340254.1865482233,\n",
       "  1317942.0862944163,\n",
       "  1318960.4010152284,\n",
       "  1339839.2538071065,\n",
       "  1324128.1522842639,\n",
       "  1336416.788071066,\n",
       "  1342967.364213198,\n",
       "  1320857.2563451778,\n",
       "  1333556.5291878174,\n",
       "  1332010.6472081218,\n",
       "  1333032.1751269035,\n",
       "  1315854.9593908628,\n",
       "  1329894.7538071065,\n",
       "  1326781.6535532996,\n",
       "  1327009.019035533,\n",
       "  1313854.3197969543,\n",
       "  1335513.6351522843,\n",
       "  1325962.654822335,\n",
       "  1341291.3851522843,\n",
       "  1308785.706218274,\n",
       "  1316542.673857868,\n",
       "  1306270.9175126904,\n",
       "  1322865.247461929,\n",
       "  1330869.1852791877,\n",
       "  1310621.1865482233,\n",
       "  1322874.5824873096,\n",
       "  1300286.5047588833,\n",
       "  1316904.9543147208,\n",
       "  1351574.1751269035,\n",
       "  1307606.7893401014,\n",
       "  1308395.961928934,\n",
       "  1326217.7874365482,\n",
       "  1337899.0494923857,\n",
       "  1313944.9835025382,\n",
       "  1301080.9739847716,\n",
       "  1300936.4311548222,\n",
       "  1311094.8788071065,\n",
       "  1318421.140862944,\n",
       "  1299424.7163705584,\n",
       "  1334256.8223350253,\n",
       "  1325098.3946700508,\n",
       "  1306776.2385786802,\n",
       "  1322958.927030457,\n",
       "  1321031.888324873,\n",
       "  1315754.3870558375,\n",
       "  1319901.4263959392,\n",
       "  1307027.3109137055,\n",
       "  1300464.8718274112,\n",
       "  1309988.6256345178,\n",
       "  1326296.8705583757,\n",
       "  1308570.6725888324,\n",
       "  1313419.5774111676,\n",
       "  1303509.9911167512,\n",
       "  1310821.6700507614,\n",
       "  1306465.187817259,\n",
       "  1295527.1056472082,\n",
       "  1313917.5964467004,\n",
       "  1306239.4149746194,\n",
       "  1314124.0964467004,\n",
       "  1317641.9568527918,\n",
       "  1314862.6085025382,\n",
       "  1307268.6395939086,\n",
       "  1296886.883248731,\n",
       "  1310981.8134517767,\n",
       "  1306107.9606598986,\n",
       "  1303006.771573604,\n",
       "  1292029.5701142133,\n",
       "  1303362.0977157361,\n",
       "  1299556.5736040608,\n",
       "  1316498.1154822335,\n",
       "  1319660.116751269,\n",
       "  1331095.7804568529,\n",
       "  1307024.9060913706,\n",
       "  1297892.442893401,\n",
       "  1293668.361675127,\n",
       "  1314341.0659898478,\n",
       "  1299632.687817259,\n",
       "  1294907.692893401,\n",
       "  1321150.8851522843,\n",
       "  1298222.8997461929,\n",
       "  1299911.5291878174,\n",
       "  1321902.1751269035,\n",
       "  1322263.0342639594,\n",
       "  1292429.1706852792,\n",
       "  1308609.1967005075,\n",
       "  1307822.1072335024,\n",
       "  1328661.0723350253,\n",
       "  1289873.7645939086,\n",
       "  1291628.611675127,\n",
       "  1306329.9714467004,\n",
       "  1294421.3743654822,\n",
       "  1294848.8439086294,\n",
       "  1284462.0142766498,\n",
       "  1294873.519035533,\n",
       "  1292088.9670050761,\n",
       "  1293284.3705583757,\n",
       "  1299162.0672588833,\n",
       "  1282931.515862944,\n",
       "  1298585.4156091372,\n",
       "  1318764.7439720812,\n",
       "  1305680.7512690355,\n",
       "  1285158.513324873,\n",
       "  1296368.6078680202,\n",
       "  1302249.9574873096,\n",
       "  1308247.361675127,\n",
       "  1320845.8718274112,\n",
       "  1302225.524111675,\n",
       "  1294419.706218274,\n",
       "  1299116.8819796955,\n",
       "  1335167.3946700508,\n",
       "  1303184.9524111676,\n",
       "  1299420.9257614212,\n",
       "  1301407.252538071,\n",
       "  1279337.0504441625,\n",
       "  1295538.923857868,\n",
       "  1310749.6484771573,\n",
       "  1307325.0085659898,\n",
       "  1312625.0038071065,\n",
       "  1295885.8477157361,\n",
       "  1279279.510469543,\n",
       "  1322068.2055837563,\n",
       "  1281909.505076142,\n",
       "  1300116.6802030457,\n",
       "  1291266.0101522843,\n",
       "  1299772.0088832488,\n",
       "  1285412.3350253806,\n",
       "  1284044.0602791877,\n",
       "  1304115.1338832488,\n",
       "  1305146.4098984771,\n",
       "  1285738.3629441625,\n",
       "  1302743.3553299492,\n",
       "  1285959.541243655,\n",
       "  1297689.7347715737,\n",
       "  1301524.135786802,\n",
       "  1283645.7887055837,\n",
       "  1309512.776649746,\n",
       "  1303994.3921319798,\n",
       "  1284170.052030457,\n",
       "  1320405.345177665,\n",
       "  1280382.1281725888,\n",
       "  1284167.736675127,\n",
       "  1286882.214467005,\n",
       "  1283517.4828680202,\n",
       "  1285965.4314720812,\n",
       "  1287769.8388324874,\n",
       "  1311770.6459390863,\n",
       "  1312209.4314720812,\n",
       "  1296641.3934010153,\n",
       "  1287298.1123096447,\n",
       "  1294641.5317258884,\n",
       "  1275519.25571066,\n",
       "  1288082.0469543147,\n",
       "  1296087.4822335024,\n",
       "  1284197.776649746,\n",
       "  1287646.3210659898,\n",
       "  1298508.6484771573,\n",
       "  1271669.6129441625,\n",
       "  1275762.4352791877,\n",
       "  1282113.1560913706,\n",
       "  1269239.4800126904,\n",
       "  1278450.9086294416,\n",
       "  1276518.2005076143,\n",
       "  1301554.822969543,\n",
       "  1278521.2106598986,\n",
       "  1290996.7322335024,\n",
       "  1275680.56535533,\n",
       "  1298766.244923858,\n",
       "  1279111.6560913706,\n",
       "  1283339.8401015229,\n",
       "  1286663.6484771573,\n",
       "  1286980.4835025382,\n",
       "  1293526.6281725888,\n",
       "  1277754.109137056,\n",
       "  1276978.2220812184,\n",
       "  1281267.8489847716,\n",
       "  1281209.3388324874,\n",
       "  1299444.5114213198,\n",
       "  1288956.4352791877,\n",
       "  1284584.81535533,\n",
       "  1271537.4022842639,\n",
       "  1280695.7195431471,\n",
       "  1276229.9555837563,\n",
       "  1279420.0469543147,\n",
       "  1286973.7626903553,\n",
       "  1288715.4314720812,\n",
       "  1281113.8553299492,\n",
       "  1263321.2319162437,\n",
       "  1272848.8191624365,\n",
       "  1266340.2182741116,\n",
       "  1288058.6681472082,\n",
       "  1267341.6040609137,\n",
       "  1263122.2271573604,\n",
       "  1274627.3578680202,\n",
       "  1266854.1472081218,\n",
       "  1272219.3426395939,\n",
       "  1288637.2779187816,\n",
       "  1273453.2220812184,\n",
       "  1271174.1065989847,\n",
       "  1293354.13071066,\n",
       "  1269733.3236040608,\n",
       "  1269942.046319797,\n",
       "  1262822.484137056,\n",
       "  1267952.4682741116,\n",
       "  1283866.0101522843,\n",
       "  1268915.730964467,\n",
       "  1263390.921319797,\n",
       "  1255876.004600254,\n",
       "  1271382.6649746194,\n",
       "  1273397.9137055837,\n",
       "  1266524.3185279188,\n",
       "  1264414.276649746,\n",
       "  1274523.8997461929,\n",
       "  1253849.1930520304,\n",
       "  1285142.3635786802,\n",
       "  1262939.3895939086,\n",
       "  1269978.3109137055,\n",
       "  1266584.6618020304,\n",
       "  1278592.776649746,\n",
       "  1287313.0926395939,\n",
       "  1258289.4911167512,\n",
       "  1267425.7918781727,\n",
       "  1267439.8946700508,\n",
       "  1267441.2829949239,\n",
       "  1271783.9695431471,\n",
       "  1269738.8489847716,\n",
       "  1258163.345177665,\n",
       "  1271494.5101522843,\n",
       "  1263718.0888324874,\n",
       "  1264095.7779187816,\n",
       "  1259185.1256345178,\n",
       "  1274264.2956852792,\n",
       "  1266778.9302030457,\n",
       "  1251651.3949873096,\n",
       "  1263307.7081218273,\n",
       "  1266043.5114213198,\n",
       "  1248295.9568527918,\n",
       "  1267021.2322335024,\n",
       "  1269049.4251269035,\n",
       "  1255930.692893401,\n",
       "  1262362.138324873,\n",
       "  1261532.133248731,\n",
       "  1260777.611675127,\n",
       "  1266837.8172588833,\n",
       "  1260829.416243655,\n",
       "  1260297.9010152284,\n",
       "  1246309.8202728427,\n",
       "  1269771.6472081218,\n",
       "  1261865.3604060914,\n",
       "  1252858.5456852792,\n",
       "  1265439.3527918782,\n",
       "  1263793.845177665,\n",
       "  1252968.9359137055,\n",
       "  1282326.4505076143,\n",
       "  1251660.785532995,\n",
       "  1268470.6789340102,\n",
       "  1263246.2017766498,\n",
       "  1277187.0329949239,\n",
       "  1280153.80964467,\n",
       "  1272288.7747461929,\n",
       "  1246913.8597715737,\n",
       "  1249321.4352791877,\n",
       "  1276050.3629441625,\n",
       "  1252492.904822335,\n",
       "  1271431.1586294416,\n",
       "  1268915.5272842639,\n",
       "  1255436.9092639594,\n",
       "  1252028.4010152284,\n",
       "  1250295.399111675,\n",
       "  1271741.3248730965,\n",
       "  1263079.945431472,\n",
       "  1240025.3727791877,\n",
       "  1245106.0932741116,\n",
       "  1251789.2131979696,\n",
       "  1280743.5583756345,\n",
       "  1252838.8248730965,\n",
       "  1258045.725888325,\n",
       "  1250178.4670050761,\n",
       "  1248256.9898477157,\n",
       "  1256277.345177665,\n",
       "  1246406.2588832488,\n",
       "  1261215.7043147208,\n",
       "  1258744.0260152284,\n",
       "  1258092.7068527918,\n",
       "  1246772.9263959392,\n",
       "  1270114.75,\n",
       "  1251528.4762055837,\n",
       "  1237335.6732233502,\n",
       "  1258255.526649746,\n",
       "  1260801.2614213198,\n",
       "  1253142.8147208123,\n",
       "  1251212.4574873096,\n",
       "  1254192.285532995,\n",
       "  1261286.1947969543,\n",
       "  1244406.5228426396,\n",
       "  1245310.269035533,\n",
       "  1248563.7950507614,\n",
       "  1247832.0748730965,\n",
       "  1260532.1319796955,\n",
       "  1248412.804568528,\n",
       "  1244193.3502538071,\n",
       "  1238684.5862944163,\n",
       "  1239564.6484771573,\n",
       "  1260282.7944162437,\n",
       "  1245828.9073604061,\n",
       "  1267622.0799492386,\n",
       "  1246775.2804568529,\n",
       "  1257543.394035533,\n",
       "  1264072.8781725888,\n",
       "  1266104.776649746,\n",
       "  1239010.8521573604,\n",
       "  1239785.0939086294,\n",
       "  1249270.3375634518,\n",
       "  1246021.0145939086,\n",
       "  1247300.7005076143,\n",
       "  1250786.984137056,\n",
       "  1231354.2639593908,\n",
       "  1242551.9847715737,\n",
       "  1255852.3109137055,\n",
       "  1240319.9124365482,\n",
       "  1239883.1376903553,\n",
       "  1259638.7918781727,\n",
       "  1234643.095177665,\n",
       "  1264105.964467005,\n",
       "  1270011.8921319798,\n",
       "  1259714.9460659898,\n",
       "  1267497.7918781727,\n",
       "  1254420.2208121826,\n",
       "  1244549.4060913706,\n",
       "  1238809.8819796955,\n",
       "  1252266.3711928935,\n",
       "  1263671.0672588833,\n",
       "  1237690.2055837563,\n",
       "  1233868.8185279188,\n",
       "  1228348.4022842639,\n",
       "  1252363.9175126904,\n",
       "  1235092.0672588833,\n",
       "  1252708.1364213198,\n",
       "  1232773.9822335024,\n",
       "  1231359.3489847716,\n",
       "  1234674.285532995,\n",
       "  1240975.0348984771,\n",
       "  1233994.6535532996,\n",
       "  1251511.4390862945,\n",
       "  1226856.5532994925,\n",
       "  1232690.4631979696,\n",
       "  1222350.9235406092,\n",
       "  1245643.918781726,\n",
       "  1246023.8921319798,\n",
       "  1244161.5926395939,\n",
       "  1248078.3248730965,\n",
       "  1228647.5964467004,\n",
       "  1241291.7664974618,\n",
       "  1228002.8521573604,\n",
       "  1251040.8730964467,\n",
       "  1232385.274111675,\n",
       "  1239510.916243655,\n",
       "  1229661.0196700508,\n",
       "  1270883.4060913706,\n",
       "  1226397.2385786802,\n",
       "  1226194.5736040608,\n",
       "  1243136.5824873096,\n",
       "  1246850.6395939086,\n",
       "  1243083.6700507614,\n",
       "  1235496.7461928935,\n",
       "  1229620.1656091372,\n",
       "  1238676.994923858,\n",
       "  1223440.2823604061,\n",
       "  1248075.883248731,\n",
       "  1267590.7493654822,\n",
       "  1242410.7614213198,\n",
       "  1227134.4860406092,\n",
       "  1227893.896573604,\n",
       "  1241995.7246192894,\n",
       "  1239092.4149746194,\n",
       "  1255445.524111675,\n",
       "  1249055.035532995,\n",
       "  1229448.848350254,\n",
       "  1255010.1763959392,\n",
       "  1240006.7195431471,\n",
       "  1229666.1065989847,\n",
       "  1245447.2195431471,\n",
       "  1240503.3388324874,\n",
       "  1247834.6040609137,\n",
       "  1234356.364213198,\n",
       "  1230884.899111675,\n",
       "  1234799.7322335024,\n",
       "  1231230.9314720812,\n",
       "  1228667.25,\n",
       "  1233281.4739847716,\n",
       "  1226875.25,\n",
       "  1225962.980964467,\n",
       "  1248294.973350254,\n",
       "  1231147.404822335,\n",
       "  1224624.3769035533,\n",
       "  1236809.4961928935,\n",
       "  1214480.5530615482,\n",
       "  1217976.4124365482,\n",
       "  1240202.3274111676,\n",
       "  1241576.0222081218,\n",
       "  1214696.4156091372,\n",
       "  1217277.0939086294,\n",
       "  1255542.8185279188,\n",
       "  1224573.61928934,\n",
       "  1236642.7994923857,\n",
       "  1219159.2112944163,\n",
       "  1219307.7455583757,\n",
       "  1244672.1560913706,\n",
       "  1234169.7246192894,\n",
       "  1240391.4682741116,\n",
       "  1234922.9467005075,\n",
       "  1216171.458756345,\n",
       "  1225034.2043147208,\n",
       "  1218821.4657360406,\n",
       "  1214300.2722081218,\n",
       "  1237194.1535532996,\n",
       "  1215107.4251269035,\n",
       "  1224561.3870558375,\n",
       "  1228227.961928934,\n",
       "  1213819.214467005,\n",
       "  1227013.6085025382,\n",
       "  1228383.4612944163,\n",
       "  1219116.9308375635,\n",
       "  1256635.2112944163,\n",
       "  1229177.4670050761,\n",
       "  1218947.7703045686,\n",
       "  1212933.6097715737,\n",
       "  1220196.0291878174,\n",
       "  1235766.1129441625,\n",
       "  1224847.3058375635,\n",
       "  1226057.9232233502,\n",
       "  1233621.8007614212,\n",
       "  1225936.7182741116,\n",
       "  1227800.502538071,\n",
       "  1229489.9568527918,\n",
       "  1230554.9073604061,\n",
       "  1209978.5509993655,\n",
       "  1235621.1453045686,\n",
       "  1226445.480964467,\n",
       "  1227940.2354060914,\n",
       "  1216971.7829949239,\n",
       "  1241464.2195431471,\n",
       "  1224872.9200507614,\n",
       "  1225147.8654822335,\n",
       "  1257867.671319797,\n",
       "  1222791.9200507614,\n",
       "  1233422.2322335024,\n",
       "  1217704.3331218273,\n",
       "  1234350.7220812184,\n",
       "  1215176.0558375635,\n",
       "  1206674.9601840102,\n",
       "  1214191.526649746,\n",
       "  1238976.4771573604,\n",
       "  1219167.6675126904,\n",
       "  1222474.7538071065,\n",
       "  1228496.7918781727,\n",
       "  1220119.192893401,\n",
       "  1231173.6040609137,\n",
       "  1221860.6789340102,\n",
       "  1227058.4930203045,\n",
       "  1210119.2246192894,\n",
       "  1222003.828680203,\n",
       "  1209404.0431472082,\n",
       "  1208208.4606598986,\n",
       "  1240204.1744923857,\n",
       "  1238616.505076142,\n",
       "  1239790.2614213198,\n",
       "  1212079.1497461929,\n",
       "  1221681.1015228427,\n",
       "  1230783.197969543,\n",
       "  1206064.5755076143,\n",
       "  1233137.8997461929,\n",
       "  1215266.5634517767,\n",
       "  1215041.1598984771,\n",
       "  1247005.7081218273,\n",
       "  1206807.4164022843,\n",
       "  1241121.497461929,\n",
       "  1227270.8972081218,\n",
       "  1226649.5444162437,\n",
       "  1208367.9327411167,\n",
       "  1232460.8934010153,\n",
       "  1213047.649111675,\n",
       "  1204157.3588991116,\n",
       "  1230106.1637055837,\n",
       "  1204156.6004124365,\n",
       "  1208759.0843908628,\n",
       "  1215152.5647208123,\n",
       "  1213673.6694162437,\n",
       "  1207279.4612944163,\n",
       "  1210546.9822335024,\n",
       "  1231456.4568527918,\n",
       "  1210234.3026649747,\n",
       "  1233424.5393401014,\n",
       "  1205596.3851522843,\n",
       "  1221429.0393401014,\n",
       "  1234961.728426396,\n",
       "  1201303.148001269,\n",
       "  1212303.6814720812,\n",
       "  1224354.2753807106,\n",
       "  1204486.0279187816,\n",
       "  1212970.4828680202,\n",
       "  1209692.6814720812,\n",
       "  1222389.390862944,\n",
       "  1205137.8477157361,\n",
       "  1220134.6649746194,\n",
       "  1216251.2131979696,\n",
       "  1232233.8464467004,\n",
       "  1213899.2538071065,\n",
       "  1224063.8737309645,\n",
       "  1237757.1027918782,\n",
       "  1212450.0513959392,\n",
       "  1231809.2131979696,\n",
       "  1222131.2779187816,\n",
       "  1202056.8159898478,\n",
       "  1219077.274111675,\n",
       "  1211699.1751269035,\n",
       "  1235593.2639593908,\n",
       "  1221775.5799492386,\n",
       "  1226672.9359137055,\n",
       "  1203776.9302030457,\n",
       "  1202296.0532994925,\n",
       "  1217595.5456852792,\n",
       "  1207429.038071066,\n",
       "  1223618.68464467,\n",
       "  1226364.3527918782,\n",
       "  1198613.2544416243,\n",
       "  1220589.5006345178,\n",
       "  1207696.7677664976,\n",
       "  1195791.7290609137,\n",
       "  1223303.4149746194,\n",
       "  1210151.1205583757,\n",
       "  1205363.3578680202,\n",
       "  1208947.9289340102,\n",
       "  1211452.6427664976,\n",
       "  1199906.3540609137,\n",
       "  1197088.2823604061,\n",
       "  1192551.9597081218,\n",
       "  1208252.7737944163,\n",
       "  1194870.7024111676,\n",
       "  1211482.5501269035,\n",
       "  1208952.491751269,\n",
       "  1218095.2005076143,\n",
       "  1213206.5101522843,\n",
       "  1202313.4098984771,\n",
       "  1193183.6998730965,\n",
       "  1199338.2335025382,\n",
       "  1198246.2373096447,\n",
       "  1204338.543781726,\n",
       "  1219335.7680837563,\n",
       "  1205595.2944162437,\n",
       "  1209449.3502538071,\n",
       "  1191620.494923858,\n",
       "  1192847.5482233502,\n",
       "  1229288.5279187816,\n",
       "  1192434.1446700508,\n",
       "  1200219.2360406092,\n",
       "  1228884.6782994925,\n",
       "  1200985.956218274,\n",
       "  1193520.5850253806,\n",
       "  1195033.1802030457,\n",
       "  1188375.0317258884,\n",
       "  1199835.9847715737,\n",
       "  1211408.769035533,\n",
       "  1188061.4749365482,\n",
       "  1203602.5926395939,\n",
       "  1195295.4276649747,\n",
       "  1208230.5209390863,\n",
       "  1207036.812182741,\n",
       "  1199240.5304568529,\n",
       "  1192903.0088832488,\n",
       "  1193523.6434010153,\n",
       "  1193913.947969543,\n",
       "  1189103.625,\n",
       "  1184247.1729060914,\n",
       "  1191745.3718274112,\n",
       "  1186574.68464467,\n",
       "  1198854.8527918782,\n",
       "  1193475.2664974618,\n",
       "  1206830.0329949239,\n",
       "  1190734.062182741,\n",
       "  1208356.109137056,\n",
       "  1213153.0228426396,\n",
       "  1203682.464467005,\n",
       "  1196933.7290609137,\n",
       "  1201505.2296954314,\n",
       "  1218577.3343908628,\n",
       "  1188873.4777918782,\n",
       "  1190979.6002538071,\n",
       "  1189023.4631979696,\n",
       "  1214344.6598984771,\n",
       "  1206692.4441624365,\n",
       "  1190335.6015228427,\n",
       "  1222484.2512690355,\n",
       "  1188378.5126903553,\n",
       "  1182430.8267766498,\n",
       "  1205183.7404822335,\n",
       "  1197408.3654822335,\n",
       "  1180362.8263404188,\n",
       "  1200327.872461929,\n",
       "  1200565.3730964467,\n",
       "  1191334.2810913706,\n",
       "  1192605.473350254,\n",
       "  1196241.3388324874,\n",
       "  1181468.0720177665,\n",
       "  1190055.918781726,\n",
       "  1182550.1345177665,\n",
       "  1199908.828680203,\n",
       "  1178794.061072335,\n",
       "  1189803.9435279188,\n",
       "  1189590.3223350253,\n",
       "  1195190.9149746194,\n",
       "  1185681.752538071,\n",
       "  1197143.8565989847,\n",
       "  1202681.864213198,\n",
       "  1187692.5228426396,\n",
       "  1190479.331218274,\n",
       "  1197729.151649746,\n",
       "  1206688.3585025382,\n",
       "  1209417.904822335,\n",
       "  1194148.2487309645,\n",
       "  1181522.6104060914,\n",
       "  1187086.2804568529,\n",
       "  1199547.5793147208,\n",
       "  1180192.7677664976,\n",
       "  1178141.052030457,\n",
       "  1191674.239213198,\n",
       "  1202890.0368020304,\n",
       "  1218226.4251269035,\n",
       "  1190522.3401015229,\n",
       "  1180212.817893401,\n",
       "  1175936.3029822335,\n",
       "  1194744.2068527918,\n",
       "  1209930.1960659898,\n",
       "  1179563.4803299492,\n",
       "  1179556.4505076143,\n",
       "  1205398.6421319798,\n",
       "  1190042.8388324874,\n",
       "  1214358.054568528,\n",
       "  1207323.0926395939,\n",
       "  1179838.5945431471,\n",
       "  1219968.9314720812,\n",
       "  1176486.345177665,\n",
       "  1185886.2208121826,\n",
       "  1192505.6180203045,\n",
       "  1183211.4473350253,\n",
       "  1186896.3876903553,\n",
       "  1212443.5767766498,\n",
       "  1190145.359137056,\n",
       "  1202815.9606598986,\n",
       "  1171317.36928934,\n",
       "  1176532.1085025382,\n",
       "  1193689.785532995,\n",
       "  1178410.7626903553,\n",
       "  1191426.8388324874,\n",
       "  1170946.3972081218,\n",
       "  1183544.173857868,\n",
       "  1182959.937817259,\n",
       "  1177586.5456852792,\n",
       "  1170710.3102791877,\n",
       "  1173590.8331218273,\n",
       "  1196673.896573604,\n",
       "  1184859.6421319798,\n",
       "  1173524.682106599,\n",
       "  1203841.8870558375,\n",
       "  1212691.3388324874,\n",
       "  1165191.2455583757,\n",
       "  1185977.2918781727,\n",
       "  1196593.7461928935,\n",
       "  1172166.640862944,\n",
       "  1165616.5293464467,\n",
       "  1178964.0126903553,\n",
       "  1186048.8565989847,\n",
       "  1203317.0152284263,\n",
       "  1175782.9308375635,\n",
       "  1181394.7335025382,\n",
       "  1173970.5532994925,\n",
       "  1169836.244923858,\n",
       "  1174720.8058375635,\n",
       "  1178602.812182741,\n",
       "  1190221.9898477157,\n",
       "  1199014.703680203,\n",
       "  1170221.013324873,\n",
       "  1172873.6129441625,\n",
       "  1182539.7519035533,\n",
       "  1209288.845177665,\n",
       "  1178392.973350254,\n",
       "  1177505.4232233502,\n",
       "  1166271.326142132,\n",
       "  1167197.4416243655,\n",
       "  1163585.5044416243,\n",
       "  1168407.703680203,\n",
       "  1186528.644035533,\n",
       "  1185483.1478426396,\n",
       "  1203022.2296954314,\n",
       "  1173833.437182741,\n",
       "  1180937.2734771573,\n",
       "  1167422.4435279188,\n",
       "  1168112.0425126904,\n",
       "  1158871.9757296955,\n",
       "  1166929.1649746194,\n",
       "  1159222.6579949239,\n",
       "  1166989.0799492386,\n",
       "  1175213.5406091372,\n",
       "  1159418.605964467,\n",
       "  1163969.9930203045,\n",
       "  1179878.6294416243,\n",
       "  1163589.7373096447,\n",
       "  1168620.8109137055,\n",
       "  1176019.543781726,\n",
       "  1196437.947969543,\n",
       "  1163680.228426396,\n",
       "  1175342.0317258884,\n",
       "  1171646.1154822335,\n",
       "  1174634.6027918782,\n",
       "  1183568.5685279188,\n",
       "  1175493.6053299492,\n",
       "  1174830.1472081218,\n",
       "  1169569.5989847716,\n",
       "  1175433.1567258884,\n",
       "  1178058.4581218273,\n",
       "  1177691.7906091372,\n",
       "  1166872.0901015229,\n",
       "  1163547.2480964467,\n",
       "  1190835.187817259,\n",
       "  1155682.5672588833,\n",
       "  1167363.9022842639,\n",
       "  1179545.8946700508,\n",
       "  1167565.6015228427,\n",
       "  1159531.7975888324,\n",
       "  1169483.7893401014,\n",
       "  1161348.0843908628,\n",
       "  1173074.1434010153,\n",
       "  1159875.1827411167,\n",
       "  1168113.0076142133,\n",
       "  1170603.30964467,\n",
       "  1171016.1986040608,\n",
       "  1180656.6269035533,\n",
       "  1169232.4035532996,\n",
       "  1170789.9441624365,\n",
       "  1162186.8527918782,\n",
       "  1156580.0888324874,\n",
       "  1160752.1732233502,\n",
       "  1175602.9365482233,\n",
       "  1166598.1922588833,\n",
       "  1164960.6833756345,\n",
       "  1166622.2601522843,\n",
       "  1168092.2848984771,\n",
       "  1169361.1700507614,\n",
       "  1166642.7785532996,\n",
       "  1155558.3610406092,\n",
       "  1159622.1700507614,\n",
       "  1146089.5355528237,\n",
       "  1150625.3813451778,\n",
       "  1160912.8565989847,\n",
       "  1168654.524111675,\n",
       "  1159877.9720812184,\n",
       "  1173845.0913705584,\n",
       "  1159325.7956852792,\n",
       "  1176642.3413705584,\n",
       "  1145264.24428934,\n",
       "  1171398.456218274,\n",
       "  1153087.5742385788,\n",
       "  1175492.2956852792,\n",
       "  1157271.9803299492,\n",
       "  1156774.651649746,\n",
       "  1175886.1345177665,\n",
       "  1161261.7296954314,\n",
       "  1160963.5196700508,\n",
       "  1156477.807106599,\n",
       "  1155565.260786802,\n",
       "  1179353.3864213198,\n",
       "  1161402.7354060914,\n",
       "  1183022.1973350253,\n",
       "  1150830.3578680202,\n",
       "  ...],\n",
       " [1439565.3587301588,\n",
       "  1439236.3073015872,\n",
       "  1438906.9053968254,\n",
       "  1438574.0393650793,\n",
       "  1438265.4273015873,\n",
       "  1437966.08,\n",
       "  1437679.354920635,\n",
       "  1437367.8984126984,\n",
       "  1437058.3111111112,\n",
       "  1436744.4266666668,\n",
       "  1436434.0063492064,\n",
       "  1436127.5123809525,\n",
       "  1435825.7625396824,\n",
       "  1435529.1479365078,\n",
       "  1435231.0857142857,\n",
       "  1434937.5034920634,\n",
       "  1434641.0158730159,\n",
       "  1434346.7123809524,\n",
       "  1434053.5974603174,\n",
       "  1433767.2076190477,\n",
       "  1433445.5365079364,\n",
       "  1433147.4082539682,\n",
       "  1432847.9796825396,\n",
       "  1432540.48,\n",
       "  1432245.12,\n",
       "  1431952.060952381,\n",
       "  1431656.7517460317,\n",
       "  1431368.0304761904,\n",
       "  1431078.5726984127,\n",
       "  1430780.5104761904,\n",
       "  1430491.7993650793,\n",
       "  1430200.193015873,\n",
       "  1429908.424126984,\n",
       "  1429615.7714285713,\n",
       "  1429328.62984127,\n",
       "  1429035.5098412698,\n",
       "  1428748.485079365,\n",
       "  1428460.0787301587,\n",
       "  1428165.2266666666,\n",
       "  1427878.8520634922,\n",
       "  1427589.6736507937,\n",
       "  1427301.0996825397,\n",
       "  1427011.073015873,\n",
       "  1426726.1612698413,\n",
       "  1426437.4095238096,\n",
       "  1426151.5276190476,\n",
       "  1425864.4774603175,\n",
       "  1425581.953015873,\n",
       "  1425286.09015873,\n",
       "  1425002.041904762,\n",
       "  1424715.9415873017,\n",
       "  1424433.412063492,\n",
       "  1424143.3244444444,\n",
       "  1423855.608888889,\n",
       "  1423569.2393650794,\n",
       "  1423283.7079365079,\n",
       "  1422996.3377777778,\n",
       "  1422708.9726984126,\n",
       "  1422422.9587301586,\n",
       "  1422139.575873016,\n",
       "  1421845.9936507936,\n",
       "  1421563.7993650793,\n",
       "  1421282.0571428572,\n",
       "  1420989.754920635,\n",
       "  1420711.37015873,\n",
       "  1420424.0101587302,\n",
       "  1420136.9853968255,\n",
       "  1419848.706031746,\n",
       "  1419564.6526984128,\n",
       "  1419284.6679365078,\n",
       "  1418998.6844444445,\n",
       "  1418715.5606349206,\n",
       "  1418428.419047619,\n",
       "  1418140.1244444444,\n",
       "  1417857.3815873016,\n",
       "  1417572.5968253969,\n",
       "  1417291.387936508,\n",
       "  1417002.4685714287,\n",
       "  1416724.4292063492,\n",
       "  1416439.3752380952,\n",
       "  1416152.3250793652,\n",
       "  1415863.354920635,\n",
       "  1415578.1942857143,\n",
       "  1415296.177777778,\n",
       "  1415013.0946031746,\n",
       "  1414732.7187301586,\n",
       "  1414454.5168253968,\n",
       "  1414169.4374603175,\n",
       "  1413884.601904762,\n",
       "  1413604.860952381,\n",
       "  1413320.700952381,\n",
       "  1413032.6653968254,\n",
       "  1412750.7453968255,\n",
       "  1412467.4488888888,\n",
       "  1412185.6863492064,\n",
       "  1411901.6533333333,\n",
       "  1411618.300952381,\n",
       "  1411337.406984127,\n",
       "  1411055.7307936507,\n",
       "  1410774.405079365,\n",
       "  1410492.794920635,\n",
       "  1410213.9885714285,\n",
       "  1409929.0107936508,\n",
       "  1409644.9676190477,\n",
       "  1409365.6584126984,\n",
       "  1409084.1295238095,\n",
       "  1408801.6609523809,\n",
       "  1408525.252063492,\n",
       "  1408238.3847619048,\n",
       "  1407958.6184126984,\n",
       "  1407677.8006349206,\n",
       "  1407398.587936508,\n",
       "  1407115.001904762,\n",
       "  1406834.6006349206,\n",
       "  1406553.2698412698,\n",
       "  1406269.5111111111,\n",
       "  1405987.8095238095,\n",
       "  1405705.2342857143,\n",
       "  1405424.137142857,\n",
       "  1405142.4406349207,\n",
       "  1404862.593015873,\n",
       "  1404585.4273015873,\n",
       "  1404302.9384126985,\n",
       "  1404021.9682539683,\n",
       "  1403744.6704761905,\n",
       "  1403464.0914285714,\n",
       "  1403184.8939682539,\n",
       "  1402900.6374603175,\n",
       "  1402615.1263492063,\n",
       "  1402340.4444444445,\n",
       "  1402057.6304761905,\n",
       "  1401775.7815873015,\n",
       "  1401502.0088888889,\n",
       "  1401219.8755555556,\n",
       "  1400940.8965079365,\n",
       "  1400662.6133333333,\n",
       "  1400377.8895238095,\n",
       "  1400101.633015873,\n",
       "  1399821.1809523809,\n",
       "  1399542.4,\n",
       "  1399260.485079365,\n",
       "  1398983.806984127,\n",
       "  1398704.5333333334,\n",
       "  1398425.1784126984,\n",
       "  1398142.6539682539,\n",
       "  1397865.0615873015,\n",
       "  1397582.857142857,\n",
       "  1397300.3326984127,\n",
       "  1397024.8076190476,\n",
       "  1396742.1765079366,\n",
       "  1396468.8761904761,\n",
       "  1396190.643809524,\n",
       "  1395913.1834920635,\n",
       "  1395630.2425396824,\n",
       "  1395352.9346031747,\n",
       "  1395072.4622222222,\n",
       "  1394793.0768253969,\n",
       "  1394514.372063492,\n",
       "  1394233.4222222222,\n",
       "  1393955.4184126984,\n",
       "  1393680.9193650794,\n",
       "  1393396.7187301586,\n",
       "  1393123.5250793651,\n",
       "  1392843.8095238095,\n",
       "  1392565.6736507937,\n",
       "  1392356.7847619047,\n",
       "  1392011.2304761906,\n",
       "  1391734.8114285714,\n",
       "  1391970.6565079365,\n",
       "  1391177.4882539683,\n",
       "  1390902.2222222222,\n",
       "  1390625.1479365078,\n",
       "  1390344.4419047618,\n",
       "  1390068.3225396825,\n",
       "  1389791.2838095238,\n",
       "  1389513.8438095239,\n",
       "  1389241.594920635,\n",
       "  1388964.220952381,\n",
       "  1388685.9631746032,\n",
       "  1388408.3606349207,\n",
       "  1388132.3885714286,\n",
       "  1387849.8946031746,\n",
       "  1387575.1822222222,\n",
       "  1387299.7841269842,\n",
       "  1387021.379047619,\n",
       "  1386742.0444444444,\n",
       "  1386467.2203174604,\n",
       "  1386193.9504761905,\n",
       "  1385917.0641269842,\n",
       "  1385638.5676190476,\n",
       "  1385360.7314285715,\n",
       "  1385086.3695238095,\n",
       "  1384805.7447619047,\n",
       "  1384533.4247619049,\n",
       "  1384257.1631746031,\n",
       "  1383978.0368253968,\n",
       "  1383697.8234920634,\n",
       "  1383426.4634920636,\n",
       "  1383147.6317460318,\n",
       "  1382868.1549206348,\n",
       "  1382592.0,\n",
       "  1382313.58984127,\n",
       "  1382040.4622222222,\n",
       "  1381765.5923809523,\n",
       "  1381491.2711111112,\n",
       "  1381209.5593650793,\n",
       "  1380931.1593650794,\n",
       "  1380653.2419047619,\n",
       "  1380383.4717460317,\n",
       "  1380111.5022222223,\n",
       "  1379836.0025396824,\n",
       "  1379563.575873016,\n",
       "  1379287.3244444444,\n",
       "  1379009.356190476,\n",
       "  1378734.1815873017,\n",
       "  1378461.048888889,\n",
       "  1378187.6165079365,\n",
       "  1377911.9542857143,\n",
       "  1377638.9942857143,\n",
       "  1377361.097142857,\n",
       "  1377084.419047619,\n",
       "  1376810.6463492063,\n",
       "  1376539.5047619047,\n",
       "  1376264.4215873017,\n",
       "  1375992.4317460319,\n",
       "  1375716.0380952382,\n",
       "  1375445.7396825396,\n",
       "  1375167.6546031747,\n",
       "  1374890.753015873,\n",
       "  1374620.4292063492,\n",
       "  1374345.8793650793,\n",
       "  1374072.7365079366,\n",
       "  1373801.0107936508,\n",
       "  1373525.10984127,\n",
       "  1373248.0203174604,\n",
       "  1372975.944126984,\n",
       "  1372699.8298412699,\n",
       "  1372425.5542857142,\n",
       "  1372156.2565079364,\n",
       "  1371882.1282539682,\n",
       "  1371607.7104761906,\n",
       "  1371336.0355555555,\n",
       "  1371063.4565079366,\n",
       "  1370792.1676190477,\n",
       "  1370515.144126984,\n",
       "  1370238.5168253968,\n",
       "  1369967.7561904762,\n",
       "  1369695.4717460317,\n",
       "  1369423.4463492064,\n",
       "  1369156.165079365,\n",
       "  1368882.046984127,\n",
       "  1368605.4349206348,\n",
       "  1368336.6857142858,\n",
       "  1368063.4615873017,\n",
       "  1367793.4831746032,\n",
       "  1367523.5047619047,\n",
       "  1367245.638095238,\n",
       "  1366979.84,\n",
       "  1366707.5555555555,\n",
       "  1366435.7587301587,\n",
       "  1366159.5174603174,\n",
       "  1365891.3625396825,\n",
       "  1365620.485079365,\n",
       "  1365353.7726984126,\n",
       "  1365079.9847619047,\n",
       "  1364810.9968253968,\n",
       "  1364540.6476190477,\n",
       "  1364268.226031746,\n",
       "  1363994.1688888888,\n",
       "  1363722.0622222223,\n",
       "  1363449.9911111111,\n",
       "  1363176.1015873016,\n",
       "  1362909.048888889,\n",
       "  1362636.1396825397,\n",
       "  1362365.693968254,\n",
       "  1362098.0520634921,\n",
       "  1361828.673015873,\n",
       "  1361554.499047619,\n",
       "  1361283.2507936507,\n",
       "  1361016.4419047618,\n",
       "  1360742.7606349206,\n",
       "  1360473.1377777779,\n",
       "  1360205.7447619047,\n",
       "  1359936.2184126985,\n",
       "  1359665.7015873017,\n",
       "  1359395.8806349207,\n",
       "  1359123.073015873,\n",
       "  1358853.4806349205,\n",
       "  1358584.3047619048,\n",
       "  1358317.7346031745,\n",
       "  1358049.28,\n",
       "  1357776.706031746,\n",
       "  1357504.0914285714,\n",
       "  1357236.165079365,\n",
       "  1356966.9993650794,\n",
       "  1356699.8146031746,\n",
       "  1356432.3453968253,\n",
       "  1356161.9149206348,\n",
       "  1355885.9987301587,\n",
       "  1355613.693968254,\n",
       "  1355344.2438095238,\n",
       "  1355076.353015873,\n",
       "  1354810.4482539683,\n",
       "  1354541.500952381,\n",
       "  1354270.526984127,\n",
       "  1354002.499047619,\n",
       "  1353727.68,\n",
       "  1353462.9892063492,\n",
       "  1353193.1885714286,\n",
       "  1354216.5282539683,\n",
       "  1352648.700952381,\n",
       "  1352386.4431746032,\n",
       "  1352121.5441269842,\n",
       "  1351844.8355555555,\n",
       "  1351576.3403174602,\n",
       "  1351306.88,\n",
       "  1351040.904126984,\n",
       "  1350772.6222222222,\n",
       "  1350508.4139682539,\n",
       "  1350238.902857143,\n",
       "  1349972.6679365078,\n",
       "  1349705.7574603176,\n",
       "  1349440.0355555555,\n",
       "  1349172.1092063491,\n",
       "  1348903.233015873,\n",
       "  1348638.1307936509,\n",
       "  1348370.7682539683,\n",
       "  1348101.754920635,\n",
       "  1347835.067936508,\n",
       "  1347564.347936508,\n",
       "  1347297.153015873,\n",
       "  1347032.5028571428,\n",
       "  1346762.3314285714,\n",
       "  1346493.3993650794,\n",
       "  1346223.8323809523,\n",
       "  1345954.8342857142,\n",
       "  1345689.7980952382,\n",
       "  1345418.8647619048,\n",
       "  1345150.7707936508,\n",
       "  1344882.361904762,\n",
       "  1344615.740952381,\n",
       "  1344350.4812698413,\n",
       "  1344088.2082539683,\n",
       "  1343816.6247619048,\n",
       "  1343547.3574603174,\n",
       "  1343279.3752380952,\n",
       "  1343015.426031746,\n",
       "  1342755.0882539682,\n",
       "  1342478.6793650794,\n",
       "  1342216.9904761906,\n",
       "  1341952.4012698412,\n",
       "  1341683.4133333333,\n",
       "  1341416.7517460317,\n",
       "  1341152.2285714287,\n",
       "  1340886.9333333333,\n",
       "  1340625.539047619,\n",
       "  1340357.2266666666,\n",
       "  1340091.8044444444,\n",
       "  1339820.2971428572,\n",
       "  1339559.426031746,\n",
       "  1339293.3536507937,\n",
       "  1339027.4946031745,\n",
       "  1338762.9104761905,\n",
       "  1338493.5161904762,\n",
       "  1338227.0425396825,\n",
       "  1337967.9238095237,\n",
       "  1337695.095873016,\n",
       "  1337433.0463492062,\n",
       "  1337166.4152380952,\n",
       "  1336904.7365079366,\n",
       "  1336639.5428571429,\n",
       "  1336382.1409523808,\n",
       "  1336109.958095238,\n",
       "  1335846.3949206348,\n",
       "  1335579.713015873,\n",
       "  1335312.0152380953,\n",
       "  1335047.873015873,\n",
       "  1334784.573968254,\n",
       "  1334520.3047619048,\n",
       "  1334255.68,\n",
       "  1333990.3187301587,\n",
       "  1333728.126984127,\n",
       "  1333461.10984127,\n",
       "  1333196.8660317461,\n",
       "  1332935.9898412698,\n",
       "  1332672.0101587302,\n",
       "  1332407.6342857142,\n",
       "  1332149.8565079365,\n",
       "  1331887.100952381,\n",
       "  1331621.9073015873,\n",
       "  1331359.299047619,\n",
       "  1331095.410793651,\n",
       "  1330830.1815873017,\n",
       "  1330566.2476190475,\n",
       "  1330303.4006349207,\n",
       "  1330042.1587301588,\n",
       "  1329777.6406349207,\n",
       "  1329514.8342857142,\n",
       "  1329249.0565079364,\n",
       "  1328983.0755555555,\n",
       "  1328719.233015873,\n",
       "  1328459.8450793652,\n",
       "  1328193.7523809525,\n",
       "  1327932.5561904763,\n",
       "  1327667.2863492065,\n",
       "  1327404.673015873,\n",
       "  1327140.9117460318,\n",
       "  1326878.8926984128,\n",
       "  1326615.867936508,\n",
       "  1326356.1193650793,\n",
       "  1326091.7841269842,\n",
       "  1325826.56,\n",
       "  1325572.9777777777,\n",
       "  1325304.766984127,\n",
       "  1325045.048888889,\n",
       "  1324783.994920635,\n",
       "  1324527.288888889,\n",
       "  1324258.4584126985,\n",
       "  1323997.6838095237,\n",
       "  1323739.646984127,\n",
       "  1323476.403809524,\n",
       "  1323214.8114285714,\n",
       "  1322954.9714285715,\n",
       "  1322693.0641269842,\n",
       "  1322429.6584126984,\n",
       "  1322167.492063492,\n",
       "  1321905.9301587301,\n",
       "  1321644.7238095237,\n",
       "  1321384.0965079365,\n",
       "  1321122.7123809524,\n",
       "  1320864.177777778,\n",
       "  1320600.5587301587,\n",
       "  1320341.0387301587,\n",
       "  1320080.1625396826,\n",
       "  1319821.5466666666,\n",
       "  1319559.9542857143,\n",
       "  1319298.0114285715,\n",
       "  1319036.220952381,\n",
       "  1318778.686984127,\n",
       "  1318520.9346031747,\n",
       "  1318259.8044444444,\n",
       "  1317995.773968254,\n",
       "  1317738.179047619,\n",
       "  1317477.4907936507,\n",
       "  1317216.5841269842,\n",
       "  1316956.9371428571,\n",
       "  1316692.4647619047,\n",
       "  1316429.9276190477,\n",
       "  1316178.9765079366,\n",
       "  1315909.3892063492,\n",
       "  1315651.5301587302,\n",
       "  1315418.6615873016,\n",
       "  1315130.8241269842,\n",
       "  1314872.904126984,\n",
       "  1314610.306031746,\n",
       "  1314353.274920635,\n",
       "  1314093.0234920634,\n",
       "  1313829.186031746,\n",
       "  1313570.951111111,\n",
       "  1313307.144126984,\n",
       "  1313052.9777777777,\n",
       "  1312788.2057142856,\n",
       "  1312529.5695238095,\n",
       "  1312268.5307936508,\n",
       "  1312012.281904762,\n",
       "  1311746.9257142858,\n",
       "  1311488.0812698412,\n",
       "  1311231.6342857142,\n",
       "  1310973.7853968253,\n",
       "  1310712.0965079365,\n",
       "  1310453.0793650793,\n",
       "  1310195.8653968254,\n",
       "  1309935.04,\n",
       "  1309675.9415873017,\n",
       "  1309417.2952380953,\n",
       "  1309160.827936508,\n",
       "  1308898.86984127,\n",
       "  1308638.9993650794,\n",
       "  1308376.253968254,\n",
       "  1308122.0622222223,\n",
       "  1307855.36,\n",
       "  1307595.895873016,\n",
       "  1307340.1396825397,\n",
       "  1307079.4615873017,\n",
       "  1306820.7644444443,\n",
       "  1306556.8660317461,\n",
       "  1306299.7536507936,\n",
       "  1306045.9123809524,\n",
       "  1305789.7955555555,\n",
       "  1305526.7149206349,\n",
       "  1305270.2323809525,\n",
       "  1305008.2184126985,\n",
       "  1304747.9568253967,\n",
       "  1304495.9136507937,\n",
       "  1304233.2088888888,\n",
       "  1303977.4628571428,\n",
       "  1303717.627936508,\n",
       "  1303458.9714285715,\n",
       "  1303206.7606349206,\n",
       "  1302946.8444444444,\n",
       "  1302692.860952381,\n",
       "  1302437.2673015874,\n",
       "  1302172.932063492,\n",
       "  1301918.5574603174,\n",
       "  1301666.9968253968,\n",
       "  1301404.2412698413,\n",
       "  1301146.7022222222,\n",
       "  1300890.3365079365,\n",
       "  1300632.96,\n",
       "  1300374.1561904761,\n",
       "  1300117.368888889,\n",
       "  1299860.8965079365,\n",
       "  1299607.0146031745,\n",
       "  1299347.4133333333,\n",
       "  1299096.3098412699,\n",
       "  1298837.4653968255,\n",
       "  1298576.4673015873,\n",
       "  1298321.9149206348,\n",
       "  1298066.1130158731,\n",
       "  1297813.0692063493,\n",
       "  1297550.0292063493,\n",
       "  1297297.1784126984,\n",
       "  1297035.6926984128,\n",
       "  1296779.3726984127,\n",
       "  1296524.606984127,\n",
       "  1296266.2247619047,\n",
       "  1296011.7942857144,\n",
       "  1295760.5638095238,\n",
       "  1295502.2019047618,\n",
       "  1295243.6977777777,\n",
       "  1294990.725079365,\n",
       "  1294733.9022222222,\n",
       "  1294472.380952381,\n",
       "  1294216.2641269842,\n",
       "  1293966.1968253967,\n",
       "  1293703.933968254,\n",
       "  1293447.034920635,\n",
       "  1293191.862857143,\n",
       "  1292936.96,\n",
       "  1292684.0838095238,\n",
       "  1292425.8285714285,\n",
       "  1292172.1853968254,\n",
       "  1291914.7682539683,\n",
       "  1291665.2292063492,\n",
       "  1291413.0641269842,\n",
       "  1291152.9803174604,\n",
       "  1290902.013968254,\n",
       "  1290643.5504761904,\n",
       "  1290389.699047619,\n",
       "  1290141.7803174604,\n",
       "  1289881.1022222221,\n",
       "  1289618.433015873,\n",
       "  1289362.9663492064,\n",
       "  1289106.1993650794,\n",
       "  1288851.1949206349,\n",
       "  1288599.2584126985,\n",
       "  1288336.645079365,\n",
       "  1288087.1314285714,\n",
       "  1287833.6253968254,\n",
       "  1287578.6107936508,\n",
       "  1287331.1085714286,\n",
       "  1287072.4368253967,\n",
       "  1286817.4526984126,\n",
       "  1286566.6336507937,\n",
       "  1286311.37015873,\n",
       "  1286059.4336507937,\n",
       "  1285802.7174603175,\n",
       "  1285552.1625396826,\n",
       "  1285299.8450793652,\n",
       "  1285048.0457142857,\n",
       "  1284788.2920634921,\n",
       "  1284537.1276190476,\n",
       "  1284283.4996825396,\n",
       "  1284039.1466666667,\n",
       "  1283787.4488888888,\n",
       "  1283524.0431746033,\n",
       "  1283268.7288888888,\n",
       "  1283015.5276190476,\n",
       "  1284930.5295238094,\n",
       "  1282512.0507936508,\n",
       "  1282265.9301587301,\n",
       "  1282007.5580952382,\n",
       "  1281750.6285714286,\n",
       "  1281503.238095238,\n",
       "  1281246.8012698414,\n",
       "  1285555.895873016,\n",
       "  1285301.6787301588,\n",
       "  1285052.9676190477,\n",
       "  1284792.7365079366,\n",
       "  1284540.5358730159,\n",
       "  1284287.0095238094,\n",
       "  1284040.772063492,\n",
       "  1283781.9377777777,\n",
       "  1283527.1923809524,\n",
       "  1283274.2806349206,\n",
       "  1283019.8907936509,\n",
       "  1282770.7225396826,\n",
       "  1282510.7403174604,\n",
       "  1282262.0495238095,\n",
       "  1282005.1047619048,\n",
       "  1281754.1587301588,\n",
       "  1281500.5257142857,\n",
       "  1281242.940952381,\n",
       "  1280998.2171428571,\n",
       "  1280736.5638095238,\n",
       "  1280477.5111111111,\n",
       "  1280224.4063492063,\n",
       "  1279971.9365079366,\n",
       "  1279719.3092063493,\n",
       "  1279465.2901587302,\n",
       "  1279218.295873016,\n",
       "  1278958.1409523808,\n",
       "  1278704.6196825397,\n",
       "  1278458.0520634921,\n",
       "  1278201.2698412698,\n",
       "  1277951.2076190477,\n",
       "  1277696.3555555556,\n",
       "  1277447.2228571428,\n",
       "  1277198.2628571428,\n",
       "  1276942.5066666666,\n",
       "  1276688.126984127,\n",
       "  1276439.8933333333,\n",
       "  1276198.7606349206,\n",
       "  1275934.6793650794,\n",
       "  1275683.7282539683,\n",
       "  1275434.1434920635,\n",
       "  1275178.626031746,\n",
       "  1274929.1733333333,\n",
       "  1274684.860952381,\n",
       "  1274428.8,\n",
       "  1274179.4234920635,\n",
       "  1273924.3885714286,\n",
       "  1273680.6603174603,\n",
       "  1273425.1276190476,\n",
       "  1273174.8063492063,\n",
       "  1272926.6946031747,\n",
       "  1272671.2634920634,\n",
       "  1272415.0704761904,\n",
       "  1272171.393015873,\n",
       "  1271920.4825396826,\n",
       "  1271671.7155555557,\n",
       "  1271425.219047619,\n",
       "  1271169.9352380952,\n",
       "  1270919.9847619047,\n",
       "  1270679.0806349206,\n",
       "  1270420.8812698412,\n",
       "  1270343.1619047618,\n",
       "  1274937.7523809525,\n",
       "  1274687.4666666666,\n",
       "  1274436.2514285715,\n",
       "  1274179.84,\n",
       "  1273930.0876190476,\n",
       "  1273681.5238095238,\n",
       "  1273431.2584126985,\n",
       "  1273178.2603174604,\n",
       "  1272923.398095238,\n",
       "  1272674.8190476191,\n",
       "  1272429.186031746,\n",
       "  1272168.0761904763,\n",
       "  1271923.636825397,\n",
       "  1271668.1346031746,\n",
       "  1271417.3714285714,\n",
       "  1271161.9758730158,\n",
       "  1270916.4901587302,\n",
       "  1270663.2228571428,\n",
       "  1270415.7561904762,\n",
       "  1270159.233015873,\n",
       "  1269909.9682539683,\n",
       "  1269673.1834920635,\n",
       "  1269408.0761904763,\n",
       "  1269163.7028571428,\n",
       "  1268904.0203174604,\n",
       "  1268651.083174603,\n",
       "  1268399.0247619047,\n",
       "  1268150.4253968254,\n",
       "  1267897.3104761904,\n",
       "  1267647.2533333334,\n",
       "  1267401.7422222223,\n",
       "  1267156.0177777777,\n",
       "  1266904.706031746,\n",
       "  1266650.2603174604,\n",
       "  1266407.0450793651,\n",
       "  1266149.9276190477,\n",
       "  1265902.902857143,\n",
       "  1265652.6831746032,\n",
       "  1265402.8952380952,\n",
       "  1265150.1612698413,\n",
       "  1264900.7288888888,\n",
       "  1264655.2584126985,\n",
       "  1264405.6634920635,\n",
       "  1264157.2774603174,\n",
       "  1263906.295873016,\n",
       "  1263654.8368253969,\n",
       "  1263405.0946031746,\n",
       "  1263155.713015873,\n",
       "  1262910.5676190476,\n",
       "  1262660.3784126984,\n",
       "  1262413.8565079365,\n",
       "  1267535.2025396826,\n",
       "  1267286.3949206348,\n",
       "  1267038.918095238,\n",
       "  1266781.0996825397,\n",
       "  1266534.1714285715,\n",
       "  1266296.2742857144,\n",
       "  1266033.3612698412,\n",
       "  1265780.0126984126,\n",
       "  1265531.5657142857,\n",
       "  1265286.4863492064,\n",
       "  1265028.733968254,\n",
       "  1264782.4863492064,\n",
       "  1264530.620952381,\n",
       "  1264283.0425396825,\n",
       "  1264038.344126984,\n",
       "  1263787.4031746031,\n",
       "  1263536.1015873016,\n",
       "  1263286.6234920635,\n",
       "  1263039.7866666666,\n",
       "  1262793.4933333334,\n",
       "  1262540.4901587302,\n",
       "  1262283.5352380953,\n",
       "  1262041.986031746,\n",
       "  1261796.0025396824,\n",
       "  1261541.1555555556,\n",
       "  1261289.0920634922,\n",
       "  1261045.6888888888,\n",
       "  1260794.2044444445,\n",
       "  1260544.5587301587,\n",
       "  1260307.5911111112,\n",
       "  1260049.0107936508,\n",
       "  1259797.693968254,\n",
       "  1259549.2317460317,\n",
       "  1259300.2311111111,\n",
       "  1259052.9422222222,\n",
       "  1258801.335873016,\n",
       "  1258554.3111111112,\n",
       "  1261175.8577777778,\n",
       "  1258057.6457142858,\n",
       "  1257813.9834920636,\n",
       "  1257557.5111111111,\n",
       "  1257301.4298412697,\n",
       "  1257062.9434920636,\n",
       "  1256812.1904761905,\n",
       "  1256561.4984126985,\n",
       "  1256316.0990476192,\n",
       "  1256062.3238095238,\n",
       "  1255813.4196825398,\n",
       "  1255570.5447619047,\n",
       "  1255315.596190476,\n",
       "  1255070.4965079366,\n",
       "  1254822.4558730158,\n",
       "  1254579.4488888888,\n",
       "  1254327.6749206348,\n",
       "  1254079.156825397,\n",
       "  1253837.2622222223,\n",
       "  1253589.2622222223,\n",
       "  1253347.3117460317,\n",
       "  1253090.9358730158,\n",
       "  1252848.9498412698,\n",
       "  1252595.9415873017,\n",
       "  1252351.624126984,\n",
       "  1252103.0044444446,\n",
       "  1251858.0520634921,\n",
       "  1251610.885079365,\n",
       "  1251372.0126984126,\n",
       "  1251122.5498412699,\n",
       "  1250876.5714285714,\n",
       "  1250628.5612698412,\n",
       "  1250379.9314285715,\n",
       "  1250128.9701587302,\n",
       "  1249888.568888889,\n",
       "  1249642.4126984128,\n",
       "  1249395.9974603176,\n",
       "  1249151.5377777778,\n",
       "  1248901.373968254,\n",
       "  1248659.1187301588,\n",
       "  1248407.873015873,\n",
       "  1248163.8196825397,\n",
       "  1247922.5955555555,\n",
       "  1247673.7980952382,\n",
       "  1247422.5422222223,\n",
       "  1247182.4761904762,\n",
       "  1246933.9784126985,\n",
       "  1246684.2158730158,\n",
       "  1246440.7923809523,\n",
       "  1246188.5612698412,\n",
       "  1245949.8717460318,\n",
       "  1245704.0203174604,\n",
       "  1245461.2012698413,\n",
       "  1245217.219047619,\n",
       "  1244966.019047619,\n",
       "  1244723.1492063492,\n",
       "  1244484.4546031747,\n",
       "  1244238.846984127,\n",
       "  1243984.2031746032,\n",
       "  1243741.2622222223,\n",
       "  1243494.1053968254,\n",
       "  1243249.8336507936,\n",
       "  1243007.3803174603,\n",
       "  1242755.7536507936,\n",
       "  1242518.7758730159,\n",
       "  1242272.8584126984,\n",
       "  1242034.3974603175,\n",
       "  1241785.986031746,\n",
       "  1241538.1587301588,\n",
       "  1241293.5212698414,\n",
       "  1241052.3326984127,\n",
       "  1240801.6355555556,\n",
       "  1240557.754920635,\n",
       "  1243382.5980952382,\n",
       "  1243136.6907936507,\n",
       "  1242901.3028571429,\n",
       "  1242654.2882539683,\n",
       "  1242445.44,\n",
       "  1242171.9466666668,\n",
       "  1241927.7968253968,\n",
       "  1241690.7276190475,\n",
       "  1241440.904126984,\n",
       "  1241201.2698412698,\n",
       "  1240959.04,\n",
       "  1240715.646984127,\n",
       "  1240473.1225396825,\n",
       "  1240238.8215873016,\n",
       "  1239990.6996825398,\n",
       "  1239753.1784126984,\n",
       "  1239512.4774603175,\n",
       "  1239289.1022222221,\n",
       "  1239031.2584126985,\n",
       "  1238792.1422222222,\n",
       "  1238547.2,\n",
       "  1238306.5142857144,\n",
       "  1238068.1803174603,\n",
       "  1237827.8653968254,\n",
       "  1237586.7428571428,\n",
       "  1237347.5301587302,\n",
       "  1237108.4495238096,\n",
       "  1236865.478095238,\n",
       "  1236629.7955555555,\n",
       "  1236385.5796825397,\n",
       "  1236145.4323809524,\n",
       "  1235914.9815873015,\n",
       "  1235663.0603174602,\n",
       "  1235423.2177777777,\n",
       "  1235189.2165079366,\n",
       "  1234966.9993650794,\n",
       "  1234702.786031746,\n",
       "  1234459.6825396826,\n",
       "  1234214.786031746,\n",
       "  1234006.9638095237,\n",
       "  1233746.4533333334,\n",
       "  1233503.873015873,\n",
       "  1233273.356190476,\n",
       "  1233022.3949206348,\n",
       "  1232780.8203174602,\n",
       "  1232556.9422222222,\n",
       "  1232298.1282539682,\n",
       "  1232060.617142857,\n",
       "  1231834.4076190477,\n",
       "  1231582.1765079366,\n",
       "  1231344.0355555555,\n",
       "  1231100.871111111,\n",
       "  1230864.0863492063,\n",
       "  1230625.528888889,\n",
       "  1230388.4393650794,\n",
       "  1230143.3955555556,\n",
       "  1229905.4984126985,\n",
       "  1229660.5561904763,\n",
       "  1229422.3187301587,\n",
       "  1229182.7047619047,\n",
       "  1228965.693968254,\n",
       "  1228706.4685714287,\n",
       "  1228467.7841269842,\n",
       "  1228227.4946031745,\n",
       "  1227992.126984127,\n",
       "  1227766.4914285715,\n",
       "  1227515.2761904763,\n",
       "  1227277.0641269842,\n",
       "  1227031.7765079364,\n",
       "  1226810.4736507935,\n",
       "  1226558.5777777778,\n",
       "  1226321.7473015874,\n",
       "  1226085.876825397,\n",
       "  1225850.372063492,\n",
       "  1225612.3936507937,\n",
       "  1225374.72,\n",
       "  1225136.2133333334,\n",
       "  1224901.0336507936,\n",
       "  1224745.28,\n",
       "  1224431.3803174603,\n",
       "  1224192.8634920635,\n",
       "  1223951.4565079366,\n",
       "  1223708.6222222222,\n",
       "  1223465.219047619,\n",
       "  1223239.939047619,\n",
       "  1222996.2006349207,\n",
       "  1222762.4787301586,\n",
       "  1222523.1746031747,\n",
       "  1222289.9707936507,\n",
       "  1222060.6425396826,\n",
       "  1221814.6234920635,\n",
       "  1221571.1085714286,\n",
       "  1221334.6844444445,\n",
       "  1221097.142857143,\n",
       "  1220862.902857143,\n",
       "  1220625.3663492063,\n",
       "  1220393.2444444445,\n",
       "  1220157.4653968255,\n",
       "  1219918.135873016,\n",
       "  1219676.8304761904,\n",
       "  1219442.2247619047,\n",
       "  1219214.6539682539,\n",
       "  1218976.4876190475,\n",
       "  1218728.1726984128,\n",
       "  1218490.4431746032,\n",
       "  1218255.608888889,\n",
       "  1218018.493968254,\n",
       "  1217788.027936508,\n",
       "  1217554.366984127,\n",
       "  1217311.2228571428,\n",
       "  1217081.8387301587,\n",
       "  1216838.013968254,\n",
       "  1216598.0393650793,\n",
       "  1216363.773968254,\n",
       "  1216124.6425396826,\n",
       "  1215892.733968254,\n",
       "  1215656.8482539682,\n",
       "  1215424.9803174604,\n",
       "  1215188.6273015873,\n",
       "  1214966.6692063492,\n",
       "  1214721.7828571429,\n",
       "  1214489.5238095238,\n",
       "  1214248.8634920635,\n",
       "  1214014.4965079366,\n",
       "  1213777.925079365,\n",
       "  1213546.1993650794,\n",
       "  1213313.9758730158,\n",
       "  1213075.1847619046,\n",
       "  1212845.4704761906,\n",
       "  1212601.351111111,\n",
       "  1212360.4723809524,\n",
       "  1212128.3047619048,\n",
       "  1211893.815873016,\n",
       "  1211652.926984127,\n",
       "  1211416.6146031746,\n",
       "  1211180.226031746,\n",
       "  1210948.2768253968,\n",
       "  1210733.368888889,\n",
       "  1210475.0425396825,\n",
       "  1210242.0622222223,\n",
       "  1210010.2044444445,\n",
       "  1209784.7415873015,\n",
       "  1209528.965079365,\n",
       "  1209296.2082539683,\n",
       "  1209058.1333333333,\n",
       "  1208824.573968254,\n",
       "  1208591.4768253968,\n",
       "  1208360.9752380953,\n",
       "  1208127.1517460318,\n",
       "  1207893.5568253968,\n",
       "  1207681.9961904762,\n",
       "  1207419.575873016,\n",
       "  1207185.1022222221,\n",
       "  1206947.4285714286,\n",
       "  1206791.1415873016,\n",
       "  1206481.8031746033,\n",
       "  1206247.4361904762,\n",
       "  1206015.6698412697,\n",
       "  1205772.419047619,\n",
       "  1205539.575873016,\n",
       "  1205316.3276190476,\n",
       "  1205077.0895238095,\n",
       "  1204843.773968254,\n",
       "  1204603.8552380952,\n",
       "  1204375.5022222223,\n",
       "  1204135.426031746,\n",
       "  1203920.452063492,\n",
       "  1203663.7765079364,\n",
       "  1203434.306031746,\n",
       "  1203200.5587301587,\n",
       "  1202970.3365079365,\n",
       "  1202747.266031746,\n",
       "  1202517.384126984,\n",
       "  1202275.4996825396,\n",
       "  1202036.4749206349,\n",
       "  1201823.238095238,\n",
       "  1201570.2857142857,\n",
       "  1201335.0806349206,\n",
       "  1201110.0596825397,\n",
       "  1200869.3892063492,\n",
       "  1200637.7295238096,\n",
       "  1200406.6692063492,\n",
       "  1200168.0253968255,\n",
       "  1200009.7726984126,\n",
       "  1199704.5231746032,\n",
       "  1199464.888888889,\n",
       "  1199229.4857142856,\n",
       "  1198995.9923809525,\n",
       "  1198768.4317460319,\n",
       "  1198527.878095238,\n",
       "  1198298.7834920634,\n",
       "  1198060.673015873,\n",
       "  ...],\n",
       " [5493.0205078125,\n",
       "  5490.3779296875,\n",
       "  5487.6552734375,\n",
       "  5484.94287109375,\n",
       "  5482.41845703125,\n",
       "  5479.9580078125,\n",
       "  5477.61767578125,\n",
       "  5475.11767578125,\n",
       "  5472.6630859375,\n",
       "  5470.201171875,\n",
       "  5467.71728515625,\n",
       "  5465.25439453125,\n",
       "  5462.87353515625,\n",
       "  5460.60888671875,\n",
       "  5458.36181640625,\n",
       "  5456.1884765625,\n",
       "  5454.01513671875,\n",
       "  5451.90234375,\n",
       "  5449.83642578125,\n",
       "  5447.81787109375,\n",
       "  5445.59375,\n",
       "  5443.5732421875,\n",
       "  5441.517578125,\n",
       "  5439.42236328125,\n",
       "  5437.45703125,\n",
       "  5435.478515625,\n",
       "  5433.59130859375,\n",
       "  5431.64697265625,\n",
       "  5429.763671875,\n",
       "  5427.8671875,\n",
       "  5425.9658203125,\n",
       "  5424.06396484375,\n",
       "  5422.2109375,\n",
       "  5420.29443359375,\n",
       "  5418.52587890625,\n",
       "  5416.69482421875,\n",
       "  5414.91748046875,\n",
       "  5413.26171875,\n",
       "  5411.375,\n",
       "  5409.60009765625,\n",
       "  5407.9052734375,\n",
       "  5406.22802734375,\n",
       "  5404.48876953125,\n",
       "  5402.93212890625,\n",
       "  5401.232421875,\n",
       "  5399.7138671875,\n",
       "  5397.8935546875,\n",
       "  5396.74072265625,\n",
       "  5394.794921875,\n",
       "  5393.1982421875,\n",
       "  5391.6611328125,\n",
       "  5390.02587890625,\n",
       "  5388.427734375,\n",
       "  5386.919921875,\n",
       "  5385.6767578125,\n",
       "  5383.966796875,\n",
       "  5382.40869140625,\n",
       "  5380.90234375,\n",
       "  5379.42138671875,\n",
       "  5378.18212890625,\n",
       "  5376.92236328125,\n",
       "  5375.2451171875,\n",
       "  5373.7646484375,\n",
       "  5372.44384765625,\n",
       "  5371.06982421875,\n",
       "  5369.58935546875,\n",
       "  5368.50341796875,\n",
       "  5366.9013671875,\n",
       "  5365.3828125,\n",
       "  5364.16455078125,\n",
       "  5362.82861328125,\n",
       "  5361.50048828125,\n",
       "  5360.28173828125,\n",
       "  5358.68994140625,\n",
       "  5358.11572265625,\n",
       "  5355.99755859375,\n",
       "  5354.90673828125,\n",
       "  5353.84521484375,\n",
       "  5352.1826171875,\n",
       "  5350.79345703125,\n",
       "  5349.48486328125,\n",
       "  5348.16845703125,\n",
       "  5346.88427734375,\n",
       "  5346.0234375,\n",
       "  5344.28173828125,\n",
       "  5342.89013671875,\n",
       "  5341.65185546875,\n",
       "  5340.46923828125,\n",
       "  5338.951171875,\n",
       "  5337.75732421875,\n",
       "  5336.37158203125,\n",
       "  5335.13134765625,\n",
       "  5333.73388671875,\n",
       "  5332.5205078125,\n",
       "  5331.26904296875,\n",
       "  5329.8876953125,\n",
       "  5329.017578125,\n",
       "  5327.45068359375,\n",
       "  5326.05224609375,\n",
       "  5325.0439453125,\n",
       "  5323.6103515625,\n",
       "  5322.6298828125,\n",
       "  5320.90576171875,\n",
       "  5319.5712890625,\n",
       "  5318.64404296875,\n",
       "  5317.3369140625,\n",
       "  5315.7470703125,\n",
       "  5314.99462890625,\n",
       "  5313.59033203125,\n",
       "  5311.99951171875,\n",
       "  5310.8681640625,\n",
       "  5309.55224609375,\n",
       "  5308.2587890625,\n",
       "  5307.11376953125,\n",
       "  5305.56005859375,\n",
       "  5304.55224609375,\n",
       "  5303.37548828125,\n",
       "  5301.79638671875,\n",
       "  5301.13037109375,\n",
       "  5299.41259765625,\n",
       "  5298.16552734375,\n",
       "  5296.96484375,\n",
       "  5295.482421875,\n",
       "  5294.2763671875,\n",
       "  5293.3251953125,\n",
       "  5291.8623046875,\n",
       "  5290.99169921875,\n",
       "  5289.34130859375,\n",
       "  5288.73388671875,\n",
       "  5286.83984375,\n",
       "  5285.51025390625,\n",
       "  5284.5078125,\n",
       "  5282.96875,\n",
       "  5281.77734375,\n",
       "  5280.822265625,\n",
       "  5279.2626953125,\n",
       "  5278.36767578125,\n",
       "  5277.43408203125,\n",
       "  5275.65966796875,\n",
       "  5274.67822265625,\n",
       "  5273.2314453125,\n",
       "  5272.046875,\n",
       "  5270.892578125,\n",
       "  5269.36328125,\n",
       "  5268.57763671875,\n",
       "  5266.9208984375,\n",
       "  5265.7353515625,\n",
       "  5264.51416015625,\n",
       "  5263.09228515625,\n",
       "  5262.06689453125,\n",
       "  5261.0771484375,\n",
       "  5259.58203125,\n",
       "  5258.58935546875,\n",
       "  5257.19189453125,\n",
       "  5255.943359375,\n",
       "  5255.04443359375,\n",
       "  5253.80224609375,\n",
       "  5252.67578125,\n",
       "  5251.2734375,\n",
       "  5250.20654296875,\n",
       "  5248.82958984375,\n",
       "  5247.49951171875,\n",
       "  5246.4677734375,\n",
       "  5245.234375,\n",
       "  5244.04541015625,\n",
       "  5243.53564453125,\n",
       "  5241.75146484375,\n",
       "  5240.642578125,\n",
       "  5243.30859375,\n",
       "  5237.947265625,\n",
       "  5236.65673828125,\n",
       "  5235.62939453125,\n",
       "  5234.66552734375,\n",
       "  5233.2109375,\n",
       "  5231.845703125,\n",
       "  5231.3623046875,\n",
       "  5230.0859375,\n",
       "  5228.42626953125,\n",
       "  5227.05908203125,\n",
       "  5226.5380859375,\n",
       "  5225.3779296875,\n",
       "  5223.62548828125,\n",
       "  5222.68994140625,\n",
       "  5221.23779296875,\n",
       "  5220.07080078125,\n",
       "  5218.87353515625,\n",
       "  5217.71533203125,\n",
       "  5216.4560546875,\n",
       "  5215.66015625,\n",
       "  5214.15380859375,\n",
       "  5212.87744140625,\n",
       "  5212.0634765625,\n",
       "  5211.41259765625,\n",
       "  5209.5,\n",
       "  5207.9951171875,\n",
       "  5206.89990234375,\n",
       "  5205.78076171875,\n",
       "  5204.5859375,\n",
       "  5203.32080078125,\n",
       "  5201.962890625,\n",
       "  5200.80615234375,\n",
       "  5199.96728515625,\n",
       "  5198.69384765625,\n",
       "  5197.494140625,\n",
       "  5196.54833984375,\n",
       "  5195.06298828125,\n",
       "  5193.4609375,\n",
       "  5192.60546875,\n",
       "  5192.23388671875,\n",
       "  5190.6015625,\n",
       "  5189.900390625,\n",
       "  5188.41748046875,\n",
       "  5186.8173828125,\n",
       "  5185.64111328125,\n",
       "  5184.6591796875,\n",
       "  5182.9580078125,\n",
       "  5182.0693359375,\n",
       "  5180.43701171875,\n",
       "  5179.56591796875,\n",
       "  5178.23046875,\n",
       "  5177.34619140625,\n",
       "  5175.9423828125,\n",
       "  5174.85400390625,\n",
       "  5173.4716796875,\n",
       "  5172.4755859375,\n",
       "  5171.51953125,\n",
       "  5170.296875,\n",
       "  5169.12548828125,\n",
       "  5167.6328125,\n",
       "  5167.1640625,\n",
       "  5166.05712890625,\n",
       "  5164.68603515625,\n",
       "  5163.7265625,\n",
       "  5162.34521484375,\n",
       "  5160.830078125,\n",
       "  5160.376953125,\n",
       "  5159.13818359375,\n",
       "  5157.68359375,\n",
       "  5156.55224609375,\n",
       "  5155.02880859375,\n",
       "  5153.9169921875,\n",
       "  5152.88037109375,\n",
       "  5151.375,\n",
       "  5150.25,\n",
       "  5149.0087890625,\n",
       "  5147.82373046875,\n",
       "  5146.54150390625,\n",
       "  5145.35693359375,\n",
       "  5144.33984375,\n",
       "  5143.17724609375,\n",
       "  5141.7900390625,\n",
       "  5141.33642578125,\n",
       "  5139.9111328125,\n",
       "  5138.3916015625,\n",
       "  5137.376953125,\n",
       "  5136.0126953125,\n",
       "  5135.2490234375,\n",
       "  5133.99560546875,\n",
       "  5132.634765625,\n",
       "  5131.41845703125,\n",
       "  5130.13134765625,\n",
       "  5129.02587890625,\n",
       "  5128.10986328125,\n",
       "  5126.61474609375,\n",
       "  5125.59228515625,\n",
       "  5124.505859375,\n",
       "  5122.9892578125,\n",
       "  5122.03857421875,\n",
       "  5120.64501953125,\n",
       "  5119.59423828125,\n",
       "  5118.54296875,\n",
       "  5117.26416015625,\n",
       "  5116.7666015625,\n",
       "  5115.3310546875,\n",
       "  5114.03125,\n",
       "  5112.6728515625,\n",
       "  5111.48388671875,\n",
       "  5110.6337890625,\n",
       "  5109.08544921875,\n",
       "  5107.87158203125,\n",
       "  5106.68994140625,\n",
       "  5105.61865234375,\n",
       "  5104.43994140625,\n",
       "  5103.3330078125,\n",
       "  5102.029296875,\n",
       "  5101.27099609375,\n",
       "  5100.07177734375,\n",
       "  5098.44140625,\n",
       "  5097.58740234375,\n",
       "  5096.41064453125,\n",
       "  5095.31005859375,\n",
       "  5094.80712890625,\n",
       "  5093.01513671875,\n",
       "  5091.841796875,\n",
       "  5090.39404296875,\n",
       "  5089.3623046875,\n",
       "  5088.4013671875,\n",
       "  5087.474609375,\n",
       "  5085.91455078125,\n",
       "  5085.1845703125,\n",
       "  5083.55029296875,\n",
       "  5082.212890625,\n",
       "  5081.1650390625,\n",
       "  5081.205078125,\n",
       "  5080.1484375,\n",
       "  5078.71728515625,\n",
       "  5076.7734375,\n",
       "  5075.6484375,\n",
       "  5074.65234375,\n",
       "  5079.17138671875,\n",
       "  5072.1904296875,\n",
       "  5071.58447265625,\n",
       "  5069.83642578125,\n",
       "  5068.48681640625,\n",
       "  5067.87158203125,\n",
       "  5066.38623046875,\n",
       "  5064.91552734375,\n",
       "  5063.91552734375,\n",
       "  5062.7919921875,\n",
       "  5061.71923828125,\n",
       "  5060.44873046875,\n",
       "  5059.6220703125,\n",
       "  5058.99755859375,\n",
       "  5056.9794921875,\n",
       "  5056.4072265625,\n",
       "  5054.77880859375,\n",
       "  5053.796875,\n",
       "  5052.4541015625,\n",
       "  5051.59375,\n",
       "  5050.24365234375,\n",
       "  5049.34228515625,\n",
       "  5047.72998046875,\n",
       "  5047.22900390625,\n",
       "  5046.0458984375,\n",
       "  5044.8134765625,\n",
       "  5043.4677734375,\n",
       "  5042.208984375,\n",
       "  5041.14013671875,\n",
       "  5039.92724609375,\n",
       "  5038.888671875,\n",
       "  5037.40185546875,\n",
       "  5036.51513671875,\n",
       "  5037.00244140625,\n",
       "  5034.1337890625,\n",
       "  5033.09228515625,\n",
       "  5032.69384765625,\n",
       "  5030.8603515625,\n",
       "  5029.583984375,\n",
       "  5028.65771484375,\n",
       "  5027.212890625,\n",
       "  5027.26953125,\n",
       "  5024.75,\n",
       "  5023.93310546875,\n",
       "  5023.14306640625,\n",
       "  5022.68017578125,\n",
       "  5020.8662109375,\n",
       "  5019.37646484375,\n",
       "  5018.3525390625,\n",
       "  5016.91357421875,\n",
       "  5015.88232421875,\n",
       "  5014.75439453125,\n",
       "  5014.0302734375,\n",
       "  5012.48388671875,\n",
       "  5011.03173828125,\n",
       "  5010.21484375,\n",
       "  5010.03173828125,\n",
       "  5007.91015625,\n",
       "  5006.93896484375,\n",
       "  5005.39013671875,\n",
       "  5004.60205078125,\n",
       "  5004.0595703125,\n",
       "  5003.50390625,\n",
       "  5001.255859375,\n",
       "  5000.40869140625,\n",
       "  4998.78369140625,\n",
       "  4998.40283203125,\n",
       "  4996.64111328125,\n",
       "  4996.03466796875,\n",
       "  4995.02294921875,\n",
       "  4993.6328125,\n",
       "  4992.5205078125,\n",
       "  4991.05419921875,\n",
       "  4989.9755859375,\n",
       "  4989.60498046875,\n",
       "  4988.421875,\n",
       "  4986.6064453125,\n",
       "  4985.48974609375,\n",
       "  4984.40380859375,\n",
       "  4984.33837890625,\n",
       "  4982.98876953125,\n",
       "  4981.25244140625,\n",
       "  4980.19189453125,\n",
       "  4978.9814453125,\n",
       "  4977.8623046875,\n",
       "  4976.84130859375,\n",
       "  4976.60791015625,\n",
       "  4974.88427734375,\n",
       "  4974.45751953125,\n",
       "  4972.21484375,\n",
       "  4971.3974609375,\n",
       "  4970.89990234375,\n",
       "  4969.560546875,\n",
       "  4967.8115234375,\n",
       "  4967.29443359375,\n",
       "  4965.97705078125,\n",
       "  4964.88330078125,\n",
       "  4963.7265625,\n",
       "  4962.79736328125,\n",
       "  4962.20458984375,\n",
       "  4960.38134765625,\n",
       "  4959.01611328125,\n",
       "  4958.06787109375,\n",
       "  4957.8017578125,\n",
       "  4956.83984375,\n",
       "  4955.408203125,\n",
       "  4954.09423828125,\n",
       "  4954.060546875,\n",
       "  4952.91943359375,\n",
       "  4951.4140625,\n",
       "  4949.58935546875,\n",
       "  4948.5322265625,\n",
       "  4947.39599609375,\n",
       "  4947.17578125,\n",
       "  4945.6474609375,\n",
       "  4944.51025390625,\n",
       "  4943.0146484375,\n",
       "  4942.19873046875,\n",
       "  4941.9140625,\n",
       "  4940.99072265625,\n",
       "  4939.61669921875,\n",
       "  4938.349609375,\n",
       "  4937.71484375,\n",
       "  4935.6455078125,\n",
       "  4935.47412109375,\n",
       "  4933.818359375,\n",
       "  4932.6015625,\n",
       "  4931.669921875,\n",
       "  4930.75439453125,\n",
       "  4929.68994140625,\n",
       "  4929.3642578125,\n",
       "  4927.607421875,\n",
       "  4926.0751953125,\n",
       "  4925.34814453125,\n",
       "  4924.05322265625,\n",
       "  4923.30908203125,\n",
       "  4922.73486328125,\n",
       "  4922.1484375,\n",
       "  4920.53662109375,\n",
       "  4920.62548828125,\n",
       "  4918.3935546875,\n",
       "  4917.4072265625,\n",
       "  4921.04052734375,\n",
       "  4914.791015625,\n",
       "  4914.24609375,\n",
       "  4912.85693359375,\n",
       "  4911.107421875,\n",
       "  4911.40283203125,\n",
       "  4908.83251953125,\n",
       "  4907.93701171875,\n",
       "  4906.85302734375,\n",
       "  4905.5869140625,\n",
       "  4905.0400390625,\n",
       "  4904.01513671875,\n",
       "  4902.4921875,\n",
       "  4902.20166015625,\n",
       "  4900.67822265625,\n",
       "  4898.96826171875,\n",
       "  4898.58642578125,\n",
       "  4897.43798828125,\n",
       "  4896.34423828125,\n",
       "  4894.9775390625,\n",
       "  4896.04931640625,\n",
       "  4893.19384765625,\n",
       "  4892.1669921875,\n",
       "  4891.4111328125,\n",
       "  4891.1953125,\n",
       "  4888.9990234375,\n",
       "  4889.92431640625,\n",
       "  4887.13818359375,\n",
       "  4885.7861328125,\n",
       "  4884.9521484375,\n",
       "  4884.15576171875,\n",
       "  4884.27734375,\n",
       "  4881.796875,\n",
       "  4881.1025390625,\n",
       "  4879.7265625,\n",
       "  4878.8828125,\n",
       "  4879.40234375,\n",
       "  4877.966796875,\n",
       "  4876.31005859375,\n",
       "  4875.3427734375,\n",
       "  4874.78759765625,\n",
       "  4872.18359375,\n",
       "  4872.15625,\n",
       "  4870.4189453125,\n",
       "  4869.5302734375,\n",
       "  4869.0537109375,\n",
       "  4867.17919921875,\n",
       "  4866.5458984375,\n",
       "  4865.64111328125,\n",
       "  4864.89208984375,\n",
       "  4864.60888671875,\n",
       "  4862.20263671875,\n",
       "  4861.23095703125,\n",
       "  4860.36962890625,\n",
       "  4859.8447265625,\n",
       "  4858.083984375,\n",
       "  4856.99853515625,\n",
       "  4856.69140625,\n",
       "  4855.52392578125,\n",
       "  4854.7607421875,\n",
       "  4852.84423828125,\n",
       "  4852.6240234375,\n",
       "  4852.08740234375,\n",
       "  4852.33544921875,\n",
       "  4849.22998046875,\n",
       "  4848.7998046875,\n",
       "  4848.23779296875,\n",
       "  4846.1748046875,\n",
       "  4846.9326171875,\n",
       "  4845.2705078125,\n",
       "  4845.49755859375,\n",
       "  4842.02392578125,\n",
       "  4840.98291015625,\n",
       "  4841.66748046875,\n",
       "  4840.22802734375,\n",
       "  4838.623046875,\n",
       "  4838.9931640625,\n",
       "  4836.3505859375,\n",
       "  4834.9052734375,\n",
       "  4834.33837890625,\n",
       "  4832.96240234375,\n",
       "  4832.5185546875,\n",
       "  4830.97998046875,\n",
       "  4833.2109375,\n",
       "  4831.73828125,\n",
       "  4830.64013671875,\n",
       "  4828.3447265625,\n",
       "  4827.298828125,\n",
       "  4826.42333984375,\n",
       "  4825.0380859375,\n",
       "  4824.39501953125,\n",
       "  4824.8291015625,\n",
       "  4823.55419921875,\n",
       "  4823.0947265625,\n",
       "  4820.40625,\n",
       "  4821.3662109375,\n",
       "  4817.474609375,\n",
       "  4817.74072265625,\n",
       "  4818.02001953125,\n",
       "  4814.61279296875,\n",
       "  4813.47021484375,\n",
       "  4812.8544921875,\n",
       "  4812.68994140625,\n",
       "  4811.82763671875,\n",
       "  4812.29638671875,\n",
       "  4809.1689453125,\n",
       "  4808.5400390625,\n",
       "  4807.12109375,\n",
       "  4806.46630859375,\n",
       "  4807.978515625,\n",
       "  4804.01025390625,\n",
       "  4803.14013671875,\n",
       "  4803.19287109375,\n",
       "  4802.44970703125,\n",
       "  4801.76806640625,\n",
       "  4798.3837890625,\n",
       "  4798.953125,\n",
       "  4798.28125,\n",
       "  4798.00146484375,\n",
       "  4795.0517578125,\n",
       "  4794.45947265625,\n",
       "  4794.1650390625,\n",
       "  4794.0166015625,\n",
       "  4793.79443359375,\n",
       "  4791.21728515625,\n",
       "  4789.55419921875,\n",
       "  4788.80810546875,\n",
       "  4798.771484375,\n",
       "  4787.5888671875,\n",
       "  4789.03662109375,\n",
       "  4787.0498046875,\n",
       "  4784.65283203125,\n",
       "  4785.45068359375,\n",
       "  4782.39990234375,\n",
       "  4799.9638671875,\n",
       "  4797.15185546875,\n",
       "  4796.60205078125,\n",
       "  4794.79638671875,\n",
       "  4794.34716796875,\n",
       "  4793.650390625,\n",
       "  4792.98876953125,\n",
       "  4792.0478515625,\n",
       "  4790.9033203125,\n",
       "  4790.15576171875,\n",
       "  4788.97607421875,\n",
       "  4792.5908203125,\n",
       "  4788.1044921875,\n",
       "  4789.5732421875,\n",
       "  4785.513671875,\n",
       "  4784.560546875,\n",
       "  4783.439453125,\n",
       "  4782.88134765625,\n",
       "  4782.83056640625,\n",
       "  4782.36669921875,\n",
       "  4778.9560546875,\n",
       "  4780.06689453125,\n",
       "  4777.06298828125,\n",
       "  4776.93408203125,\n",
       "  4777.0986328125,\n",
       "  4776.81884765625,\n",
       "  4774.865234375,\n",
       "  4774.62451171875,\n",
       "  4774.6142578125,\n",
       "  4771.580078125,\n",
       "  4770.416015625,\n",
       "  4769.4912109375,\n",
       "  4768.38134765625,\n",
       "  4767.5947265625,\n",
       "  4766.6904296875,\n",
       "  4765.12744140625,\n",
       "  4764.98193359375,\n",
       "  4765.59033203125,\n",
       "  4762.9189453125,\n",
       "  4761.27490234375,\n",
       "  4760.99951171875,\n",
       "  4759.03857421875,\n",
       "  4758.1611328125,\n",
       "  4758.93505859375,\n",
       "  4756.77978515625,\n",
       "  4757.083984375,\n",
       "  4754.61572265625,\n",
       "  4756.64013671875,\n",
       "  4753.99853515625,\n",
       "  4752.7919921875,\n",
       "  4753.50634765625,\n",
       "  4751.0849609375,\n",
       "  4749.6826171875,\n",
       "  4750.46923828125,\n",
       "  4747.19287109375,\n",
       "  4748.74951171875,\n",
       "  4748.45654296875,\n",
       "  4746.77978515625,\n",
       "  4744.73046875,\n",
       "  4747.775390625,\n",
       "  4744.62158203125,\n",
       "  4745.0947265625,\n",
       "  4759.5126953125,\n",
       "  4758.64013671875,\n",
       "  4757.1103515625,\n",
       "  4756.45263671875,\n",
       "  4756.3046875,\n",
       "  4755.76123046875,\n",
       "  4753.93603515625,\n",
       "  4754.19140625,\n",
       "  4752.38525390625,\n",
       "  4750.3349609375,\n",
       "  4754.42431640625,\n",
       "  4749.2314453125,\n",
       "  4750.92138671875,\n",
       "  4747.53515625,\n",
       "  4747.05419921875,\n",
       "  4744.5859375,\n",
       "  4743.28173828125,\n",
       "  4743.74267578125,\n",
       "  4743.5693359375,\n",
       "  4741.03955078125,\n",
       "  4740.62451171875,\n",
       "  4741.18603515625,\n",
       "  4741.1357421875,\n",
       "  4741.02783203125,\n",
       "  4737.58203125,\n",
       "  4736.46435546875,\n",
       "  4735.78076171875,\n",
       "  4734.4951171875,\n",
       "  4733.45361328125,\n",
       "  4731.12841796875,\n",
       "  4733.48828125,\n",
       "  4730.87890625,\n",
       "  4731.55224609375,\n",
       "  4728.658203125,\n",
       "  4730.13916015625,\n",
       "  4726.0166015625,\n",
       "  4725.4296875,\n",
       "  4724.7060546875,\n",
       "  4724.0322265625,\n",
       "  4724.1845703125,\n",
       "  4721.0654296875,\n",
       "  4721.75830078125,\n",
       "  4719.5888671875,\n",
       "  4718.96728515625,\n",
       "  4718.68359375,\n",
       "  4717.92626953125,\n",
       "  4718.34423828125,\n",
       "  4717.4951171875,\n",
       "  4716.56689453125,\n",
       "  4719.2158203125,\n",
       "  4716.5849609375,\n",
       "  4731.3837890625,\n",
       "  4731.26611328125,\n",
       "  4730.814453125,\n",
       "  4729.1494140625,\n",
       "  4728.58984375,\n",
       "  4732.03955078125,\n",
       "  4726.69091796875,\n",
       "  4724.83642578125,\n",
       "  4724.8642578125,\n",
       "  4725.3662109375,\n",
       "  4723.6572265625,\n",
       "  4721.30615234375,\n",
       "  4720.6640625,\n",
       "  4719.900390625,\n",
       "  4720.60595703125,\n",
       "  4718.7724609375,\n",
       "  4717.05224609375,\n",
       "  4716.33251953125,\n",
       "  4715.62646484375,\n",
       "  4716.302734375,\n",
       "  4713.80322265625,\n",
       "  4711.845703125,\n",
       "  4711.67578125,\n",
       "  4712.51708984375,\n",
       "  4711.3037109375,\n",
       "  4708.6328125,\n",
       "  4708.86572265625,\n",
       "  4707.90966796875,\n",
       "  4705.9306640625,\n",
       "  4710.23291015625,\n",
       "  4703.90869140625,\n",
       "  4703.60986328125,\n",
       "  4702.5947265625,\n",
       "  4701.92431640625,\n",
       "  4700.6455078125,\n",
       "  4699.7392578125,\n",
       "  4698.044921875,\n",
       "  4714.74462890625,\n",
       "  4698.6240234375,\n",
       "  4700.12841796875,\n",
       "  4697.314453125,\n",
       "  4693.6337890625,\n",
       "  4695.09130859375,\n",
       "  4693.587890625,\n",
       "  4692.1474609375,\n",
       "  4692.560546875,\n",
       "  4689.7685546875,\n",
       "  4690.03857421875,\n",
       "  4690.3564453125,\n",
       "  4686.42431640625,\n",
       "  4685.7763671875,\n",
       "  4685.08056640625,\n",
       "  4686.11474609375,\n",
       "  4683.35595703125,\n",
       "  4682.5029296875,\n",
       "  4682.40625,\n",
       "  4682.00048828125,\n",
       "  4682.42236328125,\n",
       "  4679.58642578125,\n",
       "  4679.298828125,\n",
       "  4677.4658203125,\n",
       "  4675.8603515625,\n",
       "  4674.0478515625,\n",
       "  4675.0947265625,\n",
       "  4673.40234375,\n",
       "  4675.1591796875,\n",
       "  4672.0439453125,\n",
       "  4669.794921875,\n",
       "  4671.1591796875,\n",
       "  4668.75146484375,\n",
       "  4666.9052734375,\n",
       "  4668.60009765625,\n",
       "  4667.533203125,\n",
       "  4666.3408203125,\n",
       "  4665.93701171875,\n",
       "  4664.23291015625,\n",
       "  4662.71923828125,\n",
       "  4661.365234375,\n",
       "  4660.298828125,\n",
       "  4663.22265625,\n",
       "  4659.13818359375,\n",
       "  4657.40966796875,\n",
       "  4659.50341796875,\n",
       "  4658.49072265625,\n",
       "  4654.8798828125,\n",
       "  4655.0673828125,\n",
       "  4652.02880859375,\n",
       "  4652.81689453125,\n",
       "  4652.853515625,\n",
       "  4650.5986328125,\n",
       "  4651.01123046875,\n",
       "  4648.619140625,\n",
       "  4648.49169921875,\n",
       "  4648.0341796875,\n",
       "  4650.13720703125,\n",
       "  4645.72900390625,\n",
       "  4645.2529296875,\n",
       "  4644.58837890625,\n",
       "  4644.650390625,\n",
       "  4644.41162109375,\n",
       "  4641.43310546875,\n",
       "  4641.4248046875,\n",
       "  4640.92529296875,\n",
       "  4641.4384765625,\n",
       "  4639.328125,\n",
       "  4636.36474609375,\n",
       "  4635.76611328125,\n",
       "  4636.28564453125,\n",
       "  4634.11083984375,\n",
       "  4634.06396484375,\n",
       "  4646.1171875,\n",
       "  4642.849609375,\n",
       "  4643.669921875,\n",
       "  4642.2890625,\n",
       "  4644.203125,\n",
       "  4643.42236328125,\n",
       "  4638.6962890625,\n",
       "  4638.62353515625,\n",
       "  4636.35888671875,\n",
       "  4635.5966796875,\n",
       "  4634.693359375,\n",
       "  4634.3369140625,\n",
       "  4633.60400390625,\n",
       "  4632.38720703125,\n",
       "  4630.69482421875,\n",
       "  4631.61181640625,\n",
       "  4629.81005859375,\n",
       "  4636.0947265625,\n",
       "  4630.271484375,\n",
       "  4626.87353515625,\n",
       "  4626.29541015625,\n",
       "  4626.60546875,\n",
       "  4624.68359375,\n",
       "  4624.517578125,\n",
       "  4623.46484375,\n",
       "  4622.2880859375,\n",
       "  4621.82763671875,\n",
       "  4619.92529296875,\n",
       "  4619.8427734375,\n",
       "  4619.4248046875,\n",
       "  4616.99853515625,\n",
       "  4619.87060546875,\n",
       "  4616.67724609375,\n",
       "  4614.87890625,\n",
       "  4616.85498046875,\n",
       "  4617.31787109375,\n",
       "  4613.62109375,\n",
       "  4612.74609375,\n",
       "  4610.47216796875,\n",
       "  4614.0302734375,\n",
       "  4610.6796875,\n",
       "  4611.107421875,\n",
       "  4612.6630859375,\n",
       "  4606.3662109375,\n",
       "  4605.42431640625,\n",
       "  4605.68896484375,\n",
       "  4604.1953125,\n",
       "  4603.5751953125,\n",
       "  4608.4619140625,\n",
       "  4601.4169921875,\n",
       "  4601.8193359375,\n",
       "  4599.3544921875,\n",
       "  4597.63916015625,\n",
       "  4598.158203125,\n",
       "  4597.76708984375,\n",
       "  4595.931640625,\n",
       "  4595.787109375,\n",
       "  4594.5634765625,\n",
       "  4593.697265625,\n",
       "  4594.06494140625,\n",
       "  4592.4423828125,\n",
       "  4590.45166015625,\n",
       "  4590.58935546875,\n",
       "  4588.55419921875,\n",
       "  4588.00244140625,\n",
       "  4591.71484375,\n",
       "  4587.35400390625,\n",
       "  4588.27685546875,\n",
       "  4584.3603515625,\n",
       "  4586.14990234375,\n",
       "  4583.32568359375,\n",
       "  4581.89306640625,\n",
       "  4582.09130859375,\n",
       "  4582.32177734375,\n",
       "  4579.5693359375,\n",
       "  4578.3291015625,\n",
       "  4578.6025390625,\n",
       "  4578.63818359375,\n",
       "  4583.83251953125,\n",
       "  4579.158203125,\n",
       "  4577.60107421875,\n",
       "  4574.7109375,\n",
       "  4571.728515625,\n",
       "  4571.50537109375,\n",
       "  4571.71630859375,\n",
       "  4568.7998046875,\n",
       "  4570.66552734375,\n",
       "  4569.896484375,\n",
       "  4567.15673828125,\n",
       "  4570.4453125,\n",
       "  4566.39892578125,\n",
       "  4564.30078125,\n",
       "  4564.09912109375,\n",
       "  4562.6298828125,\n",
       "  4562.84130859375,\n",
       "  4561.109375,\n",
       "  4561.02783203125,\n",
       "  4560.61767578125,\n",
       "  4559.3642578125,\n",
       "  4559.6044921875,\n",
       "  4557.62841796875,\n",
       "  4562.02294921875,\n",
       "  4559.80810546875,\n",
       "  4556.146484375,\n",
       "  4553.75537109375,\n",
       "  4552.9677734375,\n",
       "  4552.2705078125,\n",
       "  4552.7119140625,\n",
       "  4553.0654296875,\n",
       "  4549.775390625,\n",
       "  4551.7197265625,\n",
       "  4548.2646484375,\n",
       "  4547.49365234375,\n",
       "  4546.27734375,\n",
       "  4544.53955078125,\n",
       "  4544.09130859375,\n",
       "  4544.6357421875,\n",
       "  4542.8642578125,\n",
       "  4541.85986328125,\n",
       "  4547.63134765625,\n",
       "  4541.1181640625,\n",
       "  4542.32373046875,\n",
       "  4538.8662109375,\n",
       "  4538.4853515625,\n",
       "  4537.25830078125,\n",
       "  4537.29345703125,\n",
       "  4536.7978515625,\n",
       "  4535.2939453125,\n",
       "  4538.1162109375,\n",
       "  4533.97412109375,\n",
       "  4532.25537109375,\n",
       "  4532.3984375,\n",
       "  4531.92822265625,\n",
       "  4528.75390625,\n",
       "  4528.29345703125,\n",
       "  4527.48291015625,\n",
       "  4529.07958984375,\n",
       "  4535.931640625,\n",
       "  4527.07275390625,\n",
       "  4525.8623046875,\n",
       "  4526.41552734375,\n",
       "  4528.34033203125,\n",
       "  4523.12744140625,\n",
       "  4521.30078125,\n",
       "  4519.201171875,\n",
       "  4518.37841796875,\n",
       "  4519.22021484375,\n",
       "  4519.6005859375,\n",
       "  4519.056640625,\n",
       "  4516.3525390625,\n",
       "  4518.3642578125,\n",
       "  4515.46240234375,\n",
       "  4513.27978515625,\n",
       "  4511.876953125,\n",
       "  4517.52783203125,\n",
       "  4512.47900390625,\n",
       "  4511.82470703125,\n",
       "  4510.5185546875,\n",
       "  4507.56396484375,\n",
       "  4507.46923828125,\n",
       "  4508.47705078125,\n",
       "  4507.40185546875,\n",
       "  4507.044921875,\n",
       "  4503.78369140625,\n",
       "  4505.09912109375,\n",
       "  4504.30224609375,\n",
       "  4503.93408203125,\n",
       "  4500.70361328125,\n",
       "  4499.85595703125,\n",
       "  4498.5849609375,\n",
       "  4498.265625,\n",
       "  4498.48046875,\n",
       "  4501.1318359375,\n",
       "  4498.21142578125,\n",
       "  4494.18310546875,\n",
       "  4495.38134765625,\n",
       "  4494.55859375,\n",
       "  4492.86083984375,\n",
       "  4493.1796875,\n",
       "  4492.33935546875,\n",
       "  4490.45703125,\n",
       "  4491.837890625,\n",
       "  4488.236328125,\n",
       "  4490.7041015625,\n",
       "  4487.54345703125,\n",
       "  4485.58740234375,\n",
       "  4484.1845703125,\n",
       "  4482.69677734375,\n",
       "  4483.50927734375,\n",
       "  4481.78173828125,\n",
       "  4481.15185546875,\n",
       "  4481.47119140625,\n",
       "  ...],\n",
       " [-0.21040821075439453,\n",
       "  -0.21013367176055908,\n",
       "  -0.20985889434814453,\n",
       "  -0.20958125591278076,\n",
       "  -0.20932400226593018,\n",
       "  -0.2090742588043213,\n",
       "  -0.20883512496948242,\n",
       "  -0.20857524871826172,\n",
       "  -0.20831704139709473,\n",
       "  -0.20805537700653076,\n",
       "  -0.20779645442962646,\n",
       "  -0.2075408697128296,\n",
       "  -0.2072892189025879,\n",
       "  -0.20704174041748047,\n",
       "  -0.20679306983947754,\n",
       "  -0.20654833316802979,\n",
       "  -0.20630085468292236,\n",
       "  -0.20605552196502686,\n",
       "  -0.20581114292144775,\n",
       "  -0.20557236671447754,\n",
       "  -0.20530402660369873,\n",
       "  -0.2050553560256958,\n",
       "  -0.20480573177337646,\n",
       "  -0.20454919338226318,\n",
       "  -0.20430278778076172,\n",
       "  -0.20405828952789307,\n",
       "  -0.20381224155426025,\n",
       "  -0.20357143878936768,\n",
       "  -0.20333003997802734,\n",
       "  -0.20308136940002441,\n",
       "  -0.2028406858444214,\n",
       "  -0.20259737968444824,\n",
       "  -0.2023540735244751,\n",
       "  -0.20211005210876465,\n",
       "  -0.20187056064605713,\n",
       "  -0.20162642002105713,\n",
       "  -0.20138680934906006,\n",
       "  -0.20114624500274658,\n",
       "  -0.20090055465698242,\n",
       "  -0.20066165924072266,\n",
       "  -0.20042061805725098,\n",
       "  -0.2001800537109375,\n",
       "  -0.19993793964385986,\n",
       "  -0.1997004747390747,\n",
       "  -0.19945979118347168,\n",
       "  -0.19922125339508057,\n",
       "  -0.19898200035095215,\n",
       "  -0.19874632358551025,\n",
       "  -0.1984996795654297,\n",
       "  -0.19826269149780273,\n",
       "  -0.19802415370941162,\n",
       "  -0.19778859615325928,\n",
       "  -0.1975466012954712,\n",
       "  -0.19730687141418457,\n",
       "  -0.19706809520721436,\n",
       "  -0.19682979583740234,\n",
       "  -0.19659018516540527,\n",
       "  -0.19635069370269775,\n",
       "  -0.19611215591430664,\n",
       "  -0.19587576389312744,\n",
       "  -0.1956310272216797,\n",
       "  -0.195395827293396,\n",
       "  -0.1951608657836914,\n",
       "  -0.1949169635772705,\n",
       "  -0.1946849822998047,\n",
       "  -0.19444537162780762,\n",
       "  -0.19420623779296875,\n",
       "  -0.19396579265594482,\n",
       "  -0.19372892379760742,\n",
       "  -0.19349539279937744,\n",
       "  -0.19325697422027588,\n",
       "  -0.19302070140838623,\n",
       "  -0.1927814483642578,\n",
       "  -0.1925410032272339,\n",
       "  -0.192305326461792,\n",
       "  -0.1920679807662964,\n",
       "  -0.19183337688446045,\n",
       "  -0.19159245491027832,\n",
       "  -0.1913607120513916,\n",
       "  -0.1911228895187378,\n",
       "  -0.19088363647460938,\n",
       "  -0.19064271450042725,\n",
       "  -0.190405011177063,\n",
       "  -0.1901698112487793,\n",
       "  -0.18993377685546875,\n",
       "  -0.18970012664794922,\n",
       "  -0.1894681453704834,\n",
       "  -0.18923044204711914,\n",
       "  -0.18899297714233398,\n",
       "  -0.18875956535339355,\n",
       "  -0.1885228157043457,\n",
       "  -0.18828260898590088,\n",
       "  -0.1880476474761963,\n",
       "  -0.18781137466430664,\n",
       "  -0.18757641315460205,\n",
       "  -0.1873394250869751,\n",
       "  -0.18710339069366455,\n",
       "  -0.18686926364898682,\n",
       "  -0.18663430213928223,\n",
       "  -0.18639981746673584,\n",
       "  -0.18616509437561035,\n",
       "  -0.18593251705169678,\n",
       "  -0.18569493293762207,\n",
       "  -0.18545806407928467,\n",
       "  -0.18522512912750244,\n",
       "  -0.1849905252456665,\n",
       "  -0.1847550868988037,\n",
       "  -0.18452465534210205,\n",
       "  -0.18428552150726318,\n",
       "  -0.1840522289276123,\n",
       "  -0.18381810188293457,\n",
       "  -0.1835852861404419,\n",
       "  -0.1833488941192627,\n",
       "  -0.1831148862838745,\n",
       "  -0.18288064002990723,\n",
       "  -0.18264400959014893,\n",
       "  -0.1824091672897339,\n",
       "  -0.1821737289428711,\n",
       "  -0.1819392442703247,\n",
       "  -0.18170440196990967,\n",
       "  -0.18147099018096924,\n",
       "  -0.18123984336853027,\n",
       "  -0.18100440502166748,\n",
       "  -0.18077027797698975,\n",
       "  -0.18053901195526123,\n",
       "  -0.1803051233291626,\n",
       "  -0.18007242679595947,\n",
       "  -0.17983543872833252,\n",
       "  -0.17959749698638916,\n",
       "  -0.179368257522583,\n",
       "  -0.1791325807571411,\n",
       "  -0.17889773845672607,\n",
       "  -0.17866945266723633,\n",
       "  -0.17843425273895264,\n",
       "  -0.1782015562057495,\n",
       "  -0.17796969413757324,\n",
       "  -0.17773222923278809,\n",
       "  -0.17750203609466553,\n",
       "  -0.1772681474685669,\n",
       "  -0.17703568935394287,\n",
       "  -0.17680084705352783,\n",
       "  -0.17657005786895752,\n",
       "  -0.17633724212646484,\n",
       "  -0.17610442638397217,\n",
       "  -0.17586886882781982,\n",
       "  -0.17563748359680176,\n",
       "  -0.17540228366851807,\n",
       "  -0.17516672611236572,\n",
       "  -0.17493700981140137,\n",
       "  -0.17470145225524902,\n",
       "  -0.17447352409362793,\n",
       "  -0.17424166202545166,\n",
       "  -0.17401039600372314,\n",
       "  -0.17377448081970215,\n",
       "  -0.17354333400726318,\n",
       "  -0.1733095645904541,\n",
       "  -0.17307662963867188,\n",
       "  -0.17284440994262695,\n",
       "  -0.17261004447937012,\n",
       "  -0.17237818241119385,\n",
       "  -0.17214953899383545,\n",
       "  -0.17191267013549805,\n",
       "  -0.17168498039245605,\n",
       "  -0.17145180702209473,\n",
       "  -0.1712198257446289,\n",
       "  -0.17104732990264893,\n",
       "  -0.17075765132904053,\n",
       "  -0.17052733898162842,\n",
       "  -0.17072522640228271,\n",
       "  -0.17006278038024902,\n",
       "  -0.16983342170715332,\n",
       "  -0.1696023941040039,\n",
       "  -0.16936826705932617,\n",
       "  -0.1691380739212036,\n",
       "  -0.1689072847366333,\n",
       "  -0.16867589950561523,\n",
       "  -0.1684490442276001,\n",
       "  -0.16821777820587158,\n",
       "  -0.16798579692840576,\n",
       "  -0.1677544116973877,\n",
       "  -0.16752445697784424,\n",
       "  -0.1672888994216919,\n",
       "  -0.16705989837646484,\n",
       "  -0.1668304204940796,\n",
       "  -0.16659843921661377,\n",
       "  -0.16636550426483154,\n",
       "  -0.1661365032196045,\n",
       "  -0.1659085750579834,\n",
       "  -0.16567790508270264,\n",
       "  -0.16544568538665771,\n",
       "  -0.1652141809463501,\n",
       "  -0.1649855375289917,\n",
       "  -0.16475152969360352,\n",
       "  -0.16452455520629883,\n",
       "  -0.16429424285888672,\n",
       "  -0.16406166553497314,\n",
       "  -0.1638280153274536,\n",
       "  -0.16360187530517578,\n",
       "  -0.16336941719055176,\n",
       "  -0.16313636302947998,\n",
       "  -0.16290616989135742,\n",
       "  -0.1626741886138916,\n",
       "  -0.1624464988708496,\n",
       "  -0.16221749782562256,\n",
       "  -0.16198885440826416,\n",
       "  -0.16175401210784912,\n",
       "  -0.16152191162109375,\n",
       "  -0.16129028797149658,\n",
       "  -0.16106557846069336,\n",
       "  -0.16083872318267822,\n",
       "  -0.16060912609100342,\n",
       "  -0.16038215160369873,\n",
       "  -0.16015183925628662,\n",
       "  -0.15991997718811035,\n",
       "  -0.1596909761428833,\n",
       "  -0.15946316719055176,\n",
       "  -0.1592351198196411,\n",
       "  -0.1590055227279663,\n",
       "  -0.15877795219421387,\n",
       "  -0.15854644775390625,\n",
       "  -0.1583157777786255,\n",
       "  -0.15808749198913574,\n",
       "  -0.15786147117614746,\n",
       "  -0.15763211250305176,\n",
       "  -0.15740549564361572,\n",
       "  -0.15717506408691406,\n",
       "  -0.15694987773895264,\n",
       "  -0.15671813488006592,\n",
       "  -0.15648722648620605,\n",
       "  -0.15626204013824463,\n",
       "  -0.15603315830230713,\n",
       "  -0.1558055877685547,\n",
       "  -0.15557897090911865,\n",
       "  -0.15534913539886475,\n",
       "  -0.15511822700500488,\n",
       "  -0.1548914909362793,\n",
       "  -0.15466129779815674,\n",
       "  -0.15443265438079834,\n",
       "  -0.15420830249786377,\n",
       "  -0.15397965908050537,\n",
       "  -0.15375089645385742,\n",
       "  -0.15352463722229004,\n",
       "  -0.1532973051071167,\n",
       "  -0.15307140350341797,\n",
       "  -0.15284037590026855,\n",
       "  -0.1526099443435669,\n",
       "  -0.15238416194915771,\n",
       "  -0.15215718746185303,\n",
       "  -0.151930570602417,\n",
       "  -0.15170776844024658,\n",
       "  -0.15147936344146729,\n",
       "  -0.15124869346618652,\n",
       "  -0.15102481842041016,\n",
       "  -0.1507970094680786,\n",
       "  -0.1505720615386963,\n",
       "  -0.15034699440002441,\n",
       "  -0.1501154899597168,\n",
       "  -0.1498938798904419,\n",
       "  -0.14966702461242676,\n",
       "  -0.14944052696228027,\n",
       "  -0.14921021461486816,\n",
       "  -0.14898681640625,\n",
       "  -0.14876103401184082,\n",
       "  -0.1485387086868286,\n",
       "  -0.14831054210662842,\n",
       "  -0.14808642864227295,\n",
       "  -0.14786100387573242,\n",
       "  -0.14763402938842773,\n",
       "  -0.14740562438964844,\n",
       "  -0.14717888832092285,\n",
       "  -0.14695203304290771,\n",
       "  -0.14672386646270752,\n",
       "  -0.1465013027191162,\n",
       "  -0.14627385139465332,\n",
       "  -0.14604830741882324,\n",
       "  -0.14582538604736328,\n",
       "  -0.1456007957458496,\n",
       "  -0.1453723907470703,\n",
       "  -0.14514625072479248,\n",
       "  -0.14492392539978027,\n",
       "  -0.14469575881958008,\n",
       "  -0.1444711685180664,\n",
       "  -0.14424824714660645,\n",
       "  -0.14402365684509277,\n",
       "  -0.1437983512878418,\n",
       "  -0.14357340335845947,\n",
       "  -0.14334607124328613,\n",
       "  -0.1431213617324829,\n",
       "  -0.1428971290588379,\n",
       "  -0.14267492294311523,\n",
       "  -0.14245116710662842,\n",
       "  -0.14222395420074463,\n",
       "  -0.1419968605041504,\n",
       "  -0.14177346229553223,\n",
       "  -0.1415492296218872,\n",
       "  -0.14132654666900635,\n",
       "  -0.14110374450683594,\n",
       "  -0.14087820053100586,\n",
       "  -0.14064836502075195,\n",
       "  -0.14042150974273682,\n",
       "  -0.1401968002319336,\n",
       "  -0.13997364044189453,\n",
       "  -0.13975191116333008,\n",
       "  -0.13952815532684326,\n",
       "  -0.13930225372314453,\n",
       "  -0.13907885551452637,\n",
       "  -0.13884973526000977,\n",
       "  -0.13862895965576172,\n",
       "  -0.13840413093566895,\n",
       "  -0.13925707340240479,\n",
       "  -0.13795053958892822,\n",
       "  -0.13773202896118164,\n",
       "  -0.1375112533569336,\n",
       "  -0.13728058338165283,\n",
       "  -0.13705682754516602,\n",
       "  -0.13683223724365234,\n",
       "  -0.13661062717437744,\n",
       "  -0.13638699054718018,\n",
       "  -0.13616681098937988,\n",
       "  -0.13594233989715576,\n",
       "  -0.13572049140930176,\n",
       "  -0.13549792766571045,\n",
       "  -0.1352766752243042,\n",
       "  -0.13505339622497559,\n",
       "  -0.13482928276062012,\n",
       "  -0.13460826873779297,\n",
       "  -0.13438546657562256,\n",
       "  -0.13416147232055664,\n",
       "  -0.13393914699554443,\n",
       "  -0.1337134838104248,\n",
       "  -0.13349080085754395,\n",
       "  -0.13327014446258545,\n",
       "  -0.13304543495178223,\n",
       "  -0.1328212022781372,\n",
       "  -0.13259649276733398,\n",
       "  -0.13237237930297852,\n",
       "  -0.13215136528015137,\n",
       "  -0.1319255828857422,\n",
       "  -0.13170230388641357,\n",
       "  -0.1314786672592163,\n",
       "  -0.13125646114349365,\n",
       "  -0.1310354471206665,\n",
       "  -0.13081693649291992,\n",
       "  -0.130590558052063,\n",
       "  -0.13036608695983887,\n",
       "  -0.13014280796051025,\n",
       "  -0.12992286682128906,\n",
       "  -0.12970590591430664,\n",
       "  -0.12947559356689453,\n",
       "  -0.12925755977630615,\n",
       "  -0.1290372610092163,\n",
       "  -0.12881290912628174,\n",
       "  -0.12859070301055908,\n",
       "  -0.1283702850341797,\n",
       "  -0.12814927101135254,\n",
       "  -0.1279313564300537,\n",
       "  -0.12770771980285645,\n",
       "  -0.1274867057800293,\n",
       "  -0.12726032733917236,\n",
       "  -0.1270430088043213,\n",
       "  -0.12682127952575684,\n",
       "  -0.12659978866577148,\n",
       "  -0.1263793706893921,\n",
       "  -0.12615478038787842,\n",
       "  -0.1259326934814453,\n",
       "  -0.1257169246673584,\n",
       "  -0.1254894733428955,\n",
       "  -0.12527120113372803,\n",
       "  -0.12504899501800537,\n",
       "  -0.12483084201812744,\n",
       "  -0.12460982799530029,\n",
       "  -0.12439560890197754,\n",
       "  -0.12416863441467285,\n",
       "  -0.12394905090332031,\n",
       "  -0.12372684478759766,\n",
       "  -0.12350380420684814,\n",
       "  -0.1232837438583374,\n",
       "  -0.12306427955627441,\n",
       "  -0.12284409999847412,\n",
       "  -0.12262356281280518,\n",
       "  -0.12240242958068848,\n",
       "  -0.12218403816223145,\n",
       "  -0.12196159362792969,\n",
       "  -0.12174129486083984,\n",
       "  -0.12152409553527832,\n",
       "  -0.12130403518676758,\n",
       "  -0.12108361721038818,\n",
       "  -0.12086892127990723,\n",
       "  -0.12065005302429199,\n",
       "  -0.12042891979217529,\n",
       "  -0.12021017074584961,\n",
       "  -0.11999022960662842,\n",
       "  -0.11976933479309082,\n",
       "  -0.11954927444458008,\n",
       "  -0.11933040618896484,\n",
       "  -0.11911261081695557,\n",
       "  -0.11889231204986572,\n",
       "  -0.11867320537567139,\n",
       "  -0.11845183372497559,\n",
       "  -0.11823022365570068,\n",
       "  -0.11801040172576904,\n",
       "  -0.11779415607452393,\n",
       "  -0.11757254600524902,\n",
       "  -0.1173548698425293,\n",
       "  -0.1171337366104126,\n",
       "  -0.11691498756408691,\n",
       "  -0.11669528484344482,\n",
       "  -0.11647701263427734,\n",
       "  -0.11625790596008301,\n",
       "  -0.11604130268096924,\n",
       "  -0.1158210039138794,\n",
       "  -0.1156001091003418,\n",
       "  -0.11538910865783691,\n",
       "  -0.1151653528213501,\n",
       "  -0.11494910717010498,\n",
       "  -0.11473143100738525,\n",
       "  -0.11451756954193115,\n",
       "  -0.11429357528686523,\n",
       "  -0.11407625675201416,\n",
       "  -0.11386120319366455,\n",
       "  -0.11364197731018066,\n",
       "  -0.11342394351959229,\n",
       "  -0.11320745944976807,\n",
       "  -0.11298918724060059,\n",
       "  -0.1127697229385376,\n",
       "  -0.11255133152008057,\n",
       "  -0.11233341693878174,\n",
       "  -0.11211574077606201,\n",
       "  -0.11189854145050049,\n",
       "  -0.11168098449707031,\n",
       "  -0.1114654541015625,\n",
       "  -0.11124575138092041,\n",
       "  -0.11102962493896484,\n",
       "  -0.11081242561340332,\n",
       "  -0.11059677600860596,\n",
       "  -0.11037874221801758,\n",
       "  -0.11016058921813965,\n",
       "  -0.10994231700897217,\n",
       "  -0.10972774028778076,\n",
       "  -0.10951316356658936,\n",
       "  -0.10929524898529053,\n",
       "  -0.10907542705535889,\n",
       "  -0.10886073112487793,\n",
       "  -0.1086435317993164,\n",
       "  -0.10842621326446533,\n",
       "  -0.10820996761322021,\n",
       "  -0.10798978805541992,\n",
       "  -0.10777080059051514,\n",
       "  -0.10756170749664307,\n",
       "  -0.1073371171951294,\n",
       "  -0.10712230205535889,\n",
       "  -0.10692942142486572,\n",
       "  -0.10668838024139404,\n",
       "  -0.10647344589233398,\n",
       "  -0.10625481605529785,\n",
       "  -0.10604047775268555,\n",
       "  -0.10582363605499268,\n",
       "  -0.10560381412506104,\n",
       "  -0.10538876056671143,\n",
       "  -0.10516881942749023,\n",
       "  -0.10495734214782715,\n",
       "  -0.1047365665435791,\n",
       "  -0.10452115535736084,\n",
       "  -0.10430383682250977,\n",
       "  -0.10409009456634521,\n",
       "  -0.10386908054351807,\n",
       "  -0.1036534309387207,\n",
       "  -0.1034398078918457,\n",
       "  -0.10322487354278564,\n",
       "  -0.10300683975219727,\n",
       "  -0.10279130935668945,\n",
       "  -0.10257697105407715,\n",
       "  -0.10235965251922607,\n",
       "  -0.10214364528656006,\n",
       "  -0.1019282341003418,\n",
       "  -0.10171473026275635,\n",
       "  -0.10149633884429932,\n",
       "  -0.10127997398376465,\n",
       "  -0.10106074810028076,\n",
       "  -0.10084915161132812,\n",
       "  -0.10062682628631592,\n",
       "  -0.10041069984436035,\n",
       "  -0.100197434425354,\n",
       "  -0.09998023509979248,\n",
       "  -0.09976494312286377,\n",
       "  -0.09954512119293213,\n",
       "  -0.09933078289031982,\n",
       "  -0.09911942481994629,\n",
       "  -0.09890580177307129,\n",
       "  -0.09868693351745605,\n",
       "  -0.09847307205200195,\n",
       "  -0.09825491905212402,\n",
       "  -0.0980379581451416,\n",
       "  -0.09782803058624268,\n",
       "  -0.09760916233062744,\n",
       "  -0.0973961353302002,\n",
       "  -0.09717953205108643,\n",
       "  -0.09696400165557861,\n",
       "  -0.09675395488739014,\n",
       "  -0.09653747081756592,\n",
       "  -0.09632587432861328,\n",
       "  -0.09611272811889648,\n",
       "  -0.09589266777038574,\n",
       "  -0.095680832862854,\n",
       "  -0.09547114372253418,\n",
       "  -0.09525227546691895,\n",
       "  -0.09503769874572754,\n",
       "  -0.09482407569885254,\n",
       "  -0.09460973739624023,\n",
       "  -0.09439408779144287,\n",
       "  -0.09418010711669922,\n",
       "  -0.09396648406982422,\n",
       "  -0.09375488758087158,\n",
       "  -0.09353876113891602,\n",
       "  -0.09332942962646484,\n",
       "  -0.09311389923095703,\n",
       "  -0.09289658069610596,\n",
       "  -0.09268426895141602,\n",
       "  -0.09247136116027832,\n",
       "  -0.09226024150848389,\n",
       "  -0.09204137325286865,\n",
       "  -0.09183073043823242,\n",
       "  -0.09161293506622314,\n",
       "  -0.0913994312286377,\n",
       "  -0.09118711948394775,\n",
       "  -0.09097170829772949,\n",
       "  -0.09075987339019775,\n",
       "  -0.09055089950561523,\n",
       "  -0.09033536911010742,\n",
       "  -0.09012007713317871,\n",
       "  -0.08990919589996338,\n",
       "  -0.08969521522521973,\n",
       "  -0.0894775390625,\n",
       "  -0.08926403522491455,\n",
       "  -0.08905601501464844,\n",
       "  -0.08883750438690186,\n",
       "  -0.0886235237121582,\n",
       "  -0.08841097354888916,\n",
       "  -0.08819854259490967,\n",
       "  -0.08798778057098389,\n",
       "  -0.08777272701263428,\n",
       "  -0.08756136894226074,\n",
       "  -0.08734691143035889,\n",
       "  -0.08713924884796143,\n",
       "  -0.08692896366119385,\n",
       "  -0.08671224117279053,\n",
       "  -0.08650362491607666,\n",
       "  -0.08628785610198975,\n",
       "  -0.08607637882232666,\n",
       "  -0.08587014675140381,\n",
       "  -0.08565282821655273,\n",
       "  -0.0854339599609375,\n",
       "  -0.0852210521697998,\n",
       "  -0.08500730991363525,\n",
       "  -0.08479487895965576,\n",
       "  -0.08458483219146729,\n",
       "  -0.0843660831451416,\n",
       "  -0.08415842056274414,\n",
       "  -0.08394718170166016,\n",
       "  -0.08373475074768066,\n",
       "  -0.08352887630462646,\n",
       "  -0.08331298828125,\n",
       "  -0.08310067653656006,\n",
       "  -0.08289170265197754,\n",
       "  -0.08267927169799805,\n",
       "  -0.08246922492980957,\n",
       "  -0.08225524425506592,\n",
       "  -0.08204662799835205,\n",
       "  -0.08183670043945312,\n",
       "  -0.0816267728805542,\n",
       "  -0.08141028881072998,\n",
       "  -0.08120107650756836,\n",
       "  -0.08098983764648438,\n",
       "  -0.08078646659851074,\n",
       "  -0.08057689666748047,\n",
       "  -0.08035719394683838,\n",
       "  -0.08014452457427979,\n",
       "  -0.0799335241317749,\n",
       "  -0.08152234554290771,\n",
       "  -0.07951414585113525,\n",
       "  -0.07930946350097656,\n",
       "  -0.07909393310546875,\n",
       "  -0.0788799524307251,\n",
       "  -0.07867372035980225,\n",
       "  -0.07846009731292725,\n",
       "  -0.08204972743988037,\n",
       "  -0.08183801174163818,\n",
       "  -0.08163082599639893,\n",
       "  -0.08141398429870605,\n",
       "  -0.08120393753051758,\n",
       "  -0.0809926986694336,\n",
       "  -0.08078813552856445,\n",
       "  -0.08057200908660889,\n",
       "  -0.0803598165512085,\n",
       "  -0.08014905452728271,\n",
       "  -0.07993721961975098,\n",
       "  -0.07973003387451172,\n",
       "  -0.07951319217681885,\n",
       "  -0.07930612564086914,\n",
       "  -0.07909190654754639,\n",
       "  -0.07888293266296387,\n",
       "  -0.07867145538330078,\n",
       "  -0.07845687866210938,\n",
       "  -0.07825362682342529,\n",
       "  -0.07803535461425781,\n",
       "  -0.0778193473815918,\n",
       "  -0.07760858535766602,\n",
       "  -0.07739818096160889,\n",
       "  -0.07718765735626221,\n",
       "  -0.07697618007659912,\n",
       "  -0.07677078247070312,\n",
       "  -0.0765538215637207,\n",
       "  -0.07634270191192627,\n",
       "  -0.07613742351531982,\n",
       "  -0.07592320442199707,\n",
       "  -0.0757150650024414,\n",
       "  -0.07550263404846191,\n",
       "  -0.07529520988464355,\n",
       "  -0.07508730888366699,\n",
       "  -0.07487475872039795,\n",
       "  -0.07466280460357666,\n",
       "  -0.0744560956954956,\n",
       "  -0.07425570487976074,\n",
       "  -0.07403504848480225,\n",
       "  -0.07382619380950928,\n",
       "  -0.07361817359924316,\n",
       "  -0.07340526580810547,\n",
       "  -0.07319760322570801,\n",
       "  -0.07299411296844482,\n",
       "  -0.07278084754943848,\n",
       "  -0.07257330417633057,\n",
       "  -0.07236063480377197,\n",
       "  -0.07215774059295654,\n",
       "  -0.07194483280181885,\n",
       "  -0.07173621654510498,\n",
       "  -0.07152950763702393,\n",
       "  -0.07131683826446533,\n",
       "  -0.07110333442687988,\n",
       "  -0.07090044021606445,\n",
       "  -0.07069146633148193,\n",
       "  -0.07048428058624268,\n",
       "  -0.07027900218963623,\n",
       "  -0.07006633281707764,\n",
       "  -0.06985795497894287,\n",
       "  -0.06965756416320801,\n",
       "  -0.0694425106048584,\n",
       "  -0.06938636302947998,\n",
       "  -0.07320475578308105,\n",
       "  -0.07299613952636719,\n",
       "  -0.07278680801391602,\n",
       "  -0.07257342338562012,\n",
       "  -0.072365403175354,\n",
       "  -0.0721585750579834,\n",
       "  -0.07194983959197998,\n",
       "  -0.0717393159866333,\n",
       "  -0.07152688503265381,\n",
       "  -0.0713198184967041,\n",
       "  -0.07111537456512451,\n",
       "  -0.07089769840240479,\n",
       "  -0.0706942081451416,\n",
       "  -0.07048118114471436,\n",
       "  -0.07027244567871094,\n",
       "  -0.07005953788757324,\n",
       "  -0.06985509395599365,\n",
       "  -0.06964421272277832,\n",
       "  -0.06943833827972412,\n",
       "  -0.06922435760498047,\n",
       "  -0.06901681423187256,\n",
       "  -0.06882035732269287,\n",
       "  -0.06859886646270752,\n",
       "  -0.06839478015899658,\n",
       "  -0.06817889213562012,\n",
       "  -0.06796824932098389,\n",
       "  -0.06775820255279541,\n",
       "  -0.0675511360168457,\n",
       "  -0.06734013557434082,\n",
       "  -0.06713175773620605,\n",
       "  -0.06692743301391602,\n",
       "  -0.06672263145446777,\n",
       "  -0.0665132999420166,\n",
       "  -0.06630146503448486,\n",
       "  -0.06609892845153809,\n",
       "  -0.06588459014892578,\n",
       "  -0.06567895412445068,\n",
       "  -0.06547045707702637,\n",
       "  -0.0652623176574707,\n",
       "  -0.06505203247070312,\n",
       "  -0.06484413146972656,\n",
       "  -0.06463944911956787,\n",
       "  -0.06443166732788086,\n",
       "  -0.06422483921051025,\n",
       "  -0.06401586532592773,\n",
       "  -0.06380617618560791,\n",
       "  -0.06359827518463135,\n",
       "  -0.06339073181152344,\n",
       "  -0.06318628787994385,\n",
       "  -0.06297838687896729,\n",
       "  -0.06277287006378174,\n",
       "  -0.06703853607177734,\n",
       "  -0.06683123111724854,\n",
       "  -0.06662511825561523,\n",
       "  -0.06641030311584473,\n",
       "  -0.06620478630065918,\n",
       "  -0.06600630283355713,\n",
       "  -0.06578755378723145,\n",
       "  -0.06557631492614746,\n",
       "  -0.0653696060180664,\n",
       "  -0.06516540050506592,\n",
       "  -0.06495058536529541,\n",
       "  -0.06474554538726807,\n",
       "  -0.06453585624694824,\n",
       "  -0.06432974338531494,\n",
       "  -0.0641258955001831,\n",
       "  -0.06391692161560059,\n",
       "  -0.06370747089385986,\n",
       "  -0.0634995698928833,\n",
       "  -0.06329381465911865,\n",
       "  -0.06308901309967041,\n",
       "  -0.06287813186645508,\n",
       "  -0.06266391277313232,\n",
       "  -0.06246292591094971,\n",
       "  -0.06225788593292236,\n",
       "  -0.062045931816101074,\n",
       "  -0.061835646629333496,\n",
       "  -0.06163287162780762,\n",
       "  -0.061423659324645996,\n",
       "  -0.06121551990509033,\n",
       "  -0.06101858615875244,\n",
       "  -0.06080269813537598,\n",
       "  -0.060593366622924805,\n",
       "  -0.0603863000869751,\n",
       "  -0.06017899513244629,\n",
       "  -0.05997300148010254,\n",
       "  -0.059763431549072266,\n",
       "  -0.05955767631530762,\n",
       "  -0.061742186546325684,\n",
       "  -0.05914425849914551,\n",
       "  -0.05894148349761963,\n",
       "  -0.05872750282287598,\n",
       "  -0.05851399898529053,\n",
       "  -0.05831551551818848,\n",
       "  -0.05810666084289551,\n",
       "  -0.05789792537689209,\n",
       "  -0.0576937198638916,\n",
       "  -0.057482004165649414,\n",
       "  -0.057274580001831055,\n",
       "  -0.05707263946533203,\n",
       "  -0.05685997009277344,\n",
       "  -0.0566556453704834,\n",
       "  -0.056449174880981445,\n",
       "  -0.05624687671661377,\n",
       "  -0.056037068367004395,\n",
       "  -0.05583000183105469,\n",
       "  -0.05562877655029297,\n",
       "  -0.05542182922363281,\n",
       "  -0.055220842361450195,\n",
       "  -0.05500686168670654,\n",
       "  -0.05480539798736572,\n",
       "  -0.05459487438201904,\n",
       "  -0.05439114570617676,\n",
       "  -0.0541839599609375,\n",
       "  -0.05397987365722656,\n",
       "  -0.053774118423461914,\n",
       "  -0.05357539653778076,\n",
       "  -0.0533674955368042,\n",
       "  -0.053162455558776855,\n",
       "  -0.05295610427856445,\n",
       "  -0.052748680114746094,\n",
       "  -0.052539706230163574,\n",
       "  -0.05233967304229736,\n",
       "  -0.05213463306427002,\n",
       "  -0.05192923545837402,\n",
       "  -0.05172586441040039,\n",
       "  -0.05151724815368652,\n",
       "  -0.05131542682647705,\n",
       "  -0.05110609531402588,\n",
       "  -0.0509028434753418,\n",
       "  -0.05070233345031738,\n",
       "  -0.05049479007720947,\n",
       "  -0.0502854585647583,\n",
       "  -0.05008590221405029,\n",
       "  -0.049878597259521484,\n",
       "  -0.04967021942138672,\n",
       "  -0.04946780204772949,\n",
       "  -0.04925739765167236,\n",
       "  -0.04905867576599121,\n",
       "  -0.04885411262512207,\n",
       "  -0.048651695251464844,\n",
       "  -0.04844844341278076,\n",
       "  -0.04823923110961914,\n",
       "  -0.048037052154541016,\n",
       "  -0.047838568687438965,\n",
       "  -0.047634005546569824,\n",
       "  -0.04742145538330078,\n",
       "  -0.04721951484680176,\n",
       "  -0.047013282775878906,\n",
       "  -0.046810030937194824,\n",
       "  -0.0466080904006958,\n",
       "  -0.046398043632507324,\n",
       "  -0.04620075225830078,\n",
       "  -0.04599595069885254,\n",
       "  -0.04579746723175049,\n",
       "  -0.045590758323669434,\n",
       "  -0.04538404941558838,\n",
       "  -0.04518020153045654,\n",
       "  -0.04497957229614258,\n",
       "  -0.04477059841156006,\n",
       "  -0.04456758499145508,\n",
       "  -0.04692041873931885,\n",
       "  -0.046715378761291504,\n",
       "  -0.04651975631713867,\n",
       "  -0.04631388187408447,\n",
       "  -0.04613912105560303,\n",
       "  -0.04591214656829834,\n",
       "  -0.045708656311035156,\n",
       "  -0.04551124572753906,\n",
       "  -0.04530298709869385,\n",
       "  -0.04510343074798584,\n",
       "  -0.04490172863006592,\n",
       "  -0.04469895362854004,\n",
       "  -0.044496893882751465,\n",
       "  -0.04430198669433594,\n",
       "  -0.04409492015838623,\n",
       "  -0.043897151947021484,\n",
       "  -0.04369652271270752,\n",
       "  -0.04351174831390381,\n",
       "  -0.04329633712768555,\n",
       "  -0.04309678077697754,\n",
       "  -0.0428926944732666,\n",
       "  -0.04269230365753174,\n",
       "  -0.04249382019042969,\n",
       "  -0.04229378700256348,\n",
       "  -0.04209280014038086,\n",
       "  -0.04189348220825195,\n",
       "  -0.0416945219039917,\n",
       "  -0.04149198532104492,\n",
       "  -0.041295766830444336,\n",
       "  -0.04109227657318115,\n",
       "  -0.04089200496673584,\n",
       "  -0.04070091247558594,\n",
       "  -0.04049050807952881,\n",
       "  -0.04029059410095215,\n",
       "  -0.04009568691253662,\n",
       "  -0.03991079330444336,\n",
       "  -0.039690256118774414,\n",
       "  -0.03948807716369629,\n",
       "  -0.0392841100692749,\n",
       "  -0.03911280632019043,\n",
       "  -0.03889453411102295,\n",
       "  -0.03869223594665527,\n",
       "  -0.03850066661834717,\n",
       "  -0.03829085826873779,\n",
       "  -0.038089632987976074,\n",
       "  -0.03790390491485596,\n",
       "  -0.03768754005432129,\n",
       "  -0.03748965263366699,\n",
       "  -0.03730201721191406,\n",
       "  -0.03709113597869873,\n",
       "  -0.03689301013946533,\n",
       "  -0.036690354347229004,\n",
       "  -0.03649306297302246,\n",
       "  -0.03629457950592041,\n",
       "  -0.036096930503845215,\n",
       "  -0.03589272499084473,\n",
       "  -0.03569459915161133,\n",
       "  -0.03549063205718994,\n",
       "  -0.03529226779937744,\n",
       "  -0.03509259223937988,\n",
       "  -0.03491330146789551,\n",
       "  -0.03469586372375488,\n",
       "  -0.03449726104736328,\n",
       "  -0.03429698944091797,\n",
       "  -0.034101009368896484,\n",
       "  -0.03391385078430176,\n",
       "  -0.03370392322540283,\n",
       "  -0.03350543975830078,\n",
       "  -0.03330099582672119,\n",
       "  -0.03311753273010254,\n",
       "  -0.03290665149688721,\n",
       "  -0.032709598541259766,\n",
       "  -0.03251290321350098,\n",
       "  -0.03231704235076904,\n",
       "  -0.03211855888366699,\n",
       "  -0.031920552253723145,\n",
       "  -0.031722068786621094,\n",
       "  -0.03152632713317871,\n",
       "  -0.03139698505401611,\n",
       "  -0.03113555908203125,\n",
       "  -0.030936717987060547,\n",
       "  -0.030735373497009277,\n",
       "  -0.0305328369140625,\n",
       "  -0.030330300331115723,\n",
       "  -0.030142664909362793,\n",
       "  -0.02993953227996826,\n",
       "  -0.029745101928710938,\n",
       "  -0.02954566478729248,\n",
       "  -0.029351234436035156,\n",
       "  -0.029160737991333008,\n",
       "  -0.02895534038543701,\n",
       "  -0.028752565383911133,\n",
       "  -0.028555750846862793,\n",
       "  -0.028357744216918945,\n",
       "  -0.028162837028503418,\n",
       "  -0.02796471118927002,\n",
       "  -0.027771592140197754,\n",
       "  -0.027575135231018066,\n",
       "  -0.02737581729888916,\n",
       "  -0.027174711227416992,\n",
       "  -0.02697932720184326,\n",
       "  -0.026790142059326172,\n",
       "  -0.02659142017364502,\n",
       "  -0.026384711265563965,\n",
       "  -0.026186585426330566,\n",
       "  -0.025990962982177734,\n",
       "  -0.02579331398010254,\n",
       "  -0.025601506233215332,\n",
       "  -0.025407075881958008,\n",
       "  -0.02520430088043213,\n",
       "  -0.025013446807861328,\n",
       "  -0.024810194969177246,\n",
       "  -0.024610400199890137,\n",
       "  -0.024415135383605957,\n",
       "  -0.02421581745147705,\n",
       "  -0.024022698402404785,\n",
       "  -0.023826241493225098,\n",
       "  -0.023633241653442383,\n",
       "  -0.02343606948852539,\n",
       "  -0.023251891136169434,\n",
       "  -0.023047327995300293,\n",
       "  -0.022853851318359375,\n",
       "  -0.02265346050262451,\n",
       "  -0.022458314895629883,\n",
       "  -0.02226126194000244,\n",
       "  -0.022068381309509277,\n",
       "  -0.02187526226043701,\n",
       "  -0.021676063537597656,\n",
       "  -0.021484732627868652,\n",
       "  -0.02128136157989502,\n",
       "  -0.021080613136291504,\n",
       "  -0.020887136459350586,\n",
       "  -0.02069222927093506,\n",
       "  -0.02049100399017334,\n",
       "  -0.0202944278717041,\n",
       "  -0.02009749412536621,\n",
       "  -0.019904494285583496,\n",
       "  -0.01972639560699463,\n",
       "  -0.01951003074645996,\n",
       "  -0.01931619644165039,\n",
       "  -0.019123435020446777,\n",
       "  -0.01893627643585205,\n",
       "  -0.018722057342529297,\n",
       "  -0.018528103828430176,\n",
       "  -0.018329739570617676,\n",
       "  -0.0181351900100708,\n",
       "  -0.01794135570526123,\n",
       "  -0.01774919033050537,\n",
       "  -0.017554759979248047,\n",
       "  -0.017360210418701172,\n",
       "  -0.01718425750732422,\n",
       "  -0.016965150833129883,\n",
       "  -0.0167696475982666,\n",
       "  -0.016571640968322754,\n",
       "  -0.016441941261291504,\n",
       "  -0.016183972358703613,\n",
       "  -0.015988707542419434,\n",
       "  -0.015795111656188965,\n",
       "  -0.015592813491821289,\n",
       "  -0.01539909839630127,\n",
       "  -0.015213251113891602,\n",
       "  -0.015013813972473145,\n",
       "  -0.014819741249084473,\n",
       "  -0.01461946964263916,\n",
       "  -0.014429926872253418,\n",
       "  -0.014229416847229004,\n",
       "  -0.014050483703613281,\n",
       "  -0.013836503028869629,\n",
       "  -0.013645648956298828,\n",
       "  -0.0134507417678833,\n",
       "  -0.013258934020996094,\n",
       "  -0.013072848320007324,\n",
       "  -0.012881875038146973,\n",
       "  -0.012680292129516602,\n",
       "  -0.012480974197387695,\n",
       "  -0.012303709983825684,\n",
       "  -0.012092828750610352,\n",
       "  -0.011896967887878418,\n",
       "  -0.011708974838256836,\n",
       "  -0.011508941650390625,\n",
       "  -0.01131594181060791,\n",
       "  -0.01112353801727295,\n",
       "  -0.010924816131591797,\n",
       "  -0.010792374610900879,\n",
       "  -0.010538816452026367,\n",
       "  -0.010339021682739258,\n",
       "  -0.010142683982849121,\n",
       "  -0.009948134422302246,\n",
       "  -0.009758830070495605,\n",
       "  -0.009558320045471191,\n",
       "  -0.009367704391479492,\n",
       "  -0.009169220924377441,\n",
       "  ...])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CryptoGRU(input_size=4, embed_dim=4, hidden_size=64, num_layers=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "training_loss_history, validation_loss_history, mae_history, r2_history = train_model(\n",
    "    model, optimizer, train_loader, val_loader,\n",
    "    num_epochs=num_epochs, save_interval=save_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Training\n",
    "Training can be resumed by loading model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryptoGRU model loaded on cuda.\n",
      "Epoch [1/5000] | Time: 1.40s\n",
      "(Training) Loss: 928624.1872\n",
      "(Validation) Loss: 750071.8343, MAE: 3240.6821, R2: 0.2373\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2/5000] | Time: 0.17s\n",
      "(Training) Loss: 945392.7849\n",
      "(Validation) Loss: 749700.7111, MAE: 3221.0181, R2: 0.2377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3/5000] | Time: 0.20s\n",
      "(Training) Loss: 947367.0247\n",
      "(Validation) Loss: 749581.4337, MAE: 3218.6335, R2: 0.2378\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4/5000] | Time: 0.22s\n",
      "(Training) Loss: 935232.2081\n",
      "(Validation) Loss: 749464.8425, MAE: 3218.6963, R2: 0.2379\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [5/5000] | Time: 0.23s\n",
      "(Training) Loss: 931724.5051\n",
      "(Validation) Loss: 749353.1937, MAE: 3215.8870, R2: 0.2380\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [6/5000] | Time: 0.22s\n",
      "(Training) Loss: 940806.1022\n",
      "(Validation) Loss: 749253.9968, MAE: 3215.8274, R2: 0.2381\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [7/5000] | Time: 0.21s\n",
      "(Training) Loss: 934751.1675\n",
      "(Validation) Loss: 749145.7987, MAE: 3214.9036, R2: 0.2382\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [8/5000] | Time: 0.18s\n",
      "(Training) Loss: 924025.7357\n",
      "(Validation) Loss: 749039.1816, MAE: 3215.6902, R2: 0.2383\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [9/5000] | Time: 0.17s\n",
      "(Training) Loss: 940705.8579\n",
      "(Validation) Loss: 748939.4857, MAE: 3213.8899, R2: 0.2384\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [10/5000] | Time: 0.18s\n",
      "(Training) Loss: 930262.5609\n",
      "(Validation) Loss: 748838.7981, MAE: 3217.1035, R2: 0.2385\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [11/5000] | Time: 0.17s\n",
      "(Training) Loss: 921857.1689\n",
      "(Validation) Loss: 748734.4502, MAE: 3215.1636, R2: 0.2386\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [12/5000] | Time: 0.17s\n",
      "(Training) Loss: 930702.0717\n",
      "(Validation) Loss: 748628.3892, MAE: 3213.4304, R2: 0.2388\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [13/5000] | Time: 0.17s\n",
      "(Training) Loss: 930270.0806\n",
      "(Validation) Loss: 748565.6413, MAE: 3212.8435, R2: 0.2388\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [14/5000] | Time: 0.18s\n",
      "(Training) Loss: 943032.2227\n",
      "(Validation) Loss: 748415.2679, MAE: 3211.7644, R2: 0.2390\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [15/5000] | Time: 0.18s\n",
      "(Training) Loss: 940311.6212\n",
      "(Validation) Loss: 748307.0540, MAE: 3211.5635, R2: 0.2391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [16/5000] | Time: 0.23s\n",
      "(Training) Loss: 941448.7443\n",
      "(Validation) Loss: 748206.3924, MAE: 3211.8179, R2: 0.2392\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [17/5000] | Time: 0.18s\n",
      "(Training) Loss: 921597.3687\n",
      "(Validation) Loss: 748118.1238, MAE: 3217.2695, R2: 0.2393\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [18/5000] | Time: 0.22s\n",
      "(Training) Loss: 935523.2043\n",
      "(Validation) Loss: 747995.4984, MAE: 3210.4204, R2: 0.2394\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [19/5000] | Time: 0.22s\n",
      "(Training) Loss: 945892.2652\n",
      "(Validation) Loss: 747890.3213, MAE: 3211.1743, R2: 0.2395\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [20/5000] | Time: 0.23s\n",
      "(Training) Loss: 937120.0482\n",
      "(Validation) Loss: 747772.1187, MAE: 3212.4744, R2: 0.2396\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [21/5000] | Time: 0.20s\n",
      "(Training) Loss: 949595.9683\n",
      "(Validation) Loss: 747623.2203, MAE: 3204.2612, R2: 0.2398\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [22/5000] | Time: 0.20s\n",
      "(Training) Loss: 933780.6386\n",
      "(Validation) Loss: 734905.7505, MAE: 3171.4221, R2: 0.2526\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [23/5000] | Time: 0.20s\n",
      "(Training) Loss: 912911.6732\n",
      "(Validation) Loss: 734802.9092, MAE: 3166.5276, R2: 0.2527\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [24/5000] | Time: 0.22s\n",
      "(Training) Loss: 917390.2779\n",
      "(Validation) Loss: 734720.4984, MAE: 3170.7771, R2: 0.2528\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [25/5000] | Time: 0.22s\n",
      "(Training) Loss: 911923.4169\n",
      "(Validation) Loss: 734601.5829, MAE: 3166.8872, R2: 0.2529\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [26/5000] | Time: 0.24s\n",
      "(Training) Loss: 919699.7062\n",
      "(Validation) Loss: 734510.6432, MAE: 3169.1680, R2: 0.2530\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [27/5000] | Time: 0.25s\n",
      "(Training) Loss: 925496.4626\n",
      "(Validation) Loss: 734433.7448, MAE: 3174.0737, R2: 0.2531\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [28/5000] | Time: 0.24s\n",
      "(Training) Loss: 925447.2494\n",
      "(Validation) Loss: 732050.3651, MAE: 3162.3540, R2: 0.2555\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [29/5000] | Time: 0.23s\n",
      "(Training) Loss: 910546.4734\n",
      "(Validation) Loss: 731899.9302, MAE: 3155.1257, R2: 0.2556\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [30/5000] | Time: 0.24s\n",
      "(Training) Loss: 909954.8211\n",
      "(Validation) Loss: 731812.2768, MAE: 3160.3267, R2: 0.2557\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [31/5000] | Time: 0.26s\n",
      "(Training) Loss: 909849.9185\n",
      "(Validation) Loss: 754840.7594, MAE: 3225.9417, R2: 0.2325\n",
      "==========================================================================================\n",
      "Epoch [32/5000] | Time: 0.25s\n",
      "(Training) Loss: 944673.2430\n",
      "(Validation) Loss: 754735.7429, MAE: 3226.0823, R2: 0.2326\n",
      "==========================================================================================\n",
      "Epoch [33/5000] | Time: 0.22s\n",
      "(Training) Loss: 933720.4765\n",
      "(Validation) Loss: 754609.8070, MAE: 3222.0422, R2: 0.2327\n",
      "==========================================================================================\n",
      "Epoch [34/5000] | Time: 0.26s\n",
      "(Training) Loss: 950465.8426\n",
      "(Validation) Loss: 754501.3073, MAE: 3221.8604, R2: 0.2328\n",
      "==========================================================================================\n",
      "Epoch [35/5000] | Time: 0.22s\n",
      "(Training) Loss: 955979.3280\n",
      "(Validation) Loss: 754393.5359, MAE: 3223.0718, R2: 0.2329\n",
      "==========================================================================================\n",
      "Epoch [36/5000] | Time: 0.30s\n",
      "(Training) Loss: 958583.3325\n",
      "(Validation) Loss: 754276.1416, MAE: 3221.3689, R2: 0.2331\n",
      "==========================================================================================\n",
      "Epoch [37/5000] | Time: 0.22s\n",
      "(Training) Loss: 960151.6072\n",
      "(Validation) Loss: 754166.6317, MAE: 3220.4397, R2: 0.2332\n",
      "==========================================================================================\n",
      "Epoch [38/5000] | Time: 0.21s\n",
      "(Training) Loss: 943791.8369\n",
      "(Validation) Loss: 754054.4667, MAE: 3220.1128, R2: 0.2333\n",
      "==========================================================================================\n",
      "Epoch [39/5000] | Time: 0.22s\n",
      "(Training) Loss: 936301.6022\n",
      "(Validation) Loss: 753944.4489, MAE: 3219.1448, R2: 0.2334\n",
      "==========================================================================================\n",
      "Epoch [40/5000] | Time: 0.21s\n",
      "(Training) Loss: 946960.9994\n",
      "(Validation) Loss: 753843.2863, MAE: 3222.2505, R2: 0.2335\n",
      "==========================================================================================\n",
      "Epoch [41/5000] | Time: 0.29s\n",
      "(Training) Loss: 939468.8978\n",
      "(Validation) Loss: 753722.3283, MAE: 3218.4380, R2: 0.2336\n",
      "==========================================================================================\n",
      "Epoch [42/5000] | Time: 0.27s\n",
      "(Training) Loss: 955165.8344\n",
      "(Validation) Loss: 758544.5740, MAE: 3234.9797, R2: 0.2288\n",
      "==========================================================================================\n",
      "Epoch [43/5000] | Time: 0.23s\n",
      "(Training) Loss: 950440.8940\n",
      "(Validation) Loss: 758420.7911, MAE: 3234.0276, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [44/5000] | Time: 0.25s\n",
      "(Training) Loss: 938516.7132\n",
      "(Validation) Loss: 758309.6603, MAE: 3237.2070, R2: 0.2290\n",
      "==========================================================================================\n",
      "Epoch [45/5000] | Time: 0.24s\n",
      "(Training) Loss: 951568.3661\n",
      "(Validation) Loss: 758192.0533, MAE: 3234.9492, R2: 0.2291\n",
      "==========================================================================================\n",
      "Epoch [46/5000] | Time: 0.21s\n",
      "(Training) Loss: 957032.4575\n",
      "(Validation) Loss: 758069.7949, MAE: 3232.9417, R2: 0.2292\n",
      "==========================================================================================\n",
      "Epoch [47/5000] | Time: 0.23s\n",
      "(Training) Loss: 941405.0425\n",
      "(Validation) Loss: 757952.4025, MAE: 3233.1113, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [48/5000] | Time: 0.20s\n",
      "(Training) Loss: 959753.0362\n",
      "(Validation) Loss: 757838.4108, MAE: 3232.4937, R2: 0.2295\n",
      "==========================================================================================\n",
      "Epoch [49/5000] | Time: 0.20s\n",
      "(Training) Loss: 938913.2862\n",
      "(Validation) Loss: 757723.8946, MAE: 3232.3867, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [50/5000] | Time: 0.23s\n",
      "(Training) Loss: 948370.7595\n",
      "(Validation) Loss: 757619.0171, MAE: 3236.3945, R2: 0.2297\n",
      "==========================================================================================\n",
      "Epoch [51/5000] | Time: 0.23s\n",
      "(Training) Loss: 965540.3233\n",
      "(Validation) Loss: 763079.0444, MAE: 3256.5752, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [52/5000] | Time: 0.21s\n",
      "(Training) Loss: 949009.5615\n",
      "(Validation) Loss: 767156.4121, MAE: 3266.1033, R2: 0.2201\n",
      "==========================================================================================\n",
      "Epoch [53/5000] | Time: 0.21s\n",
      "(Training) Loss: 948755.7056\n",
      "(Validation) Loss: 766933.3689, MAE: 3264.5574, R2: 0.2203\n",
      "==========================================================================================\n",
      "Epoch [54/5000] | Time: 0.20s\n",
      "(Training) Loss: 974344.6022\n",
      "(Validation) Loss: 766907.4495, MAE: 3268.6812, R2: 0.2203\n",
      "==========================================================================================\n",
      "Epoch [55/5000] | Time: 0.21s\n",
      "(Training) Loss: 952700.3896\n",
      "(Validation) Loss: 766777.9816, MAE: 3271.2295, R2: 0.2205\n",
      "==========================================================================================\n",
      "Epoch [56/5000] | Time: 0.26s\n",
      "(Training) Loss: 957510.2855\n",
      "(Validation) Loss: 766641.1524, MAE: 3266.5786, R2: 0.2206\n",
      "==========================================================================================\n",
      "Epoch [57/5000] | Time: 0.26s\n",
      "(Training) Loss: 951124.4930\n",
      "(Validation) Loss: 766514.9473, MAE: 3265.9727, R2: 0.2207\n",
      "==========================================================================================\n",
      "Epoch [58/5000] | Time: 0.26s\n",
      "(Training) Loss: 972731.8902\n",
      "(Validation) Loss: 766391.1283, MAE: 3264.8562, R2: 0.2209\n",
      "==========================================================================================\n",
      "Epoch [59/5000] | Time: 0.24s\n",
      "(Training) Loss: 958084.0552\n",
      "(Validation) Loss: 766265.0248, MAE: 3263.8796, R2: 0.2210\n",
      "==========================================================================================\n",
      "Epoch [60/5000] | Time: 0.22s\n",
      "(Training) Loss: 950075.1275\n",
      "(Validation) Loss: 766178.0076, MAE: 3270.6355, R2: 0.2211\n",
      "==========================================================================================\n",
      "Epoch [61/5000] | Time: 0.22s\n",
      "(Training) Loss: 955242.3585\n",
      "(Validation) Loss: 766056.5676, MAE: 3268.9822, R2: 0.2212\n",
      "==========================================================================================\n",
      "Epoch [62/5000] | Time: 0.21s\n",
      "(Training) Loss: 941353.2078\n",
      "(Validation) Loss: 765922.2997, MAE: 3269.3542, R2: 0.2213\n",
      "==========================================================================================\n",
      "Epoch [63/5000] | Time: 0.22s\n",
      "(Training) Loss: 966884.5447\n",
      "(Validation) Loss: 765803.6914, MAE: 3269.7366, R2: 0.2214\n",
      "==========================================================================================\n",
      "Epoch [64/5000] | Time: 0.21s\n",
      "(Training) Loss: 968838.4924\n",
      "(Validation) Loss: 765671.4368, MAE: 3265.7417, R2: 0.2216\n",
      "==========================================================================================\n",
      "Epoch [65/5000] | Time: 0.21s\n",
      "(Training) Loss: 959519.3363\n",
      "(Validation) Loss: 765545.8940, MAE: 3264.6809, R2: 0.2217\n",
      "==========================================================================================\n",
      "Epoch [66/5000] | Time: 0.21s\n",
      "(Training) Loss: 948422.1440\n",
      "(Validation) Loss: 765449.2565, MAE: 3269.2266, R2: 0.2218\n",
      "==========================================================================================\n",
      "Epoch [67/5000] | Time: 0.26s\n",
      "(Training) Loss: 947928.3820\n",
      "(Validation) Loss: 765306.9397, MAE: 3264.6335, R2: 0.2219\n",
      "==========================================================================================\n",
      "Epoch [68/5000] | Time: 0.28s\n",
      "(Training) Loss: 956628.6066\n",
      "(Validation) Loss: 765182.5841, MAE: 3264.9648, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [69/5000] | Time: 0.26s\n",
      "(Training) Loss: 953839.2551\n",
      "(Validation) Loss: 765078.2660, MAE: 3269.1045, R2: 0.2222\n",
      "==========================================================================================\n",
      "Epoch [70/5000] | Time: 0.26s\n",
      "(Training) Loss: 954539.1821\n",
      "(Validation) Loss: 764948.1790, MAE: 3266.4568, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [71/5000] | Time: 0.26s\n",
      "(Training) Loss: 950247.6371\n",
      "(Validation) Loss: 764821.3479, MAE: 3263.1067, R2: 0.2224\n",
      "==========================================================================================\n",
      "Epoch [72/5000] | Time: 0.25s\n",
      "(Training) Loss: 943339.8902\n",
      "(Validation) Loss: 764721.6552, MAE: 3266.6858, R2: 0.2225\n",
      "==========================================================================================\n",
      "Epoch [73/5000] | Time: 0.27s\n",
      "(Training) Loss: 949620.8963\n",
      "(Validation) Loss: 764611.3511, MAE: 3266.1223, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [74/5000] | Time: 0.27s\n",
      "(Training) Loss: 947489.8712\n",
      "(Validation) Loss: 764464.7467, MAE: 3260.2979, R2: 0.2228\n",
      "==========================================================================================\n",
      "Epoch [75/5000] | Time: 0.28s\n",
      "(Training) Loss: 957397.3096\n",
      "(Validation) Loss: 764342.1505, MAE: 3259.9578, R2: 0.2229\n",
      "==========================================================================================\n",
      "Epoch [76/5000] | Time: 0.29s\n",
      "(Training) Loss: 946610.0419\n",
      "(Validation) Loss: 764227.5308, MAE: 3259.9844, R2: 0.2230\n",
      "==========================================================================================\n",
      "Epoch [77/5000] | Time: 0.27s\n",
      "(Training) Loss: 940884.0668\n",
      "(Validation) Loss: 764109.8190, MAE: 3258.5842, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [78/5000] | Time: 0.23s\n",
      "(Training) Loss: 940225.9864\n",
      "(Validation) Loss: 763991.8610, MAE: 3259.0115, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [79/5000] | Time: 0.23s\n",
      "(Training) Loss: 979499.1390\n",
      "(Validation) Loss: 763890.3708, MAE: 3261.6589, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [80/5000] | Time: 0.22s\n",
      "(Training) Loss: 951378.4581\n",
      "(Validation) Loss: 763758.5854, MAE: 3258.8887, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [81/5000] | Time: 0.21s\n",
      "(Training) Loss: 963259.4987\n",
      "(Validation) Loss: 763635.9003, MAE: 3257.4109, R2: 0.2236\n",
      "==========================================================================================\n",
      "Epoch [82/5000] | Time: 0.25s\n",
      "(Training) Loss: 960341.1453\n",
      "(Validation) Loss: 763520.9473, MAE: 3257.6182, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [83/5000] | Time: 0.28s\n",
      "(Training) Loss: 954912.7513\n",
      "(Validation) Loss: 763408.6057, MAE: 3259.5571, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [84/5000] | Time: 0.27s\n",
      "(Training) Loss: 944488.2925\n",
      "(Validation) Loss: 763256.2863, MAE: 3252.0876, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [85/5000] | Time: 0.27s\n",
      "(Training) Loss: 943610.3439\n",
      "(Validation) Loss: 763156.3048, MAE: 3256.3127, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [86/5000] | Time: 0.27s\n",
      "(Training) Loss: 951078.4987\n",
      "(Validation) Loss: 763028.1289, MAE: 3253.7112, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [87/5000] | Time: 0.26s\n",
      "(Training) Loss: 942876.7500\n",
      "(Validation) Loss: 762912.7435, MAE: 3253.3206, R2: 0.2244\n",
      "==========================================================================================\n",
      "Epoch [88/5000] | Time: 0.25s\n",
      "(Training) Loss: 946290.4878\n",
      "(Validation) Loss: 762808.9911, MAE: 3255.3772, R2: 0.2245\n",
      "==========================================================================================\n",
      "Epoch [89/5000] | Time: 0.29s\n",
      "(Training) Loss: 961437.3350\n",
      "(Validation) Loss: 762718.4870, MAE: 3258.4246, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [90/5000] | Time: 0.26s\n",
      "(Training) Loss: 959761.6358\n",
      "(Validation) Loss: 762590.4990, MAE: 3254.7615, R2: 0.2247\n",
      "==========================================================================================\n",
      "Epoch [91/5000] | Time: 0.21s\n",
      "(Training) Loss: 950579.5952\n",
      "(Validation) Loss: 762471.9860, MAE: 3254.3904, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [92/5000] | Time: 0.25s\n",
      "(Training) Loss: 977173.3166\n",
      "(Validation) Loss: 762356.2527, MAE: 3253.7444, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [93/5000] | Time: 0.24s\n",
      "(Training) Loss: 964084.4740\n",
      "(Validation) Loss: 762228.1917, MAE: 3252.1455, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [94/5000] | Time: 0.23s\n",
      "(Training) Loss: 938063.0182\n",
      "(Validation) Loss: 762122.0838, MAE: 3252.9849, R2: 0.2252\n",
      "==========================================================================================\n",
      "Epoch [95/5000] | Time: 0.27s\n",
      "(Training) Loss: 947127.3287\n",
      "(Validation) Loss: 761996.4273, MAE: 3250.5891, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [96/5000] | Time: 0.21s\n",
      "(Training) Loss: 941134.8128\n",
      "(Validation) Loss: 761895.3575, MAE: 3253.0676, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [97/5000] | Time: 0.20s\n",
      "(Training) Loss: 956477.4686\n",
      "(Validation) Loss: 761760.0102, MAE: 3249.3586, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [98/5000] | Time: 0.20s\n",
      "(Training) Loss: 941603.2221\n",
      "(Validation) Loss: 761645.2127, MAE: 3249.4158, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [99/5000] | Time: 0.20s\n",
      "(Training) Loss: 947749.0330\n",
      "(Validation) Loss: 761529.9117, MAE: 3249.2070, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [100/5000] | Time: 0.22s\n",
      "(Training) Loss: 945480.8725\n",
      "(Validation) Loss: 761411.4787, MAE: 3247.9739, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [101/5000] | Time: 0.24s\n",
      "(Training) Loss: 943280.5876\n",
      "(Validation) Loss: 761296.9359, MAE: 3248.5032, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [102/5000] | Time: 0.24s\n",
      "(Training) Loss: 938092.4962\n",
      "(Validation) Loss: 761189.0210, MAE: 3251.4546, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [103/5000] | Time: 0.25s\n",
      "(Training) Loss: 975158.4061\n",
      "(Validation) Loss: 761066.6470, MAE: 3247.7048, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [104/5000] | Time: 0.23s\n",
      "(Training) Loss: 952992.2766\n",
      "(Validation) Loss: 760951.0317, MAE: 3248.1289, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [105/5000] | Time: 0.22s\n",
      "(Training) Loss: 943885.9289\n",
      "(Validation) Loss: 760830.1917, MAE: 3246.6001, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [106/5000] | Time: 0.20s\n",
      "(Training) Loss: 956944.4803\n",
      "(Validation) Loss: 760806.1124, MAE: 3255.5388, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [107/5000] | Time: 0.23s\n",
      "(Training) Loss: 967444.8014\n",
      "(Validation) Loss: 760685.4546, MAE: 3254.3088, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [108/5000] | Time: 0.31s\n",
      "(Training) Loss: 957159.4118\n",
      "(Validation) Loss: 760566.9257, MAE: 3254.9766, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [109/5000] | Time: 0.27s\n",
      "(Training) Loss: 944200.2360\n",
      "(Validation) Loss: 760443.0813, MAE: 3252.6934, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [110/5000] | Time: 0.27s\n",
      "(Training) Loss: 954081.0539\n",
      "(Validation) Loss: 760328.8819, MAE: 3252.0864, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [111/5000] | Time: 0.30s\n",
      "(Training) Loss: 935507.2119\n",
      "(Validation) Loss: 760208.8203, MAE: 3251.4412, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [112/5000] | Time: 0.28s\n",
      "(Training) Loss: 945316.9784\n",
      "(Validation) Loss: 760097.8971, MAE: 3252.5569, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [113/5000] | Time: 0.29s\n",
      "(Training) Loss: 956132.7855\n",
      "(Validation) Loss: 759979.5816, MAE: 3250.9802, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [114/5000] | Time: 0.30s\n",
      "(Training) Loss: 959667.9201\n",
      "(Validation) Loss: 759876.8851, MAE: 3255.0774, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [115/5000] | Time: 0.32s\n",
      "(Training) Loss: 952812.2728\n",
      "(Validation) Loss: 759750.7251, MAE: 3250.8000, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [116/5000] | Time: 0.43s\n",
      "(Training) Loss: 944578.9797\n",
      "(Validation) Loss: 759632.1289, MAE: 3249.8301, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [117/5000] | Time: 0.33s\n",
      "(Training) Loss: 944287.9689\n",
      "(Validation) Loss: 759515.8063, MAE: 3248.9282, R2: 0.2278\n",
      "==========================================================================================\n",
      "Epoch [118/5000] | Time: 0.29s\n",
      "(Training) Loss: 943729.6161\n",
      "(Validation) Loss: 759398.8844, MAE: 3248.2361, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [119/5000] | Time: 0.31s\n",
      "(Training) Loss: 962834.1834\n",
      "(Validation) Loss: 759294.9276, MAE: 3252.9177, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [120/5000] | Time: 0.27s\n",
      "(Training) Loss: 956727.9689\n",
      "(Validation) Loss: 759170.7467, MAE: 3248.7593, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [121/5000] | Time: 0.26s\n",
      "(Training) Loss: 954451.5266\n",
      "(Validation) Loss: 759051.8984, MAE: 3248.3423, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [122/5000] | Time: 0.24s\n",
      "(Training) Loss: 939632.0381\n",
      "(Validation) Loss: 758936.7746, MAE: 3248.1296, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [123/5000] | Time: 0.24s\n",
      "(Training) Loss: 960966.4619\n",
      "(Validation) Loss: 758823.6857, MAE: 3247.6899, R2: 0.2285\n",
      "==========================================================================================\n",
      "Epoch [124/5000] | Time: 0.22s\n",
      "(Training) Loss: 953259.9397\n",
      "(Validation) Loss: 758707.7505, MAE: 3247.5747, R2: 0.2286\n",
      "==========================================================================================\n",
      "Epoch [125/5000] | Time: 0.22s\n",
      "(Training) Loss: 959542.4937\n",
      "(Validation) Loss: 758591.1397, MAE: 3246.5859, R2: 0.2287\n",
      "==========================================================================================\n",
      "Epoch [126/5000] | Time: 0.24s\n",
      "(Training) Loss: 944228.0178\n",
      "(Validation) Loss: 758475.3505, MAE: 3246.5676, R2: 0.2288\n",
      "==========================================================================================\n",
      "Epoch [127/5000] | Time: 0.25s\n",
      "(Training) Loss: 935229.6148\n",
      "(Validation) Loss: 758357.4038, MAE: 3245.5273, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [128/5000] | Time: 0.23s\n",
      "(Training) Loss: 943876.4600\n",
      "(Validation) Loss: 758243.6394, MAE: 3245.3477, R2: 0.2291\n",
      "==========================================================================================\n",
      "Epoch [129/5000] | Time: 0.23s\n",
      "(Training) Loss: 943927.0635\n",
      "(Validation) Loss: 758130.2806, MAE: 3244.8037, R2: 0.2292\n",
      "==========================================================================================\n",
      "Epoch [130/5000] | Time: 0.22s\n",
      "(Training) Loss: 940100.0222\n",
      "(Validation) Loss: 758013.4210, MAE: 3244.0645, R2: 0.2293\n",
      "==========================================================================================\n",
      "Epoch [131/5000] | Time: 0.22s\n",
      "(Training) Loss: 933979.6283\n",
      "(Validation) Loss: 757903.2089, MAE: 3245.0315, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [132/5000] | Time: 0.23s\n",
      "(Training) Loss: 944435.9676\n",
      "(Validation) Loss: 757784.5943, MAE: 3243.8508, R2: 0.2295\n",
      "==========================================================================================\n",
      "Epoch [133/5000] | Time: 0.24s\n",
      "(Training) Loss: 951625.6764\n",
      "(Validation) Loss: 757669.9981, MAE: 3243.1001, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [134/5000] | Time: 0.25s\n",
      "(Training) Loss: 947004.5362\n",
      "(Validation) Loss: 757554.1302, MAE: 3242.6626, R2: 0.2298\n",
      "==========================================================================================\n",
      "Epoch [135/5000] | Time: 0.25s\n",
      "(Training) Loss: 945472.4089\n",
      "(Validation) Loss: 757440.5829, MAE: 3242.8958, R2: 0.2299\n",
      "==========================================================================================\n",
      "Epoch [136/5000] | Time: 0.23s\n",
      "(Training) Loss: 938946.4651\n",
      "(Validation) Loss: 757324.5600, MAE: 3242.2336, R2: 0.2300\n",
      "==========================================================================================\n",
      "Epoch [137/5000] | Time: 0.24s\n",
      "(Training) Loss: 944281.5768\n",
      "(Validation) Loss: 757212.4235, MAE: 3242.4570, R2: 0.2301\n",
      "==========================================================================================\n",
      "Epoch [138/5000] | Time: 0.26s\n",
      "(Training) Loss: 933812.7072\n",
      "(Validation) Loss: 757095.6883, MAE: 3242.4431, R2: 0.2302\n",
      "==========================================================================================\n",
      "Epoch [139/5000] | Time: 0.25s\n",
      "(Training) Loss: 944586.1434\n",
      "(Validation) Loss: 756978.7156, MAE: 3240.3296, R2: 0.2303\n",
      "==========================================================================================\n",
      "Epoch [140/5000] | Time: 0.25s\n",
      "(Training) Loss: 944575.4340\n",
      "(Validation) Loss: 756862.8229, MAE: 3239.9907, R2: 0.2305\n",
      "==========================================================================================\n",
      "Epoch [141/5000] | Time: 0.26s\n",
      "(Training) Loss: 945814.8071\n",
      "(Validation) Loss: 756748.8921, MAE: 3239.4006, R2: 0.2306\n",
      "==========================================================================================\n",
      "Epoch [142/5000] | Time: 0.22s\n",
      "(Training) Loss: 934738.5920\n",
      "(Validation) Loss: 756634.9562, MAE: 3240.8804, R2: 0.2307\n",
      "==========================================================================================\n",
      "Epoch [143/5000] | Time: 0.26s\n",
      "(Training) Loss: 945780.1161\n",
      "(Validation) Loss: 756524.4229, MAE: 3240.1995, R2: 0.2308\n",
      "==========================================================================================\n",
      "Epoch [144/5000] | Time: 0.21s\n",
      "(Training) Loss: 966092.9664\n",
      "(Validation) Loss: 756407.5333, MAE: 3238.8010, R2: 0.2309\n",
      "==========================================================================================\n",
      "Epoch [145/5000] | Time: 0.20s\n",
      "(Training) Loss: 942218.9391\n",
      "(Validation) Loss: 756288.8083, MAE: 3238.5857, R2: 0.2310\n",
      "==========================================================================================\n",
      "Epoch [146/5000] | Time: 0.27s\n",
      "(Training) Loss: 936117.5933\n",
      "(Validation) Loss: 756175.8914, MAE: 3238.3665, R2: 0.2311\n",
      "==========================================================================================\n",
      "Epoch [147/5000] | Time: 0.28s\n",
      "(Training) Loss: 952048.3236\n",
      "(Validation) Loss: 756063.0298, MAE: 3238.2410, R2: 0.2313\n",
      "==========================================================================================\n",
      "Epoch [148/5000] | Time: 0.28s\n",
      "(Training) Loss: 943300.3991\n",
      "(Validation) Loss: 753811.9403, MAE: 3236.4634, R2: 0.2335\n",
      "==========================================================================================\n",
      "Epoch [149/5000] | Time: 0.26s\n",
      "(Training) Loss: 948329.7944\n",
      "(Validation) Loss: 753688.1010, MAE: 3232.8855, R2: 0.2337\n",
      "==========================================================================================\n",
      "Epoch [150/5000] | Time: 0.26s\n",
      "(Training) Loss: 960164.7690\n",
      "(Validation) Loss: 753579.4883, MAE: 3233.4951, R2: 0.2338\n",
      "==========================================================================================\n",
      "Epoch [151/5000] | Time: 0.25s\n",
      "(Training) Loss: 966273.3065\n",
      "(Validation) Loss: 782479.8730, MAE: 3380.7676, R2: 0.2047\n",
      "==========================================================================================\n",
      "Epoch [152/5000] | Time: 0.22s\n",
      "(Training) Loss: 973839.5393\n",
      "(Validation) Loss: 782268.2063, MAE: 3348.6721, R2: 0.2049\n",
      "==========================================================================================\n",
      "Epoch [153/5000] | Time: 0.21s\n",
      "(Training) Loss: 960515.4655\n",
      "(Validation) Loss: 782126.3987, MAE: 3343.4834, R2: 0.2050\n",
      "==========================================================================================\n",
      "Epoch [154/5000] | Time: 0.27s\n",
      "(Training) Loss: 971999.1688\n",
      "(Validation) Loss: 781995.5149, MAE: 3342.2537, R2: 0.2051\n",
      "==========================================================================================\n",
      "Epoch [155/5000] | Time: 0.29s\n",
      "(Training) Loss: 974469.9061\n",
      "(Validation) Loss: 777888.3073, MAE: 3331.5166, R2: 0.2093\n",
      "==========================================================================================\n",
      "Epoch [156/5000] | Time: 0.30s\n",
      "(Training) Loss: 967238.1707\n",
      "(Validation) Loss: 777752.0286, MAE: 3323.3215, R2: 0.2094\n",
      "==========================================================================================\n",
      "Epoch [157/5000] | Time: 0.32s\n",
      "(Training) Loss: 966104.4473\n",
      "(Validation) Loss: 777629.4565, MAE: 3323.5908, R2: 0.2095\n",
      "==========================================================================================\n",
      "Epoch [158/5000] | Time: 0.30s\n",
      "(Training) Loss: 974175.0977\n",
      "(Validation) Loss: 777501.3441, MAE: 3321.7632, R2: 0.2097\n",
      "==========================================================================================\n",
      "Epoch [159/5000] | Time: 0.27s\n",
      "(Training) Loss: 973286.1123\n",
      "(Validation) Loss: 777379.0629, MAE: 3320.7249, R2: 0.2098\n",
      "==========================================================================================\n",
      "Epoch [160/5000] | Time: 0.27s\n",
      "(Training) Loss: 974966.8369\n",
      "(Validation) Loss: 777255.2095, MAE: 3320.4409, R2: 0.2099\n",
      "==========================================================================================\n",
      "Epoch [161/5000] | Time: 0.29s\n",
      "(Training) Loss: 960002.3744\n",
      "(Validation) Loss: 777131.1295, MAE: 3320.1912, R2: 0.2100\n",
      "==========================================================================================\n",
      "Epoch [162/5000] | Time: 0.27s\n",
      "(Training) Loss: 992220.6846\n",
      "(Validation) Loss: 777009.0857, MAE: 3318.9163, R2: 0.2102\n",
      "==========================================================================================\n",
      "Epoch [163/5000] | Time: 0.27s\n",
      "(Training) Loss: 954343.4055\n",
      "(Validation) Loss: 776886.5810, MAE: 3319.3608, R2: 0.2103\n",
      "==========================================================================================\n",
      "Epoch [164/5000] | Time: 0.29s\n",
      "(Training) Loss: 957993.3791\n",
      "(Validation) Loss: 776765.4229, MAE: 3318.4121, R2: 0.2104\n",
      "==========================================================================================\n",
      "Epoch [165/5000] | Time: 0.30s\n",
      "(Training) Loss: 966210.4905\n",
      "(Validation) Loss: 776644.1321, MAE: 3317.0369, R2: 0.2105\n",
      "==========================================================================================\n",
      "Epoch [166/5000] | Time: 0.28s\n",
      "(Training) Loss: 973299.3309\n",
      "(Validation) Loss: 776521.7644, MAE: 3316.0320, R2: 0.2106\n",
      "==========================================================================================\n",
      "Epoch [167/5000] | Time: 0.24s\n",
      "(Training) Loss: 958932.1174\n",
      "(Validation) Loss: 776400.7683, MAE: 3316.6921, R2: 0.2108\n",
      "==========================================================================================\n",
      "Epoch [168/5000] | Time: 0.26s\n",
      "(Training) Loss: 966201.3223\n",
      "(Validation) Loss: 776279.2902, MAE: 3316.1978, R2: 0.2109\n",
      "==========================================================================================\n",
      "Epoch [169/5000] | Time: 0.29s\n",
      "(Training) Loss: 958887.4048\n",
      "(Validation) Loss: 776165.9702, MAE: 3317.8164, R2: 0.2110\n",
      "==========================================================================================\n",
      "Epoch [170/5000] | Time: 0.30s\n",
      "(Training) Loss: 967321.8122\n",
      "(Validation) Loss: 776035.8514, MAE: 3314.0959, R2: 0.2111\n",
      "==========================================================================================\n",
      "Epoch [171/5000] | Time: 0.32s\n",
      "(Training) Loss: 957711.6003\n",
      "(Validation) Loss: 775917.1365, MAE: 3314.5530, R2: 0.2113\n",
      "==========================================================================================\n",
      "Epoch [172/5000] | Time: 0.26s\n",
      "(Training) Loss: 966186.2694\n",
      "(Validation) Loss: 775797.2502, MAE: 3313.8806, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [173/5000] | Time: 0.28s\n",
      "(Training) Loss: 964012.9296\n",
      "(Validation) Loss: 775674.7232, MAE: 3312.0381, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [174/5000] | Time: 0.26s\n",
      "(Training) Loss: 974499.9302\n",
      "(Validation) Loss: 775555.2222, MAE: 3312.0056, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [175/5000] | Time: 0.28s\n",
      "(Training) Loss: 953446.2335\n",
      "(Validation) Loss: 775434.8470, MAE: 3311.6794, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [176/5000] | Time: 0.29s\n",
      "(Training) Loss: 953255.6099\n",
      "(Validation) Loss: 774770.8971, MAE: 3308.8760, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [177/5000] | Time: 0.31s\n",
      "(Training) Loss: 955005.7567\n",
      "(Validation) Loss: 774653.8006, MAE: 3307.6458, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [178/5000] | Time: 0.29s\n",
      "(Training) Loss: 953607.2484\n",
      "(Validation) Loss: 774538.7378, MAE: 3307.1470, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [179/5000] | Time: 0.28s\n",
      "(Training) Loss: 958247.7900\n",
      "(Validation) Loss: 761641.2794, MAE: 3264.0474, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [180/5000] | Time: 0.25s\n",
      "(Training) Loss: 949441.9359\n",
      "(Validation) Loss: 761471.0978, MAE: 3260.2239, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [181/5000] | Time: 0.28s\n",
      "(Training) Loss: 936170.8691\n",
      "(Validation) Loss: 761358.6857, MAE: 3259.2883, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [182/5000] | Time: 0.26s\n",
      "(Training) Loss: 960012.5898\n",
      "(Validation) Loss: 761251.4965, MAE: 3259.8005, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [183/5000] | Time: 0.29s\n",
      "(Training) Loss: 945226.5558\n",
      "(Validation) Loss: 761132.1994, MAE: 3257.9482, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [184/5000] | Time: 0.29s\n",
      "(Training) Loss: 950664.9822\n",
      "(Validation) Loss: 761019.0038, MAE: 3257.2847, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [185/5000] | Time: 0.27s\n",
      "(Training) Loss: 939871.1827\n",
      "(Validation) Loss: 760904.9517, MAE: 3257.0730, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [186/5000] | Time: 0.24s\n",
      "(Training) Loss: 940102.4429\n",
      "(Validation) Loss: 760795.7321, MAE: 3256.7515, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [187/5000] | Time: 0.26s\n",
      "(Training) Loss: 941867.1015\n",
      "(Validation) Loss: 760684.0368, MAE: 3257.1267, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [188/5000] | Time: 0.23s\n",
      "(Training) Loss: 944926.6396\n",
      "(Validation) Loss: 760570.5670, MAE: 3255.6177, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [189/5000] | Time: 0.27s\n",
      "(Training) Loss: 947486.3807\n",
      "(Validation) Loss: 760463.8711, MAE: 3257.2449, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [190/5000] | Time: 0.24s\n",
      "(Training) Loss: 935672.2018\n",
      "(Validation) Loss: 760348.3238, MAE: 3255.3542, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [191/5000] | Time: 0.24s\n",
      "(Training) Loss: 947620.7652\n",
      "(Validation) Loss: 760233.3435, MAE: 3254.2251, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [192/5000] | Time: 0.24s\n",
      "(Training) Loss: 936745.4128\n",
      "(Validation) Loss: 760122.7632, MAE: 3254.7502, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [193/5000] | Time: 0.29s\n",
      "(Training) Loss: 939234.1796\n",
      "(Validation) Loss: 760016.3663, MAE: 3255.2100, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [194/5000] | Time: 0.25s\n",
      "(Training) Loss: 948236.0799\n",
      "(Validation) Loss: 759901.0825, MAE: 3253.8623, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [195/5000] | Time: 0.24s\n",
      "(Training) Loss: 953749.5660\n",
      "(Validation) Loss: 759781.8032, MAE: 3252.8574, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [196/5000] | Time: 0.25s\n",
      "(Training) Loss: 944466.8991\n",
      "(Validation) Loss: 759671.4190, MAE: 3252.9395, R2: 0.2276\n",
      "==========================================================================================\n",
      "Epoch [197/5000] | Time: 0.23s\n",
      "(Training) Loss: 959007.6091\n",
      "(Validation) Loss: 759559.3778, MAE: 3252.2803, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [198/5000] | Time: 0.26s\n",
      "(Training) Loss: 954654.9657\n",
      "(Validation) Loss: 759444.8476, MAE: 3252.0325, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [199/5000] | Time: 0.24s\n",
      "(Training) Loss: 946204.4765\n",
      "(Validation) Loss: 759334.0927, MAE: 3252.4807, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [200/5000] | Time: 0.26s\n",
      "(Training) Loss: 950653.2697\n",
      "(Validation) Loss: 759218.3524, MAE: 3251.0105, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [201/5000] | Time: 0.25s\n",
      "(Training) Loss: 949366.4251\n",
      "(Validation) Loss: 759109.4356, MAE: 3251.9495, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [202/5000] | Time: 0.25s\n",
      "(Training) Loss: 963635.4404\n",
      "(Validation) Loss: 758989.9937, MAE: 3249.2075, R2: 0.2283\n",
      "==========================================================================================\n",
      "Epoch [203/5000] | Time: 0.23s\n",
      "(Training) Loss: 936488.5501\n",
      "(Validation) Loss: 758874.7930, MAE: 3248.6028, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [204/5000] | Time: 0.24s\n",
      "(Training) Loss: 944111.8832\n",
      "(Validation) Loss: 758765.8216, MAE: 3249.5510, R2: 0.2285\n",
      "==========================================================================================\n",
      "Epoch [205/5000] | Time: 0.26s\n",
      "(Training) Loss: 943611.6237\n",
      "(Validation) Loss: 758653.6146, MAE: 3249.5178, R2: 0.2286\n",
      "==========================================================================================\n",
      "Epoch [206/5000] | Time: 0.24s\n",
      "(Training) Loss: 943869.7944\n",
      "(Validation) Loss: 758549.8629, MAE: 3250.7195, R2: 0.2288\n",
      "==========================================================================================\n",
      "Epoch [207/5000] | Time: 0.26s\n",
      "(Training) Loss: 957319.3458\n",
      "(Validation) Loss: 758424.7638, MAE: 3247.3596, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [208/5000] | Time: 0.24s\n",
      "(Training) Loss: 946204.7836\n",
      "(Validation) Loss: 758314.3333, MAE: 3247.1841, R2: 0.2290\n",
      "==========================================================================================\n",
      "Epoch [209/5000] | Time: 0.25s\n",
      "(Training) Loss: 935447.1710\n",
      "(Validation) Loss: 758207.2070, MAE: 3250.8687, R2: 0.2291\n",
      "==========================================================================================\n",
      "Epoch [210/5000] | Time: 0.27s\n",
      "(Training) Loss: 937534.1415\n",
      "(Validation) Loss: 758094.7498, MAE: 3249.0837, R2: 0.2292\n",
      "==========================================================================================\n",
      "Epoch [211/5000] | Time: 0.29s\n",
      "(Training) Loss: 949969.1313\n",
      "(Validation) Loss: 757983.0400, MAE: 3249.1504, R2: 0.2293\n",
      "==========================================================================================\n",
      "Epoch [212/5000] | Time: 0.27s\n",
      "(Training) Loss: 934485.6948\n",
      "(Validation) Loss: 760841.1829, MAE: 3260.2854, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [213/5000] | Time: 0.26s\n",
      "(Training) Loss: 952552.0615\n",
      "(Validation) Loss: 760721.2406, MAE: 3256.5391, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [214/5000] | Time: 0.28s\n",
      "(Training) Loss: 938494.3341\n",
      "(Validation) Loss: 760604.9283, MAE: 3253.5913, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [215/5000] | Time: 0.27s\n",
      "(Training) Loss: 941819.9708\n",
      "(Validation) Loss: 760487.8546, MAE: 3251.4167, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [216/5000] | Time: 0.29s\n",
      "(Training) Loss: 947391.0968\n",
      "(Validation) Loss: 760382.3029, MAE: 3253.5791, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [217/5000] | Time: 0.29s\n",
      "(Training) Loss: 962600.5952\n",
      "(Validation) Loss: 760263.0483, MAE: 3251.9155, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [218/5000] | Time: 0.28s\n",
      "(Training) Loss: 952487.9968\n",
      "(Validation) Loss: 760150.8933, MAE: 3252.7566, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [219/5000] | Time: 0.27s\n",
      "(Training) Loss: 954952.4162\n",
      "(Validation) Loss: 760032.7835, MAE: 3249.8845, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [220/5000] | Time: 0.28s\n",
      "(Training) Loss: 937253.3411\n",
      "(Validation) Loss: 759922.1441, MAE: 3252.0457, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [221/5000] | Time: 0.29s\n",
      "(Training) Loss: 940255.2538\n",
      "(Validation) Loss: 759815.0425, MAE: 3253.0706, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [222/5000] | Time: 0.32s\n",
      "(Training) Loss: 938176.9673\n",
      "(Validation) Loss: 759695.0832, MAE: 3250.8115, R2: 0.2276\n",
      "==========================================================================================\n",
      "Epoch [223/5000] | Time: 0.30s\n",
      "(Training) Loss: 953058.2170\n",
      "(Validation) Loss: 774015.7448, MAE: 3296.8223, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [224/5000] | Time: 0.27s\n",
      "(Training) Loss: 953180.5143\n",
      "(Validation) Loss: 773898.3181, MAE: 3297.9331, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [225/5000] | Time: 0.24s\n",
      "(Training) Loss: 950317.5317\n",
      "(Validation) Loss: 773780.3137, MAE: 3295.5601, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [226/5000] | Time: 0.25s\n",
      "(Training) Loss: 955864.3978\n",
      "(Validation) Loss: 773668.3460, MAE: 3297.6904, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [227/5000] | Time: 0.26s\n",
      "(Training) Loss: 954445.7297\n",
      "(Validation) Loss: 773549.5289, MAE: 3296.5198, R2: 0.2136\n",
      "==========================================================================================\n",
      "Epoch [228/5000] | Time: 0.26s\n",
      "(Training) Loss: 955449.9784\n",
      "(Validation) Loss: 773430.6095, MAE: 3294.7932, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [229/5000] | Time: 0.29s\n",
      "(Training) Loss: 965573.7849\n",
      "(Validation) Loss: 773321.6178, MAE: 3297.5137, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [230/5000] | Time: 0.35s\n",
      "(Training) Loss: 954593.4740\n",
      "(Validation) Loss: 773201.0114, MAE: 3295.9749, R2: 0.2140\n",
      "==========================================================================================\n",
      "Epoch [231/5000] | Time: 0.35s\n",
      "(Training) Loss: 958989.1961\n",
      "(Validation) Loss: 773080.0857, MAE: 3294.9937, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [232/5000] | Time: 0.31s\n",
      "(Training) Loss: 992702.9048\n",
      "(Validation) Loss: 772960.4737, MAE: 3293.3110, R2: 0.2142\n",
      "==========================================================================================\n",
      "Epoch [233/5000] | Time: 0.30s\n",
      "(Training) Loss: 982467.3179\n",
      "(Validation) Loss: 772838.4044, MAE: 3292.8994, R2: 0.2144\n",
      "==========================================================================================\n",
      "Epoch [234/5000] | Time: 0.30s\n",
      "(Training) Loss: 973964.1694\n",
      "(Validation) Loss: 772720.3663, MAE: 3292.5151, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [235/5000] | Time: 0.29s\n",
      "(Training) Loss: 969944.2976\n",
      "(Validation) Loss: 772601.1289, MAE: 3290.7939, R2: 0.2146\n",
      "==========================================================================================\n",
      "Epoch [236/5000] | Time: 0.27s\n",
      "(Training) Loss: 966376.7576\n",
      "(Validation) Loss: 772486.2933, MAE: 3291.4944, R2: 0.2147\n",
      "==========================================================================================\n",
      "Epoch [237/5000] | Time: 0.28s\n",
      "(Training) Loss: 961757.4162\n",
      "(Validation) Loss: 772373.5790, MAE: 3291.8867, R2: 0.2148\n",
      "==========================================================================================\n",
      "Epoch [238/5000] | Time: 0.28s\n",
      "(Training) Loss: 962463.8610\n",
      "(Validation) Loss: 772256.0483, MAE: 3291.5415, R2: 0.2149\n",
      "==========================================================================================\n",
      "Epoch [239/5000] | Time: 0.27s\n",
      "(Training) Loss: 976835.8192\n",
      "(Validation) Loss: 772141.1905, MAE: 3292.0063, R2: 0.2151\n",
      "==========================================================================================\n",
      "Epoch [240/5000] | Time: 0.26s\n",
      "(Training) Loss: 953991.3928\n",
      "(Validation) Loss: 772018.5232, MAE: 3290.4019, R2: 0.2152\n",
      "==========================================================================================\n",
      "Epoch [241/5000] | Time: 0.25s\n",
      "(Training) Loss: 959048.5133\n",
      "(Validation) Loss: 771902.2133, MAE: 3289.4807, R2: 0.2153\n",
      "==========================================================================================\n",
      "Epoch [242/5000] | Time: 0.25s\n",
      "(Training) Loss: 969012.0482\n",
      "(Validation) Loss: 771794.8432, MAE: 3292.0020, R2: 0.2154\n",
      "==========================================================================================\n",
      "Epoch [243/5000] | Time: 0.26s\n",
      "(Training) Loss: 962461.7348\n",
      "(Validation) Loss: 771674.4076, MAE: 3291.2449, R2: 0.2155\n",
      "==========================================================================================\n",
      "Epoch [244/5000] | Time: 0.27s\n",
      "(Training) Loss: 960605.4600\n",
      "(Validation) Loss: 771558.4279, MAE: 3291.0984, R2: 0.2156\n",
      "==========================================================================================\n",
      "Epoch [245/5000] | Time: 0.26s\n",
      "(Training) Loss: 954709.1047\n",
      "(Validation) Loss: 771438.9435, MAE: 3289.2756, R2: 0.2158\n",
      "==========================================================================================\n",
      "Epoch [246/5000] | Time: 0.29s\n",
      "(Training) Loss: 971990.8376\n",
      "(Validation) Loss: 770398.0559, MAE: 3284.6790, R2: 0.2168\n",
      "==========================================================================================\n",
      "Epoch [247/5000] | Time: 0.24s\n",
      "(Training) Loss: 958644.0266\n",
      "(Validation) Loss: 770285.0940, MAE: 3285.1035, R2: 0.2169\n",
      "==========================================================================================\n",
      "Epoch [248/5000] | Time: 0.27s\n",
      "(Training) Loss: 965004.8319\n",
      "(Validation) Loss: 770172.5810, MAE: 3285.1333, R2: 0.2170\n",
      "==========================================================================================\n",
      "Epoch [249/5000] | Time: 0.23s\n",
      "(Training) Loss: 971843.8338\n",
      "(Validation) Loss: 770060.8006, MAE: 3284.7834, R2: 0.2172\n",
      "==========================================================================================\n",
      "Epoch [250/5000] | Time: 0.25s\n",
      "(Training) Loss: 965370.1783\n",
      "(Validation) Loss: 769944.5524, MAE: 3284.8386, R2: 0.2173\n",
      "==========================================================================================\n",
      "Epoch [251/5000] | Time: 0.28s\n",
      "(Training) Loss: 963413.4676\n",
      "(Validation) Loss: 769839.2279, MAE: 3285.8918, R2: 0.2174\n",
      "==========================================================================================\n",
      "Epoch [252/5000] | Time: 0.26s\n",
      "(Training) Loss: 946597.6066\n",
      "(Validation) Loss: 769718.2578, MAE: 3283.9058, R2: 0.2175\n",
      "==========================================================================================\n",
      "Epoch [253/5000] | Time: 0.24s\n",
      "(Training) Loss: 964314.2862\n",
      "(Validation) Loss: 769603.8133, MAE: 3282.5308, R2: 0.2176\n",
      "==========================================================================================\n",
      "Epoch [254/5000] | Time: 0.25s\n",
      "(Training) Loss: 959998.0425\n",
      "(Validation) Loss: 769493.2635, MAE: 3283.4917, R2: 0.2177\n",
      "==========================================================================================\n",
      "Epoch [255/5000] | Time: 0.25s\n",
      "(Training) Loss: 953370.5279\n",
      "(Validation) Loss: 769376.6711, MAE: 3282.4480, R2: 0.2178\n",
      "==========================================================================================\n",
      "Epoch [256/5000] | Time: 0.26s\n",
      "(Training) Loss: 968140.1808\n",
      "(Validation) Loss: 769272.6337, MAE: 3282.5750, R2: 0.2180\n",
      "==========================================================================================\n",
      "Epoch [257/5000] | Time: 0.23s\n",
      "(Training) Loss: 959708.1761\n",
      "(Validation) Loss: 769152.5270, MAE: 3280.3521, R2: 0.2181\n",
      "==========================================================================================\n",
      "Epoch [258/5000] | Time: 0.24s\n",
      "(Training) Loss: 955969.9848\n",
      "(Validation) Loss: 769051.0356, MAE: 3282.7222, R2: 0.2182\n",
      "==========================================================================================\n",
      "Epoch [259/5000] | Time: 0.24s\n",
      "(Training) Loss: 983793.7468\n",
      "(Validation) Loss: 768926.9454, MAE: 3279.4292, R2: 0.2183\n",
      "==========================================================================================\n",
      "Epoch [260/5000] | Time: 0.25s\n",
      "(Training) Loss: 968203.6691\n",
      "(Validation) Loss: 768813.0108, MAE: 3279.3328, R2: 0.2184\n",
      "==========================================================================================\n",
      "Epoch [261/5000] | Time: 0.24s\n",
      "(Training) Loss: 948590.0945\n",
      "(Validation) Loss: 768697.4838, MAE: 3276.9126, R2: 0.2185\n",
      "==========================================================================================\n",
      "Epoch [262/5000] | Time: 0.24s\n",
      "(Training) Loss: 961410.0425\n",
      "(Validation) Loss: 768591.5968, MAE: 3279.7869, R2: 0.2186\n",
      "==========================================================================================\n",
      "Epoch [263/5000] | Time: 0.26s\n",
      "(Training) Loss: 951376.3671\n",
      "(Validation) Loss: 768480.3511, MAE: 3278.4778, R2: 0.2187\n",
      "==========================================================================================\n",
      "Epoch [264/5000] | Time: 0.25s\n",
      "(Training) Loss: 943037.6168\n",
      "(Validation) Loss: 768366.7435, MAE: 3277.1213, R2: 0.2189\n",
      "==========================================================================================\n",
      "Epoch [265/5000] | Time: 0.26s\n",
      "(Training) Loss: 980353.5489\n",
      "(Validation) Loss: 768257.9886, MAE: 3279.5718, R2: 0.2190\n",
      "==========================================================================================\n",
      "Epoch [266/5000] | Time: 0.28s\n",
      "(Training) Loss: 948009.6402\n",
      "(Validation) Loss: 768139.6679, MAE: 3277.2021, R2: 0.2191\n",
      "==========================================================================================\n",
      "Epoch [267/5000] | Time: 0.25s\n",
      "(Training) Loss: 963894.6802\n",
      "(Validation) Loss: 768025.0324, MAE: 3275.2996, R2: 0.2192\n",
      "==========================================================================================\n",
      "Epoch [268/5000] | Time: 0.25s\n",
      "(Training) Loss: 964987.0178\n",
      "(Validation) Loss: 767913.1010, MAE: 3275.6394, R2: 0.2193\n",
      "==========================================================================================\n",
      "Epoch [269/5000] | Time: 0.26s\n",
      "(Training) Loss: 950058.8839\n",
      "(Validation) Loss: 767801.7156, MAE: 3276.2939, R2: 0.2194\n",
      "==========================================================================================\n",
      "Epoch [270/5000] | Time: 0.22s\n",
      "(Training) Loss: 958259.5178\n",
      "(Validation) Loss: 767699.1848, MAE: 3277.7258, R2: 0.2195\n",
      "==========================================================================================\n",
      "Epoch [271/5000] | Time: 0.27s\n",
      "(Training) Loss: 965211.5901\n",
      "(Validation) Loss: 767579.9917, MAE: 3275.6724, R2: 0.2197\n",
      "==========================================================================================\n",
      "Epoch [272/5000] | Time: 0.23s\n",
      "(Training) Loss: 961983.0108\n",
      "(Validation) Loss: 767466.9968, MAE: 3275.2292, R2: 0.2198\n",
      "==========================================================================================\n",
      "Epoch [273/5000] | Time: 0.30s\n",
      "(Training) Loss: 960237.8636\n",
      "(Validation) Loss: 767353.4578, MAE: 3271.9792, R2: 0.2199\n",
      "==========================================================================================\n",
      "Epoch [274/5000] | Time: 0.25s\n",
      "(Training) Loss: 944177.6082\n",
      "(Validation) Loss: 767241.8635, MAE: 3274.1208, R2: 0.2200\n",
      "==========================================================================================\n",
      "Epoch [275/5000] | Time: 0.25s\n",
      "(Training) Loss: 943897.2070\n",
      "(Validation) Loss: 767133.8533, MAE: 3274.8721, R2: 0.2201\n",
      "==========================================================================================\n",
      "Epoch [276/5000] | Time: 0.26s\n",
      "(Training) Loss: 952982.1745\n",
      "(Validation) Loss: 767060.3156, MAE: 3281.4185, R2: 0.2202\n",
      "==========================================================================================\n",
      "Epoch [277/5000] | Time: 0.26s\n",
      "(Training) Loss: 970528.0647\n",
      "(Validation) Loss: 766911.9276, MAE: 3275.2480, R2: 0.2203\n",
      "==========================================================================================\n",
      "Epoch [278/5000] | Time: 0.24s\n",
      "(Training) Loss: 942376.0583\n",
      "(Validation) Loss: 766792.9371, MAE: 3272.7847, R2: 0.2204\n",
      "==========================================================================================\n",
      "Epoch [279/5000] | Time: 0.25s\n",
      "(Training) Loss: 946368.7862\n",
      "(Validation) Loss: 766684.6648, MAE: 3272.3640, R2: 0.2206\n",
      "==========================================================================================\n",
      "Epoch [280/5000] | Time: 0.27s\n",
      "(Training) Loss: 956796.3579\n",
      "(Validation) Loss: 766577.6444, MAE: 3273.2012, R2: 0.2207\n",
      "==========================================================================================\n",
      "Epoch [281/5000] | Time: 0.27s\n",
      "(Training) Loss: 956752.5774\n",
      "(Validation) Loss: 766472.7441, MAE: 3273.2029, R2: 0.2208\n",
      "==========================================================================================\n",
      "Epoch [282/5000] | Time: 0.26s\n",
      "(Training) Loss: 970931.2202\n",
      "(Validation) Loss: 766347.9505, MAE: 3270.3740, R2: 0.2209\n",
      "==========================================================================================\n",
      "Epoch [283/5000] | Time: 0.30s\n",
      "(Training) Loss: 961142.9162\n",
      "(Validation) Loss: 766228.3962, MAE: 3268.1953, R2: 0.2210\n",
      "==========================================================================================\n",
      "Epoch [284/5000] | Time: 0.28s\n",
      "(Training) Loss: 946292.1098\n",
      "(Validation) Loss: 766120.0533, MAE: 3269.7598, R2: 0.2211\n",
      "==========================================================================================\n",
      "Epoch [285/5000] | Time: 0.23s\n",
      "(Training) Loss: 961154.3731\n",
      "(Validation) Loss: 766002.3937, MAE: 3267.3284, R2: 0.2212\n",
      "==========================================================================================\n",
      "Epoch [286/5000] | Time: 0.24s\n",
      "(Training) Loss: 977878.2253\n",
      "(Validation) Loss: 765904.6921, MAE: 3272.1873, R2: 0.2213\n",
      "==========================================================================================\n",
      "Epoch [287/5000] | Time: 0.26s\n",
      "(Training) Loss: 963496.7424\n",
      "(Validation) Loss: 765775.7759, MAE: 3265.9968, R2: 0.2215\n",
      "==========================================================================================\n",
      "Epoch [288/5000] | Time: 0.26s\n",
      "(Training) Loss: 951888.4765\n",
      "(Validation) Loss: 765665.5225, MAE: 3266.4041, R2: 0.2216\n",
      "==========================================================================================\n",
      "Epoch [289/5000] | Time: 0.27s\n",
      "(Training) Loss: 952564.4404\n",
      "(Validation) Loss: 765551.6025, MAE: 3264.8613, R2: 0.2217\n",
      "==========================================================================================\n",
      "Epoch [290/5000] | Time: 0.29s\n",
      "(Training) Loss: 944233.0247\n",
      "(Validation) Loss: 765445.0737, MAE: 3266.1096, R2: 0.2218\n",
      "==========================================================================================\n",
      "Epoch [291/5000] | Time: 0.31s\n",
      "(Training) Loss: 956955.9188\n",
      "(Validation) Loss: 765331.3689, MAE: 3265.5508, R2: 0.2219\n",
      "==========================================================================================\n",
      "Epoch [292/5000] | Time: 0.31s\n",
      "(Training) Loss: 941157.7035\n",
      "(Validation) Loss: 765227.3162, MAE: 3267.1597, R2: 0.2220\n",
      "==========================================================================================\n",
      "Epoch [293/5000] | Time: 0.26s\n",
      "(Training) Loss: 954869.5933\n",
      "(Validation) Loss: 765117.8476, MAE: 3266.8157, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [294/5000] | Time: 0.27s\n",
      "(Training) Loss: 957451.0825\n",
      "(Validation) Loss: 764999.9733, MAE: 3263.9619, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [295/5000] | Time: 0.28s\n",
      "(Training) Loss: 978308.8223\n",
      "(Validation) Loss: 764898.0908, MAE: 3266.8215, R2: 0.2224\n",
      "==========================================================================================\n",
      "Epoch [296/5000] | Time: 0.27s\n",
      "(Training) Loss: 954670.6732\n",
      "(Validation) Loss: 764778.4311, MAE: 3264.9089, R2: 0.2225\n",
      "==========================================================================================\n",
      "Epoch [297/5000] | Time: 0.25s\n",
      "(Training) Loss: 943658.1332\n",
      "(Validation) Loss: 764671.3975, MAE: 3265.9399, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [298/5000] | Time: 0.22s\n",
      "(Training) Loss: 947056.0070\n",
      "(Validation) Loss: 764560.7181, MAE: 3265.2512, R2: 0.2227\n",
      "==========================================================================================\n",
      "Epoch [299/5000] | Time: 0.26s\n",
      "(Training) Loss: 950133.8550\n",
      "(Validation) Loss: 764446.3981, MAE: 3264.2559, R2: 0.2228\n",
      "==========================================================================================\n",
      "Epoch [300/5000] | Time: 0.25s\n",
      "(Training) Loss: 958514.0070\n",
      "(Validation) Loss: 764333.5346, MAE: 3262.5574, R2: 0.2229\n",
      "==========================================================================================\n",
      "Epoch [301/5000] | Time: 0.25s\n",
      "(Training) Loss: 952206.6726\n",
      "(Validation) Loss: 764277.0140, MAE: 3264.1709, R2: 0.2230\n",
      "==========================================================================================\n",
      "Epoch [302/5000] | Time: 0.23s\n",
      "(Training) Loss: 949931.3458\n",
      "(Validation) Loss: 764167.1765, MAE: 3264.1809, R2: 0.2231\n",
      "==========================================================================================\n",
      "Epoch [303/5000] | Time: 0.25s\n",
      "(Training) Loss: 951066.0102\n",
      "(Validation) Loss: 764054.4197, MAE: 3263.4250, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [304/5000] | Time: 0.23s\n",
      "(Training) Loss: 965034.5235\n",
      "(Validation) Loss: 763948.4432, MAE: 3264.1914, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [305/5000] | Time: 0.24s\n",
      "(Training) Loss: 945016.1574\n",
      "(Validation) Loss: 763846.7562, MAE: 3265.7705, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [306/5000] | Time: 0.24s\n",
      "(Training) Loss: 956674.9181\n",
      "(Validation) Loss: 763723.5702, MAE: 3262.2556, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [307/5000] | Time: 0.26s\n",
      "(Training) Loss: 959923.5825\n",
      "(Validation) Loss: 763612.0400, MAE: 3262.7261, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [308/5000] | Time: 0.30s\n",
      "(Training) Loss: 969464.4943\n",
      "(Validation) Loss: 763504.4051, MAE: 3262.5823, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [309/5000] | Time: 0.26s\n",
      "(Training) Loss: 957582.5501\n",
      "(Validation) Loss: 763389.9797, MAE: 3262.8657, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [310/5000] | Time: 0.26s\n",
      "(Training) Loss: 948317.3008\n",
      "(Validation) Loss: 763277.8273, MAE: 3263.0466, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [311/5000] | Time: 0.24s\n",
      "(Training) Loss: 959333.5628\n",
      "(Validation) Loss: 763169.9371, MAE: 3262.4197, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [312/5000] | Time: 0.24s\n",
      "(Training) Loss: 949293.8173\n",
      "(Validation) Loss: 763059.5206, MAE: 3262.7188, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [313/5000] | Time: 0.25s\n",
      "(Training) Loss: 968937.9610\n",
      "(Validation) Loss: 762954.5822, MAE: 3263.8767, R2: 0.2243\n",
      "==========================================================================================\n",
      "Epoch [314/5000] | Time: 0.29s\n",
      "(Training) Loss: 940426.2164\n",
      "(Validation) Loss: 762831.8921, MAE: 3260.7876, R2: 0.2244\n",
      "==========================================================================================\n",
      "Epoch [315/5000] | Time: 0.24s\n",
      "(Training) Loss: 972801.7437\n",
      "(Validation) Loss: 762718.0527, MAE: 3259.0667, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [316/5000] | Time: 0.24s\n",
      "(Training) Loss: 950628.4813\n",
      "(Validation) Loss: 762617.1429, MAE: 3261.8445, R2: 0.2247\n",
      "==========================================================================================\n",
      "Epoch [317/5000] | Time: 0.26s\n",
      "(Training) Loss: 937980.9233\n",
      "(Validation) Loss: 762503.9594, MAE: 3261.3350, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [318/5000] | Time: 0.25s\n",
      "(Training) Loss: 948274.7329\n",
      "(Validation) Loss: 762385.1848, MAE: 3258.4343, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [319/5000] | Time: 0.24s\n",
      "(Training) Loss: 959688.2849\n",
      "(Validation) Loss: 762276.7105, MAE: 3258.8276, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [320/5000] | Time: 0.23s\n",
      "(Training) Loss: 937171.9143\n",
      "(Validation) Loss: 762164.4768, MAE: 3257.6716, R2: 0.2251\n",
      "==========================================================================================\n",
      "Epoch [321/5000] | Time: 0.24s\n",
      "(Training) Loss: 942015.5298\n",
      "(Validation) Loss: 762254.9676, MAE: 3259.5613, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [322/5000] | Time: 0.24s\n",
      "(Training) Loss: 956852.2018\n",
      "(Validation) Loss: 761945.1575, MAE: 3258.9502, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [323/5000] | Time: 0.30s\n",
      "(Training) Loss: 947381.2957\n",
      "(Validation) Loss: 761835.0533, MAE: 3257.1741, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [324/5000] | Time: 0.25s\n",
      "(Training) Loss: 942137.8623\n",
      "(Validation) Loss: 761472.1314, MAE: 3254.1721, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [325/5000] | Time: 0.23s\n",
      "(Training) Loss: 941243.3071\n",
      "(Validation) Loss: 761366.0521, MAE: 3254.1196, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [326/5000] | Time: 0.23s\n",
      "(Training) Loss: 942418.0355\n",
      "(Validation) Loss: 761261.5029, MAE: 3255.3159, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [327/5000] | Time: 0.25s\n",
      "(Training) Loss: 951918.0184\n",
      "(Validation) Loss: 761146.6698, MAE: 3253.2805, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [328/5000] | Time: 0.25s\n",
      "(Training) Loss: 942428.9416\n",
      "(Validation) Loss: 761041.9378, MAE: 3254.4746, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [329/5000] | Time: 0.24s\n",
      "(Training) Loss: 951840.5704\n",
      "(Validation) Loss: 760930.8952, MAE: 3252.5034, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [330/5000] | Time: 0.23s\n",
      "(Training) Loss: 958874.9829\n",
      "(Validation) Loss: 760818.2133, MAE: 3251.1809, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [331/5000] | Time: 0.26s\n",
      "(Training) Loss: 935896.2455\n",
      "(Validation) Loss: 760713.5422, MAE: 3251.9629, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [332/5000] | Time: 0.24s\n",
      "(Training) Loss: 950457.5152\n",
      "(Validation) Loss: 760604.8362, MAE: 3251.0552, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [333/5000] | Time: 0.26s\n",
      "(Training) Loss: 936306.8701\n",
      "(Validation) Loss: 760497.4933, MAE: 3251.6155, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [334/5000] | Time: 0.24s\n",
      "(Training) Loss: 945811.9480\n",
      "(Validation) Loss: 760385.4063, MAE: 3249.7832, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [335/5000] | Time: 0.26s\n",
      "(Training) Loss: 963936.2310\n",
      "(Validation) Loss: 760293.3441, MAE: 3254.4905, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [336/5000] | Time: 0.25s\n",
      "(Training) Loss: 973202.5565\n",
      "(Validation) Loss: 760166.1029, MAE: 3249.5552, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [337/5000] | Time: 0.23s\n",
      "(Training) Loss: 953651.2062\n",
      "(Validation) Loss: 760061.2705, MAE: 3250.9314, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [338/5000] | Time: 0.23s\n",
      "(Training) Loss: 942391.0736\n",
      "(Validation) Loss: 759954.0457, MAE: 3251.8247, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [339/5000] | Time: 0.22s\n",
      "(Training) Loss: 938544.2621\n",
      "(Validation) Loss: 759848.2235, MAE: 3249.9407, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [340/5000] | Time: 0.23s\n",
      "(Training) Loss: 943709.5393\n",
      "(Validation) Loss: 759750.8838, MAE: 3252.0146, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [341/5000] | Time: 0.22s\n",
      "(Training) Loss: 938179.3537\n",
      "(Validation) Loss: 759626.7568, MAE: 3247.6255, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [342/5000] | Time: 0.23s\n",
      "(Training) Loss: 939280.3420\n",
      "(Validation) Loss: 759517.1086, MAE: 3247.3796, R2: 0.2278\n",
      "==========================================================================================\n",
      "Epoch [343/5000] | Time: 0.23s\n",
      "(Training) Loss: 959904.8522\n",
      "(Validation) Loss: 759410.4152, MAE: 3246.8174, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [344/5000] | Time: 0.27s\n",
      "(Training) Loss: 947969.9010\n",
      "(Validation) Loss: 759301.8457, MAE: 3246.5796, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [345/5000] | Time: 0.24s\n",
      "(Training) Loss: 945539.8090\n",
      "(Validation) Loss: 759190.8375, MAE: 3246.2156, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [346/5000] | Time: 0.26s\n",
      "(Training) Loss: 948385.1821\n",
      "(Validation) Loss: 759086.8800, MAE: 3247.1501, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [347/5000] | Time: 0.24s\n",
      "(Training) Loss: 953425.5152\n",
      "(Validation) Loss: 758992.3365, MAE: 3250.9263, R2: 0.2283\n",
      "==========================================================================================\n",
      "Epoch [348/5000] | Time: 0.22s\n",
      "(Training) Loss: 942114.1599\n",
      "(Validation) Loss: 758881.7962, MAE: 3249.2202, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [349/5000] | Time: 0.22s\n",
      "(Training) Loss: 944537.8820\n",
      "(Validation) Loss: 758756.0660, MAE: 3244.4697, R2: 0.2285\n",
      "==========================================================================================\n",
      "Epoch [350/5000] | Time: 0.25s\n",
      "(Training) Loss: 949063.2170\n",
      "(Validation) Loss: 751702.4673, MAE: 3222.1604, R2: 0.2357\n",
      "==========================================================================================\n",
      "Epoch [351/5000] | Time: 0.25s\n",
      "(Training) Loss: 961153.5070\n",
      "(Validation) Loss: 751600.5511, MAE: 3222.4792, R2: 0.2358\n",
      "==========================================================================================\n",
      "Epoch [352/5000] | Time: 0.22s\n",
      "(Training) Loss: 940625.4683\n",
      "(Validation) Loss: 751492.2870, MAE: 3225.1328, R2: 0.2359\n",
      "==========================================================================================\n",
      "Epoch [353/5000] | Time: 0.27s\n",
      "(Training) Loss: 942921.0533\n",
      "(Validation) Loss: 751380.3060, MAE: 3220.8220, R2: 0.2360\n",
      "==========================================================================================\n",
      "Epoch [354/5000] | Time: 0.34s\n",
      "(Training) Loss: 936930.6850\n",
      "(Validation) Loss: 751279.5448, MAE: 3221.8169, R2: 0.2361\n",
      "==========================================================================================\n",
      "Epoch [355/5000] | Time: 0.26s\n",
      "(Training) Loss: 935410.2272\n",
      "(Validation) Loss: 751181.8457, MAE: 3221.8625, R2: 0.2362\n",
      "==========================================================================================\n",
      "Epoch [356/5000] | Time: 0.30s\n",
      "(Training) Loss: 929567.3147\n",
      "(Validation) Loss: 751136.0927, MAE: 3225.6313, R2: 0.2362\n",
      "==========================================================================================\n",
      "Epoch [357/5000] | Time: 0.26s\n",
      "(Training) Loss: 954167.5076\n",
      "(Validation) Loss: 751113.9619, MAE: 3229.7095, R2: 0.2362\n",
      "==========================================================================================\n",
      "Epoch [358/5000] | Time: 0.26s\n",
      "(Training) Loss: 946927.4784\n",
      "(Validation) Loss: 751000.5937, MAE: 3227.5156, R2: 0.2364\n",
      "==========================================================================================\n",
      "Epoch [359/5000] | Time: 0.24s\n",
      "(Training) Loss: 935490.2018\n",
      "(Validation) Loss: 750895.0343, MAE: 3228.8315, R2: 0.2365\n",
      "==========================================================================================\n",
      "Epoch [360/5000] | Time: 0.21s\n",
      "(Training) Loss: 934757.1434\n",
      "(Validation) Loss: 750790.3327, MAE: 3227.1680, R2: 0.2366\n",
      "==========================================================================================\n",
      "Epoch [361/5000] | Time: 0.22s\n",
      "(Training) Loss: 939070.1999\n",
      "(Validation) Loss: 750684.7079, MAE: 3226.2927, R2: 0.2367\n",
      "==========================================================================================\n",
      "Epoch [362/5000] | Time: 0.21s\n",
      "(Training) Loss: 935632.3547\n",
      "(Validation) Loss: 750575.9213, MAE: 3225.8901, R2: 0.2368\n",
      "==========================================================================================\n",
      "Epoch [363/5000] | Time: 0.24s\n",
      "(Training) Loss: 959493.7874\n",
      "(Validation) Loss: 750470.4019, MAE: 3225.5190, R2: 0.2369\n",
      "==========================================================================================\n",
      "Epoch [364/5000] | Time: 0.23s\n",
      "(Training) Loss: 936339.3934\n",
      "(Validation) Loss: 750361.7790, MAE: 3224.7275, R2: 0.2370\n",
      "==========================================================================================\n",
      "Epoch [365/5000] | Time: 0.22s\n",
      "(Training) Loss: 937463.9810\n",
      "(Validation) Loss: 750257.4324, MAE: 3224.5942, R2: 0.2371\n",
      "==========================================================================================\n",
      "Epoch [366/5000] | Time: 0.22s\n",
      "(Training) Loss: 955376.2278\n",
      "(Validation) Loss: 750151.2502, MAE: 3224.3743, R2: 0.2372\n",
      "==========================================================================================\n",
      "Epoch [367/5000] | Time: 0.22s\n",
      "(Training) Loss: 977098.6662\n",
      "(Validation) Loss: 806431.0889, MAE: 3447.4556, R2: 0.1805\n",
      "==========================================================================================\n",
      "Epoch [368/5000] | Time: 0.22s\n",
      "(Training) Loss: 1029777.9511\n",
      "(Validation) Loss: 806276.9905, MAE: 3431.9587, R2: 0.1807\n",
      "==========================================================================================\n",
      "Epoch [369/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003957.1732\n",
      "(Validation) Loss: 806159.2552, MAE: 3429.2957, R2: 0.1808\n",
      "==========================================================================================\n",
      "Epoch [370/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000347.7132\n",
      "(Validation) Loss: 806045.9600, MAE: 3430.9663, R2: 0.1809\n",
      "==========================================================================================\n",
      "Epoch [371/5000] | Time: 0.25s\n",
      "(Training) Loss: 995244.8947\n",
      "(Validation) Loss: 805924.8883, MAE: 3427.8787, R2: 0.1811\n",
      "==========================================================================================\n",
      "Epoch [372/5000] | Time: 0.26s\n",
      "(Training) Loss: 1022541.4277\n",
      "(Validation) Loss: 805833.8635, MAE: 3432.8132, R2: 0.1811\n",
      "==========================================================================================\n",
      "Epoch [373/5000] | Time: 0.27s\n",
      "(Training) Loss: 995761.9854\n",
      "(Validation) Loss: 805697.4584, MAE: 3428.7285, R2: 0.1813\n",
      "==========================================================================================\n",
      "Epoch [374/5000] | Time: 0.27s\n",
      "(Training) Loss: 996327.4810\n",
      "(Validation) Loss: 805593.6622, MAE: 3430.7666, R2: 0.1814\n",
      "==========================================================================================\n",
      "Epoch [375/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001457.7468\n",
      "(Validation) Loss: 805473.4603, MAE: 3428.1328, R2: 0.1815\n",
      "==========================================================================================\n",
      "Epoch [376/5000] | Time: 0.25s\n",
      "(Training) Loss: 1003232.9162\n",
      "(Validation) Loss: 805359.2387, MAE: 3428.1206, R2: 0.1816\n",
      "==========================================================================================\n",
      "Epoch [377/5000] | Time: 0.26s\n",
      "(Training) Loss: 991476.5539\n",
      "(Validation) Loss: 805244.2095, MAE: 3426.6775, R2: 0.1817\n",
      "==========================================================================================\n",
      "Epoch [378/5000] | Time: 0.28s\n",
      "(Training) Loss: 1010151.5286\n",
      "(Validation) Loss: 805129.7670, MAE: 3425.2874, R2: 0.1819\n",
      "==========================================================================================\n",
      "Epoch [379/5000] | Time: 0.27s\n",
      "(Training) Loss: 988264.5793\n",
      "(Validation) Loss: 805017.2432, MAE: 3426.1145, R2: 0.1820\n",
      "==========================================================================================\n",
      "Epoch [380/5000] | Time: 0.22s\n",
      "(Training) Loss: 997765.9822\n",
      "(Validation) Loss: 804905.3041, MAE: 3425.2971, R2: 0.1821\n",
      "==========================================================================================\n",
      "Epoch [381/5000] | Time: 0.23s\n",
      "(Training) Loss: 999807.6072\n",
      "(Validation) Loss: 804791.6749, MAE: 3423.1587, R2: 0.1822\n",
      "==========================================================================================\n",
      "Epoch [382/5000] | Time: 0.23s\n",
      "(Training) Loss: 999174.6117\n",
      "(Validation) Loss: 804671.7930, MAE: 3419.8315, R2: 0.1823\n",
      "==========================================================================================\n",
      "Epoch [383/5000] | Time: 0.23s\n",
      "(Training) Loss: 985832.0094\n",
      "(Validation) Loss: 804565.0635, MAE: 3423.3286, R2: 0.1824\n",
      "==========================================================================================\n",
      "Epoch [384/5000] | Time: 0.26s\n",
      "(Training) Loss: 997894.4188\n",
      "(Validation) Loss: 804453.2076, MAE: 3421.0413, R2: 0.1825\n",
      "==========================================================================================\n",
      "Epoch [385/5000] | Time: 0.23s\n",
      "(Training) Loss: 991922.8065\n",
      "(Validation) Loss: 804346.1124, MAE: 3422.1150, R2: 0.1826\n",
      "==========================================================================================\n",
      "Epoch [386/5000] | Time: 0.23s\n",
      "(Training) Loss: 1003428.1497\n",
      "(Validation) Loss: 804237.1060, MAE: 3421.8369, R2: 0.1827\n",
      "==========================================================================================\n",
      "Epoch [387/5000] | Time: 0.22s\n",
      "(Training) Loss: 995731.6307\n",
      "(Validation) Loss: 804119.3390, MAE: 3420.3435, R2: 0.1829\n",
      "==========================================================================================\n",
      "Epoch [388/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008911.5352\n",
      "(Validation) Loss: 804002.9663, MAE: 3417.0222, R2: 0.1830\n",
      "==========================================================================================\n",
      "Epoch [389/5000] | Time: 0.23s\n",
      "(Training) Loss: 995795.0774\n",
      "(Validation) Loss: 803887.3371, MAE: 3416.7021, R2: 0.1831\n",
      "==========================================================================================\n",
      "Epoch [390/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010433.5622\n",
      "(Validation) Loss: 803780.3892, MAE: 3416.6006, R2: 0.1832\n",
      "==========================================================================================\n",
      "Epoch [391/5000] | Time: 0.27s\n",
      "(Training) Loss: 1005605.3369\n",
      "(Validation) Loss: 803665.8356, MAE: 3415.7412, R2: 0.1833\n",
      "==========================================================================================\n",
      "Epoch [392/5000] | Time: 0.27s\n",
      "(Training) Loss: 1001466.8382\n",
      "(Validation) Loss: 803555.1702, MAE: 3415.8269, R2: 0.1834\n",
      "==========================================================================================\n",
      "Epoch [393/5000] | Time: 0.25s\n",
      "(Training) Loss: 1002603.3452\n",
      "(Validation) Loss: 803455.6279, MAE: 3418.2073, R2: 0.1835\n",
      "==========================================================================================\n",
      "Epoch [394/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003098.4651\n",
      "(Validation) Loss: 803339.4013, MAE: 3415.8369, R2: 0.1837\n",
      "==========================================================================================\n",
      "Epoch [395/5000] | Time: 0.25s\n",
      "(Training) Loss: 1008576.9962\n",
      "(Validation) Loss: 803218.1321, MAE: 3411.6863, R2: 0.1838\n",
      "==========================================================================================\n",
      "Epoch [396/5000] | Time: 0.28s\n",
      "(Training) Loss: 1009460.4905\n",
      "(Validation) Loss: 803107.7905, MAE: 3411.2673, R2: 0.1839\n",
      "==========================================================================================\n",
      "Epoch [397/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016904.2659\n",
      "(Validation) Loss: 803002.9886, MAE: 3413.3623, R2: 0.1840\n",
      "==========================================================================================\n",
      "Epoch [398/5000] | Time: 0.24s\n",
      "(Training) Loss: 988057.8509\n",
      "(Validation) Loss: 802882.9873, MAE: 3410.4426, R2: 0.1841\n",
      "==========================================================================================\n",
      "Epoch [399/5000] | Time: 0.23s\n",
      "(Training) Loss: 1011022.4607\n",
      "(Validation) Loss: 802775.4857, MAE: 3410.8481, R2: 0.1842\n",
      "==========================================================================================\n",
      "Epoch [400/5000] | Time: 0.25s\n",
      "(Training) Loss: 1006932.1453\n",
      "(Validation) Loss: 802681.2387, MAE: 3412.8428, R2: 0.1843\n",
      "==========================================================================================\n",
      "Epoch [401/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008025.3794\n",
      "(Validation) Loss: 802561.9187, MAE: 3411.6890, R2: 0.1844\n",
      "==========================================================================================\n",
      "Epoch [402/5000] | Time: 0.24s\n",
      "(Training) Loss: 1009773.0819\n",
      "(Validation) Loss: 802444.0356, MAE: 3409.2568, R2: 0.1846\n",
      "==========================================================================================\n",
      "Epoch [403/5000] | Time: 0.22s\n",
      "(Training) Loss: 992672.9473\n",
      "(Validation) Loss: 802338.2463, MAE: 3410.5720, R2: 0.1847\n",
      "==========================================================================================\n",
      "Epoch [404/5000] | Time: 0.24s\n",
      "(Training) Loss: 995072.8839\n",
      "(Validation) Loss: 802221.5327, MAE: 3407.3813, R2: 0.1848\n",
      "==========================================================================================\n",
      "Epoch [405/5000] | Time: 0.27s\n",
      "(Training) Loss: 1010969.5819\n",
      "(Validation) Loss: 802115.1975, MAE: 3408.1099, R2: 0.1849\n",
      "==========================================================================================\n",
      "Epoch [406/5000] | Time: 0.25s\n",
      "(Training) Loss: 986154.3769\n",
      "(Validation) Loss: 802001.2984, MAE: 3406.7566, R2: 0.1850\n",
      "==========================================================================================\n",
      "Epoch [407/5000] | Time: 0.26s\n",
      "(Training) Loss: 995204.4664\n",
      "(Validation) Loss: 801891.8559, MAE: 3405.6726, R2: 0.1851\n",
      "==========================================================================================\n",
      "Epoch [408/5000] | Time: 0.23s\n",
      "(Training) Loss: 999446.1637\n",
      "(Validation) Loss: 801786.7105, MAE: 3406.3911, R2: 0.1852\n",
      "==========================================================================================\n",
      "Epoch [409/5000] | Time: 0.31s\n",
      "(Training) Loss: 984940.8166\n",
      "(Validation) Loss: 801684.4216, MAE: 3410.0464, R2: 0.1853\n",
      "==========================================================================================\n",
      "Epoch [410/5000] | Time: 0.27s\n",
      "(Training) Loss: 983203.0971\n",
      "(Validation) Loss: 790872.3727, MAE: 3358.3162, R2: 0.1962\n",
      "==========================================================================================\n",
      "Epoch [411/5000] | Time: 0.25s\n",
      "(Training) Loss: 986560.2303\n",
      "(Validation) Loss: 790788.0895, MAE: 3363.9189, R2: 0.1963\n",
      "==========================================================================================\n",
      "Epoch [412/5000] | Time: 0.25s\n",
      "(Training) Loss: 991612.8223\n",
      "(Validation) Loss: 790691.6565, MAE: 3365.8062, R2: 0.1964\n",
      "==========================================================================================\n",
      "Epoch [413/5000] | Time: 0.25s\n",
      "(Training) Loss: 986430.0609\n",
      "(Validation) Loss: 790570.6756, MAE: 3359.4807, R2: 0.1965\n",
      "==========================================================================================\n",
      "Epoch [414/5000] | Time: 0.23s\n",
      "(Training) Loss: 980575.3909\n",
      "(Validation) Loss: 790512.8216, MAE: 3362.0168, R2: 0.1966\n",
      "==========================================================================================\n",
      "Epoch [415/5000] | Time: 0.23s\n",
      "(Training) Loss: 987093.3503\n",
      "(Validation) Loss: 790418.0984, MAE: 3365.6787, R2: 0.1967\n",
      "==========================================================================================\n",
      "Epoch [416/5000] | Time: 0.24s\n",
      "(Training) Loss: 972755.2989\n",
      "(Validation) Loss: 790298.0984, MAE: 3359.7258, R2: 0.1968\n",
      "==========================================================================================\n",
      "Epoch [417/5000] | Time: 0.24s\n",
      "(Training) Loss: 985017.6567\n",
      "(Validation) Loss: 790196.3105, MAE: 3359.6787, R2: 0.1969\n",
      "==========================================================================================\n",
      "Epoch [418/5000] | Time: 0.34s\n",
      "(Training) Loss: 975485.4378\n",
      "(Validation) Loss: 790105.3340, MAE: 3364.3291, R2: 0.1970\n",
      "==========================================================================================\n",
      "Epoch [419/5000] | Time: 0.27s\n",
      "(Training) Loss: 985093.1510\n",
      "(Validation) Loss: 789996.1752, MAE: 3361.0017, R2: 0.1971\n",
      "==========================================================================================\n",
      "Epoch [420/5000] | Time: 0.29s\n",
      "(Training) Loss: 996336.9632\n",
      "(Validation) Loss: 789889.1086, MAE: 3359.1680, R2: 0.1972\n",
      "==========================================================================================\n",
      "Epoch [421/5000] | Time: 0.33s\n",
      "(Training) Loss: 977979.2970\n",
      "(Validation) Loss: 789780.5581, MAE: 3358.8501, R2: 0.1973\n",
      "==========================================================================================\n",
      "Epoch [422/5000] | Time: 0.27s\n",
      "(Training) Loss: 970894.4749\n",
      "(Validation) Loss: 789677.2857, MAE: 3357.9595, R2: 0.1974\n",
      "==========================================================================================\n",
      "Epoch [423/5000] | Time: 0.26s\n",
      "(Training) Loss: 983624.5888\n",
      "(Validation) Loss: 789582.4171, MAE: 3360.3276, R2: 0.1975\n",
      "==========================================================================================\n",
      "Epoch [424/5000] | Time: 0.30s\n",
      "(Training) Loss: 987353.1643\n",
      "(Validation) Loss: 789480.9816, MAE: 3360.0837, R2: 0.1976\n",
      "==========================================================================================\n",
      "Epoch [425/5000] | Time: 0.28s\n",
      "(Training) Loss: 995137.1459\n",
      "(Validation) Loss: 789382.3689, MAE: 3361.7009, R2: 0.1977\n",
      "==========================================================================================\n",
      "Epoch [426/5000] | Time: 0.29s\n",
      "(Training) Loss: 985303.7126\n",
      "(Validation) Loss: 789267.9200, MAE: 3358.0017, R2: 0.1978\n",
      "==========================================================================================\n",
      "Epoch [427/5000] | Time: 0.28s\n",
      "(Training) Loss: 1005671.0470\n",
      "(Validation) Loss: 789176.6806, MAE: 3360.2117, R2: 0.1979\n",
      "==========================================================================================\n",
      "Epoch [428/5000] | Time: 0.26s\n",
      "(Training) Loss: 989729.4391\n",
      "(Validation) Loss: 789058.7086, MAE: 3356.7749, R2: 0.1980\n",
      "==========================================================================================\n",
      "Epoch [429/5000] | Time: 0.28s\n",
      "(Training) Loss: 975236.7614\n",
      "(Validation) Loss: 788970.0571, MAE: 3360.2234, R2: 0.1981\n",
      "==========================================================================================\n",
      "Epoch [430/5000] | Time: 0.29s\n",
      "(Training) Loss: 969709.4362\n",
      "(Validation) Loss: 788976.9016, MAE: 3363.3862, R2: 0.1981\n",
      "==========================================================================================\n",
      "Epoch [431/5000] | Time: 0.25s\n",
      "(Training) Loss: 983261.5222\n",
      "(Validation) Loss: 788875.5206, MAE: 3363.8105, R2: 0.1982\n",
      "==========================================================================================\n",
      "Epoch [432/5000] | Time: 0.28s\n",
      "(Training) Loss: 986790.8147\n",
      "(Validation) Loss: 788770.3162, MAE: 3363.6079, R2: 0.1983\n",
      "==========================================================================================\n",
      "Epoch [433/5000] | Time: 0.31s\n",
      "(Training) Loss: 979179.7970\n",
      "(Validation) Loss: 788666.7340, MAE: 3363.3120, R2: 0.1984\n",
      "==========================================================================================\n",
      "Epoch [434/5000] | Time: 0.27s\n",
      "(Training) Loss: 974644.9499\n",
      "(Validation) Loss: 788558.6298, MAE: 3360.2961, R2: 0.1985\n",
      "==========================================================================================\n",
      "Epoch [435/5000] | Time: 0.26s\n",
      "(Training) Loss: 974371.6745\n",
      "(Validation) Loss: 788460.6076, MAE: 3362.0730, R2: 0.1986\n",
      "==========================================================================================\n",
      "Epoch [436/5000] | Time: 0.24s\n",
      "(Training) Loss: 969691.2364\n",
      "(Validation) Loss: 788356.1829, MAE: 3362.6978, R2: 0.1987\n",
      "==========================================================================================\n",
      "Epoch [437/5000] | Time: 0.24s\n",
      "(Training) Loss: 1007506.8928\n",
      "(Validation) Loss: 788259.5797, MAE: 3364.2004, R2: 0.1988\n",
      "==========================================================================================\n",
      "Epoch [438/5000] | Time: 0.24s\n",
      "(Training) Loss: 975748.0565\n",
      "(Validation) Loss: 788143.8527, MAE: 3359.6089, R2: 0.1989\n",
      "==========================================================================================\n",
      "Epoch [439/5000] | Time: 0.24s\n",
      "(Training) Loss: 972732.8484\n",
      "(Validation) Loss: 788038.1098, MAE: 3358.5330, R2: 0.1991\n",
      "==========================================================================================\n",
      "Epoch [440/5000] | Time: 0.26s\n",
      "(Training) Loss: 991791.5482\n",
      "(Validation) Loss: 787944.0216, MAE: 3360.5093, R2: 0.1991\n",
      "==========================================================================================\n",
      "Epoch [441/5000] | Time: 0.25s\n",
      "(Training) Loss: 985079.4118\n",
      "(Validation) Loss: 787835.4667, MAE: 3358.5637, R2: 0.1993\n",
      "==========================================================================================\n",
      "Epoch [442/5000] | Time: 0.25s\n",
      "(Training) Loss: 983293.7595\n",
      "(Validation) Loss: 787732.1251, MAE: 3358.5410, R2: 0.1994\n",
      "==========================================================================================\n",
      "Epoch [443/5000] | Time: 0.27s\n",
      "(Training) Loss: 999734.2189\n",
      "(Validation) Loss: 787627.9924, MAE: 3358.9690, R2: 0.1995\n",
      "==========================================================================================\n",
      "Epoch [444/5000] | Time: 0.28s\n",
      "(Training) Loss: 996636.0704\n",
      "(Validation) Loss: 787524.7479, MAE: 3358.5374, R2: 0.1996\n",
      "==========================================================================================\n",
      "Epoch [445/5000] | Time: 0.30s\n",
      "(Training) Loss: 975547.6980\n",
      "(Validation) Loss: 787415.0286, MAE: 3356.2874, R2: 0.1997\n",
      "==========================================================================================\n",
      "Epoch [446/5000] | Time: 0.35s\n",
      "(Training) Loss: 983919.5412\n",
      "(Validation) Loss: 787310.5206, MAE: 3355.7549, R2: 0.1998\n",
      "==========================================================================================\n",
      "Epoch [447/5000] | Time: 0.26s\n",
      "(Training) Loss: 978746.9124\n",
      "(Validation) Loss: 787208.2990, MAE: 3355.8828, R2: 0.1999\n",
      "==========================================================================================\n",
      "Epoch [448/5000] | Time: 0.26s\n",
      "(Training) Loss: 982654.6815\n",
      "(Validation) Loss: 787101.4083, MAE: 3355.2861, R2: 0.2000\n",
      "==========================================================================================\n",
      "Epoch [449/5000] | Time: 0.26s\n",
      "(Training) Loss: 985489.6041\n",
      "(Validation) Loss: 787000.5403, MAE: 3355.4998, R2: 0.2001\n",
      "==========================================================================================\n",
      "Epoch [450/5000] | Time: 0.33s\n",
      "(Training) Loss: 973009.2817\n",
      "(Validation) Loss: 786895.5689, MAE: 3354.1228, R2: 0.2002\n",
      "==========================================================================================\n",
      "Epoch [451/5000] | Time: 0.30s\n",
      "(Training) Loss: 965462.5984\n",
      "(Validation) Loss: 786792.8044, MAE: 3354.8528, R2: 0.2003\n",
      "==========================================================================================\n",
      "Epoch [452/5000] | Time: 0.25s\n",
      "(Training) Loss: 997071.4645\n",
      "(Validation) Loss: 786692.5587, MAE: 3354.2661, R2: 0.2004\n",
      "==========================================================================================\n",
      "Epoch [453/5000] | Time: 0.27s\n",
      "(Training) Loss: 979416.7646\n",
      "(Validation) Loss: 786589.4489, MAE: 3355.2271, R2: 0.2005\n",
      "==========================================================================================\n",
      "Epoch [454/5000] | Time: 0.29s\n",
      "(Training) Loss: 991496.0774\n",
      "(Validation) Loss: 786488.8629, MAE: 3356.3203, R2: 0.2006\n",
      "==========================================================================================\n",
      "Epoch [455/5000] | Time: 0.30s\n",
      "(Training) Loss: 974150.3991\n",
      "(Validation) Loss: 786376.2762, MAE: 3352.9221, R2: 0.2007\n",
      "==========================================================================================\n",
      "Epoch [456/5000] | Time: 0.27s\n",
      "(Training) Loss: 975109.6003\n",
      "(Validation) Loss: 786287.7283, MAE: 3355.5525, R2: 0.2008\n",
      "==========================================================================================\n",
      "Epoch [457/5000] | Time: 0.28s\n",
      "(Training) Loss: 985239.7094\n",
      "(Validation) Loss: 786174.4248, MAE: 3355.2126, R2: 0.2009\n",
      "==========================================================================================\n",
      "Epoch [458/5000] | Time: 0.29s\n",
      "(Training) Loss: 980362.9803\n",
      "(Validation) Loss: 786077.8051, MAE: 3355.3813, R2: 0.2010\n",
      "==========================================================================================\n",
      "Epoch [459/5000] | Time: 0.28s\n",
      "(Training) Loss: 979126.8629\n",
      "(Validation) Loss: 785979.7905, MAE: 3355.7202, R2: 0.2011\n",
      "==========================================================================================\n",
      "Epoch [460/5000] | Time: 0.27s\n",
      "(Training) Loss: 980390.5888\n",
      "(Validation) Loss: 785858.4965, MAE: 3351.8489, R2: 0.2012\n",
      "==========================================================================================\n",
      "Epoch [461/5000] | Time: 0.27s\n",
      "(Training) Loss: 989683.1878\n",
      "(Validation) Loss: 785755.3486, MAE: 3349.5308, R2: 0.2014\n",
      "==========================================================================================\n",
      "Epoch [462/5000] | Time: 0.25s\n",
      "(Training) Loss: 981332.4394\n",
      "(Validation) Loss: 785650.1340, MAE: 3350.8149, R2: 0.2015\n",
      "==========================================================================================\n",
      "Epoch [463/5000] | Time: 0.25s\n",
      "(Training) Loss: 985895.3680\n",
      "(Validation) Loss: 785551.7702, MAE: 3350.9724, R2: 0.2016\n",
      "==========================================================================================\n",
      "Epoch [464/5000] | Time: 0.27s\n",
      "(Training) Loss: 978839.7246\n",
      "(Validation) Loss: 785445.0857, MAE: 3349.0801, R2: 0.2017\n",
      "==========================================================================================\n",
      "Epoch [465/5000] | Time: 0.27s\n",
      "(Training) Loss: 977803.4226\n",
      "(Validation) Loss: 785354.3092, MAE: 3352.4019, R2: 0.2018\n",
      "==========================================================================================\n",
      "Epoch [466/5000] | Time: 0.27s\n",
      "(Training) Loss: 970894.2665\n",
      "(Validation) Loss: 785240.2559, MAE: 3353.2012, R2: 0.2019\n",
      "==========================================================================================\n",
      "Epoch [467/5000] | Time: 0.27s\n",
      "(Training) Loss: 972895.0330\n",
      "(Validation) Loss: 785132.8438, MAE: 3350.0266, R2: 0.2020\n",
      "==========================================================================================\n",
      "Epoch [468/5000] | Time: 0.28s\n",
      "(Training) Loss: 966143.2754\n",
      "(Validation) Loss: 785030.3587, MAE: 3347.8379, R2: 0.2021\n",
      "==========================================================================================\n",
      "Epoch [469/5000] | Time: 0.27s\n",
      "(Training) Loss: 966993.5178\n",
      "(Validation) Loss: 784928.8743, MAE: 3348.5574, R2: 0.2022\n",
      "==========================================================================================\n",
      "Epoch [470/5000] | Time: 0.27s\n",
      "(Training) Loss: 962773.9492\n",
      "(Validation) Loss: 784825.1987, MAE: 3346.5391, R2: 0.2023\n",
      "==========================================================================================\n",
      "Epoch [471/5000] | Time: 0.27s\n",
      "(Training) Loss: 982213.1713\n",
      "(Validation) Loss: 784722.4216, MAE: 3345.3298, R2: 0.2024\n",
      "==========================================================================================\n",
      "Epoch [472/5000] | Time: 0.25s\n",
      "(Training) Loss: 982313.0780\n",
      "(Validation) Loss: 784618.3848, MAE: 3346.2197, R2: 0.2025\n",
      "==========================================================================================\n",
      "Epoch [473/5000] | Time: 0.27s\n",
      "(Training) Loss: 985818.9162\n",
      "(Validation) Loss: 784520.7346, MAE: 3347.0938, R2: 0.2026\n",
      "==========================================================================================\n",
      "Epoch [474/5000] | Time: 0.26s\n",
      "(Training) Loss: 977201.5520\n",
      "(Validation) Loss: 784417.3943, MAE: 3347.2622, R2: 0.2027\n",
      "==========================================================================================\n",
      "Epoch [475/5000] | Time: 0.29s\n",
      "(Training) Loss: 964117.2278\n",
      "(Validation) Loss: 784315.1206, MAE: 3346.2832, R2: 0.2028\n",
      "==========================================================================================\n",
      "Epoch [476/5000] | Time: 0.26s\n",
      "(Training) Loss: 970087.7005\n",
      "(Validation) Loss: 784207.7460, MAE: 3344.6892, R2: 0.2029\n",
      "==========================================================================================\n",
      "Epoch [477/5000] | Time: 0.26s\n",
      "(Training) Loss: 975596.0952\n",
      "(Validation) Loss: 784108.2616, MAE: 3344.2473, R2: 0.2030\n",
      "==========================================================================================\n",
      "Epoch [478/5000] | Time: 0.30s\n",
      "(Training) Loss: 991302.6561\n",
      "(Validation) Loss: 784006.4571, MAE: 3345.2715, R2: 0.2031\n",
      "==========================================================================================\n",
      "Epoch [479/5000] | Time: 0.32s\n",
      "(Training) Loss: 975609.4949\n",
      "(Validation) Loss: 783897.5225, MAE: 3342.5696, R2: 0.2032\n",
      "==========================================================================================\n",
      "Epoch [480/5000] | Time: 0.30s\n",
      "(Training) Loss: 990220.5806\n",
      "(Validation) Loss: 783795.5981, MAE: 3342.6169, R2: 0.2033\n",
      "==========================================================================================\n",
      "Epoch [481/5000] | Time: 0.32s\n",
      "(Training) Loss: 976703.1650\n",
      "(Validation) Loss: 783691.6063, MAE: 3343.8809, R2: 0.2034\n",
      "==========================================================================================\n",
      "Epoch [482/5000] | Time: 0.27s\n",
      "(Training) Loss: 970892.9042\n",
      "(Validation) Loss: 783588.5092, MAE: 3342.4375, R2: 0.2035\n",
      "==========================================================================================\n",
      "Epoch [483/5000] | Time: 0.30s\n",
      "(Training) Loss: 973155.4340\n",
      "(Validation) Loss: 783353.1441, MAE: 3341.3740, R2: 0.2038\n",
      "==========================================================================================\n",
      "Epoch [484/5000] | Time: 0.30s\n",
      "(Training) Loss: 975470.0178\n",
      "(Validation) Loss: 783284.7137, MAE: 3345.0347, R2: 0.2038\n",
      "==========================================================================================\n",
      "Epoch [485/5000] | Time: 0.29s\n",
      "(Training) Loss: 976156.0266\n",
      "(Validation) Loss: 783202.3251, MAE: 3342.1431, R2: 0.2039\n",
      "==========================================================================================\n",
      "Epoch [486/5000] | Time: 0.27s\n",
      "(Training) Loss: 975945.5717\n",
      "(Validation) Loss: 783060.0902, MAE: 3333.1406, R2: 0.2041\n",
      "==========================================================================================\n",
      "Epoch [487/5000] | Time: 0.27s\n",
      "(Training) Loss: 965990.2462\n",
      "(Validation) Loss: 782961.1949, MAE: 3333.0349, R2: 0.2042\n",
      "==========================================================================================\n",
      "Epoch [488/5000] | Time: 0.26s\n",
      "(Training) Loss: 981422.4600\n",
      "(Validation) Loss: 782855.7683, MAE: 3332.2559, R2: 0.2043\n",
      "==========================================================================================\n",
      "Epoch [489/5000] | Time: 0.24s\n",
      "(Training) Loss: 969953.4695\n",
      "(Validation) Loss: 782747.8756, MAE: 3329.3350, R2: 0.2044\n",
      "==========================================================================================\n",
      "Epoch [490/5000] | Time: 0.26s\n",
      "(Training) Loss: 986016.7716\n",
      "(Validation) Loss: 782646.7498, MAE: 3330.9707, R2: 0.2045\n",
      "==========================================================================================\n",
      "Epoch [491/5000] | Time: 0.24s\n",
      "(Training) Loss: 981606.6878\n",
      "(Validation) Loss: 782546.0489, MAE: 3330.3704, R2: 0.2046\n",
      "==========================================================================================\n",
      "Epoch [492/5000] | Time: 0.25s\n",
      "(Training) Loss: 974403.4397\n",
      "(Validation) Loss: 782439.0927, MAE: 3330.2571, R2: 0.2047\n",
      "==========================================================================================\n",
      "Epoch [493/5000] | Time: 0.26s\n",
      "(Training) Loss: 960708.9828\n",
      "(Validation) Loss: 782335.7537, MAE: 3329.1101, R2: 0.2048\n",
      "==========================================================================================\n",
      "Epoch [494/5000] | Time: 0.25s\n",
      "(Training) Loss: 979559.3731\n",
      "(Validation) Loss: 782231.9867, MAE: 3328.8545, R2: 0.2049\n",
      "==========================================================================================\n",
      "Epoch [495/5000] | Time: 0.26s\n",
      "(Training) Loss: 978417.5266\n",
      "(Validation) Loss: 782104.9962, MAE: 3339.2864, R2: 0.2050\n",
      "==========================================================================================\n",
      "Epoch [496/5000] | Time: 0.25s\n",
      "(Training) Loss: 980138.4708\n",
      "(Validation) Loss: 782022.5060, MAE: 3326.2729, R2: 0.2051\n",
      "==========================================================================================\n",
      "Epoch [497/5000] | Time: 0.24s\n",
      "(Training) Loss: 983261.0317\n",
      "(Validation) Loss: 809430.7784, MAE: 3432.1907, R2: 0.1775\n",
      "==========================================================================================\n",
      "Epoch [498/5000] | Time: 0.25s\n",
      "(Training) Loss: 1019961.3207\n",
      "(Validation) Loss: 809316.9543, MAE: 3428.7170, R2: 0.1776\n",
      "==========================================================================================\n",
      "Epoch [499/5000] | Time: 0.26s\n",
      "(Training) Loss: 1021118.2563\n",
      "(Validation) Loss: 809211.9549, MAE: 3430.0688, R2: 0.1777\n",
      "==========================================================================================\n",
      "Epoch [500/5000] | Time: 0.24s\n",
      "(Training) Loss: 997987.2373\n",
      "(Validation) Loss: 809113.3448, MAE: 3432.8782, R2: 0.1778\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch500.pth\n",
      "==========================================================================================\n",
      "Epoch [501/5000] | Time: 0.24s\n",
      "(Training) Loss: 991251.4205\n",
      "(Validation) Loss: 809033.7244, MAE: 3437.5674, R2: 0.1779\n",
      "==========================================================================================\n",
      "Epoch [502/5000] | Time: 0.28s\n",
      "(Training) Loss: 999209.5806\n",
      "(Validation) Loss: 808886.2838, MAE: 3430.1743, R2: 0.1781\n",
      "==========================================================================================\n",
      "Epoch [503/5000] | Time: 0.23s\n",
      "(Training) Loss: 1006881.4787\n",
      "(Validation) Loss: 808763.9187, MAE: 3425.7629, R2: 0.1782\n",
      "==========================================================================================\n",
      "Epoch [504/5000] | Time: 0.21s\n",
      "(Training) Loss: 996973.4086\n",
      "(Validation) Loss: 808661.7575, MAE: 3426.7993, R2: 0.1783\n",
      "==========================================================================================\n",
      "Epoch [505/5000] | Time: 0.20s\n",
      "(Training) Loss: 1011716.6199\n",
      "(Validation) Loss: 808550.5600, MAE: 3426.0276, R2: 0.1784\n",
      "==========================================================================================\n",
      "Epoch [506/5000] | Time: 0.22s\n",
      "(Training) Loss: 1005689.3845\n",
      "(Validation) Loss: 808462.6781, MAE: 3430.8633, R2: 0.1785\n",
      "==========================================================================================\n",
      "Epoch [507/5000] | Time: 0.20s\n",
      "(Training) Loss: 1017206.8376\n",
      "(Validation) Loss: 808329.3276, MAE: 3424.9158, R2: 0.1786\n",
      "==========================================================================================\n",
      "Epoch [508/5000] | Time: 0.21s\n",
      "(Training) Loss: 999371.9327\n",
      "(Validation) Loss: 808225.8254, MAE: 3426.2068, R2: 0.1787\n",
      "==========================================================================================\n",
      "Epoch [509/5000] | Time: 0.21s\n",
      "(Training) Loss: 1003193.0108\n",
      "(Validation) Loss: 808110.0559, MAE: 3424.7349, R2: 0.1789\n",
      "==========================================================================================\n",
      "Epoch [510/5000] | Time: 0.21s\n",
      "(Training) Loss: 989803.1899\n",
      "(Validation) Loss: 808026.0584, MAE: 3428.3572, R2: 0.1789\n",
      "==========================================================================================\n",
      "Epoch [511/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005142.5444\n",
      "(Validation) Loss: 807900.6241, MAE: 3424.6980, R2: 0.1791\n",
      "==========================================================================================\n",
      "Epoch [512/5000] | Time: 0.23s\n",
      "(Training) Loss: 992902.5038\n",
      "(Validation) Loss: 807803.6286, MAE: 3427.1377, R2: 0.1792\n",
      "==========================================================================================\n",
      "Epoch [513/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007807.2081\n",
      "(Validation) Loss: 807688.2197, MAE: 3425.7339, R2: 0.1793\n",
      "==========================================================================================\n",
      "Epoch [514/5000] | Time: 0.21s\n",
      "(Training) Loss: 1015077.6723\n",
      "(Validation) Loss: 807578.1384, MAE: 3425.8423, R2: 0.1794\n",
      "==========================================================================================\n",
      "Epoch [515/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000714.6942\n",
      "(Validation) Loss: 807464.6648, MAE: 3424.7434, R2: 0.1795\n",
      "==========================================================================================\n",
      "Epoch [516/5000] | Time: 0.22s\n",
      "(Training) Loss: 989015.2076\n",
      "(Validation) Loss: 807350.3968, MAE: 3422.0181, R2: 0.1796\n",
      "==========================================================================================\n",
      "Epoch [517/5000] | Time: 0.21s\n",
      "(Training) Loss: 1013395.7151\n",
      "(Validation) Loss: 807250.6273, MAE: 3423.5020, R2: 0.1797\n",
      "==========================================================================================\n",
      "Epoch [518/5000] | Time: 0.21s\n",
      "(Training) Loss: 992403.8687\n",
      "(Validation) Loss: 807142.9156, MAE: 3423.6096, R2: 0.1798\n",
      "==========================================================================================\n",
      "Epoch [519/5000] | Time: 0.21s\n",
      "(Training) Loss: 999918.9226\n",
      "(Validation) Loss: 807029.1854, MAE: 3422.8037, R2: 0.1799\n",
      "==========================================================================================\n",
      "Epoch [520/5000] | Time: 0.21s\n",
      "(Training) Loss: 1016940.8490\n",
      "(Validation) Loss: 806917.1397, MAE: 3419.5591, R2: 0.1801\n",
      "==========================================================================================\n",
      "Epoch [521/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002633.9346\n",
      "(Validation) Loss: 806817.1854, MAE: 3421.9175, R2: 0.1802\n",
      "==========================================================================================\n",
      "Epoch [522/5000] | Time: 0.23s\n",
      "(Training) Loss: 991493.6497\n",
      "(Validation) Loss: 806705.3263, MAE: 3421.5315, R2: 0.1803\n",
      "==========================================================================================\n",
      "Epoch [523/5000] | Time: 0.24s\n",
      "(Training) Loss: 1023422.2398\n",
      "(Validation) Loss: 806593.4298, MAE: 3417.5784, R2: 0.1804\n",
      "==========================================================================================\n",
      "Epoch [524/5000] | Time: 0.22s\n",
      "(Training) Loss: 1032038.2351\n",
      "(Validation) Loss: 806487.4857, MAE: 3420.9258, R2: 0.1805\n",
      "==========================================================================================\n",
      "Epoch [525/5000] | Time: 0.22s\n",
      "(Training) Loss: 989601.2475\n",
      "(Validation) Loss: 806375.8400, MAE: 3418.3179, R2: 0.1806\n",
      "==========================================================================================\n",
      "Epoch [526/5000] | Time: 0.23s\n",
      "(Training) Loss: 991989.6320\n",
      "(Validation) Loss: 806274.7803, MAE: 3418.2473, R2: 0.1807\n",
      "==========================================================================================\n",
      "Epoch [527/5000] | Time: 0.24s\n",
      "(Training) Loss: 1011933.0279\n",
      "(Validation) Loss: 806159.2286, MAE: 3415.4548, R2: 0.1808\n",
      "==========================================================================================\n",
      "Epoch [528/5000] | Time: 0.23s\n",
      "(Training) Loss: 989258.1396\n",
      "(Validation) Loss: 806050.2317, MAE: 3415.0964, R2: 0.1809\n",
      "==========================================================================================\n",
      "Epoch [529/5000] | Time: 0.25s\n",
      "(Training) Loss: 1007300.6377\n",
      "(Validation) Loss: 805946.2997, MAE: 3418.0562, R2: 0.1810\n",
      "==========================================================================================\n",
      "Epoch [530/5000] | Time: 0.24s\n",
      "(Training) Loss: 987715.2952\n",
      "(Validation) Loss: 805834.2533, MAE: 3414.5732, R2: 0.1811\n",
      "==========================================================================================\n",
      "Epoch [531/5000] | Time: 0.24s\n",
      "(Training) Loss: 1010840.7849\n",
      "(Validation) Loss: 805734.7816, MAE: 3416.3850, R2: 0.1812\n",
      "==========================================================================================\n",
      "Epoch [532/5000] | Time: 0.25s\n",
      "(Training) Loss: 1015532.6904\n",
      "(Validation) Loss: 805628.1994, MAE: 3417.5723, R2: 0.1814\n",
      "==========================================================================================\n",
      "Epoch [533/5000] | Time: 0.24s\n",
      "(Training) Loss: 1006306.6521\n",
      "(Validation) Loss: 805517.3721, MAE: 3416.7000, R2: 0.1815\n",
      "==========================================================================================\n",
      "Epoch [534/5000] | Time: 0.23s\n",
      "(Training) Loss: 991715.6942\n",
      "(Validation) Loss: 805411.9098, MAE: 3415.9753, R2: 0.1816\n",
      "==========================================================================================\n",
      "Epoch [535/5000] | Time: 0.24s\n",
      "(Training) Loss: 1013035.1060\n",
      "(Validation) Loss: 805303.2832, MAE: 3413.4534, R2: 0.1817\n",
      "==========================================================================================\n",
      "Epoch [536/5000] | Time: 0.24s\n",
      "(Training) Loss: 1013960.1091\n",
      "(Validation) Loss: 805216.2025, MAE: 3418.8518, R2: 0.1818\n",
      "==========================================================================================\n",
      "Epoch [537/5000] | Time: 0.24s\n",
      "(Training) Loss: 993641.8706\n",
      "(Validation) Loss: 805089.5784, MAE: 3412.0952, R2: 0.1819\n",
      "==========================================================================================\n",
      "Epoch [538/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005771.8569\n",
      "(Validation) Loss: 804994.4857, MAE: 3415.1150, R2: 0.1820\n",
      "==========================================================================================\n",
      "Epoch [539/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003550.1225\n",
      "(Validation) Loss: 804873.1835, MAE: 3410.9629, R2: 0.1821\n",
      "==========================================================================================\n",
      "Epoch [540/5000] | Time: 0.23s\n",
      "(Training) Loss: 995465.6313\n",
      "(Validation) Loss: 804768.8203, MAE: 3412.7275, R2: 0.1822\n",
      "==========================================================================================\n",
      "Epoch [541/5000] | Time: 0.23s\n",
      "(Training) Loss: 991869.7107\n",
      "(Validation) Loss: 804673.6914, MAE: 3417.8062, R2: 0.1823\n",
      "==========================================================================================\n",
      "Epoch [542/5000] | Time: 0.29s\n",
      "(Training) Loss: 1018194.1047\n",
      "(Validation) Loss: 804566.0813, MAE: 3411.5940, R2: 0.1824\n",
      "==========================================================================================\n",
      "Epoch [543/5000] | Time: 0.30s\n",
      "(Training) Loss: 1027468.7119\n",
      "(Validation) Loss: 804452.0552, MAE: 3411.6836, R2: 0.1825\n",
      "==========================================================================================\n",
      "Epoch [544/5000] | Time: 0.27s\n",
      "(Training) Loss: 984843.3044\n",
      "(Validation) Loss: 804332.1448, MAE: 3420.9961, R2: 0.1827\n",
      "==========================================================================================\n",
      "Epoch [545/5000] | Time: 0.24s\n",
      "(Training) Loss: 988618.0238\n",
      "(Validation) Loss: 804295.7759, MAE: 3416.6758, R2: 0.1827\n",
      "==========================================================================================\n",
      "Epoch [546/5000] | Time: 0.28s\n",
      "(Training) Loss: 989631.9226\n",
      "(Validation) Loss: 804197.7181, MAE: 3418.8936, R2: 0.1828\n",
      "==========================================================================================\n",
      "Epoch [547/5000] | Time: 0.28s\n",
      "(Training) Loss: 990410.3629\n",
      "(Validation) Loss: 804078.3346, MAE: 3413.7463, R2: 0.1829\n",
      "==========================================================================================\n",
      "Epoch [548/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001103.7316\n",
      "(Validation) Loss: 803974.5689, MAE: 3413.0718, R2: 0.1830\n",
      "==========================================================================================\n",
      "Epoch [549/5000] | Time: 0.24s\n",
      "(Training) Loss: 999626.2887\n",
      "(Validation) Loss: 803871.5194, MAE: 3414.2170, R2: 0.1831\n",
      "==========================================================================================\n",
      "Epoch [550/5000] | Time: 0.25s\n",
      "(Training) Loss: 994496.1783\n",
      "(Validation) Loss: 803766.7397, MAE: 3413.9983, R2: 0.1832\n",
      "==========================================================================================\n",
      "Epoch [551/5000] | Time: 0.22s\n",
      "(Training) Loss: 1030340.1580\n",
      "(Validation) Loss: 803659.4667, MAE: 3413.1150, R2: 0.1833\n",
      "==========================================================================================\n",
      "Epoch [552/5000] | Time: 0.27s\n",
      "(Training) Loss: 990282.3832\n",
      "(Validation) Loss: 803557.2387, MAE: 3416.7747, R2: 0.1834\n",
      "==========================================================================================\n",
      "Epoch [553/5000] | Time: 0.24s\n",
      "(Training) Loss: 995135.8046\n",
      "(Validation) Loss: 803444.4248, MAE: 3412.6001, R2: 0.1835\n",
      "==========================================================================================\n",
      "Epoch [554/5000] | Time: 0.23s\n",
      "(Training) Loss: 991310.1263\n",
      "(Validation) Loss: 803347.4819, MAE: 3414.0342, R2: 0.1836\n",
      "==========================================================================================\n",
      "Epoch [555/5000] | Time: 0.26s\n",
      "(Training) Loss: 991968.5038\n",
      "(Validation) Loss: 803225.5765, MAE: 3410.3318, R2: 0.1838\n",
      "==========================================================================================\n",
      "Epoch [556/5000] | Time: 0.28s\n",
      "(Training) Loss: 1007877.5393\n",
      "(Validation) Loss: 803129.0584, MAE: 3411.6299, R2: 0.1839\n",
      "==========================================================================================\n",
      "Epoch [557/5000] | Time: 0.25s\n",
      "(Training) Loss: 1019346.6193\n",
      "(Validation) Loss: 803039.9594, MAE: 3417.8132, R2: 0.1840\n",
      "==========================================================================================\n",
      "Epoch [558/5000] | Time: 0.26s\n",
      "(Training) Loss: 991628.7868\n",
      "(Validation) Loss: 802913.7651, MAE: 3411.6763, R2: 0.1841\n",
      "==========================================================================================\n",
      "Epoch [559/5000] | Time: 0.27s\n",
      "(Training) Loss: 990252.1745\n",
      "(Validation) Loss: 802815.3854, MAE: 3410.8608, R2: 0.1842\n",
      "==========================================================================================\n",
      "Epoch [560/5000] | Time: 0.27s\n",
      "(Training) Loss: 1006937.5533\n",
      "(Validation) Loss: 802705.1149, MAE: 3413.1704, R2: 0.1843\n",
      "==========================================================================================\n",
      "Epoch [561/5000] | Time: 0.22s\n",
      "(Training) Loss: 987695.4061\n",
      "(Validation) Loss: 802593.1175, MAE: 3409.5061, R2: 0.1844\n",
      "==========================================================================================\n",
      "Epoch [562/5000] | Time: 0.21s\n",
      "(Training) Loss: 1015263.3763\n",
      "(Validation) Loss: 802489.8502, MAE: 3410.5701, R2: 0.1845\n",
      "==========================================================================================\n",
      "Epoch [563/5000] | Time: 0.29s\n",
      "(Training) Loss: 984730.5289\n",
      "(Validation) Loss: 802387.7562, MAE: 3409.3721, R2: 0.1846\n",
      "==========================================================================================\n",
      "Epoch [564/5000] | Time: 0.26s\n",
      "(Training) Loss: 1007900.3636\n",
      "(Validation) Loss: 802266.6311, MAE: 3406.1616, R2: 0.1847\n",
      "==========================================================================================\n",
      "Epoch [565/5000] | Time: 0.25s\n",
      "(Training) Loss: 994882.0977\n",
      "(Validation) Loss: 802162.4178, MAE: 3405.8347, R2: 0.1848\n",
      "==========================================================================================\n",
      "Epoch [566/5000] | Time: 0.25s\n",
      "(Training) Loss: 997418.8312\n",
      "(Validation) Loss: 802070.8419, MAE: 3410.5791, R2: 0.1849\n",
      "==========================================================================================\n",
      "Epoch [567/5000] | Time: 0.30s\n",
      "(Training) Loss: 996335.0412\n",
      "(Validation) Loss: 801958.6927, MAE: 3408.6426, R2: 0.1850\n",
      "==========================================================================================\n",
      "Epoch [568/5000] | Time: 0.30s\n",
      "(Training) Loss: 983205.8122\n",
      "(Validation) Loss: 801876.5829, MAE: 3414.8936, R2: 0.1851\n",
      "==========================================================================================\n",
      "Epoch [569/5000] | Time: 0.27s\n",
      "(Training) Loss: 990847.8604\n",
      "(Validation) Loss: 801757.8527, MAE: 3407.0898, R2: 0.1852\n",
      "==========================================================================================\n",
      "Epoch [570/5000] | Time: 0.26s\n",
      "(Training) Loss: 1014927.1726\n",
      "(Validation) Loss: 801670.0940, MAE: 3412.3616, R2: 0.1853\n",
      "==========================================================================================\n",
      "Epoch [571/5000] | Time: 0.26s\n",
      "(Training) Loss: 998399.5996\n",
      "(Validation) Loss: 801535.3092, MAE: 3404.6895, R2: 0.1855\n",
      "==========================================================================================\n",
      "Epoch [572/5000] | Time: 0.27s\n",
      "(Training) Loss: 985442.2836\n",
      "(Validation) Loss: 801437.4051, MAE: 3406.9580, R2: 0.1856\n",
      "==========================================================================================\n",
      "Epoch [573/5000] | Time: 0.26s\n",
      "(Training) Loss: 999114.2830\n",
      "(Validation) Loss: 801337.1219, MAE: 3406.1899, R2: 0.1857\n",
      "==========================================================================================\n",
      "Epoch [574/5000] | Time: 0.28s\n",
      "(Training) Loss: 988251.2836\n",
      "(Validation) Loss: 801208.4762, MAE: 3402.3359, R2: 0.1858\n",
      "==========================================================================================\n",
      "Epoch [575/5000] | Time: 0.23s\n",
      "(Training) Loss: 989022.2855\n",
      "(Validation) Loss: 801103.0857, MAE: 3401.8660, R2: 0.1859\n",
      "==========================================================================================\n",
      "Epoch [576/5000] | Time: 0.24s\n",
      "(Training) Loss: 992855.7824\n",
      "(Validation) Loss: 801002.3200, MAE: 3402.0442, R2: 0.1860\n",
      "==========================================================================================\n",
      "Epoch [577/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012366.8211\n",
      "(Validation) Loss: 800894.9029, MAE: 3401.4902, R2: 0.1861\n",
      "==========================================================================================\n",
      "Epoch [578/5000] | Time: 0.32s\n",
      "(Training) Loss: 1002243.9220\n",
      "(Validation) Loss: 800791.4914, MAE: 3401.8037, R2: 0.1862\n",
      "==========================================================================================\n",
      "Epoch [579/5000] | Time: 0.33s\n",
      "(Training) Loss: 1020416.2766\n",
      "(Validation) Loss: 800699.6527, MAE: 3411.2134, R2: 0.1863\n",
      "==========================================================================================\n",
      "Epoch [580/5000] | Time: 0.25s\n",
      "(Training) Loss: 1005427.2525\n",
      "(Validation) Loss: 800579.2952, MAE: 3403.0845, R2: 0.1864\n",
      "==========================================================================================\n",
      "Epoch [581/5000] | Time: 0.26s\n",
      "(Training) Loss: 1017243.4036\n",
      "(Validation) Loss: 800478.0584, MAE: 3401.6191, R2: 0.1865\n",
      "==========================================================================================\n",
      "Epoch [582/5000] | Time: 0.28s\n",
      "(Training) Loss: 998854.0381\n",
      "(Validation) Loss: 800382.5219, MAE: 3408.2642, R2: 0.1866\n",
      "==========================================================================================\n",
      "Epoch [583/5000] | Time: 0.26s\n",
      "(Training) Loss: 996147.2893\n",
      "(Validation) Loss: 800277.0305, MAE: 3403.1360, R2: 0.1867\n",
      "==========================================================================================\n",
      "Epoch [584/5000] | Time: 0.26s\n",
      "(Training) Loss: 982501.1837\n",
      "(Validation) Loss: 800155.8660, MAE: 3400.1248, R2: 0.1869\n",
      "==========================================================================================\n",
      "Epoch [585/5000] | Time: 0.24s\n",
      "(Training) Loss: 999396.7379\n",
      "(Validation) Loss: 800043.6095, MAE: 3397.6953, R2: 0.1870\n",
      "==========================================================================================\n",
      "Epoch [586/5000] | Time: 0.27s\n",
      "(Training) Loss: 982243.6694\n",
      "(Validation) Loss: 799942.0076, MAE: 3397.5442, R2: 0.1871\n",
      "==========================================================================================\n",
      "Epoch [587/5000] | Time: 0.26s\n",
      "(Training) Loss: 994164.6570\n",
      "(Validation) Loss: 799849.1752, MAE: 3400.7131, R2: 0.1872\n",
      "==========================================================================================\n",
      "Epoch [588/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001494.8668\n",
      "(Validation) Loss: 799774.8876, MAE: 3404.7537, R2: 0.1872\n",
      "==========================================================================================\n",
      "Epoch [589/5000] | Time: 0.29s\n",
      "(Training) Loss: 981924.1789\n",
      "(Validation) Loss: 799649.8229, MAE: 3403.7642, R2: 0.1874\n",
      "==========================================================================================\n",
      "Epoch [590/5000] | Time: 0.27s\n",
      "(Training) Loss: 995914.8566\n",
      "(Validation) Loss: 799529.4552, MAE: 3398.1113, R2: 0.1875\n",
      "==========================================================================================\n",
      "Epoch [591/5000] | Time: 0.25s\n",
      "(Training) Loss: 1004175.8934\n",
      "(Validation) Loss: 799421.6946, MAE: 3398.4285, R2: 0.1876\n",
      "==========================================================================================\n",
      "Epoch [592/5000] | Time: 0.31s\n",
      "(Training) Loss: 988489.3668\n",
      "(Validation) Loss: 799320.7200, MAE: 3399.3994, R2: 0.1877\n",
      "==========================================================================================\n",
      "Epoch [593/5000] | Time: 0.26s\n",
      "(Training) Loss: 1000975.7532\n",
      "(Validation) Loss: 799207.2495, MAE: 3395.9934, R2: 0.1878\n",
      "==========================================================================================\n",
      "Epoch [594/5000] | Time: 0.26s\n",
      "(Training) Loss: 985778.2621\n",
      "(Validation) Loss: 798980.3816, MAE: 3388.0166, R2: 0.1880\n",
      "==========================================================================================\n",
      "Epoch [595/5000] | Time: 0.26s\n",
      "(Training) Loss: 984732.7944\n",
      "(Validation) Loss: 799043.4971, MAE: 3415.1414, R2: 0.1880\n",
      "==========================================================================================\n",
      "Epoch [596/5000] | Time: 0.25s\n",
      "(Training) Loss: 980314.9216\n",
      "(Validation) Loss: 798775.4737, MAE: 3388.7888, R2: 0.1883\n",
      "==========================================================================================\n",
      "Epoch [597/5000] | Time: 0.26s\n",
      "(Training) Loss: 992694.6383\n",
      "(Validation) Loss: 798665.7670, MAE: 3387.7505, R2: 0.1884\n",
      "==========================================================================================\n",
      "Epoch [598/5000] | Time: 0.22s\n",
      "(Training) Loss: 997248.2741\n",
      "(Validation) Loss: 798562.1003, MAE: 3387.0085, R2: 0.1885\n",
      "==========================================================================================\n",
      "Epoch [599/5000] | Time: 0.24s\n",
      "(Training) Loss: 986569.5444\n",
      "(Validation) Loss: 798459.4502, MAE: 3384.9739, R2: 0.1886\n",
      "==========================================================================================\n",
      "Epoch [600/5000] | Time: 0.26s\n",
      "(Training) Loss: 998132.9270\n",
      "(Validation) Loss: 798346.2863, MAE: 3387.4438, R2: 0.1887\n",
      "==========================================================================================\n",
      "Epoch [601/5000] | Time: 0.24s\n",
      "(Training) Loss: 979004.0079\n",
      "(Validation) Loss: 798226.3283, MAE: 3382.8713, R2: 0.1888\n",
      "==========================================================================================\n",
      "Epoch [602/5000] | Time: 0.26s\n",
      "(Training) Loss: 1021333.5819\n",
      "(Validation) Loss: 798124.7879, MAE: 3382.2156, R2: 0.1889\n",
      "==========================================================================================\n",
      "Epoch [603/5000] | Time: 0.27s\n",
      "(Training) Loss: 989374.6431\n",
      "(Validation) Loss: 798041.3098, MAE: 3387.3650, R2: 0.1890\n",
      "==========================================================================================\n",
      "Epoch [604/5000] | Time: 0.27s\n",
      "(Training) Loss: 986027.2944\n",
      "(Validation) Loss: 797937.9022, MAE: 3386.3735, R2: 0.1891\n",
      "==========================================================================================\n",
      "Epoch [605/5000] | Time: 0.27s\n",
      "(Training) Loss: 1002620.8687\n",
      "(Validation) Loss: 797824.2559, MAE: 3384.7661, R2: 0.1892\n",
      "==========================================================================================\n",
      "Epoch [606/5000] | Time: 0.26s\n",
      "(Training) Loss: 997939.3864\n",
      "(Validation) Loss: 797709.7314, MAE: 3381.3235, R2: 0.1893\n",
      "==========================================================================================\n",
      "Epoch [607/5000] | Time: 0.21s\n",
      "(Training) Loss: 990174.4854\n",
      "(Validation) Loss: 797616.7790, MAE: 3384.2644, R2: 0.1894\n",
      "==========================================================================================\n",
      "Epoch [608/5000] | Time: 0.24s\n",
      "(Training) Loss: 992592.9556\n",
      "(Validation) Loss: 797505.0686, MAE: 3383.0381, R2: 0.1895\n",
      "==========================================================================================\n",
      "Epoch [609/5000] | Time: 0.26s\n",
      "(Training) Loss: 981242.5286\n",
      "(Validation) Loss: 797413.9683, MAE: 3383.7004, R2: 0.1896\n",
      "==========================================================================================\n",
      "Epoch [610/5000] | Time: 0.24s\n",
      "(Training) Loss: 987577.3211\n",
      "(Validation) Loss: 797376.8152, MAE: 3396.1924, R2: 0.1897\n",
      "==========================================================================================\n",
      "Epoch [611/5000] | Time: 0.30s\n",
      "(Training) Loss: 983530.6148\n",
      "(Validation) Loss: 797224.7213, MAE: 3389.8552, R2: 0.1898\n",
      "==========================================================================================\n",
      "Epoch [612/5000] | Time: 0.25s\n",
      "(Training) Loss: 995704.5996\n",
      "(Validation) Loss: 797071.9092, MAE: 3378.3035, R2: 0.1900\n",
      "==========================================================================================\n",
      "Epoch [613/5000] | Time: 0.24s\n",
      "(Training) Loss: 983875.0774\n",
      "(Validation) Loss: 790439.9295, MAE: 3355.8254, R2: 0.1966\n",
      "==========================================================================================\n",
      "Epoch [614/5000] | Time: 0.21s\n",
      "(Training) Loss: 970980.2062\n",
      "(Validation) Loss: 790331.4686, MAE: 3353.5718, R2: 0.1967\n",
      "==========================================================================================\n",
      "Epoch [615/5000] | Time: 0.25s\n",
      "(Training) Loss: 975094.1472\n",
      "(Validation) Loss: 790222.3054, MAE: 3351.3750, R2: 0.1969\n",
      "==========================================================================================\n",
      "Epoch [616/5000] | Time: 0.24s\n",
      "(Training) Loss: 974393.9518\n",
      "(Validation) Loss: 790127.1149, MAE: 3352.4958, R2: 0.1970\n",
      "==========================================================================================\n",
      "Epoch [617/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008460.8369\n",
      "(Validation) Loss: 790033.5860, MAE: 3355.3196, R2: 0.1971\n",
      "==========================================================================================\n",
      "Epoch [618/5000] | Time: 0.22s\n",
      "(Training) Loss: 975551.0679\n",
      "(Validation) Loss: 789921.6622, MAE: 3351.8274, R2: 0.1972\n",
      "==========================================================================================\n",
      "Epoch [619/5000] | Time: 0.24s\n",
      "(Training) Loss: 992539.6992\n",
      "(Validation) Loss: 789819.5448, MAE: 3352.9607, R2: 0.1973\n",
      "==========================================================================================\n",
      "Epoch [620/5000] | Time: 0.25s\n",
      "(Training) Loss: 972546.6967\n",
      "(Validation) Loss: 789717.7168, MAE: 3349.9153, R2: 0.1974\n",
      "==========================================================================================\n",
      "Epoch [621/5000] | Time: 0.25s\n",
      "(Training) Loss: 981036.0476\n",
      "(Validation) Loss: 789638.5822, MAE: 3352.9790, R2: 0.1974\n",
      "==========================================================================================\n",
      "Epoch [622/5000] | Time: 0.22s\n",
      "(Training) Loss: 969353.7890\n",
      "(Validation) Loss: 789538.5975, MAE: 3353.0854, R2: 0.1975\n",
      "==========================================================================================\n",
      "Epoch [623/5000] | Time: 0.24s\n",
      "(Training) Loss: 978805.9258\n",
      "(Validation) Loss: 789417.6590, MAE: 3348.3223, R2: 0.1977\n",
      "==========================================================================================\n",
      "Epoch [624/5000] | Time: 0.24s\n",
      "(Training) Loss: 980553.4277\n",
      "(Validation) Loss: 789312.1098, MAE: 3347.2603, R2: 0.1978\n",
      "==========================================================================================\n",
      "Epoch [625/5000] | Time: 0.29s\n",
      "(Training) Loss: 987207.8680\n",
      "(Validation) Loss: 789218.8140, MAE: 3348.4734, R2: 0.1979\n",
      "==========================================================================================\n",
      "Epoch [626/5000] | Time: 0.27s\n",
      "(Training) Loss: 969070.2548\n",
      "(Validation) Loss: 789123.1168, MAE: 3350.7615, R2: 0.1980\n",
      "==========================================================================================\n",
      "Epoch [627/5000] | Time: 0.29s\n",
      "(Training) Loss: 1004794.4448\n",
      "(Validation) Loss: 789016.9467, MAE: 3347.3115, R2: 0.1981\n",
      "==========================================================================================\n",
      "Epoch [628/5000] | Time: 0.27s\n",
      "(Training) Loss: 977816.2544\n",
      "(Validation) Loss: 788917.9333, MAE: 3347.7163, R2: 0.1982\n",
      "==========================================================================================\n",
      "Epoch [629/5000] | Time: 0.24s\n",
      "(Training) Loss: 990536.2113\n",
      "(Validation) Loss: 788821.3016, MAE: 3347.7322, R2: 0.1983\n",
      "==========================================================================================\n",
      "Epoch [630/5000] | Time: 0.27s\n",
      "(Training) Loss: 991841.7874\n",
      "(Validation) Loss: 788720.1695, MAE: 3348.3394, R2: 0.1984\n",
      "==========================================================================================\n",
      "Epoch [631/5000] | Time: 0.21s\n",
      "(Training) Loss: 982833.9873\n",
      "(Validation) Loss: 788614.6114, MAE: 3347.1287, R2: 0.1985\n",
      "==========================================================================================\n",
      "Epoch [632/5000] | Time: 0.27s\n",
      "(Training) Loss: 989903.3591\n",
      "(Validation) Loss: 788502.2540, MAE: 3344.2297, R2: 0.1986\n",
      "==========================================================================================\n",
      "Epoch [633/5000] | Time: 0.27s\n",
      "(Training) Loss: 986451.6815\n",
      "(Validation) Loss: 788405.1200, MAE: 3344.6406, R2: 0.1987\n",
      "==========================================================================================\n",
      "Epoch [634/5000] | Time: 0.21s\n",
      "(Training) Loss: 1002472.0539\n",
      "(Validation) Loss: 788306.9771, MAE: 3344.9121, R2: 0.1988\n",
      "==========================================================================================\n",
      "Epoch [635/5000] | Time: 0.25s\n",
      "(Training) Loss: 980820.7925\n",
      "(Validation) Loss: 788200.1968, MAE: 3343.4438, R2: 0.1989\n",
      "==========================================================================================\n",
      "Epoch [636/5000] | Time: 0.34s\n",
      "(Training) Loss: 980517.8287\n",
      "(Validation) Loss: 788092.3156, MAE: 3342.4451, R2: 0.1990\n",
      "==========================================================================================\n",
      "Epoch [637/5000] | Time: 0.30s\n",
      "(Training) Loss: 987509.5723\n",
      "(Validation) Loss: 788006.1956, MAE: 3345.6660, R2: 0.1991\n",
      "==========================================================================================\n",
      "Epoch [638/5000] | Time: 0.26s\n",
      "(Training) Loss: 983451.2716\n",
      "(Validation) Loss: 787909.0260, MAE: 3346.2251, R2: 0.1992\n",
      "==========================================================================================\n",
      "Epoch [639/5000] | Time: 0.22s\n",
      "(Training) Loss: 992170.0317\n",
      "(Validation) Loss: 787800.7397, MAE: 3344.9517, R2: 0.1993\n",
      "==========================================================================================\n",
      "Epoch [640/5000] | Time: 0.24s\n",
      "(Training) Loss: 985227.8937\n",
      "(Validation) Loss: 787700.3181, MAE: 3345.0088, R2: 0.1994\n",
      "==========================================================================================\n",
      "Epoch [641/5000] | Time: 0.26s\n",
      "(Training) Loss: 979530.4385\n",
      "(Validation) Loss: 787593.4121, MAE: 3340.7549, R2: 0.1995\n",
      "==========================================================================================\n",
      "Epoch [642/5000] | Time: 0.26s\n",
      "(Training) Loss: 977383.6897\n",
      "(Validation) Loss: 787488.7784, MAE: 3339.8914, R2: 0.1996\n",
      "==========================================================================================\n",
      "Epoch [643/5000] | Time: 0.21s\n",
      "(Training) Loss: 981950.0615\n",
      "(Validation) Loss: 787390.9816, MAE: 3340.7908, R2: 0.1997\n",
      "==========================================================================================\n",
      "Epoch [644/5000] | Time: 0.21s\n",
      "(Training) Loss: 969154.9883\n",
      "(Validation) Loss: 787294.4463, MAE: 3340.8777, R2: 0.1998\n",
      "==========================================================================================\n",
      "Epoch [645/5000] | Time: 0.25s\n",
      "(Training) Loss: 973646.6586\n",
      "(Validation) Loss: 787205.6857, MAE: 3342.0588, R2: 0.1999\n",
      "==========================================================================================\n",
      "Epoch [646/5000] | Time: 0.26s\n",
      "(Training) Loss: 978577.2183\n",
      "(Validation) Loss: 787094.6146, MAE: 3340.9661, R2: 0.2000\n",
      "==========================================================================================\n",
      "Epoch [647/5000] | Time: 0.25s\n",
      "(Training) Loss: 966071.8805\n",
      "(Validation) Loss: 786999.7638, MAE: 3341.9453, R2: 0.2001\n",
      "==========================================================================================\n",
      "Epoch [648/5000] | Time: 0.22s\n",
      "(Training) Loss: 965136.0084\n",
      "(Validation) Loss: 786901.5149, MAE: 3345.7412, R2: 0.2002\n",
      "==========================================================================================\n",
      "Epoch [649/5000] | Time: 0.23s\n",
      "(Training) Loss: 971475.7487\n",
      "(Validation) Loss: 786789.6146, MAE: 3337.9692, R2: 0.2003\n",
      "==========================================================================================\n",
      "Epoch [650/5000] | Time: 0.29s\n",
      "(Training) Loss: 970227.2240\n",
      "(Validation) Loss: 786694.5581, MAE: 3339.6587, R2: 0.2004\n",
      "==========================================================================================\n",
      "Epoch [651/5000] | Time: 0.24s\n",
      "(Training) Loss: 982383.5673\n",
      "(Validation) Loss: 786602.2248, MAE: 3342.6321, R2: 0.2005\n",
      "==========================================================================================\n",
      "Epoch [652/5000] | Time: 0.31s\n",
      "(Training) Loss: 975861.0590\n",
      "(Validation) Loss: 786515.5422, MAE: 3341.6914, R2: 0.2006\n",
      "==========================================================================================\n",
      "Epoch [653/5000] | Time: 0.21s\n",
      "(Training) Loss: 965631.6260\n",
      "(Validation) Loss: 786387.9441, MAE: 3336.3655, R2: 0.2007\n",
      "==========================================================================================\n",
      "Epoch [654/5000] | Time: 0.24s\n",
      "(Training) Loss: 999810.0952\n",
      "(Validation) Loss: 786289.2108, MAE: 3335.6885, R2: 0.2008\n",
      "==========================================================================================\n",
      "Epoch [655/5000] | Time: 0.28s\n",
      "(Training) Loss: 968165.8826\n",
      "(Validation) Loss: 786189.6013, MAE: 3339.1599, R2: 0.2009\n",
      "==========================================================================================\n",
      "Epoch [656/5000] | Time: 0.24s\n",
      "(Training) Loss: 970834.5206\n",
      "(Validation) Loss: 786090.9359, MAE: 3337.6572, R2: 0.2010\n",
      "==========================================================================================\n",
      "Epoch [657/5000] | Time: 0.25s\n",
      "(Training) Loss: 981683.4188\n",
      "(Validation) Loss: 785999.5492, MAE: 3336.8201, R2: 0.2011\n",
      "==========================================================================================\n",
      "Epoch [658/5000] | Time: 0.24s\n",
      "(Training) Loss: 991268.9454\n",
      "(Validation) Loss: 785882.7086, MAE: 3337.1882, R2: 0.2012\n",
      "==========================================================================================\n",
      "Epoch [659/5000] | Time: 0.27s\n",
      "(Training) Loss: 977180.5780\n",
      "(Validation) Loss: 785800.9314, MAE: 3338.4543, R2: 0.2013\n",
      "==========================================================================================\n",
      "Epoch [660/5000] | Time: 0.24s\n",
      "(Training) Loss: 975621.4334\n",
      "(Validation) Loss: 797396.7479, MAE: 3383.9602, R2: 0.1896\n",
      "==========================================================================================\n",
      "Epoch [661/5000] | Time: 0.27s\n",
      "(Training) Loss: 979287.3058\n",
      "(Validation) Loss: 785579.1321, MAE: 3332.0496, R2: 0.2015\n",
      "==========================================================================================\n",
      "Epoch [662/5000] | Time: 0.26s\n",
      "(Training) Loss: 971241.8579\n",
      "(Validation) Loss: 785475.4578, MAE: 3331.3459, R2: 0.2016\n",
      "==========================================================================================\n",
      "Epoch [663/5000] | Time: 0.27s\n",
      "(Training) Loss: 986742.8909\n",
      "(Validation) Loss: 785498.9143, MAE: 3339.6938, R2: 0.2016\n",
      "==========================================================================================\n",
      "Epoch [664/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000046.7100\n",
      "(Validation) Loss: 785416.3124, MAE: 3351.2312, R2: 0.2017\n",
      "==========================================================================================\n",
      "Epoch [665/5000] | Time: 0.26s\n",
      "(Training) Loss: 992010.2760\n",
      "(Validation) Loss: 785292.9905, MAE: 3339.8062, R2: 0.2018\n",
      "==========================================================================================\n",
      "Epoch [666/5000] | Time: 0.28s\n",
      "(Training) Loss: 968874.9226\n",
      "(Validation) Loss: 785207.9702, MAE: 3341.6472, R2: 0.2019\n",
      "==========================================================================================\n",
      "Epoch [667/5000] | Time: 0.28s\n",
      "(Training) Loss: 968397.0327\n",
      "(Validation) Loss: 785090.1854, MAE: 3338.4189, R2: 0.2020\n",
      "==========================================================================================\n",
      "Epoch [668/5000] | Time: 0.28s\n",
      "(Training) Loss: 963279.0140\n",
      "(Validation) Loss: 785013.3937, MAE: 3342.0505, R2: 0.2021\n",
      "==========================================================================================\n",
      "Epoch [669/5000] | Time: 0.27s\n",
      "(Training) Loss: 976008.4898\n",
      "(Validation) Loss: 784904.0362, MAE: 3341.2158, R2: 0.2022\n",
      "==========================================================================================\n",
      "Epoch [670/5000] | Time: 0.25s\n",
      "(Training) Loss: 978429.6523\n",
      "(Validation) Loss: 784791.0133, MAE: 3337.8369, R2: 0.2023\n",
      "==========================================================================================\n",
      "Epoch [671/5000] | Time: 0.24s\n",
      "(Training) Loss: 970696.1624\n",
      "(Validation) Loss: 784689.1556, MAE: 3337.5774, R2: 0.2024\n",
      "==========================================================================================\n",
      "Epoch [672/5000] | Time: 0.25s\n",
      "(Training) Loss: 968910.4956\n",
      "(Validation) Loss: 784601.6229, MAE: 3338.9512, R2: 0.2025\n",
      "==========================================================================================\n",
      "Epoch [673/5000] | Time: 0.23s\n",
      "(Training) Loss: 977327.6434\n",
      "(Validation) Loss: 784492.1384, MAE: 3336.1499, R2: 0.2026\n",
      "==========================================================================================\n",
      "Epoch [674/5000] | Time: 0.21s\n",
      "(Training) Loss: 963170.7793\n",
      "(Validation) Loss: 784394.2838, MAE: 3337.3513, R2: 0.2027\n",
      "==========================================================================================\n",
      "Epoch [675/5000] | Time: 0.25s\n",
      "(Training) Loss: 978639.1193\n",
      "(Validation) Loss: 784287.3448, MAE: 3334.9504, R2: 0.2028\n",
      "==========================================================================================\n",
      "Epoch [676/5000] | Time: 0.24s\n",
      "(Training) Loss: 965007.1720\n",
      "(Validation) Loss: 781437.5892, MAE: 3324.8953, R2: 0.2057\n",
      "==========================================================================================\n",
      "Epoch [677/5000] | Time: 0.23s\n",
      "(Training) Loss: 976710.6624\n",
      "(Validation) Loss: 781337.7003, MAE: 3322.6045, R2: 0.2058\n",
      "==========================================================================================\n",
      "Epoch [678/5000] | Time: 0.24s\n",
      "(Training) Loss: 975212.7462\n",
      "(Validation) Loss: 781247.9314, MAE: 3324.3000, R2: 0.2059\n",
      "==========================================================================================\n",
      "Epoch [679/5000] | Time: 0.25s\n",
      "(Training) Loss: 973462.4340\n",
      "(Validation) Loss: 781139.1854, MAE: 3320.8264, R2: 0.2060\n",
      "==========================================================================================\n",
      "Epoch [680/5000] | Time: 0.23s\n",
      "(Training) Loss: 988500.1091\n",
      "(Validation) Loss: 781051.2032, MAE: 3322.3572, R2: 0.2061\n",
      "==========================================================================================\n",
      "Epoch [681/5000] | Time: 0.25s\n",
      "(Training) Loss: 987648.6796\n",
      "(Validation) Loss: 780904.3238, MAE: 3318.1172, R2: 0.2062\n",
      "==========================================================================================\n",
      "Epoch [682/5000] | Time: 0.24s\n",
      "(Training) Loss: 960532.9375\n",
      "(Validation) Loss: 780768.9543, MAE: 3319.1895, R2: 0.2064\n",
      "==========================================================================================\n",
      "Epoch [683/5000] | Time: 0.23s\n",
      "(Training) Loss: 984283.7494\n",
      "(Validation) Loss: 780640.7206, MAE: 3313.9756, R2: 0.2065\n",
      "==========================================================================================\n",
      "Epoch [684/5000] | Time: 0.26s\n",
      "(Training) Loss: 967469.6599\n",
      "(Validation) Loss: 780532.2794, MAE: 3312.8542, R2: 0.2066\n",
      "==========================================================================================\n",
      "Epoch [685/5000] | Time: 0.24s\n",
      "(Training) Loss: 986954.5952\n",
      "(Validation) Loss: 782854.8114, MAE: 3328.0435, R2: 0.2043\n",
      "==========================================================================================\n",
      "Epoch [686/5000] | Time: 0.22s\n",
      "(Training) Loss: 967454.4962\n",
      "(Validation) Loss: 782731.9467, MAE: 3325.9121, R2: 0.2044\n",
      "==========================================================================================\n",
      "Epoch [687/5000] | Time: 0.24s\n",
      "(Training) Loss: 970888.4949\n",
      "(Validation) Loss: 782639.1625, MAE: 3329.1890, R2: 0.2045\n",
      "==========================================================================================\n",
      "Epoch [688/5000] | Time: 0.22s\n",
      "(Training) Loss: 975484.9499\n",
      "(Validation) Loss: 782532.2902, MAE: 3327.5273, R2: 0.2046\n",
      "==========================================================================================\n",
      "Epoch [689/5000] | Time: 0.27s\n",
      "(Training) Loss: 974573.5761\n",
      "(Validation) Loss: 782415.6768, MAE: 3324.1213, R2: 0.2047\n",
      "==========================================================================================\n",
      "Epoch [690/5000] | Time: 0.24s\n",
      "(Training) Loss: 984554.9429\n",
      "(Validation) Loss: 782313.2959, MAE: 3323.6382, R2: 0.2048\n",
      "==========================================================================================\n",
      "Epoch [691/5000] | Time: 0.25s\n",
      "(Training) Loss: 969313.4048\n",
      "(Validation) Loss: 782222.1537, MAE: 3329.0413, R2: 0.2049\n",
      "==========================================================================================\n",
      "Epoch [692/5000] | Time: 0.25s\n",
      "(Training) Loss: 976696.0298\n",
      "(Validation) Loss: 782116.7714, MAE: 3326.6228, R2: 0.2050\n",
      "==========================================================================================\n",
      "Epoch [693/5000] | Time: 0.22s\n",
      "(Training) Loss: 971010.7703\n",
      "(Validation) Loss: 782005.8267, MAE: 3323.1477, R2: 0.2051\n",
      "==========================================================================================\n",
      "Epoch [694/5000] | Time: 0.25s\n",
      "(Training) Loss: 983601.9334\n",
      "(Validation) Loss: 781559.7987, MAE: 3322.5933, R2: 0.2056\n",
      "==========================================================================================\n",
      "Epoch [695/5000] | Time: 0.24s\n",
      "(Training) Loss: 961522.4813\n",
      "(Validation) Loss: 781453.5987, MAE: 3321.8174, R2: 0.2057\n",
      "==========================================================================================\n",
      "Epoch [696/5000] | Time: 0.24s\n",
      "(Training) Loss: 995719.5311\n",
      "(Validation) Loss: 781353.2679, MAE: 3319.7737, R2: 0.2058\n",
      "==========================================================================================\n",
      "Epoch [697/5000] | Time: 0.24s\n",
      "(Training) Loss: 962260.3411\n",
      "(Validation) Loss: 781253.9638, MAE: 3319.8601, R2: 0.2059\n",
      "==========================================================================================\n",
      "Epoch [698/5000] | Time: 0.24s\n",
      "(Training) Loss: 974746.5133\n",
      "(Validation) Loss: 781153.5848, MAE: 3319.1184, R2: 0.2060\n",
      "==========================================================================================\n",
      "Epoch [699/5000] | Time: 0.25s\n",
      "(Training) Loss: 988689.4327\n",
      "(Validation) Loss: 781054.0616, MAE: 3317.9263, R2: 0.2061\n",
      "==========================================================================================\n",
      "Epoch [700/5000] | Time: 0.30s\n",
      "(Training) Loss: 977538.9016\n",
      "(Validation) Loss: 780968.0121, MAE: 3321.2971, R2: 0.2062\n",
      "==========================================================================================\n",
      "Epoch [701/5000] | Time: 0.27s\n",
      "(Training) Loss: 974143.6434\n",
      "(Validation) Loss: 780870.6787, MAE: 3320.8069, R2: 0.2063\n",
      "==========================================================================================\n",
      "Epoch [702/5000] | Time: 0.25s\n",
      "(Training) Loss: 975592.1421\n",
      "(Validation) Loss: 780773.5257, MAE: 3320.9761, R2: 0.2064\n",
      "==========================================================================================\n",
      "Epoch [703/5000] | Time: 0.25s\n",
      "(Training) Loss: 980118.6942\n",
      "(Validation) Loss: 780672.1403, MAE: 3319.7368, R2: 0.2065\n",
      "==========================================================================================\n",
      "Epoch [704/5000] | Time: 0.31s\n",
      "(Training) Loss: 971203.8763\n",
      "(Validation) Loss: 780565.3308, MAE: 3319.3679, R2: 0.2066\n",
      "==========================================================================================\n",
      "Epoch [705/5000] | Time: 0.26s\n",
      "(Training) Loss: 978978.8636\n",
      "(Validation) Loss: 780476.2451, MAE: 3319.4470, R2: 0.2067\n",
      "==========================================================================================\n",
      "Epoch [706/5000] | Time: 0.26s\n",
      "(Training) Loss: 967681.0736\n",
      "(Validation) Loss: 780367.3644, MAE: 3317.6550, R2: 0.2068\n",
      "==========================================================================================\n",
      "Epoch [707/5000] | Time: 0.23s\n",
      "(Training) Loss: 971608.8395\n",
      "(Validation) Loss: 780272.2819, MAE: 3321.5388, R2: 0.2069\n",
      "==========================================================================================\n",
      "Epoch [708/5000] | Time: 0.25s\n",
      "(Training) Loss: 978711.8788\n",
      "(Validation) Loss: 780187.7397, MAE: 3321.5791, R2: 0.2070\n",
      "==========================================================================================\n",
      "Epoch [709/5000] | Time: 0.22s\n",
      "(Training) Loss: 960166.5511\n",
      "(Validation) Loss: 780086.0597, MAE: 3320.1875, R2: 0.2071\n",
      "==========================================================================================\n",
      "Epoch [710/5000] | Time: 0.23s\n",
      "(Training) Loss: 978108.0343\n",
      "(Validation) Loss: 779975.0692, MAE: 3316.4111, R2: 0.2072\n",
      "==========================================================================================\n",
      "Epoch [711/5000] | Time: 0.20s\n",
      "(Training) Loss: 981464.8255\n",
      "(Validation) Loss: 779898.1257, MAE: 3318.9683, R2: 0.2073\n",
      "==========================================================================================\n",
      "Epoch [712/5000] | Time: 0.22s\n",
      "(Training) Loss: 963867.9067\n",
      "(Validation) Loss: 779798.0546, MAE: 3318.1543, R2: 0.2074\n",
      "==========================================================================================\n",
      "Epoch [713/5000] | Time: 0.21s\n",
      "(Training) Loss: 968528.2462\n",
      "(Validation) Loss: 782421.7232, MAE: 3324.3608, R2: 0.2047\n",
      "==========================================================================================\n",
      "Epoch [714/5000] | Time: 0.22s\n",
      "(Training) Loss: 961740.2091\n",
      "(Validation) Loss: 782314.6133, MAE: 3324.4248, R2: 0.2048\n",
      "==========================================================================================\n",
      "Epoch [715/5000] | Time: 0.23s\n",
      "(Training) Loss: 979054.6821\n",
      "(Validation) Loss: 782228.4832, MAE: 3327.7991, R2: 0.2049\n",
      "==========================================================================================\n",
      "Epoch [716/5000] | Time: 0.23s\n",
      "(Training) Loss: 991283.8319\n",
      "(Validation) Loss: 782114.0070, MAE: 3323.7866, R2: 0.2050\n",
      "==========================================================================================\n",
      "Epoch [717/5000] | Time: 0.24s\n",
      "(Training) Loss: 959974.6510\n",
      "(Validation) Loss: 760996.2863, MAE: 3255.6699, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [718/5000] | Time: 0.23s\n",
      "(Training) Loss: 947722.6402\n",
      "(Validation) Loss: 760872.1105, MAE: 3244.4819, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [719/5000] | Time: 0.24s\n",
      "(Training) Loss: 947522.6129\n",
      "(Validation) Loss: 760791.3638, MAE: 3248.1223, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [720/5000] | Time: 0.22s\n",
      "(Training) Loss: 947276.8522\n",
      "(Validation) Loss: 760713.2260, MAE: 3251.4006, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [721/5000] | Time: 0.21s\n",
      "(Training) Loss: 949825.2443\n",
      "(Validation) Loss: 760655.0032, MAE: 3257.6482, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [722/5000] | Time: 0.24s\n",
      "(Training) Loss: 940809.8997\n",
      "(Validation) Loss: 760527.6019, MAE: 3251.6069, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [723/5000] | Time: 0.26s\n",
      "(Training) Loss: 960865.7659\n",
      "(Validation) Loss: 760456.9117, MAE: 3254.6575, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [724/5000] | Time: 0.25s\n",
      "(Training) Loss: 952496.1428\n",
      "(Validation) Loss: 760320.1003, MAE: 3249.5811, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [725/5000] | Time: 0.27s\n",
      "(Training) Loss: 961469.1076\n",
      "(Validation) Loss: 760217.1429, MAE: 3246.0129, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [726/5000] | Time: 0.23s\n",
      "(Training) Loss: 950867.2900\n",
      "(Validation) Loss: 760121.3765, MAE: 3247.2466, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [727/5000] | Time: 0.20s\n",
      "(Training) Loss: 938949.8693\n",
      "(Validation) Loss: 760011.0648, MAE: 3243.8032, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [728/5000] | Time: 0.26s\n",
      "(Training) Loss: 948690.5444\n",
      "(Validation) Loss: 759912.4857, MAE: 3242.3931, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [729/5000] | Time: 0.23s\n",
      "(Training) Loss: 953661.9378\n",
      "(Validation) Loss: 759814.3295, MAE: 3241.9617, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [730/5000] | Time: 0.22s\n",
      "(Training) Loss: 937999.1037\n",
      "(Validation) Loss: 759750.7111, MAE: 3247.8774, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [731/5000] | Time: 0.21s\n",
      "(Training) Loss: 936069.0690\n",
      "(Validation) Loss: 759634.4762, MAE: 3241.8772, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [732/5000] | Time: 0.20s\n",
      "(Training) Loss: 941167.6916\n",
      "(Validation) Loss: 759545.5917, MAE: 3245.0061, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [733/5000] | Time: 0.22s\n",
      "(Training) Loss: 950757.4962\n",
      "(Validation) Loss: 759440.1568, MAE: 3242.2876, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [734/5000] | Time: 0.24s\n",
      "(Training) Loss: 949609.9137\n",
      "(Validation) Loss: 759338.9486, MAE: 3239.3718, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [735/5000] | Time: 0.23s\n",
      "(Training) Loss: 945696.0063\n",
      "(Validation) Loss: 759243.5454, MAE: 3239.7686, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [736/5000] | Time: 0.23s\n",
      "(Training) Loss: 934391.5382\n",
      "(Validation) Loss: 759166.0565, MAE: 3244.2520, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [737/5000] | Time: 0.23s\n",
      "(Training) Loss: 944589.9562\n",
      "(Validation) Loss: 759070.1010, MAE: 3243.5432, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [738/5000] | Time: 0.22s\n",
      "(Training) Loss: 941847.1304\n",
      "(Validation) Loss: 758976.6832, MAE: 3244.3315, R2: 0.2283\n",
      "==========================================================================================\n",
      "Epoch [739/5000] | Time: 0.22s\n",
      "(Training) Loss: 944959.9226\n",
      "(Validation) Loss: 758868.4762, MAE: 3239.4949, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [740/5000] | Time: 0.21s\n",
      "(Training) Loss: 946556.7138\n",
      "(Validation) Loss: 758791.0451, MAE: 3239.8945, R2: 0.2285\n",
      "==========================================================================================\n",
      "Epoch [741/5000] | Time: 0.21s\n",
      "(Training) Loss: 939690.5869\n",
      "(Validation) Loss: 758700.9460, MAE: 3241.5508, R2: 0.2286\n",
      "==========================================================================================\n",
      "Epoch [742/5000] | Time: 0.22s\n",
      "(Training) Loss: 937202.1072\n",
      "(Validation) Loss: 758604.1283, MAE: 3240.8616, R2: 0.2287\n",
      "==========================================================================================\n",
      "Epoch [743/5000] | Time: 0.22s\n",
      "(Training) Loss: 953118.8407\n",
      "(Validation) Loss: 758519.3956, MAE: 3242.6807, R2: 0.2288\n",
      "==========================================================================================\n",
      "Epoch [744/5000] | Time: 0.22s\n",
      "(Training) Loss: 941266.4239\n",
      "(Validation) Loss: 758409.3460, MAE: 3239.0161, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [745/5000] | Time: 0.22s\n",
      "(Training) Loss: 939273.1675\n",
      "(Validation) Loss: 758317.9321, MAE: 3240.1248, R2: 0.2290\n",
      "==========================================================================================\n",
      "Epoch [746/5000] | Time: 0.23s\n",
      "(Training) Loss: 934699.0676\n",
      "(Validation) Loss: 758223.1829, MAE: 3239.7280, R2: 0.2291\n",
      "==========================================================================================\n",
      "Epoch [747/5000] | Time: 0.22s\n",
      "(Training) Loss: 941361.6358\n",
      "(Validation) Loss: 758136.0292, MAE: 3242.3909, R2: 0.2292\n",
      "==========================================================================================\n",
      "Epoch [748/5000] | Time: 0.25s\n",
      "(Training) Loss: 951409.3807\n",
      "(Validation) Loss: 758043.3733, MAE: 3241.6367, R2: 0.2293\n",
      "==========================================================================================\n",
      "Epoch [749/5000] | Time: 0.21s\n",
      "(Training) Loss: 955942.7300\n",
      "(Validation) Loss: 757931.7098, MAE: 3239.3762, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [750/5000] | Time: 0.21s\n",
      "(Training) Loss: 958722.0914\n",
      "(Validation) Loss: 757861.2641, MAE: 3244.1440, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [751/5000] | Time: 0.21s\n",
      "(Training) Loss: 972866.2418\n",
      "(Validation) Loss: 757751.5276, MAE: 3242.8501, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [752/5000] | Time: 0.22s\n",
      "(Training) Loss: 951202.3141\n",
      "(Validation) Loss: 753808.3092, MAE: 3223.7769, R2: 0.2335\n",
      "==========================================================================================\n",
      "Epoch [753/5000] | Time: 0.22s\n",
      "(Training) Loss: 946106.7411\n",
      "(Validation) Loss: 753719.9403, MAE: 3225.8506, R2: 0.2336\n",
      "==========================================================================================\n",
      "Epoch [754/5000] | Time: 0.23s\n",
      "(Training) Loss: 953012.9226\n",
      "(Validation) Loss: 768962.3143, MAE: 3273.2502, R2: 0.2183\n",
      "==========================================================================================\n",
      "Epoch [755/5000] | Time: 0.22s\n",
      "(Training) Loss: 952985.8553\n",
      "(Validation) Loss: 768872.3124, MAE: 3274.1409, R2: 0.2184\n",
      "==========================================================================================\n",
      "Epoch [756/5000] | Time: 0.23s\n",
      "(Training) Loss: 968475.7449\n",
      "(Validation) Loss: 768776.3727, MAE: 3274.8455, R2: 0.2185\n",
      "==========================================================================================\n",
      "Epoch [757/5000] | Time: 0.23s\n",
      "(Training) Loss: 945110.4746\n",
      "(Validation) Loss: 768691.0044, MAE: 3275.8701, R2: 0.2185\n",
      "==========================================================================================\n",
      "Epoch [758/5000] | Time: 0.24s\n",
      "(Training) Loss: 948880.9269\n",
      "(Validation) Loss: 768580.4229, MAE: 3273.0974, R2: 0.2186\n",
      "==========================================================================================\n",
      "Epoch [759/5000] | Time: 0.24s\n",
      "(Training) Loss: 964479.6415\n",
      "(Validation) Loss: 768480.0324, MAE: 3271.0889, R2: 0.2187\n",
      "==========================================================================================\n",
      "Epoch [760/5000] | Time: 0.23s\n",
      "(Training) Loss: 954239.3963\n",
      "(Validation) Loss: 768389.6159, MAE: 3274.4412, R2: 0.2188\n",
      "==========================================================================================\n",
      "Epoch [761/5000] | Time: 0.23s\n",
      "(Training) Loss: 970022.5019\n",
      "(Validation) Loss: 768285.4787, MAE: 3269.5876, R2: 0.2189\n",
      "==========================================================================================\n",
      "Epoch [762/5000] | Time: 0.26s\n",
      "(Training) Loss: 968309.7849\n",
      "(Validation) Loss: 768192.4470, MAE: 3271.5930, R2: 0.2190\n",
      "==========================================================================================\n",
      "Epoch [763/5000] | Time: 0.24s\n",
      "(Training) Loss: 943869.8210\n",
      "(Validation) Loss: 768095.9194, MAE: 3271.6450, R2: 0.2191\n",
      "==========================================================================================\n",
      "Epoch [764/5000] | Time: 0.23s\n",
      "(Training) Loss: 965246.3642\n",
      "(Validation) Loss: 768018.2425, MAE: 3272.7292, R2: 0.2192\n",
      "==========================================================================================\n",
      "Epoch [765/5000] | Time: 0.22s\n",
      "(Training) Loss: 963607.7608\n",
      "(Validation) Loss: 767916.7740, MAE: 3273.6746, R2: 0.2193\n",
      "==========================================================================================\n",
      "Epoch [766/5000] | Time: 0.22s\n",
      "(Training) Loss: 973220.0451\n",
      "(Validation) Loss: 767819.9962, MAE: 3275.7937, R2: 0.2194\n",
      "==========================================================================================\n",
      "Epoch [767/5000] | Time: 0.26s\n",
      "(Training) Loss: 943995.1589\n",
      "(Validation) Loss: 767706.2876, MAE: 3267.9038, R2: 0.2195\n",
      "==========================================================================================\n",
      "Epoch [768/5000] | Time: 0.22s\n",
      "(Training) Loss: 947722.2145\n",
      "(Validation) Loss: 767655.6121, MAE: 3279.8835, R2: 0.2196\n",
      "==========================================================================================\n",
      "Epoch [769/5000] | Time: 0.27s\n",
      "(Training) Loss: 955622.5025\n",
      "(Validation) Loss: 767570.5930, MAE: 3276.6331, R2: 0.2197\n",
      "==========================================================================================\n",
      "Epoch [770/5000] | Time: 0.24s\n",
      "(Training) Loss: 955796.9588\n",
      "(Validation) Loss: 767420.2235, MAE: 3268.4734, R2: 0.2198\n",
      "==========================================================================================\n",
      "Epoch [771/5000] | Time: 0.26s\n",
      "(Training) Loss: 946644.3791\n",
      "(Validation) Loss: 767337.7949, MAE: 3268.3252, R2: 0.2199\n",
      "==========================================================================================\n",
      "Epoch [772/5000] | Time: 0.25s\n",
      "(Training) Loss: 959039.4112\n",
      "(Validation) Loss: 767239.0921, MAE: 3267.6809, R2: 0.2200\n",
      "==========================================================================================\n",
      "Epoch [773/5000] | Time: 0.28s\n",
      "(Training) Loss: 948788.9657\n",
      "(Validation) Loss: 767145.1613, MAE: 3269.7126, R2: 0.2201\n",
      "==========================================================================================\n",
      "Epoch [774/5000] | Time: 0.25s\n",
      "(Training) Loss: 956307.2792\n",
      "(Validation) Loss: 767038.5403, MAE: 3265.8069, R2: 0.2202\n",
      "==========================================================================================\n",
      "Epoch [775/5000] | Time: 0.25s\n",
      "(Training) Loss: 955328.7963\n",
      "(Validation) Loss: 766938.8229, MAE: 3265.1726, R2: 0.2203\n",
      "==========================================================================================\n",
      "Epoch [776/5000] | Time: 0.26s\n",
      "(Training) Loss: 949151.7779\n",
      "(Validation) Loss: 766864.2337, MAE: 3268.9163, R2: 0.2204\n",
      "==========================================================================================\n",
      "Epoch [777/5000] | Time: 0.24s\n",
      "(Training) Loss: 943139.9344\n",
      "(Validation) Loss: 766745.7079, MAE: 3263.8855, R2: 0.2205\n",
      "==========================================================================================\n",
      "Epoch [778/5000] | Time: 0.23s\n",
      "(Training) Loss: 960257.5470\n",
      "(Validation) Loss: 766658.9416, MAE: 3265.1663, R2: 0.2206\n",
      "==========================================================================================\n",
      "Epoch [779/5000] | Time: 0.21s\n",
      "(Training) Loss: 972722.0879\n",
      "(Validation) Loss: 766557.2571, MAE: 3264.4460, R2: 0.2207\n",
      "==========================================================================================\n",
      "Epoch [780/5000] | Time: 0.24s\n",
      "(Training) Loss: 950414.7329\n",
      "(Validation) Loss: 766482.6495, MAE: 3268.0479, R2: 0.2208\n",
      "==========================================================================================\n",
      "Epoch [781/5000] | Time: 0.24s\n",
      "(Training) Loss: 959953.2430\n",
      "(Validation) Loss: 766405.0127, MAE: 3275.0442, R2: 0.2208\n",
      "==========================================================================================\n",
      "Epoch [782/5000] | Time: 0.22s\n",
      "(Training) Loss: 968853.2297\n",
      "(Validation) Loss: 766273.8514, MAE: 3266.0039, R2: 0.2210\n",
      "==========================================================================================\n",
      "Epoch [783/5000] | Time: 0.24s\n",
      "(Training) Loss: 943592.9654\n",
      "(Validation) Loss: 766169.3079, MAE: 3262.3735, R2: 0.2211\n",
      "==========================================================================================\n",
      "Epoch [784/5000] | Time: 0.24s\n",
      "(Training) Loss: 972118.9251\n",
      "(Validation) Loss: 766092.3867, MAE: 3266.3311, R2: 0.2212\n",
      "==========================================================================================\n",
      "Epoch [785/5000] | Time: 0.24s\n",
      "(Training) Loss: 948353.7322\n",
      "(Validation) Loss: 765981.0857, MAE: 3261.7021, R2: 0.2213\n",
      "==========================================================================================\n",
      "Epoch [786/5000] | Time: 0.23s\n",
      "(Training) Loss: 955197.7094\n",
      "(Validation) Loss: 765883.5410, MAE: 3261.5588, R2: 0.2214\n",
      "==========================================================================================\n",
      "Epoch [787/5000] | Time: 0.21s\n",
      "(Training) Loss: 948510.1402\n",
      "(Validation) Loss: 765796.9283, MAE: 3263.1682, R2: 0.2215\n",
      "==========================================================================================\n",
      "Epoch [788/5000] | Time: 0.26s\n",
      "(Training) Loss: 958742.0882\n",
      "(Validation) Loss: 765699.4013, MAE: 3266.4570, R2: 0.2216\n",
      "==========================================================================================\n",
      "Epoch [789/5000] | Time: 0.21s\n",
      "(Training) Loss: 976539.5501\n",
      "(Validation) Loss: 765608.1524, MAE: 3263.2756, R2: 0.2216\n",
      "==========================================================================================\n",
      "Epoch [790/5000] | Time: 0.19s\n",
      "(Training) Loss: 945561.3569\n",
      "(Validation) Loss: 765518.1232, MAE: 3265.6990, R2: 0.2217\n",
      "==========================================================================================\n",
      "Epoch [791/5000] | Time: 0.22s\n",
      "(Training) Loss: 941878.5793\n",
      "(Validation) Loss: 765408.9498, MAE: 3260.9390, R2: 0.2218\n",
      "==========================================================================================\n",
      "Epoch [792/5000] | Time: 0.20s\n",
      "(Training) Loss: 948923.5165\n",
      "(Validation) Loss: 765321.7346, MAE: 3260.7598, R2: 0.2219\n",
      "==========================================================================================\n",
      "Epoch [793/5000] | Time: 0.23s\n",
      "(Training) Loss: 960494.2234\n",
      "(Validation) Loss: 765238.4603, MAE: 3262.7393, R2: 0.2220\n",
      "==========================================================================================\n",
      "Epoch [794/5000] | Time: 0.25s\n",
      "(Training) Loss: 961967.0324\n",
      "(Validation) Loss: 765145.1143, MAE: 3264.2346, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [795/5000] | Time: 0.24s\n",
      "(Training) Loss: 961983.2760\n",
      "(Validation) Loss: 765033.6698, MAE: 3260.0159, R2: 0.2222\n",
      "==========================================================================================\n",
      "Epoch [796/5000] | Time: 0.23s\n",
      "(Training) Loss: 949128.1827\n",
      "(Validation) Loss: 764937.8451, MAE: 3259.7878, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [797/5000] | Time: 0.22s\n",
      "(Training) Loss: 957627.5127\n",
      "(Validation) Loss: 764846.2895, MAE: 3260.2615, R2: 0.2224\n",
      "==========================================================================================\n",
      "Epoch [798/5000] | Time: 0.23s\n",
      "(Training) Loss: 960455.3001\n",
      "(Validation) Loss: 764756.6076, MAE: 3259.9912, R2: 0.2225\n",
      "==========================================================================================\n",
      "Epoch [799/5000] | Time: 0.24s\n",
      "(Training) Loss: 946115.3414\n",
      "(Validation) Loss: 764677.2921, MAE: 3263.5635, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [800/5000] | Time: 0.23s\n",
      "(Training) Loss: 939979.9159\n",
      "(Validation) Loss: 764550.5619, MAE: 3260.3083, R2: 0.2227\n",
      "==========================================================================================\n",
      "Epoch [801/5000] | Time: 0.25s\n",
      "(Training) Loss: 942035.9051\n",
      "(Validation) Loss: 764498.3460, MAE: 3259.2588, R2: 0.2228\n",
      "==========================================================================================\n",
      "Epoch [802/5000] | Time: 0.29s\n",
      "(Training) Loss: 946968.2348\n",
      "(Validation) Loss: 764420.2305, MAE: 3265.3936, R2: 0.2228\n",
      "==========================================================================================\n",
      "Epoch [803/5000] | Time: 0.27s\n",
      "(Training) Loss: 950022.4594\n",
      "(Validation) Loss: 764319.8762, MAE: 3260.9231, R2: 0.2229\n",
      "==========================================================================================\n",
      "Epoch [804/5000] | Time: 0.26s\n",
      "(Training) Loss: 949578.0806\n",
      "(Validation) Loss: 764219.3073, MAE: 3259.8984, R2: 0.2230\n",
      "==========================================================================================\n",
      "Epoch [805/5000] | Time: 0.29s\n",
      "(Training) Loss: 956059.6948\n",
      "(Validation) Loss: 764128.8813, MAE: 3262.5879, R2: 0.2231\n",
      "==========================================================================================\n",
      "Epoch [806/5000] | Time: 0.22s\n",
      "(Training) Loss: 955731.1358\n",
      "(Validation) Loss: 764049.6400, MAE: 3265.9744, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [807/5000] | Time: 0.22s\n",
      "(Training) Loss: 947362.4987\n",
      "(Validation) Loss: 763961.9733, MAE: 3268.4268, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [808/5000] | Time: 0.25s\n",
      "(Training) Loss: 952906.1713\n",
      "(Validation) Loss: 763891.3905, MAE: 3268.9492, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [809/5000] | Time: 0.22s\n",
      "(Training) Loss: 956779.6681\n",
      "(Validation) Loss: 763739.6921, MAE: 3258.1279, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [810/5000] | Time: 0.22s\n",
      "(Training) Loss: 961170.5863\n",
      "(Validation) Loss: 763649.2305, MAE: 3257.9082, R2: 0.2236\n",
      "==========================================================================================\n",
      "Epoch [811/5000] | Time: 0.22s\n",
      "(Training) Loss: 942539.9299\n",
      "(Validation) Loss: 763544.7549, MAE: 3257.7927, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [812/5000] | Time: 0.23s\n",
      "(Training) Loss: 959166.9619\n",
      "(Validation) Loss: 763460.4978, MAE: 3257.5330, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [813/5000] | Time: 0.21s\n",
      "(Training) Loss: 942829.9845\n",
      "(Validation) Loss: 763361.8057, MAE: 3256.3076, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [814/5000] | Time: 0.20s\n",
      "(Training) Loss: 946039.8331\n",
      "(Validation) Loss: 763275.3937, MAE: 3258.4050, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [815/5000] | Time: 0.24s\n",
      "(Training) Loss: 965198.6320\n",
      "(Validation) Loss: 763179.2533, MAE: 3258.7876, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [816/5000] | Time: 0.23s\n",
      "(Training) Loss: 954954.3782\n",
      "(Validation) Loss: 763079.5403, MAE: 3255.8560, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [817/5000] | Time: 0.22s\n",
      "(Training) Loss: 942015.2030\n",
      "(Validation) Loss: 763000.6946, MAE: 3260.1016, R2: 0.2243\n",
      "==========================================================================================\n",
      "Epoch [818/5000] | Time: 0.26s\n",
      "(Training) Loss: 953471.2766\n",
      "(Validation) Loss: 762882.0508, MAE: 3255.4832, R2: 0.2244\n",
      "==========================================================================================\n",
      "Epoch [819/5000] | Time: 0.24s\n",
      "(Training) Loss: 952847.2544\n",
      "(Validation) Loss: 762795.3841, MAE: 3257.9175, R2: 0.2245\n",
      "==========================================================================================\n",
      "Epoch [820/5000] | Time: 0.22s\n",
      "(Training) Loss: 953301.2989\n",
      "(Validation) Loss: 762706.7651, MAE: 3257.5425, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [821/5000] | Time: 0.22s\n",
      "(Training) Loss: 943910.1142\n",
      "(Validation) Loss: 762600.6457, MAE: 3255.2190, R2: 0.2247\n",
      "==========================================================================================\n",
      "Epoch [822/5000] | Time: 0.24s\n",
      "(Training) Loss: 949645.3452\n",
      "(Validation) Loss: 762521.2305, MAE: 3261.6511, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [823/5000] | Time: 0.21s\n",
      "(Training) Loss: 951037.1643\n",
      "(Validation) Loss: 762406.5041, MAE: 3253.2080, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [824/5000] | Time: 0.20s\n",
      "(Training) Loss: 944023.9994\n",
      "(Validation) Loss: 762328.3676, MAE: 3256.4014, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [825/5000] | Time: 0.22s\n",
      "(Training) Loss: 947779.5013\n",
      "(Validation) Loss: 762227.3905, MAE: 3256.2400, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [826/5000] | Time: 0.22s\n",
      "(Training) Loss: 952966.8940\n",
      "(Validation) Loss: 762132.8184, MAE: 3255.0530, R2: 0.2251\n",
      "==========================================================================================\n",
      "Epoch [827/5000] | Time: 0.22s\n",
      "(Training) Loss: 946461.0279\n",
      "(Validation) Loss: 762031.1327, MAE: 3251.0337, R2: 0.2252\n",
      "==========================================================================================\n",
      "Epoch [828/5000] | Time: 0.22s\n",
      "(Training) Loss: 960035.4721\n",
      "(Validation) Loss: 761943.4267, MAE: 3252.1863, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [829/5000] | Time: 0.23s\n",
      "(Training) Loss: 946307.9016\n",
      "(Validation) Loss: 761844.3917, MAE: 3251.5696, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [830/5000] | Time: 0.22s\n",
      "(Training) Loss: 954155.6612\n",
      "(Validation) Loss: 761756.3022, MAE: 3252.9426, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [831/5000] | Time: 0.23s\n",
      "(Training) Loss: 941301.8693\n",
      "(Validation) Loss: 761656.2006, MAE: 3251.9343, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [832/5000] | Time: 0.21s\n",
      "(Training) Loss: 956115.8699\n",
      "(Validation) Loss: 761566.5397, MAE: 3256.1384, R2: 0.2257\n",
      "==========================================================================================\n",
      "Epoch [833/5000] | Time: 0.22s\n",
      "(Training) Loss: 954812.2500\n",
      "(Validation) Loss: 761490.1981, MAE: 3271.2830, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [834/5000] | Time: 0.26s\n",
      "(Training) Loss: 958369.2906\n",
      "(Validation) Loss: 761377.3378, MAE: 3262.1768, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [835/5000] | Time: 0.25s\n",
      "(Training) Loss: 941010.6685\n",
      "(Validation) Loss: 761286.6921, MAE: 3260.0723, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [836/5000] | Time: 0.21s\n",
      "(Training) Loss: 954915.2582\n",
      "(Validation) Loss: 761185.1416, MAE: 3257.4729, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [837/5000] | Time: 0.26s\n",
      "(Training) Loss: 942992.4886\n",
      "(Validation) Loss: 761101.9930, MAE: 3260.0464, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [838/5000] | Time: 0.21s\n",
      "(Training) Loss: 953600.1148\n",
      "(Validation) Loss: 761000.0146, MAE: 3257.1985, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [839/5000] | Time: 0.22s\n",
      "(Training) Loss: 936431.2077\n",
      "(Validation) Loss: 760911.1365, MAE: 3257.7429, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [840/5000] | Time: 0.24s\n",
      "(Training) Loss: 945081.6009\n",
      "(Validation) Loss: 760811.3371, MAE: 3256.4546, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [841/5000] | Time: 0.21s\n",
      "(Training) Loss: 941338.9277\n",
      "(Validation) Loss: 760715.4978, MAE: 3254.9153, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [842/5000] | Time: 0.20s\n",
      "(Training) Loss: 939916.3820\n",
      "(Validation) Loss: 760622.8787, MAE: 3255.1394, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [843/5000] | Time: 0.22s\n",
      "(Training) Loss: 955490.3179\n",
      "(Validation) Loss: 760543.4927, MAE: 3259.0349, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [844/5000] | Time: 0.22s\n",
      "(Training) Loss: 935742.6984\n",
      "(Validation) Loss: 760434.8889, MAE: 3254.8210, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [845/5000] | Time: 0.25s\n",
      "(Training) Loss: 947779.1497\n",
      "(Validation) Loss: 760343.1295, MAE: 3256.4417, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [846/5000] | Time: 0.22s\n",
      "(Training) Loss: 945926.7582\n",
      "(Validation) Loss: 760251.9879, MAE: 3254.1948, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [847/5000] | Time: 0.21s\n",
      "(Training) Loss: 950632.7487\n",
      "(Validation) Loss: 760153.8387, MAE: 3252.9294, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [848/5000] | Time: 0.20s\n",
      "(Training) Loss: 947325.9569\n",
      "(Validation) Loss: 760056.3676, MAE: 3251.7471, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [849/5000] | Time: 0.22s\n",
      "(Training) Loss: 956821.4137\n",
      "(Validation) Loss: 759962.8095, MAE: 3252.8767, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [850/5000] | Time: 0.22s\n",
      "(Training) Loss: 949786.9321\n",
      "(Validation) Loss: 759866.2730, MAE: 3251.4167, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [851/5000] | Time: 0.23s\n",
      "(Training) Loss: 952605.3750\n",
      "(Validation) Loss: 759768.1689, MAE: 3251.1074, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [852/5000] | Time: 0.24s\n",
      "(Training) Loss: 936217.7386\n",
      "(Validation) Loss: 759679.6032, MAE: 3250.2793, R2: 0.2276\n",
      "==========================================================================================\n",
      "Epoch [853/5000] | Time: 0.25s\n",
      "(Training) Loss: 956832.8312\n",
      "(Validation) Loss: 759605.1543, MAE: 3254.0166, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [854/5000] | Time: 0.24s\n",
      "(Training) Loss: 937059.7240\n",
      "(Validation) Loss: 759473.9771, MAE: 3245.0525, R2: 0.2278\n",
      "==========================================================================================\n",
      "Epoch [855/5000] | Time: 0.23s\n",
      "(Training) Loss: 952008.9353\n",
      "(Validation) Loss: 759394.8876, MAE: 3250.6462, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [856/5000] | Time: 0.22s\n",
      "(Training) Loss: 953625.9968\n",
      "(Validation) Loss: 759301.6476, MAE: 3249.3115, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [857/5000] | Time: 0.22s\n",
      "(Training) Loss: 944128.9372\n",
      "(Validation) Loss: 759198.6787, MAE: 3246.6270, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [858/5000] | Time: 0.21s\n",
      "(Training) Loss: 943101.8344\n",
      "(Validation) Loss: 759112.2260, MAE: 3247.7495, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [859/5000] | Time: 0.22s\n",
      "(Training) Loss: 963235.5298\n",
      "(Validation) Loss: 759009.0216, MAE: 3244.1101, R2: 0.2283\n",
      "==========================================================================================\n",
      "Epoch [860/5000] | Time: 0.20s\n",
      "(Training) Loss: 941203.8274\n",
      "(Validation) Loss: 758900.4914, MAE: 3240.4385, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [861/5000] | Time: 0.21s\n",
      "(Training) Loss: 964708.8230\n",
      "(Validation) Loss: 758813.1175, MAE: 3241.3196, R2: 0.2285\n",
      "==========================================================================================\n",
      "Epoch [862/5000] | Time: 0.22s\n",
      "(Training) Loss: 936791.8268\n",
      "(Validation) Loss: 758724.5029, MAE: 3244.6272, R2: 0.2286\n",
      "==========================================================================================\n",
      "Epoch [863/5000] | Time: 0.23s\n",
      "(Training) Loss: 959527.0717\n",
      "(Validation) Loss: 758622.4394, MAE: 3240.7825, R2: 0.2287\n",
      "==========================================================================================\n",
      "Epoch [864/5000] | Time: 0.24s\n",
      "(Training) Loss: 942520.2081\n",
      "(Validation) Loss: 758624.5689, MAE: 3247.2825, R2: 0.2287\n",
      "==========================================================================================\n",
      "Epoch [865/5000] | Time: 0.23s\n",
      "(Training) Loss: 950279.9245\n",
      "(Validation) Loss: 758442.7048, MAE: 3242.1238, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [866/5000] | Time: 0.20s\n",
      "(Training) Loss: 958510.4137\n",
      "(Validation) Loss: 758354.7835, MAE: 3243.7058, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [867/5000] | Time: 0.22s\n",
      "(Training) Loss: 961915.4378\n",
      "(Validation) Loss: 758256.1651, MAE: 3242.8818, R2: 0.2290\n",
      "==========================================================================================\n",
      "Epoch [868/5000] | Time: 0.20s\n",
      "(Training) Loss: 948010.3953\n",
      "(Validation) Loss: 758167.0946, MAE: 3243.4988, R2: 0.2291\n",
      "==========================================================================================\n",
      "Epoch [869/5000] | Time: 0.20s\n",
      "(Training) Loss: 937832.7386\n",
      "(Validation) Loss: 758060.8184, MAE: 3239.5518, R2: 0.2292\n",
      "==========================================================================================\n",
      "Epoch [870/5000] | Time: 0.22s\n",
      "(Training) Loss: 939118.7570\n",
      "(Validation) Loss: 757978.1111, MAE: 3242.7952, R2: 0.2293\n",
      "==========================================================================================\n",
      "Epoch [871/5000] | Time: 0.25s\n",
      "(Training) Loss: 972976.3258\n",
      "(Validation) Loss: 757867.3302, MAE: 3240.5574, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [872/5000] | Time: 0.28s\n",
      "(Training) Loss: 963139.3179\n",
      "(Validation) Loss: 757778.3841, MAE: 3239.6155, R2: 0.2295\n",
      "==========================================================================================\n",
      "Epoch [873/5000] | Time: 0.23s\n",
      "(Training) Loss: 950386.5761\n",
      "(Validation) Loss: 757699.7778, MAE: 3241.8799, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [874/5000] | Time: 0.25s\n",
      "(Training) Loss: 951642.4981\n",
      "(Validation) Loss: 757585.2597, MAE: 3238.3760, R2: 0.2297\n",
      "==========================================================================================\n",
      "Epoch [875/5000] | Time: 0.26s\n",
      "(Training) Loss: 953460.4391\n",
      "(Validation) Loss: 757495.9549, MAE: 3239.2878, R2: 0.2298\n",
      "==========================================================================================\n",
      "Epoch [876/5000] | Time: 0.23s\n",
      "(Training) Loss: 955606.6523\n",
      "(Validation) Loss: 757407.2159, MAE: 3239.3823, R2: 0.2299\n",
      "==========================================================================================\n",
      "Epoch [877/5000] | Time: 0.22s\n",
      "(Training) Loss: 940984.0209\n",
      "(Validation) Loss: 757309.6229, MAE: 3238.2285, R2: 0.2300\n",
      "==========================================================================================\n",
      "Epoch [878/5000] | Time: 0.21s\n",
      "(Training) Loss: 947371.2354\n",
      "(Validation) Loss: 757213.0648, MAE: 3237.2371, R2: 0.2301\n",
      "==========================================================================================\n",
      "Epoch [879/5000] | Time: 0.22s\n",
      "(Training) Loss: 937989.5869\n",
      "(Validation) Loss: 757122.6032, MAE: 3238.9019, R2: 0.2302\n",
      "==========================================================================================\n",
      "Epoch [880/5000] | Time: 0.21s\n",
      "(Training) Loss: 953224.8731\n",
      "(Validation) Loss: 757018.3175, MAE: 3235.3943, R2: 0.2303\n",
      "==========================================================================================\n",
      "Epoch [881/5000] | Time: 0.21s\n",
      "(Training) Loss: 932575.0446\n",
      "(Validation) Loss: 756940.5441, MAE: 3239.0212, R2: 0.2304\n",
      "==========================================================================================\n",
      "Epoch [882/5000] | Time: 0.22s\n",
      "(Training) Loss: 944232.8077\n",
      "(Validation) Loss: 756850.3505, MAE: 3239.0664, R2: 0.2305\n",
      "==========================================================================================\n",
      "Epoch [883/5000] | Time: 0.22s\n",
      "(Training) Loss: 945880.6891\n",
      "(Validation) Loss: 756759.8819, MAE: 3242.5723, R2: 0.2306\n",
      "==========================================================================================\n",
      "Epoch [884/5000] | Time: 0.23s\n",
      "(Training) Loss: 933093.9258\n",
      "(Validation) Loss: 756643.4133, MAE: 3235.3201, R2: 0.2307\n",
      "==========================================================================================\n",
      "Epoch [885/5000] | Time: 0.24s\n",
      "(Training) Loss: 934388.4607\n",
      "(Validation) Loss: 756591.6298, MAE: 3241.3665, R2: 0.2307\n",
      "==========================================================================================\n",
      "Epoch [886/5000] | Time: 0.22s\n",
      "(Training) Loss: 941919.6098\n",
      "(Validation) Loss: 756459.5886, MAE: 3233.8323, R2: 0.2309\n",
      "==========================================================================================\n",
      "Epoch [887/5000] | Time: 0.22s\n",
      "(Training) Loss: 947228.2589\n",
      "(Validation) Loss: 756371.1219, MAE: 3236.8657, R2: 0.2309\n",
      "==========================================================================================\n",
      "Epoch [888/5000] | Time: 0.21s\n",
      "(Training) Loss: 941128.7900\n",
      "(Validation) Loss: 756279.9676, MAE: 3234.9734, R2: 0.2310\n",
      "==========================================================================================\n",
      "Epoch [889/5000] | Time: 0.22s\n",
      "(Training) Loss: 941955.3997\n",
      "(Validation) Loss: 756197.6857, MAE: 3236.5740, R2: 0.2311\n",
      "==========================================================================================\n",
      "Epoch [890/5000] | Time: 0.23s\n",
      "(Training) Loss: 943167.4594\n",
      "(Validation) Loss: 756088.5594, MAE: 3232.5352, R2: 0.2312\n",
      "==========================================================================================\n",
      "Epoch [891/5000] | Time: 0.23s\n",
      "(Training) Loss: 933954.5600\n",
      "(Validation) Loss: 755997.5206, MAE: 3232.8418, R2: 0.2313\n",
      "==========================================================================================\n",
      "Epoch [892/5000] | Time: 0.23s\n",
      "(Training) Loss: 936652.1869\n",
      "(Validation) Loss: 755899.8337, MAE: 3231.2773, R2: 0.2314\n",
      "==========================================================================================\n",
      "Epoch [893/5000] | Time: 0.23s\n",
      "(Training) Loss: 929902.8511\n",
      "(Validation) Loss: 755812.8667, MAE: 3233.0647, R2: 0.2315\n",
      "==========================================================================================\n",
      "Epoch [894/5000] | Time: 0.24s\n",
      "(Training) Loss: 944829.8547\n",
      "(Validation) Loss: 755724.2921, MAE: 3234.6128, R2: 0.2316\n",
      "==========================================================================================\n",
      "Epoch [895/5000] | Time: 0.26s\n",
      "(Training) Loss: 945974.2649\n",
      "(Validation) Loss: 755625.8603, MAE: 3234.7578, R2: 0.2317\n",
      "==========================================================================================\n",
      "Epoch [896/5000] | Time: 0.26s\n",
      "(Training) Loss: 945813.7049\n",
      "(Validation) Loss: 755526.3924, MAE: 3231.5994, R2: 0.2318\n",
      "==========================================================================================\n",
      "Epoch [897/5000] | Time: 0.21s\n",
      "(Training) Loss: 971100.5996\n",
      "(Validation) Loss: 763945.5054, MAE: 3266.1438, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [898/5000] | Time: 0.21s\n",
      "(Training) Loss: 947097.8496\n",
      "(Validation) Loss: 763843.4368, MAE: 3262.1863, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [899/5000] | Time: 0.23s\n",
      "(Training) Loss: 944350.1904\n",
      "(Validation) Loss: 763738.5486, MAE: 3263.0674, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [900/5000] | Time: 0.25s\n",
      "(Training) Loss: 958787.7640\n",
      "(Validation) Loss: 763642.9403, MAE: 3259.0908, R2: 0.2236\n",
      "==========================================================================================\n",
      "Epoch [901/5000] | Time: 0.24s\n",
      "(Training) Loss: 959336.1263\n",
      "(Validation) Loss: 763557.4159, MAE: 3261.6035, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [902/5000] | Time: 0.22s\n",
      "(Training) Loss: 946418.9778\n",
      "(Validation) Loss: 763456.3200, MAE: 3263.2590, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [903/5000] | Time: 0.24s\n",
      "(Training) Loss: 959904.2868\n",
      "(Validation) Loss: 763372.1060, MAE: 3263.6577, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [904/5000] | Time: 0.22s\n",
      "(Training) Loss: 951287.7151\n",
      "(Validation) Loss: 763257.0610, MAE: 3259.4199, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [905/5000] | Time: 0.22s\n",
      "(Training) Loss: 948078.0914\n",
      "(Validation) Loss: 763127.6349, MAE: 3264.6997, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [906/5000] | Time: 0.24s\n",
      "(Training) Loss: 957140.5609\n",
      "(Validation) Loss: 762717.7359, MAE: 3261.7703, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [907/5000] | Time: 0.21s\n",
      "(Training) Loss: 957814.3249\n",
      "(Validation) Loss: 762609.1124, MAE: 3256.1963, R2: 0.2247\n",
      "==========================================================================================\n",
      "Epoch [908/5000] | Time: 0.25s\n",
      "(Training) Loss: 955984.7278\n",
      "(Validation) Loss: 762501.4990, MAE: 3256.2012, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [909/5000] | Time: 0.24s\n",
      "(Training) Loss: 947797.9848\n",
      "(Validation) Loss: 762404.2775, MAE: 3255.4460, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [910/5000] | Time: 0.24s\n",
      "(Training) Loss: 964023.7202\n",
      "(Validation) Loss: 762299.4241, MAE: 3254.8962, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [911/5000] | Time: 0.22s\n",
      "(Training) Loss: 939929.9397\n",
      "(Validation) Loss: 762210.7924, MAE: 3256.5330, R2: 0.2251\n",
      "==========================================================================================\n",
      "Epoch [912/5000] | Time: 0.21s\n",
      "(Training) Loss: 944418.0019\n",
      "(Validation) Loss: 766545.3860, MAE: 3275.6279, R2: 0.2207\n",
      "==========================================================================================\n",
      "Epoch [913/5000] | Time: 0.21s\n",
      "(Training) Loss: 968423.6662\n",
      "(Validation) Loss: 766433.0895, MAE: 3271.5918, R2: 0.2208\n",
      "==========================================================================================\n",
      "Epoch [914/5000] | Time: 0.21s\n",
      "(Training) Loss: 951652.5136\n",
      "(Validation) Loss: 766333.8235, MAE: 3271.8242, R2: 0.2209\n",
      "==========================================================================================\n",
      "Epoch [915/5000] | Time: 0.24s\n",
      "(Training) Loss: 966085.3522\n",
      "(Validation) Loss: 766218.5575, MAE: 3271.0474, R2: 0.2210\n",
      "==========================================================================================\n",
      "Epoch [916/5000] | Time: 0.21s\n",
      "(Training) Loss: 958858.9645\n",
      "(Validation) Loss: 766120.8146, MAE: 3276.8528, R2: 0.2211\n",
      "==========================================================================================\n",
      "Epoch [917/5000] | Time: 0.21s\n",
      "(Training) Loss: 952391.2484\n",
      "(Validation) Loss: 766005.8749, MAE: 3270.0305, R2: 0.2212\n",
      "==========================================================================================\n",
      "Epoch [918/5000] | Time: 0.22s\n",
      "(Training) Loss: 943815.3547\n",
      "(Validation) Loss: 765896.8038, MAE: 3268.6589, R2: 0.2214\n",
      "==========================================================================================\n",
      "Epoch [919/5000] | Time: 0.22s\n",
      "(Training) Loss: 944705.3246\n",
      "(Validation) Loss: 765796.1632, MAE: 3268.5359, R2: 0.2215\n",
      "==========================================================================================\n",
      "Epoch [920/5000] | Time: 0.22s\n",
      "(Training) Loss: 947331.7297\n",
      "(Validation) Loss: 765703.8775, MAE: 3271.6331, R2: 0.2215\n",
      "==========================================================================================\n",
      "Epoch [921/5000] | Time: 0.21s\n",
      "(Training) Loss: 968887.8791\n",
      "(Validation) Loss: 779849.5314, MAE: 3320.6343, R2: 0.2073\n",
      "==========================================================================================\n",
      "Epoch [922/5000] | Time: 0.21s\n",
      "(Training) Loss: 982498.0006\n",
      "(Validation) Loss: 779744.1314, MAE: 3320.3469, R2: 0.2074\n",
      "==========================================================================================\n",
      "Epoch [923/5000] | Time: 0.20s\n",
      "(Training) Loss: 973759.4289\n",
      "(Validation) Loss: 779628.3511, MAE: 3315.8350, R2: 0.2075\n",
      "==========================================================================================\n",
      "Epoch [924/5000] | Time: 0.21s\n",
      "(Training) Loss: 970049.1371\n",
      "(Validation) Loss: 779523.8895, MAE: 3314.3640, R2: 0.2076\n",
      "==========================================================================================\n",
      "Epoch [925/5000] | Time: 0.22s\n",
      "(Training) Loss: 969585.6961\n",
      "(Validation) Loss: 779423.2559, MAE: 3314.0452, R2: 0.2077\n",
      "==========================================================================================\n",
      "Epoch [926/5000] | Time: 0.25s\n",
      "(Training) Loss: 962516.6250\n",
      "(Validation) Loss: 779323.1498, MAE: 3314.3877, R2: 0.2078\n",
      "==========================================================================================\n",
      "Epoch [927/5000] | Time: 0.23s\n",
      "(Training) Loss: 971316.2798\n",
      "(Validation) Loss: 779206.7238, MAE: 3311.1851, R2: 0.2079\n",
      "==========================================================================================\n",
      "Epoch [928/5000] | Time: 0.21s\n",
      "(Training) Loss: 968601.6980\n",
      "(Validation) Loss: 779117.2597, MAE: 3313.3672, R2: 0.2080\n",
      "==========================================================================================\n",
      "Epoch [929/5000] | Time: 0.21s\n",
      "(Training) Loss: 970909.0247\n",
      "(Validation) Loss: 779010.5556, MAE: 3312.0657, R2: 0.2081\n",
      "==========================================================================================\n",
      "Epoch [930/5000] | Time: 0.21s\n",
      "(Training) Loss: 964261.6402\n",
      "(Validation) Loss: 778903.8190, MAE: 3310.7942, R2: 0.2083\n",
      "==========================================================================================\n",
      "Epoch [931/5000] | Time: 0.20s\n",
      "(Training) Loss: 979282.9822\n",
      "(Validation) Loss: 778799.0813, MAE: 3310.1006, R2: 0.2084\n",
      "==========================================================================================\n",
      "Epoch [932/5000] | Time: 0.24s\n",
      "(Training) Loss: 967349.4822\n",
      "(Validation) Loss: 778697.4451, MAE: 3310.4866, R2: 0.2085\n",
      "==========================================================================================\n",
      "Epoch [933/5000] | Time: 0.25s\n",
      "(Training) Loss: 964238.2766\n",
      "(Validation) Loss: 778609.5073, MAE: 3312.5447, R2: 0.2085\n",
      "==========================================================================================\n",
      "Epoch [934/5000] | Time: 0.20s\n",
      "(Training) Loss: 965424.8547\n",
      "(Validation) Loss: 778498.7454, MAE: 3311.7231, R2: 0.2087\n",
      "==========================================================================================\n",
      "Epoch [935/5000] | Time: 0.20s\n",
      "(Training) Loss: 965142.1542\n",
      "(Validation) Loss: 778422.9403, MAE: 3311.4399, R2: 0.2087\n",
      "==========================================================================================\n",
      "Epoch [936/5000] | Time: 0.21s\n",
      "(Training) Loss: 983441.0095\n",
      "(Validation) Loss: 778288.4083, MAE: 3308.2285, R2: 0.2089\n",
      "==========================================================================================\n",
      "Epoch [937/5000] | Time: 0.23s\n",
      "(Training) Loss: 976648.8239\n",
      "(Validation) Loss: 778312.9498, MAE: 3316.3899, R2: 0.2088\n",
      "==========================================================================================\n",
      "Epoch [938/5000] | Time: 0.21s\n",
      "(Training) Loss: 987957.6079\n",
      "(Validation) Loss: 778212.6914, MAE: 3317.4834, R2: 0.2089\n",
      "==========================================================================================\n",
      "Epoch [939/5000] | Time: 0.21s\n",
      "(Training) Loss: 966711.5819\n",
      "(Validation) Loss: 778100.3549, MAE: 3313.4121, R2: 0.2091\n",
      "==========================================================================================\n",
      "Epoch [940/5000] | Time: 0.21s\n",
      "(Training) Loss: 970591.1957\n",
      "(Validation) Loss: 778001.1384, MAE: 3311.6301, R2: 0.2092\n",
      "==========================================================================================\n",
      "Epoch [941/5000] | Time: 0.23s\n",
      "(Training) Loss: 959544.5311\n",
      "(Validation) Loss: 777902.6432, MAE: 3311.5764, R2: 0.2093\n",
      "==========================================================================================\n",
      "Epoch [942/5000] | Time: 0.25s\n",
      "(Training) Loss: 963165.0660\n",
      "(Validation) Loss: 777798.8508, MAE: 3310.7698, R2: 0.2094\n",
      "==========================================================================================\n",
      "Epoch [943/5000] | Time: 0.27s\n",
      "(Training) Loss: 957319.0936\n",
      "(Validation) Loss: 777698.4546, MAE: 3310.1912, R2: 0.2095\n",
      "==========================================================================================\n",
      "Epoch [944/5000] | Time: 0.27s\n",
      "(Training) Loss: 955857.9348\n",
      "(Validation) Loss: 777599.3556, MAE: 3309.9177, R2: 0.2096\n",
      "==========================================================================================\n",
      "Epoch [945/5000] | Time: 0.28s\n",
      "(Training) Loss: 965284.8617\n",
      "(Validation) Loss: 777499.3206, MAE: 3310.1279, R2: 0.2097\n",
      "==========================================================================================\n",
      "Epoch [946/5000] | Time: 0.26s\n",
      "(Training) Loss: 967169.3407\n",
      "(Validation) Loss: 777401.5289, MAE: 3309.5002, R2: 0.2098\n",
      "==========================================================================================\n",
      "Epoch [947/5000] | Time: 0.27s\n",
      "(Training) Loss: 962096.3445\n",
      "(Validation) Loss: 777304.6311, MAE: 3312.1853, R2: 0.2099\n",
      "==========================================================================================\n",
      "Epoch [948/5000] | Time: 0.24s\n",
      "(Training) Loss: 954217.0273\n",
      "(Validation) Loss: 777206.5771, MAE: 3310.6768, R2: 0.2100\n",
      "==========================================================================================\n",
      "Epoch [949/5000] | Time: 0.24s\n",
      "(Training) Loss: 969090.4661\n",
      "(Validation) Loss: 777102.7695, MAE: 3310.4771, R2: 0.2101\n",
      "==========================================================================================\n",
      "Epoch [950/5000] | Time: 0.24s\n",
      "(Training) Loss: 984465.5971\n",
      "(Validation) Loss: 777029.3683, MAE: 3315.3257, R2: 0.2101\n",
      "==========================================================================================\n",
      "Epoch [951/5000] | Time: 0.23s\n",
      "(Training) Loss: 972368.2839\n",
      "(Validation) Loss: 776897.3892, MAE: 3307.8796, R2: 0.2103\n",
      "==========================================================================================\n",
      "Epoch [952/5000] | Time: 0.22s\n",
      "(Training) Loss: 969869.9435\n",
      "(Validation) Loss: 776813.6597, MAE: 3310.3899, R2: 0.2104\n",
      "==========================================================================================\n",
      "Epoch [953/5000] | Time: 0.21s\n",
      "(Training) Loss: 958745.6250\n",
      "(Validation) Loss: 776695.8641, MAE: 3306.6196, R2: 0.2105\n",
      "==========================================================================================\n",
      "Epoch [954/5000] | Time: 0.21s\n",
      "(Training) Loss: 965463.5197\n",
      "(Validation) Loss: 776594.5086, MAE: 3305.0515, R2: 0.2106\n",
      "==========================================================================================\n",
      "Epoch [955/5000] | Time: 0.23s\n",
      "(Training) Loss: 957091.8915\n",
      "(Validation) Loss: 776494.9492, MAE: 3304.7466, R2: 0.2107\n",
      "==========================================================================================\n",
      "Epoch [956/5000] | Time: 0.21s\n",
      "(Training) Loss: 985143.6631\n",
      "(Validation) Loss: 776402.6013, MAE: 3307.2175, R2: 0.2108\n",
      "==========================================================================================\n",
      "Epoch [957/5000] | Time: 0.21s\n",
      "(Training) Loss: 956319.0622\n",
      "(Validation) Loss: 776294.4292, MAE: 3304.5764, R2: 0.2109\n",
      "==========================================================================================\n",
      "Epoch [958/5000] | Time: 0.19s\n",
      "(Training) Loss: 961248.0171\n",
      "(Validation) Loss: 776197.5263, MAE: 3303.6523, R2: 0.2110\n",
      "==========================================================================================\n",
      "Epoch [959/5000] | Time: 0.21s\n",
      "(Training) Loss: 968327.6037\n",
      "(Validation) Loss: 776098.6489, MAE: 3302.7842, R2: 0.2111\n",
      "==========================================================================================\n",
      "Epoch [960/5000] | Time: 0.21s\n",
      "(Training) Loss: 953334.4828\n",
      "(Validation) Loss: 775998.5213, MAE: 3308.0859, R2: 0.2112\n",
      "==========================================================================================\n",
      "Epoch [961/5000] | Time: 0.22s\n",
      "(Training) Loss: 960565.2849\n",
      "(Validation) Loss: 775897.4171, MAE: 3304.6448, R2: 0.2113\n",
      "==========================================================================================\n",
      "Epoch [962/5000] | Time: 0.21s\n",
      "(Training) Loss: 992342.3852\n",
      "(Validation) Loss: 775800.7987, MAE: 3305.4521, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [963/5000] | Time: 0.22s\n",
      "(Training) Loss: 958579.6301\n",
      "(Validation) Loss: 775714.6514, MAE: 3307.5437, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [964/5000] | Time: 0.23s\n",
      "(Training) Loss: 958167.9048\n",
      "(Validation) Loss: 775600.8317, MAE: 3304.1628, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [965/5000] | Time: 0.24s\n",
      "(Training) Loss: 971075.4118\n",
      "(Validation) Loss: 775502.4590, MAE: 3304.9875, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [966/5000] | Time: 0.23s\n",
      "(Training) Loss: 962739.8344\n",
      "(Validation) Loss: 775403.0311, MAE: 3304.2632, R2: 0.2118\n",
      "==========================================================================================\n",
      "Epoch [967/5000] | Time: 0.22s\n",
      "(Training) Loss: 987169.7424\n",
      "(Validation) Loss: 775315.7829, MAE: 3306.0337, R2: 0.2119\n",
      "==========================================================================================\n",
      "Epoch [968/5000] | Time: 0.21s\n",
      "(Training) Loss: 962735.7557\n",
      "(Validation) Loss: 775200.4844, MAE: 3303.9895, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [969/5000] | Time: 0.22s\n",
      "(Training) Loss: 964115.6110\n",
      "(Validation) Loss: 775100.3943, MAE: 3302.8284, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [970/5000] | Time: 0.23s\n",
      "(Training) Loss: 962534.1555\n",
      "(Validation) Loss: 775001.2743, MAE: 3303.1042, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [971/5000] | Time: 0.25s\n",
      "(Training) Loss: 951766.9910\n",
      "(Validation) Loss: 774898.8521, MAE: 3302.3975, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [972/5000] | Time: 0.24s\n",
      "(Training) Loss: 955573.7646\n",
      "(Validation) Loss: 774817.3657, MAE: 3306.5610, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [973/5000] | Time: 0.24s\n",
      "(Training) Loss: 960522.9365\n",
      "(Validation) Loss: 774708.1841, MAE: 3303.2122, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [974/5000] | Time: 0.23s\n",
      "(Training) Loss: 952683.7007\n",
      "(Validation) Loss: 774605.5384, MAE: 3300.9290, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [975/5000] | Time: 0.24s\n",
      "(Training) Loss: 966391.4353\n",
      "(Validation) Loss: 774505.5994, MAE: 3299.8083, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [976/5000] | Time: 0.24s\n",
      "(Training) Loss: 953854.4978\n",
      "(Validation) Loss: 774421.8038, MAE: 3305.1946, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [977/5000] | Time: 0.21s\n",
      "(Training) Loss: 975557.2297\n",
      "(Validation) Loss: 774250.3486, MAE: 3297.6997, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [978/5000] | Time: 0.22s\n",
      "(Training) Loss: 959344.2557\n",
      "(Validation) Loss: 774198.1517, MAE: 3317.8359, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [979/5000] | Time: 0.23s\n",
      "(Training) Loss: 974888.4683\n",
      "(Validation) Loss: 774045.4451, MAE: 3296.0422, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [980/5000] | Time: 0.22s\n",
      "(Training) Loss: 976155.2605\n",
      "(Validation) Loss: 773949.1187, MAE: 3295.8359, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [981/5000] | Time: 0.23s\n",
      "(Training) Loss: 968893.4981\n",
      "(Validation) Loss: 773848.1746, MAE: 3297.1487, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [982/5000] | Time: 0.25s\n",
      "(Training) Loss: 962820.8261\n",
      "(Validation) Loss: 773756.6895, MAE: 3296.5383, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [983/5000] | Time: 0.22s\n",
      "(Training) Loss: 963716.2557\n",
      "(Validation) Loss: 773655.6521, MAE: 3295.1787, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [984/5000] | Time: 0.24s\n",
      "(Training) Loss: 954145.1650\n",
      "(Validation) Loss: 773547.5029, MAE: 3291.9321, R2: 0.2136\n",
      "==========================================================================================\n",
      "Epoch [985/5000] | Time: 0.26s\n",
      "(Training) Loss: 957859.1726\n",
      "(Validation) Loss: 773454.5175, MAE: 3292.4124, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [986/5000] | Time: 0.25s\n",
      "(Training) Loss: 957031.6301\n",
      "(Validation) Loss: 773355.3416, MAE: 3293.7578, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [987/5000] | Time: 0.23s\n",
      "(Training) Loss: 960762.7754\n",
      "(Validation) Loss: 773255.6286, MAE: 3294.2495, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [988/5000] | Time: 0.23s\n",
      "(Training) Loss: 988322.6402\n",
      "(Validation) Loss: 773148.7105, MAE: 3291.4397, R2: 0.2140\n",
      "==========================================================================================\n",
      "Epoch [989/5000] | Time: 0.24s\n",
      "(Training) Loss: 976531.4016\n",
      "(Validation) Loss: 773052.5092, MAE: 3290.8108, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [990/5000] | Time: 0.25s\n",
      "(Training) Loss: 952284.9340\n",
      "(Validation) Loss: 772953.6933, MAE: 3291.7571, R2: 0.2142\n",
      "==========================================================================================\n",
      "Epoch [991/5000] | Time: 0.24s\n",
      "(Training) Loss: 968363.7246\n",
      "(Validation) Loss: 772870.8883, MAE: 3293.3933, R2: 0.2143\n",
      "==========================================================================================\n",
      "Epoch [992/5000] | Time: 0.24s\n",
      "(Training) Loss: 979303.2646\n",
      "(Validation) Loss: 772758.7841, MAE: 3290.6619, R2: 0.2144\n",
      "==========================================================================================\n",
      "Epoch [993/5000] | Time: 0.21s\n",
      "(Training) Loss: 961720.7551\n",
      "(Validation) Loss: 772698.0483, MAE: 3298.9143, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [994/5000] | Time: 0.25s\n",
      "(Training) Loss: 969760.0057\n",
      "(Validation) Loss: 772562.5295, MAE: 3291.5791, R2: 0.2146\n",
      "==========================================================================================\n",
      "Epoch [995/5000] | Time: 0.22s\n",
      "(Training) Loss: 971062.2487\n",
      "(Validation) Loss: 772482.2000, MAE: 3294.8130, R2: 0.2147\n",
      "==========================================================================================\n",
      "Epoch [996/5000] | Time: 0.22s\n",
      "(Training) Loss: 954677.5495\n",
      "(Validation) Loss: 772358.5683, MAE: 3289.2197, R2: 0.2148\n",
      "==========================================================================================\n",
      "Epoch [997/5000] | Time: 0.22s\n",
      "(Training) Loss: 958419.7595\n",
      "(Validation) Loss: 772290.2108, MAE: 3307.5730, R2: 0.2149\n",
      "==========================================================================================\n",
      "Epoch [998/5000] | Time: 0.23s\n",
      "(Training) Loss: 976959.7811\n",
      "(Validation) Loss: 772162.4470, MAE: 3290.4666, R2: 0.2150\n",
      "==========================================================================================\n",
      "Epoch [999/5000] | Time: 0.23s\n",
      "(Training) Loss: 972528.4657\n",
      "(Validation) Loss: 772062.7644, MAE: 3288.4521, R2: 0.2151\n",
      "==========================================================================================\n",
      "Epoch [1000/5000] | Time: 0.23s\n",
      "(Training) Loss: 948203.6509\n",
      "(Validation) Loss: 771960.8076, MAE: 3287.7473, R2: 0.2152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch1000.pth\n",
      "==========================================================================================\n",
      "Epoch [1001/5000] | Time: 0.23s\n",
      "(Training) Loss: 961879.3173\n",
      "(Validation) Loss: 771869.1371, MAE: 3289.7275, R2: 0.2153\n",
      "==========================================================================================\n",
      "Epoch [1002/5000] | Time: 0.23s\n",
      "(Training) Loss: 956432.5203\n",
      "(Validation) Loss: 771766.8590, MAE: 3287.1519, R2: 0.2154\n",
      "==========================================================================================\n",
      "Epoch [1003/5000] | Time: 0.23s\n",
      "(Training) Loss: 954104.5165\n",
      "(Validation) Loss: 771679.5943, MAE: 3290.4009, R2: 0.2155\n",
      "==========================================================================================\n",
      "Epoch [1004/5000] | Time: 0.23s\n",
      "(Training) Loss: 972763.8179\n",
      "(Validation) Loss: 771568.4952, MAE: 3285.6301, R2: 0.2156\n",
      "==========================================================================================\n",
      "Epoch [1005/5000] | Time: 0.23s\n",
      "(Training) Loss: 948437.4894\n",
      "(Validation) Loss: 771471.4184, MAE: 3285.8425, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [1006/5000] | Time: 0.30s\n",
      "(Training) Loss: 954245.2665\n",
      "(Validation) Loss: 771379.2857, MAE: 3286.8196, R2: 0.2158\n",
      "==========================================================================================\n",
      "Epoch [1007/5000] | Time: 0.21s\n",
      "(Training) Loss: 950704.5730\n",
      "(Validation) Loss: 771273.8102, MAE: 3284.8904, R2: 0.2159\n",
      "==========================================================================================\n",
      "Epoch [1008/5000] | Time: 0.21s\n",
      "(Training) Loss: 950408.9124\n",
      "(Validation) Loss: 771176.6521, MAE: 3285.3555, R2: 0.2160\n",
      "==========================================================================================\n",
      "Epoch [1009/5000] | Time: 0.22s\n",
      "(Training) Loss: 980332.9058\n",
      "(Validation) Loss: 771083.1873, MAE: 3286.8352, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [1010/5000] | Time: 0.20s\n",
      "(Training) Loss: 967597.5178\n",
      "(Validation) Loss: 770997.9162, MAE: 3298.8911, R2: 0.2162\n",
      "==========================================================================================\n",
      "Epoch [1011/5000] | Time: 0.21s\n",
      "(Training) Loss: 986515.7931\n",
      "(Validation) Loss: 770895.1022, MAE: 3290.9290, R2: 0.2163\n",
      "==========================================================================================\n",
      "Epoch [1012/5000] | Time: 0.20s\n",
      "(Training) Loss: 961477.7195\n",
      "(Validation) Loss: 774766.8489, MAE: 3299.6311, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [1013/5000] | Time: 0.27s\n",
      "(Training) Loss: 952409.9546\n",
      "(Validation) Loss: 774649.1327, MAE: 3297.8242, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [1014/5000] | Time: 0.27s\n",
      "(Training) Loss: 966550.0006\n",
      "(Validation) Loss: 774545.5162, MAE: 3299.5493, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [1015/5000] | Time: 0.27s\n",
      "(Training) Loss: 952641.2717\n",
      "(Validation) Loss: 774443.8400, MAE: 3300.6829, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [1016/5000] | Time: 0.25s\n",
      "(Training) Loss: 954184.6669\n",
      "(Validation) Loss: 774332.3911, MAE: 3296.4556, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [1017/5000] | Time: 0.21s\n",
      "(Training) Loss: 957865.7589\n",
      "(Validation) Loss: 774231.7721, MAE: 3297.4282, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [1018/5000] | Time: 0.20s\n",
      "(Training) Loss: 956038.7684\n",
      "(Validation) Loss: 774129.0298, MAE: 3297.8066, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [1019/5000] | Time: 0.21s\n",
      "(Training) Loss: 952956.9879\n",
      "(Validation) Loss: 774034.1879, MAE: 3300.1028, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [1020/5000] | Time: 0.24s\n",
      "(Training) Loss: 970216.8008\n",
      "(Validation) Loss: 773968.6063, MAE: 3301.8591, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [1021/5000] | Time: 0.25s\n",
      "(Training) Loss: 951668.3855\n",
      "(Validation) Loss: 773825.4990, MAE: 3298.2961, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [1022/5000] | Time: 0.21s\n",
      "(Training) Loss: 970921.1574\n",
      "(Validation) Loss: 773742.2203, MAE: 3298.2175, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [1023/5000] | Time: 0.23s\n",
      "(Training) Loss: 964568.1415\n",
      "(Validation) Loss: 773684.4730, MAE: 3298.3474, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [1024/5000] | Time: 0.21s\n",
      "(Training) Loss: 960561.4251\n",
      "(Validation) Loss: 773576.0038, MAE: 3297.9353, R2: 0.2136\n",
      "==========================================================================================\n",
      "Epoch [1025/5000] | Time: 0.25s\n",
      "(Training) Loss: 976132.7424\n",
      "(Validation) Loss: 773482.7130, MAE: 3300.7996, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [1026/5000] | Time: 0.21s\n",
      "(Training) Loss: 963070.9454\n",
      "(Validation) Loss: 773372.9454, MAE: 3297.6492, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [1027/5000] | Time: 0.23s\n",
      "(Training) Loss: 975842.8883\n",
      "(Validation) Loss: 773272.7492, MAE: 3297.0415, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [1028/5000] | Time: 0.23s\n",
      "(Training) Loss: 976958.1777\n",
      "(Validation) Loss: 773166.6997, MAE: 3296.2390, R2: 0.2140\n",
      "==========================================================================================\n",
      "Epoch [1029/5000] | Time: 0.22s\n",
      "(Training) Loss: 970694.3522\n",
      "(Validation) Loss: 773061.9816, MAE: 3295.6963, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [1030/5000] | Time: 0.23s\n",
      "(Training) Loss: 949285.4293\n",
      "(Validation) Loss: 773033.1841, MAE: 3309.4756, R2: 0.2142\n",
      "==========================================================================================\n",
      "Epoch [1031/5000] | Time: 0.23s\n",
      "(Training) Loss: 962613.5596\n",
      "(Validation) Loss: 772874.8971, MAE: 3299.6812, R2: 0.2143\n",
      "==========================================================================================\n",
      "Epoch [1032/5000] | Time: 0.20s\n",
      "(Training) Loss: 959630.2595\n",
      "(Validation) Loss: 772762.5873, MAE: 3296.9236, R2: 0.2144\n",
      "==========================================================================================\n",
      "Epoch [1033/5000] | Time: 0.22s\n",
      "(Training) Loss: 954787.2532\n",
      "(Validation) Loss: 772666.1594, MAE: 3297.7026, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [1034/5000] | Time: 0.21s\n",
      "(Training) Loss: 972503.0197\n",
      "(Validation) Loss: 772561.3778, MAE: 3297.9863, R2: 0.2146\n",
      "==========================================================================================\n",
      "Epoch [1035/5000] | Time: 0.27s\n",
      "(Training) Loss: 956628.5381\n",
      "(Validation) Loss: 782962.4546, MAE: 3333.1741, R2: 0.2042\n",
      "==========================================================================================\n",
      "Epoch [1036/5000] | Time: 0.21s\n",
      "(Training) Loss: 976207.9524\n",
      "(Validation) Loss: 782861.1181, MAE: 3332.6213, R2: 0.2043\n",
      "==========================================================================================\n",
      "Epoch [1037/5000] | Time: 0.22s\n",
      "(Training) Loss: 967696.0857\n",
      "(Validation) Loss: 782750.7422, MAE: 3330.9839, R2: 0.2044\n",
      "==========================================================================================\n",
      "Epoch [1038/5000] | Time: 0.21s\n",
      "(Training) Loss: 978295.5247\n",
      "(Validation) Loss: 782645.2400, MAE: 3330.9209, R2: 0.2045\n",
      "==========================================================================================\n",
      "Epoch [1039/5000] | Time: 0.22s\n",
      "(Training) Loss: 989279.2278\n",
      "(Validation) Loss: 782544.3537, MAE: 3331.6753, R2: 0.2046\n",
      "==========================================================================================\n",
      "Epoch [1040/5000] | Time: 0.24s\n",
      "(Training) Loss: 969855.3579\n",
      "(Validation) Loss: 782437.5206, MAE: 3330.4409, R2: 0.2047\n",
      "==========================================================================================\n",
      "Epoch [1041/5000] | Time: 0.26s\n",
      "(Training) Loss: 978806.3604\n",
      "(Validation) Loss: 782330.0825, MAE: 3329.7832, R2: 0.2048\n",
      "==========================================================================================\n",
      "Epoch [1042/5000] | Time: 0.24s\n",
      "(Training) Loss: 971746.0038\n",
      "(Validation) Loss: 782225.9721, MAE: 3330.0876, R2: 0.2049\n",
      "==========================================================================================\n",
      "Epoch [1043/5000] | Time: 0.27s\n",
      "(Training) Loss: 973843.9365\n",
      "(Validation) Loss: 782118.3702, MAE: 3328.8079, R2: 0.2050\n",
      "==========================================================================================\n",
      "Epoch [1044/5000] | Time: 0.21s\n",
      "(Training) Loss: 985505.1155\n",
      "(Validation) Loss: 782016.9067, MAE: 3330.2493, R2: 0.2051\n",
      "==========================================================================================\n",
      "Epoch [1045/5000] | Time: 0.24s\n",
      "(Training) Loss: 979796.6897\n",
      "(Validation) Loss: 779280.8413, MAE: 3318.9802, R2: 0.2079\n",
      "==========================================================================================\n",
      "Epoch [1046/5000] | Time: 0.22s\n",
      "(Training) Loss: 971588.6129\n",
      "(Validation) Loss: 779191.6057, MAE: 3321.5044, R2: 0.2080\n",
      "==========================================================================================\n",
      "Epoch [1047/5000] | Time: 0.22s\n",
      "(Training) Loss: 969084.5799\n",
      "(Validation) Loss: 779079.0108, MAE: 3318.1321, R2: 0.2081\n",
      "==========================================================================================\n",
      "Epoch [1048/5000] | Time: 0.21s\n",
      "(Training) Loss: 978006.3344\n",
      "(Validation) Loss: 778979.6057, MAE: 3318.0933, R2: 0.2082\n",
      "==========================================================================================\n",
      "Epoch [1049/5000] | Time: 0.21s\n",
      "(Training) Loss: 966213.1548\n",
      "(Validation) Loss: 778880.8216, MAE: 3318.4673, R2: 0.2083\n",
      "==========================================================================================\n",
      "Epoch [1050/5000] | Time: 0.21s\n",
      "(Training) Loss: 972319.3832\n",
      "(Validation) Loss: 778776.9638, MAE: 3315.5017, R2: 0.2084\n",
      "==========================================================================================\n",
      "Epoch [1051/5000] | Time: 0.21s\n",
      "(Training) Loss: 966860.9023\n",
      "(Validation) Loss: 778687.3517, MAE: 3318.5718, R2: 0.2085\n",
      "==========================================================================================\n",
      "Epoch [1052/5000] | Time: 0.26s\n",
      "(Training) Loss: 971572.2906\n",
      "(Validation) Loss: 778574.4946, MAE: 3313.8459, R2: 0.2086\n",
      "==========================================================================================\n",
      "Epoch [1053/5000] | Time: 0.25s\n",
      "(Training) Loss: 969454.7982\n",
      "(Validation) Loss: 778476.1930, MAE: 3314.6584, R2: 0.2087\n",
      "==========================================================================================\n",
      "Epoch [1054/5000] | Time: 0.22s\n",
      "(Training) Loss: 963336.9201\n",
      "(Validation) Loss: 778372.3498, MAE: 3313.6875, R2: 0.2088\n",
      "==========================================================================================\n",
      "Epoch [1055/5000] | Time: 0.24s\n",
      "(Training) Loss: 959198.2544\n",
      "(Validation) Loss: 778270.8921, MAE: 3313.5698, R2: 0.2089\n",
      "==========================================================================================\n",
      "Epoch [1056/5000] | Time: 0.22s\n",
      "(Training) Loss: 971942.7005\n",
      "(Validation) Loss: 778174.1714, MAE: 3314.1001, R2: 0.2090\n",
      "==========================================================================================\n",
      "Epoch [1057/5000] | Time: 0.23s\n",
      "(Training) Loss: 958448.5082\n",
      "(Validation) Loss: 778084.8114, MAE: 3324.9026, R2: 0.2091\n",
      "==========================================================================================\n",
      "Epoch [1058/5000] | Time: 0.25s\n",
      "(Training) Loss: 980896.6732\n",
      "(Validation) Loss: 777984.4025, MAE: 3318.8042, R2: 0.2092\n",
      "==========================================================================================\n",
      "Epoch [1059/5000] | Time: 0.25s\n",
      "(Training) Loss: 963229.9975\n",
      "(Validation) Loss: 777880.0140, MAE: 3319.7083, R2: 0.2093\n",
      "==========================================================================================\n",
      "Epoch [1060/5000] | Time: 0.25s\n",
      "(Training) Loss: 965832.4530\n",
      "(Validation) Loss: 777781.1098, MAE: 3316.7556, R2: 0.2094\n",
      "==========================================================================================\n",
      "Epoch [1061/5000] | Time: 0.23s\n",
      "(Training) Loss: 968331.2582\n",
      "(Validation) Loss: 777676.6317, MAE: 3315.2280, R2: 0.2095\n",
      "==========================================================================================\n",
      "Epoch [1062/5000] | Time: 0.22s\n",
      "(Training) Loss: 965828.7709\n",
      "(Validation) Loss: 777579.2229, MAE: 3315.8315, R2: 0.2096\n",
      "==========================================================================================\n",
      "Epoch [1063/5000] | Time: 0.22s\n",
      "(Training) Loss: 965178.0257\n",
      "(Validation) Loss: 777474.9575, MAE: 3313.3450, R2: 0.2097\n",
      "==========================================================================================\n",
      "Epoch [1064/5000] | Time: 0.24s\n",
      "(Training) Loss: 962380.8610\n",
      "(Validation) Loss: 777381.5556, MAE: 3315.2354, R2: 0.2098\n",
      "==========================================================================================\n",
      "Epoch [1065/5000] | Time: 0.24s\n",
      "(Training) Loss: 962066.2170\n",
      "(Validation) Loss: 777277.5181, MAE: 3314.6680, R2: 0.2099\n",
      "==========================================================================================\n",
      "Epoch [1066/5000] | Time: 0.23s\n",
      "(Training) Loss: 954108.3379\n",
      "(Validation) Loss: 777177.5810, MAE: 3311.7942, R2: 0.2100\n",
      "==========================================================================================\n",
      "Epoch [1067/5000] | Time: 0.22s\n",
      "(Training) Loss: 971402.4657\n",
      "(Validation) Loss: 777075.5683, MAE: 3311.9092, R2: 0.2101\n",
      "==========================================================================================\n",
      "Epoch [1068/5000] | Time: 0.25s\n",
      "(Training) Loss: 965069.5330\n",
      "(Validation) Loss: 776985.1511, MAE: 3315.1931, R2: 0.2102\n",
      "==========================================================================================\n",
      "Epoch [1069/5000] | Time: 0.21s\n",
      "(Training) Loss: 961739.6361\n",
      "(Validation) Loss: 776872.9035, MAE: 3310.0017, R2: 0.2103\n",
      "==========================================================================================\n",
      "Epoch [1070/5000] | Time: 0.22s\n",
      "(Training) Loss: 974095.6237\n",
      "(Validation) Loss: 776774.6305, MAE: 3310.6536, R2: 0.2104\n",
      "==========================================================================================\n",
      "Epoch [1071/5000] | Time: 0.23s\n",
      "(Training) Loss: 973049.0102\n",
      "(Validation) Loss: 776677.1365, MAE: 3311.5571, R2: 0.2105\n",
      "==========================================================================================\n",
      "Epoch [1072/5000] | Time: 0.23s\n",
      "(Training) Loss: 959257.1653\n",
      "(Validation) Loss: 776573.3708, MAE: 3309.8901, R2: 0.2106\n",
      "==========================================================================================\n",
      "Epoch [1073/5000] | Time: 0.25s\n",
      "(Training) Loss: 955819.7947\n",
      "(Validation) Loss: 776480.1098, MAE: 3310.7444, R2: 0.2107\n",
      "==========================================================================================\n",
      "Epoch [1074/5000] | Time: 0.25s\n",
      "(Training) Loss: 968179.0400\n",
      "(Validation) Loss: 776376.2254, MAE: 3308.8403, R2: 0.2108\n",
      "==========================================================================================\n",
      "Epoch [1075/5000] | Time: 0.23s\n",
      "(Training) Loss: 970766.6409\n",
      "(Validation) Loss: 776288.9721, MAE: 3311.2026, R2: 0.2109\n",
      "==========================================================================================\n",
      "Epoch [1076/5000] | Time: 0.26s\n",
      "(Training) Loss: 979286.3249\n",
      "(Validation) Loss: 776178.8571, MAE: 3307.8320, R2: 0.2110\n",
      "==========================================================================================\n",
      "Epoch [1077/5000] | Time: 0.23s\n",
      "(Training) Loss: 984722.3369\n",
      "(Validation) Loss: 776081.5187, MAE: 3309.2390, R2: 0.2111\n",
      "==========================================================================================\n",
      "Epoch [1078/5000] | Time: 0.23s\n",
      "(Training) Loss: 963920.6225\n",
      "(Validation) Loss: 775977.5759, MAE: 3307.7524, R2: 0.2112\n",
      "==========================================================================================\n",
      "Epoch [1079/5000] | Time: 0.24s\n",
      "(Training) Loss: 980578.2157\n",
      "(Validation) Loss: 775876.5708, MAE: 3306.2485, R2: 0.2113\n",
      "==========================================================================================\n",
      "Epoch [1080/5000] | Time: 0.23s\n",
      "(Training) Loss: 955923.0355\n",
      "(Validation) Loss: 775784.2222, MAE: 3308.4045, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [1081/5000] | Time: 0.24s\n",
      "(Training) Loss: 964298.7297\n",
      "(Validation) Loss: 775681.1295, MAE: 3308.1934, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [1082/5000] | Time: 0.29s\n",
      "(Training) Loss: 958837.3141\n",
      "(Validation) Loss: 775574.9181, MAE: 3305.3159, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [1083/5000] | Time: 0.28s\n",
      "(Training) Loss: 972801.3737\n",
      "(Validation) Loss: 775474.1759, MAE: 3305.3545, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [1084/5000] | Time: 0.27s\n",
      "(Training) Loss: 956228.3953\n",
      "(Validation) Loss: 775376.2260, MAE: 3306.4600, R2: 0.2118\n",
      "==========================================================================================\n",
      "Epoch [1085/5000] | Time: 0.28s\n",
      "(Training) Loss: 961113.4010\n",
      "(Validation) Loss: 775280.5130, MAE: 3306.3794, R2: 0.2119\n",
      "==========================================================================================\n",
      "Epoch [1086/5000] | Time: 0.27s\n",
      "(Training) Loss: 977017.0444\n",
      "(Validation) Loss: 775189.5981, MAE: 3308.7583, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [1087/5000] | Time: 0.29s\n",
      "(Training) Loss: 956211.5114\n",
      "(Validation) Loss: 775076.0762, MAE: 3303.6890, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [1088/5000] | Time: 0.24s\n",
      "(Training) Loss: 990852.3966\n",
      "(Validation) Loss: 774980.9956, MAE: 3304.1755, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [1089/5000] | Time: 0.21s\n",
      "(Training) Loss: 957775.8217\n",
      "(Validation) Loss: 774880.6990, MAE: 3305.0125, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [1090/5000] | Time: 0.22s\n",
      "(Training) Loss: 969974.8877\n",
      "(Validation) Loss: 774785.8356, MAE: 3304.6367, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [1091/5000] | Time: 0.28s\n",
      "(Training) Loss: 970258.9353\n",
      "(Validation) Loss: 774687.3911, MAE: 3304.2146, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [1092/5000] | Time: 0.26s\n",
      "(Training) Loss: 958704.9835\n",
      "(Validation) Loss: 774590.0368, MAE: 3305.5688, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [1093/5000] | Time: 0.23s\n",
      "(Training) Loss: 974505.0336\n",
      "(Validation) Loss: 774483.9594, MAE: 3303.5303, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [1094/5000] | Time: 0.21s\n",
      "(Training) Loss: 964733.6313\n",
      "(Validation) Loss: 774386.9422, MAE: 3302.5559, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [1095/5000] | Time: 0.21s\n",
      "(Training) Loss: 958071.9480\n",
      "(Validation) Loss: 774284.2552, MAE: 3302.1597, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [1096/5000] | Time: 0.21s\n",
      "(Training) Loss: 956526.3071\n",
      "(Validation) Loss: 774185.4654, MAE: 3302.8076, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [1097/5000] | Time: 0.21s\n",
      "(Training) Loss: 973397.4854\n",
      "(Validation) Loss: 774096.0273, MAE: 3304.3699, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [1098/5000] | Time: 0.25s\n",
      "(Training) Loss: 969976.9340\n",
      "(Validation) Loss: 773988.3917, MAE: 3301.5984, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [1099/5000] | Time: 0.24s\n",
      "(Training) Loss: 955441.3826\n",
      "(Validation) Loss: 773883.1130, MAE: 3299.7048, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [1100/5000] | Time: 0.25s\n",
      "(Training) Loss: 964865.7938\n",
      "(Validation) Loss: 773787.4197, MAE: 3300.0129, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [1101/5000] | Time: 0.24s\n",
      "(Training) Loss: 969674.6536\n",
      "(Validation) Loss: 773692.0876, MAE: 3300.6978, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [1102/5000] | Time: 0.26s\n",
      "(Training) Loss: 957649.6339\n",
      "(Validation) Loss: 773591.2229, MAE: 3299.4238, R2: 0.2136\n",
      "==========================================================================================\n",
      "Epoch [1103/5000] | Time: 0.22s\n",
      "(Training) Loss: 978938.5546\n",
      "(Validation) Loss: 773501.4457, MAE: 3299.8101, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [1104/5000] | Time: 0.21s\n",
      "(Training) Loss: 950205.9778\n",
      "(Validation) Loss: 773406.7219, MAE: 3303.6709, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [1105/5000] | Time: 0.21s\n",
      "(Training) Loss: 974803.5381\n",
      "(Validation) Loss: 773409.4235, MAE: 3306.7075, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [1106/5000] | Time: 0.21s\n",
      "(Training) Loss: 963192.5222\n",
      "(Validation) Loss: 773301.8159, MAE: 3304.2043, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [1107/5000] | Time: 0.26s\n",
      "(Training) Loss: 954142.7183\n",
      "(Validation) Loss: 773212.9968, MAE: 3307.1096, R2: 0.2140\n",
      "==========================================================================================\n",
      "Epoch [1108/5000] | Time: 0.23s\n",
      "(Training) Loss: 957441.5082\n",
      "(Validation) Loss: 773104.9238, MAE: 3305.3213, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [1109/5000] | Time: 0.25s\n",
      "(Training) Loss: 959121.5324\n",
      "(Validation) Loss: 773006.6121, MAE: 3305.1045, R2: 0.2142\n",
      "==========================================================================================\n",
      "Epoch [1110/5000] | Time: 0.24s\n",
      "(Training) Loss: 967953.1732\n",
      "(Validation) Loss: 772912.0356, MAE: 3306.0317, R2: 0.2143\n",
      "==========================================================================================\n",
      "Epoch [1111/5000] | Time: 0.24s\n",
      "(Training) Loss: 950900.3476\n",
      "(Validation) Loss: 772804.4121, MAE: 3304.1047, R2: 0.2144\n",
      "==========================================================================================\n",
      "Epoch [1112/5000] | Time: 0.25s\n",
      "(Training) Loss: 963027.0508\n",
      "(Validation) Loss: 772711.3022, MAE: 3306.5625, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [1113/5000] | Time: 0.25s\n",
      "(Training) Loss: 961993.2360\n",
      "(Validation) Loss: 772602.4692, MAE: 3302.0664, R2: 0.2146\n",
      "==========================================================================================\n",
      "Epoch [1114/5000] | Time: 0.26s\n",
      "(Training) Loss: 951455.9213\n",
      "(Validation) Loss: 772501.8914, MAE: 3301.3796, R2: 0.2147\n",
      "==========================================================================================\n",
      "Epoch [1115/5000] | Time: 0.24s\n",
      "(Training) Loss: 949054.1410\n",
      "(Validation) Loss: 772404.6559, MAE: 3300.3179, R2: 0.2148\n",
      "==========================================================================================\n",
      "Epoch [1116/5000] | Time: 0.25s\n",
      "(Training) Loss: 964020.0812\n",
      "(Validation) Loss: 772314.9962, MAE: 3302.0933, R2: 0.2149\n",
      "==========================================================================================\n",
      "Epoch [1117/5000] | Time: 0.24s\n",
      "(Training) Loss: 966463.7811\n",
      "(Validation) Loss: 772227.1219, MAE: 3305.1875, R2: 0.2150\n",
      "==========================================================================================\n",
      "Epoch [1118/5000] | Time: 0.24s\n",
      "(Training) Loss: 984443.4622\n",
      "(Validation) Loss: 772126.5975, MAE: 3304.5540, R2: 0.2151\n",
      "==========================================================================================\n",
      "Epoch [1119/5000] | Time: 0.26s\n",
      "(Training) Loss: 954601.9086\n",
      "(Validation) Loss: 772018.5981, MAE: 3303.3523, R2: 0.2152\n",
      "==========================================================================================\n",
      "Epoch [1120/5000] | Time: 0.25s\n",
      "(Training) Loss: 963576.1034\n",
      "(Validation) Loss: 771910.8235, MAE: 3298.9670, R2: 0.2153\n",
      "==========================================================================================\n",
      "Epoch [1121/5000] | Time: 0.27s\n",
      "(Training) Loss: 968371.4835\n",
      "(Validation) Loss: 771822.8121, MAE: 3303.5117, R2: 0.2154\n",
      "==========================================================================================\n",
      "Epoch [1122/5000] | Time: 0.23s\n",
      "(Training) Loss: 947948.2237\n",
      "(Validation) Loss: 771726.5778, MAE: 3303.0242, R2: 0.2155\n",
      "==========================================================================================\n",
      "Epoch [1123/5000] | Time: 0.22s\n",
      "(Training) Loss: 970532.3198\n",
      "(Validation) Loss: 771609.9740, MAE: 3296.8308, R2: 0.2156\n",
      "==========================================================================================\n",
      "Epoch [1124/5000] | Time: 0.23s\n",
      "(Training) Loss: 956762.5520\n",
      "(Validation) Loss: 771516.7086, MAE: 3298.3806, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [1125/5000] | Time: 0.23s\n",
      "(Training) Loss: 966702.2164\n",
      "(Validation) Loss: 771434.6559, MAE: 3302.5461, R2: 0.2158\n",
      "==========================================================================================\n",
      "Epoch [1126/5000] | Time: 0.22s\n",
      "(Training) Loss: 958732.5977\n",
      "(Validation) Loss: 771328.7778, MAE: 3300.0400, R2: 0.2159\n",
      "==========================================================================================\n",
      "Epoch [1127/5000] | Time: 0.24s\n",
      "(Training) Loss: 958161.9296\n",
      "(Validation) Loss: 771226.5898, MAE: 3299.1860, R2: 0.2160\n",
      "==========================================================================================\n",
      "Epoch [1128/5000] | Time: 0.23s\n",
      "(Training) Loss: 967423.8750\n",
      "(Validation) Loss: 771131.6610, MAE: 3298.6653, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [1129/5000] | Time: 0.23s\n",
      "(Training) Loss: 953491.5266\n",
      "(Validation) Loss: 771022.9244, MAE: 3296.8879, R2: 0.2162\n",
      "==========================================================================================\n",
      "Epoch [1130/5000] | Time: 0.24s\n",
      "(Training) Loss: 966955.8077\n",
      "(Validation) Loss: 770925.8000, MAE: 3298.1775, R2: 0.2163\n",
      "==========================================================================================\n",
      "Epoch [1131/5000] | Time: 0.24s\n",
      "(Training) Loss: 990136.4975\n",
      "(Validation) Loss: 770823.3594, MAE: 3295.7729, R2: 0.2164\n",
      "==========================================================================================\n",
      "Epoch [1132/5000] | Time: 0.25s\n",
      "(Training) Loss: 961544.3366\n",
      "(Validation) Loss: 770731.6406, MAE: 3298.7307, R2: 0.2165\n",
      "==========================================================================================\n",
      "Epoch [1133/5000] | Time: 0.26s\n",
      "(Training) Loss: 955929.4454\n",
      "(Validation) Loss: 770633.4838, MAE: 3298.3682, R2: 0.2166\n",
      "==========================================================================================\n",
      "Epoch [1134/5000] | Time: 0.23s\n",
      "(Training) Loss: 950334.0320\n",
      "(Validation) Loss: 770527.1003, MAE: 3295.6133, R2: 0.2167\n",
      "==========================================================================================\n",
      "Epoch [1135/5000] | Time: 0.26s\n",
      "(Training) Loss: 962262.0419\n",
      "(Validation) Loss: 770462.6197, MAE: 3301.3093, R2: 0.2167\n",
      "==========================================================================================\n",
      "Epoch [1136/5000] | Time: 0.24s\n",
      "(Training) Loss: 975691.4365\n",
      "(Validation) Loss: 770327.4083, MAE: 3293.2410, R2: 0.2169\n",
      "==========================================================================================\n",
      "Epoch [1137/5000] | Time: 0.24s\n",
      "(Training) Loss: 965360.3096\n",
      "(Validation) Loss: 770237.9130, MAE: 3296.8848, R2: 0.2170\n",
      "==========================================================================================\n",
      "Epoch [1138/5000] | Time: 0.25s\n",
      "(Training) Loss: 966573.8417\n",
      "(Validation) Loss: 770129.7867, MAE: 3293.8406, R2: 0.2171\n",
      "==========================================================================================\n",
      "Epoch [1139/5000] | Time: 0.26s\n",
      "(Training) Loss: 955825.1218\n",
      "(Validation) Loss: 770038.2590, MAE: 3293.8381, R2: 0.2172\n",
      "==========================================================================================\n",
      "Epoch [1140/5000] | Time: 0.21s\n",
      "(Training) Loss: 946028.1793\n",
      "(Validation) Loss: 769944.0000, MAE: 3297.2739, R2: 0.2173\n",
      "==========================================================================================\n",
      "Epoch [1141/5000] | Time: 0.24s\n",
      "(Training) Loss: 961059.5387\n",
      "(Validation) Loss: 769835.2463, MAE: 3292.7952, R2: 0.2174\n",
      "==========================================================================================\n",
      "Epoch [1142/5000] | Time: 0.21s\n",
      "(Training) Loss: 993724.1973\n",
      "(Validation) Loss: 809097.9848, MAE: 3461.4268, R2: 0.1779\n",
      "==========================================================================================\n",
      "Epoch [1143/5000] | Time: 0.19s\n",
      "(Training) Loss: 1001164.0833\n",
      "(Validation) Loss: 824816.0063, MAE: 3496.9282, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [1144/5000] | Time: 0.19s\n",
      "(Training) Loss: 1021554.7494\n",
      "(Validation) Loss: 824488.4756, MAE: 3502.9407, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [1145/5000] | Time: 0.18s\n",
      "(Training) Loss: 1002069.3648\n",
      "(Validation) Loss: 803170.4648, MAE: 3415.2639, R2: 0.1838\n",
      "==========================================================================================\n",
      "Epoch [1146/5000] | Time: 0.18s\n",
      "(Training) Loss: 996729.4391\n",
      "(Validation) Loss: 803066.8413, MAE: 3403.4712, R2: 0.1839\n",
      "==========================================================================================\n",
      "Epoch [1147/5000] | Time: 0.18s\n",
      "(Training) Loss: 996334.2703\n",
      "(Validation) Loss: 803010.6419, MAE: 3406.3362, R2: 0.1840\n",
      "==========================================================================================\n",
      "Epoch [1148/5000] | Time: 0.22s\n",
      "(Training) Loss: 999831.9511\n",
      "(Validation) Loss: 803043.8349, MAE: 3409.2419, R2: 0.1840\n",
      "==========================================================================================\n",
      "Epoch [1149/5000] | Time: 0.23s\n",
      "(Training) Loss: 989438.5089\n",
      "(Validation) Loss: 802948.9708, MAE: 3407.9714, R2: 0.1840\n",
      "==========================================================================================\n",
      "Epoch [1150/5000] | Time: 0.24s\n",
      "(Training) Loss: 992301.4562\n",
      "(Validation) Loss: 802851.9968, MAE: 3406.8474, R2: 0.1841\n",
      "==========================================================================================\n",
      "Epoch [1151/5000] | Time: 0.24s\n",
      "(Training) Loss: 986420.0244\n",
      "(Validation) Loss: 802685.5359, MAE: 3406.6968, R2: 0.1843\n",
      "==========================================================================================\n",
      "Epoch [1152/5000] | Time: 0.28s\n",
      "(Training) Loss: 1006557.8122\n",
      "(Validation) Loss: 802589.0851, MAE: 3404.1921, R2: 0.1844\n",
      "==========================================================================================\n",
      "Epoch [1153/5000] | Time: 0.24s\n",
      "(Training) Loss: 1005792.1313\n",
      "(Validation) Loss: 802493.7092, MAE: 3405.5042, R2: 0.1845\n",
      "==========================================================================================\n",
      "Epoch [1154/5000] | Time: 0.21s\n",
      "(Training) Loss: 1026776.6117\n",
      "(Validation) Loss: 802390.3251, MAE: 3401.7456, R2: 0.1846\n",
      "==========================================================================================\n",
      "Epoch [1155/5000] | Time: 0.21s\n",
      "(Training) Loss: 988112.7963\n",
      "(Validation) Loss: 802298.1314, MAE: 3401.9802, R2: 0.1847\n",
      "==========================================================================================\n",
      "Epoch [1156/5000] | Time: 0.20s\n",
      "(Training) Loss: 994090.0914\n",
      "(Validation) Loss: 802213.5740, MAE: 3402.9346, R2: 0.1848\n",
      "==========================================================================================\n",
      "Epoch [1157/5000] | Time: 0.21s\n",
      "(Training) Loss: 991973.2373\n",
      "(Validation) Loss: 802119.6356, MAE: 3403.5837, R2: 0.1849\n",
      "==========================================================================================\n",
      "Epoch [1158/5000] | Time: 0.22s\n",
      "(Training) Loss: 996267.8737\n",
      "(Validation) Loss: 802029.7232, MAE: 3403.9500, R2: 0.1850\n",
      "==========================================================================================\n",
      "Epoch [1159/5000] | Time: 0.23s\n",
      "(Training) Loss: 992659.3433\n",
      "(Validation) Loss: 801937.0235, MAE: 3402.4619, R2: 0.1851\n",
      "==========================================================================================\n",
      "Epoch [1160/5000] | Time: 0.22s\n",
      "(Training) Loss: 983023.3955\n",
      "(Validation) Loss: 801841.2673, MAE: 3402.2910, R2: 0.1852\n",
      "==========================================================================================\n",
      "Epoch [1161/5000] | Time: 0.29s\n",
      "(Training) Loss: 984130.7389\n",
      "(Validation) Loss: 801759.2095, MAE: 3402.4810, R2: 0.1852\n",
      "==========================================================================================\n",
      "Epoch [1162/5000] | Time: 0.27s\n",
      "(Training) Loss: 996259.6168\n",
      "(Validation) Loss: 801653.4883, MAE: 3399.4067, R2: 0.1854\n",
      "==========================================================================================\n",
      "Epoch [1163/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001843.7640\n",
      "(Validation) Loss: 801566.9117, MAE: 3400.4600, R2: 0.1854\n",
      "==========================================================================================\n",
      "Epoch [1164/5000] | Time: 0.29s\n",
      "(Training) Loss: 997595.7291\n",
      "(Validation) Loss: 801467.7657, MAE: 3397.7009, R2: 0.1855\n",
      "==========================================================================================\n",
      "Epoch [1165/5000] | Time: 0.31s\n",
      "(Training) Loss: 1000836.2887\n",
      "(Validation) Loss: 801389.4971, MAE: 3402.2000, R2: 0.1856\n",
      "==========================================================================================\n",
      "Epoch [1166/5000] | Time: 0.29s\n",
      "(Training) Loss: 993644.6802\n",
      "(Validation) Loss: 801288.9778, MAE: 3398.6372, R2: 0.1857\n",
      "==========================================================================================\n",
      "Epoch [1167/5000] | Time: 0.31s\n",
      "(Training) Loss: 1002913.3756\n",
      "(Validation) Loss: 801194.0089, MAE: 3397.3489, R2: 0.1858\n",
      "==========================================================================================\n",
      "Epoch [1168/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004723.6212\n",
      "(Validation) Loss: 801103.6933, MAE: 3397.9670, R2: 0.1859\n",
      "==========================================================================================\n",
      "Epoch [1169/5000] | Time: 0.24s\n",
      "(Training) Loss: 1024150.5945\n",
      "(Validation) Loss: 801009.9219, MAE: 3396.8796, R2: 0.1860\n",
      "==========================================================================================\n",
      "Epoch [1170/5000] | Time: 0.22s\n",
      "(Training) Loss: 988112.9505\n",
      "(Validation) Loss: 800918.1194, MAE: 3397.5168, R2: 0.1861\n",
      "==========================================================================================\n",
      "Epoch [1171/5000] | Time: 0.23s\n",
      "(Training) Loss: 997376.3255\n",
      "(Validation) Loss: 800827.1600, MAE: 3396.5527, R2: 0.1862\n",
      "==========================================================================================\n",
      "Epoch [1172/5000] | Time: 0.25s\n",
      "(Training) Loss: 992949.0216\n",
      "(Validation) Loss: 800737.3556, MAE: 3397.7896, R2: 0.1863\n",
      "==========================================================================================\n",
      "Epoch [1173/5000] | Time: 0.25s\n",
      "(Training) Loss: 999851.5669\n",
      "(Validation) Loss: 800643.0286, MAE: 3395.3093, R2: 0.1864\n",
      "==========================================================================================\n",
      "Epoch [1174/5000] | Time: 0.30s\n",
      "(Training) Loss: 987651.4997\n",
      "(Validation) Loss: 800555.2571, MAE: 3396.8691, R2: 0.1865\n",
      "==========================================================================================\n",
      "Epoch [1175/5000] | Time: 0.24s\n",
      "(Training) Loss: 984810.3541\n",
      "(Validation) Loss: 800459.3594, MAE: 3395.7175, R2: 0.1866\n",
      "==========================================================================================\n",
      "Epoch [1176/5000] | Time: 0.28s\n",
      "(Training) Loss: 993133.0330\n",
      "(Validation) Loss: 800368.8273, MAE: 3394.8032, R2: 0.1866\n",
      "==========================================================================================\n",
      "Epoch [1177/5000] | Time: 0.30s\n",
      "(Training) Loss: 991687.3896\n",
      "(Validation) Loss: 800276.9987, MAE: 3394.5781, R2: 0.1867\n",
      "==========================================================================================\n",
      "Epoch [1178/5000] | Time: 0.29s\n",
      "(Training) Loss: 989964.3788\n",
      "(Validation) Loss: 800187.1822, MAE: 3394.0393, R2: 0.1868\n",
      "==========================================================================================\n",
      "Epoch [1179/5000] | Time: 0.31s\n",
      "(Training) Loss: 990942.7265\n",
      "(Validation) Loss: 800107.3067, MAE: 3396.5906, R2: 0.1869\n",
      "==========================================================================================\n",
      "Epoch [1180/5000] | Time: 0.30s\n",
      "(Training) Loss: 980193.9472\n",
      "(Validation) Loss: 800003.7879, MAE: 3392.6003, R2: 0.1870\n",
      "==========================================================================================\n",
      "Epoch [1181/5000] | Time: 0.32s\n",
      "(Training) Loss: 999392.0793\n",
      "(Validation) Loss: 799918.2863, MAE: 3394.6130, R2: 0.1871\n",
      "==========================================================================================\n",
      "Epoch [1182/5000] | Time: 0.29s\n",
      "(Training) Loss: 986573.9036\n",
      "(Validation) Loss: 799830.4076, MAE: 3395.0833, R2: 0.1872\n",
      "==========================================================================================\n",
      "Epoch [1183/5000] | Time: 0.30s\n",
      "(Training) Loss: 984926.2576\n",
      "(Validation) Loss: 799731.9111, MAE: 3392.2417, R2: 0.1873\n",
      "==========================================================================================\n",
      "Epoch [1184/5000] | Time: 0.29s\n",
      "(Training) Loss: 996640.0476\n",
      "(Validation) Loss: 799645.6146, MAE: 3393.7102, R2: 0.1874\n",
      "==========================================================================================\n",
      "Epoch [1185/5000] | Time: 0.27s\n",
      "(Training) Loss: 1001354.5723\n",
      "(Validation) Loss: 799550.2229, MAE: 3392.0044, R2: 0.1875\n",
      "==========================================================================================\n",
      "Epoch [1186/5000] | Time: 0.28s\n",
      "(Training) Loss: 1003826.2049\n",
      "(Validation) Loss: 799457.8070, MAE: 3391.0039, R2: 0.1876\n",
      "==========================================================================================\n",
      "Epoch [1187/5000] | Time: 0.27s\n",
      "(Training) Loss: 980364.4097\n",
      "(Validation) Loss: 799367.3606, MAE: 3391.5134, R2: 0.1877\n",
      "==========================================================================================\n",
      "Epoch [1188/5000] | Time: 0.28s\n",
      "(Training) Loss: 1010815.9429\n",
      "(Validation) Loss: 800459.7829, MAE: 3395.6997, R2: 0.1866\n",
      "==========================================================================================\n",
      "Epoch [1189/5000] | Time: 0.29s\n",
      "(Training) Loss: 983257.6526\n",
      "(Validation) Loss: 800356.6775, MAE: 3395.3628, R2: 0.1867\n",
      "==========================================================================================\n",
      "Epoch [1190/5000] | Time: 0.28s\n",
      "(Training) Loss: 983988.2443\n",
      "(Validation) Loss: 800260.0508, MAE: 3395.3479, R2: 0.1868\n",
      "==========================================================================================\n",
      "Epoch [1191/5000] | Time: 0.26s\n",
      "(Training) Loss: 992960.0451\n",
      "(Validation) Loss: 800164.6737, MAE: 3395.5933, R2: 0.1869\n",
      "==========================================================================================\n",
      "Epoch [1192/5000] | Time: 0.35s\n",
      "(Training) Loss: 996752.0292\n",
      "(Validation) Loss: 800068.4432, MAE: 3397.0415, R2: 0.1869\n",
      "==========================================================================================\n",
      "Epoch [1193/5000] | Time: 0.32s\n",
      "(Training) Loss: 984157.5466\n",
      "(Validation) Loss: 799967.9949, MAE: 3394.9648, R2: 0.1870\n",
      "==========================================================================================\n",
      "Epoch [1194/5000] | Time: 0.27s\n",
      "(Training) Loss: 992297.6605\n",
      "(Validation) Loss: 799871.3790, MAE: 3394.1038, R2: 0.1871\n",
      "==========================================================================================\n",
      "Epoch [1195/5000] | Time: 0.29s\n",
      "(Training) Loss: 1006784.5698\n",
      "(Validation) Loss: 799774.6184, MAE: 3393.2305, R2: 0.1872\n",
      "==========================================================================================\n",
      "Epoch [1196/5000] | Time: 0.27s\n",
      "(Training) Loss: 1005071.4353\n",
      "(Validation) Loss: 799676.9619, MAE: 3392.1238, R2: 0.1873\n",
      "==========================================================================================\n",
      "Epoch [1197/5000] | Time: 0.25s\n",
      "(Training) Loss: 998705.1504\n",
      "(Validation) Loss: 799582.8857, MAE: 3390.3962, R2: 0.1874\n",
      "==========================================================================================\n",
      "Epoch [1198/5000] | Time: 0.24s\n",
      "(Training) Loss: 984439.7329\n",
      "(Validation) Loss: 799496.2540, MAE: 3394.5007, R2: 0.1875\n",
      "==========================================================================================\n",
      "Epoch [1199/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000989.8947\n",
      "(Validation) Loss: 799409.3086, MAE: 3395.2190, R2: 0.1876\n",
      "==========================================================================================\n",
      "Epoch [1200/5000] | Time: 0.24s\n",
      "(Training) Loss: 999907.3852\n",
      "(Validation) Loss: 799298.1752, MAE: 3388.8689, R2: 0.1877\n",
      "==========================================================================================\n",
      "Epoch [1201/5000] | Time: 0.24s\n",
      "(Training) Loss: 994426.3668\n",
      "(Validation) Loss: 799204.3556, MAE: 3390.6492, R2: 0.1878\n",
      "==========================================================================================\n",
      "Epoch [1202/5000] | Time: 0.24s\n",
      "(Training) Loss: 982232.7421\n",
      "(Validation) Loss: 799110.1854, MAE: 3388.6333, R2: 0.1879\n",
      "==========================================================================================\n",
      "Epoch [1203/5000] | Time: 0.26s\n",
      "(Training) Loss: 1009643.1758\n",
      "(Validation) Loss: 799017.2781, MAE: 3389.0867, R2: 0.1880\n",
      "==========================================================================================\n",
      "Epoch [1204/5000] | Time: 0.26s\n",
      "(Training) Loss: 984479.8236\n",
      "(Validation) Loss: 798919.5702, MAE: 3387.1123, R2: 0.1881\n",
      "==========================================================================================\n",
      "Epoch [1205/5000] | Time: 0.24s\n",
      "(Training) Loss: 979648.8163\n",
      "(Validation) Loss: 798829.7854, MAE: 3387.0537, R2: 0.1882\n",
      "==========================================================================================\n",
      "Epoch [1206/5000] | Time: 0.25s\n",
      "(Training) Loss: 994407.2341\n",
      "(Validation) Loss: 798733.2533, MAE: 3386.1775, R2: 0.1883\n",
      "==========================================================================================\n",
      "Epoch [1207/5000] | Time: 0.25s\n",
      "(Training) Loss: 985004.1942\n",
      "(Validation) Loss: 798641.7848, MAE: 3386.5356, R2: 0.1884\n",
      "==========================================================================================\n",
      "Epoch [1208/5000] | Time: 0.22s\n",
      "(Training) Loss: 981374.7786\n",
      "(Validation) Loss: 798549.4165, MAE: 3386.4675, R2: 0.1885\n",
      "==========================================================================================\n",
      "Epoch [1209/5000] | Time: 0.22s\n",
      "(Training) Loss: 999390.4918\n",
      "(Validation) Loss: 798451.3302, MAE: 3384.8418, R2: 0.1886\n",
      "==========================================================================================\n",
      "Epoch [1210/5000] | Time: 0.27s\n",
      "(Training) Loss: 984782.8376\n",
      "(Validation) Loss: 798357.3448, MAE: 3384.4875, R2: 0.1887\n",
      "==========================================================================================\n",
      "Epoch [1211/5000] | Time: 0.30s\n",
      "(Training) Loss: 1002777.3826\n",
      "(Validation) Loss: 798262.6019, MAE: 3384.0520, R2: 0.1888\n",
      "==========================================================================================\n",
      "Epoch [1212/5000] | Time: 0.29s\n",
      "(Training) Loss: 981608.9159\n",
      "(Validation) Loss: 798175.8946, MAE: 3386.1553, R2: 0.1889\n",
      "==========================================================================================\n",
      "Epoch [1213/5000] | Time: 0.32s\n",
      "(Training) Loss: 984776.7970\n",
      "(Validation) Loss: 798086.8063, MAE: 3386.9875, R2: 0.1889\n",
      "==========================================================================================\n",
      "Epoch [1214/5000] | Time: 0.30s\n",
      "(Training) Loss: 998031.1142\n",
      "(Validation) Loss: 797993.5384, MAE: 3385.7629, R2: 0.1890\n",
      "==========================================================================================\n",
      "Epoch [1215/5000] | Time: 0.28s\n",
      "(Training) Loss: 991956.2208\n",
      "(Validation) Loss: 797890.5695, MAE: 3382.3813, R2: 0.1891\n",
      "==========================================================================================\n",
      "Epoch [1216/5000] | Time: 0.26s\n",
      "(Training) Loss: 1004215.2944\n",
      "(Validation) Loss: 797797.6749, MAE: 3382.1716, R2: 0.1892\n",
      "==========================================================================================\n",
      "Epoch [1217/5000] | Time: 0.27s\n",
      "(Training) Loss: 978980.9973\n",
      "(Validation) Loss: 797708.8514, MAE: 3383.4595, R2: 0.1893\n",
      "==========================================================================================\n",
      "Epoch [1218/5000] | Time: 0.25s\n",
      "(Training) Loss: 977852.2370\n",
      "(Validation) Loss: 797609.1771, MAE: 3382.3743, R2: 0.1894\n",
      "==========================================================================================\n",
      "Epoch [1219/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006003.0571\n",
      "(Validation) Loss: 797518.4203, MAE: 3382.6287, R2: 0.1895\n",
      "==========================================================================================\n",
      "Epoch [1220/5000] | Time: 0.30s\n",
      "(Training) Loss: 995271.0819\n",
      "(Validation) Loss: 797422.8787, MAE: 3380.2134, R2: 0.1896\n",
      "==========================================================================================\n",
      "Epoch [1221/5000] | Time: 0.24s\n",
      "(Training) Loss: 982083.9461\n",
      "(Validation) Loss: 797327.8286, MAE: 3379.5601, R2: 0.1897\n",
      "==========================================================================================\n",
      "Epoch [1222/5000] | Time: 0.25s\n",
      "(Training) Loss: 989711.2487\n",
      "(Validation) Loss: 797220.4203, MAE: 3384.4158, R2: 0.1898\n",
      "==========================================================================================\n",
      "Epoch [1223/5000] | Time: 0.23s\n",
      "(Training) Loss: 978124.2192\n",
      "(Validation) Loss: 797119.2857, MAE: 3378.6716, R2: 0.1899\n",
      "==========================================================================================\n",
      "Epoch [1224/5000] | Time: 0.26s\n",
      "(Training) Loss: 984202.1853\n",
      "(Validation) Loss: 797043.3016, MAE: 3383.9199, R2: 0.1900\n",
      "==========================================================================================\n",
      "Epoch [1225/5000] | Time: 0.26s\n",
      "(Training) Loss: 983038.5615\n",
      "(Validation) Loss: 797008.3035, MAE: 3385.9983, R2: 0.1900\n",
      "==========================================================================================\n",
      "Epoch [1226/5000] | Time: 0.26s\n",
      "(Training) Loss: 972718.9772\n",
      "(Validation) Loss: 783059.7689, MAE: 3331.5623, R2: 0.2041\n",
      "==========================================================================================\n",
      "Epoch [1227/5000] | Time: 0.30s\n",
      "(Training) Loss: 1021893.8788\n",
      "(Validation) Loss: 782964.9657, MAE: 3331.9895, R2: 0.2042\n",
      "==========================================================================================\n",
      "Epoch [1228/5000] | Time: 0.25s\n",
      "(Training) Loss: 985072.9518\n",
      "(Validation) Loss: 782871.8603, MAE: 3332.4150, R2: 0.2043\n",
      "==========================================================================================\n",
      "Epoch [1229/5000] | Time: 0.25s\n",
      "(Training) Loss: 968752.0749\n",
      "(Validation) Loss: 782771.7086, MAE: 3330.8613, R2: 0.2044\n",
      "==========================================================================================\n",
      "Epoch [1230/5000] | Time: 0.28s\n",
      "(Training) Loss: 981610.2437\n",
      "(Validation) Loss: 781250.7721, MAE: 3327.9580, R2: 0.2059\n",
      "==========================================================================================\n",
      "Epoch [1231/5000] | Time: 0.27s\n",
      "(Training) Loss: 964413.1066\n",
      "(Validation) Loss: 781160.1168, MAE: 3328.3083, R2: 0.2060\n",
      "==========================================================================================\n",
      "Epoch [1232/5000] | Time: 0.26s\n",
      "(Training) Loss: 970938.0146\n",
      "(Validation) Loss: 781049.3244, MAE: 3324.0950, R2: 0.2061\n",
      "==========================================================================================\n",
      "Epoch [1233/5000] | Time: 0.25s\n",
      "(Training) Loss: 961945.6583\n",
      "(Validation) Loss: 776165.7854, MAE: 3307.0791, R2: 0.2110\n",
      "==========================================================================================\n",
      "Epoch [1234/5000] | Time: 0.27s\n",
      "(Training) Loss: 968634.6669\n",
      "(Validation) Loss: 776073.7213, MAE: 3303.3569, R2: 0.2111\n",
      "==========================================================================================\n",
      "Epoch [1235/5000] | Time: 0.24s\n",
      "(Training) Loss: 973495.0571\n",
      "(Validation) Loss: 775990.1689, MAE: 3304.4585, R2: 0.2112\n",
      "==========================================================================================\n",
      "Epoch [1236/5000] | Time: 0.27s\n",
      "(Training) Loss: 955568.3858\n",
      "(Validation) Loss: 775907.6279, MAE: 3306.2727, R2: 0.2113\n",
      "==========================================================================================\n",
      "Epoch [1237/5000] | Time: 0.25s\n",
      "(Training) Loss: 957939.1561\n",
      "(Validation) Loss: 775805.6368, MAE: 3302.0623, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [1238/5000] | Time: 0.25s\n",
      "(Training) Loss: 961298.2259\n",
      "(Validation) Loss: 775726.2610, MAE: 3302.6455, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [1239/5000] | Time: 0.25s\n",
      "(Training) Loss: 959878.1662\n",
      "(Validation) Loss: 775643.1727, MAE: 3305.4658, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [1240/5000] | Time: 0.26s\n",
      "(Training) Loss: 976543.2576\n",
      "(Validation) Loss: 775572.0013, MAE: 3305.0242, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [1241/5000] | Time: 0.25s\n",
      "(Training) Loss: 991209.8852\n",
      "(Validation) Loss: 775462.7321, MAE: 3299.4756, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [1242/5000] | Time: 0.31s\n",
      "(Training) Loss: 963916.0901\n",
      "(Validation) Loss: 775377.8756, MAE: 3301.3164, R2: 0.2118\n",
      "==========================================================================================\n",
      "Epoch [1243/5000] | Time: 0.28s\n",
      "(Training) Loss: 965950.2186\n",
      "(Validation) Loss: 775286.8889, MAE: 3300.4927, R2: 0.2119\n",
      "==========================================================================================\n",
      "Epoch [1244/5000] | Time: 0.28s\n",
      "(Training) Loss: 1004018.5673\n",
      "(Validation) Loss: 775209.0844, MAE: 3301.5784, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [1245/5000] | Time: 0.27s\n",
      "(Training) Loss: 971350.8725\n",
      "(Validation) Loss: 775108.0070, MAE: 3297.9548, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [1246/5000] | Time: 0.24s\n",
      "(Training) Loss: 967213.1180\n",
      "(Validation) Loss: 775027.4457, MAE: 3300.0850, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [1247/5000] | Time: 0.26s\n",
      "(Training) Loss: 975231.2716\n",
      "(Validation) Loss: 774934.3917, MAE: 3297.7234, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [1248/5000] | Time: 0.27s\n",
      "(Training) Loss: 959631.2836\n",
      "(Validation) Loss: 774858.0197, MAE: 3299.8086, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [1249/5000] | Time: 0.25s\n",
      "(Training) Loss: 966013.2481\n",
      "(Validation) Loss: 774769.7086, MAE: 3300.2021, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [1250/5000] | Time: 0.27s\n",
      "(Training) Loss: 956731.5178\n",
      "(Validation) Loss: 774684.6425, MAE: 3298.8132, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [1251/5000] | Time: 0.26s\n",
      "(Training) Loss: 988651.0596\n",
      "(Validation) Loss: 774594.7575, MAE: 3298.6626, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [1252/5000] | Time: 0.27s\n",
      "(Training) Loss: 955605.7164\n",
      "(Validation) Loss: 774507.9124, MAE: 3297.5469, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [1253/5000] | Time: 0.25s\n",
      "(Training) Loss: 968830.2944\n",
      "(Validation) Loss: 774425.7867, MAE: 3298.7175, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [1254/5000] | Time: 0.27s\n",
      "(Training) Loss: 969786.8344\n",
      "(Validation) Loss: 774331.4013, MAE: 3296.1177, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [1255/5000] | Time: 0.26s\n",
      "(Training) Loss: 958749.9150\n",
      "(Validation) Loss: 774257.6165, MAE: 3299.2798, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [1256/5000] | Time: 0.28s\n",
      "(Training) Loss: 953606.2649\n",
      "(Validation) Loss: 775528.0730, MAE: 3304.8108, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [1257/5000] | Time: 0.30s\n",
      "(Training) Loss: 972232.9797\n",
      "(Validation) Loss: 774565.3105, MAE: 3300.8467, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [1258/5000] | Time: 0.24s\n",
      "(Training) Loss: 957937.0044\n",
      "(Validation) Loss: 774473.6425, MAE: 3299.0073, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [1259/5000] | Time: 0.24s\n",
      "(Training) Loss: 959833.8991\n",
      "(Validation) Loss: 774376.3200, MAE: 3297.9978, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [1260/5000] | Time: 0.26s\n",
      "(Training) Loss: 957310.5444\n",
      "(Validation) Loss: 774288.4133, MAE: 3297.2749, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [1261/5000] | Time: 0.24s\n",
      "(Training) Loss: 953892.1110\n",
      "(Validation) Loss: 774203.6381, MAE: 3298.8213, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [1262/5000] | Time: 0.26s\n",
      "(Training) Loss: 958280.4918\n",
      "(Validation) Loss: 771518.0965, MAE: 3291.2961, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [1263/5000] | Time: 0.24s\n",
      "(Training) Loss: 972513.1916\n",
      "(Validation) Loss: 771425.6559, MAE: 3291.5818, R2: 0.2158\n",
      "==========================================================================================\n",
      "Epoch [1264/5000] | Time: 0.27s\n",
      "(Training) Loss: 962867.2862\n",
      "(Validation) Loss: 771313.9073, MAE: 3286.0620, R2: 0.2159\n",
      "==========================================================================================\n",
      "Epoch [1265/5000] | Time: 0.25s\n",
      "(Training) Loss: 960651.3103\n",
      "(Validation) Loss: 771222.0254, MAE: 3288.0283, R2: 0.2160\n",
      "==========================================================================================\n",
      "Epoch [1266/5000] | Time: 0.25s\n",
      "(Training) Loss: 956875.3357\n",
      "(Validation) Loss: 771129.7168, MAE: 3288.2048, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [1267/5000] | Time: 0.25s\n",
      "(Training) Loss: 956366.0799\n",
      "(Validation) Loss: 771036.1086, MAE: 3287.7266, R2: 0.2162\n",
      "==========================================================================================\n",
      "Epoch [1268/5000] | Time: 0.24s\n",
      "(Training) Loss: 971772.8852\n",
      "(Validation) Loss: 770955.7467, MAE: 3288.5317, R2: 0.2163\n",
      "==========================================================================================\n",
      "Epoch [1269/5000] | Time: 0.26s\n",
      "(Training) Loss: 961240.4632\n",
      "(Validation) Loss: 770841.4870, MAE: 3285.8052, R2: 0.2164\n",
      "==========================================================================================\n",
      "Epoch [1270/5000] | Time: 0.26s\n",
      "(Training) Loss: 960216.6428\n",
      "(Validation) Loss: 770740.6629, MAE: 3284.4912, R2: 0.2165\n",
      "==========================================================================================\n",
      "Epoch [1271/5000] | Time: 0.34s\n",
      "(Training) Loss: 957309.5920\n",
      "(Validation) Loss: 770652.9930, MAE: 3284.7397, R2: 0.2166\n",
      "==========================================================================================\n",
      "Epoch [1272/5000] | Time: 0.28s\n",
      "(Training) Loss: 968862.0876\n",
      "(Validation) Loss: 770573.5054, MAE: 3288.7512, R2: 0.2166\n",
      "==========================================================================================\n",
      "Epoch [1273/5000] | Time: 0.25s\n",
      "(Training) Loss: 953020.7976\n",
      "(Validation) Loss: 757502.6921, MAE: 3241.7537, R2: 0.2298\n",
      "==========================================================================================\n",
      "Epoch [1274/5000] | Time: 0.30s\n",
      "(Training) Loss: 937934.3642\n",
      "(Validation) Loss: 757419.2667, MAE: 3240.7737, R2: 0.2299\n",
      "==========================================================================================\n",
      "Epoch [1275/5000] | Time: 0.30s\n",
      "(Training) Loss: 941641.5393\n",
      "(Validation) Loss: 757334.6184, MAE: 3239.9866, R2: 0.2300\n",
      "==========================================================================================\n",
      "Epoch [1276/5000] | Time: 0.30s\n",
      "(Training) Loss: 966100.0920\n",
      "(Validation) Loss: 757248.3359, MAE: 3240.3054, R2: 0.2301\n",
      "==========================================================================================\n",
      "Epoch [1277/5000] | Time: 0.35s\n",
      "(Training) Loss: 944628.8801\n",
      "(Validation) Loss: 757154.1162, MAE: 3238.5845, R2: 0.2302\n",
      "==========================================================================================\n",
      "Epoch [1278/5000] | Time: 0.30s\n",
      "(Training) Loss: 947810.1104\n",
      "(Validation) Loss: 757077.4997, MAE: 3239.8213, R2: 0.2302\n",
      "==========================================================================================\n",
      "Epoch [1279/5000] | Time: 0.26s\n",
      "(Training) Loss: 943497.2205\n",
      "(Validation) Loss: 756998.2311, MAE: 3242.8247, R2: 0.2303\n",
      "==========================================================================================\n",
      "Epoch [1280/5000] | Time: 0.25s\n",
      "(Training) Loss: 953909.1659\n",
      "(Validation) Loss: 756906.4203, MAE: 3239.5276, R2: 0.2304\n",
      "==========================================================================================\n",
      "Epoch [1281/5000] | Time: 0.26s\n",
      "(Training) Loss: 937187.8033\n",
      "(Validation) Loss: 756833.1911, MAE: 3240.8657, R2: 0.2305\n",
      "==========================================================================================\n",
      "Epoch [1282/5000] | Time: 0.22s\n",
      "(Training) Loss: 937386.0898\n",
      "(Validation) Loss: 756731.1727, MAE: 3238.5254, R2: 0.2306\n",
      "==========================================================================================\n",
      "Epoch [1283/5000] | Time: 0.23s\n",
      "(Training) Loss: 951456.8655\n",
      "(Validation) Loss: 756642.4908, MAE: 3236.8691, R2: 0.2307\n",
      "==========================================================================================\n",
      "Epoch [1284/5000] | Time: 0.21s\n",
      "(Training) Loss: 941252.9327\n",
      "(Validation) Loss: 756563.0914, MAE: 3238.1025, R2: 0.2308\n",
      "==========================================================================================\n",
      "Epoch [1285/5000] | Time: 0.26s\n",
      "(Training) Loss: 931971.6290\n",
      "(Validation) Loss: 756459.2076, MAE: 3235.3696, R2: 0.2309\n",
      "==========================================================================================\n",
      "Epoch [1286/5000] | Time: 0.25s\n",
      "(Training) Loss: 944595.2608\n",
      "(Validation) Loss: 756390.4705, MAE: 3238.6577, R2: 0.2309\n",
      "==========================================================================================\n",
      "Epoch [1287/5000] | Time: 0.24s\n",
      "(Training) Loss: 933189.8423\n",
      "(Validation) Loss: 756297.5752, MAE: 3235.8711, R2: 0.2310\n",
      "==========================================================================================\n",
      "Epoch [1288/5000] | Time: 0.23s\n",
      "(Training) Loss: 964580.9245\n",
      "(Validation) Loss: 760769.8781, MAE: 3278.5474, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [1289/5000] | Time: 0.23s\n",
      "(Training) Loss: 945468.4848\n",
      "(Validation) Loss: 760732.9314, MAE: 3294.3330, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [1290/5000] | Time: 0.22s\n",
      "(Training) Loss: 939608.7208\n",
      "(Validation) Loss: 760586.2813, MAE: 3274.3728, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [1291/5000] | Time: 0.23s\n",
      "(Training) Loss: 945959.2088\n",
      "(Validation) Loss: 760497.6933, MAE: 3275.8672, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [1292/5000] | Time: 0.24s\n",
      "(Training) Loss: 953762.4511\n",
      "(Validation) Loss: 760425.1162, MAE: 3279.3901, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [1293/5000] | Time: 0.22s\n",
      "(Training) Loss: 949388.7011\n",
      "(Validation) Loss: 760314.3911, MAE: 3273.4480, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [1294/5000] | Time: 0.23s\n",
      "(Training) Loss: 941235.5241\n",
      "(Validation) Loss: 760235.5403, MAE: 3276.9863, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [1295/5000] | Time: 0.27s\n",
      "(Training) Loss: 944205.9213\n",
      "(Validation) Loss: 760129.9886, MAE: 3272.3613, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [1296/5000] | Time: 0.26s\n",
      "(Training) Loss: 946585.3058\n",
      "(Validation) Loss: 760048.1429, MAE: 3274.5334, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [1297/5000] | Time: 0.23s\n",
      "(Training) Loss: 959091.5984\n",
      "(Validation) Loss: 759955.5086, MAE: 3272.4939, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [1298/5000] | Time: 0.25s\n",
      "(Training) Loss: 950008.6891\n",
      "(Validation) Loss: 774954.3333, MAE: 3329.4944, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [1299/5000] | Time: 0.25s\n",
      "(Training) Loss: 962342.9201\n",
      "(Validation) Loss: 774836.4502, MAE: 3322.3306, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [1300/5000] | Time: 0.26s\n",
      "(Training) Loss: 971899.5654\n",
      "(Validation) Loss: 774721.4337, MAE: 3312.3777, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [1301/5000] | Time: 0.23s\n",
      "(Training) Loss: 961358.8604\n",
      "(Validation) Loss: 774616.6800, MAE: 3307.9548, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [1302/5000] | Time: 0.23s\n",
      "(Training) Loss: 958740.3195\n",
      "(Validation) Loss: 774530.7149, MAE: 3306.3425, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [1303/5000] | Time: 0.24s\n",
      "(Training) Loss: 959267.5501\n",
      "(Validation) Loss: 774432.7549, MAE: 3306.4150, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [1304/5000] | Time: 0.27s\n",
      "(Training) Loss: 963377.1218\n",
      "(Validation) Loss: 774346.5581, MAE: 3306.7012, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [1305/5000] | Time: 0.24s\n",
      "(Training) Loss: 991225.2766\n",
      "(Validation) Loss: 774262.5638, MAE: 3313.3596, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [1306/5000] | Time: 0.24s\n",
      "(Training) Loss: 963407.4264\n",
      "(Validation) Loss: 774185.6863, MAE: 3311.2520, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [1307/5000] | Time: 0.25s\n",
      "(Training) Loss: 974379.7253\n",
      "(Validation) Loss: 774127.6921, MAE: 3315.1619, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [1308/5000] | Time: 0.23s\n",
      "(Training) Loss: 966952.8947\n",
      "(Validation) Loss: 773993.8737, MAE: 3306.7000, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [1309/5000] | Time: 0.26s\n",
      "(Training) Loss: 971798.1704\n",
      "(Validation) Loss: 773896.9092, MAE: 3304.1755, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [1310/5000] | Time: 0.23s\n",
      "(Training) Loss: 956392.7138\n",
      "(Validation) Loss: 773817.4425, MAE: 3305.9929, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [1311/5000] | Time: 0.24s\n",
      "(Training) Loss: 958877.8503\n",
      "(Validation) Loss: 765870.0432, MAE: 3296.7471, R2: 0.2214\n",
      "==========================================================================================\n",
      "Epoch [1312/5000] | Time: 0.24s\n",
      "(Training) Loss: 945663.7659\n",
      "(Validation) Loss: 765769.9632, MAE: 3280.0479, R2: 0.2215\n",
      "==========================================================================================\n",
      "Epoch [1313/5000] | Time: 0.25s\n",
      "(Training) Loss: 988775.2332\n",
      "(Validation) Loss: 765628.4165, MAE: 3267.5232, R2: 0.2216\n",
      "==========================================================================================\n",
      "Epoch [1314/5000] | Time: 0.24s\n",
      "(Training) Loss: 948202.4734\n",
      "(Validation) Loss: 765533.9854, MAE: 3267.2844, R2: 0.2217\n",
      "==========================================================================================\n",
      "Epoch [1315/5000] | Time: 0.26s\n",
      "(Training) Loss: 949303.4454\n",
      "(Validation) Loss: 765463.0933, MAE: 3269.8000, R2: 0.2218\n",
      "==========================================================================================\n",
      "Epoch [1316/5000] | Time: 0.26s\n",
      "(Training) Loss: 954954.1961\n",
      "(Validation) Loss: 765354.6838, MAE: 3265.9451, R2: 0.2219\n",
      "==========================================================================================\n",
      "Epoch [1317/5000] | Time: 0.26s\n",
      "(Training) Loss: 957085.4315\n",
      "(Validation) Loss: 765281.5517, MAE: 3270.3975, R2: 0.2220\n",
      "==========================================================================================\n",
      "Epoch [1318/5000] | Time: 0.28s\n",
      "(Training) Loss: 953797.7830\n",
      "(Validation) Loss: 765187.2654, MAE: 3270.3232, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [1319/5000] | Time: 0.25s\n",
      "(Training) Loss: 977632.0552\n",
      "(Validation) Loss: 765124.1810, MAE: 3274.4492, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [1320/5000] | Time: 0.23s\n",
      "(Training) Loss: 959110.4886\n",
      "(Validation) Loss: 765020.0559, MAE: 3266.9822, R2: 0.2222\n",
      "==========================================================================================\n",
      "Epoch [1321/5000] | Time: 0.25s\n",
      "(Training) Loss: 970906.1066\n",
      "(Validation) Loss: 764940.8108, MAE: 3267.6196, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [1322/5000] | Time: 0.25s\n",
      "(Training) Loss: 955781.9949\n",
      "(Validation) Loss: 764844.3206, MAE: 3266.6479, R2: 0.2224\n",
      "==========================================================================================\n",
      "Epoch [1323/5000] | Time: 0.23s\n",
      "(Training) Loss: 940629.7403\n",
      "(Validation) Loss: 764749.5467, MAE: 3265.4055, R2: 0.2225\n",
      "==========================================================================================\n",
      "Epoch [1324/5000] | Time: 0.25s\n",
      "(Training) Loss: 947647.8750\n",
      "(Validation) Loss: 764659.2825, MAE: 3264.7476, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [1325/5000] | Time: 0.24s\n",
      "(Training) Loss: 959784.2709\n",
      "(Validation) Loss: 764573.0057, MAE: 3264.3264, R2: 0.2227\n",
      "==========================================================================================\n",
      "Epoch [1326/5000] | Time: 0.24s\n",
      "(Training) Loss: 952444.1523\n",
      "(Validation) Loss: 764481.4521, MAE: 3263.9739, R2: 0.2228\n",
      "==========================================================================================\n",
      "Epoch [1327/5000] | Time: 0.23s\n",
      "(Training) Loss: 953128.2297\n",
      "(Validation) Loss: 764400.1111, MAE: 3265.1794, R2: 0.2229\n",
      "==========================================================================================\n",
      "Epoch [1328/5000] | Time: 0.23s\n",
      "(Training) Loss: 960407.0666\n",
      "(Validation) Loss: 764311.3079, MAE: 3264.6440, R2: 0.2229\n",
      "==========================================================================================\n",
      "Epoch [1329/5000] | Time: 0.22s\n",
      "(Training) Loss: 946012.3230\n",
      "(Validation) Loss: 764218.0800, MAE: 3263.6628, R2: 0.2230\n",
      "==========================================================================================\n",
      "Epoch [1330/5000] | Time: 0.23s\n",
      "(Training) Loss: 952104.7722\n",
      "(Validation) Loss: 764156.3530, MAE: 3267.6753, R2: 0.2231\n",
      "==========================================================================================\n",
      "Epoch [1331/5000] | Time: 0.26s\n",
      "(Training) Loss: 945184.7817\n",
      "(Validation) Loss: 764053.6629, MAE: 3264.9778, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [1332/5000] | Time: 0.27s\n",
      "(Training) Loss: 949200.4549\n",
      "(Validation) Loss: 763967.7365, MAE: 3266.4209, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [1333/5000] | Time: 0.29s\n",
      "(Training) Loss: 945825.4201\n",
      "(Validation) Loss: 763867.8527, MAE: 3262.4812, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [1334/5000] | Time: 0.26s\n",
      "(Training) Loss: 958327.9258\n",
      "(Validation) Loss: 763790.4013, MAE: 3264.2158, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [1335/5000] | Time: 0.29s\n",
      "(Training) Loss: 944614.2900\n",
      "(Validation) Loss: 763694.6508, MAE: 3263.1169, R2: 0.2236\n",
      "==========================================================================================\n",
      "Epoch [1336/5000] | Time: 0.28s\n",
      "(Training) Loss: 971887.6694\n",
      "(Validation) Loss: 763607.0375, MAE: 3262.5107, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [1337/5000] | Time: 0.27s\n",
      "(Training) Loss: 941753.4930\n",
      "(Validation) Loss: 763510.9930, MAE: 3262.2390, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [1338/5000] | Time: 0.35s\n",
      "(Training) Loss: 940300.5543\n",
      "(Validation) Loss: 763435.7194, MAE: 3264.0991, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [1339/5000] | Time: 0.27s\n",
      "(Training) Loss: 941761.7744\n",
      "(Validation) Loss: 763359.9841, MAE: 3266.2249, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [1340/5000] | Time: 0.29s\n",
      "(Training) Loss: 947597.3268\n",
      "(Validation) Loss: 763253.5949, MAE: 3262.4924, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [1341/5000] | Time: 0.30s\n",
      "(Training) Loss: 942374.1421\n",
      "(Validation) Loss: 763170.9702, MAE: 3264.5388, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [1342/5000] | Time: 0.30s\n",
      "(Training) Loss: 938227.2473\n",
      "(Validation) Loss: 763083.2463, MAE: 3263.4902, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [1343/5000] | Time: 0.27s\n",
      "(Training) Loss: 946707.3039\n",
      "(Validation) Loss: 763019.7784, MAE: 3268.2358, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [1344/5000] | Time: 0.27s\n",
      "(Training) Loss: 958710.0958\n",
      "(Validation) Loss: 762945.4895, MAE: 3266.9482, R2: 0.2243\n",
      "==========================================================================================\n",
      "Epoch [1345/5000] | Time: 0.25s\n",
      "(Training) Loss: 958533.0901\n",
      "(Validation) Loss: 762814.8584, MAE: 3259.2864, R2: 0.2245\n",
      "==========================================================================================\n",
      "Epoch [1346/5000] | Time: 0.24s\n",
      "(Training) Loss: 942655.7462\n",
      "(Validation) Loss: 762729.5505, MAE: 3260.6318, R2: 0.2245\n",
      "==========================================================================================\n",
      "Epoch [1347/5000] | Time: 0.24s\n",
      "(Training) Loss: 944036.6250\n",
      "(Validation) Loss: 762630.9676, MAE: 3256.7639, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [1348/5000] | Time: 0.24s\n",
      "(Training) Loss: 941244.7008\n",
      "(Validation) Loss: 762581.3740, MAE: 3264.2537, R2: 0.2247\n",
      "==========================================================================================\n",
      "Epoch [1349/5000] | Time: 0.25s\n",
      "(Training) Loss: 951000.4042\n",
      "(Validation) Loss: 762457.1600, MAE: 3256.3328, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [1350/5000] | Time: 0.25s\n",
      "(Training) Loss: 947444.6758\n",
      "(Validation) Loss: 762384.0413, MAE: 3258.8889, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [1351/5000] | Time: 0.27s\n",
      "(Training) Loss: 941567.2995\n",
      "(Validation) Loss: 762305.8781, MAE: 3260.3147, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [1352/5000] | Time: 0.24s\n",
      "(Training) Loss: 956610.6491\n",
      "(Validation) Loss: 762223.9092, MAE: 3261.3511, R2: 0.2251\n",
      "==========================================================================================\n",
      "Epoch [1353/5000] | Time: 0.23s\n",
      "(Training) Loss: 937972.8852\n",
      "(Validation) Loss: 762114.0394, MAE: 3257.6191, R2: 0.2252\n",
      "==========================================================================================\n",
      "Epoch [1354/5000] | Time: 0.23s\n",
      "(Training) Loss: 956211.7887\n",
      "(Validation) Loss: 762029.2356, MAE: 3256.8687, R2: 0.2252\n",
      "==========================================================================================\n",
      "Epoch [1355/5000] | Time: 0.24s\n",
      "(Training) Loss: 956085.1383\n",
      "(Validation) Loss: 761935.3822, MAE: 3257.7915, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [1356/5000] | Time: 0.23s\n",
      "(Training) Loss: 976356.1110\n",
      "(Validation) Loss: 761853.8432, MAE: 3257.3171, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [1357/5000] | Time: 0.24s\n",
      "(Training) Loss: 958775.7811\n",
      "(Validation) Loss: 761762.6844, MAE: 3255.7632, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [1358/5000] | Time: 0.23s\n",
      "(Training) Loss: 937672.0447\n",
      "(Validation) Loss: 761669.2051, MAE: 3254.8887, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [1359/5000] | Time: 0.26s\n",
      "(Training) Loss: 938134.8049\n",
      "(Validation) Loss: 761586.7333, MAE: 3256.0208, R2: 0.2257\n",
      "==========================================================================================\n",
      "Epoch [1360/5000] | Time: 0.25s\n",
      "(Training) Loss: 936262.8760\n",
      "(Validation) Loss: 761496.1378, MAE: 3255.0120, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [1361/5000] | Time: 0.25s\n",
      "(Training) Loss: 969700.1371\n",
      "(Validation) Loss: 761418.5784, MAE: 3255.6543, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [1362/5000] | Time: 0.22s\n",
      "(Training) Loss: 962841.9664\n",
      "(Validation) Loss: 761333.7606, MAE: 3257.2039, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [1363/5000] | Time: 0.23s\n",
      "(Training) Loss: 951788.0013\n",
      "(Validation) Loss: 761241.0648, MAE: 3255.2249, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [1364/5000] | Time: 0.23s\n",
      "(Training) Loss: 956207.9987\n",
      "(Validation) Loss: 761151.8495, MAE: 3255.3140, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [1365/5000] | Time: 0.22s\n",
      "(Training) Loss: 952333.5447\n",
      "(Validation) Loss: 761074.1619, MAE: 3255.8237, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [1366/5000] | Time: 0.24s\n",
      "(Training) Loss: 945103.8401\n",
      "(Validation) Loss: 760988.4851, MAE: 3256.6045, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [1367/5000] | Time: 0.25s\n",
      "(Training) Loss: 958577.9746\n",
      "(Validation) Loss: 760890.8089, MAE: 3254.0437, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [1368/5000] | Time: 0.28s\n",
      "(Training) Loss: 936425.1649\n",
      "(Validation) Loss: 760801.9975, MAE: 3253.2737, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [1369/5000] | Time: 0.27s\n",
      "(Training) Loss: 946442.1117\n",
      "(Validation) Loss: 760722.3898, MAE: 3254.7244, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [1370/5000] | Time: 0.24s\n",
      "(Training) Loss: 952400.8477\n",
      "(Validation) Loss: 760635.1289, MAE: 3254.4534, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [1371/5000] | Time: 0.31s\n",
      "(Training) Loss: 953611.5146\n",
      "(Validation) Loss: 760544.3111, MAE: 3255.5176, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [1372/5000] | Time: 0.27s\n",
      "(Training) Loss: 954312.2843\n",
      "(Validation) Loss: 760449.8984, MAE: 3253.2244, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [1373/5000] | Time: 0.26s\n",
      "(Training) Loss: 943138.6028\n",
      "(Validation) Loss: 760362.6559, MAE: 3250.7073, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [1374/5000] | Time: 0.23s\n",
      "(Training) Loss: 938391.3223\n",
      "(Validation) Loss: 760287.5651, MAE: 3253.9246, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [1375/5000] | Time: 0.25s\n",
      "(Training) Loss: 937424.9607\n",
      "(Validation) Loss: 760183.5422, MAE: 3248.5940, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [1376/5000] | Time: 0.24s\n",
      "(Training) Loss: 947607.1961\n",
      "(Validation) Loss: 760116.5194, MAE: 3251.8025, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [1377/5000] | Time: 0.25s\n",
      "(Training) Loss: 945244.3839\n",
      "(Validation) Loss: 760025.2533, MAE: 3252.3848, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [1378/5000] | Time: 0.22s\n",
      "(Training) Loss: 960716.8641\n",
      "(Validation) Loss: 759932.8813, MAE: 3251.1184, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [1379/5000] | Time: 0.26s\n",
      "(Training) Loss: 948718.3845\n",
      "(Validation) Loss: 759846.7302, MAE: 3249.7000, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [1380/5000] | Time: 0.22s\n",
      "(Training) Loss: 944162.8750\n",
      "(Validation) Loss: 759746.5467, MAE: 3246.6821, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [1381/5000] | Time: 0.22s\n",
      "(Training) Loss: 943004.7563\n",
      "(Validation) Loss: 759680.7346, MAE: 3253.6653, R2: 0.2276\n",
      "==========================================================================================\n",
      "Epoch [1382/5000] | Time: 0.22s\n",
      "(Training) Loss: 951018.2513\n",
      "(Validation) Loss: 759587.2102, MAE: 3251.9314, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [1383/5000] | Time: 0.22s\n",
      "(Training) Loss: 942246.1136\n",
      "(Validation) Loss: 759497.5479, MAE: 3249.9702, R2: 0.2278\n",
      "==========================================================================================\n",
      "Epoch [1384/5000] | Time: 0.22s\n",
      "(Training) Loss: 962300.5698\n",
      "(Validation) Loss: 759408.3835, MAE: 3248.5818, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [1385/5000] | Time: 0.22s\n",
      "(Training) Loss: 952986.5952\n",
      "(Validation) Loss: 759322.7384, MAE: 3248.9587, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [1386/5000] | Time: 0.29s\n",
      "(Training) Loss: 960344.2881\n",
      "(Validation) Loss: 759227.0673, MAE: 3249.7114, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [1387/5000] | Time: 0.45s\n",
      "(Training) Loss: 954365.4714\n",
      "(Validation) Loss: 759148.0089, MAE: 3252.5583, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [1388/5000] | Time: 0.25s\n",
      "(Training) Loss: 946343.7126\n",
      "(Validation) Loss: 759048.0876, MAE: 3247.4619, R2: 0.2283\n",
      "==========================================================================================\n",
      "Epoch [1389/5000] | Time: 0.25s\n",
      "(Training) Loss: 949852.5032\n",
      "(Validation) Loss: 758980.9314, MAE: 3250.5020, R2: 0.2283\n",
      "==========================================================================================\n",
      "Epoch [1390/5000] | Time: 0.23s\n",
      "(Training) Loss: 950564.2145\n",
      "(Validation) Loss: 758910.7867, MAE: 3252.3574, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [1391/5000] | Time: 0.21s\n",
      "(Training) Loss: 956014.7449\n",
      "(Validation) Loss: 758788.4400, MAE: 3245.6440, R2: 0.2285\n",
      "==========================================================================================\n",
      "Epoch [1392/5000] | Time: 0.21s\n",
      "(Training) Loss: 956997.0590\n",
      "(Validation) Loss: 758699.2927, MAE: 3245.6418, R2: 0.2286\n",
      "==========================================================================================\n",
      "Epoch [1393/5000] | Time: 0.21s\n",
      "(Training) Loss: 959295.4397\n",
      "(Validation) Loss: 758612.8730, MAE: 3243.9929, R2: 0.2287\n",
      "==========================================================================================\n",
      "Epoch [1394/5000] | Time: 0.23s\n",
      "(Training) Loss: 944550.2418\n",
      "(Validation) Loss: 758537.1632, MAE: 3247.8713, R2: 0.2288\n",
      "==========================================================================================\n",
      "Epoch [1395/5000] | Time: 0.24s\n",
      "(Training) Loss: 940092.9794\n",
      "(Validation) Loss: 758452.6470, MAE: 3247.3037, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [1396/5000] | Time: 0.28s\n",
      "(Training) Loss: 948898.9150\n",
      "(Validation) Loss: 758366.8489, MAE: 3247.3105, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [1397/5000] | Time: 0.24s\n",
      "(Training) Loss: 939262.8071\n",
      "(Validation) Loss: 758264.3352, MAE: 3242.9705, R2: 0.2290\n",
      "==========================================================================================\n",
      "Epoch [1398/5000] | Time: 0.26s\n",
      "(Training) Loss: 949446.6745\n",
      "(Validation) Loss: 758185.2190, MAE: 3244.9009, R2: 0.2291\n",
      "==========================================================================================\n",
      "Epoch [1399/5000] | Time: 0.27s\n",
      "(Training) Loss: 942724.4372\n",
      "(Validation) Loss: 758095.6648, MAE: 3244.3645, R2: 0.2292\n",
      "==========================================================================================\n",
      "Epoch [1400/5000] | Time: 0.26s\n",
      "(Training) Loss: 958227.2430\n",
      "(Validation) Loss: 758004.8787, MAE: 3244.1372, R2: 0.2293\n",
      "==========================================================================================\n",
      "Epoch [1401/5000] | Time: 0.31s\n",
      "(Training) Loss: 942318.8775\n",
      "(Validation) Loss: 757938.0279, MAE: 3247.5500, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [1402/5000] | Time: 0.28s\n",
      "(Training) Loss: 953397.0400\n",
      "(Validation) Loss: 757872.4711, MAE: 3247.6582, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [1403/5000] | Time: 0.30s\n",
      "(Training) Loss: 945124.8902\n",
      "(Validation) Loss: 757760.2419, MAE: 3245.3330, R2: 0.2295\n",
      "==========================================================================================\n",
      "Epoch [1404/5000] | Time: 0.30s\n",
      "(Training) Loss: 941108.0102\n",
      "(Validation) Loss: 757675.5702, MAE: 3265.3201, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [1405/5000] | Time: 0.27s\n",
      "(Training) Loss: 955678.7684\n",
      "(Validation) Loss: 757601.1689, MAE: 3250.9341, R2: 0.2297\n",
      "==========================================================================================\n",
      "Epoch [1406/5000] | Time: 0.30s\n",
      "(Training) Loss: 939844.2030\n",
      "(Validation) Loss: 757499.3638, MAE: 3246.0212, R2: 0.2298\n",
      "==========================================================================================\n",
      "Epoch [1407/5000] | Time: 0.27s\n",
      "(Training) Loss: 947315.0140\n",
      "(Validation) Loss: 757407.3829, MAE: 3242.5540, R2: 0.2299\n",
      "==========================================================================================\n",
      "Epoch [1408/5000] | Time: 0.26s\n",
      "(Training) Loss: 937186.4695\n",
      "(Validation) Loss: 757326.7041, MAE: 3244.4780, R2: 0.2300\n",
      "==========================================================================================\n",
      "Epoch [1409/5000] | Time: 0.26s\n",
      "(Training) Loss: 941442.8198\n",
      "(Validation) Loss: 757219.2406, MAE: 3239.4026, R2: 0.2301\n",
      "==========================================================================================\n",
      "Epoch [1410/5000] | Time: 0.25s\n",
      "(Training) Loss: 957922.7589\n",
      "(Validation) Loss: 771176.4127, MAE: 3284.7117, R2: 0.2160\n",
      "==========================================================================================\n",
      "Epoch [1411/5000] | Time: 0.28s\n",
      "(Training) Loss: 978358.9308\n",
      "(Validation) Loss: 771127.1162, MAE: 3294.7112, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [1412/5000] | Time: 0.32s\n",
      "(Training) Loss: 972330.5780\n",
      "(Validation) Loss: 770985.2565, MAE: 3286.0911, R2: 0.2162\n",
      "==========================================================================================\n",
      "Epoch [1413/5000] | Time: 0.28s\n",
      "(Training) Loss: 961224.8382\n",
      "(Validation) Loss: 770888.7175, MAE: 3284.7480, R2: 0.2163\n",
      "==========================================================================================\n",
      "Epoch [1414/5000] | Time: 0.29s\n",
      "(Training) Loss: 961615.0895\n",
      "(Validation) Loss: 770802.7194, MAE: 3285.7939, R2: 0.2164\n",
      "==========================================================================================\n",
      "Epoch [1415/5000] | Time: 0.27s\n",
      "(Training) Loss: 975700.4353\n",
      "(Validation) Loss: 770692.1479, MAE: 3283.4966, R2: 0.2165\n",
      "==========================================================================================\n",
      "Epoch [1416/5000] | Time: 0.37s\n",
      "(Training) Loss: 949827.8347\n",
      "(Validation) Loss: 770611.0432, MAE: 3285.7209, R2: 0.2166\n",
      "==========================================================================================\n",
      "Epoch [1417/5000] | Time: 0.28s\n",
      "(Training) Loss: 964236.9975\n",
      "(Validation) Loss: 770502.9168, MAE: 3282.2634, R2: 0.2167\n",
      "==========================================================================================\n",
      "Epoch [1418/5000] | Time: 0.26s\n",
      "(Training) Loss: 954556.9353\n",
      "(Validation) Loss: 770405.9289, MAE: 3280.8870, R2: 0.2168\n",
      "==========================================================================================\n",
      "Epoch [1419/5000] | Time: 0.30s\n",
      "(Training) Loss: 965598.1472\n",
      "(Validation) Loss: 770316.1638, MAE: 3281.6895, R2: 0.2169\n",
      "==========================================================================================\n",
      "Epoch [1420/5000] | Time: 0.29s\n",
      "(Training) Loss: 962838.8864\n",
      "(Validation) Loss: 770236.6565, MAE: 3284.3000, R2: 0.2170\n",
      "==========================================================================================\n",
      "Epoch [1421/5000] | Time: 0.29s\n",
      "(Training) Loss: 967926.5812\n",
      "(Validation) Loss: 770157.4444, MAE: 3285.4119, R2: 0.2171\n",
      "==========================================================================================\n",
      "Epoch [1422/5000] | Time: 0.28s\n",
      "(Training) Loss: 957549.6536\n",
      "(Validation) Loss: 770034.2781, MAE: 3280.2317, R2: 0.2172\n",
      "==========================================================================================\n",
      "Epoch [1423/5000] | Time: 0.31s\n",
      "(Training) Loss: 949639.2183\n",
      "(Validation) Loss: 769960.6724, MAE: 3284.2493, R2: 0.2173\n",
      "==========================================================================================\n",
      "Epoch [1424/5000] | Time: 0.29s\n",
      "(Training) Loss: 976278.5089\n",
      "(Validation) Loss: 769856.4959, MAE: 3282.1594, R2: 0.2174\n",
      "==========================================================================================\n",
      "Epoch [1425/5000] | Time: 0.30s\n",
      "(Training) Loss: 970058.8788\n",
      "(Validation) Loss: 769766.7168, MAE: 3281.4348, R2: 0.2175\n",
      "==========================================================================================\n",
      "Epoch [1426/5000] | Time: 0.31s\n",
      "(Training) Loss: 948755.5257\n",
      "(Validation) Loss: 769675.6152, MAE: 3282.0786, R2: 0.2175\n",
      "==========================================================================================\n",
      "Epoch [1427/5000] | Time: 0.33s\n",
      "(Training) Loss: 969622.5628\n",
      "(Validation) Loss: 769659.5346, MAE: 3288.3315, R2: 0.2176\n",
      "==========================================================================================\n",
      "Epoch [1428/5000] | Time: 0.34s\n",
      "(Training) Loss: 954305.1307\n",
      "(Validation) Loss: 769526.0032, MAE: 3285.7234, R2: 0.2177\n",
      "==========================================================================================\n",
      "Epoch [1429/5000] | Time: 0.42s\n",
      "(Training) Loss: 964060.7665\n",
      "(Validation) Loss: 769425.6083, MAE: 3282.3181, R2: 0.2178\n",
      "==========================================================================================\n",
      "Epoch [1430/5000] | Time: 0.37s\n",
      "(Training) Loss: 964986.3211\n",
      "(Validation) Loss: 769341.8622, MAE: 3285.7412, R2: 0.2179\n",
      "==========================================================================================\n",
      "Epoch [1431/5000] | Time: 0.35s\n",
      "(Training) Loss: 959710.1555\n",
      "(Validation) Loss: 769203.9663, MAE: 3278.0825, R2: 0.2180\n",
      "==========================================================================================\n",
      "Epoch [1432/5000] | Time: 0.32s\n",
      "(Training) Loss: 950845.9086\n",
      "(Validation) Loss: 769114.9181, MAE: 3279.1533, R2: 0.2181\n",
      "==========================================================================================\n",
      "Epoch [1433/5000] | Time: 0.36s\n",
      "(Training) Loss: 963499.4039\n",
      "(Validation) Loss: 769028.8584, MAE: 3279.6143, R2: 0.2182\n",
      "==========================================================================================\n",
      "Epoch [1434/5000] | Time: 0.28s\n",
      "(Training) Loss: 953569.1815\n",
      "(Validation) Loss: 768959.9010, MAE: 3284.9272, R2: 0.2183\n",
      "==========================================================================================\n",
      "Epoch [1435/5000] | Time: 0.34s\n",
      "(Training) Loss: 965216.6938\n",
      "(Validation) Loss: 768831.5746, MAE: 3276.6013, R2: 0.2184\n",
      "==========================================================================================\n",
      "Epoch [1436/5000] | Time: 0.31s\n",
      "(Training) Loss: 968010.3547\n",
      "(Validation) Loss: 768767.4933, MAE: 3281.8687, R2: 0.2185\n",
      "==========================================================================================\n",
      "Epoch [1437/5000] | Time: 0.26s\n",
      "(Training) Loss: 947585.9232\n",
      "(Validation) Loss: 768644.3105, MAE: 3275.0718, R2: 0.2186\n",
      "==========================================================================================\n",
      "Epoch [1438/5000] | Time: 0.27s\n",
      "(Training) Loss: 950627.4575\n",
      "(Validation) Loss: 768563.2857, MAE: 3276.7693, R2: 0.2187\n",
      "==========================================================================================\n",
      "Epoch [1439/5000] | Time: 0.24s\n",
      "(Training) Loss: 948902.1453\n",
      "(Validation) Loss: 768475.4013, MAE: 3277.4888, R2: 0.2188\n",
      "==========================================================================================\n",
      "Epoch [1440/5000] | Time: 0.23s\n",
      "(Training) Loss: 955986.0596\n",
      "(Validation) Loss: 768374.7232, MAE: 3274.4246, R2: 0.2189\n",
      "==========================================================================================\n",
      "Epoch [1441/5000] | Time: 0.25s\n",
      "(Training) Loss: 963338.7437\n",
      "(Validation) Loss: 768284.3733, MAE: 3274.6680, R2: 0.2189\n",
      "==========================================================================================\n",
      "Epoch [1442/5000] | Time: 0.24s\n",
      "(Training) Loss: 956728.0761\n",
      "(Validation) Loss: 768214.3556, MAE: 3278.4473, R2: 0.2190\n",
      "==========================================================================================\n",
      "Epoch [1443/5000] | Time: 0.24s\n",
      "(Training) Loss: 949610.3852\n",
      "(Validation) Loss: 765147.0184, MAE: 3270.6455, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [1444/5000] | Time: 0.23s\n",
      "(Training) Loss: 959803.2544\n",
      "(Validation) Loss: 765029.8698, MAE: 3265.4419, R2: 0.2222\n",
      "==========================================================================================\n",
      "Epoch [1445/5000] | Time: 0.26s\n",
      "(Training) Loss: 963914.8363\n",
      "(Validation) Loss: 764941.3429, MAE: 3263.5356, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [1446/5000] | Time: 0.25s\n",
      "(Training) Loss: 945967.2462\n",
      "(Validation) Loss: 764854.6400, MAE: 3264.6416, R2: 0.2224\n",
      "==========================================================================================\n",
      "Epoch [1447/5000] | Time: 0.24s\n",
      "(Training) Loss: 949779.7316\n",
      "(Validation) Loss: 764777.8273, MAE: 3264.7200, R2: 0.2225\n",
      "==========================================================================================\n",
      "Epoch [1448/5000] | Time: 0.25s\n",
      "(Training) Loss: 966258.5025\n",
      "(Validation) Loss: 764670.9905, MAE: 3260.6392, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [1449/5000] | Time: 0.25s\n",
      "(Training) Loss: 940099.7375\n",
      "(Validation) Loss: 764583.9790, MAE: 3259.1714, R2: 0.2227\n",
      "==========================================================================================\n",
      "Epoch [1450/5000] | Time: 0.24s\n",
      "(Training) Loss: 952184.5692\n",
      "(Validation) Loss: 764640.8775, MAE: 3271.9404, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [1451/5000] | Time: 0.26s\n",
      "(Training) Loss: 951304.0311\n",
      "(Validation) Loss: 764544.4978, MAE: 3268.5542, R2: 0.2227\n",
      "==========================================================================================\n",
      "Epoch [1452/5000] | Time: 0.26s\n",
      "(Training) Loss: 941152.0349\n",
      "(Validation) Loss: 764468.7981, MAE: 3271.8047, R2: 0.2228\n",
      "==========================================================================================\n",
      "Epoch [1453/5000] | Time: 0.26s\n",
      "(Training) Loss: 957008.1123\n",
      "(Validation) Loss: 764372.2857, MAE: 3269.5898, R2: 0.2229\n",
      "==========================================================================================\n",
      "Epoch [1454/5000] | Time: 0.29s\n",
      "(Training) Loss: 946775.8864\n",
      "(Validation) Loss: 764287.0406, MAE: 3271.0610, R2: 0.2230\n",
      "==========================================================================================\n",
      "Epoch [1455/5000] | Time: 0.28s\n",
      "(Training) Loss: 951741.3547\n",
      "(Validation) Loss: 764199.2940, MAE: 3270.1384, R2: 0.2231\n",
      "==========================================================================================\n",
      "Epoch [1456/5000] | Time: 0.27s\n",
      "(Training) Loss: 940039.6312\n",
      "(Validation) Loss: 764106.9771, MAE: 3272.2749, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [1457/5000] | Time: 0.27s\n",
      "(Training) Loss: 944032.5438\n",
      "(Validation) Loss: 764037.3410, MAE: 3273.3711, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [1458/5000] | Time: 0.27s\n",
      "(Training) Loss: 947187.0844\n",
      "(Validation) Loss: 763937.3181, MAE: 3270.6956, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [1459/5000] | Time: 0.26s\n",
      "(Training) Loss: 941338.1758\n",
      "(Validation) Loss: 763848.2032, MAE: 3271.8259, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [1460/5000] | Time: 0.25s\n",
      "(Training) Loss: 940328.3138\n",
      "(Validation) Loss: 763749.7454, MAE: 3266.0437, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [1461/5000] | Time: 0.26s\n",
      "(Training) Loss: 965370.6282\n",
      "(Validation) Loss: 763701.6584, MAE: 3270.8689, R2: 0.2236\n",
      "==========================================================================================\n",
      "Epoch [1462/5000] | Time: 0.26s\n",
      "(Training) Loss: 941791.1808\n",
      "(Validation) Loss: 763580.3492, MAE: 3266.2576, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [1463/5000] | Time: 0.25s\n",
      "(Training) Loss: 940874.6735\n",
      "(Validation) Loss: 763489.6032, MAE: 3265.9841, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [1464/5000] | Time: 0.25s\n",
      "(Training) Loss: 949132.9048\n",
      "(Validation) Loss: 763402.6083, MAE: 3266.2815, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [1465/5000] | Time: 0.25s\n",
      "(Training) Loss: 942596.3484\n",
      "(Validation) Loss: 763332.5225, MAE: 3273.7634, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [1466/5000] | Time: 0.25s\n",
      "(Training) Loss: 954337.7316\n",
      "(Validation) Loss: 763232.9403, MAE: 3269.5823, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [1467/5000] | Time: 0.26s\n",
      "(Training) Loss: 934631.1681\n",
      "(Validation) Loss: 756884.7029, MAE: 3245.8818, R2: 0.2304\n",
      "==========================================================================================\n",
      "Epoch [1468/5000] | Time: 0.26s\n",
      "(Training) Loss: 939747.3839\n",
      "(Validation) Loss: 756791.3759, MAE: 3244.6577, R2: 0.2305\n",
      "==========================================================================================\n",
      "Epoch [1469/5000] | Time: 0.26s\n",
      "(Training) Loss: 943310.5527\n",
      "(Validation) Loss: 756691.8965, MAE: 3242.2549, R2: 0.2306\n",
      "==========================================================================================\n",
      "Epoch [1470/5000] | Time: 0.23s\n",
      "(Training) Loss: 936283.1136\n",
      "(Validation) Loss: 757436.7968, MAE: 3247.8423, R2: 0.2299\n",
      "==========================================================================================\n",
      "Epoch [1471/5000] | Time: 0.25s\n",
      "(Training) Loss: 938583.3515\n",
      "(Validation) Loss: 757341.4375, MAE: 3246.5327, R2: 0.2300\n",
      "==========================================================================================\n",
      "Epoch [1472/5000] | Time: 0.27s\n",
      "(Training) Loss: 971195.7855\n",
      "(Validation) Loss: 757238.7257, MAE: 3245.7026, R2: 0.2301\n",
      "==========================================================================================\n",
      "Epoch [1473/5000] | Time: 0.23s\n",
      "(Training) Loss: 939102.0013\n",
      "(Validation) Loss: 757131.8584, MAE: 3242.3740, R2: 0.2302\n",
      "==========================================================================================\n",
      "Epoch [1474/5000] | Time: 0.25s\n",
      "(Training) Loss: 954318.2811\n",
      "(Validation) Loss: 757051.0724, MAE: 3245.9241, R2: 0.2303\n",
      "==========================================================================================\n",
      "Epoch [1475/5000] | Time: 0.26s\n",
      "(Training) Loss: 951688.9797\n",
      "(Validation) Loss: 756944.3873, MAE: 3243.6067, R2: 0.2304\n",
      "==========================================================================================\n",
      "Epoch [1476/5000] | Time: 0.30s\n",
      "(Training) Loss: 940077.7335\n",
      "(Validation) Loss: 756846.5270, MAE: 3242.1184, R2: 0.2305\n",
      "==========================================================================================\n",
      "Epoch [1477/5000] | Time: 0.30s\n",
      "(Training) Loss: 935352.6320\n",
      "(Validation) Loss: 756755.1403, MAE: 3244.7021, R2: 0.2306\n",
      "==========================================================================================\n",
      "Epoch [1478/5000] | Time: 0.24s\n",
      "(Training) Loss: 934579.8055\n",
      "(Validation) Loss: 756659.7943, MAE: 3243.7512, R2: 0.2307\n",
      "==========================================================================================\n",
      "Epoch [1479/5000] | Time: 0.27s\n",
      "(Training) Loss: 931101.9351\n",
      "(Validation) Loss: 756559.0089, MAE: 3241.9590, R2: 0.2308\n",
      "==========================================================================================\n",
      "Epoch [1480/5000] | Time: 0.29s\n",
      "(Training) Loss: 956477.8648\n",
      "(Validation) Loss: 756474.1194, MAE: 3242.6438, R2: 0.2308\n",
      "==========================================================================================\n",
      "Epoch [1481/5000] | Time: 0.26s\n",
      "(Training) Loss: 941945.5990\n",
      "(Validation) Loss: 756383.1448, MAE: 3249.1328, R2: 0.2309\n",
      "==========================================================================================\n",
      "Epoch [1482/5000] | Time: 0.27s\n",
      "(Training) Loss: 951414.3493\n",
      "(Validation) Loss: 756309.8343, MAE: 3247.5959, R2: 0.2310\n",
      "==========================================================================================\n",
      "Epoch [1483/5000] | Time: 0.28s\n",
      "(Training) Loss: 957276.2475\n",
      "(Validation) Loss: 756207.7213, MAE: 3247.5786, R2: 0.2311\n",
      "==========================================================================================\n",
      "Epoch [1484/5000] | Time: 0.27s\n",
      "(Training) Loss: 950064.6802\n",
      "(Validation) Loss: 756102.4216, MAE: 3242.4712, R2: 0.2312\n",
      "==========================================================================================\n",
      "Epoch [1485/5000] | Time: 0.25s\n",
      "(Training) Loss: 939390.0806\n",
      "(Validation) Loss: 756008.2717, MAE: 3241.2991, R2: 0.2313\n",
      "==========================================================================================\n",
      "Epoch [1486/5000] | Time: 0.29s\n",
      "(Training) Loss: 958320.1745\n",
      "(Validation) Loss: 755914.7111, MAE: 3241.1621, R2: 0.2314\n",
      "==========================================================================================\n",
      "Epoch [1487/5000] | Time: 0.26s\n",
      "(Training) Loss: 945865.4511\n",
      "(Validation) Loss: 755818.5733, MAE: 3239.8647, R2: 0.2315\n",
      "==========================================================================================\n",
      "Epoch [1488/5000] | Time: 0.26s\n",
      "(Training) Loss: 952550.2811\n",
      "(Validation) Loss: 755736.6965, MAE: 3242.1138, R2: 0.2316\n",
      "==========================================================================================\n",
      "Epoch [1489/5000] | Time: 0.25s\n",
      "(Training) Loss: 942803.1539\n",
      "(Validation) Loss: 755626.1937, MAE: 3237.2837, R2: 0.2317\n",
      "==========================================================================================\n",
      "Epoch [1490/5000] | Time: 0.24s\n",
      "(Training) Loss: 934157.9067\n",
      "(Validation) Loss: 755537.1708, MAE: 3238.5054, R2: 0.2318\n",
      "==========================================================================================\n",
      "Epoch [1491/5000] | Time: 0.25s\n",
      "(Training) Loss: 931088.0476\n",
      "(Validation) Loss: 755450.9905, MAE: 3239.3474, R2: 0.2319\n",
      "==========================================================================================\n",
      "Epoch [1492/5000] | Time: 0.27s\n",
      "(Training) Loss: 948509.8940\n",
      "(Validation) Loss: 755350.2565, MAE: 3236.3713, R2: 0.2320\n",
      "==========================================================================================\n",
      "Epoch [1493/5000] | Time: 0.31s\n",
      "(Training) Loss: 932098.6253\n",
      "(Validation) Loss: 755279.0597, MAE: 3242.1880, R2: 0.2320\n",
      "==========================================================================================\n",
      "Epoch [1494/5000] | Time: 0.23s\n",
      "(Training) Loss: 965575.6294\n",
      "(Validation) Loss: 755172.5829, MAE: 3236.9343, R2: 0.2322\n",
      "==========================================================================================\n",
      "Epoch [1495/5000] | Time: 0.25s\n",
      "(Training) Loss: 929814.7774\n",
      "(Validation) Loss: 755080.1625, MAE: 3237.0964, R2: 0.2322\n",
      "==========================================================================================\n",
      "Epoch [1496/5000] | Time: 0.24s\n",
      "(Training) Loss: 929221.5382\n",
      "(Validation) Loss: 754996.3410, MAE: 3238.3396, R2: 0.2323\n",
      "==========================================================================================\n",
      "Epoch [1497/5000] | Time: 0.26s\n",
      "(Training) Loss: 942277.5952\n",
      "(Validation) Loss: 754899.0343, MAE: 3236.1079, R2: 0.2324\n",
      "==========================================================================================\n",
      "Epoch [1498/5000] | Time: 0.30s\n",
      "(Training) Loss: 956872.7919\n",
      "(Validation) Loss: 754798.8311, MAE: 3232.9250, R2: 0.2325\n",
      "==========================================================================================\n",
      "Epoch [1499/5000] | Time: 0.32s\n",
      "(Training) Loss: 941325.5596\n",
      "(Validation) Loss: 754716.7822, MAE: 3235.5911, R2: 0.2326\n",
      "==========================================================================================\n",
      "Epoch [1500/5000] | Time: 0.27s\n",
      "(Training) Loss: 938348.8642\n",
      "(Validation) Loss: 754633.5060, MAE: 3236.9929, R2: 0.2327\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch1500.pth\n",
      "==========================================================================================\n",
      "Epoch [1501/5000] | Time: 0.29s\n",
      "(Training) Loss: 942959.0298\n",
      "(Validation) Loss: 754565.8019, MAE: 3241.9167, R2: 0.2328\n",
      "==========================================================================================\n",
      "Epoch [1502/5000] | Time: 0.32s\n",
      "(Training) Loss: 946790.7335\n",
      "(Validation) Loss: 754455.2438, MAE: 3237.8845, R2: 0.2329\n",
      "==========================================================================================\n",
      "Epoch [1503/5000] | Time: 0.25s\n",
      "(Training) Loss: 936404.4407\n",
      "(Validation) Loss: 754340.1035, MAE: 3230.9531, R2: 0.2330\n",
      "==========================================================================================\n",
      "Epoch [1504/5000] | Time: 0.26s\n",
      "(Training) Loss: 935356.4791\n",
      "(Validation) Loss: 754255.2203, MAE: 3234.1812, R2: 0.2331\n",
      "==========================================================================================\n",
      "Epoch [1505/5000] | Time: 0.25s\n",
      "(Training) Loss: 957207.6053\n",
      "(Validation) Loss: 754165.5149, MAE: 3235.8728, R2: 0.2332\n",
      "==========================================================================================\n",
      "Epoch [1506/5000] | Time: 0.23s\n",
      "(Training) Loss: 944307.7176\n",
      "(Validation) Loss: 754073.0260, MAE: 3232.2878, R2: 0.2333\n",
      "==========================================================================================\n",
      "Epoch [1507/5000] | Time: 0.26s\n",
      "(Training) Loss: 936868.3718\n",
      "(Validation) Loss: 754067.5632, MAE: 3237.2644, R2: 0.2333\n",
      "==========================================================================================\n",
      "Epoch [1508/5000] | Time: 0.22s\n",
      "(Training) Loss: 928551.8265\n",
      "(Validation) Loss: 753974.2063, MAE: 3237.8577, R2: 0.2334\n",
      "==========================================================================================\n",
      "Epoch [1509/5000] | Time: 0.25s\n",
      "(Training) Loss: 938817.4745\n",
      "(Validation) Loss: 753891.5219, MAE: 3241.7019, R2: 0.2334\n",
      "==========================================================================================\n",
      "Epoch [1510/5000] | Time: 0.26s\n",
      "(Training) Loss: 939274.6612\n",
      "(Validation) Loss: 753794.5594, MAE: 3237.9490, R2: 0.2335\n",
      "==========================================================================================\n",
      "Epoch [1511/5000] | Time: 0.24s\n",
      "(Training) Loss: 942769.4879\n",
      "(Validation) Loss: 753704.7771, MAE: 3238.1016, R2: 0.2336\n",
      "==========================================================================================\n",
      "Epoch [1512/5000] | Time: 0.23s\n",
      "(Training) Loss: 940768.8458\n",
      "(Validation) Loss: 753612.5695, MAE: 3236.2200, R2: 0.2337\n",
      "==========================================================================================\n",
      "Epoch [1513/5000] | Time: 0.28s\n",
      "(Training) Loss: 929991.0044\n",
      "(Validation) Loss: 753519.6654, MAE: 3237.0093, R2: 0.2338\n",
      "==========================================================================================\n",
      "Epoch [1514/5000] | Time: 0.23s\n",
      "(Training) Loss: 929004.4048\n",
      "(Validation) Loss: 753439.6533, MAE: 3240.8479, R2: 0.2339\n",
      "==========================================================================================\n",
      "Epoch [1515/5000] | Time: 0.31s\n",
      "(Training) Loss: 936805.8439\n",
      "(Validation) Loss: 753345.2648, MAE: 3237.8750, R2: 0.2340\n",
      "==========================================================================================\n",
      "Epoch [1516/5000] | Time: 0.30s\n",
      "(Training) Loss: 931724.1263\n",
      "(Validation) Loss: 753261.1949, MAE: 3239.8823, R2: 0.2341\n",
      "==========================================================================================\n",
      "Epoch [1517/5000] | Time: 0.35s\n",
      "(Training) Loss: 944245.0654\n",
      "(Validation) Loss: 753161.6222, MAE: 3237.1619, R2: 0.2342\n",
      "==========================================================================================\n",
      "Epoch [1518/5000] | Time: 0.32s\n",
      "(Training) Loss: 955910.1865\n",
      "(Validation) Loss: 753066.8971, MAE: 3235.0234, R2: 0.2343\n",
      "==========================================================================================\n",
      "Epoch [1519/5000] | Time: 0.32s\n",
      "(Training) Loss: 955316.4220\n",
      "(Validation) Loss: 752973.1429, MAE: 3234.1914, R2: 0.2344\n",
      "==========================================================================================\n",
      "Epoch [1520/5000] | Time: 0.31s\n",
      "(Training) Loss: 934221.4385\n",
      "(Validation) Loss: 752884.0184, MAE: 3235.6492, R2: 0.2345\n",
      "==========================================================================================\n",
      "Epoch [1521/5000] | Time: 0.27s\n",
      "(Training) Loss: 939689.7398\n",
      "(Validation) Loss: 752787.2679, MAE: 3233.3223, R2: 0.2346\n",
      "==========================================================================================\n",
      "Epoch [1522/5000] | Time: 0.31s\n",
      "(Training) Loss: 945015.6688\n",
      "(Validation) Loss: 752695.0057, MAE: 3231.7783, R2: 0.2346\n",
      "==========================================================================================\n",
      "Epoch [1523/5000] | Time: 0.34s\n",
      "(Training) Loss: 935721.4048\n",
      "(Validation) Loss: 752601.6451, MAE: 3232.8491, R2: 0.2347\n",
      "==========================================================================================\n",
      "Epoch [1524/5000] | Time: 0.27s\n",
      "(Training) Loss: 928328.2126\n",
      "(Validation) Loss: 752509.7714, MAE: 3231.9531, R2: 0.2348\n",
      "==========================================================================================\n",
      "Epoch [1525/5000] | Time: 0.31s\n",
      "(Training) Loss: 930322.0336\n",
      "(Validation) Loss: 752419.5130, MAE: 3230.7244, R2: 0.2349\n",
      "==========================================================================================\n",
      "Epoch [1526/5000] | Time: 0.31s\n",
      "(Training) Loss: 932834.7801\n",
      "(Validation) Loss: 752333.0190, MAE: 3231.5200, R2: 0.2350\n",
      "==========================================================================================\n",
      "Epoch [1527/5000] | Time: 0.28s\n",
      "(Training) Loss: 935359.1770\n",
      "(Validation) Loss: 752246.6432, MAE: 3231.9072, R2: 0.2351\n",
      "==========================================================================================\n",
      "Epoch [1528/5000] | Time: 0.30s\n",
      "(Training) Loss: 952760.6453\n",
      "(Validation) Loss: 752157.5829, MAE: 3231.7168, R2: 0.2352\n",
      "==========================================================================================\n",
      "Epoch [1529/5000] | Time: 0.28s\n",
      "(Training) Loss: 932112.1377\n",
      "(Validation) Loss: 752058.2457, MAE: 3230.1885, R2: 0.2353\n",
      "==========================================================================================\n",
      "Epoch [1530/5000] | Time: 0.26s\n",
      "(Training) Loss: 961340.3744\n",
      "(Validation) Loss: 751975.6394, MAE: 3232.9109, R2: 0.2354\n",
      "==========================================================================================\n",
      "Epoch [1531/5000] | Time: 0.27s\n",
      "(Training) Loss: 947730.1605\n",
      "(Validation) Loss: 751886.6260, MAE: 3233.1521, R2: 0.2355\n",
      "==========================================================================================\n",
      "Epoch [1532/5000] | Time: 0.28s\n",
      "(Training) Loss: 929111.5419\n",
      "(Validation) Loss: 751790.5232, MAE: 3231.0391, R2: 0.2356\n",
      "==========================================================================================\n",
      "Epoch [1533/5000] | Time: 0.30s\n",
      "(Training) Loss: 939959.3458\n",
      "(Validation) Loss: 751696.4876, MAE: 3230.6138, R2: 0.2357\n",
      "==========================================================================================\n",
      "Epoch [1534/5000] | Time: 0.28s\n",
      "(Training) Loss: 943571.4721\n",
      "(Validation) Loss: 751611.8768, MAE: 3233.0698, R2: 0.2357\n",
      "==========================================================================================\n",
      "Epoch [1535/5000] | Time: 0.29s\n",
      "(Training) Loss: 930051.1542\n",
      "(Validation) Loss: 751519.1263, MAE: 3233.2773, R2: 0.2358\n",
      "==========================================================================================\n",
      "Epoch [1536/5000] | Time: 0.31s\n",
      "(Training) Loss: 935293.8154\n",
      "(Validation) Loss: 751431.8146, MAE: 3233.1345, R2: 0.2359\n",
      "==========================================================================================\n",
      "Epoch [1537/5000] | Time: 0.27s\n",
      "(Training) Loss: 938044.5641\n",
      "(Validation) Loss: 751333.3283, MAE: 3229.5559, R2: 0.2360\n",
      "==========================================================================================\n",
      "Epoch [1538/5000] | Time: 0.29s\n",
      "(Training) Loss: 927231.5596\n",
      "(Validation) Loss: 751242.5968, MAE: 3228.7302, R2: 0.2361\n",
      "==========================================================================================\n",
      "Epoch [1539/5000] | Time: 0.29s\n",
      "(Training) Loss: 956978.3744\n",
      "(Validation) Loss: 751155.9619, MAE: 3228.6394, R2: 0.2362\n",
      "==========================================================================================\n",
      "Epoch [1540/5000] | Time: 0.27s\n",
      "(Training) Loss: 928740.0584\n",
      "(Validation) Loss: 751060.7524, MAE: 3229.5610, R2: 0.2363\n",
      "==========================================================================================\n",
      "Epoch [1541/5000] | Time: 0.29s\n",
      "(Training) Loss: 946415.5685\n",
      "(Validation) Loss: 750995.3708, MAE: 3240.8750, R2: 0.2364\n",
      "==========================================================================================\n",
      "Epoch [1542/5000] | Time: 0.33s\n",
      "(Training) Loss: 941349.0647\n",
      "(Validation) Loss: 750880.5295, MAE: 3230.6460, R2: 0.2365\n",
      "==========================================================================================\n",
      "Epoch [1543/5000] | Time: 0.37s\n",
      "(Training) Loss: 939337.0019\n",
      "(Validation) Loss: 750796.6451, MAE: 3233.6162, R2: 0.2366\n",
      "==========================================================================================\n",
      "Epoch [1544/5000] | Time: 0.32s\n",
      "(Training) Loss: 928463.0692\n",
      "(Validation) Loss: 750715.6692, MAE: 3236.1621, R2: 0.2366\n",
      "==========================================================================================\n",
      "Epoch [1545/5000] | Time: 0.26s\n",
      "(Training) Loss: 932421.1294\n",
      "(Validation) Loss: 750619.5333, MAE: 3232.9863, R2: 0.2367\n",
      "==========================================================================================\n",
      "Epoch [1546/5000] | Time: 0.28s\n",
      "(Training) Loss: 953111.8515\n",
      "(Validation) Loss: 750530.1911, MAE: 3233.4451, R2: 0.2368\n",
      "==========================================================================================\n",
      "Epoch [1547/5000] | Time: 0.27s\n",
      "(Training) Loss: 933877.7246\n",
      "(Validation) Loss: 750448.4775, MAE: 3234.1772, R2: 0.2369\n",
      "==========================================================================================\n",
      "Epoch [1548/5000] | Time: 0.29s\n",
      "(Training) Loss: 938833.9746\n",
      "(Validation) Loss: 750344.7632, MAE: 3231.4072, R2: 0.2370\n",
      "==========================================================================================\n",
      "Epoch [1549/5000] | Time: 0.30s\n",
      "(Training) Loss: 943382.2437\n",
      "(Validation) Loss: 750252.0724, MAE: 3230.7610, R2: 0.2371\n",
      "==========================================================================================\n",
      "Epoch [1550/5000] | Time: 0.28s\n",
      "(Training) Loss: 935091.0197\n",
      "(Validation) Loss: 750168.1683, MAE: 3231.9993, R2: 0.2372\n",
      "==========================================================================================\n",
      "Epoch [1551/5000] | Time: 0.26s\n",
      "(Training) Loss: 939167.8813\n",
      "(Validation) Loss: 750079.6025, MAE: 3231.8457, R2: 0.2373\n",
      "==========================================================================================\n",
      "Epoch [1552/5000] | Time: 0.25s\n",
      "(Training) Loss: 939830.0565\n",
      "(Validation) Loss: 749977.5714, MAE: 3228.3347, R2: 0.2374\n",
      "==========================================================================================\n",
      "Epoch [1553/5000] | Time: 0.27s\n",
      "(Training) Loss: 934113.0882\n",
      "(Validation) Loss: 749884.2686, MAE: 3227.6367, R2: 0.2375\n",
      "==========================================================================================\n",
      "Epoch [1554/5000] | Time: 0.24s\n",
      "(Training) Loss: 943916.2011\n",
      "(Validation) Loss: 749798.8444, MAE: 3228.9146, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [1555/5000] | Time: 0.27s\n",
      "(Training) Loss: 949130.1891\n",
      "(Validation) Loss: 749718.4698, MAE: 3231.7058, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [1556/5000] | Time: 0.25s\n",
      "(Training) Loss: 949826.1104\n",
      "(Validation) Loss: 749617.8324, MAE: 3229.6990, R2: 0.2378\n",
      "==========================================================================================\n",
      "Epoch [1557/5000] | Time: 0.26s\n",
      "(Training) Loss: 972235.6561\n",
      "(Validation) Loss: 749520.2832, MAE: 3225.8406, R2: 0.2378\n",
      "==========================================================================================\n",
      "Epoch [1558/5000] | Time: 0.27s\n",
      "(Training) Loss: 933835.1708\n",
      "(Validation) Loss: 749427.1194, MAE: 3225.8530, R2: 0.2379\n",
      "==========================================================================================\n",
      "Epoch [1559/5000] | Time: 0.26s\n",
      "(Training) Loss: 935657.1491\n",
      "(Validation) Loss: 749343.7460, MAE: 3229.5552, R2: 0.2380\n",
      "==========================================================================================\n",
      "Epoch [1560/5000] | Time: 0.24s\n",
      "(Training) Loss: 933427.5140\n",
      "(Validation) Loss: 749251.6514, MAE: 3225.7424, R2: 0.2381\n",
      "==========================================================================================\n",
      "Epoch [1561/5000] | Time: 0.25s\n",
      "(Training) Loss: 925914.0676\n",
      "(Validation) Loss: 749158.8121, MAE: 3224.8914, R2: 0.2382\n",
      "==========================================================================================\n",
      "Epoch [1562/5000] | Time: 0.29s\n",
      "(Training) Loss: 928547.7351\n",
      "(Validation) Loss: 749073.6673, MAE: 3225.9250, R2: 0.2383\n",
      "==========================================================================================\n",
      "Epoch [1563/5000] | Time: 0.26s\n",
      "(Training) Loss: 922038.3855\n",
      "(Validation) Loss: 748984.4305, MAE: 3225.8511, R2: 0.2384\n",
      "==========================================================================================\n",
      "Epoch [1564/5000] | Time: 0.26s\n",
      "(Training) Loss: 951511.3319\n",
      "(Validation) Loss: 748895.4070, MAE: 3224.4504, R2: 0.2385\n",
      "==========================================================================================\n",
      "Epoch [1565/5000] | Time: 0.22s\n",
      "(Training) Loss: 934279.3775\n",
      "(Validation) Loss: 748798.5981, MAE: 3223.4312, R2: 0.2386\n",
      "==========================================================================================\n",
      "Epoch [1566/5000] | Time: 0.24s\n",
      "(Training) Loss: 938206.6240\n",
      "(Validation) Loss: 748720.5987, MAE: 3224.4531, R2: 0.2387\n",
      "==========================================================================================\n",
      "Epoch [1567/5000] | Time: 0.25s\n",
      "(Training) Loss: 924304.3817\n",
      "(Validation) Loss: 748616.3905, MAE: 3221.7031, R2: 0.2388\n",
      "==========================================================================================\n",
      "Epoch [1568/5000] | Time: 0.24s\n",
      "(Training) Loss: 928586.2506\n",
      "(Validation) Loss: 748538.6229, MAE: 3230.0430, R2: 0.2388\n",
      "==========================================================================================\n",
      "Epoch [1569/5000] | Time: 0.24s\n",
      "(Training) Loss: 948386.9302\n",
      "(Validation) Loss: 748444.7797, MAE: 3225.3411, R2: 0.2389\n",
      "==========================================================================================\n",
      "Epoch [1570/5000] | Time: 0.27s\n",
      "(Training) Loss: 932033.5286\n",
      "(Validation) Loss: 748365.6330, MAE: 3225.1057, R2: 0.2390\n",
      "==========================================================================================\n",
      "Epoch [1571/5000] | Time: 0.22s\n",
      "(Training) Loss: 923135.2483\n",
      "(Validation) Loss: 748259.9397, MAE: 3219.3022, R2: 0.2391\n",
      "==========================================================================================\n",
      "Epoch [1572/5000] | Time: 0.27s\n",
      "(Training) Loss: 931590.3725\n",
      "(Validation) Loss: 748174.6076, MAE: 3221.4705, R2: 0.2392\n",
      "==========================================================================================\n",
      "Epoch [1573/5000] | Time: 0.32s\n",
      "(Training) Loss: 939530.8610\n",
      "(Validation) Loss: 767092.1187, MAE: 3279.7307, R2: 0.2201\n",
      "==========================================================================================\n",
      "Epoch [1574/5000] | Time: 0.26s\n",
      "(Training) Loss: 944943.4378\n",
      "(Validation) Loss: 766995.1486, MAE: 3278.3047, R2: 0.2202\n",
      "==========================================================================================\n",
      "Epoch [1575/5000] | Time: 0.27s\n",
      "(Training) Loss: 945283.6072\n",
      "(Validation) Loss: 766913.2248, MAE: 3282.6023, R2: 0.2203\n",
      "==========================================================================================\n",
      "Epoch [1576/5000] | Time: 0.23s\n",
      "(Training) Loss: 951645.1605\n",
      "(Validation) Loss: 766818.5816, MAE: 3285.4380, R2: 0.2204\n",
      "==========================================================================================\n",
      "Epoch [1577/5000] | Time: 0.27s\n",
      "(Training) Loss: 949735.6453\n",
      "(Validation) Loss: 766713.0565, MAE: 3279.3701, R2: 0.2205\n",
      "==========================================================================================\n",
      "Epoch [1578/5000] | Time: 0.26s\n",
      "(Training) Loss: 956145.4810\n",
      "(Validation) Loss: 766640.4483, MAE: 3284.8274, R2: 0.2206\n",
      "==========================================================================================\n",
      "Epoch [1579/5000] | Time: 0.23s\n",
      "(Training) Loss: 946439.0679\n",
      "(Validation) Loss: 766565.1175, MAE: 3288.7253, R2: 0.2207\n",
      "==========================================================================================\n",
      "Epoch [1580/5000] | Time: 0.26s\n",
      "(Training) Loss: 969099.6409\n",
      "(Validation) Loss: 766428.6762, MAE: 3277.9280, R2: 0.2208\n",
      "==========================================================================================\n",
      "Epoch [1581/5000] | Time: 0.26s\n",
      "(Training) Loss: 953625.7868\n",
      "(Validation) Loss: 766330.5765, MAE: 3278.4802, R2: 0.2209\n",
      "==========================================================================================\n",
      "Epoch [1582/5000] | Time: 0.23s\n",
      "(Training) Loss: 954658.7481\n",
      "(Validation) Loss: 766243.9441, MAE: 3280.4990, R2: 0.2210\n",
      "==========================================================================================\n",
      "Epoch [1583/5000] | Time: 0.23s\n",
      "(Training) Loss: 955942.1364\n",
      "(Validation) Loss: 766139.0044, MAE: 3274.8423, R2: 0.2211\n",
      "==========================================================================================\n",
      "Epoch [1584/5000] | Time: 0.20s\n",
      "(Training) Loss: 945809.3804\n",
      "(Validation) Loss: 766054.0984, MAE: 3277.1812, R2: 0.2212\n",
      "==========================================================================================\n",
      "Epoch [1585/5000] | Time: 0.24s\n",
      "(Training) Loss: 953247.5365\n",
      "(Validation) Loss: 765951.1790, MAE: 3274.1265, R2: 0.2213\n",
      "==========================================================================================\n",
      "Epoch [1586/5000] | Time: 0.25s\n",
      "(Training) Loss: 955154.5819\n",
      "(Validation) Loss: 765857.9378, MAE: 3276.5969, R2: 0.2214\n",
      "==========================================================================================\n",
      "Epoch [1587/5000] | Time: 0.23s\n",
      "(Training) Loss: 941236.7681\n",
      "(Validation) Loss: 765768.1454, MAE: 3277.1689, R2: 0.2215\n",
      "==========================================================================================\n",
      "Epoch [1588/5000] | Time: 0.24s\n",
      "(Training) Loss: 946529.5279\n",
      "(Validation) Loss: 765669.3537, MAE: 3275.9272, R2: 0.2216\n",
      "==========================================================================================\n",
      "Epoch [1589/5000] | Time: 0.25s\n",
      "(Training) Loss: 964194.3077\n",
      "(Validation) Loss: 765590.2813, MAE: 3276.0610, R2: 0.2217\n",
      "==========================================================================================\n",
      "Epoch [1590/5000] | Time: 0.22s\n",
      "(Training) Loss: 958118.4150\n",
      "(Validation) Loss: 765484.7340, MAE: 3273.2336, R2: 0.2218\n",
      "==========================================================================================\n",
      "Epoch [1591/5000] | Time: 0.30s\n",
      "(Training) Loss: 954825.2164\n",
      "(Validation) Loss: 765392.4990, MAE: 3273.9724, R2: 0.2219\n",
      "==========================================================================================\n",
      "Epoch [1592/5000] | Time: 0.42s\n",
      "(Training) Loss: 950737.2741\n",
      "(Validation) Loss: 765292.4406, MAE: 3271.4849, R2: 0.2220\n",
      "==========================================================================================\n",
      "Epoch [1593/5000] | Time: 0.28s\n",
      "(Training) Loss: 948932.2703\n",
      "(Validation) Loss: 765202.3270, MAE: 3271.6694, R2: 0.2220\n",
      "==========================================================================================\n",
      "Epoch [1594/5000] | Time: 0.29s\n",
      "(Training) Loss: 951408.6631\n",
      "(Validation) Loss: 765121.0051, MAE: 3274.0198, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [1595/5000] | Time: 0.30s\n",
      "(Training) Loss: 953015.3744\n",
      "(Validation) Loss: 765032.0959, MAE: 3274.2244, R2: 0.2222\n",
      "==========================================================================================\n",
      "Epoch [1596/5000] | Time: 0.28s\n",
      "(Training) Loss: 951188.2475\n",
      "(Validation) Loss: 764913.5733, MAE: 3268.9504, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [1597/5000] | Time: 0.32s\n",
      "(Training) Loss: 955322.3020\n",
      "(Validation) Loss: 761849.3130, MAE: 3270.7603, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [1598/5000] | Time: 0.29s\n",
      "(Training) Loss: 943923.3680\n",
      "(Validation) Loss: 761750.2870, MAE: 3266.6577, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [1599/5000] | Time: 0.29s\n",
      "(Training) Loss: 941412.4074\n",
      "(Validation) Loss: 761639.4565, MAE: 3263.9146, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [1600/5000] | Time: 0.26s\n",
      "(Training) Loss: 958947.0552\n",
      "(Validation) Loss: 761543.3137, MAE: 3263.3022, R2: 0.2257\n",
      "==========================================================================================\n",
      "Epoch [1601/5000] | Time: 0.24s\n",
      "(Training) Loss: 957222.6980\n",
      "(Validation) Loss: 761431.7911, MAE: 3260.4902, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [1602/5000] | Time: 0.24s\n",
      "(Training) Loss: 957659.0850\n",
      "(Validation) Loss: 761339.6102, MAE: 3262.5642, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [1603/5000] | Time: 0.27s\n",
      "(Training) Loss: 953356.9365\n",
      "(Validation) Loss: 761245.4438, MAE: 3263.0632, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [1604/5000] | Time: 0.27s\n",
      "(Training) Loss: 940468.3845\n",
      "(Validation) Loss: 761139.5365, MAE: 3259.2209, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [1605/5000] | Time: 0.25s\n",
      "(Training) Loss: 941708.6605\n",
      "(Validation) Loss: 761051.5403, MAE: 3265.6990, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [1606/5000] | Time: 0.22s\n",
      "(Training) Loss: 958767.0704\n",
      "(Validation) Loss: 760953.9060, MAE: 3260.8164, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [1607/5000] | Time: 0.21s\n",
      "(Training) Loss: 965178.5019\n",
      "(Validation) Loss: 760855.3568, MAE: 3259.1150, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [1608/5000] | Time: 0.26s\n",
      "(Training) Loss: 948625.0114\n",
      "(Validation) Loss: 760755.8248, MAE: 3256.5374, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [1609/5000] | Time: 0.27s\n",
      "(Training) Loss: 941004.1345\n",
      "(Validation) Loss: 760659.8203, MAE: 3258.9644, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [1610/5000] | Time: 0.26s\n",
      "(Training) Loss: 947420.5412\n",
      "(Validation) Loss: 760590.6825, MAE: 3263.7483, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [1611/5000] | Time: 0.26s\n",
      "(Training) Loss: 951507.3217\n",
      "(Validation) Loss: 760483.2400, MAE: 3264.3965, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [1612/5000] | Time: 0.26s\n",
      "(Training) Loss: 945326.6459\n",
      "(Validation) Loss: 760375.3879, MAE: 3258.7107, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [1613/5000] | Time: 0.27s\n",
      "(Training) Loss: 964862.5673\n",
      "(Validation) Loss: 760279.1403, MAE: 3258.5088, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [1614/5000] | Time: 0.26s\n",
      "(Training) Loss: 935490.4503\n",
      "(Validation) Loss: 760094.3962, MAE: 3256.5500, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [1615/5000] | Time: 0.26s\n",
      "(Training) Loss: 939659.9486\n",
      "(Validation) Loss: 759986.1816, MAE: 3252.9771, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [1616/5000] | Time: 0.25s\n",
      "(Training) Loss: 941509.0964\n",
      "(Validation) Loss: 759867.2686, MAE: 3246.8562, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [1617/5000] | Time: 0.27s\n",
      "(Training) Loss: 935398.6842\n",
      "(Validation) Loss: 759875.5435, MAE: 3253.7344, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [1618/5000] | Time: 0.25s\n",
      "(Training) Loss: 953452.4613\n",
      "(Validation) Loss: 759801.8876, MAE: 3254.5505, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [1619/5000] | Time: 0.27s\n",
      "(Training) Loss: 952065.5489\n",
      "(Validation) Loss: 759710.3156, MAE: 3257.3438, R2: 0.2276\n",
      "==========================================================================================\n",
      "Epoch [1620/5000] | Time: 0.23s\n",
      "(Training) Loss: 940133.4213\n",
      "(Validation) Loss: 759612.0990, MAE: 3254.5278, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [1621/5000] | Time: 0.25s\n",
      "(Training) Loss: 960580.2088\n",
      "(Validation) Loss: 759548.4197, MAE: 3260.6904, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [1622/5000] | Time: 0.23s\n",
      "(Training) Loss: 942516.4365\n",
      "(Validation) Loss: 759420.5143, MAE: 3252.7673, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [1623/5000] | Time: 0.25s\n",
      "(Training) Loss: 956935.1885\n",
      "(Validation) Loss: 759340.2330, MAE: 3257.8032, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [1624/5000] | Time: 0.25s\n",
      "(Training) Loss: 951521.4346\n",
      "(Validation) Loss: 759242.9549, MAE: 3256.3289, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [1625/5000] | Time: 0.24s\n",
      "(Training) Loss: 943430.3084\n",
      "(Validation) Loss: 759137.0254, MAE: 3252.6082, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [1626/5000] | Time: 0.24s\n",
      "(Training) Loss: 944418.0013\n",
      "(Validation) Loss: 759047.1956, MAE: 3252.8635, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [1627/5000] | Time: 0.25s\n",
      "(Training) Loss: 952002.3750\n",
      "(Validation) Loss: 758949.5778, MAE: 3254.1970, R2: 0.2283\n",
      "==========================================================================================\n",
      "Epoch [1628/5000] | Time: 0.23s\n",
      "(Training) Loss: 935377.8566\n",
      "(Validation) Loss: 758862.9321, MAE: 3254.0051, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [1629/5000] | Time: 0.26s\n",
      "(Training) Loss: 934806.8363\n",
      "(Validation) Loss: 758757.2286, MAE: 3251.0708, R2: 0.2285\n",
      "==========================================================================================\n",
      "Epoch [1630/5000] | Time: 0.27s\n",
      "(Training) Loss: 938907.8934\n",
      "(Validation) Loss: 758689.2248, MAE: 3258.3562, R2: 0.2286\n",
      "==========================================================================================\n",
      "Epoch [1631/5000] | Time: 0.26s\n",
      "(Training) Loss: 952914.8027\n",
      "(Validation) Loss: 758643.6654, MAE: 3264.2058, R2: 0.2287\n",
      "==========================================================================================\n",
      "Epoch [1632/5000] | Time: 0.27s\n",
      "(Training) Loss: 957173.9778\n",
      "(Validation) Loss: 758494.4222, MAE: 3251.8645, R2: 0.2288\n",
      "==========================================================================================\n",
      "Epoch [1633/5000] | Time: 0.26s\n",
      "(Training) Loss: 942323.8154\n",
      "(Validation) Loss: 758397.4806, MAE: 3251.6799, R2: 0.2289\n",
      "==========================================================================================\n",
      "Epoch [1634/5000] | Time: 0.30s\n",
      "(Training) Loss: 959840.3617\n",
      "(Validation) Loss: 758291.2540, MAE: 3250.3540, R2: 0.2290\n",
      "==========================================================================================\n",
      "Epoch [1635/5000] | Time: 0.28s\n",
      "(Training) Loss: 945507.5330\n",
      "(Validation) Loss: 758119.9105, MAE: 3245.4854, R2: 0.2292\n",
      "==========================================================================================\n",
      "Epoch [1636/5000] | Time: 0.27s\n",
      "(Training) Loss: 936051.0482\n",
      "(Validation) Loss: 758028.7911, MAE: 3245.9126, R2: 0.2293\n",
      "==========================================================================================\n",
      "Epoch [1637/5000] | Time: 0.27s\n",
      "(Training) Loss: 936120.9400\n",
      "(Validation) Loss: 757923.2863, MAE: 3241.2847, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [1638/5000] | Time: 0.26s\n",
      "(Training) Loss: 935821.6164\n",
      "(Validation) Loss: 757840.5511, MAE: 3245.0388, R2: 0.2295\n",
      "==========================================================================================\n",
      "Epoch [1639/5000] | Time: 0.27s\n",
      "(Training) Loss: 950437.4010\n",
      "(Validation) Loss: 757746.4159, MAE: 3245.2969, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [1640/5000] | Time: 0.26s\n",
      "(Training) Loss: 933994.6983\n",
      "(Validation) Loss: 757702.1930, MAE: 3248.7549, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [1641/5000] | Time: 0.27s\n",
      "(Training) Loss: 935693.9829\n",
      "(Validation) Loss: 757487.5873, MAE: 3234.0945, R2: 0.2298\n",
      "==========================================================================================\n",
      "Epoch [1642/5000] | Time: 0.28s\n",
      "(Training) Loss: 964447.7538\n",
      "(Validation) Loss: 762153.7917, MAE: 3253.0583, R2: 0.2251\n",
      "==========================================================================================\n",
      "Epoch [1643/5000] | Time: 0.22s\n",
      "(Training) Loss: 963927.8452\n",
      "(Validation) Loss: 762067.1156, MAE: 3256.0696, R2: 0.2252\n",
      "==========================================================================================\n",
      "Epoch [1644/5000] | Time: 0.25s\n",
      "(Training) Loss: 955057.7265\n",
      "(Validation) Loss: 761978.6089, MAE: 3255.4395, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [1645/5000] | Time: 0.30s\n",
      "(Training) Loss: 953802.1079\n",
      "(Validation) Loss: 761835.3657, MAE: 3249.0564, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [1646/5000] | Time: 0.25s\n",
      "(Training) Loss: 942286.0806\n",
      "(Validation) Loss: 761734.3943, MAE: 3248.5867, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [1647/5000] | Time: 0.26s\n",
      "(Training) Loss: 944322.3185\n",
      "(Validation) Loss: 761653.4578, MAE: 3255.1987, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [1648/5000] | Time: 0.27s\n",
      "(Training) Loss: 944416.1491\n",
      "(Validation) Loss: 761626.8133, MAE: 3259.7720, R2: 0.2257\n",
      "==========================================================================================\n",
      "Epoch [1649/5000] | Time: 0.25s\n",
      "(Training) Loss: 954744.3261\n",
      "(Validation) Loss: 761445.7397, MAE: 3251.0012, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [1650/5000] | Time: 0.28s\n",
      "(Training) Loss: 946735.8052\n",
      "(Validation) Loss: 761419.4197, MAE: 3259.3931, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [1651/5000] | Time: 0.23s\n",
      "(Training) Loss: 947063.1478\n",
      "(Validation) Loss: 761259.0590, MAE: 3251.1387, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [1652/5000] | Time: 0.21s\n",
      "(Training) Loss: 957852.1653\n",
      "(Validation) Loss: 761153.1829, MAE: 3249.8276, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [1653/5000] | Time: 0.23s\n",
      "(Training) Loss: 948015.3871\n",
      "(Validation) Loss: 761036.8952, MAE: 3248.5874, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [1654/5000] | Time: 0.24s\n",
      "(Training) Loss: 940591.1421\n",
      "(Validation) Loss: 760939.7841, MAE: 3245.8259, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [1655/5000] | Time: 0.24s\n",
      "(Training) Loss: 964161.9619\n",
      "(Validation) Loss: 760850.6254, MAE: 3248.0234, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [1656/5000] | Time: 0.25s\n",
      "(Training) Loss: 936303.9899\n",
      "(Validation) Loss: 760749.2146, MAE: 3246.4004, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [1657/5000] | Time: 0.26s\n",
      "(Training) Loss: 969063.0780\n",
      "(Validation) Loss: 760649.3467, MAE: 3245.5969, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [1658/5000] | Time: 0.24s\n",
      "(Training) Loss: 945056.8350\n",
      "(Validation) Loss: 760550.3879, MAE: 3247.0220, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [1659/5000] | Time: 0.25s\n",
      "(Training) Loss: 946101.3763\n",
      "(Validation) Loss: 760452.2400, MAE: 3249.8442, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [1660/5000] | Time: 0.22s\n",
      "(Training) Loss: 937916.8376\n",
      "(Validation) Loss: 760366.5911, MAE: 3249.4014, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [1661/5000] | Time: 0.25s\n",
      "(Training) Loss: 955202.7722\n",
      "(Validation) Loss: 760266.5130, MAE: 3252.1138, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [1662/5000] | Time: 0.25s\n",
      "(Training) Loss: 942562.1548\n",
      "(Validation) Loss: 760163.2616, MAE: 3246.2019, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [1663/5000] | Time: 0.23s\n",
      "(Training) Loss: 938507.0866\n",
      "(Validation) Loss: 760073.4203, MAE: 3248.2344, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [1664/5000] | Time: 0.23s\n",
      "(Training) Loss: 936113.8322\n",
      "(Validation) Loss: 760010.7251, MAE: 3252.3792, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [1665/5000] | Time: 0.27s\n",
      "(Training) Loss: 970040.9213\n",
      "(Validation) Loss: 759865.0590, MAE: 3243.4409, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [1666/5000] | Time: 0.28s\n",
      "(Training) Loss: 937406.3855\n",
      "(Validation) Loss: 759779.2051, MAE: 3244.2515, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [1667/5000] | Time: 0.29s\n",
      "(Training) Loss: 944806.8458\n",
      "(Validation) Loss: 759683.6768, MAE: 3242.9031, R2: 0.2276\n",
      "==========================================================================================\n",
      "Epoch [1668/5000] | Time: 0.25s\n",
      "(Training) Loss: 952327.0178\n",
      "(Validation) Loss: 759601.8133, MAE: 3245.7729, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [1669/5000] | Time: 0.46s\n",
      "(Training) Loss: 942922.3382\n",
      "(Validation) Loss: 759482.2597, MAE: 3242.3867, R2: 0.2278\n",
      "==========================================================================================\n",
      "Epoch [1670/5000] | Time: 0.25s\n",
      "(Training) Loss: 951914.5780\n",
      "(Validation) Loss: 759423.6095, MAE: 3248.0764, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [1671/5000] | Time: 0.32s\n",
      "(Training) Loss: 946160.8401\n",
      "(Validation) Loss: 759307.8216, MAE: 3249.8767, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [1672/5000] | Time: 0.24s\n",
      "(Training) Loss: 938676.0571\n",
      "(Validation) Loss: 759189.5587, MAE: 3241.6172, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [1673/5000] | Time: 0.29s\n",
      "(Training) Loss: 956218.5222\n",
      "(Validation) Loss: 775209.6260, MAE: 3305.9082, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [1674/5000] | Time: 0.28s\n",
      "(Training) Loss: 957097.6428\n",
      "(Validation) Loss: 775093.5035, MAE: 3300.8079, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [1675/5000] | Time: 0.28s\n",
      "(Training) Loss: 961021.0774\n",
      "(Validation) Loss: 774988.8540, MAE: 3299.2688, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [1676/5000] | Time: 0.26s\n",
      "(Training) Loss: 966490.4556\n",
      "(Validation) Loss: 774891.4590, MAE: 3298.7622, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [1677/5000] | Time: 0.26s\n",
      "(Training) Loss: 957515.9442\n",
      "(Validation) Loss: 774792.4521, MAE: 3300.9458, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [1678/5000] | Time: 0.29s\n",
      "(Training) Loss: 968229.5378\n",
      "(Validation) Loss: 774689.5340, MAE: 3298.2705, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [1679/5000] | Time: 0.30s\n",
      "(Training) Loss: 955214.2333\n",
      "(Validation) Loss: 774604.5295, MAE: 3300.9163, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [1680/5000] | Time: 0.28s\n",
      "(Training) Loss: 951203.2799\n",
      "(Validation) Loss: 774494.7854, MAE: 3298.3999, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [1681/5000] | Time: 0.29s\n",
      "(Training) Loss: 972870.7912\n",
      "(Validation) Loss: 774392.3340, MAE: 3301.8381, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [1682/5000] | Time: 0.31s\n",
      "(Training) Loss: 957631.0152\n",
      "(Validation) Loss: 774295.7803, MAE: 3303.4829, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [1683/5000] | Time: 0.26s\n",
      "(Training) Loss: 964408.5403\n",
      "(Validation) Loss: 774191.6095, MAE: 3297.9729, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [1684/5000] | Time: 0.27s\n",
      "(Training) Loss: 953996.4667\n",
      "(Validation) Loss: 774112.2997, MAE: 3301.5864, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [1685/5000] | Time: 0.29s\n",
      "(Training) Loss: 960041.4181\n",
      "(Validation) Loss: 773985.7137, MAE: 3297.2620, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [1686/5000] | Time: 0.27s\n",
      "(Training) Loss: 978139.2208\n",
      "(Validation) Loss: 773882.7060, MAE: 3295.4155, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [1687/5000] | Time: 0.33s\n",
      "(Training) Loss: 955923.6764\n",
      "(Validation) Loss: 773805.9162, MAE: 3299.6553, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [1688/5000] | Time: 0.29s\n",
      "(Training) Loss: 977120.0844\n",
      "(Validation) Loss: 773674.2222, MAE: 3293.7234, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [1689/5000] | Time: 0.31s\n",
      "(Training) Loss: 963455.7018\n",
      "(Validation) Loss: 773581.4508, MAE: 3295.9734, R2: 0.2136\n",
      "==========================================================================================\n",
      "Epoch [1690/5000] | Time: 0.29s\n",
      "(Training) Loss: 951480.6862\n",
      "(Validation) Loss: 773489.3956, MAE: 3294.7085, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [1691/5000] | Time: 0.24s\n",
      "(Training) Loss: 963738.5343\n",
      "(Validation) Loss: 773380.2044, MAE: 3297.3333, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [1692/5000] | Time: 0.30s\n",
      "(Training) Loss: 971185.7703\n",
      "(Validation) Loss: 773276.4940, MAE: 3293.7483, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [1693/5000] | Time: 0.34s\n",
      "(Training) Loss: 979292.7519\n",
      "(Validation) Loss: 773181.5492, MAE: 3294.5349, R2: 0.2140\n",
      "==========================================================================================\n",
      "Epoch [1694/5000] | Time: 0.32s\n",
      "(Training) Loss: 972287.4549\n",
      "(Validation) Loss: 773081.4089, MAE: 3292.4087, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [1695/5000] | Time: 0.32s\n",
      "(Training) Loss: 955539.7303\n",
      "(Validation) Loss: 772989.3702, MAE: 3294.5454, R2: 0.2142\n",
      "==========================================================================================\n",
      "Epoch [1696/5000] | Time: 0.29s\n",
      "(Training) Loss: 950043.9572\n",
      "(Validation) Loss: 772877.0063, MAE: 3292.2683, R2: 0.2143\n",
      "==========================================================================================\n",
      "Epoch [1697/5000] | Time: 0.31s\n",
      "(Training) Loss: 974585.7862\n",
      "(Validation) Loss: 772773.5346, MAE: 3291.3267, R2: 0.2144\n",
      "==========================================================================================\n",
      "Epoch [1698/5000] | Time: 0.28s\n",
      "(Training) Loss: 971577.5863\n",
      "(Validation) Loss: 772686.3022, MAE: 3295.1472, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [1699/5000] | Time: 0.26s\n",
      "(Training) Loss: 953747.9816\n",
      "(Validation) Loss: 772578.4717, MAE: 3293.2820, R2: 0.2146\n",
      "==========================================================================================\n",
      "Epoch [1700/5000] | Time: 0.28s\n",
      "(Training) Loss: 969755.0549\n",
      "(Validation) Loss: 772481.7200, MAE: 3291.0317, R2: 0.2147\n",
      "==========================================================================================\n",
      "Epoch [1701/5000] | Time: 0.29s\n",
      "(Training) Loss: 963652.8547\n",
      "(Validation) Loss: 772380.5505, MAE: 3292.8921, R2: 0.2148\n",
      "==========================================================================================\n",
      "Epoch [1702/5000] | Time: 0.28s\n",
      "(Training) Loss: 969326.0869\n",
      "(Validation) Loss: 772282.9644, MAE: 3291.6089, R2: 0.2149\n",
      "==========================================================================================\n",
      "Epoch [1703/5000] | Time: 0.28s\n",
      "(Training) Loss: 954381.9353\n",
      "(Validation) Loss: 772173.0089, MAE: 3289.4119, R2: 0.2150\n",
      "==========================================================================================\n",
      "Epoch [1704/5000] | Time: 0.24s\n",
      "(Training) Loss: 968811.2805\n",
      "(Validation) Loss: 772076.0489, MAE: 3287.6938, R2: 0.2151\n",
      "==========================================================================================\n",
      "Epoch [1705/5000] | Time: 0.27s\n",
      "(Training) Loss: 976161.9492\n",
      "(Validation) Loss: 771979.8825, MAE: 3289.5093, R2: 0.2152\n",
      "==========================================================================================\n",
      "Epoch [1706/5000] | Time: 0.27s\n",
      "(Training) Loss: 962329.8154\n",
      "(Validation) Loss: 771885.3867, MAE: 3290.0054, R2: 0.2153\n",
      "==========================================================================================\n",
      "Epoch [1707/5000] | Time: 0.30s\n",
      "(Training) Loss: 967543.2475\n",
      "(Validation) Loss: 771785.5854, MAE: 3287.8384, R2: 0.2154\n",
      "==========================================================================================\n",
      "Epoch [1708/5000] | Time: 0.28s\n",
      "(Training) Loss: 952427.5178\n",
      "(Validation) Loss: 771698.0927, MAE: 3291.4458, R2: 0.2155\n",
      "==========================================================================================\n",
      "Epoch [1709/5000] | Time: 0.29s\n",
      "(Training) Loss: 962488.4949\n",
      "(Validation) Loss: 771593.1365, MAE: 3287.5159, R2: 0.2156\n",
      "==========================================================================================\n",
      "Epoch [1710/5000] | Time: 0.26s\n",
      "(Training) Loss: 963218.7481\n",
      "(Validation) Loss: 771486.2863, MAE: 3284.7515, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [1711/5000] | Time: 0.27s\n",
      "(Training) Loss: 958505.1859\n",
      "(Validation) Loss: 771396.3702, MAE: 3287.7146, R2: 0.2158\n",
      "==========================================================================================\n",
      "Epoch [1712/5000] | Time: 0.28s\n",
      "(Training) Loss: 949064.6905\n",
      "(Validation) Loss: 771293.6476, MAE: 3289.2710, R2: 0.2159\n",
      "==========================================================================================\n",
      "Epoch [1713/5000] | Time: 0.26s\n",
      "(Training) Loss: 959922.3629\n",
      "(Validation) Loss: 771191.0146, MAE: 3284.2642, R2: 0.2160\n",
      "==========================================================================================\n",
      "Epoch [1714/5000] | Time: 0.25s\n",
      "(Training) Loss: 953282.1301\n",
      "(Validation) Loss: 771107.0686, MAE: 3287.8174, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [1715/5000] | Time: 0.24s\n",
      "(Training) Loss: 959557.1104\n",
      "(Validation) Loss: 770991.5467, MAE: 3283.9268, R2: 0.2162\n",
      "==========================================================================================\n",
      "Epoch [1716/5000] | Time: 0.24s\n",
      "(Training) Loss: 951405.0197\n",
      "(Validation) Loss: 770890.9206, MAE: 3281.7075, R2: 0.2163\n",
      "==========================================================================================\n",
      "Epoch [1717/5000] | Time: 0.29s\n",
      "(Training) Loss: 950471.4952\n",
      "(Validation) Loss: 770801.4756, MAE: 3282.0508, R2: 0.2164\n",
      "==========================================================================================\n",
      "Epoch [1718/5000] | Time: 0.28s\n",
      "(Training) Loss: 963950.8103\n",
      "(Validation) Loss: 770700.7752, MAE: 3284.9004, R2: 0.2165\n",
      "==========================================================================================\n",
      "Epoch [1719/5000] | Time: 0.36s\n",
      "(Training) Loss: 957230.2652\n",
      "(Validation) Loss: 770619.5137, MAE: 3286.9912, R2: 0.2166\n",
      "==========================================================================================\n",
      "Epoch [1720/5000] | Time: 0.33s\n",
      "(Training) Loss: 959326.6339\n",
      "(Validation) Loss: 770506.8006, MAE: 3283.3877, R2: 0.2167\n",
      "==========================================================================================\n",
      "Epoch [1721/5000] | Time: 0.22s\n",
      "(Training) Loss: 954643.1815\n",
      "(Validation) Loss: 770399.9232, MAE: 3282.4341, R2: 0.2168\n",
      "==========================================================================================\n",
      "Epoch [1722/5000] | Time: 0.21s\n",
      "(Training) Loss: 959096.2970\n",
      "(Validation) Loss: 770313.7029, MAE: 3282.5161, R2: 0.2169\n",
      "==========================================================================================\n",
      "Epoch [1723/5000] | Time: 0.22s\n",
      "(Training) Loss: 957046.6624\n",
      "(Validation) Loss: 781158.7124, MAE: 3316.7229, R2: 0.2060\n",
      "==========================================================================================\n",
      "Epoch [1724/5000] | Time: 0.21s\n",
      "(Training) Loss: 988722.5609\n",
      "(Validation) Loss: 794501.1943, MAE: 3372.7556, R2: 0.1926\n",
      "==========================================================================================\n",
      "Epoch [1725/5000] | Time: 0.21s\n",
      "(Training) Loss: 1015638.9727\n",
      "(Validation) Loss: 794395.5765, MAE: 3370.0532, R2: 0.1927\n",
      "==========================================================================================\n",
      "Epoch [1726/5000] | Time: 0.20s\n",
      "(Training) Loss: 1003471.1193\n",
      "(Validation) Loss: 794293.6102, MAE: 3367.8228, R2: 0.1928\n",
      "==========================================================================================\n",
      "Epoch [1727/5000] | Time: 0.39s\n",
      "(Training) Loss: 989438.1567\n",
      "(Validation) Loss: 794195.4108, MAE: 3370.4746, R2: 0.1929\n",
      "==========================================================================================\n",
      "Epoch [1728/5000] | Time: 0.29s\n",
      "(Training) Loss: 976337.5530\n",
      "(Validation) Loss: 794089.5530, MAE: 3367.7703, R2: 0.1930\n",
      "==========================================================================================\n",
      "Epoch [1729/5000] | Time: 0.22s\n",
      "(Training) Loss: 976050.5057\n",
      "(Validation) Loss: 794125.1778, MAE: 3383.6003, R2: 0.1929\n",
      "==========================================================================================\n",
      "Epoch [1730/5000] | Time: 0.29s\n",
      "(Training) Loss: 993425.1459\n",
      "(Validation) Loss: 794016.2660, MAE: 3377.5461, R2: 0.1930\n",
      "==========================================================================================\n",
      "Epoch [1731/5000] | Time: 0.23s\n",
      "(Training) Loss: 985894.1548\n",
      "(Validation) Loss: 793909.1708, MAE: 3376.2886, R2: 0.1931\n",
      "==========================================================================================\n",
      "Epoch [1732/5000] | Time: 0.26s\n",
      "(Training) Loss: 991128.6536\n",
      "(Validation) Loss: 793810.2603, MAE: 3379.5632, R2: 0.1932\n",
      "==========================================================================================\n",
      "Epoch [1733/5000] | Time: 0.23s\n",
      "(Training) Loss: 983069.8522\n",
      "(Validation) Loss: 793742.4603, MAE: 3382.0854, R2: 0.1933\n",
      "==========================================================================================\n",
      "Epoch [1734/5000] | Time: 0.24s\n",
      "(Training) Loss: 993460.9150\n",
      "(Validation) Loss: 793616.5232, MAE: 3378.4216, R2: 0.1934\n",
      "==========================================================================================\n",
      "Epoch [1735/5000] | Time: 0.24s\n",
      "(Training) Loss: 974503.2468\n",
      "(Validation) Loss: 793511.0368, MAE: 3374.2632, R2: 0.1935\n",
      "==========================================================================================\n",
      "Epoch [1736/5000] | Time: 0.26s\n",
      "(Training) Loss: 987095.1402\n",
      "(Validation) Loss: 793415.2533, MAE: 3374.6292, R2: 0.1936\n",
      "==========================================================================================\n",
      "Epoch [1737/5000] | Time: 0.22s\n",
      "(Training) Loss: 986970.5241\n",
      "(Validation) Loss: 793310.2717, MAE: 3371.8818, R2: 0.1937\n",
      "==========================================================================================\n",
      "Epoch [1738/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001394.4765\n",
      "(Validation) Loss: 793215.4032, MAE: 3374.4565, R2: 0.1938\n",
      "==========================================================================================\n",
      "Epoch [1739/5000] | Time: 0.20s\n",
      "(Training) Loss: 1003438.1992\n",
      "(Validation) Loss: 793111.8603, MAE: 3372.8132, R2: 0.1939\n",
      "==========================================================================================\n",
      "Epoch [1740/5000] | Time: 0.19s\n",
      "(Training) Loss: 990080.3655\n",
      "(Validation) Loss: 793011.6717, MAE: 3371.9207, R2: 0.1940\n",
      "==========================================================================================\n",
      "Epoch [1741/5000] | Time: 0.21s\n",
      "(Training) Loss: 983392.8877\n",
      "(Validation) Loss: 792915.2743, MAE: 3371.4849, R2: 0.1941\n",
      "==========================================================================================\n",
      "Epoch [1742/5000] | Time: 0.24s\n",
      "(Training) Loss: 990775.3693\n",
      "(Validation) Loss: 792870.0857, MAE: 3379.4346, R2: 0.1942\n",
      "==========================================================================================\n",
      "Epoch [1743/5000] | Time: 0.20s\n",
      "(Training) Loss: 981500.7855\n",
      "(Validation) Loss: 792717.3187, MAE: 3370.7598, R2: 0.1943\n",
      "==========================================================================================\n",
      "Epoch [1744/5000] | Time: 0.19s\n",
      "(Training) Loss: 1002756.9860\n",
      "(Validation) Loss: 792615.1156, MAE: 3368.5537, R2: 0.1944\n",
      "==========================================================================================\n",
      "Epoch [1745/5000] | Time: 0.19s\n",
      "(Training) Loss: 972076.7794\n",
      "(Validation) Loss: 792525.2819, MAE: 3369.8921, R2: 0.1945\n",
      "==========================================================================================\n",
      "Epoch [1746/5000] | Time: 0.19s\n",
      "(Training) Loss: 983049.7157\n",
      "(Validation) Loss: 792422.6781, MAE: 3367.6255, R2: 0.1946\n",
      "==========================================================================================\n",
      "Epoch [1747/5000] | Time: 0.19s\n",
      "(Training) Loss: 993522.2735\n",
      "(Validation) Loss: 792320.4267, MAE: 3367.0764, R2: 0.1947\n",
      "==========================================================================================\n",
      "Epoch [1748/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004302.2703\n",
      "(Validation) Loss: 792235.1035, MAE: 3371.6140, R2: 0.1948\n",
      "==========================================================================================\n",
      "Epoch [1749/5000] | Time: 0.21s\n",
      "(Training) Loss: 983431.8947\n",
      "(Validation) Loss: 792122.6546, MAE: 3367.1035, R2: 0.1949\n",
      "==========================================================================================\n",
      "Epoch [1750/5000] | Time: 0.25s\n",
      "(Training) Loss: 985172.4385\n",
      "(Validation) Loss: 792033.5479, MAE: 3366.7947, R2: 0.1950\n",
      "==========================================================================================\n",
      "Epoch [1751/5000] | Time: 0.26s\n",
      "(Training) Loss: 985834.3522\n",
      "(Validation) Loss: 791930.1740, MAE: 3366.2634, R2: 0.1951\n",
      "==========================================================================================\n",
      "Epoch [1752/5000] | Time: 0.28s\n",
      "(Training) Loss: 987244.7513\n",
      "(Validation) Loss: 791834.6686, MAE: 3366.1113, R2: 0.1952\n",
      "==========================================================================================\n",
      "Epoch [1753/5000] | Time: 0.21s\n",
      "(Training) Loss: 979655.1688\n",
      "(Validation) Loss: 791742.2717, MAE: 3367.0881, R2: 0.1953\n",
      "==========================================================================================\n",
      "Epoch [1754/5000] | Time: 0.19s\n",
      "(Training) Loss: 989218.3629\n",
      "(Validation) Loss: 791657.2063, MAE: 3371.9575, R2: 0.1954\n",
      "==========================================================================================\n",
      "Epoch [1755/5000] | Time: 0.29s\n",
      "(Training) Loss: 993693.2544\n",
      "(Validation) Loss: 791644.2737, MAE: 3390.4341, R2: 0.1954\n",
      "==========================================================================================\n",
      "Epoch [1756/5000] | Time: 0.29s\n",
      "(Training) Loss: 970922.8656\n",
      "(Validation) Loss: 791462.2800, MAE: 3374.1228, R2: 0.1956\n",
      "==========================================================================================\n",
      "Epoch [1757/5000] | Time: 0.29s\n",
      "(Training) Loss: 984935.7208\n",
      "(Validation) Loss: 791349.5702, MAE: 3366.9463, R2: 0.1957\n",
      "==========================================================================================\n",
      "Epoch [1758/5000] | Time: 0.28s\n",
      "(Training) Loss: 982486.6891\n",
      "(Validation) Loss: 791254.7073, MAE: 3367.6721, R2: 0.1958\n",
      "==========================================================================================\n",
      "Epoch [1759/5000] | Time: 0.29s\n",
      "(Training) Loss: 972955.1808\n",
      "(Validation) Loss: 791155.4057, MAE: 3366.0847, R2: 0.1959\n",
      "==========================================================================================\n",
      "Epoch [1760/5000] | Time: 0.28s\n",
      "(Training) Loss: 970710.1931\n",
      "(Validation) Loss: 791053.6781, MAE: 3364.6985, R2: 0.1960\n",
      "==========================================================================================\n",
      "Epoch [1761/5000] | Time: 0.32s\n",
      "(Training) Loss: 979298.4365\n",
      "(Validation) Loss: 790957.0990, MAE: 3362.8777, R2: 0.1961\n",
      "==========================================================================================\n",
      "Epoch [1762/5000] | Time: 0.32s\n",
      "(Training) Loss: 991512.9683\n",
      "(Validation) Loss: 790860.8184, MAE: 3363.0432, R2: 0.1962\n",
      "==========================================================================================\n",
      "Epoch [1763/5000] | Time: 0.29s\n",
      "(Training) Loss: 974975.6485\n",
      "(Validation) Loss: 790762.8933, MAE: 3363.7461, R2: 0.1963\n",
      "==========================================================================================\n",
      "Epoch [1764/5000] | Time: 0.31s\n",
      "(Training) Loss: 994036.5279\n",
      "(Validation) Loss: 790669.4870, MAE: 3363.2239, R2: 0.1964\n",
      "==========================================================================================\n",
      "Epoch [1765/5000] | Time: 0.32s\n",
      "(Training) Loss: 971811.5002\n",
      "(Validation) Loss: 790577.8337, MAE: 3364.2366, R2: 0.1965\n",
      "==========================================================================================\n",
      "Epoch [1766/5000] | Time: 0.33s\n",
      "(Training) Loss: 973598.1707\n",
      "(Validation) Loss: 790466.6267, MAE: 3361.9089, R2: 0.1966\n",
      "==========================================================================================\n",
      "Epoch [1767/5000] | Time: 0.33s\n",
      "(Training) Loss: 984438.7976\n",
      "(Validation) Loss: 790373.3708, MAE: 3363.0400, R2: 0.1967\n",
      "==========================================================================================\n",
      "Epoch [1768/5000] | Time: 0.35s\n",
      "(Training) Loss: 984098.0666\n",
      "(Validation) Loss: 790298.2571, MAE: 3367.6318, R2: 0.1968\n",
      "==========================================================================================\n",
      "Epoch [1769/5000] | Time: 0.23s\n",
      "(Training) Loss: 970510.0370\n",
      "(Validation) Loss: 790184.6908, MAE: 3361.8333, R2: 0.1969\n",
      "==========================================================================================\n",
      "Epoch [1770/5000] | Time: 0.28s\n",
      "(Training) Loss: 978242.1992\n",
      "(Validation) Loss: 790020.2927, MAE: 3359.6794, R2: 0.1971\n",
      "==========================================================================================\n",
      "Epoch [1771/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008660.6980\n",
      "(Validation) Loss: 789925.0946, MAE: 3357.5127, R2: 0.1972\n",
      "==========================================================================================\n",
      "Epoch [1772/5000] | Time: 0.29s\n",
      "(Training) Loss: 997993.4251\n",
      "(Validation) Loss: 789831.2165, MAE: 3356.8425, R2: 0.1973\n",
      "==========================================================================================\n",
      "Epoch [1773/5000] | Time: 0.34s\n",
      "(Training) Loss: 987655.5089\n",
      "(Validation) Loss: 777876.9537, MAE: 3312.8572, R2: 0.2093\n",
      "==========================================================================================\n",
      "Epoch [1774/5000] | Time: 0.41s\n",
      "(Training) Loss: 973629.2544\n",
      "(Validation) Loss: 787222.7206, MAE: 3347.7112, R2: 0.1999\n",
      "==========================================================================================\n",
      "Epoch [1775/5000] | Time: 0.28s\n",
      "(Training) Loss: 978255.3001\n",
      "(Validation) Loss: 787132.7765, MAE: 3346.3877, R2: 0.2000\n",
      "==========================================================================================\n",
      "Epoch [1776/5000] | Time: 0.37s\n",
      "(Training) Loss: 984002.4543\n",
      "(Validation) Loss: 787038.7314, MAE: 3345.1050, R2: 0.2001\n",
      "==========================================================================================\n",
      "Epoch [1777/5000] | Time: 0.35s\n",
      "(Training) Loss: 965143.3263\n",
      "(Validation) Loss: 786947.3029, MAE: 3344.9045, R2: 0.2002\n",
      "==========================================================================================\n",
      "Epoch [1778/5000] | Time: 0.35s\n",
      "(Training) Loss: 983042.6098\n",
      "(Validation) Loss: 786860.4775, MAE: 3347.4622, R2: 0.2002\n",
      "==========================================================================================\n",
      "Epoch [1779/5000] | Time: 0.33s\n",
      "(Training) Loss: 967217.3426\n",
      "(Validation) Loss: 786768.6673, MAE: 3348.5149, R2: 0.2003\n",
      "==========================================================================================\n",
      "Epoch [1780/5000] | Time: 0.24s\n",
      "(Training) Loss: 973532.8934\n",
      "(Validation) Loss: 786681.8495, MAE: 3344.9314, R2: 0.2004\n",
      "==========================================================================================\n",
      "Epoch [1781/5000] | Time: 0.26s\n",
      "(Training) Loss: 975804.3420\n",
      "(Validation) Loss: 786586.0667, MAE: 3346.0002, R2: 0.2005\n",
      "==========================================================================================\n",
      "Epoch [1782/5000] | Time: 0.25s\n",
      "(Training) Loss: 977891.3128\n",
      "(Validation) Loss: 786493.0279, MAE: 3342.8247, R2: 0.2006\n",
      "==========================================================================================\n",
      "Epoch [1783/5000] | Time: 0.28s\n",
      "(Training) Loss: 980949.8591\n",
      "(Validation) Loss: 786403.9314, MAE: 3343.4980, R2: 0.2007\n",
      "==========================================================================================\n",
      "Epoch [1784/5000] | Time: 0.27s\n",
      "(Training) Loss: 973802.9727\n",
      "(Validation) Loss: 786336.0013, MAE: 3345.7893, R2: 0.2008\n",
      "==========================================================================================\n",
      "Epoch [1785/5000] | Time: 0.25s\n",
      "(Training) Loss: 991103.0359\n",
      "(Validation) Loss: 786224.0362, MAE: 3345.7917, R2: 0.2009\n",
      "==========================================================================================\n",
      "Epoch [1786/5000] | Time: 0.26s\n",
      "(Training) Loss: 966985.9689\n",
      "(Validation) Loss: 786128.9429, MAE: 3341.3340, R2: 0.2010\n",
      "==========================================================================================\n",
      "Epoch [1787/5000] | Time: 0.31s\n",
      "(Training) Loss: 975327.1948\n",
      "(Validation) Loss: 786047.7721, MAE: 3343.8413, R2: 0.2011\n",
      "==========================================================================================\n",
      "Epoch [1788/5000] | Time: 0.25s\n",
      "(Training) Loss: 978392.3813\n",
      "(Validation) Loss: 786132.4400, MAE: 3355.6367, R2: 0.2010\n",
      "==========================================================================================\n",
      "Epoch [1789/5000] | Time: 0.23s\n",
      "(Training) Loss: 979275.9289\n",
      "(Validation) Loss: 786039.8832, MAE: 3354.2810, R2: 0.2011\n",
      "==========================================================================================\n",
      "Epoch [1790/5000] | Time: 0.20s\n",
      "(Training) Loss: 979860.4854\n",
      "(Validation) Loss: 785948.1467, MAE: 3353.9038, R2: 0.2012\n",
      "==========================================================================================\n",
      "Epoch [1791/5000] | Time: 0.30s\n",
      "(Training) Loss: 979736.6358\n",
      "(Validation) Loss: 785856.1124, MAE: 3353.5022, R2: 0.2012\n",
      "==========================================================================================\n",
      "Epoch [1792/5000] | Time: 0.27s\n",
      "(Training) Loss: 980422.4702\n",
      "(Validation) Loss: 785764.6184, MAE: 3352.7893, R2: 0.2013\n",
      "==========================================================================================\n",
      "Epoch [1793/5000] | Time: 0.24s\n",
      "(Training) Loss: 964626.9933\n",
      "(Validation) Loss: 785680.1092, MAE: 3359.4619, R2: 0.2014\n",
      "==========================================================================================\n",
      "Epoch [1794/5000] | Time: 0.27s\n",
      "(Training) Loss: 973248.7157\n",
      "(Validation) Loss: 785590.7410, MAE: 3358.7629, R2: 0.2015\n",
      "==========================================================================================\n",
      "Epoch [1795/5000] | Time: 0.20s\n",
      "(Training) Loss: 969715.8255\n",
      "(Validation) Loss: 785494.3289, MAE: 3351.2241, R2: 0.2016\n",
      "==========================================================================================\n",
      "Epoch [1796/5000] | Time: 0.24s\n",
      "(Training) Loss: 965134.5198\n",
      "(Validation) Loss: 785405.1371, MAE: 3352.1880, R2: 0.2017\n",
      "==========================================================================================\n",
      "Epoch [1797/5000] | Time: 0.28s\n",
      "(Training) Loss: 973858.7462\n",
      "(Validation) Loss: 785307.8508, MAE: 3350.3445, R2: 0.2018\n",
      "==========================================================================================\n",
      "Epoch [1798/5000] | Time: 0.22s\n",
      "(Training) Loss: 968674.8477\n",
      "(Validation) Loss: 785215.7746, MAE: 3349.3337, R2: 0.2019\n",
      "==========================================================================================\n",
      "Epoch [1799/5000] | Time: 0.23s\n",
      "(Training) Loss: 974277.5044\n",
      "(Validation) Loss: 785130.4622, MAE: 3356.1426, R2: 0.2020\n",
      "==========================================================================================\n",
      "Epoch [1800/5000] | Time: 0.23s\n",
      "(Training) Loss: 971025.1954\n",
      "(Validation) Loss: 785031.3848, MAE: 3346.7683, R2: 0.2021\n",
      "==========================================================================================\n",
      "Epoch [1801/5000] | Time: 0.25s\n",
      "(Training) Loss: 984530.7329\n",
      "(Validation) Loss: 769976.7537, MAE: 3313.7949, R2: 0.2172\n",
      "==========================================================================================\n",
      "Epoch [1802/5000] | Time: 0.28s\n",
      "(Training) Loss: 956565.5451\n",
      "(Validation) Loss: 769860.2673, MAE: 3298.2466, R2: 0.2174\n",
      "==========================================================================================\n",
      "Epoch [1803/5000] | Time: 0.25s\n",
      "(Training) Loss: 947895.8826\n",
      "(Validation) Loss: 769757.1594, MAE: 3294.6631, R2: 0.2175\n",
      "==========================================================================================\n",
      "Epoch [1804/5000] | Time: 0.25s\n",
      "(Training) Loss: 957763.5838\n",
      "(Validation) Loss: 769670.2724, MAE: 3293.8037, R2: 0.2175\n",
      "==========================================================================================\n",
      "Epoch [1805/5000] | Time: 0.25s\n",
      "(Training) Loss: 956093.1789\n",
      "(Validation) Loss: 769586.3867, MAE: 3297.1558, R2: 0.2176\n",
      "==========================================================================================\n",
      "Epoch [1806/5000] | Time: 0.25s\n",
      "(Training) Loss: 978808.0736\n",
      "(Validation) Loss: 769483.2667, MAE: 3292.6519, R2: 0.2177\n",
      "==========================================================================================\n",
      "Epoch [1807/5000] | Time: 0.24s\n",
      "(Training) Loss: 955489.6098\n",
      "(Validation) Loss: 769387.9181, MAE: 3292.2380, R2: 0.2178\n",
      "==========================================================================================\n",
      "Epoch [1808/5000] | Time: 0.26s\n",
      "(Training) Loss: 962744.7354\n",
      "(Validation) Loss: 769296.3270, MAE: 3295.5784, R2: 0.2179\n",
      "==========================================================================================\n",
      "Epoch [1809/5000] | Time: 0.23s\n",
      "(Training) Loss: 947585.4010\n",
      "(Validation) Loss: 769197.5975, MAE: 3288.5276, R2: 0.2180\n",
      "==========================================================================================\n",
      "Epoch [1810/5000] | Time: 0.22s\n",
      "(Training) Loss: 948263.6031\n",
      "(Validation) Loss: 769103.4521, MAE: 3286.6682, R2: 0.2181\n",
      "==========================================================================================\n",
      "Epoch [1811/5000] | Time: 0.21s\n",
      "(Training) Loss: 955320.5470\n",
      "(Validation) Loss: 769034.7263, MAE: 3290.3127, R2: 0.2182\n",
      "==========================================================================================\n",
      "Epoch [1812/5000] | Time: 0.24s\n",
      "(Training) Loss: 944898.4539\n",
      "(Validation) Loss: 768924.6451, MAE: 3286.5381, R2: 0.2183\n",
      "==========================================================================================\n",
      "Epoch [1813/5000] | Time: 0.28s\n",
      "(Training) Loss: 959055.9511\n",
      "(Validation) Loss: 768835.9613, MAE: 3286.1790, R2: 0.2184\n",
      "==========================================================================================\n",
      "Epoch [1814/5000] | Time: 0.32s\n",
      "(Training) Loss: 960492.9556\n",
      "(Validation) Loss: 768740.0933, MAE: 3282.2390, R2: 0.2185\n",
      "==========================================================================================\n",
      "Epoch [1815/5000] | Time: 0.36s\n",
      "(Training) Loss: 956086.2322\n",
      "(Validation) Loss: 768640.7321, MAE: 3282.8894, R2: 0.2186\n",
      "==========================================================================================\n",
      "Epoch [1816/5000] | Time: 0.30s\n",
      "(Training) Loss: 961247.3382\n",
      "(Validation) Loss: 768567.2800, MAE: 3284.7466, R2: 0.2187\n",
      "==========================================================================================\n",
      "Epoch [1817/5000] | Time: 0.24s\n",
      "(Training) Loss: 955778.0774\n",
      "(Validation) Loss: 768484.6324, MAE: 3292.2104, R2: 0.2187\n",
      "==========================================================================================\n",
      "Epoch [1818/5000] | Time: 0.27s\n",
      "(Training) Loss: 958342.7170\n",
      "(Validation) Loss: 768375.5206, MAE: 3281.9524, R2: 0.2189\n",
      "==========================================================================================\n",
      "Epoch [1819/5000] | Time: 0.27s\n",
      "(Training) Loss: 950174.7665\n",
      "(Validation) Loss: 768286.4527, MAE: 3285.9546, R2: 0.2189\n",
      "==========================================================================================\n",
      "Epoch [1820/5000] | Time: 0.26s\n",
      "(Training) Loss: 963007.5013\n",
      "(Validation) Loss: 768197.4895, MAE: 3281.1843, R2: 0.2190\n",
      "==========================================================================================\n",
      "Epoch [1821/5000] | Time: 0.27s\n",
      "(Training) Loss: 948300.8953\n",
      "(Validation) Loss: 749712.5784, MAE: 3256.1240, R2: 0.2377\n",
      "==========================================================================================\n",
      "Epoch [1822/5000] | Time: 0.28s\n",
      "(Training) Loss: 947087.8115\n",
      "(Validation) Loss: 758456.6743, MAE: 3268.2473, R2: 0.2288\n",
      "==========================================================================================\n",
      "Epoch [1823/5000] | Time: 0.28s\n",
      "(Training) Loss: 933262.2183\n",
      "(Validation) Loss: 758341.6933, MAE: 3260.8765, R2: 0.2290\n",
      "==========================================================================================\n",
      "Epoch [1824/5000] | Time: 0.34s\n",
      "(Training) Loss: 948202.4848\n",
      "(Validation) Loss: 758257.2775, MAE: 3259.1882, R2: 0.2290\n",
      "==========================================================================================\n",
      "Epoch [1825/5000] | Time: 0.33s\n",
      "(Training) Loss: 939012.5952\n",
      "(Validation) Loss: 758160.1524, MAE: 3255.3318, R2: 0.2291\n",
      "==========================================================================================\n",
      "Epoch [1826/5000] | Time: 0.28s\n",
      "(Training) Loss: 933484.0054\n",
      "(Validation) Loss: 758125.6438, MAE: 3264.5781, R2: 0.2292\n",
      "==========================================================================================\n",
      "Epoch [1827/5000] | Time: 0.31s\n",
      "(Training) Loss: 939598.2170\n",
      "(Validation) Loss: 757987.2552, MAE: 3254.8931, R2: 0.2293\n",
      "==========================================================================================\n",
      "Epoch [1828/5000] | Time: 0.27s\n",
      "(Training) Loss: 938758.2551\n",
      "(Validation) Loss: 757916.6578, MAE: 3256.9443, R2: 0.2294\n",
      "==========================================================================================\n",
      "Epoch [1829/5000] | Time: 0.36s\n",
      "(Training) Loss: 939351.3579\n",
      "(Validation) Loss: 757832.3879, MAE: 3258.1755, R2: 0.2295\n",
      "==========================================================================================\n",
      "Epoch [1830/5000] | Time: 0.31s\n",
      "(Training) Loss: 938312.5920\n",
      "(Validation) Loss: 757745.8324, MAE: 3257.4924, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [1831/5000] | Time: 0.33s\n",
      "(Training) Loss: 944558.3261\n",
      "(Validation) Loss: 757659.8451, MAE: 3256.1277, R2: 0.2296\n",
      "==========================================================================================\n",
      "Epoch [1832/5000] | Time: 0.34s\n",
      "(Training) Loss: 939428.8769\n",
      "(Validation) Loss: 757575.0641, MAE: 3257.1218, R2: 0.2297\n",
      "==========================================================================================\n",
      "Epoch [1833/5000] | Time: 0.30s\n",
      "(Training) Loss: 939760.3725\n",
      "(Validation) Loss: 746030.1816, MAE: 3223.9072, R2: 0.2414\n",
      "==========================================================================================\n",
      "Epoch [1834/5000] | Time: 0.32s\n",
      "(Training) Loss: 935766.1701\n",
      "(Validation) Loss: 745932.1384, MAE: 3223.2339, R2: 0.2415\n",
      "==========================================================================================\n",
      "Epoch [1835/5000] | Time: 0.27s\n",
      "(Training) Loss: 926085.4511\n",
      "(Validation) Loss: 745835.3752, MAE: 3221.7898, R2: 0.2416\n",
      "==========================================================================================\n",
      "Epoch [1836/5000] | Time: 0.28s\n",
      "(Training) Loss: 929894.8798\n",
      "(Validation) Loss: 745749.0337, MAE: 3222.4094, R2: 0.2417\n",
      "==========================================================================================\n",
      "Epoch [1837/5000] | Time: 0.26s\n",
      "(Training) Loss: 942033.3813\n",
      "(Validation) Loss: 745652.6870, MAE: 3221.5583, R2: 0.2417\n",
      "==========================================================================================\n",
      "Epoch [1838/5000] | Time: 0.29s\n",
      "(Training) Loss: 929108.1897\n",
      "(Validation) Loss: 745528.7676, MAE: 3218.4463, R2: 0.2419\n",
      "==========================================================================================\n",
      "Epoch [1839/5000] | Time: 0.28s\n",
      "(Training) Loss: 928898.9397\n",
      "(Validation) Loss: 745428.4127, MAE: 3215.2039, R2: 0.2420\n",
      "==========================================================================================\n",
      "Epoch [1840/5000] | Time: 0.31s\n",
      "(Training) Loss: 938044.7754\n",
      "(Validation) Loss: 745337.9594, MAE: 3214.2878, R2: 0.2421\n",
      "==========================================================================================\n",
      "Epoch [1841/5000] | Time: 0.28s\n",
      "(Training) Loss: 931694.9873\n",
      "(Validation) Loss: 745250.9771, MAE: 3214.5061, R2: 0.2422\n",
      "==========================================================================================\n",
      "Epoch [1842/5000] | Time: 0.26s\n",
      "(Training) Loss: 940051.7043\n",
      "(Validation) Loss: 745161.4622, MAE: 3214.3403, R2: 0.2422\n",
      "==========================================================================================\n",
      "Epoch [1843/5000] | Time: 0.28s\n",
      "(Training) Loss: 934696.1015\n",
      "(Validation) Loss: 745080.4546, MAE: 3215.5950, R2: 0.2423\n",
      "==========================================================================================\n",
      "Epoch [1844/5000] | Time: 0.28s\n",
      "(Training) Loss: 924196.1707\n",
      "(Validation) Loss: 745004.3587, MAE: 3217.1292, R2: 0.2424\n",
      "==========================================================================================\n",
      "Epoch [1845/5000] | Time: 0.32s\n",
      "(Training) Loss: 923893.1504\n",
      "(Validation) Loss: 744907.8813, MAE: 3216.5244, R2: 0.2425\n",
      "==========================================================================================\n",
      "Epoch [1846/5000] | Time: 0.30s\n",
      "(Training) Loss: 925843.4207\n",
      "(Validation) Loss: 744820.5302, MAE: 3215.1672, R2: 0.2426\n",
      "==========================================================================================\n",
      "Epoch [1847/5000] | Time: 0.25s\n",
      "(Training) Loss: 931561.1307\n",
      "(Validation) Loss: 744723.1454, MAE: 3213.6384, R2: 0.2427\n",
      "==========================================================================================\n",
      "Epoch [1848/5000] | Time: 0.26s\n",
      "(Training) Loss: 918474.4132\n",
      "(Validation) Loss: 744637.3632, MAE: 3213.1775, R2: 0.2428\n",
      "==========================================================================================\n",
      "Epoch [1849/5000] | Time: 0.25s\n",
      "(Training) Loss: 918724.0179\n",
      "(Validation) Loss: 744549.2133, MAE: 3212.1292, R2: 0.2429\n",
      "==========================================================================================\n",
      "Epoch [1850/5000] | Time: 0.23s\n",
      "(Training) Loss: 936994.0114\n",
      "(Validation) Loss: 744467.8006, MAE: 3214.3232, R2: 0.2429\n",
      "==========================================================================================\n",
      "Epoch [1851/5000] | Time: 0.25s\n",
      "(Training) Loss: 930894.1459\n",
      "(Validation) Loss: 744422.1092, MAE: 3218.5242, R2: 0.2430\n",
      "==========================================================================================\n",
      "Epoch [1852/5000] | Time: 0.23s\n",
      "(Training) Loss: 962085.0863\n",
      "(Validation) Loss: 744305.2184, MAE: 3215.0627, R2: 0.2431\n",
      "==========================================================================================\n",
      "Epoch [1853/5000] | Time: 0.23s\n",
      "(Training) Loss: 919856.7056\n",
      "(Validation) Loss: 744201.3797, MAE: 3211.7590, R2: 0.2432\n",
      "==========================================================================================\n",
      "Epoch [1854/5000] | Time: 0.22s\n",
      "(Training) Loss: 944599.7132\n",
      "(Validation) Loss: 744114.7975, MAE: 3211.7473, R2: 0.2433\n",
      "==========================================================================================\n",
      "Epoch [1855/5000] | Time: 0.27s\n",
      "(Training) Loss: 918898.5254\n",
      "(Validation) Loss: 744033.0133, MAE: 3212.4895, R2: 0.2434\n",
      "==========================================================================================\n",
      "Epoch [1856/5000] | Time: 0.26s\n",
      "(Training) Loss: 924906.7678\n",
      "(Validation) Loss: 743953.2648, MAE: 3213.8713, R2: 0.2435\n",
      "==========================================================================================\n",
      "Epoch [1857/5000] | Time: 0.24s\n",
      "(Training) Loss: 939153.1187\n",
      "(Validation) Loss: 743852.1886, MAE: 3210.5071, R2: 0.2436\n",
      "==========================================================================================\n",
      "Epoch [1858/5000] | Time: 0.22s\n",
      "(Training) Loss: 937027.2119\n",
      "(Validation) Loss: 743772.6394, MAE: 3212.8975, R2: 0.2436\n",
      "==========================================================================================\n",
      "Epoch [1859/5000] | Time: 0.28s\n",
      "(Training) Loss: 933144.6973\n",
      "(Validation) Loss: 743678.4883, MAE: 3210.4309, R2: 0.2437\n",
      "==========================================================================================\n",
      "Epoch [1860/5000] | Time: 0.23s\n",
      "(Training) Loss: 920725.6326\n",
      "(Validation) Loss: 743597.5302, MAE: 3212.8052, R2: 0.2438\n",
      "==========================================================================================\n",
      "Epoch [1861/5000] | Time: 0.22s\n",
      "(Training) Loss: 963602.3823\n",
      "(Validation) Loss: 743500.3600, MAE: 3208.5398, R2: 0.2439\n",
      "==========================================================================================\n",
      "Epoch [1862/5000] | Time: 0.26s\n",
      "(Training) Loss: 930154.0006\n",
      "(Validation) Loss: 743409.6527, MAE: 3208.0569, R2: 0.2440\n",
      "==========================================================================================\n",
      "Epoch [1863/5000] | Time: 0.25s\n",
      "(Training) Loss: 918980.9721\n",
      "(Validation) Loss: 743320.8533, MAE: 3206.4531, R2: 0.2441\n",
      "==========================================================================================\n",
      "Epoch [1864/5000] | Time: 0.26s\n",
      "(Training) Loss: 944949.1218\n",
      "(Validation) Loss: 743241.4019, MAE: 3210.5264, R2: 0.2442\n",
      "==========================================================================================\n",
      "Epoch [1865/5000] | Time: 0.22s\n",
      "(Training) Loss: 932902.4892\n",
      "(Validation) Loss: 743150.2032, MAE: 3206.8918, R2: 0.2443\n",
      "==========================================================================================\n",
      "Epoch [1866/5000] | Time: 0.25s\n",
      "(Training) Loss: 938438.6041\n",
      "(Validation) Loss: 743064.0457, MAE: 3207.8306, R2: 0.2444\n",
      "==========================================================================================\n",
      "Epoch [1867/5000] | Time: 0.26s\n",
      "(Training) Loss: 923760.6371\n",
      "(Validation) Loss: 742974.7327, MAE: 3206.5181, R2: 0.2444\n",
      "==========================================================================================\n",
      "Epoch [1868/5000] | Time: 0.23s\n",
      "(Training) Loss: 945024.7982\n",
      "(Validation) Loss: 742890.1949, MAE: 3207.1638, R2: 0.2445\n",
      "==========================================================================================\n",
      "Epoch [1869/5000] | Time: 0.32s\n",
      "(Training) Loss: 917410.8645\n",
      "(Validation) Loss: 742799.3143, MAE: 3205.6187, R2: 0.2446\n",
      "==========================================================================================\n",
      "Epoch [1870/5000] | Time: 0.24s\n",
      "(Training) Loss: 939178.2253\n",
      "(Validation) Loss: 742717.0946, MAE: 3207.5002, R2: 0.2447\n",
      "==========================================================================================\n",
      "Epoch [1871/5000] | Time: 0.23s\n",
      "(Training) Loss: 922491.2602\n",
      "(Validation) Loss: 742626.4610, MAE: 3205.3132, R2: 0.2448\n",
      "==========================================================================================\n",
      "Epoch [1872/5000] | Time: 0.27s\n",
      "(Training) Loss: 921212.7411\n",
      "(Validation) Loss: 742546.1524, MAE: 3206.2148, R2: 0.2449\n",
      "==========================================================================================\n",
      "Epoch [1873/5000] | Time: 0.34s\n",
      "(Training) Loss: 932114.6155\n",
      "(Validation) Loss: 742452.6432, MAE: 3203.9968, R2: 0.2450\n",
      "==========================================================================================\n",
      "Epoch [1874/5000] | Time: 0.34s\n",
      "(Training) Loss: 938419.2608\n",
      "(Validation) Loss: 742363.7651, MAE: 3203.8755, R2: 0.2451\n",
      "==========================================================================================\n",
      "Epoch [1875/5000] | Time: 0.37s\n",
      "(Training) Loss: 934425.0444\n",
      "(Validation) Loss: 742281.1308, MAE: 3204.0896, R2: 0.2451\n",
      "==========================================================================================\n",
      "Epoch [1876/5000] | Time: 0.35s\n",
      "(Training) Loss: 947268.1720\n",
      "(Validation) Loss: 742329.8616, MAE: 3214.2456, R2: 0.2451\n",
      "==========================================================================================\n",
      "Epoch [1877/5000] | Time: 0.34s\n",
      "(Training) Loss: 933692.5787\n",
      "(Validation) Loss: 742249.9149, MAE: 3216.6309, R2: 0.2452\n",
      "==========================================================================================\n",
      "Epoch [1878/5000] | Time: 0.29s\n",
      "(Training) Loss: 935277.7824\n",
      "(Validation) Loss: 742170.5943, MAE: 3219.7896, R2: 0.2453\n",
      "==========================================================================================\n",
      "Epoch [1879/5000] | Time: 0.27s\n",
      "(Training) Loss: 924816.9505\n",
      "(Validation) Loss: 742067.0959, MAE: 3214.4634, R2: 0.2454\n",
      "==========================================================================================\n",
      "Epoch [1880/5000] | Time: 0.36s\n",
      "(Training) Loss: 919822.7506\n",
      "(Validation) Loss: 741977.7168, MAE: 3212.4280, R2: 0.2454\n",
      "==========================================================================================\n",
      "Epoch [1881/5000] | Time: 0.30s\n",
      "(Training) Loss: 930695.7690\n",
      "(Validation) Loss: 741913.0203, MAE: 3218.1577, R2: 0.2455\n",
      "==========================================================================================\n",
      "Epoch [1882/5000] | Time: 0.27s\n",
      "(Training) Loss: 924621.2297\n",
      "(Validation) Loss: 741814.9384, MAE: 3215.3003, R2: 0.2456\n",
      "==========================================================================================\n",
      "Epoch [1883/5000] | Time: 0.26s\n",
      "(Training) Loss: 959303.7719\n",
      "(Validation) Loss: 741716.8654, MAE: 3211.3201, R2: 0.2457\n",
      "==========================================================================================\n",
      "Epoch [1884/5000] | Time: 0.32s\n",
      "(Training) Loss: 917627.3839\n",
      "(Validation) Loss: 741627.9422, MAE: 3210.7981, R2: 0.2458\n",
      "==========================================================================================\n",
      "Epoch [1885/5000] | Time: 0.29s\n",
      "(Training) Loss: 932417.1053\n",
      "(Validation) Loss: 741538.4070, MAE: 3210.3628, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [1886/5000] | Time: 0.28s\n",
      "(Training) Loss: 931400.1923\n",
      "(Validation) Loss: 741458.2025, MAE: 3211.0786, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [1887/5000] | Time: 0.30s\n",
      "(Training) Loss: 937932.2716\n",
      "(Validation) Loss: 741369.8229, MAE: 3209.2029, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [1888/5000] | Time: 0.28s\n",
      "(Training) Loss: 934739.4975\n",
      "(Validation) Loss: 741281.7162, MAE: 3210.1680, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [1889/5000] | Time: 0.28s\n",
      "(Training) Loss: 923365.5742\n",
      "(Validation) Loss: 741201.3930, MAE: 3211.9080, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [1890/5000] | Time: 0.29s\n",
      "(Training) Loss: 927538.9718\n",
      "(Validation) Loss: 741112.4686, MAE: 3210.2805, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [1891/5000] | Time: 0.26s\n",
      "(Training) Loss: 928781.6015\n",
      "(Validation) Loss: 741017.7130, MAE: 3207.6853, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [1892/5000] | Time: 0.27s\n",
      "(Training) Loss: 918160.4645\n",
      "(Validation) Loss: 740934.1454, MAE: 3207.2168, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [1893/5000] | Time: 0.28s\n",
      "(Training) Loss: 937312.1605\n",
      "(Validation) Loss: 740849.0952, MAE: 3208.0190, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [1894/5000] | Time: 0.28s\n",
      "(Training) Loss: 931958.0054\n",
      "(Validation) Loss: 740773.4851, MAE: 3210.3740, R2: 0.2467\n",
      "==========================================================================================\n",
      "Epoch [1895/5000] | Time: 0.27s\n",
      "(Training) Loss: 935381.2494\n",
      "(Validation) Loss: 740671.7841, MAE: 3206.4419, R2: 0.2468\n",
      "==========================================================================================\n",
      "Epoch [1896/5000] | Time: 0.28s\n",
      "(Training) Loss: 912462.0074\n",
      "(Validation) Loss: 740590.5308, MAE: 3207.4507, R2: 0.2468\n",
      "==========================================================================================\n",
      "Epoch [1897/5000] | Time: 0.28s\n",
      "(Training) Loss: 913130.0460\n",
      "(Validation) Loss: 740497.1727, MAE: 3205.2004, R2: 0.2469\n",
      "==========================================================================================\n",
      "Epoch [1898/5000] | Time: 0.30s\n",
      "(Training) Loss: 933258.2237\n",
      "(Validation) Loss: 740415.5010, MAE: 3206.0938, R2: 0.2470\n",
      "==========================================================================================\n",
      "Epoch [1899/5000] | Time: 0.28s\n",
      "(Training) Loss: 936920.5977\n",
      "(Validation) Loss: 740326.5816, MAE: 3204.7842, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [1900/5000] | Time: 0.26s\n",
      "(Training) Loss: 937630.3547\n",
      "(Validation) Loss: 740235.7549, MAE: 3202.9155, R2: 0.2472\n",
      "==========================================================================================\n",
      "Epoch [1901/5000] | Time: 0.27s\n",
      "(Training) Loss: 940688.8668\n",
      "(Validation) Loss: 740154.8800, MAE: 3204.7551, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [1902/5000] | Time: 0.32s\n",
      "(Training) Loss: 929240.9359\n",
      "(Validation) Loss: 740081.0622, MAE: 3209.3108, R2: 0.2474\n",
      "==========================================================================================\n",
      "Epoch [1903/5000] | Time: 0.24s\n",
      "(Training) Loss: 922248.6536\n",
      "(Validation) Loss: 739981.9092, MAE: 3205.3550, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [1904/5000] | Time: 0.29s\n",
      "(Training) Loss: 944617.5869\n",
      "(Validation) Loss: 739900.9441, MAE: 3206.3628, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [1905/5000] | Time: 0.27s\n",
      "(Training) Loss: 948059.7462\n",
      "(Validation) Loss: 739802.6121, MAE: 3203.3647, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [1906/5000] | Time: 0.28s\n",
      "(Training) Loss: 932893.7151\n",
      "(Validation) Loss: 739716.7606, MAE: 3203.3042, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [1907/5000] | Time: 0.27s\n",
      "(Training) Loss: 920975.3357\n",
      "(Validation) Loss: 739628.8368, MAE: 3202.4893, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [1908/5000] | Time: 0.28s\n",
      "(Training) Loss: 921991.2570\n",
      "(Validation) Loss: 739551.0089, MAE: 3204.0520, R2: 0.2479\n",
      "==========================================================================================\n",
      "Epoch [1909/5000] | Time: 0.28s\n",
      "(Training) Loss: 918616.4175\n",
      "(Validation) Loss: 739466.8876, MAE: 3205.3005, R2: 0.2480\n",
      "==========================================================================================\n",
      "Epoch [1910/5000] | Time: 0.31s\n",
      "(Training) Loss: 935757.1212\n",
      "(Validation) Loss: 739369.0990, MAE: 3201.4365, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [1911/5000] | Time: 0.27s\n",
      "(Training) Loss: 917279.8515\n",
      "(Validation) Loss: 739282.8527, MAE: 3201.6829, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [1912/5000] | Time: 0.28s\n",
      "(Training) Loss: 929556.7088\n",
      "(Validation) Loss: 739203.6686, MAE: 3202.6074, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [1913/5000] | Time: 0.31s\n",
      "(Training) Loss: 912926.7909\n",
      "(Validation) Loss: 739116.9079, MAE: 3202.3511, R2: 0.2483\n",
      "==========================================================================================\n",
      "Epoch [1914/5000] | Time: 0.27s\n",
      "(Training) Loss: 925207.4524\n",
      "(Validation) Loss: 739026.7886, MAE: 3200.9270, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [1915/5000] | Time: 0.28s\n",
      "(Training) Loss: 917790.3566\n",
      "(Validation) Loss: 738940.1733, MAE: 3200.6572, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [1916/5000] | Time: 0.28s\n",
      "(Training) Loss: 913048.8030\n",
      "(Validation) Loss: 738856.3270, MAE: 3201.9961, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [1917/5000] | Time: 0.25s\n",
      "(Training) Loss: 910779.3932\n",
      "(Validation) Loss: 738766.8768, MAE: 3199.8613, R2: 0.2487\n",
      "==========================================================================================\n",
      "Epoch [1918/5000] | Time: 0.26s\n",
      "(Training) Loss: 923653.2018\n",
      "(Validation) Loss: 738682.6470, MAE: 3199.3264, R2: 0.2488\n",
      "==========================================================================================\n",
      "Epoch [1919/5000] | Time: 0.27s\n",
      "(Training) Loss: 934729.4524\n",
      "(Validation) Loss: 738597.7365, MAE: 3200.6177, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [1920/5000] | Time: 0.27s\n",
      "(Training) Loss: 930570.5451\n",
      "(Validation) Loss: 738507.6565, MAE: 3199.7261, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [1921/5000] | Time: 0.27s\n",
      "(Training) Loss: 919356.3712\n",
      "(Validation) Loss: 738420.4616, MAE: 3199.1699, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [1922/5000] | Time: 0.29s\n",
      "(Training) Loss: 918013.1371\n",
      "(Validation) Loss: 738339.6825, MAE: 3199.5051, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [1923/5000] | Time: 0.28s\n",
      "(Training) Loss: 925652.1085\n",
      "(Validation) Loss: 738252.1117, MAE: 3197.7039, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [1924/5000] | Time: 0.28s\n",
      "(Training) Loss: 922735.1948\n",
      "(Validation) Loss: 738166.3683, MAE: 3199.0071, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [1925/5000] | Time: 0.26s\n",
      "(Training) Loss: 911215.9256\n",
      "(Validation) Loss: 738073.1568, MAE: 3196.3977, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [1926/5000] | Time: 0.29s\n",
      "(Training) Loss: 909843.1568\n",
      "(Validation) Loss: 737990.1600, MAE: 3196.8813, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [1927/5000] | Time: 0.29s\n",
      "(Training) Loss: 934485.1631\n",
      "(Validation) Loss: 737905.1143, MAE: 3195.9380, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [1928/5000] | Time: 0.40s\n",
      "(Training) Loss: 928238.7862\n",
      "(Validation) Loss: 737829.1848, MAE: 3200.7207, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [1929/5000] | Time: 0.31s\n",
      "(Training) Loss: 929048.2091\n",
      "(Validation) Loss: 737750.9651, MAE: 3202.6921, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [1930/5000] | Time: 0.34s\n",
      "(Training) Loss: 915380.7722\n",
      "(Validation) Loss: 737650.4089, MAE: 3197.9268, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [1931/5000] | Time: 0.27s\n",
      "(Training) Loss: 917116.0774\n",
      "(Validation) Loss: 737633.8317, MAE: 3205.5549, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [1932/5000] | Time: 0.47s\n",
      "(Training) Loss: 908926.3569\n",
      "(Validation) Loss: 737297.0889, MAE: 3182.2134, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [1933/5000] | Time: 0.30s\n",
      "(Training) Loss: 919703.6770\n",
      "(Validation) Loss: 737329.1854, MAE: 3193.9026, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [1934/5000] | Time: 0.28s\n",
      "(Training) Loss: 910276.0520\n",
      "(Validation) Loss: 737269.2959, MAE: 3193.7349, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [1935/5000] | Time: 0.25s\n",
      "(Training) Loss: 918659.5882\n",
      "(Validation) Loss: 737050.4171, MAE: 3183.7556, R2: 0.2504\n",
      "==========================================================================================\n",
      "Epoch [1936/5000] | Time: 0.30s\n",
      "(Training) Loss: 919915.5241\n",
      "(Validation) Loss: 736970.5117, MAE: 3184.0063, R2: 0.2505\n",
      "==========================================================================================\n",
      "Epoch [1937/5000] | Time: 0.32s\n",
      "(Training) Loss: 927191.4473\n",
      "(Validation) Loss: 738957.8686, MAE: 3189.5276, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [1938/5000] | Time: 0.34s\n",
      "(Training) Loss: 929986.1821\n",
      "(Validation) Loss: 738855.4400, MAE: 3188.9219, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [1939/5000] | Time: 0.26s\n",
      "(Training) Loss: 921475.1117\n",
      "(Validation) Loss: 738759.7860, MAE: 3187.1162, R2: 0.2487\n",
      "==========================================================================================\n",
      "Epoch [1940/5000] | Time: 0.29s\n",
      "(Training) Loss: 944236.1510\n",
      "(Validation) Loss: 738670.2546, MAE: 3189.4429, R2: 0.2488\n",
      "==========================================================================================\n",
      "Epoch [1941/5000] | Time: 0.26s\n",
      "(Training) Loss: 910981.7779\n",
      "(Validation) Loss: 738585.5378, MAE: 3190.1372, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [1942/5000] | Time: 0.25s\n",
      "(Training) Loss: 920522.4841\n",
      "(Validation) Loss: 738488.3073, MAE: 3195.3140, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [1943/5000] | Time: 0.24s\n",
      "(Training) Loss: 911662.9051\n",
      "(Validation) Loss: 738396.2565, MAE: 3193.5701, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [1944/5000] | Time: 0.22s\n",
      "(Training) Loss: 934528.7855\n",
      "(Validation) Loss: 738305.6533, MAE: 3190.2729, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [1945/5000] | Time: 0.21s\n",
      "(Training) Loss: 923681.0495\n",
      "(Validation) Loss: 738266.0451, MAE: 3193.0723, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [1946/5000] | Time: 0.25s\n",
      "(Training) Loss: 932530.8274\n",
      "(Validation) Loss: 738122.5479, MAE: 3187.7737, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [1947/5000] | Time: 0.25s\n",
      "(Training) Loss: 941260.2056\n",
      "(Validation) Loss: 738030.5295, MAE: 3187.8210, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [1948/5000] | Time: 0.23s\n",
      "(Training) Loss: 925572.3426\n",
      "(Validation) Loss: 737952.3410, MAE: 3190.2234, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [1949/5000] | Time: 0.28s\n",
      "(Training) Loss: 931802.2069\n",
      "(Validation) Loss: 737850.0025, MAE: 3186.9824, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [1950/5000] | Time: 0.28s\n",
      "(Training) Loss: 913889.2678\n",
      "(Validation) Loss: 737757.5371, MAE: 3185.8157, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [1951/5000] | Time: 0.27s\n",
      "(Training) Loss: 925722.0742\n",
      "(Validation) Loss: 737677.2006, MAE: 3188.3064, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [1952/5000] | Time: 0.36s\n",
      "(Training) Loss: 915720.4746\n",
      "(Validation) Loss: 737587.8108, MAE: 3187.6091, R2: 0.2499\n",
      "==========================================================================================\n",
      "Epoch [1953/5000] | Time: 0.32s\n",
      "(Training) Loss: 925982.8737\n",
      "(Validation) Loss: 737498.0559, MAE: 3186.9277, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [1954/5000] | Time: 0.30s\n",
      "(Training) Loss: 920322.3122\n",
      "(Validation) Loss: 737409.8044, MAE: 3188.3445, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [1955/5000] | Time: 0.28s\n",
      "(Training) Loss: 924915.0384\n",
      "(Validation) Loss: 747176.0984, MAE: 3216.0066, R2: 0.2402\n",
      "==========================================================================================\n",
      "Epoch [1956/5000] | Time: 0.33s\n",
      "(Training) Loss: 949890.6136\n",
      "(Validation) Loss: 771138.4152, MAE: 3297.0298, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [1957/5000] | Time: 0.29s\n",
      "(Training) Loss: 965888.5063\n",
      "(Validation) Loss: 771036.2952, MAE: 3293.7410, R2: 0.2162\n",
      "==========================================================================================\n",
      "Epoch [1958/5000] | Time: 0.29s\n",
      "(Training) Loss: 959989.3071\n",
      "(Validation) Loss: 770919.6006, MAE: 3290.8298, R2: 0.2163\n",
      "==========================================================================================\n",
      "Epoch [1959/5000] | Time: 0.37s\n",
      "(Training) Loss: 983055.4009\n",
      "(Validation) Loss: 770826.0013, MAE: 3290.3586, R2: 0.2164\n",
      "==========================================================================================\n",
      "Epoch [1960/5000] | Time: 0.48s\n",
      "(Training) Loss: 952248.8585\n",
      "(Validation) Loss: 770725.6470, MAE: 3288.2959, R2: 0.2165\n",
      "==========================================================================================\n",
      "Epoch [1961/5000] | Time: 0.38s\n",
      "(Training) Loss: 953528.8401\n",
      "(Validation) Loss: 770632.8946, MAE: 3288.4502, R2: 0.2166\n",
      "==========================================================================================\n",
      "Epoch [1962/5000] | Time: 0.38s\n",
      "(Training) Loss: 952526.3604\n",
      "(Validation) Loss: 770550.0622, MAE: 3290.4109, R2: 0.2167\n",
      "==========================================================================================\n",
      "Epoch [1963/5000] | Time: 0.34s\n",
      "(Training) Loss: 976007.9581\n",
      "(Validation) Loss: 770443.1987, MAE: 3287.3540, R2: 0.2168\n",
      "==========================================================================================\n",
      "Epoch [1964/5000] | Time: 0.36s\n",
      "(Training) Loss: 960949.1196\n",
      "(Validation) Loss: 770350.8978, MAE: 3287.4087, R2: 0.2169\n",
      "==========================================================================================\n",
      "Epoch [1965/5000] | Time: 0.40s\n",
      "(Training) Loss: 949191.5882\n",
      "(Validation) Loss: 770260.0717, MAE: 3288.0129, R2: 0.2170\n",
      "==========================================================================================\n",
      "Epoch [1966/5000] | Time: 0.38s\n",
      "(Training) Loss: 952095.0089\n",
      "(Validation) Loss: 770164.1283, MAE: 3288.2031, R2: 0.2171\n",
      "==========================================================================================\n",
      "Epoch [1967/5000] | Time: 0.41s\n",
      "(Training) Loss: 952743.5286\n",
      "(Validation) Loss: 770074.8648, MAE: 3288.9988, R2: 0.2171\n",
      "==========================================================================================\n",
      "Epoch [1968/5000] | Time: 0.39s\n",
      "(Training) Loss: 967574.2582\n",
      "(Validation) Loss: 769978.2375, MAE: 3286.9990, R2: 0.2172\n",
      "==========================================================================================\n",
      "Epoch [1969/5000] | Time: 0.38s\n",
      "(Training) Loss: 980134.6332\n",
      "(Validation) Loss: 769886.3149, MAE: 3287.9819, R2: 0.2173\n",
      "==========================================================================================\n",
      "Epoch [1970/5000] | Time: 0.32s\n",
      "(Training) Loss: 961192.4429\n",
      "(Validation) Loss: 769789.5606, MAE: 3286.6914, R2: 0.2174\n",
      "==========================================================================================\n",
      "Epoch [1971/5000] | Time: 0.36s\n",
      "(Training) Loss: 963083.4867\n",
      "(Validation) Loss: 769715.7994, MAE: 3290.1055, R2: 0.2175\n",
      "==========================================================================================\n",
      "Epoch [1972/5000] | Time: 0.31s\n",
      "(Training) Loss: 959557.9016\n",
      "(Validation) Loss: 769599.7352, MAE: 3285.4028, R2: 0.2176\n",
      "==========================================================================================\n",
      "Epoch [1973/5000] | Time: 0.38s\n",
      "(Training) Loss: 959474.8319\n",
      "(Validation) Loss: 769508.1511, MAE: 3286.4219, R2: 0.2177\n",
      "==========================================================================================\n",
      "Epoch [1974/5000] | Time: 0.36s\n",
      "(Training) Loss: 972572.1504\n",
      "(Validation) Loss: 769413.1676, MAE: 3284.8418, R2: 0.2178\n",
      "==========================================================================================\n",
      "Epoch [1975/5000] | Time: 0.34s\n",
      "(Training) Loss: 957793.0044\n",
      "(Validation) Loss: 769320.0978, MAE: 3284.8455, R2: 0.2179\n",
      "==========================================================================================\n",
      "Epoch [1976/5000] | Time: 0.40s\n",
      "(Training) Loss: 974358.7322\n",
      "(Validation) Loss: 768992.8019, MAE: 3285.2085, R2: 0.2182\n",
      "==========================================================================================\n",
      "Epoch [1977/5000] | Time: 0.40s\n",
      "(Training) Loss: 952240.3515\n",
      "(Validation) Loss: 768883.3663, MAE: 3284.0085, R2: 0.2183\n",
      "==========================================================================================\n",
      "Epoch [1978/5000] | Time: 0.48s\n",
      "(Training) Loss: 967182.3496\n",
      "(Validation) Loss: 768783.0254, MAE: 3283.9131, R2: 0.2184\n",
      "==========================================================================================\n",
      "Epoch [1979/5000] | Time: 0.47s\n",
      "(Training) Loss: 955967.0013\n",
      "(Validation) Loss: 768681.1117, MAE: 3281.8997, R2: 0.2185\n",
      "==========================================================================================\n",
      "Epoch [1980/5000] | Time: 0.45s\n",
      "(Training) Loss: 974680.4965\n",
      "(Validation) Loss: 768586.5257, MAE: 3281.8564, R2: 0.2186\n",
      "==========================================================================================\n",
      "Epoch [1981/5000] | Time: 0.46s\n",
      "(Training) Loss: 959747.7411\n",
      "(Validation) Loss: 768486.4032, MAE: 3281.7222, R2: 0.2187\n",
      "==========================================================================================\n",
      "Epoch [1982/5000] | Time: 0.40s\n",
      "(Training) Loss: 957036.1187\n",
      "(Validation) Loss: 768391.9676, MAE: 3282.8083, R2: 0.2188\n",
      "==========================================================================================\n",
      "Epoch [1983/5000] | Time: 0.34s\n",
      "(Training) Loss: 956527.2195\n",
      "(Validation) Loss: 768294.7511, MAE: 3280.9595, R2: 0.2189\n",
      "==========================================================================================\n",
      "Epoch [1984/5000] | Time: 0.32s\n",
      "(Training) Loss: 951720.8642\n",
      "(Validation) Loss: 768205.5187, MAE: 3282.1423, R2: 0.2190\n",
      "==========================================================================================\n",
      "Epoch [1985/5000] | Time: 0.40s\n",
      "(Training) Loss: 947759.3737\n",
      "(Validation) Loss: 768101.6508, MAE: 3279.9631, R2: 0.2191\n",
      "==========================================================================================\n",
      "Epoch [1986/5000] | Time: 0.52s\n",
      "(Training) Loss: 944256.8825\n",
      "(Validation) Loss: 768005.5111, MAE: 3279.9421, R2: 0.2192\n",
      "==========================================================================================\n",
      "Epoch [1987/5000] | Time: 0.31s\n",
      "(Training) Loss: 944476.9593\n",
      "(Validation) Loss: 767919.8229, MAE: 3281.2729, R2: 0.2193\n",
      "==========================================================================================\n",
      "Epoch [1988/5000] | Time: 0.49s\n",
      "(Training) Loss: 953347.1440\n",
      "(Validation) Loss: 767816.1543, MAE: 3278.7295, R2: 0.2194\n",
      "==========================================================================================\n",
      "Epoch [1989/5000] | Time: 0.38s\n",
      "(Training) Loss: 978829.1574\n",
      "(Validation) Loss: 767732.6692, MAE: 3282.1968, R2: 0.2195\n",
      "==========================================================================================\n",
      "Epoch [1990/5000] | Time: 0.39s\n",
      "(Training) Loss: 948860.6818\n",
      "(Validation) Loss: 767642.8533, MAE: 3280.1384, R2: 0.2196\n",
      "==========================================================================================\n",
      "Epoch [1991/5000] | Time: 0.29s\n",
      "(Training) Loss: 958277.5558\n",
      "(Validation) Loss: 767533.2317, MAE: 3279.0349, R2: 0.2197\n",
      "==========================================================================================\n",
      "Epoch [1992/5000] | Time: 0.28s\n",
      "(Training) Loss: 964463.1256\n",
      "(Validation) Loss: 767438.5752, MAE: 3277.7788, R2: 0.2198\n",
      "==========================================================================================\n",
      "Epoch [1993/5000] | Time: 0.27s\n",
      "(Training) Loss: 958259.0387\n",
      "(Validation) Loss: 767345.6006, MAE: 3276.2095, R2: 0.2199\n",
      "==========================================================================================\n",
      "Epoch [1994/5000] | Time: 0.28s\n",
      "(Training) Loss: 954921.4543\n",
      "(Validation) Loss: 767250.9206, MAE: 3276.5652, R2: 0.2200\n",
      "==========================================================================================\n",
      "Epoch [1995/5000] | Time: 0.31s\n",
      "(Training) Loss: 962465.0647\n",
      "(Validation) Loss: 767152.0235, MAE: 3274.9888, R2: 0.2201\n",
      "==========================================================================================\n",
      "Epoch [1996/5000] | Time: 0.38s\n",
      "(Training) Loss: 971841.8198\n",
      "(Validation) Loss: 767089.3232, MAE: 3279.6360, R2: 0.2201\n",
      "==========================================================================================\n",
      "Epoch [1997/5000] | Time: 0.38s\n",
      "(Training) Loss: 961371.2322\n",
      "(Validation) Loss: 766990.7016, MAE: 3278.9968, R2: 0.2202\n",
      "==========================================================================================\n",
      "Epoch [1998/5000] | Time: 0.39s\n",
      "(Training) Loss: 958300.5108\n",
      "(Validation) Loss: 766869.2108, MAE: 3274.3496, R2: 0.2204\n",
      "==========================================================================================\n",
      "Epoch [1999/5000] | Time: 0.25s\n",
      "(Training) Loss: 962556.5438\n",
      "(Validation) Loss: 766774.1302, MAE: 3274.7656, R2: 0.2205\n",
      "==========================================================================================\n",
      "Epoch [2000/5000] | Time: 0.30s\n",
      "(Training) Loss: 943798.7032\n",
      "(Validation) Loss: 766692.1359, MAE: 3276.4399, R2: 0.2206\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch2000.pth\n",
      "==========================================================================================\n",
      "Epoch [2001/5000] | Time: 0.27s\n",
      "(Training) Loss: 965479.9987\n",
      "(Validation) Loss: 766599.3594, MAE: 3274.2761, R2: 0.2206\n",
      "==========================================================================================\n",
      "Epoch [2002/5000] | Time: 0.29s\n",
      "(Training) Loss: 971626.5063\n",
      "(Validation) Loss: 766491.2940, MAE: 3272.5400, R2: 0.2208\n",
      "==========================================================================================\n",
      "Epoch [2003/5000] | Time: 0.33s\n",
      "(Training) Loss: 977898.4635\n",
      "(Validation) Loss: 766398.5784, MAE: 3273.6938, R2: 0.2208\n",
      "==========================================================================================\n",
      "Epoch [2004/5000] | Time: 0.38s\n",
      "(Training) Loss: 952473.2881\n",
      "(Validation) Loss: 766349.8686, MAE: 3277.5940, R2: 0.2209\n",
      "==========================================================================================\n",
      "Epoch [2005/5000] | Time: 0.38s\n",
      "(Training) Loss: 958362.2627\n",
      "(Validation) Loss: 766256.7378, MAE: 3277.2988, R2: 0.2210\n",
      "==========================================================================================\n",
      "Epoch [2006/5000] | Time: 0.27s\n",
      "(Training) Loss: 961458.9581\n",
      "(Validation) Loss: 766124.5619, MAE: 3273.0161, R2: 0.2211\n",
      "==========================================================================================\n",
      "Epoch [2007/5000] | Time: 0.28s\n",
      "(Training) Loss: 973583.9055\n",
      "(Validation) Loss: 766019.9562, MAE: 3269.4885, R2: 0.2212\n",
      "==========================================================================================\n",
      "Epoch [2008/5000] | Time: 0.27s\n",
      "(Training) Loss: 963080.8871\n",
      "(Validation) Loss: 765928.0451, MAE: 3270.1438, R2: 0.2213\n",
      "==========================================================================================\n",
      "Epoch [2009/5000] | Time: 0.26s\n",
      "(Training) Loss: 956944.3223\n",
      "(Validation) Loss: 765830.9562, MAE: 3269.3999, R2: 0.2214\n",
      "==========================================================================================\n",
      "Epoch [2010/5000] | Time: 0.36s\n",
      "(Training) Loss: 956751.0673\n",
      "(Validation) Loss: 765737.1987, MAE: 3268.8179, R2: 0.2215\n",
      "==========================================================================================\n",
      "Epoch [2011/5000] | Time: 0.26s\n",
      "(Training) Loss: 942955.7538\n",
      "(Validation) Loss: 765653.4698, MAE: 3270.1138, R2: 0.2216\n",
      "==========================================================================================\n",
      "Epoch [2012/5000] | Time: 0.27s\n",
      "(Training) Loss: 954284.1929\n",
      "(Validation) Loss: 765549.7143, MAE: 3267.0520, R2: 0.2217\n",
      "==========================================================================================\n",
      "Epoch [2013/5000] | Time: 0.32s\n",
      "(Training) Loss: 950911.1605\n",
      "(Validation) Loss: 765455.2210, MAE: 3266.2615, R2: 0.2218\n",
      "==========================================================================================\n",
      "Epoch [2014/5000] | Time: 0.38s\n",
      "(Training) Loss: 941814.6145\n",
      "(Validation) Loss: 765372.9467, MAE: 3267.5303, R2: 0.2219\n",
      "==========================================================================================\n",
      "Epoch [2015/5000] | Time: 0.29s\n",
      "(Training) Loss: 967679.9400\n",
      "(Validation) Loss: 765277.2819, MAE: 3267.3384, R2: 0.2220\n",
      "==========================================================================================\n",
      "Epoch [2016/5000] | Time: 0.30s\n",
      "(Training) Loss: 967544.4889\n",
      "(Validation) Loss: 765184.8159, MAE: 3268.4849, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [2017/5000] | Time: 0.30s\n",
      "(Training) Loss: 955546.9010\n",
      "(Validation) Loss: 765092.1225, MAE: 3266.1448, R2: 0.2222\n",
      "==========================================================================================\n",
      "Epoch [2018/5000] | Time: 0.27s\n",
      "(Training) Loss: 941897.1945\n",
      "(Validation) Loss: 765000.8540, MAE: 3268.2969, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [2019/5000] | Time: 0.27s\n",
      "(Training) Loss: 954424.5780\n",
      "(Validation) Loss: 764935.5467, MAE: 3270.9016, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [2020/5000] | Time: 0.22s\n",
      "(Training) Loss: 959131.8414\n",
      "(Validation) Loss: 764816.0127, MAE: 3268.3572, R2: 0.2224\n",
      "==========================================================================================\n",
      "Epoch [2021/5000] | Time: 0.26s\n",
      "(Training) Loss: 958231.1459\n",
      "(Validation) Loss: 764717.3695, MAE: 3264.6208, R2: 0.2225\n",
      "==========================================================================================\n",
      "Epoch [2022/5000] | Time: 0.28s\n",
      "(Training) Loss: 944933.2398\n",
      "(Validation) Loss: 764631.0235, MAE: 3265.0540, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [2023/5000] | Time: 0.27s\n",
      "(Training) Loss: 955497.3953\n",
      "(Validation) Loss: 764531.4578, MAE: 3264.7158, R2: 0.2227\n",
      "==========================================================================================\n",
      "Epoch [2024/5000] | Time: 0.26s\n",
      "(Training) Loss: 957067.7557\n",
      "(Validation) Loss: 764444.0940, MAE: 3264.9058, R2: 0.2228\n",
      "==========================================================================================\n",
      "Epoch [2025/5000] | Time: 0.26s\n",
      "(Training) Loss: 957161.7418\n",
      "(Validation) Loss: 764356.7422, MAE: 3266.6741, R2: 0.2229\n",
      "==========================================================================================\n",
      "Epoch [2026/5000] | Time: 0.38s\n",
      "(Training) Loss: 962213.5761\n",
      "(Validation) Loss: 764252.1937, MAE: 3263.6487, R2: 0.2230\n",
      "==========================================================================================\n",
      "Epoch [2027/5000] | Time: 0.38s\n",
      "(Training) Loss: 949425.2398\n",
      "(Validation) Loss: 764157.9619, MAE: 3262.2886, R2: 0.2231\n",
      "==========================================================================================\n",
      "Epoch [2028/5000] | Time: 0.34s\n",
      "(Training) Loss: 939965.8079\n",
      "(Validation) Loss: 764069.8197, MAE: 3262.5474, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [2029/5000] | Time: 0.30s\n",
      "(Training) Loss: 951388.0133\n",
      "(Validation) Loss: 763982.5994, MAE: 3264.6565, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [2030/5000] | Time: 0.33s\n",
      "(Training) Loss: 945250.2760\n",
      "(Validation) Loss: 763893.3175, MAE: 3265.5876, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [2031/5000] | Time: 0.29s\n",
      "(Training) Loss: 951257.6307\n",
      "(Validation) Loss: 763804.6343, MAE: 3263.6272, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [2032/5000] | Time: 0.27s\n",
      "(Training) Loss: 948825.7195\n",
      "(Validation) Loss: 763697.0863, MAE: 3261.8936, R2: 0.2236\n",
      "==========================================================================================\n",
      "Epoch [2033/5000] | Time: 0.29s\n",
      "(Training) Loss: 955905.5508\n",
      "(Validation) Loss: 763612.0552, MAE: 3261.5076, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [2034/5000] | Time: 0.25s\n",
      "(Training) Loss: 955999.3255\n",
      "(Validation) Loss: 763512.6927, MAE: 3263.6228, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [2035/5000] | Time: 0.26s\n",
      "(Training) Loss: 949569.0489\n",
      "(Validation) Loss: 763420.4552, MAE: 3261.9534, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [2036/5000] | Time: 0.22s\n",
      "(Training) Loss: 955949.8947\n",
      "(Validation) Loss: 763336.3410, MAE: 3261.8423, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [2037/5000] | Time: 0.21s\n",
      "(Training) Loss: 956064.5463\n",
      "(Validation) Loss: 763231.6089, MAE: 3259.7600, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [2038/5000] | Time: 0.25s\n",
      "(Training) Loss: 949000.3560\n",
      "(Validation) Loss: 763137.7708, MAE: 3259.2317, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [2039/5000] | Time: 0.24s\n",
      "(Training) Loss: 978952.7151\n",
      "(Validation) Loss: 763062.6673, MAE: 3262.6558, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [2040/5000] | Time: 0.23s\n",
      "(Training) Loss: 961258.1390\n",
      "(Validation) Loss: 762947.1238, MAE: 3257.6089, R2: 0.2243\n",
      "==========================================================================================\n",
      "Epoch [2041/5000] | Time: 0.24s\n",
      "(Training) Loss: 951568.7687\n",
      "(Validation) Loss: 762866.8851, MAE: 3259.5464, R2: 0.2244\n",
      "==========================================================================================\n",
      "Epoch [2042/5000] | Time: 0.27s\n",
      "(Training) Loss: 966757.3655\n",
      "(Validation) Loss: 762770.4394, MAE: 3259.8677, R2: 0.2245\n",
      "==========================================================================================\n",
      "Epoch [2043/5000] | Time: 0.24s\n",
      "(Training) Loss: 962930.9499\n",
      "(Validation) Loss: 762683.3276, MAE: 3259.7000, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [2044/5000] | Time: 0.25s\n",
      "(Training) Loss: 939634.5625\n",
      "(Validation) Loss: 762587.3124, MAE: 3258.5930, R2: 0.2247\n",
      "==========================================================================================\n",
      "Epoch [2045/5000] | Time: 0.23s\n",
      "(Training) Loss: 948196.4645\n",
      "(Validation) Loss: 762492.9956, MAE: 3257.8501, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [2046/5000] | Time: 0.25s\n",
      "(Training) Loss: 941971.1504\n",
      "(Validation) Loss: 762399.3352, MAE: 3257.0750, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [2047/5000] | Time: 0.25s\n",
      "(Training) Loss: 953699.7874\n",
      "(Validation) Loss: 762304.5479, MAE: 3255.7715, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [2048/5000] | Time: 0.30s\n",
      "(Training) Loss: 950440.2246\n",
      "(Validation) Loss: 762226.0133, MAE: 3261.8274, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [2049/5000] | Time: 0.29s\n",
      "(Training) Loss: 955501.6504\n",
      "(Validation) Loss: 762134.1035, MAE: 3256.7883, R2: 0.2251\n",
      "==========================================================================================\n",
      "Epoch [2050/5000] | Time: 0.24s\n",
      "(Training) Loss: 946848.4042\n",
      "(Validation) Loss: 762028.2667, MAE: 3255.6746, R2: 0.2252\n",
      "==========================================================================================\n",
      "Epoch [2051/5000] | Time: 0.33s\n",
      "(Training) Loss: 955971.6923\n",
      "(Validation) Loss: 761930.6794, MAE: 3255.4819, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [2052/5000] | Time: 0.26s\n",
      "(Training) Loss: 944904.7843\n",
      "(Validation) Loss: 761840.6095, MAE: 3254.7654, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [2053/5000] | Time: 0.28s\n",
      "(Training) Loss: 947377.9803\n",
      "(Validation) Loss: 761762.0178, MAE: 3257.5688, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [2054/5000] | Time: 0.27s\n",
      "(Training) Loss: 949919.3414\n",
      "(Validation) Loss: 761657.3162, MAE: 3255.4082, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [2055/5000] | Time: 0.27s\n",
      "(Training) Loss: 948264.1148\n",
      "(Validation) Loss: 761574.0749, MAE: 3254.8276, R2: 0.2257\n",
      "==========================================================================================\n",
      "Epoch [2056/5000] | Time: 0.26s\n",
      "(Training) Loss: 948228.1345\n",
      "(Validation) Loss: 761468.2927, MAE: 3251.7942, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [2057/5000] | Time: 0.25s\n",
      "(Training) Loss: 973193.8566\n",
      "(Validation) Loss: 761377.4159, MAE: 3254.4622, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [2058/5000] | Time: 0.26s\n",
      "(Training) Loss: 945377.7354\n",
      "(Validation) Loss: 761299.1708, MAE: 3255.1868, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [2059/5000] | Time: 0.25s\n",
      "(Training) Loss: 946588.7589\n",
      "(Validation) Loss: 761191.8648, MAE: 3251.4290, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [2060/5000] | Time: 0.26s\n",
      "(Training) Loss: 943883.3598\n",
      "(Validation) Loss: 761103.1771, MAE: 3251.2285, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [2061/5000] | Time: 0.24s\n",
      "(Training) Loss: 936741.1562\n",
      "(Validation) Loss: 761008.2749, MAE: 3250.5754, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [2062/5000] | Time: 0.26s\n",
      "(Training) Loss: 935687.3967\n",
      "(Validation) Loss: 760933.7867, MAE: 3254.6299, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [2063/5000] | Time: 0.23s\n",
      "(Training) Loss: 936317.8606\n",
      "(Validation) Loss: 760840.4006, MAE: 3253.7581, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [2064/5000] | Time: 0.23s\n",
      "(Training) Loss: 936570.3683\n",
      "(Validation) Loss: 760735.4470, MAE: 3250.3809, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [2065/5000] | Time: 0.24s\n",
      "(Training) Loss: 951311.4080\n",
      "(Validation) Loss: 760650.2324, MAE: 3251.9617, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [2066/5000] | Time: 0.25s\n",
      "(Training) Loss: 937509.3874\n",
      "(Validation) Loss: 760562.9308, MAE: 3251.1582, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [2067/5000] | Time: 0.26s\n",
      "(Training) Loss: 939909.4645\n",
      "(Validation) Loss: 760467.9403, MAE: 3250.7283, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [2068/5000] | Time: 0.25s\n",
      "(Training) Loss: 941096.3407\n",
      "(Validation) Loss: 760503.2546, MAE: 3265.8000, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [2069/5000] | Time: 0.25s\n",
      "(Training) Loss: 935044.5083\n",
      "(Validation) Loss: 760403.0660, MAE: 3258.4839, R2: 0.2269\n",
      "==========================================================================================\n",
      "Epoch [2070/5000] | Time: 0.26s\n",
      "(Training) Loss: 951132.1720\n",
      "(Validation) Loss: 760317.3016, MAE: 3258.9219, R2: 0.2270\n",
      "==========================================================================================\n",
      "Epoch [2071/5000] | Time: 0.24s\n",
      "(Training) Loss: 939367.6536\n",
      "(Validation) Loss: 760217.9657, MAE: 3257.1521, R2: 0.2271\n",
      "==========================================================================================\n",
      "Epoch [2072/5000] | Time: 0.23s\n",
      "(Training) Loss: 945964.5492\n",
      "(Validation) Loss: 760130.9841, MAE: 3259.1912, R2: 0.2272\n",
      "==========================================================================================\n",
      "Epoch [2073/5000] | Time: 0.24s\n",
      "(Training) Loss: 947196.5032\n",
      "(Validation) Loss: 760031.9067, MAE: 3256.5034, R2: 0.2273\n",
      "==========================================================================================\n",
      "Epoch [2074/5000] | Time: 0.26s\n",
      "(Training) Loss: 938714.9334\n",
      "(Validation) Loss: 759937.4432, MAE: 3256.3152, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [2075/5000] | Time: 0.26s\n",
      "(Training) Loss: 966705.8966\n",
      "(Validation) Loss: 759843.3086, MAE: 3254.1074, R2: 0.2274\n",
      "==========================================================================================\n",
      "Epoch [2076/5000] | Time: 0.24s\n",
      "(Training) Loss: 955891.9010\n",
      "(Validation) Loss: 759755.2406, MAE: 3255.0906, R2: 0.2275\n",
      "==========================================================================================\n",
      "Epoch [2077/5000] | Time: 0.26s\n",
      "(Training) Loss: 936216.2326\n",
      "(Validation) Loss: 759657.7467, MAE: 3253.4854, R2: 0.2276\n",
      "==========================================================================================\n",
      "Epoch [2078/5000] | Time: 0.28s\n",
      "(Training) Loss: 953767.1878\n",
      "(Validation) Loss: 759565.2578, MAE: 3253.4038, R2: 0.2277\n",
      "==========================================================================================\n",
      "Epoch [2079/5000] | Time: 0.25s\n",
      "(Training) Loss: 947573.2912\n",
      "(Validation) Loss: 759492.1714, MAE: 3257.1863, R2: 0.2278\n",
      "==========================================================================================\n",
      "Epoch [2080/5000] | Time: 0.25s\n",
      "(Training) Loss: 946047.8883\n",
      "(Validation) Loss: 759377.4546, MAE: 3253.2185, R2: 0.2279\n",
      "==========================================================================================\n",
      "Epoch [2081/5000] | Time: 0.25s\n",
      "(Training) Loss: 960880.0060\n",
      "(Validation) Loss: 759292.6400, MAE: 3253.4321, R2: 0.2280\n",
      "==========================================================================================\n",
      "Epoch [2082/5000] | Time: 0.27s\n",
      "(Training) Loss: 952977.8163\n",
      "(Validation) Loss: 759198.3232, MAE: 3253.0461, R2: 0.2281\n",
      "==========================================================================================\n",
      "Epoch [2083/5000] | Time: 0.25s\n",
      "(Training) Loss: 937634.9029\n",
      "(Validation) Loss: 759098.8775, MAE: 3249.8975, R2: 0.2282\n",
      "==========================================================================================\n",
      "Epoch [2084/5000] | Time: 0.27s\n",
      "(Training) Loss: 923152.8553\n",
      "(Validation) Loss: 746785.9879, MAE: 3211.5356, R2: 0.2406\n",
      "==========================================================================================\n",
      "Epoch [2085/5000] | Time: 0.26s\n",
      "(Training) Loss: 919589.9858\n",
      "(Validation) Loss: 746751.7632, MAE: 3220.0977, R2: 0.2406\n",
      "==========================================================================================\n",
      "Epoch [2086/5000] | Time: 0.28s\n",
      "(Training) Loss: 925774.6656\n",
      "(Validation) Loss: 746619.6908, MAE: 3211.1208, R2: 0.2408\n",
      "==========================================================================================\n",
      "Epoch [2087/5000] | Time: 0.27s\n",
      "(Training) Loss: 941293.7348\n",
      "(Validation) Loss: 746555.7359, MAE: 3213.4575, R2: 0.2408\n",
      "==========================================================================================\n",
      "Epoch [2088/5000] | Time: 0.29s\n",
      "(Training) Loss: 920131.2600\n",
      "(Validation) Loss: 746452.8724, MAE: 3211.9246, R2: 0.2409\n",
      "==========================================================================================\n",
      "Epoch [2089/5000] | Time: 0.27s\n",
      "(Training) Loss: 943955.8027\n",
      "(Validation) Loss: 746362.9829, MAE: 3209.9980, R2: 0.2410\n",
      "==========================================================================================\n",
      "Epoch [2090/5000] | Time: 0.28s\n",
      "(Training) Loss: 922073.3274\n",
      "(Validation) Loss: 746106.5232, MAE: 3206.6946, R2: 0.2413\n",
      "==========================================================================================\n",
      "Epoch [2091/5000] | Time: 0.25s\n",
      "(Training) Loss: 924266.9264\n",
      "(Validation) Loss: 746024.4756, MAE: 3210.5410, R2: 0.2414\n",
      "==========================================================================================\n",
      "Epoch [2092/5000] | Time: 0.25s\n",
      "(Training) Loss: 934444.8598\n",
      "(Validation) Loss: 745930.0775, MAE: 3209.6650, R2: 0.2415\n",
      "==========================================================================================\n",
      "Epoch [2093/5000] | Time: 0.24s\n",
      "(Training) Loss: 929579.3556\n",
      "(Validation) Loss: 745830.7619, MAE: 3206.3782, R2: 0.2416\n",
      "==========================================================================================\n",
      "Epoch [2094/5000] | Time: 0.25s\n",
      "(Training) Loss: 922116.3062\n",
      "(Validation) Loss: 745747.0533, MAE: 3208.7075, R2: 0.2417\n",
      "==========================================================================================\n",
      "Epoch [2095/5000] | Time: 0.26s\n",
      "(Training) Loss: 923630.1789\n",
      "(Validation) Loss: 745661.1733, MAE: 3211.4167, R2: 0.2417\n",
      "==========================================================================================\n",
      "Epoch [2096/5000] | Time: 0.23s\n",
      "(Training) Loss: 927944.1136\n",
      "(Validation) Loss: 753815.3416, MAE: 3233.7476, R2: 0.2335\n",
      "==========================================================================================\n",
      "Epoch [2097/5000] | Time: 0.24s\n",
      "(Training) Loss: 942865.0400\n",
      "(Validation) Loss: 753727.4521, MAE: 3233.1704, R2: 0.2336\n",
      "==========================================================================================\n",
      "Epoch [2098/5000] | Time: 0.25s\n",
      "(Training) Loss: 932826.8236\n",
      "(Validation) Loss: 753550.6184, MAE: 3231.0032, R2: 0.2338\n",
      "==========================================================================================\n",
      "Epoch [2099/5000] | Time: 0.24s\n",
      "(Training) Loss: 938035.6834\n",
      "(Validation) Loss: 753442.6330, MAE: 3227.0422, R2: 0.2339\n",
      "==========================================================================================\n",
      "Epoch [2100/5000] | Time: 0.23s\n",
      "(Training) Loss: 955705.2900\n",
      "(Validation) Loss: 753324.8870, MAE: 3223.0400, R2: 0.2340\n",
      "==========================================================================================\n",
      "Epoch [2101/5000] | Time: 0.24s\n",
      "(Training) Loss: 931538.2427\n",
      "(Validation) Loss: 753232.4794, MAE: 3222.4790, R2: 0.2341\n",
      "==========================================================================================\n",
      "Epoch [2102/5000] | Time: 0.26s\n",
      "(Training) Loss: 940692.5444\n",
      "(Validation) Loss: 753139.3060, MAE: 3221.8977, R2: 0.2342\n",
      "==========================================================================================\n",
      "Epoch [2103/5000] | Time: 0.27s\n",
      "(Training) Loss: 932894.0076\n",
      "(Validation) Loss: 753074.4203, MAE: 3229.4517, R2: 0.2343\n",
      "==========================================================================================\n",
      "Epoch [2104/5000] | Time: 0.26s\n",
      "(Training) Loss: 932644.0844\n",
      "(Validation) Loss: 752960.5016, MAE: 3222.5908, R2: 0.2344\n",
      "==========================================================================================\n",
      "Epoch [2105/5000] | Time: 0.24s\n",
      "(Training) Loss: 935289.8280\n",
      "(Validation) Loss: 752888.4622, MAE: 3227.5430, R2: 0.2345\n",
      "==========================================================================================\n",
      "Epoch [2106/5000] | Time: 0.27s\n",
      "(Training) Loss: 947464.5673\n",
      "(Validation) Loss: 752781.9302, MAE: 3222.0596, R2: 0.2346\n",
      "==========================================================================================\n",
      "Epoch [2107/5000] | Time: 0.29s\n",
      "(Training) Loss: 939673.0945\n",
      "(Validation) Loss: 752697.5848, MAE: 3224.4570, R2: 0.2346\n",
      "==========================================================================================\n",
      "Epoch [2108/5000] | Time: 0.25s\n",
      "(Training) Loss: 932379.0489\n",
      "(Validation) Loss: 752591.7930, MAE: 3223.2717, R2: 0.2348\n",
      "==========================================================================================\n",
      "Epoch [2109/5000] | Time: 0.24s\n",
      "(Training) Loss: 937497.7563\n",
      "(Validation) Loss: 752501.4895, MAE: 3219.7139, R2: 0.2348\n",
      "==========================================================================================\n",
      "Epoch [2110/5000] | Time: 0.25s\n",
      "(Training) Loss: 942255.4530\n",
      "(Validation) Loss: 752419.5657, MAE: 3222.1892, R2: 0.2349\n",
      "==========================================================================================\n",
      "Epoch [2111/5000] | Time: 0.24s\n",
      "(Training) Loss: 930045.7766\n",
      "(Validation) Loss: 752322.5956, MAE: 3219.8809, R2: 0.2350\n",
      "==========================================================================================\n",
      "Epoch [2112/5000] | Time: 0.24s\n",
      "(Training) Loss: 927964.6272\n",
      "(Validation) Loss: 752249.8552, MAE: 3224.5901, R2: 0.2351\n",
      "==========================================================================================\n",
      "Epoch [2113/5000] | Time: 0.27s\n",
      "(Training) Loss: 932304.6802\n",
      "(Validation) Loss: 752144.7149, MAE: 3221.0642, R2: 0.2352\n",
      "==========================================================================================\n",
      "Epoch [2114/5000] | Time: 0.28s\n",
      "(Training) Loss: 934470.3863\n",
      "(Validation) Loss: 752058.5879, MAE: 3222.1079, R2: 0.2353\n",
      "==========================================================================================\n",
      "Epoch [2115/5000] | Time: 0.24s\n",
      "(Training) Loss: 937063.4473\n",
      "(Validation) Loss: 751950.0159, MAE: 3217.4585, R2: 0.2354\n",
      "==========================================================================================\n",
      "Epoch [2116/5000] | Time: 0.25s\n",
      "(Training) Loss: 936853.1745\n",
      "(Validation) Loss: 751866.1651, MAE: 3218.6924, R2: 0.2355\n",
      "==========================================================================================\n",
      "Epoch [2117/5000] | Time: 0.25s\n",
      "(Training) Loss: 955832.6926\n",
      "(Validation) Loss: 751766.7727, MAE: 3217.2759, R2: 0.2356\n",
      "==========================================================================================\n",
      "Epoch [2118/5000] | Time: 0.26s\n",
      "(Training) Loss: 955233.0051\n",
      "(Validation) Loss: 751677.1175, MAE: 3218.3140, R2: 0.2357\n",
      "==========================================================================================\n",
      "Epoch [2119/5000] | Time: 0.25s\n",
      "(Training) Loss: 935864.3883\n",
      "(Validation) Loss: 751583.7422, MAE: 3215.6934, R2: 0.2358\n",
      "==========================================================================================\n",
      "Epoch [2120/5000] | Time: 0.25s\n",
      "(Training) Loss: 938324.2500\n",
      "(Validation) Loss: 751496.6121, MAE: 3216.6628, R2: 0.2359\n",
      "==========================================================================================\n",
      "Epoch [2121/5000] | Time: 0.26s\n",
      "(Training) Loss: 950692.5704\n",
      "(Validation) Loss: 751409.4019, MAE: 3217.2412, R2: 0.2359\n",
      "==========================================================================================\n",
      "Epoch [2122/5000] | Time: 0.26s\n",
      "(Training) Loss: 954490.3896\n",
      "(Validation) Loss: 751317.9276, MAE: 3218.7878, R2: 0.2360\n",
      "==========================================================================================\n",
      "Epoch [2123/5000] | Time: 0.25s\n",
      "(Training) Loss: 950783.6415\n",
      "(Validation) Loss: 751217.0038, MAE: 3215.5728, R2: 0.2361\n",
      "==========================================================================================\n",
      "Epoch [2124/5000] | Time: 0.25s\n",
      "(Training) Loss: 934139.8223\n",
      "(Validation) Loss: 751138.1283, MAE: 3218.0723, R2: 0.2362\n",
      "==========================================================================================\n",
      "Epoch [2125/5000] | Time: 0.26s\n",
      "(Training) Loss: 936169.7005\n",
      "(Validation) Loss: 751093.0311, MAE: 3218.6555, R2: 0.2363\n",
      "==========================================================================================\n",
      "Epoch [2126/5000] | Time: 0.27s\n",
      "(Training) Loss: 950337.7519\n",
      "(Validation) Loss: 750951.7968, MAE: 3219.0732, R2: 0.2364\n",
      "==========================================================================================\n",
      "Epoch [2127/5000] | Time: 0.26s\n",
      "(Training) Loss: 936787.9607\n",
      "(Validation) Loss: 750874.3460, MAE: 3219.9197, R2: 0.2365\n",
      "==========================================================================================\n",
      "Epoch [2128/5000] | Time: 0.24s\n",
      "(Training) Loss: 946446.1713\n",
      "(Validation) Loss: 750789.1397, MAE: 3218.9873, R2: 0.2366\n",
      "==========================================================================================\n",
      "Epoch [2129/5000] | Time: 0.23s\n",
      "(Training) Loss: 927130.8464\n",
      "(Validation) Loss: 750685.1441, MAE: 3217.9336, R2: 0.2367\n",
      "==========================================================================================\n",
      "Epoch [2130/5000] | Time: 0.25s\n",
      "(Training) Loss: 925709.8074\n",
      "(Validation) Loss: 750593.4737, MAE: 3216.7019, R2: 0.2368\n",
      "==========================================================================================\n",
      "Epoch [2131/5000] | Time: 0.27s\n",
      "(Training) Loss: 940705.0019\n",
      "(Validation) Loss: 750509.0768, MAE: 3217.5732, R2: 0.2369\n",
      "==========================================================================================\n",
      "Epoch [2132/5000] | Time: 0.24s\n",
      "(Training) Loss: 935011.3319\n",
      "(Validation) Loss: 750422.3143, MAE: 3220.0020, R2: 0.2369\n",
      "==========================================================================================\n",
      "Epoch [2133/5000] | Time: 0.25s\n",
      "(Training) Loss: 938980.0482\n",
      "(Validation) Loss: 750365.4387, MAE: 3220.0552, R2: 0.2370\n",
      "==========================================================================================\n",
      "Epoch [2134/5000] | Time: 0.23s\n",
      "(Training) Loss: 947460.9918\n",
      "(Validation) Loss: 750278.1352, MAE: 3222.1143, R2: 0.2371\n",
      "==========================================================================================\n",
      "Epoch [2135/5000] | Time: 0.25s\n",
      "(Training) Loss: 925870.8718\n",
      "(Validation) Loss: 750182.2387, MAE: 3219.1660, R2: 0.2372\n",
      "==========================================================================================\n",
      "Epoch [2136/5000] | Time: 0.25s\n",
      "(Training) Loss: 975124.5799\n",
      "(Validation) Loss: 750097.3581, MAE: 3219.8171, R2: 0.2373\n",
      "==========================================================================================\n",
      "Epoch [2137/5000] | Time: 0.24s\n",
      "(Training) Loss: 942753.7398\n",
      "(Validation) Loss: 749999.7124, MAE: 3219.1536, R2: 0.2374\n",
      "==========================================================================================\n",
      "Epoch [2138/5000] | Time: 0.24s\n",
      "(Training) Loss: 932062.9721\n",
      "(Validation) Loss: 749912.8394, MAE: 3218.6426, R2: 0.2375\n",
      "==========================================================================================\n",
      "Epoch [2139/5000] | Time: 0.27s\n",
      "(Training) Loss: 946001.5019\n",
      "(Validation) Loss: 749824.5994, MAE: 3218.5869, R2: 0.2375\n",
      "==========================================================================================\n",
      "Epoch [2140/5000] | Time: 0.25s\n",
      "(Training) Loss: 935170.9207\n",
      "(Validation) Loss: 749738.8571, MAE: 3220.7036, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [2141/5000] | Time: 0.24s\n",
      "(Training) Loss: 929634.5682\n",
      "(Validation) Loss: 749644.6794, MAE: 3218.0049, R2: 0.2377\n",
      "==========================================================================================\n",
      "Epoch [2142/5000] | Time: 0.32s\n",
      "(Training) Loss: 954080.4156\n",
      "(Validation) Loss: 749570.2286, MAE: 3218.0601, R2: 0.2378\n",
      "==========================================================================================\n",
      "Epoch [2143/5000] | Time: 0.30s\n",
      "(Training) Loss: 942448.7716\n",
      "(Validation) Loss: 749457.6686, MAE: 3217.7729, R2: 0.2379\n",
      "==========================================================================================\n",
      "Epoch [2144/5000] | Time: 0.27s\n",
      "(Training) Loss: 934549.5133\n",
      "(Validation) Loss: 749375.0044, MAE: 3221.4556, R2: 0.2380\n",
      "==========================================================================================\n",
      "Epoch [2145/5000] | Time: 0.26s\n",
      "(Training) Loss: 930350.0603\n",
      "(Validation) Loss: 749277.8324, MAE: 3218.4683, R2: 0.2381\n",
      "==========================================================================================\n",
      "Epoch [2146/5000] | Time: 0.31s\n",
      "(Training) Loss: 942691.3096\n",
      "(Validation) Loss: 749195.3397, MAE: 3219.4949, R2: 0.2382\n",
      "==========================================================================================\n",
      "Epoch [2147/5000] | Time: 0.34s\n",
      "(Training) Loss: 929946.8588\n",
      "(Validation) Loss: 749104.6394, MAE: 3217.5938, R2: 0.2383\n",
      "==========================================================================================\n",
      "Epoch [2148/5000] | Time: 0.30s\n",
      "(Training) Loss: 939234.6028\n",
      "(Validation) Loss: 749011.5657, MAE: 3215.9004, R2: 0.2384\n",
      "==========================================================================================\n",
      "Epoch [2149/5000] | Time: 0.30s\n",
      "(Training) Loss: 947232.6034\n",
      "(Validation) Loss: 748925.6356, MAE: 3218.1892, R2: 0.2385\n",
      "==========================================================================================\n",
      "Epoch [2150/5000] | Time: 0.33s\n",
      "(Training) Loss: 924180.7662\n",
      "(Validation) Loss: 748825.4438, MAE: 3216.1931, R2: 0.2386\n",
      "==========================================================================================\n",
      "Epoch [2151/5000] | Time: 0.36s\n",
      "(Training) Loss: 933358.1142\n",
      "(Validation) Loss: 748746.0076, MAE: 3217.8459, R2: 0.2386\n",
      "==========================================================================================\n",
      "Epoch [2152/5000] | Time: 0.31s\n",
      "(Training) Loss: 942015.3103\n",
      "(Validation) Loss: 748647.8743, MAE: 3214.5198, R2: 0.2387\n",
      "==========================================================================================\n",
      "Epoch [2153/5000] | Time: 0.33s\n",
      "(Training) Loss: 926207.7291\n",
      "(Validation) Loss: 748556.2730, MAE: 3215.6172, R2: 0.2388\n",
      "==========================================================================================\n",
      "Epoch [2154/5000] | Time: 0.34s\n",
      "(Training) Loss: 938338.5812\n",
      "(Validation) Loss: 748460.9117, MAE: 3212.7847, R2: 0.2389\n",
      "==========================================================================================\n",
      "Epoch [2155/5000] | Time: 0.32s\n",
      "(Training) Loss: 924718.6596\n",
      "(Validation) Loss: 748380.8521, MAE: 3215.1663, R2: 0.2390\n",
      "==========================================================================================\n",
      "Epoch [2156/5000] | Time: 0.27s\n",
      "(Training) Loss: 922187.6395\n",
      "(Validation) Loss: 748287.3010, MAE: 3212.6309, R2: 0.2391\n",
      "==========================================================================================\n",
      "Epoch [2157/5000] | Time: 0.23s\n",
      "(Training) Loss: 930944.1015\n",
      "(Validation) Loss: 748195.7746, MAE: 3213.5029, R2: 0.2392\n",
      "==========================================================================================\n",
      "Epoch [2158/5000] | Time: 0.25s\n",
      "(Training) Loss: 930469.4524\n",
      "(Validation) Loss: 748104.5048, MAE: 3213.2747, R2: 0.2393\n",
      "==========================================================================================\n",
      "Epoch [2159/5000] | Time: 0.22s\n",
      "(Training) Loss: 927050.7272\n",
      "(Validation) Loss: 748034.6565, MAE: 3216.2466, R2: 0.2393\n",
      "==========================================================================================\n",
      "Epoch [2160/5000] | Time: 0.27s\n",
      "(Training) Loss: 932381.6885\n",
      "(Validation) Loss: 747928.7816, MAE: 3211.7834, R2: 0.2395\n",
      "==========================================================================================\n",
      "Epoch [2161/5000] | Time: 0.23s\n",
      "(Training) Loss: 942379.0882\n",
      "(Validation) Loss: 747857.6362, MAE: 3214.1914, R2: 0.2395\n",
      "==========================================================================================\n",
      "Epoch [2162/5000] | Time: 0.25s\n",
      "(Training) Loss: 930625.1428\n",
      "(Validation) Loss: 747755.5943, MAE: 3213.4055, R2: 0.2396\n",
      "==========================================================================================\n",
      "Epoch [2163/5000] | Time: 0.25s\n",
      "(Training) Loss: 932261.2126\n",
      "(Validation) Loss: 747654.4381, MAE: 3213.1042, R2: 0.2397\n",
      "==========================================================================================\n",
      "Epoch [2164/5000] | Time: 0.26s\n",
      "(Training) Loss: 935285.1015\n",
      "(Validation) Loss: 747569.8533, MAE: 3211.8628, R2: 0.2398\n",
      "==========================================================================================\n",
      "Epoch [2165/5000] | Time: 0.23s\n",
      "(Training) Loss: 929145.7297\n",
      "(Validation) Loss: 747473.2946, MAE: 3209.5635, R2: 0.2399\n",
      "==========================================================================================\n",
      "Epoch [2166/5000] | Time: 0.28s\n",
      "(Training) Loss: 940827.3287\n",
      "(Validation) Loss: 747387.9613, MAE: 3211.3333, R2: 0.2400\n",
      "==========================================================================================\n",
      "Epoch [2167/5000] | Time: 0.27s\n",
      "(Training) Loss: 921992.0825\n",
      "(Validation) Loss: 747299.3994, MAE: 3210.2654, R2: 0.2401\n",
      "==========================================================================================\n",
      "Epoch [2168/5000] | Time: 0.27s\n",
      "(Training) Loss: 936807.3512\n",
      "(Validation) Loss: 747201.7505, MAE: 3208.4829, R2: 0.2402\n",
      "==========================================================================================\n",
      "Epoch [2169/5000] | Time: 0.30s\n",
      "(Training) Loss: 954735.8769\n",
      "(Validation) Loss: 747112.8044, MAE: 3208.8323, R2: 0.2403\n",
      "==========================================================================================\n",
      "Epoch [2170/5000] | Time: 0.24s\n",
      "(Training) Loss: 935248.8915\n",
      "(Validation) Loss: 747030.0349, MAE: 3209.5835, R2: 0.2404\n",
      "==========================================================================================\n",
      "Epoch [2171/5000] | Time: 0.27s\n",
      "(Training) Loss: 929112.2303\n",
      "(Validation) Loss: 746949.8940, MAE: 3213.4880, R2: 0.2404\n",
      "==========================================================================================\n",
      "Epoch [2172/5000] | Time: 0.25s\n",
      "(Training) Loss: 929265.7798\n",
      "(Validation) Loss: 746843.1898, MAE: 3208.2688, R2: 0.2405\n",
      "==========================================================================================\n",
      "Epoch [2173/5000] | Time: 0.23s\n",
      "(Training) Loss: 941145.6580\n",
      "(Validation) Loss: 746760.7505, MAE: 3209.6255, R2: 0.2406\n",
      "==========================================================================================\n",
      "Epoch [2174/5000] | Time: 0.23s\n",
      "(Training) Loss: 934845.0977\n",
      "(Validation) Loss: 746665.0679, MAE: 3207.4221, R2: 0.2407\n",
      "==========================================================================================\n",
      "Epoch [2175/5000] | Time: 0.23s\n",
      "(Training) Loss: 930340.1720\n",
      "(Validation) Loss: 746580.8641, MAE: 3209.2964, R2: 0.2408\n",
      "==========================================================================================\n",
      "Epoch [2176/5000] | Time: 0.26s\n",
      "(Training) Loss: 931496.0806\n",
      "(Validation) Loss: 746495.1981, MAE: 3208.4771, R2: 0.2409\n",
      "==========================================================================================\n",
      "Epoch [2177/5000] | Time: 0.23s\n",
      "(Training) Loss: 922995.9093\n",
      "(Validation) Loss: 746410.8832, MAE: 3214.0564, R2: 0.2410\n",
      "==========================================================================================\n",
      "Epoch [2178/5000] | Time: 0.25s\n",
      "(Training) Loss: 940807.7792\n",
      "(Validation) Loss: 746319.9111, MAE: 3209.3047, R2: 0.2411\n",
      "==========================================================================================\n",
      "Epoch [2179/5000] | Time: 0.23s\n",
      "(Training) Loss: 935343.0019\n",
      "(Validation) Loss: 746228.1111, MAE: 3211.3245, R2: 0.2412\n",
      "==========================================================================================\n",
      "Epoch [2180/5000] | Time: 0.25s\n",
      "(Training) Loss: 936111.1637\n",
      "(Validation) Loss: 746136.7467, MAE: 3208.2253, R2: 0.2413\n",
      "==========================================================================================\n",
      "Epoch [2181/5000] | Time: 0.23s\n",
      "(Training) Loss: 938020.1662\n",
      "(Validation) Loss: 746052.3924, MAE: 3209.4270, R2: 0.2413\n",
      "==========================================================================================\n",
      "Epoch [2182/5000] | Time: 0.25s\n",
      "(Training) Loss: 929111.3782\n",
      "(Validation) Loss: 745955.6127, MAE: 3207.6895, R2: 0.2414\n",
      "==========================================================================================\n",
      "Epoch [2183/5000] | Time: 0.23s\n",
      "(Training) Loss: 926062.4848\n",
      "(Validation) Loss: 745861.9346, MAE: 3206.9849, R2: 0.2415\n",
      "==========================================================================================\n",
      "Epoch [2184/5000] | Time: 0.24s\n",
      "(Training) Loss: 934273.6206\n",
      "(Validation) Loss: 739142.9213, MAE: 3188.8318, R2: 0.2483\n",
      "==========================================================================================\n",
      "Epoch [2185/5000] | Time: 0.24s\n",
      "(Training) Loss: 926817.7189\n",
      "(Validation) Loss: 739027.1695, MAE: 3184.1575, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [2186/5000] | Time: 0.23s\n",
      "(Training) Loss: 918548.6256\n",
      "(Validation) Loss: 738948.1486, MAE: 3183.9087, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [2187/5000] | Time: 0.24s\n",
      "(Training) Loss: 914141.0368\n",
      "(Validation) Loss: 738843.0971, MAE: 3181.8350, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [2188/5000] | Time: 0.24s\n",
      "(Training) Loss: 930396.5359\n",
      "(Validation) Loss: 738772.8571, MAE: 3184.1609, R2: 0.2487\n",
      "==========================================================================================\n",
      "Epoch [2189/5000] | Time: 0.25s\n",
      "(Training) Loss: 917634.4239\n",
      "(Validation) Loss: 738672.8095, MAE: 3182.2905, R2: 0.2488\n",
      "==========================================================================================\n",
      "Epoch [2190/5000] | Time: 0.24s\n",
      "(Training) Loss: 920372.6694\n",
      "(Validation) Loss: 738589.9537, MAE: 3186.7761, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [2191/5000] | Time: 0.26s\n",
      "(Training) Loss: 933144.2760\n",
      "(Validation) Loss: 738503.5111, MAE: 3183.1667, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [2192/5000] | Time: 0.25s\n",
      "(Training) Loss: 927693.8431\n",
      "(Validation) Loss: 738425.8152, MAE: 3185.3997, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [2193/5000] | Time: 0.24s\n",
      "(Training) Loss: 918214.7335\n",
      "(Validation) Loss: 738323.7841, MAE: 3181.5266, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [2194/5000] | Time: 0.23s\n",
      "(Training) Loss: 924433.8928\n",
      "(Validation) Loss: 738235.9416, MAE: 3182.4705, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [2195/5000] | Time: 0.23s\n",
      "(Training) Loss: 927272.2443\n",
      "(Validation) Loss: 738139.9048, MAE: 3179.0515, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [2196/5000] | Time: 0.25s\n",
      "(Training) Loss: 949475.5501\n",
      "(Validation) Loss: 738059.3638, MAE: 3181.6780, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [2197/5000] | Time: 0.24s\n",
      "(Training) Loss: 923403.3338\n",
      "(Validation) Loss: 737968.1695, MAE: 3181.6851, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [2198/5000] | Time: 0.23s\n",
      "(Training) Loss: 915123.9473\n",
      "(Validation) Loss: 737875.5848, MAE: 3182.2244, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [2199/5000] | Time: 0.23s\n",
      "(Training) Loss: 941349.2348\n",
      "(Validation) Loss: 737805.7498, MAE: 3182.7607, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [2200/5000] | Time: 0.25s\n",
      "(Training) Loss: 911594.8484\n",
      "(Validation) Loss: 737706.4825, MAE: 3182.5801, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [2201/5000] | Time: 0.23s\n",
      "(Training) Loss: 909028.6957\n",
      "(Validation) Loss: 737621.2032, MAE: 3180.9685, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [2202/5000] | Time: 0.25s\n",
      "(Training) Loss: 926517.6815\n",
      "(Validation) Loss: 737527.8876, MAE: 3178.4744, R2: 0.2499\n",
      "==========================================================================================\n",
      "Epoch [2203/5000] | Time: 0.23s\n",
      "(Training) Loss: 921927.0977\n",
      "(Validation) Loss: 737438.0070, MAE: 3178.1736, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [2204/5000] | Time: 0.26s\n",
      "(Training) Loss: 916325.4918\n",
      "(Validation) Loss: 737355.2184, MAE: 3179.3252, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [2205/5000] | Time: 0.24s\n",
      "(Training) Loss: 921230.0463\n",
      "(Validation) Loss: 737276.0527, MAE: 3180.9966, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [2206/5000] | Time: 0.25s\n",
      "(Training) Loss: 911635.6177\n",
      "(Validation) Loss: 737181.1619, MAE: 3180.4683, R2: 0.2503\n",
      "==========================================================================================\n",
      "Epoch [2207/5000] | Time: 0.24s\n",
      "(Training) Loss: 908995.4558\n",
      "(Validation) Loss: 737122.9759, MAE: 3188.4939, R2: 0.2503\n",
      "==========================================================================================\n",
      "Epoch [2208/5000] | Time: 0.23s\n",
      "(Training) Loss: 927075.3699\n",
      "(Validation) Loss: 737039.9854, MAE: 3184.6450, R2: 0.2504\n",
      "==========================================================================================\n",
      "Epoch [2209/5000] | Time: 0.26s\n",
      "(Training) Loss: 934006.3839\n",
      "(Validation) Loss: 738726.7911, MAE: 3186.6858, R2: 0.2487\n",
      "==========================================================================================\n",
      "Epoch [2210/5000] | Time: 0.25s\n",
      "(Training) Loss: 920276.2062\n",
      "(Validation) Loss: 738621.1587, MAE: 3185.3740, R2: 0.2488\n",
      "==========================================================================================\n",
      "Epoch [2211/5000] | Time: 0.26s\n",
      "(Training) Loss: 940111.6891\n",
      "(Validation) Loss: 738542.3517, MAE: 3188.8457, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [2212/5000] | Time: 0.28s\n",
      "(Training) Loss: 934883.1085\n",
      "(Validation) Loss: 738446.3727, MAE: 3187.6165, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [2213/5000] | Time: 0.27s\n",
      "(Training) Loss: 927311.9327\n",
      "(Validation) Loss: 738340.3035, MAE: 3186.6763, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [2214/5000] | Time: 0.24s\n",
      "(Training) Loss: 920358.8915\n",
      "(Validation) Loss: 738249.3606, MAE: 3186.1567, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [2215/5000] | Time: 0.25s\n",
      "(Training) Loss: 926129.3610\n",
      "(Validation) Loss: 738144.8997, MAE: 3184.3074, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [2216/5000] | Time: 0.24s\n",
      "(Training) Loss: 937217.5317\n",
      "(Validation) Loss: 738082.5219, MAE: 3185.8235, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [2217/5000] | Time: 0.25s\n",
      "(Training) Loss: 930554.2773\n",
      "(Validation) Loss: 737992.5079, MAE: 3185.7920, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [2218/5000] | Time: 0.23s\n",
      "(Training) Loss: 921690.2398\n",
      "(Validation) Loss: 737917.0844, MAE: 3187.1265, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [2219/5000] | Time: 0.26s\n",
      "(Training) Loss: 919623.2195\n",
      "(Validation) Loss: 737809.7321, MAE: 3186.0066, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [2220/5000] | Time: 0.24s\n",
      "(Training) Loss: 931076.5742\n",
      "(Validation) Loss: 737715.8432, MAE: 3185.0320, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [2221/5000] | Time: 0.25s\n",
      "(Training) Loss: 919171.3312\n",
      "(Validation) Loss: 737620.8990, MAE: 3185.1628, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [2222/5000] | Time: 0.24s\n",
      "(Training) Loss: 909210.4827\n",
      "(Validation) Loss: 737533.0565, MAE: 3184.8813, R2: 0.2499\n",
      "==========================================================================================\n",
      "Epoch [2223/5000] | Time: 0.24s\n",
      "(Training) Loss: 927846.4873\n",
      "(Validation) Loss: 737448.0590, MAE: 3186.4517, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [2224/5000] | Time: 0.25s\n",
      "(Training) Loss: 912604.4740\n",
      "(Validation) Loss: 737355.7797, MAE: 3185.4961, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [2225/5000] | Time: 0.28s\n",
      "(Training) Loss: 921693.6764\n",
      "(Validation) Loss: 737265.7010, MAE: 3184.5415, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [2226/5000] | Time: 0.24s\n",
      "(Training) Loss: 911260.1402\n",
      "(Validation) Loss: 737165.9575, MAE: 3183.6724, R2: 0.2503\n",
      "==========================================================================================\n",
      "Epoch [2227/5000] | Time: 0.29s\n",
      "(Training) Loss: 934277.5412\n",
      "(Validation) Loss: 737079.2768, MAE: 3184.3298, R2: 0.2504\n",
      "==========================================================================================\n",
      "Epoch [2228/5000] | Time: 0.30s\n",
      "(Training) Loss: 930719.1827\n",
      "(Validation) Loss: 736986.2152, MAE: 3184.6826, R2: 0.2505\n",
      "==========================================================================================\n",
      "Epoch [2229/5000] | Time: 0.24s\n",
      "(Training) Loss: 911954.0273\n",
      "(Validation) Loss: 736898.9886, MAE: 3184.5833, R2: 0.2506\n",
      "==========================================================================================\n",
      "Epoch [2230/5000] | Time: 0.24s\n",
      "(Training) Loss: 926048.8712\n",
      "(Validation) Loss: 736802.0914, MAE: 3183.2957, R2: 0.2507\n",
      "==========================================================================================\n",
      "Epoch [2231/5000] | Time: 0.25s\n",
      "(Training) Loss: 922405.4340\n",
      "(Validation) Loss: 736716.9549, MAE: 3182.8394, R2: 0.2508\n",
      "==========================================================================================\n",
      "Epoch [2232/5000] | Time: 0.25s\n",
      "(Training) Loss: 908573.6071\n",
      "(Validation) Loss: 736622.2489, MAE: 3183.5222, R2: 0.2509\n",
      "==========================================================================================\n",
      "Epoch [2233/5000] | Time: 0.26s\n",
      "(Training) Loss: 928786.7126\n",
      "(Validation) Loss: 736532.3098, MAE: 3182.9373, R2: 0.2509\n",
      "==========================================================================================\n",
      "Epoch [2234/5000] | Time: 0.26s\n",
      "(Training) Loss: 912754.7088\n",
      "(Validation) Loss: 736438.0095, MAE: 3182.8967, R2: 0.2510\n",
      "==========================================================================================\n",
      "Epoch [2235/5000] | Time: 0.24s\n",
      "(Training) Loss: 912883.7329\n",
      "(Validation) Loss: 736342.6711, MAE: 3180.9817, R2: 0.2511\n",
      "==========================================================================================\n",
      "Epoch [2236/5000] | Time: 0.24s\n",
      "(Training) Loss: 919331.9150\n",
      "(Validation) Loss: 723723.8648, MAE: 3158.6714, R2: 0.2639\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2237/5000] | Time: 0.27s\n",
      "(Training) Loss: 911393.1028\n",
      "(Validation) Loss: 723605.7403, MAE: 3152.0371, R2: 0.2640\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2238/5000] | Time: 0.28s\n",
      "(Training) Loss: 893553.9401\n",
      "(Validation) Loss: 723534.1384, MAE: 3152.8127, R2: 0.2641\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2239/5000] | Time: 0.25s\n",
      "(Training) Loss: 893566.6933\n",
      "(Validation) Loss: 723427.5079, MAE: 3150.2117, R2: 0.2642\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2240/5000] | Time: 0.24s\n",
      "(Training) Loss: 907598.3223\n",
      "(Validation) Loss: 723364.8533, MAE: 3151.2102, R2: 0.2642\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2241/5000] | Time: 0.28s\n",
      "(Training) Loss: 919228.4708\n",
      "(Validation) Loss: 723273.2914, MAE: 3152.4490, R2: 0.2643\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2242/5000] | Time: 0.26s\n",
      "(Training) Loss: 899935.5165\n",
      "(Validation) Loss: 723163.6629, MAE: 3147.3142, R2: 0.2644\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2243/5000] | Time: 0.25s\n",
      "(Training) Loss: 906207.0679\n",
      "(Validation) Loss: 723072.2000, MAE: 3147.6584, R2: 0.2645\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2244/5000] | Time: 0.25s\n",
      "(Training) Loss: 906420.0152\n",
      "(Validation) Loss: 723002.7194, MAE: 3151.6133, R2: 0.2646\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2245/5000] | Time: 0.26s\n",
      "(Training) Loss: 916459.6523\n",
      "(Validation) Loss: 722905.4025, MAE: 3146.5552, R2: 0.2647\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2246/5000] | Time: 0.24s\n",
      "(Training) Loss: 893528.1818\n",
      "(Validation) Loss: 722812.0203, MAE: 3147.9153, R2: 0.2648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2247/5000] | Time: 0.25s\n",
      "(Training) Loss: 923892.3192\n",
      "(Validation) Loss: 722751.8527, MAE: 3149.8184, R2: 0.2648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2248/5000] | Time: 0.24s\n",
      "(Training) Loss: 899680.4740\n",
      "(Validation) Loss: 722640.2083, MAE: 3144.1917, R2: 0.2650\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2249/5000] | Time: 0.26s\n",
      "(Training) Loss: 905137.3420\n",
      "(Validation) Loss: 722552.1975, MAE: 3146.8882, R2: 0.2650\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2250/5000] | Time: 0.24s\n",
      "(Training) Loss: 910618.9879\n",
      "(Validation) Loss: 722476.1435, MAE: 3149.5398, R2: 0.2651\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2251/5000] | Time: 0.24s\n",
      "(Training) Loss: 894749.5317\n",
      "(Validation) Loss: 722394.5695, MAE: 3147.8582, R2: 0.2652\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2252/5000] | Time: 0.28s\n",
      "(Training) Loss: 906341.3934\n",
      "(Validation) Loss: 722304.3390, MAE: 3145.2122, R2: 0.2653\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2253/5000] | Time: 0.25s\n",
      "(Training) Loss: 899533.5105\n",
      "(Validation) Loss: 722223.8787, MAE: 3145.1482, R2: 0.2654\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2254/5000] | Time: 0.25s\n",
      "(Training) Loss: 891887.3485\n",
      "(Validation) Loss: 722137.1289, MAE: 3144.5732, R2: 0.2655\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2255/5000] | Time: 0.23s\n",
      "(Training) Loss: 904086.9416\n",
      "(Validation) Loss: 722050.9041, MAE: 3148.4399, R2: 0.2655\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2256/5000] | Time: 0.24s\n",
      "(Training) Loss: 896899.5438\n",
      "(Validation) Loss: 721965.3556, MAE: 3144.0911, R2: 0.2656\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2257/5000] | Time: 0.24s\n",
      "(Training) Loss: 900250.3445\n",
      "(Validation) Loss: 721895.6400, MAE: 3146.6436, R2: 0.2657\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2258/5000] | Time: 0.24s\n",
      "(Training) Loss: 901186.4181\n",
      "(Validation) Loss: 721790.2876, MAE: 3144.1628, R2: 0.2658\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2259/5000] | Time: 0.23s\n",
      "(Training) Loss: 896668.0964\n",
      "(Validation) Loss: 721699.0292, MAE: 3142.5115, R2: 0.2659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2260/5000] | Time: 0.23s\n",
      "(Training) Loss: 911077.3712\n",
      "(Validation) Loss: 721612.6089, MAE: 3144.1614, R2: 0.2660\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2261/5000] | Time: 0.24s\n",
      "(Training) Loss: 901887.3160\n",
      "(Validation) Loss: 721525.7200, MAE: 3144.3962, R2: 0.2661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2262/5000] | Time: 0.24s\n",
      "(Training) Loss: 894492.4905\n",
      "(Validation) Loss: 721435.9676, MAE: 3142.8347, R2: 0.2662\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2263/5000] | Time: 0.23s\n",
      "(Training) Loss: 901238.8947\n",
      "(Validation) Loss: 721361.6114, MAE: 3145.0867, R2: 0.2662\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2264/5000] | Time: 0.26s\n",
      "(Training) Loss: 901236.2284\n",
      "(Validation) Loss: 721270.4311, MAE: 3142.9607, R2: 0.2663\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2265/5000] | Time: 0.25s\n",
      "(Training) Loss: 891659.9551\n",
      "(Validation) Loss: 721176.5441, MAE: 3143.0974, R2: 0.2664\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2266/5000] | Time: 0.27s\n",
      "(Training) Loss: 899476.6846\n",
      "(Validation) Loss: 721089.6508, MAE: 3141.6418, R2: 0.2665\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2267/5000] | Time: 0.25s\n",
      "(Training) Loss: 901545.9258\n",
      "(Validation) Loss: 721000.4114, MAE: 3140.8823, R2: 0.2666\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2268/5000] | Time: 0.26s\n",
      "(Training) Loss: 906458.4251\n",
      "(Validation) Loss: 720911.2368, MAE: 3140.6926, R2: 0.2667\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2269/5000] | Time: 0.37s\n",
      "(Training) Loss: 891926.4191\n",
      "(Validation) Loss: 720830.7657, MAE: 3143.8088, R2: 0.2668\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2270/5000] | Time: 0.27s\n",
      "(Training) Loss: 897320.1796\n",
      "(Validation) Loss: 720740.1314, MAE: 3141.5200, R2: 0.2669\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2271/5000] | Time: 0.26s\n",
      "(Training) Loss: 922023.8782\n",
      "(Validation) Loss: 720660.9956, MAE: 3143.0212, R2: 0.2669\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2272/5000] | Time: 0.28s\n",
      "(Training) Loss: 895468.3033\n",
      "(Validation) Loss: 720589.6933, MAE: 3143.7227, R2: 0.2670\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2273/5000] | Time: 0.27s\n",
      "(Training) Loss: 894999.4213\n",
      "(Validation) Loss: 720492.2375, MAE: 3141.8672, R2: 0.2671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2274/5000] | Time: 0.31s\n",
      "(Training) Loss: 890676.5173\n",
      "(Validation) Loss: 720403.1537, MAE: 3143.2578, R2: 0.2672\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2275/5000] | Time: 0.30s\n",
      "(Training) Loss: 908880.0013\n",
      "(Validation) Loss: 720315.3206, MAE: 3144.2107, R2: 0.2673\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2276/5000] | Time: 0.25s\n",
      "(Training) Loss: 897782.7900\n",
      "(Validation) Loss: 720217.5543, MAE: 3141.3879, R2: 0.2674\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2277/5000] | Time: 0.27s\n",
      "(Training) Loss: 906650.4816\n",
      "(Validation) Loss: 720125.5854, MAE: 3138.6711, R2: 0.2675\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2278/5000] | Time: 0.24s\n",
      "(Training) Loss: 906800.6923\n",
      "(Validation) Loss: 720041.6419, MAE: 3139.8352, R2: 0.2676\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2279/5000] | Time: 0.24s\n",
      "(Training) Loss: 904501.4117\n",
      "(Validation) Loss: 719960.2432, MAE: 3142.2253, R2: 0.2677\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2280/5000] | Time: 0.23s\n",
      "(Training) Loss: 920658.5952\n",
      "(Validation) Loss: 719877.5321, MAE: 3143.2463, R2: 0.2677\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2281/5000] | Time: 0.25s\n",
      "(Training) Loss: 893063.5933\n",
      "(Validation) Loss: 719802.9962, MAE: 3142.7512, R2: 0.2678\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2282/5000] | Time: 0.25s\n",
      "(Training) Loss: 903671.0489\n",
      "(Validation) Loss: 719696.5479, MAE: 3140.3838, R2: 0.2679\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2283/5000] | Time: 0.27s\n",
      "(Training) Loss: 897076.1688\n",
      "(Validation) Loss: 719604.3067, MAE: 3139.5393, R2: 0.2680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2284/5000] | Time: 0.24s\n",
      "(Training) Loss: 904322.2103\n",
      "(Validation) Loss: 719517.1505, MAE: 3138.5642, R2: 0.2681\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2285/5000] | Time: 0.26s\n",
      "(Training) Loss: 890088.9775\n",
      "(Validation) Loss: 719433.2870, MAE: 3140.7837, R2: 0.2682\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2286/5000] | Time: 0.27s\n",
      "(Training) Loss: 900688.4638\n",
      "(Validation) Loss: 719357.4590, MAE: 3140.7632, R2: 0.2683\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2287/5000] | Time: 0.28s\n",
      "(Training) Loss: 901947.8959\n",
      "(Validation) Loss: 719281.9111, MAE: 3141.6292, R2: 0.2683\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2288/5000] | Time: 0.26s\n",
      "(Training) Loss: 908692.6574\n",
      "(Validation) Loss: 719103.5898, MAE: 3131.9980, R2: 0.2685\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2289/5000] | Time: 0.28s\n",
      "(Training) Loss: 905420.7836\n",
      "(Validation) Loss: 719044.3435, MAE: 3138.0496, R2: 0.2686\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2290/5000] | Time: 0.31s\n",
      "(Training) Loss: 892968.4207\n",
      "(Validation) Loss: 718935.3549, MAE: 3130.5483, R2: 0.2687\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2291/5000] | Time: 0.30s\n",
      "(Training) Loss: 888213.4082\n",
      "(Validation) Loss: 718930.5079, MAE: 3141.8413, R2: 0.2687\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2292/5000] | Time: 0.27s\n",
      "(Training) Loss: 893933.2652\n",
      "(Validation) Loss: 718843.9511, MAE: 3140.1028, R2: 0.2688\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2293/5000] | Time: 0.27s\n",
      "(Training) Loss: 898392.1361\n",
      "(Validation) Loss: 718736.1054, MAE: 3136.7529, R2: 0.2689\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2294/5000] | Time: 0.27s\n",
      "(Training) Loss: 896216.3775\n",
      "(Validation) Loss: 718675.5695, MAE: 3140.4016, R2: 0.2690\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2295/5000] | Time: 0.27s\n",
      "(Training) Loss: 889341.7779\n",
      "(Validation) Loss: 718574.9244, MAE: 3139.8701, R2: 0.2691\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2296/5000] | Time: 0.25s\n",
      "(Training) Loss: 900815.7138\n",
      "(Validation) Loss: 718483.9956, MAE: 3137.0410, R2: 0.2691\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2297/5000] | Time: 0.28s\n",
      "(Training) Loss: 897341.0457\n",
      "(Validation) Loss: 718408.1162, MAE: 3140.0271, R2: 0.2692\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2298/5000] | Time: 0.26s\n",
      "(Training) Loss: 900814.7849\n",
      "(Validation) Loss: 718331.6178, MAE: 3138.6509, R2: 0.2693\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2299/5000] | Time: 0.24s\n",
      "(Training) Loss: 895743.8122\n",
      "(Validation) Loss: 718238.3162, MAE: 3139.0349, R2: 0.2694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2300/5000] | Time: 0.24s\n",
      "(Training) Loss: 903625.7341\n",
      "(Validation) Loss: 718131.0425, MAE: 3135.3577, R2: 0.2695\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2301/5000] | Time: 0.24s\n",
      "(Training) Loss: 900318.6713\n",
      "(Validation) Loss: 718220.5867, MAE: 3146.4917, R2: 0.2694\n",
      "==========================================================================================\n",
      "Epoch [2302/5000] | Time: 0.23s\n",
      "(Training) Loss: 902145.5032\n",
      "(Validation) Loss: 718128.9079, MAE: 3145.2898, R2: 0.2695\n",
      "==========================================================================================\n",
      "Epoch [2303/5000] | Time: 0.25s\n",
      "(Training) Loss: 896634.4162\n",
      "(Validation) Loss: 718049.8057, MAE: 3148.8030, R2: 0.2696\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2304/5000] | Time: 0.23s\n",
      "(Training) Loss: 904721.1656\n",
      "(Validation) Loss: 717961.8006, MAE: 3148.0874, R2: 0.2697\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2305/5000] | Time: 0.25s\n",
      "(Training) Loss: 894289.3801\n",
      "(Validation) Loss: 714424.7727, MAE: 3138.0469, R2: 0.2732\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2306/5000] | Time: 0.30s\n",
      "(Training) Loss: 885691.9746\n",
      "(Validation) Loss: 714351.9898, MAE: 3137.9907, R2: 0.2733\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2307/5000] | Time: 0.24s\n",
      "(Training) Loss: 888875.0774\n",
      "(Validation) Loss: 714259.7219, MAE: 3134.9055, R2: 0.2734\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2308/5000] | Time: 0.24s\n",
      "(Training) Loss: 901506.4365\n",
      "(Validation) Loss: 714171.6705, MAE: 3132.9802, R2: 0.2735\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2309/5000] | Time: 0.26s\n",
      "(Training) Loss: 894358.3414\n",
      "(Validation) Loss: 714086.3549, MAE: 3132.7456, R2: 0.2736\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2310/5000] | Time: 0.26s\n",
      "(Training) Loss: 882962.0317\n",
      "(Validation) Loss: 713971.7390, MAE: 3132.8228, R2: 0.2737\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2311/5000] | Time: 0.31s\n",
      "(Training) Loss: 881828.2416\n",
      "(Validation) Loss: 713884.1860, MAE: 3131.3640, R2: 0.2738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2312/5000] | Time: 0.27s\n",
      "(Training) Loss: 893133.6510\n",
      "(Validation) Loss: 713796.4298, MAE: 3130.2368, R2: 0.2739\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2313/5000] | Time: 0.26s\n",
      "(Training) Loss: 911956.7766\n",
      "(Validation) Loss: 713707.1886, MAE: 3130.1277, R2: 0.2740\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2314/5000] | Time: 0.23s\n",
      "(Training) Loss: 882151.2120\n",
      "(Validation) Loss: 713615.5359, MAE: 3126.8582, R2: 0.2741\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2315/5000] | Time: 0.27s\n",
      "(Training) Loss: 905617.4772\n",
      "(Validation) Loss: 713535.6140, MAE: 3129.0254, R2: 0.2741\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2316/5000] | Time: 0.26s\n",
      "(Training) Loss: 909361.9575\n",
      "(Validation) Loss: 713460.4133, MAE: 3130.7410, R2: 0.2742\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2317/5000] | Time: 0.27s\n",
      "(Training) Loss: 899936.9651\n",
      "(Validation) Loss: 713377.3778, MAE: 3129.9866, R2: 0.2743\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2318/5000] | Time: 0.28s\n",
      "(Training) Loss: 892756.2525\n",
      "(Validation) Loss: 713306.3117, MAE: 3133.5149, R2: 0.2744\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2319/5000] | Time: 0.24s\n",
      "(Training) Loss: 894227.1748\n",
      "(Validation) Loss: 713201.8083, MAE: 3129.4089, R2: 0.2745\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2320/5000] | Time: 0.24s\n",
      "(Training) Loss: 916362.9873\n",
      "(Validation) Loss: 713116.6260, MAE: 3130.4990, R2: 0.2746\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2321/5000] | Time: 0.26s\n",
      "(Training) Loss: 893189.6872\n",
      "(Validation) Loss: 713030.2800, MAE: 3129.6565, R2: 0.2746\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2322/5000] | Time: 0.24s\n",
      "(Training) Loss: 883845.5546\n",
      "(Validation) Loss: 712948.2889, MAE: 3128.3542, R2: 0.2747\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2323/5000] | Time: 0.26s\n",
      "(Training) Loss: 881649.1973\n",
      "(Validation) Loss: 712861.6387, MAE: 3129.6921, R2: 0.2748\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2324/5000] | Time: 0.25s\n",
      "(Training) Loss: 922060.1574\n",
      "(Validation) Loss: 712778.5111, MAE: 3127.3252, R2: 0.2749\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2325/5000] | Time: 0.29s\n",
      "(Training) Loss: 890906.6396\n",
      "(Validation) Loss: 712689.5784, MAE: 3127.0432, R2: 0.2750\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2326/5000] | Time: 0.24s\n",
      "(Training) Loss: 884126.8122\n",
      "(Validation) Loss: 712611.7410, MAE: 3128.2012, R2: 0.2751\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2327/5000] | Time: 0.26s\n",
      "(Training) Loss: 888177.7640\n",
      "(Validation) Loss: 712527.3632, MAE: 3127.5676, R2: 0.2752\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2328/5000] | Time: 0.27s\n",
      "(Training) Loss: 890986.8382\n",
      "(Validation) Loss: 712442.6019, MAE: 3127.7949, R2: 0.2752\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2329/5000] | Time: 0.25s\n",
      "(Training) Loss: 894267.0501\n",
      "(Validation) Loss: 712358.9206, MAE: 3126.0784, R2: 0.2753\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2330/5000] | Time: 0.31s\n",
      "(Training) Loss: 890246.6440\n",
      "(Validation) Loss: 708537.8165, MAE: 3120.0178, R2: 0.2792\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2331/5000] | Time: 0.29s\n",
      "(Training) Loss: 876627.6702\n",
      "(Validation) Loss: 708460.7606, MAE: 3120.6672, R2: 0.2793\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2332/5000] | Time: 0.30s\n",
      "(Training) Loss: 887468.7766\n",
      "(Validation) Loss: 708357.0324, MAE: 3114.7568, R2: 0.2794\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2333/5000] | Time: 0.30s\n",
      "(Training) Loss: 883763.3985\n",
      "(Validation) Loss: 708290.2679, MAE: 3115.2983, R2: 0.2794\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2334/5000] | Time: 0.28s\n",
      "(Training) Loss: 876347.1306\n",
      "(Validation) Loss: 708185.9727, MAE: 3111.6797, R2: 0.2795\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2335/5000] | Time: 0.29s\n",
      "(Training) Loss: 881270.5964\n",
      "(Validation) Loss: 708103.0667, MAE: 3110.8474, R2: 0.2796\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2336/5000] | Time: 0.32s\n",
      "(Training) Loss: 893174.5232\n",
      "(Validation) Loss: 708012.9073, MAE: 3106.7937, R2: 0.2797\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2337/5000] | Time: 0.31s\n",
      "(Training) Loss: 887521.2297\n",
      "(Validation) Loss: 707937.5879, MAE: 3110.3538, R2: 0.2798\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2338/5000] | Time: 0.34s\n",
      "(Training) Loss: 892421.9708\n",
      "(Validation) Loss: 707861.5149, MAE: 3112.4949, R2: 0.2799\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2339/5000] | Time: 0.30s\n",
      "(Training) Loss: 893205.9683\n",
      "(Validation) Loss: 707764.1187, MAE: 3108.1013, R2: 0.2800\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2340/5000] | Time: 0.27s\n",
      "(Training) Loss: 881876.8528\n",
      "(Validation) Loss: 707680.1283, MAE: 3108.6851, R2: 0.2800\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2341/5000] | Time: 0.28s\n",
      "(Training) Loss: 878463.3331\n",
      "(Validation) Loss: 707610.2825, MAE: 3115.6672, R2: 0.2801\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2342/5000] | Time: 0.28s\n",
      "(Training) Loss: 910726.3014\n",
      "(Validation) Loss: 707511.2971, MAE: 3107.0107, R2: 0.2802\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2343/5000] | Time: 0.31s\n",
      "(Training) Loss: 887520.5711\n",
      "(Validation) Loss: 707437.2565, MAE: 3108.7715, R2: 0.2803\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2344/5000] | Time: 0.29s\n",
      "(Training) Loss: 888946.5368\n",
      "(Validation) Loss: 707350.8102, MAE: 3109.5552, R2: 0.2804\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2345/5000] | Time: 0.27s\n",
      "(Training) Loss: 880733.9848\n",
      "(Validation) Loss: 707254.7752, MAE: 3104.6025, R2: 0.2805\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2346/5000] | Time: 0.31s\n",
      "(Training) Loss: 909513.9772\n",
      "(Validation) Loss: 707172.9003, MAE: 3104.7302, R2: 0.2806\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2347/5000] | Time: 0.26s\n",
      "(Training) Loss: 889274.0006\n",
      "(Validation) Loss: 707094.1232, MAE: 3107.6746, R2: 0.2806\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2348/5000] | Time: 0.27s\n",
      "(Training) Loss: 876217.5774\n",
      "(Validation) Loss: 707007.5619, MAE: 3105.3164, R2: 0.2807\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2349/5000] | Time: 0.26s\n",
      "(Training) Loss: 910891.2805\n",
      "(Validation) Loss: 706940.6508, MAE: 3112.7590, R2: 0.2808\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2350/5000] | Time: 0.29s\n",
      "(Training) Loss: 878220.1662\n",
      "(Validation) Loss: 706845.6546, MAE: 3107.9880, R2: 0.2809\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2351/5000] | Time: 0.29s\n",
      "(Training) Loss: 890893.2963\n",
      "(Validation) Loss: 706764.2565, MAE: 3104.6819, R2: 0.2810\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2352/5000] | Time: 0.32s\n",
      "(Training) Loss: 877972.8236\n",
      "(Validation) Loss: 706675.4737, MAE: 3103.8428, R2: 0.2811\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2353/5000] | Time: 0.30s\n",
      "(Training) Loss: 901371.8528\n",
      "(Validation) Loss: 706590.5257, MAE: 3103.9231, R2: 0.2811\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2354/5000] | Time: 0.29s\n",
      "(Training) Loss: 891236.5114\n",
      "(Validation) Loss: 706503.1638, MAE: 3101.6050, R2: 0.2812\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2355/5000] | Time: 0.32s\n",
      "(Training) Loss: 897647.0292\n",
      "(Validation) Loss: 706423.5505, MAE: 3103.5654, R2: 0.2813\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2356/5000] | Time: 0.26s\n",
      "(Training) Loss: 879961.1256\n",
      "(Validation) Loss: 706347.8648, MAE: 3105.7378, R2: 0.2814\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2357/5000] | Time: 0.29s\n",
      "(Training) Loss: 875361.4889\n",
      "(Validation) Loss: 706255.0083, MAE: 3101.0613, R2: 0.2815\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2358/5000] | Time: 0.33s\n",
      "(Training) Loss: 886279.5076\n",
      "(Validation) Loss: 706176.5797, MAE: 3103.8086, R2: 0.2816\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2359/5000] | Time: 0.28s\n",
      "(Training) Loss: 883021.7379\n",
      "(Validation) Loss: 705996.5568, MAE: 3096.6604, R2: 0.2817\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2360/5000] | Time: 0.33s\n",
      "(Training) Loss: 885309.7665\n",
      "(Validation) Loss: 705901.9556, MAE: 3093.1758, R2: 0.2818\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2361/5000] | Time: 0.30s\n",
      "(Training) Loss: 883299.6910\n",
      "(Validation) Loss: 705843.7390, MAE: 3096.6836, R2: 0.2819\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2362/5000] | Time: 0.28s\n",
      "(Training) Loss: 889907.8947\n",
      "(Validation) Loss: 705897.3244, MAE: 3106.0842, R2: 0.2818\n",
      "==========================================================================================\n",
      "Epoch [2363/5000] | Time: 0.28s\n",
      "(Training) Loss: 880235.1428\n",
      "(Validation) Loss: 705836.3010, MAE: 3111.5928, R2: 0.2819\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2364/5000] | Time: 0.29s\n",
      "(Training) Loss: 890621.3008\n",
      "(Validation) Loss: 705728.5702, MAE: 3104.1213, R2: 0.2820\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2365/5000] | Time: 0.28s\n",
      "(Training) Loss: 883657.4378\n",
      "(Validation) Loss: 705645.9803, MAE: 3105.6355, R2: 0.2821\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2366/5000] | Time: 0.32s\n",
      "(Training) Loss: 893514.6402\n",
      "(Validation) Loss: 705575.3168, MAE: 3108.1304, R2: 0.2822\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2367/5000] | Time: 0.32s\n",
      "(Training) Loss: 882842.6085\n",
      "(Validation) Loss: 705478.5765, MAE: 3103.8894, R2: 0.2823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2368/5000] | Time: 0.28s\n",
      "(Training) Loss: 876560.0831\n",
      "(Validation) Loss: 705400.2552, MAE: 3105.1101, R2: 0.2823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2369/5000] | Time: 0.29s\n",
      "(Training) Loss: 888834.5095\n",
      "(Validation) Loss: 705310.9422, MAE: 3102.6953, R2: 0.2824\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2370/5000] | Time: 0.28s\n",
      "(Training) Loss: 886540.7678\n",
      "(Validation) Loss: 705227.4089, MAE: 3102.9504, R2: 0.2825\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2371/5000] | Time: 0.30s\n",
      "(Training) Loss: 886017.8382\n",
      "(Validation) Loss: 705164.8254, MAE: 3108.5256, R2: 0.2826\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2372/5000] | Time: 0.26s\n",
      "(Training) Loss: 888203.6440\n",
      "(Validation) Loss: 705059.5797, MAE: 3102.5447, R2: 0.2827\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2373/5000] | Time: 0.27s\n",
      "(Training) Loss: 873905.4772\n",
      "(Validation) Loss: 704984.2076, MAE: 3102.2092, R2: 0.2828\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2374/5000] | Time: 0.23s\n",
      "(Training) Loss: 874010.5774\n",
      "(Validation) Loss: 704913.7022, MAE: 3105.2512, R2: 0.2828\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2375/5000] | Time: 0.27s\n",
      "(Training) Loss: 894917.7398\n",
      "(Validation) Loss: 704806.3663, MAE: 3099.3506, R2: 0.2829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2376/5000] | Time: 0.25s\n",
      "(Training) Loss: 904530.1225\n",
      "(Validation) Loss: 704725.2222, MAE: 3098.1016, R2: 0.2830\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2377/5000] | Time: 0.27s\n",
      "(Training) Loss: 877511.1085\n",
      "(Validation) Loss: 704640.1651, MAE: 3098.7190, R2: 0.2831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2378/5000] | Time: 0.31s\n",
      "(Training) Loss: 880234.3179\n",
      "(Validation) Loss: 704561.3308, MAE: 3100.4729, R2: 0.2832\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2379/5000] | Time: 0.29s\n",
      "(Training) Loss: 884138.6009\n",
      "(Validation) Loss: 704491.6648, MAE: 3103.3638, R2: 0.2833\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2380/5000] | Time: 0.27s\n",
      "(Training) Loss: 895806.3553\n",
      "(Validation) Loss: 704354.9613, MAE: 3096.1462, R2: 0.2834\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2381/5000] | Time: 0.30s\n",
      "(Training) Loss: 880853.6409\n",
      "(Validation) Loss: 704280.3600, MAE: 3099.1663, R2: 0.2835\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2382/5000] | Time: 0.28s\n",
      "(Training) Loss: 900800.4353\n",
      "(Validation) Loss: 704182.8368, MAE: 3095.6753, R2: 0.2836\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2383/5000] | Time: 0.29s\n",
      "(Training) Loss: 890028.3004\n",
      "(Validation) Loss: 704108.8432, MAE: 3096.2400, R2: 0.2836\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2384/5000] | Time: 0.35s\n",
      "(Training) Loss: 875904.2430\n",
      "(Validation) Loss: 704016.8133, MAE: 3094.3628, R2: 0.2837\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2385/5000] | Time: 0.32s\n",
      "(Training) Loss: 883229.2941\n",
      "(Validation) Loss: 703943.8324, MAE: 3095.9460, R2: 0.2838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2386/5000] | Time: 0.32s\n",
      "(Training) Loss: 896636.7931\n",
      "(Validation) Loss: 703859.6076, MAE: 3095.9683, R2: 0.2839\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2387/5000] | Time: 0.31s\n",
      "(Training) Loss: 885280.8915\n",
      "(Validation) Loss: 703789.2705, MAE: 3097.9023, R2: 0.2840\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2388/5000] | Time: 0.36s\n",
      "(Training) Loss: 877265.1202\n",
      "(Validation) Loss: 703689.2451, MAE: 3093.9570, R2: 0.2841\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2389/5000] | Time: 0.31s\n",
      "(Training) Loss: 884664.9289\n",
      "(Validation) Loss: 712740.1467, MAE: 3116.3315, R2: 0.2749\n",
      "==========================================================================================\n",
      "Epoch [2390/5000] | Time: 0.30s\n",
      "(Training) Loss: 899487.5723\n",
      "(Validation) Loss: 703520.0502, MAE: 3093.0525, R2: 0.2842\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2391/5000] | Time: 0.31s\n",
      "(Training) Loss: 883542.4007\n",
      "(Validation) Loss: 703448.3746, MAE: 3094.9207, R2: 0.2843\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2392/5000] | Time: 0.27s\n",
      "(Training) Loss: 882636.9708\n",
      "(Validation) Loss: 703361.2146, MAE: 3095.7388, R2: 0.2844\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2393/5000] | Time: 0.29s\n",
      "(Training) Loss: 873160.8820\n",
      "(Validation) Loss: 703278.5314, MAE: 3094.2036, R2: 0.2845\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2394/5000] | Time: 0.30s\n",
      "(Training) Loss: 880687.2259\n",
      "(Validation) Loss: 703201.6095, MAE: 3096.0437, R2: 0.2846\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2395/5000] | Time: 0.29s\n",
      "(Training) Loss: 885657.2690\n",
      "(Validation) Loss: 703116.5232, MAE: 3094.3232, R2: 0.2847\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2396/5000] | Time: 0.26s\n",
      "(Training) Loss: 876417.9070\n",
      "(Validation) Loss: 703043.0641, MAE: 3097.7336, R2: 0.2847\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2397/5000] | Time: 0.27s\n",
      "(Training) Loss: 877463.2843\n",
      "(Validation) Loss: 702946.4908, MAE: 3093.3955, R2: 0.2848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2398/5000] | Time: 0.30s\n",
      "(Training) Loss: 873119.0349\n",
      "(Validation) Loss: 702862.2692, MAE: 3093.5051, R2: 0.2849\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2399/5000] | Time: 0.29s\n",
      "(Training) Loss: 884207.8426\n",
      "(Validation) Loss: 702780.4616, MAE: 3092.9158, R2: 0.2850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2400/5000] | Time: 0.29s\n",
      "(Training) Loss: 886994.4848\n",
      "(Validation) Loss: 702698.1010, MAE: 3093.8062, R2: 0.2851\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2401/5000] | Time: 0.29s\n",
      "(Training) Loss: 869783.7352\n",
      "(Validation) Loss: 702619.7346, MAE: 3093.3481, R2: 0.2852\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2402/5000] | Time: 0.30s\n",
      "(Training) Loss: 885406.5482\n",
      "(Validation) Loss: 702538.0914, MAE: 3093.2559, R2: 0.2852\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2403/5000] | Time: 0.27s\n",
      "(Training) Loss: 877971.1260\n",
      "(Validation) Loss: 702453.9537, MAE: 3091.8152, R2: 0.2853\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2404/5000] | Time: 0.29s\n",
      "(Training) Loss: 892388.9416\n",
      "(Validation) Loss: 702370.1568, MAE: 3091.9346, R2: 0.2854\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2405/5000] | Time: 0.28s\n",
      "(Training) Loss: 869651.0574\n",
      "(Validation) Loss: 702288.7365, MAE: 3092.0288, R2: 0.2855\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2406/5000] | Time: 0.27s\n",
      "(Training) Loss: 868718.2321\n",
      "(Validation) Loss: 702213.0902, MAE: 3092.7085, R2: 0.2856\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2407/5000] | Time: 0.34s\n",
      "(Training) Loss: 889974.6796\n",
      "(Validation) Loss: 702122.4603, MAE: 3090.6572, R2: 0.2857\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2408/5000] | Time: 0.30s\n",
      "(Training) Loss: 875304.3246\n",
      "(Validation) Loss: 702039.6883, MAE: 3091.0869, R2: 0.2857\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2409/5000] | Time: 0.29s\n",
      "(Training) Loss: 884020.5114\n",
      "(Validation) Loss: 701968.1898, MAE: 3092.5166, R2: 0.2858\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2410/5000] | Time: 0.31s\n",
      "(Training) Loss: 872128.3871\n",
      "(Validation) Loss: 701899.4102, MAE: 3095.0605, R2: 0.2859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2411/5000] | Time: 0.32s\n",
      "(Training) Loss: 871815.5349\n",
      "(Validation) Loss: 701793.5054, MAE: 3089.5938, R2: 0.2860\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2412/5000] | Time: 0.27s\n",
      "(Training) Loss: 875967.0095\n",
      "(Validation) Loss: 701714.0241, MAE: 3089.5452, R2: 0.2861\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2413/5000] | Time: 0.29s\n",
      "(Training) Loss: 868800.5162\n",
      "(Validation) Loss: 701638.4324, MAE: 3093.1086, R2: 0.2861\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2414/5000] | Time: 0.32s\n",
      "(Training) Loss: 881530.2053\n",
      "(Validation) Loss: 701551.6762, MAE: 3089.3228, R2: 0.2862\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2415/5000] | Time: 0.26s\n",
      "(Training) Loss: 881029.3490\n",
      "(Validation) Loss: 701479.9467, MAE: 3092.7678, R2: 0.2863\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2416/5000] | Time: 0.29s\n",
      "(Training) Loss: 878978.4638\n",
      "(Validation) Loss: 701397.2832, MAE: 3093.1436, R2: 0.2864\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2417/5000] | Time: 0.27s\n",
      "(Training) Loss: 885429.1967\n",
      "(Validation) Loss: 701301.7987, MAE: 3089.3179, R2: 0.2865\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2418/5000] | Time: 0.30s\n",
      "(Training) Loss: 882927.0184\n",
      "(Validation) Loss: 701224.3613, MAE: 3090.4292, R2: 0.2866\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2419/5000] | Time: 0.26s\n",
      "(Training) Loss: 891245.0552\n",
      "(Validation) Loss: 701136.2463, MAE: 3088.2131, R2: 0.2867\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2420/5000] | Time: 0.28s\n",
      "(Training) Loss: 880422.3344\n",
      "(Validation) Loss: 701062.8711, MAE: 3090.9104, R2: 0.2867\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2421/5000] | Time: 0.28s\n",
      "(Training) Loss: 873214.7576\n",
      "(Validation) Loss: 700970.1562, MAE: 3087.6350, R2: 0.2868\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2422/5000] | Time: 0.30s\n",
      "(Training) Loss: 873481.1688\n",
      "(Validation) Loss: 700890.5416, MAE: 3089.0190, R2: 0.2869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2423/5000] | Time: 0.28s\n",
      "(Training) Loss: 882766.9365\n",
      "(Validation) Loss: 700820.1613, MAE: 3090.0229, R2: 0.2870\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2424/5000] | Time: 0.29s\n",
      "(Training) Loss: 886732.6003\n",
      "(Validation) Loss: 700722.4775, MAE: 3086.0229, R2: 0.2871\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2425/5000] | Time: 0.28s\n",
      "(Training) Loss: 876535.8909\n",
      "(Validation) Loss: 700643.9778, MAE: 3086.9158, R2: 0.2871\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2426/5000] | Time: 0.30s\n",
      "(Training) Loss: 879999.3395\n",
      "(Validation) Loss: 700559.4235, MAE: 3087.2825, R2: 0.2872\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2427/5000] | Time: 0.31s\n",
      "(Training) Loss: 880732.5669\n",
      "(Validation) Loss: 700483.7054, MAE: 3090.0493, R2: 0.2873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2428/5000] | Time: 0.31s\n",
      "(Training) Loss: 875053.5600\n",
      "(Validation) Loss: 700490.6425, MAE: 3094.1626, R2: 0.2873\n",
      "==========================================================================================\n",
      "Epoch [2429/5000] | Time: 0.33s\n",
      "(Training) Loss: 867508.1754\n",
      "(Validation) Loss: 700406.4610, MAE: 3094.5818, R2: 0.2874\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2430/5000] | Time: 0.27s\n",
      "(Training) Loss: 866818.2719\n",
      "(Validation) Loss: 700325.1854, MAE: 3095.0698, R2: 0.2875\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2431/5000] | Time: 0.27s\n",
      "(Training) Loss: 873360.8173\n",
      "(Validation) Loss: 700240.5867, MAE: 3092.9409, R2: 0.2876\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2432/5000] | Time: 0.28s\n",
      "(Training) Loss: 876488.1320\n",
      "(Validation) Loss: 700163.3371, MAE: 3093.9055, R2: 0.2876\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2433/5000] | Time: 0.28s\n",
      "(Training) Loss: 884474.0635\n",
      "(Validation) Loss: 700078.7111, MAE: 3094.5317, R2: 0.2877\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2434/5000] | Time: 0.29s\n",
      "(Training) Loss: 904243.1745\n",
      "(Validation) Loss: 699894.7994, MAE: 3088.0605, R2: 0.2879\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2435/5000] | Time: 0.29s\n",
      "(Training) Loss: 898299.8560\n",
      "(Validation) Loss: 726132.8432, MAE: 3150.2869, R2: 0.2614\n",
      "==========================================================================================\n",
      "Epoch [2436/5000] | Time: 0.28s\n",
      "(Training) Loss: 913122.0228\n",
      "(Validation) Loss: 726043.3670, MAE: 3150.9778, R2: 0.2615\n",
      "==========================================================================================\n",
      "Epoch [2437/5000] | Time: 0.28s\n",
      "(Training) Loss: 919036.0216\n",
      "(Validation) Loss: 725951.1435, MAE: 3149.5696, R2: 0.2616\n",
      "==========================================================================================\n",
      "Epoch [2438/5000] | Time: 0.28s\n",
      "(Training) Loss: 906658.4746\n",
      "(Validation) Loss: 725864.1683, MAE: 3148.9026, R2: 0.2617\n",
      "==========================================================================================\n",
      "Epoch [2439/5000] | Time: 0.30s\n",
      "(Training) Loss: 905704.0222\n",
      "(Validation) Loss: 725785.4749, MAE: 3152.8657, R2: 0.2618\n",
      "==========================================================================================\n",
      "Epoch [2440/5000] | Time: 0.30s\n",
      "(Training) Loss: 910733.8813\n",
      "(Validation) Loss: 725699.4514, MAE: 3150.6660, R2: 0.2619\n",
      "==========================================================================================\n",
      "Epoch [2441/5000] | Time: 0.31s\n",
      "(Training) Loss: 906443.9277\n",
      "(Validation) Loss: 725592.4508, MAE: 3148.5325, R2: 0.2620\n",
      "==========================================================================================\n",
      "Epoch [2442/5000] | Time: 0.37s\n",
      "(Training) Loss: 899998.0070\n",
      "(Validation) Loss: 725519.6089, MAE: 3153.7012, R2: 0.2620\n",
      "==========================================================================================\n",
      "Epoch [2443/5000] | Time: 0.34s\n",
      "(Training) Loss: 907386.8223\n",
      "(Validation) Loss: 725416.8895, MAE: 3148.3655, R2: 0.2622\n",
      "==========================================================================================\n",
      "Epoch [2444/5000] | Time: 0.27s\n",
      "(Training) Loss: 908526.5603\n",
      "(Validation) Loss: 725331.3194, MAE: 3150.6680, R2: 0.2622\n",
      "==========================================================================================\n",
      "Epoch [2445/5000] | Time: 0.28s\n",
      "(Training) Loss: 904430.2602\n",
      "(Validation) Loss: 725245.8863, MAE: 3148.9238, R2: 0.2623\n",
      "==========================================================================================\n",
      "Epoch [2446/5000] | Time: 0.26s\n",
      "(Training) Loss: 909784.6929\n",
      "(Validation) Loss: 725166.8508, MAE: 3150.7600, R2: 0.2624\n",
      "==========================================================================================\n",
      "Epoch [2447/5000] | Time: 0.29s\n",
      "(Training) Loss: 910992.6193\n",
      "(Validation) Loss: 725094.5473, MAE: 3149.0715, R2: 0.2625\n",
      "==========================================================================================\n",
      "Epoch [2448/5000] | Time: 0.34s\n",
      "(Training) Loss: 907570.3154\n",
      "(Validation) Loss: 725002.9003, MAE: 3147.0623, R2: 0.2626\n",
      "==========================================================================================\n",
      "Epoch [2449/5000] | Time: 0.30s\n",
      "(Training) Loss: 899515.9841\n",
      "(Validation) Loss: 724936.6616, MAE: 3155.3713, R2: 0.2626\n",
      "==========================================================================================\n",
      "Epoch [2450/5000] | Time: 0.27s\n",
      "(Training) Loss: 907579.9569\n",
      "(Validation) Loss: 724830.9619, MAE: 3151.4438, R2: 0.2627\n",
      "==========================================================================================\n",
      "Epoch [2451/5000] | Time: 0.27s\n",
      "(Training) Loss: 896505.5853\n",
      "(Validation) Loss: 724763.7810, MAE: 3155.2822, R2: 0.2628\n",
      "==========================================================================================\n",
      "Epoch [2452/5000] | Time: 0.24s\n",
      "(Training) Loss: 897595.1907\n",
      "(Validation) Loss: 724666.7149, MAE: 3151.6533, R2: 0.2629\n",
      "==========================================================================================\n",
      "Epoch [2453/5000] | Time: 0.24s\n",
      "(Training) Loss: 897313.9232\n",
      "(Validation) Loss: 724561.6692, MAE: 3147.2983, R2: 0.2630\n",
      "==========================================================================================\n",
      "Epoch [2454/5000] | Time: 0.24s\n",
      "(Training) Loss: 908817.9676\n",
      "(Validation) Loss: 724482.9683, MAE: 3149.7314, R2: 0.2631\n",
      "==========================================================================================\n",
      "Epoch [2455/5000] | Time: 0.26s\n",
      "(Training) Loss: 908348.2024\n",
      "(Validation) Loss: 724394.7663, MAE: 3149.4045, R2: 0.2632\n",
      "==========================================================================================\n",
      "Epoch [2456/5000] | Time: 0.24s\n",
      "(Training) Loss: 903098.7843\n",
      "(Validation) Loss: 724298.3079, MAE: 3145.8152, R2: 0.2633\n",
      "==========================================================================================\n",
      "Epoch [2457/5000] | Time: 0.24s\n",
      "(Training) Loss: 914855.9860\n",
      "(Validation) Loss: 724212.4546, MAE: 3145.5637, R2: 0.2634\n",
      "==========================================================================================\n",
      "Epoch [2458/5000] | Time: 0.22s\n",
      "(Training) Loss: 898435.4048\n",
      "(Validation) Loss: 724132.2413, MAE: 3148.6160, R2: 0.2634\n",
      "==========================================================================================\n",
      "Epoch [2459/5000] | Time: 0.25s\n",
      "(Training) Loss: 900690.3769\n",
      "(Validation) Loss: 724039.6127, MAE: 3147.2566, R2: 0.2635\n",
      "==========================================================================================\n",
      "Epoch [2460/5000] | Time: 0.25s\n",
      "(Training) Loss: 906532.7069\n",
      "(Validation) Loss: 723965.8083, MAE: 3150.5410, R2: 0.2636\n",
      "==========================================================================================\n",
      "Epoch [2461/5000] | Time: 0.26s\n",
      "(Training) Loss: 932407.2621\n",
      "(Validation) Loss: 723865.7441, MAE: 3147.3047, R2: 0.2637\n",
      "==========================================================================================\n",
      "Epoch [2462/5000] | Time: 0.26s\n",
      "(Training) Loss: 907084.4968\n",
      "(Validation) Loss: 723771.5378, MAE: 3144.9285, R2: 0.2638\n",
      "==========================================================================================\n",
      "Epoch [2463/5000] | Time: 0.23s\n",
      "(Training) Loss: 899748.6168\n",
      "(Validation) Loss: 723700.5467, MAE: 3147.5632, R2: 0.2639\n",
      "==========================================================================================\n",
      "Epoch [2464/5000] | Time: 0.23s\n",
      "(Training) Loss: 902933.0003\n",
      "(Validation) Loss: 723597.5111, MAE: 3143.0442, R2: 0.2640\n",
      "==========================================================================================\n",
      "Epoch [2465/5000] | Time: 0.27s\n",
      "(Training) Loss: 895832.5831\n",
      "(Validation) Loss: 723511.9283, MAE: 3143.1216, R2: 0.2641\n",
      "==========================================================================================\n",
      "Epoch [2466/5000] | Time: 0.24s\n",
      "(Training) Loss: 903825.2786\n",
      "(Validation) Loss: 723427.4578, MAE: 3143.1587, R2: 0.2642\n",
      "==========================================================================================\n",
      "Epoch [2467/5000] | Time: 0.24s\n",
      "(Training) Loss: 899051.2633\n",
      "(Validation) Loss: 723347.7873, MAE: 3143.7473, R2: 0.2642\n",
      "==========================================================================================\n",
      "Epoch [2468/5000] | Time: 0.21s\n",
      "(Training) Loss: 902610.7316\n",
      "(Validation) Loss: 723258.1759, MAE: 3143.5537, R2: 0.2643\n",
      "==========================================================================================\n",
      "Epoch [2469/5000] | Time: 0.26s\n",
      "(Training) Loss: 908831.6313\n",
      "(Validation) Loss: 723174.7733, MAE: 3146.3320, R2: 0.2644\n",
      "==========================================================================================\n",
      "Epoch [2470/5000] | Time: 0.22s\n",
      "(Training) Loss: 904137.2056\n",
      "(Validation) Loss: 723089.4610, MAE: 3145.7529, R2: 0.2645\n",
      "==========================================================================================\n",
      "Epoch [2471/5000] | Time: 0.20s\n",
      "(Training) Loss: 913865.9860\n",
      "(Validation) Loss: 722991.7486, MAE: 3144.8032, R2: 0.2646\n",
      "==========================================================================================\n",
      "Epoch [2472/5000] | Time: 0.21s\n",
      "(Training) Loss: 906724.7855\n",
      "(Validation) Loss: 722913.1333, MAE: 3146.4753, R2: 0.2647\n",
      "==========================================================================================\n",
      "Epoch [2473/5000] | Time: 0.25s\n",
      "(Training) Loss: 901179.0178\n",
      "(Validation) Loss: 722825.1479, MAE: 3145.3799, R2: 0.2648\n",
      "==========================================================================================\n",
      "Epoch [2474/5000] | Time: 0.22s\n",
      "(Training) Loss: 897464.3858\n",
      "(Validation) Loss: 722744.5124, MAE: 3147.0793, R2: 0.2648\n",
      "==========================================================================================\n",
      "Epoch [2475/5000] | Time: 0.25s\n",
      "(Training) Loss: 907277.0863\n",
      "(Validation) Loss: 722650.7219, MAE: 3145.2412, R2: 0.2649\n",
      "==========================================================================================\n",
      "Epoch [2476/5000] | Time: 0.24s\n",
      "(Training) Loss: 917388.2341\n",
      "(Validation) Loss: 722572.1937, MAE: 3146.8887, R2: 0.2650\n",
      "==========================================================================================\n",
      "Epoch [2477/5000] | Time: 0.23s\n",
      "(Training) Loss: 903169.6180\n",
      "(Validation) Loss: 722477.6590, MAE: 3143.8445, R2: 0.2651\n",
      "==========================================================================================\n",
      "Epoch [2478/5000] | Time: 0.23s\n",
      "(Training) Loss: 902897.7227\n",
      "(Validation) Loss: 722386.4057, MAE: 3141.3215, R2: 0.2652\n",
      "==========================================================================================\n",
      "Epoch [2479/5000] | Time: 0.21s\n",
      "(Training) Loss: 909041.9188\n",
      "(Validation) Loss: 722307.7835, MAE: 3144.6753, R2: 0.2653\n",
      "==========================================================================================\n",
      "Epoch [2480/5000] | Time: 0.26s\n",
      "(Training) Loss: 918839.2386\n",
      "(Validation) Loss: 722218.6521, MAE: 3143.8042, R2: 0.2654\n",
      "==========================================================================================\n",
      "Epoch [2481/5000] | Time: 0.25s\n",
      "(Training) Loss: 899023.9816\n",
      "(Validation) Loss: 722132.7962, MAE: 3143.4824, R2: 0.2655\n",
      "==========================================================================================\n",
      "Epoch [2482/5000] | Time: 0.25s\n",
      "(Training) Loss: 909297.9461\n",
      "(Validation) Loss: 722056.5994, MAE: 3147.7893, R2: 0.2655\n",
      "==========================================================================================\n",
      "Epoch [2483/5000] | Time: 0.24s\n",
      "(Training) Loss: 897686.3071\n",
      "(Validation) Loss: 721972.6057, MAE: 3147.5701, R2: 0.2656\n",
      "==========================================================================================\n",
      "Epoch [2484/5000] | Time: 0.26s\n",
      "(Training) Loss: 903618.6669\n",
      "(Validation) Loss: 721873.8698, MAE: 3142.4260, R2: 0.2657\n",
      "==========================================================================================\n",
      "Epoch [2485/5000] | Time: 0.26s\n",
      "(Training) Loss: 900125.4239\n",
      "(Validation) Loss: 721790.1454, MAE: 3142.3828, R2: 0.2658\n",
      "==========================================================================================\n",
      "Epoch [2486/5000] | Time: 0.24s\n",
      "(Training) Loss: 892240.3683\n",
      "(Validation) Loss: 721748.4463, MAE: 3151.4167, R2: 0.2659\n",
      "==========================================================================================\n",
      "Epoch [2487/5000] | Time: 0.27s\n",
      "(Training) Loss: 898470.0552\n",
      "(Validation) Loss: 721618.5721, MAE: 3143.0952, R2: 0.2660\n",
      "==========================================================================================\n",
      "Epoch [2488/5000] | Time: 0.27s\n",
      "(Training) Loss: 909895.8763\n",
      "(Validation) Loss: 720372.5390, MAE: 3144.0913, R2: 0.2673\n",
      "==========================================================================================\n",
      "Epoch [2489/5000] | Time: 0.24s\n",
      "(Training) Loss: 887527.6910\n",
      "(Validation) Loss: 708998.0057, MAE: 3113.9092, R2: 0.2787\n",
      "==========================================================================================\n",
      "Epoch [2490/5000] | Time: 0.24s\n",
      "(Training) Loss: 882461.4968\n",
      "(Validation) Loss: 708894.4844, MAE: 3109.8608, R2: 0.2788\n",
      "==========================================================================================\n",
      "Epoch [2491/5000] | Time: 0.25s\n",
      "(Training) Loss: 896623.4832\n",
      "(Validation) Loss: 708802.0514, MAE: 3108.9031, R2: 0.2789\n",
      "==========================================================================================\n",
      "Epoch [2492/5000] | Time: 0.26s\n",
      "(Training) Loss: 891867.4886\n",
      "(Validation) Loss: 708726.4673, MAE: 3111.5356, R2: 0.2790\n",
      "==========================================================================================\n",
      "Epoch [2493/5000] | Time: 0.25s\n",
      "(Training) Loss: 892388.7437\n",
      "(Validation) Loss: 708651.1892, MAE: 3114.3003, R2: 0.2791\n",
      "==========================================================================================\n",
      "Epoch [2494/5000] | Time: 0.25s\n",
      "(Training) Loss: 880722.7522\n",
      "(Validation) Loss: 708550.4578, MAE: 3109.5930, R2: 0.2792\n",
      "==========================================================================================\n",
      "Epoch [2495/5000] | Time: 0.25s\n",
      "(Training) Loss: 888753.0451\n",
      "(Validation) Loss: 708461.6032, MAE: 3109.6423, R2: 0.2793\n",
      "==========================================================================================\n",
      "Epoch [2496/5000] | Time: 0.23s\n",
      "(Training) Loss: 875515.8712\n",
      "(Validation) Loss: 708390.1543, MAE: 3114.7012, R2: 0.2793\n",
      "==========================================================================================\n",
      "Epoch [2497/5000] | Time: 0.25s\n",
      "(Training) Loss: 882692.9220\n",
      "(Validation) Loss: 708283.4114, MAE: 3107.5149, R2: 0.2794\n",
      "==========================================================================================\n",
      "Epoch [2498/5000] | Time: 0.26s\n",
      "(Training) Loss: 880122.6885\n",
      "(Validation) Loss: 708576.8311, MAE: 3114.5747, R2: 0.2791\n",
      "==========================================================================================\n",
      "Epoch [2499/5000] | Time: 0.24s\n",
      "(Training) Loss: 907899.0181\n",
      "(Validation) Loss: 719547.6641, MAE: 3137.8337, R2: 0.2681\n",
      "==========================================================================================\n",
      "Epoch [2500/5000] | Time: 0.27s\n",
      "(Training) Loss: 898874.0025\n",
      "(Validation) Loss: 719510.1010, MAE: 3142.5645, R2: 0.2681\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch2500.pth\n",
      "==========================================================================================\n",
      "Epoch [2501/5000] | Time: 0.26s\n",
      "(Training) Loss: 893906.8001\n",
      "(Validation) Loss: 713092.0870, MAE: 3117.6731, R2: 0.2746\n",
      "==========================================================================================\n",
      "Epoch [2502/5000] | Time: 0.24s\n",
      "(Training) Loss: 884555.1345\n",
      "(Validation) Loss: 713012.9740, MAE: 3121.2068, R2: 0.2747\n",
      "==========================================================================================\n",
      "Epoch [2503/5000] | Time: 0.26s\n",
      "(Training) Loss: 884276.1345\n",
      "(Validation) Loss: 712909.6152, MAE: 3119.0444, R2: 0.2748\n",
      "==========================================================================================\n",
      "Epoch [2504/5000] | Time: 0.21s\n",
      "(Training) Loss: 887617.2989\n",
      "(Validation) Loss: 712816.2959, MAE: 3117.1589, R2: 0.2749\n",
      "==========================================================================================\n",
      "Epoch [2505/5000] | Time: 0.29s\n",
      "(Training) Loss: 890831.8731\n",
      "(Validation) Loss: 712735.5289, MAE: 3120.0410, R2: 0.2749\n",
      "==========================================================================================\n",
      "Epoch [2506/5000] | Time: 0.29s\n",
      "(Training) Loss: 892057.8871\n",
      "(Validation) Loss: 712637.3803, MAE: 3118.1177, R2: 0.2750\n",
      "==========================================================================================\n",
      "Epoch [2507/5000] | Time: 0.30s\n",
      "(Training) Loss: 883043.6329\n",
      "(Validation) Loss: 712550.0654, MAE: 3116.8284, R2: 0.2751\n",
      "==========================================================================================\n",
      "Epoch [2508/5000] | Time: 0.32s\n",
      "(Training) Loss: 920137.6701\n",
      "(Validation) Loss: 712461.9016, MAE: 3116.1194, R2: 0.2752\n",
      "==========================================================================================\n",
      "Epoch [2509/5000] | Time: 0.32s\n",
      "(Training) Loss: 894545.5755\n",
      "(Validation) Loss: 712386.0565, MAE: 3119.7893, R2: 0.2753\n",
      "==========================================================================================\n",
      "Epoch [2510/5000] | Time: 0.30s\n",
      "(Training) Loss: 882035.3537\n",
      "(Validation) Loss: 712294.3905, MAE: 3118.7368, R2: 0.2754\n",
      "==========================================================================================\n",
      "Epoch [2511/5000] | Time: 0.27s\n",
      "(Training) Loss: 894021.1536\n",
      "(Validation) Loss: 712200.8032, MAE: 3118.0261, R2: 0.2755\n",
      "==========================================================================================\n",
      "Epoch [2512/5000] | Time: 0.23s\n",
      "(Training) Loss: 889324.9264\n",
      "(Validation) Loss: 712115.4654, MAE: 3117.6128, R2: 0.2756\n",
      "==========================================================================================\n",
      "Epoch [2513/5000] | Time: 0.25s\n",
      "(Training) Loss: 886391.9810\n",
      "(Validation) Loss: 712019.8000, MAE: 3114.7632, R2: 0.2757\n",
      "==========================================================================================\n",
      "Epoch [2514/5000] | Time: 0.20s\n",
      "(Training) Loss: 900791.5647\n",
      "(Validation) Loss: 711935.1848, MAE: 3115.8125, R2: 0.2758\n",
      "==========================================================================================\n",
      "Epoch [2515/5000] | Time: 0.21s\n",
      "(Training) Loss: 887945.4778\n",
      "(Validation) Loss: 711852.5587, MAE: 3117.3799, R2: 0.2758\n",
      "==========================================================================================\n",
      "Epoch [2516/5000] | Time: 0.22s\n",
      "(Training) Loss: 898502.6980\n",
      "(Validation) Loss: 711806.1041, MAE: 3117.7534, R2: 0.2759\n",
      "==========================================================================================\n",
      "Epoch [2517/5000] | Time: 0.21s\n",
      "(Training) Loss: 897882.5121\n",
      "(Validation) Loss: 711674.5251, MAE: 3117.2729, R2: 0.2760\n",
      "==========================================================================================\n",
      "Epoch [2518/5000] | Time: 0.20s\n",
      "(Training) Loss: 895725.6225\n",
      "(Validation) Loss: 711583.4794, MAE: 3115.6018, R2: 0.2761\n",
      "==========================================================================================\n",
      "Epoch [2519/5000] | Time: 0.21s\n",
      "(Training) Loss: 901293.8141\n",
      "(Validation) Loss: 711501.9975, MAE: 3116.7068, R2: 0.2762\n",
      "==========================================================================================\n",
      "Epoch [2520/5000] | Time: 0.23s\n",
      "(Training) Loss: 893801.7779\n",
      "(Validation) Loss: 711416.0044, MAE: 3116.6541, R2: 0.2763\n",
      "==========================================================================================\n",
      "Epoch [2521/5000] | Time: 0.21s\n",
      "(Training) Loss: 900204.2462\n",
      "(Validation) Loss: 711327.4216, MAE: 3115.7703, R2: 0.2764\n",
      "==========================================================================================\n",
      "Epoch [2522/5000] | Time: 0.22s\n",
      "(Training) Loss: 891084.7906\n",
      "(Validation) Loss: 711253.8324, MAE: 3117.9607, R2: 0.2764\n",
      "==========================================================================================\n",
      "Epoch [2523/5000] | Time: 0.21s\n",
      "(Training) Loss: 899060.9918\n",
      "(Validation) Loss: 711145.0038, MAE: 3113.7876, R2: 0.2765\n",
      "==========================================================================================\n",
      "Epoch [2524/5000] | Time: 0.21s\n",
      "(Training) Loss: 888890.2500\n",
      "(Validation) Loss: 711062.8229, MAE: 3113.9810, R2: 0.2766\n",
      "==========================================================================================\n",
      "Epoch [2525/5000] | Time: 0.21s\n",
      "(Training) Loss: 884723.0260\n",
      "(Validation) Loss: 710981.8070, MAE: 3114.0896, R2: 0.2767\n",
      "==========================================================================================\n",
      "Epoch [2526/5000] | Time: 0.21s\n",
      "(Training) Loss: 890632.3223\n",
      "(Validation) Loss: 710896.2146, MAE: 3116.5627, R2: 0.2768\n",
      "==========================================================================================\n",
      "Epoch [2527/5000] | Time: 0.22s\n",
      "(Training) Loss: 887887.6745\n",
      "(Validation) Loss: 710844.7467, MAE: 3122.7419, R2: 0.2769\n",
      "==========================================================================================\n",
      "Epoch [2528/5000] | Time: 0.22s\n",
      "(Training) Loss: 878399.4740\n",
      "(Validation) Loss: 710718.8089, MAE: 3113.2747, R2: 0.2770\n",
      "==========================================================================================\n",
      "Epoch [2529/5000] | Time: 0.21s\n",
      "(Training) Loss: 901907.0999\n",
      "(Validation) Loss: 710630.6197, MAE: 3112.5134, R2: 0.2771\n",
      "==========================================================================================\n",
      "Epoch [2530/5000] | Time: 0.21s\n",
      "(Training) Loss: 915004.5152\n",
      "(Validation) Loss: 710545.9937, MAE: 3112.9377, R2: 0.2772\n",
      "==========================================================================================\n",
      "Epoch [2531/5000] | Time: 0.23s\n",
      "(Training) Loss: 895591.9956\n",
      "(Validation) Loss: 710464.4679, MAE: 3115.3730, R2: 0.2772\n",
      "==========================================================================================\n",
      "Epoch [2532/5000] | Time: 0.25s\n",
      "(Training) Loss: 898263.9873\n",
      "(Validation) Loss: 710365.6711, MAE: 3110.8953, R2: 0.2773\n",
      "==========================================================================================\n",
      "Epoch [2533/5000] | Time: 0.22s\n",
      "(Training) Loss: 885568.8280\n",
      "(Validation) Loss: 710303.8527, MAE: 3116.7039, R2: 0.2774\n",
      "==========================================================================================\n",
      "Epoch [2534/5000] | Time: 0.24s\n",
      "(Training) Loss: 882623.1567\n",
      "(Validation) Loss: 710192.4686, MAE: 3111.5229, R2: 0.2775\n",
      "==========================================================================================\n",
      "Epoch [2535/5000] | Time: 0.24s\n",
      "(Training) Loss: 880472.8204\n",
      "(Validation) Loss: 710107.6489, MAE: 3110.8730, R2: 0.2776\n",
      "==========================================================================================\n",
      "Epoch [2536/5000] | Time: 0.25s\n",
      "(Training) Loss: 889833.5527\n",
      "(Validation) Loss: 710030.3003, MAE: 3113.7559, R2: 0.2777\n",
      "==========================================================================================\n",
      "Epoch [2537/5000] | Time: 0.24s\n",
      "(Training) Loss: 896551.2602\n",
      "(Validation) Loss: 709951.2121, MAE: 3114.5020, R2: 0.2778\n",
      "==========================================================================================\n",
      "Epoch [2538/5000] | Time: 0.27s\n",
      "(Training) Loss: 906670.0425\n",
      "(Validation) Loss: 709847.9714, MAE: 3110.0452, R2: 0.2779\n",
      "==========================================================================================\n",
      "Epoch [2539/5000] | Time: 0.26s\n",
      "(Training) Loss: 887848.6710\n",
      "(Validation) Loss: 709775.4146, MAE: 3111.4387, R2: 0.2779\n",
      "==========================================================================================\n",
      "Epoch [2540/5000] | Time: 0.23s\n",
      "(Training) Loss: 902850.5622\n",
      "(Validation) Loss: 709747.8483, MAE: 3124.3887, R2: 0.2780\n",
      "==========================================================================================\n",
      "Epoch [2541/5000] | Time: 0.23s\n",
      "(Training) Loss: 904505.0565\n",
      "(Validation) Loss: 709614.7098, MAE: 3115.3816, R2: 0.2781\n",
      "==========================================================================================\n",
      "Epoch [2542/5000] | Time: 0.25s\n",
      "(Training) Loss: 881253.4822\n",
      "(Validation) Loss: 709508.6406, MAE: 3110.7324, R2: 0.2782\n",
      "==========================================================================================\n",
      "Epoch [2543/5000] | Time: 0.21s\n",
      "(Training) Loss: 878708.4334\n",
      "(Validation) Loss: 709419.1759, MAE: 3111.2959, R2: 0.2783\n",
      "==========================================================================================\n",
      "Epoch [2544/5000] | Time: 0.26s\n",
      "(Training) Loss: 885608.4143\n",
      "(Validation) Loss: 709338.7784, MAE: 3111.5530, R2: 0.2784\n",
      "==========================================================================================\n",
      "Epoch [2545/5000] | Time: 0.23s\n",
      "(Training) Loss: 887744.4372\n",
      "(Validation) Loss: 709246.1365, MAE: 3109.4368, R2: 0.2785\n",
      "==========================================================================================\n",
      "Epoch [2546/5000] | Time: 0.25s\n",
      "(Training) Loss: 877341.2424\n",
      "(Validation) Loss: 709173.1041, MAE: 3112.1963, R2: 0.2785\n",
      "==========================================================================================\n",
      "Epoch [2547/5000] | Time: 0.25s\n",
      "(Training) Loss: 910751.2195\n",
      "(Validation) Loss: 709078.4908, MAE: 3110.0127, R2: 0.2786\n",
      "==========================================================================================\n",
      "Epoch [2548/5000] | Time: 0.26s\n",
      "(Training) Loss: 877245.3994\n",
      "(Validation) Loss: 708998.8381, MAE: 3111.4717, R2: 0.2787\n",
      "==========================================================================================\n",
      "Epoch [2549/5000] | Time: 0.26s\n",
      "(Training) Loss: 878160.2985\n",
      "(Validation) Loss: 708909.1187, MAE: 3109.8193, R2: 0.2788\n",
      "==========================================================================================\n",
      "Epoch [2550/5000] | Time: 0.23s\n",
      "(Training) Loss: 882975.7770\n",
      "(Validation) Loss: 708832.8311, MAE: 3112.6311, R2: 0.2789\n",
      "==========================================================================================\n",
      "Epoch [2551/5000] | Time: 0.24s\n",
      "(Training) Loss: 890742.8598\n",
      "(Validation) Loss: 708753.0978, MAE: 3113.6716, R2: 0.2790\n",
      "==========================================================================================\n",
      "Epoch [2552/5000] | Time: 0.25s\n",
      "(Training) Loss: 910478.1091\n",
      "(Validation) Loss: 708661.4908, MAE: 3112.5156, R2: 0.2791\n",
      "==========================================================================================\n",
      "Epoch [2553/5000] | Time: 0.26s\n",
      "(Training) Loss: 885259.0799\n",
      "(Validation) Loss: 708588.2210, MAE: 3115.9214, R2: 0.2791\n",
      "==========================================================================================\n",
      "Epoch [2554/5000] | Time: 0.26s\n",
      "(Training) Loss: 883829.0596\n",
      "(Validation) Loss: 708482.5187, MAE: 3109.8174, R2: 0.2792\n",
      "==========================================================================================\n",
      "Epoch [2555/5000] | Time: 0.29s\n",
      "(Training) Loss: 887611.6456\n",
      "(Validation) Loss: 708410.3886, MAE: 3112.3501, R2: 0.2793\n",
      "==========================================================================================\n",
      "Epoch [2556/5000] | Time: 0.30s\n",
      "(Training) Loss: 893321.8953\n",
      "(Validation) Loss: 708321.5029, MAE: 3112.3384, R2: 0.2794\n",
      "==========================================================================================\n",
      "Epoch [2557/5000] | Time: 0.32s\n",
      "(Training) Loss: 896506.9772\n",
      "(Validation) Loss: 708232.0794, MAE: 3110.5859, R2: 0.2795\n",
      "==========================================================================================\n",
      "Epoch [2558/5000] | Time: 0.27s\n",
      "(Training) Loss: 905599.3718\n",
      "(Validation) Loss: 708137.7010, MAE: 3108.6226, R2: 0.2796\n",
      "==========================================================================================\n",
      "Epoch [2559/5000] | Time: 0.31s\n",
      "(Training) Loss: 885586.3112\n",
      "(Validation) Loss: 719548.0190, MAE: 3182.4849, R2: 0.2681\n",
      "==========================================================================================\n",
      "Epoch [2560/5000] | Time: 0.29s\n",
      "(Training) Loss: 935222.4994\n",
      "(Validation) Loss: 727442.5162, MAE: 3173.5210, R2: 0.2601\n",
      "==========================================================================================\n",
      "Epoch [2561/5000] | Time: 0.26s\n",
      "(Training) Loss: 917772.0431\n",
      "(Validation) Loss: 727339.6698, MAE: 3166.5696, R2: 0.2602\n",
      "==========================================================================================\n",
      "Epoch [2562/5000] | Time: 0.25s\n",
      "(Training) Loss: 911317.5749\n",
      "(Validation) Loss: 727248.6971, MAE: 3166.1694, R2: 0.2603\n",
      "==========================================================================================\n",
      "Epoch [2563/5000] | Time: 0.26s\n",
      "(Training) Loss: 923207.2951\n",
      "(Validation) Loss: 727156.5829, MAE: 3165.4226, R2: 0.2604\n",
      "==========================================================================================\n",
      "Epoch [2564/5000] | Time: 0.24s\n",
      "(Training) Loss: 904767.6472\n",
      "(Validation) Loss: 727061.7663, MAE: 3163.6599, R2: 0.2605\n",
      "==========================================================================================\n",
      "Epoch [2565/5000] | Time: 0.25s\n",
      "(Training) Loss: 898285.1110\n",
      "(Validation) Loss: 726995.0787, MAE: 3167.1472, R2: 0.2606\n",
      "==========================================================================================\n",
      "Epoch [2566/5000] | Time: 0.23s\n",
      "(Training) Loss: 902983.5025\n",
      "(Validation) Loss: 726887.9638, MAE: 3163.4507, R2: 0.2607\n",
      "==========================================================================================\n",
      "Epoch [2567/5000] | Time: 0.21s\n",
      "(Training) Loss: 897850.4689\n",
      "(Validation) Loss: 726796.7257, MAE: 3163.1204, R2: 0.2608\n",
      "==========================================================================================\n",
      "Epoch [2568/5000] | Time: 0.20s\n",
      "(Training) Loss: 913219.0006\n",
      "(Validation) Loss: 726713.0641, MAE: 3162.9492, R2: 0.2608\n",
      "==========================================================================================\n",
      "Epoch [2569/5000] | Time: 0.25s\n",
      "(Training) Loss: 907203.9505\n",
      "(Validation) Loss: 726627.2546, MAE: 3164.8933, R2: 0.2609\n",
      "==========================================================================================\n",
      "Epoch [2570/5000] | Time: 0.25s\n",
      "(Training) Loss: 901995.3763\n",
      "(Validation) Loss: 726535.4622, MAE: 3162.4368, R2: 0.2610\n",
      "==========================================================================================\n",
      "Epoch [2571/5000] | Time: 0.23s\n",
      "(Training) Loss: 915648.4277\n",
      "(Validation) Loss: 726442.4692, MAE: 3161.5593, R2: 0.2611\n",
      "==========================================================================================\n",
      "Epoch [2572/5000] | Time: 0.25s\n",
      "(Training) Loss: 898565.0784\n",
      "(Validation) Loss: 726358.3435, MAE: 3162.0117, R2: 0.2612\n",
      "==========================================================================================\n",
      "Epoch [2573/5000] | Time: 0.25s\n",
      "(Training) Loss: 904027.8445\n",
      "(Validation) Loss: 726276.8794, MAE: 3164.2400, R2: 0.2613\n",
      "==========================================================================================\n",
      "Epoch [2574/5000] | Time: 0.26s\n",
      "(Training) Loss: 923440.6548\n",
      "(Validation) Loss: 726186.2121, MAE: 3162.0273, R2: 0.2614\n",
      "==========================================================================================\n",
      "Epoch [2575/5000] | Time: 0.26s\n",
      "(Training) Loss: 906313.7126\n",
      "(Validation) Loss: 726106.5327, MAE: 3166.2864, R2: 0.2615\n",
      "==========================================================================================\n",
      "Epoch [2576/5000] | Time: 0.25s\n",
      "(Training) Loss: 910869.8014\n",
      "(Validation) Loss: 726014.4667, MAE: 3164.1587, R2: 0.2615\n",
      "==========================================================================================\n",
      "Epoch [2577/5000] | Time: 0.22s\n",
      "(Training) Loss: 915975.4188\n",
      "(Validation) Loss: 725932.5378, MAE: 3164.8354, R2: 0.2616\n",
      "==========================================================================================\n",
      "Epoch [2578/5000] | Time: 0.26s\n",
      "(Training) Loss: 911271.3648\n",
      "(Validation) Loss: 725838.0349, MAE: 3162.5901, R2: 0.2617\n",
      "==========================================================================================\n",
      "Epoch [2579/5000] | Time: 0.25s\n",
      "(Training) Loss: 917311.5025\n",
      "(Validation) Loss: 725748.3816, MAE: 3162.2495, R2: 0.2618\n",
      "==========================================================================================\n",
      "Epoch [2580/5000] | Time: 0.26s\n",
      "(Training) Loss: 909896.1808\n",
      "(Validation) Loss: 725664.7270, MAE: 3163.7388, R2: 0.2619\n",
      "==========================================================================================\n",
      "Epoch [2581/5000] | Time: 0.26s\n",
      "(Training) Loss: 899636.5273\n",
      "(Validation) Loss: 725619.6292, MAE: 3173.1536, R2: 0.2619\n",
      "==========================================================================================\n",
      "Epoch [2582/5000] | Time: 0.26s\n",
      "(Training) Loss: 905518.1072\n",
      "(Validation) Loss: 725488.1829, MAE: 3164.2253, R2: 0.2621\n",
      "==========================================================================================\n",
      "Epoch [2583/5000] | Time: 0.25s\n",
      "(Training) Loss: 915108.9994\n",
      "(Validation) Loss: 725423.0622, MAE: 3166.9104, R2: 0.2621\n",
      "==========================================================================================\n",
      "Epoch [2584/5000] | Time: 0.25s\n",
      "(Training) Loss: 913429.7862\n",
      "(Validation) Loss: 725311.3124, MAE: 3163.3318, R2: 0.2623\n",
      "==========================================================================================\n",
      "Epoch [2585/5000] | Time: 0.25s\n",
      "(Training) Loss: 898088.5076\n",
      "(Validation) Loss: 725232.3562, MAE: 3164.1365, R2: 0.2623\n",
      "==========================================================================================\n",
      "Epoch [2586/5000] | Time: 0.23s\n",
      "(Training) Loss: 914967.5964\n",
      "(Validation) Loss: 725140.1340, MAE: 3163.8264, R2: 0.2624\n",
      "==========================================================================================\n",
      "Epoch [2587/5000] | Time: 0.25s\n",
      "(Training) Loss: 904254.8376\n",
      "(Validation) Loss: 725055.0229, MAE: 3164.2947, R2: 0.2625\n",
      "==========================================================================================\n",
      "Epoch [2588/5000] | Time: 0.25s\n",
      "(Training) Loss: 900637.8610\n",
      "(Validation) Loss: 724991.1022, MAE: 3168.9209, R2: 0.2626\n",
      "==========================================================================================\n",
      "Epoch [2589/5000] | Time: 0.24s\n",
      "(Training) Loss: 938567.2525\n",
      "(Validation) Loss: 724892.0673, MAE: 3166.6504, R2: 0.2627\n",
      "==========================================================================================\n",
      "Epoch [2590/5000] | Time: 0.25s\n",
      "(Training) Loss: 933056.9239\n",
      "(Validation) Loss: 724794.8387, MAE: 3164.1038, R2: 0.2628\n",
      "==========================================================================================\n",
      "Epoch [2591/5000] | Time: 0.27s\n",
      "(Training) Loss: 904169.7951\n",
      "(Validation) Loss: 724707.3098, MAE: 3164.2444, R2: 0.2629\n",
      "==========================================================================================\n",
      "Epoch [2592/5000] | Time: 0.24s\n",
      "(Training) Loss: 914386.9749\n",
      "(Validation) Loss: 724621.1867, MAE: 3163.6152, R2: 0.2630\n",
      "==========================================================================================\n",
      "Epoch [2593/5000] | Time: 0.26s\n",
      "(Training) Loss: 903989.3382\n",
      "(Validation) Loss: 724535.6063, MAE: 3163.3359, R2: 0.2630\n",
      "==========================================================================================\n",
      "Epoch [2594/5000] | Time: 0.25s\n",
      "(Training) Loss: 905104.1180\n",
      "(Validation) Loss: 724452.1854, MAE: 3164.3975, R2: 0.2631\n",
      "==========================================================================================\n",
      "Epoch [2595/5000] | Time: 0.25s\n",
      "(Training) Loss: 910009.4442\n",
      "(Validation) Loss: 724364.8152, MAE: 3163.4812, R2: 0.2632\n",
      "==========================================================================================\n",
      "Epoch [2596/5000] | Time: 0.25s\n",
      "(Training) Loss: 905830.2122\n",
      "(Validation) Loss: 724271.8552, MAE: 3162.1470, R2: 0.2633\n",
      "==========================================================================================\n",
      "Epoch [2597/5000] | Time: 0.23s\n",
      "(Training) Loss: 910941.6739\n",
      "(Validation) Loss: 724201.9727, MAE: 3164.8604, R2: 0.2634\n",
      "==========================================================================================\n",
      "Epoch [2598/5000] | Time: 0.25s\n",
      "(Training) Loss: 919878.7862\n",
      "(Validation) Loss: 724092.9784, MAE: 3158.1255, R2: 0.2635\n",
      "==========================================================================================\n",
      "Epoch [2599/5000] | Time: 0.26s\n",
      "(Training) Loss: 896816.6313\n",
      "(Validation) Loss: 724004.8654, MAE: 3158.1748, R2: 0.2636\n",
      "==========================================================================================\n",
      "Epoch [2600/5000] | Time: 0.25s\n",
      "(Training) Loss: 907618.3991\n",
      "(Validation) Loss: 723919.7721, MAE: 3158.2314, R2: 0.2637\n",
      "==========================================================================================\n",
      "Epoch [2601/5000] | Time: 0.26s\n",
      "(Training) Loss: 911058.5977\n",
      "(Validation) Loss: 723833.4940, MAE: 3158.0793, R2: 0.2637\n",
      "==========================================================================================\n",
      "Epoch [2602/5000] | Time: 0.28s\n",
      "(Training) Loss: 897964.4251\n",
      "(Validation) Loss: 723747.7689, MAE: 3157.2844, R2: 0.2638\n",
      "==========================================================================================\n",
      "Epoch [2603/5000] | Time: 0.23s\n",
      "(Training) Loss: 898332.7107\n",
      "(Validation) Loss: 723674.4349, MAE: 3159.4570, R2: 0.2639\n",
      "==========================================================================================\n",
      "Epoch [2604/5000] | Time: 0.24s\n",
      "(Training) Loss: 939006.9841\n",
      "(Validation) Loss: 723586.4984, MAE: 3159.9299, R2: 0.2640\n",
      "==========================================================================================\n",
      "Epoch [2605/5000] | Time: 0.25s\n",
      "(Training) Loss: 921540.4524\n",
      "(Validation) Loss: 723497.4889, MAE: 3160.3289, R2: 0.2641\n",
      "==========================================================================================\n",
      "Epoch [2606/5000] | Time: 0.25s\n",
      "(Training) Loss: 918686.0384\n",
      "(Validation) Loss: 723404.1219, MAE: 3158.0378, R2: 0.2642\n",
      "==========================================================================================\n",
      "Epoch [2607/5000] | Time: 0.24s\n",
      "(Training) Loss: 913332.2640\n",
      "(Validation) Loss: 723312.6565, MAE: 3158.0020, R2: 0.2643\n",
      "==========================================================================================\n",
      "Epoch [2608/5000] | Time: 0.27s\n",
      "(Training) Loss: 903293.1885\n",
      "(Validation) Loss: 723231.3371, MAE: 3158.4153, R2: 0.2644\n",
      "==========================================================================================\n",
      "Epoch [2609/5000] | Time: 0.25s\n",
      "(Training) Loss: 919345.5730\n",
      "(Validation) Loss: 723140.7683, MAE: 3156.0679, R2: 0.2644\n",
      "==========================================================================================\n",
      "Epoch [2610/5000] | Time: 0.26s\n",
      "(Training) Loss: 903767.1574\n",
      "(Validation) Loss: 723069.1441, MAE: 3159.4336, R2: 0.2645\n",
      "==========================================================================================\n",
      "Epoch [2611/5000] | Time: 0.24s\n",
      "(Training) Loss: 914610.3588\n",
      "(Validation) Loss: 722983.2102, MAE: 3158.0107, R2: 0.2646\n",
      "==========================================================================================\n",
      "Epoch [2612/5000] | Time: 0.26s\n",
      "(Training) Loss: 900504.5949\n",
      "(Validation) Loss: 722887.8660, MAE: 3156.6541, R2: 0.2647\n",
      "==========================================================================================\n",
      "Epoch [2613/5000] | Time: 0.25s\n",
      "(Training) Loss: 899870.4423\n",
      "(Validation) Loss: 722792.2063, MAE: 3154.8301, R2: 0.2648\n",
      "==========================================================================================\n",
      "Epoch [2614/5000] | Time: 0.24s\n",
      "(Training) Loss: 899842.0355\n",
      "(Validation) Loss: 722723.0349, MAE: 3158.9978, R2: 0.2649\n",
      "==========================================================================================\n",
      "Epoch [2615/5000] | Time: 0.26s\n",
      "(Training) Loss: 896695.7138\n",
      "(Validation) Loss: 722627.9524, MAE: 3155.1870, R2: 0.2650\n",
      "==========================================================================================\n",
      "Epoch [2616/5000] | Time: 0.23s\n",
      "(Training) Loss: 906681.6231\n",
      "(Validation) Loss: 722543.6210, MAE: 3155.2886, R2: 0.2650\n",
      "==========================================================================================\n",
      "Epoch [2617/5000] | Time: 0.24s\n",
      "(Training) Loss: 902060.6504\n",
      "(Validation) Loss: 722455.0298, MAE: 3155.3657, R2: 0.2651\n",
      "==========================================================================================\n",
      "Epoch [2618/5000] | Time: 0.23s\n",
      "(Training) Loss: 901940.6478\n",
      "(Validation) Loss: 722362.2190, MAE: 3153.6042, R2: 0.2652\n",
      "==========================================================================================\n",
      "Epoch [2619/5000] | Time: 0.24s\n",
      "(Training) Loss: 908517.4365\n",
      "(Validation) Loss: 722288.6698, MAE: 3154.8967, R2: 0.2653\n",
      "==========================================================================================\n",
      "Epoch [2620/5000] | Time: 0.24s\n",
      "(Training) Loss: 894906.8144\n",
      "(Validation) Loss: 722197.7790, MAE: 3154.9578, R2: 0.2654\n",
      "==========================================================================================\n",
      "Epoch [2621/5000] | Time: 0.24s\n",
      "(Training) Loss: 919967.5470\n",
      "(Validation) Loss: 722107.9822, MAE: 3153.2781, R2: 0.2655\n",
      "==========================================================================================\n",
      "Epoch [2622/5000] | Time: 0.22s\n",
      "(Training) Loss: 913482.2697\n",
      "(Validation) Loss: 722027.0813, MAE: 3154.1514, R2: 0.2656\n",
      "==========================================================================================\n",
      "Epoch [2623/5000] | Time: 0.22s\n",
      "(Training) Loss: 892649.5479\n",
      "(Validation) Loss: 721932.9257, MAE: 3153.6272, R2: 0.2657\n",
      "==========================================================================================\n",
      "Epoch [2624/5000] | Time: 0.22s\n",
      "(Training) Loss: 902796.6098\n",
      "(Validation) Loss: 722027.1327, MAE: 3167.3667, R2: 0.2656\n",
      "==========================================================================================\n",
      "Epoch [2625/5000] | Time: 0.22s\n",
      "(Training) Loss: 913573.1313\n",
      "(Validation) Loss: 721936.0337, MAE: 3165.6726, R2: 0.2657\n",
      "==========================================================================================\n",
      "Epoch [2626/5000] | Time: 0.23s\n",
      "(Training) Loss: 902434.3725\n",
      "(Validation) Loss: 721865.4584, MAE: 3169.4009, R2: 0.2657\n",
      "==========================================================================================\n",
      "Epoch [2627/5000] | Time: 0.24s\n",
      "(Training) Loss: 904525.4315\n",
      "(Validation) Loss: 721764.0990, MAE: 3164.8713, R2: 0.2658\n",
      "==========================================================================================\n",
      "Epoch [2628/5000] | Time: 0.23s\n",
      "(Training) Loss: 892682.3157\n",
      "(Validation) Loss: 721675.2457, MAE: 3163.2195, R2: 0.2659\n",
      "==========================================================================================\n",
      "Epoch [2629/5000] | Time: 0.25s\n",
      "(Training) Loss: 903372.3582\n",
      "(Validation) Loss: 721593.8089, MAE: 3165.4111, R2: 0.2660\n",
      "==========================================================================================\n",
      "Epoch [2630/5000] | Time: 0.24s\n",
      "(Training) Loss: 897682.8604\n",
      "(Validation) Loss: 721510.0832, MAE: 3165.5303, R2: 0.2661\n",
      "==========================================================================================\n",
      "Epoch [2631/5000] | Time: 0.26s\n",
      "(Training) Loss: 905357.1758\n",
      "(Validation) Loss: 721420.4019, MAE: 3164.6565, R2: 0.2662\n",
      "==========================================================================================\n",
      "Epoch [2632/5000] | Time: 0.24s\n",
      "(Training) Loss: 904843.1047\n",
      "(Validation) Loss: 721333.5981, MAE: 3163.6335, R2: 0.2663\n",
      "==========================================================================================\n",
      "Epoch [2633/5000] | Time: 0.21s\n",
      "(Training) Loss: 899984.0990\n",
      "(Validation) Loss: 721247.0838, MAE: 3163.5024, R2: 0.2664\n",
      "==========================================================================================\n",
      "Epoch [2634/5000] | Time: 0.21s\n",
      "(Training) Loss: 905618.6773\n",
      "(Validation) Loss: 721160.8349, MAE: 3163.1106, R2: 0.2664\n",
      "==========================================================================================\n",
      "Epoch [2635/5000] | Time: 0.25s\n",
      "(Training) Loss: 898199.4321\n",
      "(Validation) Loss: 721075.8216, MAE: 3163.4834, R2: 0.2665\n",
      "==========================================================================================\n",
      "Epoch [2636/5000] | Time: 0.24s\n",
      "(Training) Loss: 900140.6643\n",
      "(Validation) Loss: 720990.5479, MAE: 3163.2346, R2: 0.2666\n",
      "==========================================================================================\n",
      "Epoch [2637/5000] | Time: 0.26s\n",
      "(Training) Loss: 904022.2151\n",
      "(Validation) Loss: 720912.3924, MAE: 3165.1245, R2: 0.2667\n",
      "==========================================================================================\n",
      "Epoch [2638/5000] | Time: 0.27s\n",
      "(Training) Loss: 898900.7138\n",
      "(Validation) Loss: 720819.7581, MAE: 3163.5723, R2: 0.2668\n",
      "==========================================================================================\n",
      "Epoch [2639/5000] | Time: 0.25s\n",
      "(Training) Loss: 892393.5378\n",
      "(Validation) Loss: 720732.6616, MAE: 3163.4094, R2: 0.2669\n",
      "==========================================================================================\n",
      "Epoch [2640/5000] | Time: 0.30s\n",
      "(Training) Loss: 912403.2544\n",
      "(Validation) Loss: 720658.6565, MAE: 3165.2993, R2: 0.2670\n",
      "==========================================================================================\n",
      "Epoch [2641/5000] | Time: 0.25s\n",
      "(Training) Loss: 900757.0996\n",
      "(Validation) Loss: 720568.7695, MAE: 3166.0557, R2: 0.2670\n",
      "==========================================================================================\n",
      "Epoch [2642/5000] | Time: 0.24s\n",
      "(Training) Loss: 898999.3065\n",
      "(Validation) Loss: 720475.5962, MAE: 3161.8022, R2: 0.2671\n",
      "==========================================================================================\n",
      "Epoch [2643/5000] | Time: 0.23s\n",
      "(Training) Loss: 911559.3896\n",
      "(Validation) Loss: 720393.5790, MAE: 3162.3552, R2: 0.2672\n",
      "==========================================================================================\n",
      "Epoch [2644/5000] | Time: 0.25s\n",
      "(Training) Loss: 902638.2069\n",
      "(Validation) Loss: 720301.3378, MAE: 3160.6641, R2: 0.2673\n",
      "==========================================================================================\n",
      "Epoch [2645/5000] | Time: 0.22s\n",
      "(Training) Loss: 911003.7931\n",
      "(Validation) Loss: 720219.6032, MAE: 3161.8860, R2: 0.2674\n",
      "==========================================================================================\n",
      "Epoch [2646/5000] | Time: 0.21s\n",
      "(Training) Loss: 903780.7697\n",
      "(Validation) Loss: 720128.7105, MAE: 3160.3447, R2: 0.2675\n",
      "==========================================================================================\n",
      "Epoch [2647/5000] | Time: 0.24s\n",
      "(Training) Loss: 903743.7878\n",
      "(Validation) Loss: 720046.0559, MAE: 3162.0254, R2: 0.2676\n",
      "==========================================================================================\n",
      "Epoch [2648/5000] | Time: 0.25s\n",
      "(Training) Loss: 895530.5044\n",
      "(Validation) Loss: 719959.9384, MAE: 3160.6775, R2: 0.2677\n",
      "==========================================================================================\n",
      "Epoch [2649/5000] | Time: 0.23s\n",
      "(Training) Loss: 906349.3566\n",
      "(Validation) Loss: 719873.8375, MAE: 3160.3132, R2: 0.2677\n",
      "==========================================================================================\n",
      "Epoch [2650/5000] | Time: 0.25s\n",
      "(Training) Loss: 911346.6393\n",
      "(Validation) Loss: 719797.5289, MAE: 3163.1470, R2: 0.2678\n",
      "==========================================================================================\n",
      "Epoch [2651/5000] | Time: 0.23s\n",
      "(Training) Loss: 906236.7627\n",
      "(Validation) Loss: 719701.6914, MAE: 3160.1375, R2: 0.2679\n",
      "==========================================================================================\n",
      "Epoch [2652/5000] | Time: 0.25s\n",
      "(Training) Loss: 903051.6110\n",
      "(Validation) Loss: 719629.0140, MAE: 3163.2883, R2: 0.2680\n",
      "==========================================================================================\n",
      "Epoch [2653/5000] | Time: 0.23s\n",
      "(Training) Loss: 891446.3477\n",
      "(Validation) Loss: 719529.2102, MAE: 3159.3506, R2: 0.2681\n",
      "==========================================================================================\n",
      "Epoch [2654/5000] | Time: 0.22s\n",
      "(Training) Loss: 892884.1358\n",
      "(Validation) Loss: 719303.4260, MAE: 3152.7239, R2: 0.2683\n",
      "==========================================================================================\n",
      "Epoch [2655/5000] | Time: 0.24s\n",
      "(Training) Loss: 895722.2522\n",
      "(Validation) Loss: 719197.4552, MAE: 3146.6714, R2: 0.2684\n",
      "==========================================================================================\n",
      "Epoch [2656/5000] | Time: 0.23s\n",
      "(Training) Loss: 906291.2386\n",
      "(Validation) Loss: 719111.8108, MAE: 3147.7866, R2: 0.2685\n",
      "==========================================================================================\n",
      "Epoch [2657/5000] | Time: 0.23s\n",
      "(Training) Loss: 899689.1951\n",
      "(Validation) Loss: 719037.4571, MAE: 3150.2297, R2: 0.2686\n",
      "==========================================================================================\n",
      "Epoch [2658/5000] | Time: 0.20s\n",
      "(Training) Loss: 926880.8864\n",
      "(Validation) Loss: 718952.9600, MAE: 3149.6118, R2: 0.2687\n",
      "==========================================================================================\n",
      "Epoch [2659/5000] | Time: 0.19s\n",
      "(Training) Loss: 921648.0025\n",
      "(Validation) Loss: 740328.3340, MAE: 3226.3162, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [2660/5000] | Time: 0.21s\n",
      "(Training) Loss: 926125.0393\n",
      "(Validation) Loss: 740190.5035, MAE: 3216.1636, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [2661/5000] | Time: 0.21s\n",
      "(Training) Loss: 911986.1175\n",
      "(Validation) Loss: 740101.3492, MAE: 3215.9036, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [2662/5000] | Time: 0.18s\n",
      "(Training) Loss: 921755.3921\n",
      "(Validation) Loss: 740008.2737, MAE: 3215.6609, R2: 0.2474\n",
      "==========================================================================================\n",
      "Epoch [2663/5000] | Time: 0.19s\n",
      "(Training) Loss: 929213.9499\n",
      "(Validation) Loss: 739912.9149, MAE: 3213.7837, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [2664/5000] | Time: 0.18s\n",
      "(Training) Loss: 915931.9784\n",
      "(Validation) Loss: 739825.2400, MAE: 3214.1653, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [2665/5000] | Time: 0.18s\n",
      "(Training) Loss: 925372.3991\n",
      "(Validation) Loss: 739732.7219, MAE: 3214.1680, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [2666/5000] | Time: 0.18s\n",
      "(Training) Loss: 915115.7383\n",
      "(Validation) Loss: 739644.2470, MAE: 3214.3953, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [2667/5000] | Time: 0.19s\n",
      "(Training) Loss: 929168.3706\n",
      "(Validation) Loss: 739550.6063, MAE: 3212.6726, R2: 0.2479\n",
      "==========================================================================================\n",
      "Epoch [2668/5000] | Time: 0.24s\n",
      "(Training) Loss: 931523.8782\n",
      "(Validation) Loss: 739462.7073, MAE: 3213.9880, R2: 0.2480\n",
      "==========================================================================================\n",
      "Epoch [2669/5000] | Time: 0.19s\n",
      "(Training) Loss: 939177.5228\n",
      "(Validation) Loss: 739371.1168, MAE: 3212.9041, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [2670/5000] | Time: 0.21s\n",
      "(Training) Loss: 928476.2005\n",
      "(Validation) Loss: 739277.5003, MAE: 3212.6003, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [2671/5000] | Time: 0.21s\n",
      "(Training) Loss: 927198.1117\n",
      "(Validation) Loss: 739188.3810, MAE: 3212.9026, R2: 0.2483\n",
      "==========================================================================================\n",
      "Epoch [2672/5000] | Time: 0.20s\n",
      "(Training) Loss: 925753.5311\n",
      "(Validation) Loss: 739100.7829, MAE: 3213.3691, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [2673/5000] | Time: 0.19s\n",
      "(Training) Loss: 914485.2560\n",
      "(Validation) Loss: 739023.8730, MAE: 3215.5879, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [2674/5000] | Time: 0.20s\n",
      "(Training) Loss: 936024.7843\n",
      "(Validation) Loss: 738923.0444, MAE: 3213.5298, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [2675/5000] | Time: 0.19s\n",
      "(Training) Loss: 929761.9086\n",
      "(Validation) Loss: 738834.7524, MAE: 3213.4980, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [2676/5000] | Time: 0.21s\n",
      "(Training) Loss: 923860.3890\n",
      "(Validation) Loss: 738743.5867, MAE: 3213.2664, R2: 0.2487\n",
      "==========================================================================================\n",
      "Epoch [2677/5000] | Time: 0.19s\n",
      "(Training) Loss: 912596.7900\n",
      "(Validation) Loss: 738652.1448, MAE: 3213.6499, R2: 0.2488\n",
      "==========================================================================================\n",
      "Epoch [2678/5000] | Time: 0.19s\n",
      "(Training) Loss: 914450.8598\n",
      "(Validation) Loss: 738565.0844, MAE: 3212.9912, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [2679/5000] | Time: 0.20s\n",
      "(Training) Loss: 924565.9905\n",
      "(Validation) Loss: 738469.7968, MAE: 3211.6848, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [2680/5000] | Time: 0.22s\n",
      "(Training) Loss: 916410.1653\n",
      "(Validation) Loss: 738380.3663, MAE: 3211.7488, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [2681/5000] | Time: 0.22s\n",
      "(Training) Loss: 919245.9918\n",
      "(Validation) Loss: 738300.5987, MAE: 3213.2000, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [2682/5000] | Time: 0.26s\n",
      "(Training) Loss: 914995.4588\n",
      "(Validation) Loss: 738206.4025, MAE: 3211.8386, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [2683/5000] | Time: 0.20s\n",
      "(Training) Loss: 939683.0558\n",
      "(Validation) Loss: 738123.2324, MAE: 3212.9185, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [2684/5000] | Time: 0.20s\n",
      "(Training) Loss: 935654.7716\n",
      "(Validation) Loss: 738020.5168, MAE: 3210.1821, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [2685/5000] | Time: 0.20s\n",
      "(Training) Loss: 914164.9530\n",
      "(Validation) Loss: 737938.8565, MAE: 3212.4443, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [2686/5000] | Time: 0.22s\n",
      "(Training) Loss: 934561.1313\n",
      "(Validation) Loss: 737850.1879, MAE: 3212.5012, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [2687/5000] | Time: 0.20s\n",
      "(Training) Loss: 929845.8192\n",
      "(Validation) Loss: 737755.5467, MAE: 3209.8171, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [2688/5000] | Time: 0.20s\n",
      "(Training) Loss: 913890.0774\n",
      "(Validation) Loss: 737660.6444, MAE: 3208.9832, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [2689/5000] | Time: 0.20s\n",
      "(Training) Loss: 939406.6612\n",
      "(Validation) Loss: 737583.2648, MAE: 3210.4229, R2: 0.2499\n",
      "==========================================================================================\n",
      "Epoch [2690/5000] | Time: 0.22s\n",
      "(Training) Loss: 925215.2430\n",
      "(Validation) Loss: 737510.2279, MAE: 3212.5303, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [2691/5000] | Time: 0.20s\n",
      "(Training) Loss: 914006.6472\n",
      "(Validation) Loss: 737407.8883, MAE: 3210.9314, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [2692/5000] | Time: 0.24s\n",
      "(Training) Loss: 917924.4385\n",
      "(Validation) Loss: 737332.1562, MAE: 3212.4358, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [2693/5000] | Time: 0.23s\n",
      "(Training) Loss: 921525.7135\n",
      "(Validation) Loss: 737218.2711, MAE: 3208.1414, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [2694/5000] | Time: 0.20s\n",
      "(Training) Loss: 909165.0704\n",
      "(Validation) Loss: 737128.5562, MAE: 3208.2651, R2: 0.2503\n",
      "==========================================================================================\n",
      "Epoch [2695/5000] | Time: 0.25s\n",
      "(Training) Loss: 908889.9544\n",
      "(Validation) Loss: 737047.5410, MAE: 3209.5762, R2: 0.2504\n",
      "==========================================================================================\n",
      "Epoch [2696/5000] | Time: 0.21s\n",
      "(Training) Loss: 908711.1592\n",
      "(Validation) Loss: 736968.7327, MAE: 3212.3596, R2: 0.2505\n",
      "==========================================================================================\n",
      "Epoch [2697/5000] | Time: 0.24s\n",
      "(Training) Loss: 910387.2719\n",
      "(Validation) Loss: 736868.8603, MAE: 3209.1963, R2: 0.2506\n",
      "==========================================================================================\n",
      "Epoch [2698/5000] | Time: 0.25s\n",
      "(Training) Loss: 910502.9178\n",
      "(Validation) Loss: 736780.3314, MAE: 3208.3711, R2: 0.2507\n",
      "==========================================================================================\n",
      "Epoch [2699/5000] | Time: 0.27s\n",
      "(Training) Loss: 940203.6739\n",
      "(Validation) Loss: 736686.7708, MAE: 3206.6699, R2: 0.2508\n",
      "==========================================================================================\n",
      "Epoch [2700/5000] | Time: 0.25s\n",
      "(Training) Loss: 909637.1253\n",
      "(Validation) Loss: 736598.3067, MAE: 3206.8894, R2: 0.2509\n",
      "==========================================================================================\n",
      "Epoch [2701/5000] | Time: 0.24s\n",
      "(Training) Loss: 931294.9112\n",
      "(Validation) Loss: 752873.6260, MAE: 3270.6467, R2: 0.2345\n",
      "==========================================================================================\n",
      "Epoch [2702/5000] | Time: 0.24s\n",
      "(Training) Loss: 931791.5761\n",
      "(Validation) Loss: 752778.7371, MAE: 3269.1436, R2: 0.2346\n",
      "==========================================================================================\n",
      "Epoch [2703/5000] | Time: 0.24s\n",
      "(Training) Loss: 939678.9575\n",
      "(Validation) Loss: 752689.2902, MAE: 3269.0374, R2: 0.2347\n",
      "==========================================================================================\n",
      "Epoch [2704/5000] | Time: 0.22s\n",
      "(Training) Loss: 943682.8404\n",
      "(Validation) Loss: 752594.7867, MAE: 3267.7292, R2: 0.2348\n",
      "==========================================================================================\n",
      "Epoch [2705/5000] | Time: 0.21s\n",
      "(Training) Loss: 929334.4670\n",
      "(Validation) Loss: 752503.3663, MAE: 3266.9758, R2: 0.2348\n",
      "==========================================================================================\n",
      "Epoch [2706/5000] | Time: 0.22s\n",
      "(Training) Loss: 943698.6999\n",
      "(Validation) Loss: 752412.5975, MAE: 3266.5801, R2: 0.2349\n",
      "==========================================================================================\n",
      "Epoch [2707/5000] | Time: 0.21s\n",
      "(Training) Loss: 946544.0159\n",
      "(Validation) Loss: 752319.6870, MAE: 3266.6519, R2: 0.2350\n",
      "==========================================================================================\n",
      "Epoch [2708/5000] | Time: 0.24s\n",
      "(Training) Loss: 936790.1079\n",
      "(Validation) Loss: 752226.2711, MAE: 3264.7781, R2: 0.2351\n",
      "==========================================================================================\n",
      "Epoch [2709/5000] | Time: 0.24s\n",
      "(Training) Loss: 939130.7113\n",
      "(Validation) Loss: 752134.9644, MAE: 3263.7856, R2: 0.2352\n",
      "==========================================================================================\n",
      "Epoch [2710/5000] | Time: 0.25s\n",
      "(Training) Loss: 927208.2962\n",
      "(Validation) Loss: 752046.6902, MAE: 3263.8413, R2: 0.2353\n",
      "==========================================================================================\n",
      "Epoch [2711/5000] | Time: 0.25s\n",
      "(Training) Loss: 935011.4042\n",
      "(Validation) Loss: 751962.6311, MAE: 3265.2131, R2: 0.2354\n",
      "==========================================================================================\n",
      "Epoch [2712/5000] | Time: 0.29s\n",
      "(Training) Loss: 926827.1789\n",
      "(Validation) Loss: 751865.0654, MAE: 3263.1670, R2: 0.2355\n",
      "==========================================================================================\n",
      "Epoch [2713/5000] | Time: 0.24s\n",
      "(Training) Loss: 950827.7195\n",
      "(Validation) Loss: 751780.3721, MAE: 3263.7390, R2: 0.2356\n",
      "==========================================================================================\n",
      "Epoch [2714/5000] | Time: 0.22s\n",
      "(Training) Loss: 930189.1802\n",
      "(Validation) Loss: 751684.6978, MAE: 3262.7305, R2: 0.2357\n",
      "==========================================================================================\n",
      "Epoch [2715/5000] | Time: 0.23s\n",
      "(Training) Loss: 945326.4784\n",
      "(Validation) Loss: 751595.9702, MAE: 3263.2422, R2: 0.2358\n",
      "==========================================================================================\n",
      "Epoch [2716/5000] | Time: 0.26s\n",
      "(Training) Loss: 942430.2386\n",
      "(Validation) Loss: 751503.8952, MAE: 3262.9216, R2: 0.2358\n",
      "==========================================================================================\n",
      "Epoch [2717/5000] | Time: 0.24s\n",
      "(Training) Loss: 938739.3890\n",
      "(Validation) Loss: 751411.0737, MAE: 3261.6584, R2: 0.2359\n",
      "==========================================================================================\n",
      "Epoch [2718/5000] | Time: 0.24s\n",
      "(Training) Loss: 937431.6447\n",
      "(Validation) Loss: 751323.3600, MAE: 3262.2671, R2: 0.2360\n",
      "==========================================================================================\n",
      "Epoch [2719/5000] | Time: 0.22s\n",
      "(Training) Loss: 929541.4588\n",
      "(Validation) Loss: 751239.5219, MAE: 3264.0498, R2: 0.2361\n",
      "==========================================================================================\n",
      "Epoch [2720/5000] | Time: 0.24s\n",
      "(Training) Loss: 956798.9994\n",
      "(Validation) Loss: 751150.0013, MAE: 3262.4441, R2: 0.2362\n",
      "==========================================================================================\n",
      "Epoch [2721/5000] | Time: 0.24s\n",
      "(Training) Loss: 926359.6859\n",
      "(Validation) Loss: 751054.4559, MAE: 3260.9839, R2: 0.2363\n",
      "==========================================================================================\n",
      "Epoch [2722/5000] | Time: 0.26s\n",
      "(Training) Loss: 939398.8325\n",
      "(Validation) Loss: 750969.8933, MAE: 3260.8469, R2: 0.2364\n",
      "==========================================================================================\n",
      "Epoch [2723/5000] | Time: 0.22s\n",
      "(Training) Loss: 926354.2199\n",
      "(Validation) Loss: 750878.7175, MAE: 3262.6470, R2: 0.2365\n",
      "==========================================================================================\n",
      "Epoch [2724/5000] | Time: 0.22s\n",
      "(Training) Loss: 949166.3052\n",
      "(Validation) Loss: 750786.7867, MAE: 3259.5920, R2: 0.2366\n",
      "==========================================================================================\n",
      "Epoch [2725/5000] | Time: 0.26s\n",
      "(Training) Loss: 940732.6529\n",
      "(Validation) Loss: 750696.7632, MAE: 3260.1584, R2: 0.2367\n",
      "==========================================================================================\n",
      "Epoch [2726/5000] | Time: 0.26s\n",
      "(Training) Loss: 933003.5260\n",
      "(Validation) Loss: 750635.0013, MAE: 3263.7695, R2: 0.2367\n",
      "==========================================================================================\n",
      "Epoch [2727/5000] | Time: 0.24s\n",
      "(Training) Loss: 924941.9743\n",
      "(Validation) Loss: 750587.1429, MAE: 3272.4009, R2: 0.2368\n",
      "==========================================================================================\n",
      "Epoch [2728/5000] | Time: 0.25s\n",
      "(Training) Loss: 924346.6166\n",
      "(Validation) Loss: 750447.1435, MAE: 3264.6387, R2: 0.2369\n",
      "==========================================================================================\n",
      "Epoch [2729/5000] | Time: 0.23s\n",
      "(Training) Loss: 928689.6110\n",
      "(Validation) Loss: 750351.2387, MAE: 3263.1521, R2: 0.2370\n",
      "==========================================================================================\n",
      "Epoch [2730/5000] | Time: 0.23s\n",
      "(Training) Loss: 938694.7567\n",
      "(Validation) Loss: 750257.7581, MAE: 3261.9141, R2: 0.2371\n",
      "==========================================================================================\n",
      "Epoch [2731/5000] | Time: 0.25s\n",
      "(Training) Loss: 944472.6117\n",
      "(Validation) Loss: 750182.2921, MAE: 3263.6328, R2: 0.2372\n",
      "==========================================================================================\n",
      "Epoch [2732/5000] | Time: 0.22s\n",
      "(Training) Loss: 933169.0615\n",
      "(Validation) Loss: 750072.3302, MAE: 3258.0974, R2: 0.2373\n",
      "==========================================================================================\n",
      "Epoch [2733/5000] | Time: 0.22s\n",
      "(Training) Loss: 941095.1904\n",
      "(Validation) Loss: 749985.3962, MAE: 3257.5754, R2: 0.2374\n",
      "==========================================================================================\n",
      "Epoch [2734/5000] | Time: 0.24s\n",
      "(Training) Loss: 936761.5032\n",
      "(Validation) Loss: 749897.1835, MAE: 3257.7800, R2: 0.2375\n",
      "==========================================================================================\n",
      "Epoch [2735/5000] | Time: 0.25s\n",
      "(Training) Loss: 922900.5788\n",
      "(Validation) Loss: 749813.2603, MAE: 3259.4133, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [2736/5000] | Time: 0.26s\n",
      "(Training) Loss: 927964.8845\n",
      "(Validation) Loss: 749721.2730, MAE: 3258.7698, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [2737/5000] | Time: 0.24s\n",
      "(Training) Loss: 961250.7145\n",
      "(Validation) Loss: 749632.1270, MAE: 3258.2529, R2: 0.2377\n",
      "==========================================================================================\n",
      "Epoch [2738/5000] | Time: 0.23s\n",
      "(Training) Loss: 929983.9511\n",
      "(Validation) Loss: 749543.2610, MAE: 3257.7661, R2: 0.2378\n",
      "==========================================================================================\n",
      "Epoch [2739/5000] | Time: 0.25s\n",
      "(Training) Loss: 954644.9975\n",
      "(Validation) Loss: 749464.0616, MAE: 3259.1404, R2: 0.2379\n",
      "==========================================================================================\n",
      "Epoch [2740/5000] | Time: 0.22s\n",
      "(Training) Loss: 929422.0431\n",
      "(Validation) Loss: 749362.2178, MAE: 3257.1677, R2: 0.2380\n",
      "==========================================================================================\n",
      "Epoch [2741/5000] | Time: 0.22s\n",
      "(Training) Loss: 928543.3871\n",
      "(Validation) Loss: 749282.8610, MAE: 3258.2607, R2: 0.2381\n",
      "==========================================================================================\n",
      "Epoch [2742/5000] | Time: 0.25s\n",
      "(Training) Loss: 932281.0006\n",
      "(Validation) Loss: 749193.1181, MAE: 3257.7988, R2: 0.2382\n",
      "==========================================================================================\n",
      "Epoch [2743/5000] | Time: 0.24s\n",
      "(Training) Loss: 926020.3867\n",
      "(Validation) Loss: 749107.4394, MAE: 3257.5264, R2: 0.2383\n",
      "==========================================================================================\n",
      "Epoch [2744/5000] | Time: 0.23s\n",
      "(Training) Loss: 928497.3725\n",
      "(Validation) Loss: 749020.1460, MAE: 3257.6318, R2: 0.2384\n",
      "==========================================================================================\n",
      "Epoch [2745/5000] | Time: 0.23s\n",
      "(Training) Loss: 933787.8763\n",
      "(Validation) Loss: 748929.8298, MAE: 3257.5220, R2: 0.2384\n",
      "==========================================================================================\n",
      "Epoch [2746/5000] | Time: 0.25s\n",
      "(Training) Loss: 941610.5025\n",
      "(Validation) Loss: 748840.8387, MAE: 3257.2336, R2: 0.2385\n",
      "==========================================================================================\n",
      "Epoch [2747/5000] | Time: 0.23s\n",
      "(Training) Loss: 922460.6569\n",
      "(Validation) Loss: 748747.5575, MAE: 3255.7864, R2: 0.2386\n",
      "==========================================================================================\n",
      "Epoch [2748/5000] | Time: 0.24s\n",
      "(Training) Loss: 947009.6777\n",
      "(Validation) Loss: 748658.9606, MAE: 3254.3259, R2: 0.2387\n",
      "==========================================================================================\n",
      "Epoch [2749/5000] | Time: 0.25s\n",
      "(Training) Loss: 948654.4670\n",
      "(Validation) Loss: 748571.1644, MAE: 3254.9280, R2: 0.2388\n",
      "==========================================================================================\n",
      "Epoch [2750/5000] | Time: 0.23s\n",
      "(Training) Loss: 938168.3566\n",
      "(Validation) Loss: 748477.6178, MAE: 3253.7356, R2: 0.2389\n",
      "==========================================================================================\n",
      "Epoch [2751/5000] | Time: 0.21s\n",
      "(Training) Loss: 932087.5669\n",
      "(Validation) Loss: 748391.7092, MAE: 3253.8618, R2: 0.2390\n",
      "==========================================================================================\n",
      "Epoch [2752/5000] | Time: 0.21s\n",
      "(Training) Loss: 932154.0070\n",
      "(Validation) Loss: 748303.7213, MAE: 3253.5024, R2: 0.2391\n",
      "==========================================================================================\n",
      "Epoch [2753/5000] | Time: 0.21s\n",
      "(Training) Loss: 936256.7690\n",
      "(Validation) Loss: 748217.1829, MAE: 3254.5320, R2: 0.2392\n",
      "==========================================================================================\n",
      "Epoch [2754/5000] | Time: 0.22s\n",
      "(Training) Loss: 941278.2348\n",
      "(Validation) Loss: 748135.3251, MAE: 3254.4443, R2: 0.2392\n",
      "==========================================================================================\n",
      "Epoch [2755/5000] | Time: 0.21s\n",
      "(Training) Loss: 944663.0114\n",
      "(Validation) Loss: 748038.7619, MAE: 3252.6987, R2: 0.2393\n",
      "==========================================================================================\n",
      "Epoch [2756/5000] | Time: 0.22s\n",
      "(Training) Loss: 938647.5514\n",
      "(Validation) Loss: 747948.2171, MAE: 3252.6079, R2: 0.2394\n",
      "==========================================================================================\n",
      "Epoch [2757/5000] | Time: 0.21s\n",
      "(Training) Loss: 941697.1992\n",
      "(Validation) Loss: 747860.4222, MAE: 3252.1614, R2: 0.2395\n",
      "==========================================================================================\n",
      "Epoch [2758/5000] | Time: 0.21s\n",
      "(Training) Loss: 927691.9118\n",
      "(Validation) Loss: 747789.0057, MAE: 3255.4343, R2: 0.2396\n",
      "==========================================================================================\n",
      "Epoch [2759/5000] | Time: 0.22s\n",
      "(Training) Loss: 937202.4394\n",
      "(Validation) Loss: 747689.6990, MAE: 3253.5837, R2: 0.2397\n",
      "==========================================================================================\n",
      "Epoch [2760/5000] | Time: 0.22s\n",
      "(Training) Loss: 943115.9759\n",
      "(Validation) Loss: 747608.7816, MAE: 3254.5139, R2: 0.2398\n",
      "==========================================================================================\n",
      "Epoch [2761/5000] | Time: 0.21s\n",
      "(Training) Loss: 924754.7418\n",
      "(Validation) Loss: 747513.9156, MAE: 3253.1392, R2: 0.2399\n",
      "==========================================================================================\n",
      "Epoch [2762/5000] | Time: 0.36s\n",
      "(Training) Loss: 939978.1770\n",
      "(Validation) Loss: 747424.7644, MAE: 3252.6584, R2: 0.2400\n",
      "==========================================================================================\n",
      "Epoch [2763/5000] | Time: 0.35s\n",
      "(Training) Loss: 931752.4156\n",
      "(Validation) Loss: 747332.6432, MAE: 3250.7498, R2: 0.2401\n",
      "==========================================================================================\n",
      "Epoch [2764/5000] | Time: 0.35s\n",
      "(Training) Loss: 942728.3414\n",
      "(Validation) Loss: 747245.1644, MAE: 3250.7942, R2: 0.2401\n",
      "==========================================================================================\n",
      "Epoch [2765/5000] | Time: 0.54s\n",
      "(Training) Loss: 923804.8766\n",
      "(Validation) Loss: 747187.5746, MAE: 3255.9705, R2: 0.2402\n",
      "==========================================================================================\n",
      "Epoch [2766/5000] | Time: 0.56s\n",
      "(Training) Loss: 927530.5349\n",
      "(Validation) Loss: 747069.9048, MAE: 3250.9766, R2: 0.2403\n",
      "==========================================================================================\n",
      "Epoch [2767/5000] | Time: 0.47s\n",
      "(Training) Loss: 940889.9816\n",
      "(Validation) Loss: 746984.6990, MAE: 3251.3936, R2: 0.2404\n",
      "==========================================================================================\n",
      "Epoch [2768/5000] | Time: 0.39s\n",
      "(Training) Loss: 957343.5907\n",
      "(Validation) Loss: 746892.5797, MAE: 3249.2959, R2: 0.2405\n",
      "==========================================================================================\n",
      "Epoch [2769/5000] | Time: 0.31s\n",
      "(Training) Loss: 948808.5146\n",
      "(Validation) Loss: 746819.2375, MAE: 3254.0564, R2: 0.2406\n",
      "==========================================================================================\n",
      "Epoch [2770/5000] | Time: 0.29s\n",
      "(Training) Loss: 952168.4651\n",
      "(Validation) Loss: 746719.2870, MAE: 3250.5342, R2: 0.2407\n",
      "==========================================================================================\n",
      "Epoch [2771/5000] | Time: 0.31s\n",
      "(Training) Loss: 928135.8528\n",
      "(Validation) Loss: 746628.7575, MAE: 3250.4431, R2: 0.2408\n",
      "==========================================================================================\n",
      "Epoch [2772/5000] | Time: 0.33s\n",
      "(Training) Loss: 925892.4397\n",
      "(Validation) Loss: 746541.4908, MAE: 3248.8667, R2: 0.2409\n",
      "==========================================================================================\n",
      "Epoch [2773/5000] | Time: 0.53s\n",
      "(Training) Loss: 929887.6948\n",
      "(Validation) Loss: 746452.1073, MAE: 3249.4792, R2: 0.2409\n",
      "==========================================================================================\n",
      "Epoch [2774/5000] | Time: 0.32s\n",
      "(Training) Loss: 935923.6827\n",
      "(Validation) Loss: 746368.9568, MAE: 3249.0352, R2: 0.2410\n",
      "==========================================================================================\n",
      "Epoch [2775/5000] | Time: 0.35s\n",
      "(Training) Loss: 932073.9949\n",
      "(Validation) Loss: 746280.6127, MAE: 3249.7485, R2: 0.2411\n",
      "==========================================================================================\n",
      "Epoch [2776/5000] | Time: 0.39s\n",
      "(Training) Loss: 944608.5140\n",
      "(Validation) Loss: 746201.6229, MAE: 3250.8020, R2: 0.2412\n",
      "==========================================================================================\n",
      "Epoch [2777/5000] | Time: 0.30s\n",
      "(Training) Loss: 940119.9829\n",
      "(Validation) Loss: 746100.6844, MAE: 3247.7239, R2: 0.2413\n",
      "==========================================================================================\n",
      "Epoch [2778/5000] | Time: 0.39s\n",
      "(Training) Loss: 936945.5343\n",
      "(Validation) Loss: 746022.8997, MAE: 3250.9707, R2: 0.2414\n",
      "==========================================================================================\n",
      "Epoch [2779/5000] | Time: 0.33s\n",
      "(Training) Loss: 944718.4124\n",
      "(Validation) Loss: 745924.2641, MAE: 3247.6270, R2: 0.2415\n",
      "==========================================================================================\n",
      "Epoch [2780/5000] | Time: 0.36s\n",
      "(Training) Loss: 946653.1821\n",
      "(Validation) Loss: 745841.2768, MAE: 3248.7537, R2: 0.2416\n",
      "==========================================================================================\n",
      "Epoch [2781/5000] | Time: 0.34s\n",
      "(Training) Loss: 927272.7348\n",
      "(Validation) Loss: 745306.8717, MAE: 3245.3030, R2: 0.2421\n",
      "==========================================================================================\n",
      "Epoch [2782/5000] | Time: 0.33s\n",
      "(Training) Loss: 921413.7253\n",
      "(Validation) Loss: 745223.6362, MAE: 3245.7263, R2: 0.2422\n",
      "==========================================================================================\n",
      "Epoch [2783/5000] | Time: 0.40s\n",
      "(Training) Loss: 936161.3509\n",
      "(Validation) Loss: 745138.5587, MAE: 3244.7600, R2: 0.2423\n",
      "==========================================================================================\n",
      "Epoch [2784/5000] | Time: 0.36s\n",
      "(Training) Loss: 936439.9734\n",
      "(Validation) Loss: 745064.5441, MAE: 3247.3542, R2: 0.2423\n",
      "==========================================================================================\n",
      "Epoch [2785/5000] | Time: 0.35s\n",
      "(Training) Loss: 942278.6123\n",
      "(Validation) Loss: 744964.7613, MAE: 3244.2820, R2: 0.2424\n",
      "==========================================================================================\n",
      "Epoch [2786/5000] | Time: 0.35s\n",
      "(Training) Loss: 917817.4875\n",
      "(Validation) Loss: 744883.6940, MAE: 3245.8735, R2: 0.2425\n",
      "==========================================================================================\n",
      "Epoch [2787/5000] | Time: 0.42s\n",
      "(Training) Loss: 917389.9251\n",
      "(Validation) Loss: 744795.7568, MAE: 3243.9304, R2: 0.2426\n",
      "==========================================================================================\n",
      "Epoch [2788/5000] | Time: 0.46s\n",
      "(Training) Loss: 933423.0343\n",
      "(Validation) Loss: 744717.5676, MAE: 3245.3115, R2: 0.2427\n",
      "==========================================================================================\n",
      "Epoch [2789/5000] | Time: 0.35s\n",
      "(Training) Loss: 917145.9636\n",
      "(Validation) Loss: 744627.0241, MAE: 3242.8560, R2: 0.2428\n",
      "==========================================================================================\n",
      "Epoch [2790/5000] | Time: 0.37s\n",
      "(Training) Loss: 928267.6885\n",
      "(Validation) Loss: 744550.6527, MAE: 3245.4412, R2: 0.2429\n",
      "==========================================================================================\n",
      "Epoch [2791/5000] | Time: 0.41s\n",
      "(Training) Loss: 921518.2963\n",
      "(Validation) Loss: 744460.4660, MAE: 3244.6880, R2: 0.2429\n",
      "==========================================================================================\n",
      "Epoch [2792/5000] | Time: 0.34s\n",
      "(Training) Loss: 921351.6396\n",
      "(Validation) Loss: 744370.1524, MAE: 3242.2876, R2: 0.2430\n",
      "==========================================================================================\n",
      "Epoch [2793/5000] | Time: 0.35s\n",
      "(Training) Loss: 923725.5679\n",
      "(Validation) Loss: 744297.3841, MAE: 3244.7041, R2: 0.2431\n",
      "==========================================================================================\n",
      "Epoch [2794/5000] | Time: 0.33s\n",
      "(Training) Loss: 924209.8944\n",
      "(Validation) Loss: 744204.8419, MAE: 3242.9575, R2: 0.2432\n",
      "==========================================================================================\n",
      "Epoch [2795/5000] | Time: 0.32s\n",
      "(Training) Loss: 924264.8896\n",
      "(Validation) Loss: 744123.2032, MAE: 3243.6477, R2: 0.2433\n",
      "==========================================================================================\n",
      "Epoch [2796/5000] | Time: 0.40s\n",
      "(Training) Loss: 944192.5044\n",
      "(Validation) Loss: 744034.4635, MAE: 3242.7200, R2: 0.2434\n",
      "==========================================================================================\n",
      "Epoch [2797/5000] | Time: 0.33s\n",
      "(Training) Loss: 918030.8406\n",
      "(Validation) Loss: 743947.5029, MAE: 3241.8931, R2: 0.2435\n",
      "==========================================================================================\n",
      "Epoch [2798/5000] | Time: 0.31s\n",
      "(Training) Loss: 948685.2690\n",
      "(Validation) Loss: 743859.6013, MAE: 3240.5510, R2: 0.2436\n",
      "==========================================================================================\n",
      "Epoch [2799/5000] | Time: 0.32s\n",
      "(Training) Loss: 919301.3039\n",
      "(Validation) Loss: 743776.5587, MAE: 3241.0969, R2: 0.2436\n",
      "==========================================================================================\n",
      "Epoch [2800/5000] | Time: 0.43s\n",
      "(Training) Loss: 918482.7011\n",
      "(Validation) Loss: 743691.9473, MAE: 3241.2166, R2: 0.2437\n",
      "==========================================================================================\n",
      "Epoch [2801/5000] | Time: 0.42s\n",
      "(Training) Loss: 938815.9524\n",
      "(Validation) Loss: 743608.5549, MAE: 3241.0359, R2: 0.2438\n",
      "==========================================================================================\n",
      "Epoch [2802/5000] | Time: 0.39s\n",
      "(Training) Loss: 935031.2678\n",
      "(Validation) Loss: 743529.9505, MAE: 3243.1082, R2: 0.2439\n",
      "==========================================================================================\n",
      "Epoch [2803/5000] | Time: 0.37s\n",
      "(Training) Loss: 928222.6294\n",
      "(Validation) Loss: 743445.6305, MAE: 3242.8765, R2: 0.2440\n",
      "==========================================================================================\n",
      "Epoch [2804/5000] | Time: 0.38s\n",
      "(Training) Loss: 919744.0736\n",
      "(Validation) Loss: 743363.7689, MAE: 3243.4526, R2: 0.2441\n",
      "==========================================================================================\n",
      "Epoch [2805/5000] | Time: 0.36s\n",
      "(Training) Loss: 926184.1973\n",
      "(Validation) Loss: 743272.4152, MAE: 3241.9968, R2: 0.2441\n",
      "==========================================================================================\n",
      "Epoch [2806/5000] | Time: 0.37s\n",
      "(Training) Loss: 943724.5006\n",
      "(Validation) Loss: 743188.6825, MAE: 3241.4844, R2: 0.2442\n",
      "==========================================================================================\n",
      "Epoch [2807/5000] | Time: 0.34s\n",
      "(Training) Loss: 922947.3192\n",
      "(Validation) Loss: 743095.5435, MAE: 3239.2361, R2: 0.2443\n",
      "==========================================================================================\n",
      "Epoch [2808/5000] | Time: 0.32s\n",
      "(Training) Loss: 937338.9473\n",
      "(Validation) Loss: 743015.3105, MAE: 3240.4089, R2: 0.2444\n",
      "==========================================================================================\n",
      "Epoch [2809/5000] | Time: 0.31s\n",
      "(Training) Loss: 924516.3737\n",
      "(Validation) Loss: 742933.5314, MAE: 3242.2676, R2: 0.2445\n",
      "==========================================================================================\n",
      "Epoch [2810/5000] | Time: 0.41s\n",
      "(Training) Loss: 932286.7614\n",
      "(Validation) Loss: 742841.2914, MAE: 3238.4253, R2: 0.2446\n",
      "==========================================================================================\n",
      "Epoch [2811/5000] | Time: 0.30s\n",
      "(Training) Loss: 925861.2043\n",
      "(Validation) Loss: 742757.2432, MAE: 3238.8274, R2: 0.2447\n",
      "==========================================================================================\n",
      "Epoch [2812/5000] | Time: 0.30s\n",
      "(Training) Loss: 927018.3236\n",
      "(Validation) Loss: 742672.2229, MAE: 3238.4817, R2: 0.2448\n",
      "==========================================================================================\n",
      "Epoch [2813/5000] | Time: 0.29s\n",
      "(Training) Loss: 924304.4283\n",
      "(Validation) Loss: 742588.8419, MAE: 3238.4780, R2: 0.2448\n",
      "==========================================================================================\n",
      "Epoch [2814/5000] | Time: 0.30s\n",
      "(Training) Loss: 939842.9924\n",
      "(Validation) Loss: 742506.9581, MAE: 3239.6213, R2: 0.2449\n",
      "==========================================================================================\n",
      "Epoch [2815/5000] | Time: 0.30s\n",
      "(Training) Loss: 925723.4645\n",
      "(Validation) Loss: 742418.8102, MAE: 3239.4399, R2: 0.2450\n",
      "==========================================================================================\n",
      "Epoch [2816/5000] | Time: 0.37s\n",
      "(Training) Loss: 955948.1136\n",
      "(Validation) Loss: 742341.7149, MAE: 3240.0347, R2: 0.2451\n",
      "==========================================================================================\n",
      "Epoch [2817/5000] | Time: 0.34s\n",
      "(Training) Loss: 924779.4962\n",
      "(Validation) Loss: 742249.8133, MAE: 3238.9365, R2: 0.2452\n",
      "==========================================================================================\n",
      "Epoch [2818/5000] | Time: 0.36s\n",
      "(Training) Loss: 935033.2773\n",
      "(Validation) Loss: 742100.4095, MAE: 3246.1736, R2: 0.2453\n",
      "==========================================================================================\n",
      "Epoch [2819/5000] | Time: 0.32s\n",
      "(Training) Loss: 949455.0876\n",
      "(Validation) Loss: 741873.5035, MAE: 3223.1335, R2: 0.2456\n",
      "==========================================================================================\n",
      "Epoch [2820/5000] | Time: 0.30s\n",
      "(Training) Loss: 914147.0984\n",
      "(Validation) Loss: 741801.7987, MAE: 3225.0527, R2: 0.2456\n",
      "==========================================================================================\n",
      "Epoch [2821/5000] | Time: 0.34s\n",
      "(Training) Loss: 926767.0996\n",
      "(Validation) Loss: 741739.5562, MAE: 3227.4182, R2: 0.2457\n",
      "==========================================================================================\n",
      "Epoch [2822/5000] | Time: 0.38s\n",
      "(Training) Loss: 934139.7741\n",
      "(Validation) Loss: 741641.5962, MAE: 3225.9343, R2: 0.2458\n",
      "==========================================================================================\n",
      "Epoch [2823/5000] | Time: 0.32s\n",
      "(Training) Loss: 928256.9781\n",
      "(Validation) Loss: 741537.1670, MAE: 3222.5435, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [2824/5000] | Time: 0.29s\n",
      "(Training) Loss: 920373.1923\n",
      "(Validation) Loss: 729455.3778, MAE: 3196.4734, R2: 0.2581\n",
      "==========================================================================================\n",
      "Epoch [2825/5000] | Time: 0.34s\n",
      "(Training) Loss: 910555.4734\n",
      "(Validation) Loss: 729314.6660, MAE: 3185.7463, R2: 0.2582\n",
      "==========================================================================================\n",
      "Epoch [2826/5000] | Time: 0.31s\n",
      "(Training) Loss: 902010.1662\n",
      "(Validation) Loss: 729244.6819, MAE: 3186.3687, R2: 0.2583\n",
      "==========================================================================================\n",
      "Epoch [2827/5000] | Time: 0.31s\n",
      "(Training) Loss: 904906.6542\n",
      "(Validation) Loss: 729191.8990, MAE: 3193.8745, R2: 0.2583\n",
      "==========================================================================================\n",
      "Epoch [2828/5000] | Time: 0.33s\n",
      "(Training) Loss: 904400.9702\n",
      "(Validation) Loss: 729077.7816, MAE: 3184.5442, R2: 0.2585\n",
      "==========================================================================================\n",
      "Epoch [2829/5000] | Time: 0.31s\n",
      "(Training) Loss: 907418.9537\n",
      "(Validation) Loss: 729000.7752, MAE: 3185.3530, R2: 0.2585\n",
      "==========================================================================================\n",
      "Epoch [2830/5000] | Time: 0.32s\n",
      "(Training) Loss: 914236.9175\n",
      "(Validation) Loss: 728917.5295, MAE: 3183.8013, R2: 0.2586\n",
      "==========================================================================================\n",
      "Epoch [2831/5000] | Time: 0.33s\n",
      "(Training) Loss: 919738.5819\n",
      "(Validation) Loss: 728822.8825, MAE: 3181.5972, R2: 0.2587\n",
      "==========================================================================================\n",
      "Epoch [2832/5000] | Time: 0.35s\n",
      "(Training) Loss: 948922.2716\n",
      "(Validation) Loss: 728805.9333, MAE: 3190.2952, R2: 0.2587\n",
      "==========================================================================================\n",
      "Epoch [2833/5000] | Time: 0.38s\n",
      "(Training) Loss: 911094.6428\n",
      "(Validation) Loss: 728711.3854, MAE: 3188.5042, R2: 0.2588\n",
      "==========================================================================================\n",
      "Epoch [2834/5000] | Time: 0.34s\n",
      "(Training) Loss: 916766.5482\n",
      "(Validation) Loss: 728624.9117, MAE: 3187.6646, R2: 0.2589\n",
      "==========================================================================================\n",
      "Epoch [2835/5000] | Time: 0.35s\n",
      "(Training) Loss: 908582.7690\n",
      "(Validation) Loss: 728568.5689, MAE: 3191.6418, R2: 0.2590\n",
      "==========================================================================================\n",
      "Epoch [2836/5000] | Time: 0.32s\n",
      "(Training) Loss: 921333.8534\n",
      "(Validation) Loss: 728443.6521, MAE: 3185.0762, R2: 0.2591\n",
      "==========================================================================================\n",
      "Epoch [2837/5000] | Time: 0.34s\n",
      "(Training) Loss: 912438.4105\n",
      "(Validation) Loss: 728417.7524, MAE: 3189.8228, R2: 0.2591\n",
      "==========================================================================================\n",
      "Epoch [2838/5000] | Time: 0.36s\n",
      "(Training) Loss: 910644.4178\n",
      "(Validation) Loss: 731880.3625, MAE: 3189.1975, R2: 0.2556\n",
      "==========================================================================================\n",
      "Epoch [2839/5000] | Time: 0.32s\n",
      "(Training) Loss: 915246.5635\n",
      "(Validation) Loss: 731790.9606, MAE: 3189.8137, R2: 0.2557\n",
      "==========================================================================================\n",
      "Epoch [2840/5000] | Time: 0.37s\n",
      "(Training) Loss: 911348.9740\n",
      "(Validation) Loss: 731714.4565, MAE: 3191.5183, R2: 0.2558\n",
      "==========================================================================================\n",
      "Epoch [2841/5000] | Time: 0.39s\n",
      "(Training) Loss: 916716.7202\n",
      "(Validation) Loss: 731623.8825, MAE: 3190.7864, R2: 0.2559\n",
      "==========================================================================================\n",
      "Epoch [2842/5000] | Time: 0.39s\n",
      "(Training) Loss: 913370.9943\n",
      "(Validation) Loss: 731614.4590, MAE: 3198.2527, R2: 0.2559\n",
      "==========================================================================================\n",
      "Epoch [2843/5000] | Time: 0.34s\n",
      "(Training) Loss: 911758.4416\n",
      "(Validation) Loss: 731536.1054, MAE: 3200.6257, R2: 0.2560\n",
      "==========================================================================================\n",
      "Epoch [2844/5000] | Time: 0.31s\n",
      "(Training) Loss: 914293.7786\n",
      "(Validation) Loss: 731444.8032, MAE: 3198.4961, R2: 0.2561\n",
      "==========================================================================================\n",
      "Epoch [2845/5000] | Time: 0.31s\n",
      "(Training) Loss: 903616.6015\n",
      "(Validation) Loss: 731362.0806, MAE: 3198.8994, R2: 0.2562\n",
      "==========================================================================================\n",
      "Epoch [2846/5000] | Time: 0.32s\n",
      "(Training) Loss: 911508.8890\n",
      "(Validation) Loss: 731283.8502, MAE: 3199.0930, R2: 0.2562\n",
      "==========================================================================================\n",
      "Epoch [2847/5000] | Time: 0.31s\n",
      "(Training) Loss: 924217.3756\n",
      "(Validation) Loss: 731202.5359, MAE: 3200.3696, R2: 0.2563\n",
      "==========================================================================================\n",
      "Epoch [2848/5000] | Time: 0.31s\n",
      "(Training) Loss: 902824.6031\n",
      "(Validation) Loss: 731111.1702, MAE: 3196.7996, R2: 0.2564\n",
      "==========================================================================================\n",
      "Epoch [2849/5000] | Time: 0.37s\n",
      "(Training) Loss: 912144.2709\n",
      "(Validation) Loss: 731020.5854, MAE: 3196.2451, R2: 0.2565\n",
      "==========================================================================================\n",
      "Epoch [2850/5000] | Time: 0.37s\n",
      "(Training) Loss: 905995.8287\n",
      "(Validation) Loss: 730937.7232, MAE: 3196.2424, R2: 0.2566\n",
      "==========================================================================================\n",
      "Epoch [2851/5000] | Time: 0.33s\n",
      "(Training) Loss: 906189.0216\n",
      "(Validation) Loss: 730858.9041, MAE: 3196.2917, R2: 0.2567\n",
      "==========================================================================================\n",
      "Epoch [2852/5000] | Time: 0.38s\n",
      "(Training) Loss: 906025.5882\n",
      "(Validation) Loss: 730775.2502, MAE: 3196.1948, R2: 0.2567\n",
      "==========================================================================================\n",
      "Epoch [2853/5000] | Time: 0.33s\n",
      "(Training) Loss: 901424.4705\n",
      "(Validation) Loss: 730699.0737, MAE: 3198.3523, R2: 0.2568\n",
      "==========================================================================================\n",
      "Epoch [2854/5000] | Time: 0.33s\n",
      "(Training) Loss: 922749.0247\n",
      "(Validation) Loss: 730613.4990, MAE: 3195.9626, R2: 0.2569\n",
      "==========================================================================================\n",
      "Epoch [2855/5000] | Time: 0.32s\n",
      "(Training) Loss: 908436.9346\n",
      "(Validation) Loss: 730536.7930, MAE: 3197.4690, R2: 0.2570\n",
      "==========================================================================================\n",
      "Epoch [2856/5000] | Time: 0.31s\n",
      "(Training) Loss: 910324.3680\n",
      "(Validation) Loss: 730450.2622, MAE: 3197.0625, R2: 0.2571\n",
      "==========================================================================================\n",
      "Epoch [2857/5000] | Time: 0.32s\n",
      "(Training) Loss: 902578.8947\n",
      "(Validation) Loss: 730375.1422, MAE: 3199.7703, R2: 0.2572\n",
      "==========================================================================================\n",
      "Epoch [2858/5000] | Time: 0.34s\n",
      "(Training) Loss: 901449.9854\n",
      "(Validation) Loss: 730283.4540, MAE: 3196.3521, R2: 0.2572\n",
      "==========================================================================================\n",
      "Epoch [2859/5000] | Time: 0.33s\n",
      "(Training) Loss: 935095.5996\n",
      "(Validation) Loss: 730201.4368, MAE: 3195.5498, R2: 0.2573\n",
      "==========================================================================================\n",
      "Epoch [2860/5000] | Time: 0.36s\n",
      "(Training) Loss: 905083.2944\n",
      "(Validation) Loss: 730122.9924, MAE: 3198.2512, R2: 0.2574\n",
      "==========================================================================================\n",
      "Epoch [2861/5000] | Time: 0.32s\n",
      "(Training) Loss: 907466.4651\n",
      "(Validation) Loss: 730035.0146, MAE: 3197.2766, R2: 0.2575\n",
      "==========================================================================================\n",
      "Epoch [2862/5000] | Time: 0.32s\n",
      "(Training) Loss: 904751.9235\n",
      "(Validation) Loss: 745659.1714, MAE: 3260.7893, R2: 0.2417\n",
      "==========================================================================================\n",
      "Epoch [2863/5000] | Time: 0.33s\n",
      "(Training) Loss: 934456.5730\n",
      "(Validation) Loss: 745502.3448, MAE: 3245.4272, R2: 0.2419\n",
      "==========================================================================================\n",
      "Epoch [2864/5000] | Time: 0.41s\n",
      "(Training) Loss: 928460.6174\n",
      "(Validation) Loss: 745412.9257, MAE: 3245.6255, R2: 0.2420\n",
      "==========================================================================================\n",
      "Epoch [2865/5000] | Time: 0.38s\n",
      "(Training) Loss: 936020.1561\n",
      "(Validation) Loss: 745324.0152, MAE: 3244.1572, R2: 0.2421\n",
      "==========================================================================================\n",
      "Epoch [2866/5000] | Time: 0.40s\n",
      "(Training) Loss: 930855.7830\n",
      "(Validation) Loss: 745238.4895, MAE: 3244.9917, R2: 0.2422\n",
      "==========================================================================================\n",
      "Epoch [2867/5000] | Time: 0.36s\n",
      "(Training) Loss: 935901.1669\n",
      "(Validation) Loss: 745161.8933, MAE: 3246.7180, R2: 0.2422\n",
      "==========================================================================================\n",
      "Epoch [2868/5000] | Time: 0.33s\n",
      "(Training) Loss: 926097.3531\n",
      "(Validation) Loss: 745060.1740, MAE: 3243.4304, R2: 0.2423\n",
      "==========================================================================================\n",
      "Epoch [2869/5000] | Time: 0.33s\n",
      "(Training) Loss: 942829.3058\n",
      "(Validation) Loss: 744971.9206, MAE: 3242.5178, R2: 0.2424\n",
      "==========================================================================================\n",
      "Epoch [2870/5000] | Time: 0.34s\n",
      "(Training) Loss: 922843.6935\n",
      "(Validation) Loss: 744886.8692, MAE: 3243.0461, R2: 0.2425\n",
      "==========================================================================================\n",
      "Epoch [2871/5000] | Time: 0.35s\n",
      "(Training) Loss: 929862.8699\n",
      "(Validation) Loss: 744799.0857, MAE: 3241.8342, R2: 0.2426\n",
      "==========================================================================================\n",
      "Epoch [2872/5000] | Time: 0.33s\n",
      "(Training) Loss: 940025.4746\n",
      "(Validation) Loss: 744714.0616, MAE: 3243.1472, R2: 0.2427\n",
      "==========================================================================================\n",
      "Epoch [2873/5000] | Time: 0.30s\n",
      "(Training) Loss: 933039.6510\n",
      "(Validation) Loss: 744637.5530, MAE: 3244.7017, R2: 0.2428\n",
      "==========================================================================================\n",
      "Epoch [2874/5000] | Time: 0.33s\n",
      "(Training) Loss: 924192.5057\n",
      "(Validation) Loss: 744537.1200, MAE: 3241.1594, R2: 0.2429\n",
      "==========================================================================================\n",
      "Epoch [2875/5000] | Time: 0.34s\n",
      "(Training) Loss: 920625.9924\n",
      "(Validation) Loss: 742117.7689, MAE: 3233.0032, R2: 0.2453\n",
      "==========================================================================================\n",
      "Epoch [2876/5000] | Time: 0.32s\n",
      "(Training) Loss: 914590.7123\n",
      "(Validation) Loss: 742040.4825, MAE: 3235.0688, R2: 0.2454\n",
      "==========================================================================================\n",
      "Epoch [2877/5000] | Time: 0.31s\n",
      "(Training) Loss: 921938.3033\n",
      "(Validation) Loss: 741965.1429, MAE: 3234.8169, R2: 0.2455\n",
      "==========================================================================================\n",
      "Epoch [2878/5000] | Time: 0.37s\n",
      "(Training) Loss: 929983.4346\n",
      "(Validation) Loss: 741877.0508, MAE: 3232.9502, R2: 0.2456\n",
      "==========================================================================================\n",
      "Epoch [2879/5000] | Time: 0.32s\n",
      "(Training) Loss: 931172.1846\n",
      "(Validation) Loss: 741786.8216, MAE: 3231.4851, R2: 0.2456\n",
      "==========================================================================================\n",
      "Epoch [2880/5000] | Time: 0.33s\n",
      "(Training) Loss: 937543.4924\n",
      "(Validation) Loss: 741701.9187, MAE: 3230.6772, R2: 0.2457\n",
      "==========================================================================================\n",
      "Epoch [2881/5000] | Time: 0.33s\n",
      "(Training) Loss: 926499.4816\n",
      "(Validation) Loss: 741622.3644, MAE: 3231.4050, R2: 0.2458\n",
      "==========================================================================================\n",
      "Epoch [2882/5000] | Time: 0.34s\n",
      "(Training) Loss: 916423.2608\n",
      "(Validation) Loss: 741534.9327, MAE: 3230.4495, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [2883/5000] | Time: 0.34s\n",
      "(Training) Loss: 928775.7843\n",
      "(Validation) Loss: 741466.7175, MAE: 3233.2590, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [2884/5000] | Time: 0.32s\n",
      "(Training) Loss: 941347.0041\n",
      "(Validation) Loss: 741390.1035, MAE: 3233.7561, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [2885/5000] | Time: 0.33s\n",
      "(Training) Loss: 922342.7544\n",
      "(Validation) Loss: 741302.0406, MAE: 3232.4517, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [2886/5000] | Time: 0.35s\n",
      "(Training) Loss: 922467.7766\n",
      "(Validation) Loss: 741222.5397, MAE: 3232.1631, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [2887/5000] | Time: 0.35s\n",
      "(Training) Loss: 931849.3236\n",
      "(Validation) Loss: 741132.5448, MAE: 3231.1172, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [2888/5000] | Time: 0.34s\n",
      "(Training) Loss: 929081.7995\n",
      "(Validation) Loss: 741035.8838, MAE: 3228.3342, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [2889/5000] | Time: 0.33s\n",
      "(Training) Loss: 933930.7284\n",
      "(Validation) Loss: 740956.4216, MAE: 3228.3657, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [2890/5000] | Time: 0.33s\n",
      "(Training) Loss: 934057.9962\n",
      "(Validation) Loss: 740875.8870, MAE: 3229.3850, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [2891/5000] | Time: 0.31s\n",
      "(Training) Loss: 923619.7348\n",
      "(Validation) Loss: 740808.2019, MAE: 3231.7734, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [2892/5000] | Time: 0.32s\n",
      "(Training) Loss: 925650.9511\n",
      "(Validation) Loss: 740715.4298, MAE: 3228.9844, R2: 0.2467\n",
      "==========================================================================================\n",
      "Epoch [2893/5000] | Time: 0.32s\n",
      "(Training) Loss: 917337.6418\n",
      "(Validation) Loss: 740623.3657, MAE: 3227.7202, R2: 0.2468\n",
      "==========================================================================================\n",
      "Epoch [2894/5000] | Time: 0.31s\n",
      "(Training) Loss: 912619.4852\n",
      "(Validation) Loss: 740540.1435, MAE: 3226.7717, R2: 0.2469\n",
      "==========================================================================================\n",
      "Epoch [2895/5000] | Time: 0.34s\n",
      "(Training) Loss: 928775.9670\n",
      "(Validation) Loss: 740460.4730, MAE: 3228.8877, R2: 0.2470\n",
      "==========================================================================================\n",
      "Epoch [2896/5000] | Time: 0.32s\n",
      "(Training) Loss: 915342.6834\n",
      "(Validation) Loss: 740380.0114, MAE: 3228.1572, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [2897/5000] | Time: 0.39s\n",
      "(Training) Loss: 922892.8445\n",
      "(Validation) Loss: 740297.6165, MAE: 3227.3079, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [2898/5000] | Time: 0.37s\n",
      "(Training) Loss: 921620.0247\n",
      "(Validation) Loss: 740213.3638, MAE: 3226.1472, R2: 0.2472\n",
      "==========================================================================================\n",
      "Epoch [2899/5000] | Time: 0.34s\n",
      "(Training) Loss: 948238.9213\n",
      "(Validation) Loss: 740147.8070, MAE: 3228.7456, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [2900/5000] | Time: 0.34s\n",
      "(Training) Loss: 921984.4105\n",
      "(Validation) Loss: 740057.8444, MAE: 3227.9702, R2: 0.2474\n",
      "==========================================================================================\n",
      "Epoch [2901/5000] | Time: 0.33s\n",
      "(Training) Loss: 932337.9994\n",
      "(Validation) Loss: 739966.8686, MAE: 3225.7830, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [2902/5000] | Time: 0.32s\n",
      "(Training) Loss: 937659.8687\n",
      "(Validation) Loss: 739890.6356, MAE: 3227.0359, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [2903/5000] | Time: 0.31s\n",
      "(Training) Loss: 917891.0422\n",
      "(Validation) Loss: 739808.2851, MAE: 3226.9375, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [2904/5000] | Time: 0.35s\n",
      "(Training) Loss: 924350.9372\n",
      "(Validation) Loss: 739731.0159, MAE: 3226.9553, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [2905/5000] | Time: 0.35s\n",
      "(Training) Loss: 919276.6504\n",
      "(Validation) Loss: 739645.8508, MAE: 3226.3174, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [2906/5000] | Time: 0.35s\n",
      "(Training) Loss: 919684.1516\n",
      "(Validation) Loss: 739551.9543, MAE: 3224.1099, R2: 0.2479\n",
      "==========================================================================================\n",
      "Epoch [2907/5000] | Time: 0.34s\n",
      "(Training) Loss: 922867.2627\n",
      "(Validation) Loss: 739475.9232, MAE: 3225.3074, R2: 0.2480\n",
      "==========================================================================================\n",
      "Epoch [2908/5000] | Time: 0.36s\n",
      "(Training) Loss: 911130.2688\n",
      "(Validation) Loss: 739389.0425, MAE: 3223.6047, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [2909/5000] | Time: 0.35s\n",
      "(Training) Loss: 931541.8725\n",
      "(Validation) Loss: 739309.0660, MAE: 3223.7493, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [2910/5000] | Time: 0.33s\n",
      "(Training) Loss: 916376.2157\n",
      "(Validation) Loss: 739222.3346, MAE: 3222.7200, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [2911/5000] | Time: 0.33s\n",
      "(Training) Loss: 931288.6237\n",
      "(Validation) Loss: 739152.0070, MAE: 3224.4790, R2: 0.2483\n",
      "==========================================================================================\n",
      "Epoch [2912/5000] | Time: 0.34s\n",
      "(Training) Loss: 930149.0241\n",
      "(Validation) Loss: 739079.4444, MAE: 3226.7053, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [2913/5000] | Time: 0.37s\n",
      "(Training) Loss: 920178.3090\n",
      "(Validation) Loss: 738993.7822, MAE: 3225.6716, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [2914/5000] | Time: 0.32s\n",
      "(Training) Loss: 926451.7094\n",
      "(Validation) Loss: 738901.8489, MAE: 3223.1614, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [2915/5000] | Time: 0.31s\n",
      "(Training) Loss: 919271.2690\n",
      "(Validation) Loss: 738820.1276, MAE: 3222.4485, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [2916/5000] | Time: 0.31s\n",
      "(Training) Loss: 919376.7931\n",
      "(Validation) Loss: 738730.5644, MAE: 3220.6208, R2: 0.2487\n",
      "==========================================================================================\n",
      "Epoch [2917/5000] | Time: 0.33s\n",
      "(Training) Loss: 920545.8928\n",
      "(Validation) Loss: 738654.5086, MAE: 3222.0247, R2: 0.2488\n",
      "==========================================================================================\n",
      "Epoch [2918/5000] | Time: 0.32s\n",
      "(Training) Loss: 936480.7551\n",
      "(Validation) Loss: 738593.3333, MAE: 3224.2974, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [2919/5000] | Time: 0.34s\n",
      "(Training) Loss: 912939.8293\n",
      "(Validation) Loss: 738496.5816, MAE: 3222.9939, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [2920/5000] | Time: 0.31s\n",
      "(Training) Loss: 933356.9391\n",
      "(Validation) Loss: 738430.8152, MAE: 3225.4800, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [2921/5000] | Time: 0.29s\n",
      "(Training) Loss: 916481.9664\n",
      "(Validation) Loss: 738326.3194, MAE: 3221.7185, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [2922/5000] | Time: 0.30s\n",
      "(Training) Loss: 919137.5838\n",
      "(Validation) Loss: 738245.2838, MAE: 3221.4473, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [2923/5000] | Time: 0.30s\n",
      "(Training) Loss: 923777.2855\n",
      "(Validation) Loss: 738160.0483, MAE: 3219.6118, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [2924/5000] | Time: 0.33s\n",
      "(Training) Loss: 921583.0641\n",
      "(Validation) Loss: 738078.7562, MAE: 3219.9861, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [2925/5000] | Time: 0.33s\n",
      "(Training) Loss: 931485.4423\n",
      "(Validation) Loss: 737993.0102, MAE: 3218.8464, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [2926/5000] | Time: 0.31s\n",
      "(Training) Loss: 937056.7316\n",
      "(Validation) Loss: 737913.7130, MAE: 3219.5720, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [2927/5000] | Time: 0.35s\n",
      "(Training) Loss: 918652.0749\n",
      "(Validation) Loss: 737850.7962, MAE: 3222.8184, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [2928/5000] | Time: 0.34s\n",
      "(Training) Loss: 926586.3452\n",
      "(Validation) Loss: 737750.0089, MAE: 3218.7495, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [2929/5000] | Time: 0.34s\n",
      "(Training) Loss: 940390.3433\n",
      "(Validation) Loss: 737669.8902, MAE: 3219.1392, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [2930/5000] | Time: 0.34s\n",
      "(Training) Loss: 916064.1041\n",
      "(Validation) Loss: 737590.9606, MAE: 3220.6111, R2: 0.2499\n",
      "==========================================================================================\n",
      "Epoch [2931/5000] | Time: 0.32s\n",
      "(Training) Loss: 926406.8820\n",
      "(Validation) Loss: 737507.1778, MAE: 3218.9133, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [2932/5000] | Time: 0.37s\n",
      "(Training) Loss: 924360.9169\n",
      "(Validation) Loss: 737427.2406, MAE: 3218.5430, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [2933/5000] | Time: 0.32s\n",
      "(Training) Loss: 922159.2735\n",
      "(Validation) Loss: 737250.7632, MAE: 3211.8911, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [2934/5000] | Time: 0.32s\n",
      "(Training) Loss: 910626.1424\n",
      "(Validation) Loss: 737170.6000, MAE: 3211.9236, R2: 0.2503\n",
      "==========================================================================================\n",
      "Epoch [2935/5000] | Time: 0.32s\n",
      "(Training) Loss: 927107.4251\n",
      "(Validation) Loss: 737092.3930, MAE: 3212.1711, R2: 0.2504\n",
      "==========================================================================================\n",
      "Epoch [2936/5000] | Time: 0.33s\n",
      "(Training) Loss: 916345.8033\n",
      "(Validation) Loss: 737012.3302, MAE: 3212.4753, R2: 0.2505\n",
      "==========================================================================================\n",
      "Epoch [2937/5000] | Time: 0.32s\n",
      "(Training) Loss: 925122.9143\n",
      "(Validation) Loss: 736947.7422, MAE: 3214.1279, R2: 0.2505\n",
      "==========================================================================================\n",
      "Epoch [2938/5000] | Time: 0.33s\n",
      "(Training) Loss: 924276.3211\n",
      "(Validation) Loss: 736856.5803, MAE: 3211.7493, R2: 0.2506\n",
      "==========================================================================================\n",
      "Epoch [2939/5000] | Time: 0.34s\n",
      "(Training) Loss: 920702.6681\n",
      "(Validation) Loss: 736781.6794, MAE: 3211.9673, R2: 0.2507\n",
      "==========================================================================================\n",
      "Epoch [2940/5000] | Time: 0.32s\n",
      "(Training) Loss: 920973.3642\n",
      "(Validation) Loss: 736771.3765, MAE: 3215.8540, R2: 0.2507\n",
      "==========================================================================================\n",
      "Epoch [2941/5000] | Time: 0.33s\n",
      "(Training) Loss: 926277.8712\n",
      "(Validation) Loss: 736672.9689, MAE: 3211.7520, R2: 0.2508\n",
      "==========================================================================================\n",
      "Epoch [2942/5000] | Time: 0.36s\n",
      "(Training) Loss: 927111.0635\n",
      "(Validation) Loss: 736585.4076, MAE: 3210.4260, R2: 0.2509\n",
      "==========================================================================================\n",
      "Epoch [2943/5000] | Time: 0.32s\n",
      "(Training) Loss: 929306.9245\n",
      "(Validation) Loss: 736511.7143, MAE: 3211.7766, R2: 0.2510\n",
      "==========================================================================================\n",
      "Epoch [2944/5000] | Time: 0.47s\n",
      "(Training) Loss: 913242.6548\n",
      "(Validation) Loss: 736422.1359, MAE: 3209.7039, R2: 0.2511\n",
      "==========================================================================================\n",
      "Epoch [2945/5000] | Time: 0.48s\n",
      "(Training) Loss: 909036.7327\n",
      "(Validation) Loss: 736354.4394, MAE: 3212.4548, R2: 0.2511\n",
      "==========================================================================================\n",
      "Epoch [2946/5000] | Time: 0.40s\n",
      "(Training) Loss: 909804.1605\n",
      "(Validation) Loss: 736273.5149, MAE: 3212.3882, R2: 0.2512\n",
      "==========================================================================================\n",
      "Epoch [2947/5000] | Time: 0.42s\n",
      "(Training) Loss: 920316.7957\n",
      "(Validation) Loss: 736198.9771, MAE: 3212.2222, R2: 0.2513\n",
      "==========================================================================================\n",
      "Epoch [2948/5000] | Time: 0.42s\n",
      "(Training) Loss: 930268.4067\n",
      "(Validation) Loss: 736126.5346, MAE: 3216.6851, R2: 0.2514\n",
      "==========================================================================================\n",
      "Epoch [2949/5000] | Time: 0.45s\n",
      "(Training) Loss: 922516.2525\n",
      "(Validation) Loss: 736005.0292, MAE: 3206.5547, R2: 0.2515\n",
      "==========================================================================================\n",
      "Epoch [2950/5000] | Time: 0.43s\n",
      "(Training) Loss: 914400.3382\n",
      "(Validation) Loss: 735920.3683, MAE: 3206.3318, R2: 0.2516\n",
      "==========================================================================================\n",
      "Epoch [2951/5000] | Time: 0.46s\n",
      "(Training) Loss: 916340.3115\n",
      "(Validation) Loss: 735835.1549, MAE: 3203.9126, R2: 0.2516\n",
      "==========================================================================================\n",
      "Epoch [2952/5000] | Time: 0.39s\n",
      "(Training) Loss: 917635.1675\n",
      "(Validation) Loss: 735758.6044, MAE: 3205.2974, R2: 0.2517\n",
      "==========================================================================================\n",
      "Epoch [2953/5000] | Time: 0.37s\n",
      "(Training) Loss: 929061.9334\n",
      "(Validation) Loss: 735680.6584, MAE: 3205.2769, R2: 0.2518\n",
      "==========================================================================================\n",
      "Epoch [2954/5000] | Time: 0.40s\n",
      "(Training) Loss: 906828.9326\n",
      "(Validation) Loss: 735604.2794, MAE: 3205.7810, R2: 0.2519\n",
      "==========================================================================================\n",
      "Epoch [2955/5000] | Time: 0.40s\n",
      "(Training) Loss: 917244.3585\n",
      "(Validation) Loss: 735535.3683, MAE: 3208.8013, R2: 0.2520\n",
      "==========================================================================================\n",
      "Epoch [2956/5000] | Time: 0.40s\n",
      "(Training) Loss: 907303.8636\n",
      "(Validation) Loss: 735429.1867, MAE: 3201.5356, R2: 0.2521\n",
      "==========================================================================================\n",
      "Epoch [2957/5000] | Time: 0.46s\n",
      "(Training) Loss: 918548.6954\n",
      "(Validation) Loss: 735362.3822, MAE: 3200.7419, R2: 0.2521\n",
      "==========================================================================================\n",
      "Epoch [2958/5000] | Time: 0.41s\n",
      "(Training) Loss: 925203.6358\n",
      "(Validation) Loss: 735268.2311, MAE: 3193.1169, R2: 0.2522\n",
      "==========================================================================================\n",
      "Epoch [2959/5000] | Time: 0.36s\n",
      "(Training) Loss: 923216.2227\n",
      "(Validation) Loss: 735164.7263, MAE: 3188.7622, R2: 0.2523\n",
      "==========================================================================================\n",
      "Epoch [2960/5000] | Time: 0.42s\n",
      "(Training) Loss: 928496.7811\n",
      "(Validation) Loss: 735089.9803, MAE: 3188.3110, R2: 0.2524\n",
      "==========================================================================================\n",
      "Epoch [2961/5000] | Time: 0.42s\n",
      "(Training) Loss: 917041.8464\n",
      "(Validation) Loss: 734991.9238, MAE: 3182.5093, R2: 0.2525\n",
      "==========================================================================================\n",
      "Epoch [2962/5000] | Time: 0.42s\n",
      "(Training) Loss: 917856.4074\n",
      "(Validation) Loss: 734918.8432, MAE: 3183.9375, R2: 0.2526\n",
      "==========================================================================================\n",
      "Epoch [2963/5000] | Time: 0.41s\n",
      "(Training) Loss: 919983.7265\n",
      "(Validation) Loss: 734840.9841, MAE: 3184.0869, R2: 0.2526\n",
      "==========================================================================================\n",
      "Epoch [2964/5000] | Time: 0.38s\n",
      "(Training) Loss: 906611.6727\n",
      "(Validation) Loss: 734751.4216, MAE: 3181.4282, R2: 0.2527\n",
      "==========================================================================================\n",
      "Epoch [2965/5000] | Time: 0.41s\n",
      "(Training) Loss: 939731.9784\n",
      "(Validation) Loss: 772163.1213, MAE: 3348.2136, R2: 0.2150\n",
      "==========================================================================================\n",
      "Epoch [2966/5000] | Time: 0.39s\n",
      "(Training) Loss: 964417.4575\n",
      "(Validation) Loss: 772047.7003, MAE: 3336.5254, R2: 0.2152\n",
      "==========================================================================================\n",
      "Epoch [2967/5000] | Time: 0.45s\n",
      "(Training) Loss: 950582.3509\n",
      "(Validation) Loss: 771944.8737, MAE: 3332.4609, R2: 0.2153\n",
      "==========================================================================================\n",
      "Epoch [2968/5000] | Time: 0.37s\n",
      "(Training) Loss: 968317.3826\n",
      "(Validation) Loss: 771843.4025, MAE: 3329.0911, R2: 0.2154\n",
      "==========================================================================================\n",
      "Epoch [2969/5000] | Time: 0.37s\n",
      "(Training) Loss: 947907.1955\n",
      "(Validation) Loss: 771750.5276, MAE: 3328.8108, R2: 0.2155\n",
      "==========================================================================================\n",
      "Epoch [2970/5000] | Time: 0.40s\n",
      "(Training) Loss: 965664.9169\n",
      "(Validation) Loss: 771642.5829, MAE: 3320.4797, R2: 0.2156\n",
      "==========================================================================================\n",
      "Epoch [2971/5000] | Time: 0.38s\n",
      "(Training) Loss: 979605.5438\n",
      "(Validation) Loss: 771548.0711, MAE: 3320.5149, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [2972/5000] | Time: 0.38s\n",
      "(Training) Loss: 972268.9467\n",
      "(Validation) Loss: 771453.2444, MAE: 3319.2019, R2: 0.2158\n",
      "==========================================================================================\n",
      "Epoch [2973/5000] | Time: 0.41s\n",
      "(Training) Loss: 955679.5146\n",
      "(Validation) Loss: 771356.7067, MAE: 3317.0972, R2: 0.2159\n",
      "==========================================================================================\n",
      "Epoch [2974/5000] | Time: 0.36s\n",
      "(Training) Loss: 971566.7088\n",
      "(Validation) Loss: 771264.9333, MAE: 3313.5244, R2: 0.2159\n",
      "==========================================================================================\n",
      "Epoch [2975/5000] | Time: 0.38s\n",
      "(Training) Loss: 958624.9169\n",
      "(Validation) Loss: 771169.9759, MAE: 3312.8206, R2: 0.2160\n",
      "==========================================================================================\n",
      "Epoch [2976/5000] | Time: 0.40s\n",
      "(Training) Loss: 956668.1504\n",
      "(Validation) Loss: 771073.1175, MAE: 3308.3882, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [2977/5000] | Time: 0.40s\n",
      "(Training) Loss: 971436.3325\n",
      "(Validation) Loss: 770979.9194, MAE: 3305.4094, R2: 0.2162\n",
      "==========================================================================================\n",
      "Epoch [2978/5000] | Time: 0.37s\n",
      "(Training) Loss: 960795.6586\n",
      "(Validation) Loss: 770879.2279, MAE: 3304.4502, R2: 0.2163\n",
      "==========================================================================================\n",
      "Epoch [2979/5000] | Time: 0.39s\n",
      "(Training) Loss: 956340.7246\n",
      "(Validation) Loss: 770788.0394, MAE: 3304.6106, R2: 0.2164\n",
      "==========================================================================================\n",
      "Epoch [2980/5000] | Time: 0.38s\n",
      "(Training) Loss: 966478.3610\n",
      "(Validation) Loss: 770692.7670, MAE: 3301.4675, R2: 0.2165\n",
      "==========================================================================================\n",
      "Epoch [2981/5000] | Time: 0.36s\n",
      "(Training) Loss: 954443.1152\n",
      "(Validation) Loss: 770598.9086, MAE: 3299.4778, R2: 0.2166\n",
      "==========================================================================================\n",
      "Epoch [2982/5000] | Time: 0.35s\n",
      "(Training) Loss: 966780.9175\n",
      "(Validation) Loss: 770549.5714, MAE: 3304.6799, R2: 0.2167\n",
      "==========================================================================================\n",
      "Epoch [2983/5000] | Time: 0.41s\n",
      "(Training) Loss: 955080.7056\n",
      "(Validation) Loss: 770432.4597, MAE: 3299.7844, R2: 0.2168\n",
      "==========================================================================================\n",
      "Epoch [2984/5000] | Time: 0.39s\n",
      "(Training) Loss: 962480.7874\n",
      "(Validation) Loss: 770337.0844, MAE: 3298.4294, R2: 0.2169\n",
      "==========================================================================================\n",
      "Epoch [2985/5000] | Time: 0.35s\n",
      "(Training) Loss: 945490.5013\n",
      "(Validation) Loss: 759038.5244, MAE: 3256.2996, R2: 0.2283\n",
      "==========================================================================================\n",
      "Epoch [2986/5000] | Time: 0.34s\n",
      "(Training) Loss: 939899.7405\n",
      "(Validation) Loss: 758939.0933, MAE: 3255.8936, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [2987/5000] | Time: 0.32s\n",
      "(Training) Loss: 934771.8488\n",
      "(Validation) Loss: 758853.9029, MAE: 3258.0657, R2: 0.2284\n",
      "==========================================================================================\n",
      "Epoch [2988/5000] | Time: 0.35s\n",
      "(Training) Loss: 951008.2100\n",
      "(Validation) Loss: 758767.9225, MAE: 3257.3315, R2: 0.2285\n",
      "==========================================================================================\n",
      "Epoch [2989/5000] | Time: 0.38s\n",
      "(Training) Loss: 960182.2510\n",
      "(Validation) Loss: 749128.9467, MAE: 3223.0835, R2: 0.2382\n",
      "==========================================================================================\n",
      "Epoch [2990/5000] | Time: 0.38s\n",
      "(Training) Loss: 931410.0971\n",
      "(Validation) Loss: 749069.9937, MAE: 3227.1599, R2: 0.2383\n",
      "==========================================================================================\n",
      "Epoch [2991/5000] | Time: 0.37s\n",
      "(Training) Loss: 929511.3014\n",
      "(Validation) Loss: 748969.3981, MAE: 3223.3506, R2: 0.2384\n",
      "==========================================================================================\n",
      "Epoch [2992/5000] | Time: 0.37s\n",
      "(Training) Loss: 939042.2168\n",
      "(Validation) Loss: 748915.6844, MAE: 3230.6404, R2: 0.2385\n",
      "==========================================================================================\n",
      "Epoch [2993/5000] | Time: 0.37s\n",
      "(Training) Loss: 931607.1383\n",
      "(Validation) Loss: 748813.8737, MAE: 3226.6123, R2: 0.2386\n",
      "==========================================================================================\n",
      "Epoch [2994/5000] | Time: 0.37s\n",
      "(Training) Loss: 940946.7297\n",
      "(Validation) Loss: 748711.1276, MAE: 3222.0183, R2: 0.2387\n",
      "==========================================================================================\n",
      "Epoch [2995/5000] | Time: 0.40s\n",
      "(Training) Loss: 943943.4860\n",
      "(Validation) Loss: 748637.0470, MAE: 3223.2070, R2: 0.2387\n",
      "==========================================================================================\n",
      "Epoch [2996/5000] | Time: 0.40s\n",
      "(Training) Loss: 922770.6315\n",
      "(Validation) Loss: 748545.9206, MAE: 3222.3030, R2: 0.2388\n",
      "==========================================================================================\n",
      "Epoch [2997/5000] | Time: 0.39s\n",
      "(Training) Loss: 940831.8001\n",
      "(Validation) Loss: 748462.5460, MAE: 3219.8291, R2: 0.2389\n",
      "==========================================================================================\n",
      "Epoch [2998/5000] | Time: 0.41s\n",
      "(Training) Loss: 940275.0584\n",
      "(Validation) Loss: 748375.9225, MAE: 3220.1123, R2: 0.2390\n",
      "==========================================================================================\n",
      "Epoch [2999/5000] | Time: 0.40s\n",
      "(Training) Loss: 924951.2944\n",
      "(Validation) Loss: 748287.7867, MAE: 3218.7063, R2: 0.2391\n",
      "==========================================================================================\n",
      "Epoch [3000/5000] | Time: 0.38s\n",
      "(Training) Loss: 947138.9207\n",
      "(Validation) Loss: 748236.2629, MAE: 3224.1228, R2: 0.2391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch3000.pth\n",
      "==========================================================================================\n",
      "Epoch [3001/5000] | Time: 0.37s\n",
      "(Training) Loss: 929454.1574\n",
      "(Validation) Loss: 748143.9632, MAE: 3221.5325, R2: 0.2392\n",
      "==========================================================================================\n",
      "Epoch [3002/5000] | Time: 0.41s\n",
      "(Training) Loss: 947387.5920\n",
      "(Validation) Loss: 748045.7759, MAE: 3219.6248, R2: 0.2393\n",
      "==========================================================================================\n",
      "Epoch [3003/5000] | Time: 0.41s\n",
      "(Training) Loss: 927837.8376\n",
      "(Validation) Loss: 747970.5651, MAE: 3222.1086, R2: 0.2394\n",
      "==========================================================================================\n",
      "Epoch [3004/5000] | Time: 0.37s\n",
      "(Training) Loss: 940642.8242\n",
      "(Validation) Loss: 747897.6876, MAE: 3222.5222, R2: 0.2395\n",
      "==========================================================================================\n",
      "Epoch [3005/5000] | Time: 0.36s\n",
      "(Training) Loss: 929136.8122\n",
      "(Validation) Loss: 747807.8559, MAE: 3220.0229, R2: 0.2396\n",
      "==========================================================================================\n",
      "Epoch [3006/5000] | Time: 0.38s\n",
      "(Training) Loss: 942440.8832\n",
      "(Validation) Loss: 747715.6990, MAE: 3218.4553, R2: 0.2397\n",
      "==========================================================================================\n",
      "Epoch [3007/5000] | Time: 0.35s\n",
      "(Training) Loss: 926702.1110\n",
      "(Validation) Loss: 747631.3765, MAE: 3218.8755, R2: 0.2398\n",
      "==========================================================================================\n",
      "Epoch [3008/5000] | Time: 0.36s\n",
      "(Training) Loss: 938101.9753\n",
      "(Validation) Loss: 747548.8660, MAE: 3217.4395, R2: 0.2398\n",
      "==========================================================================================\n",
      "Epoch [3009/5000] | Time: 0.34s\n",
      "(Training) Loss: 950091.4619\n",
      "(Validation) Loss: 747455.3537, MAE: 3215.1619, R2: 0.2399\n",
      "==========================================================================================\n",
      "Epoch [3010/5000] | Time: 0.34s\n",
      "(Training) Loss: 925383.4327\n",
      "(Validation) Loss: 747374.5683, MAE: 3217.0786, R2: 0.2400\n",
      "==========================================================================================\n",
      "Epoch [3011/5000] | Time: 0.34s\n",
      "(Training) Loss: 955588.2030\n",
      "(Validation) Loss: 747291.5302, MAE: 3215.5908, R2: 0.2401\n",
      "==========================================================================================\n",
      "Epoch [3012/5000] | Time: 0.33s\n",
      "(Training) Loss: 927228.6028\n",
      "(Validation) Loss: 747207.9689, MAE: 3214.9915, R2: 0.2402\n",
      "==========================================================================================\n",
      "Epoch [3013/5000] | Time: 0.35s\n",
      "(Training) Loss: 924679.6548\n",
      "(Validation) Loss: 747143.8381, MAE: 3215.9238, R2: 0.2402\n",
      "==========================================================================================\n",
      "Epoch [3014/5000] | Time: 0.35s\n",
      "(Training) Loss: 941740.0343\n",
      "(Validation) Loss: 747074.4730, MAE: 3238.6377, R2: 0.2403\n",
      "==========================================================================================\n",
      "Epoch [3015/5000] | Time: 0.35s\n",
      "(Training) Loss: 941006.6174\n",
      "(Validation) Loss: 747005.2451, MAE: 3244.6536, R2: 0.2404\n",
      "==========================================================================================\n",
      "Epoch [3016/5000] | Time: 0.35s\n",
      "(Training) Loss: 925175.5926\n",
      "(Validation) Loss: 746933.9352, MAE: 3246.0366, R2: 0.2405\n",
      "==========================================================================================\n",
      "Epoch [3017/5000] | Time: 0.36s\n",
      "(Training) Loss: 931940.1231\n",
      "(Validation) Loss: 746841.7251, MAE: 3243.6270, R2: 0.2406\n",
      "==========================================================================================\n",
      "Epoch [3018/5000] | Time: 0.36s\n",
      "(Training) Loss: 928673.1624\n",
      "(Validation) Loss: 746763.0489, MAE: 3245.3362, R2: 0.2406\n",
      "==========================================================================================\n",
      "Epoch [3019/5000] | Time: 0.31s\n",
      "(Training) Loss: 932946.9892\n",
      "(Validation) Loss: 746688.9270, MAE: 3245.9373, R2: 0.2407\n",
      "==========================================================================================\n",
      "Epoch [3020/5000] | Time: 0.35s\n",
      "(Training) Loss: 933852.2817\n",
      "(Validation) Loss: 746585.7994, MAE: 3241.4553, R2: 0.2408\n",
      "==========================================================================================\n",
      "Epoch [3021/5000] | Time: 0.32s\n",
      "(Training) Loss: 924911.3515\n",
      "(Validation) Loss: 746514.0876, MAE: 3243.0574, R2: 0.2409\n",
      "==========================================================================================\n",
      "Epoch [3022/5000] | Time: 0.35s\n",
      "(Training) Loss: 934191.3598\n",
      "(Validation) Loss: 746422.1003, MAE: 3241.2927, R2: 0.2410\n",
      "==========================================================================================\n",
      "Epoch [3023/5000] | Time: 0.35s\n",
      "(Training) Loss: 927001.2024\n",
      "(Validation) Loss: 746340.7251, MAE: 3241.4087, R2: 0.2411\n",
      "==========================================================================================\n",
      "Epoch [3024/5000] | Time: 0.38s\n",
      "(Training) Loss: 927840.7849\n",
      "(Validation) Loss: 746254.6229, MAE: 3239.6501, R2: 0.2411\n",
      "==========================================================================================\n",
      "Epoch [3025/5000] | Time: 0.36s\n",
      "(Training) Loss: 933766.2966\n",
      "(Validation) Loss: 746176.5873, MAE: 3240.6604, R2: 0.2412\n",
      "==========================================================================================\n",
      "Epoch [3026/5000] | Time: 0.44s\n",
      "(Training) Loss: 931181.6910\n",
      "(Validation) Loss: 746104.8013, MAE: 3242.5984, R2: 0.2413\n",
      "==========================================================================================\n",
      "Epoch [3027/5000] | Time: 0.40s\n",
      "(Training) Loss: 937866.0228\n",
      "(Validation) Loss: 746035.8476, MAE: 3244.4875, R2: 0.2414\n",
      "==========================================================================================\n",
      "Epoch [3028/5000] | Time: 0.38s\n",
      "(Training) Loss: 931829.3794\n",
      "(Validation) Loss: 745923.7644, MAE: 3238.9563, R2: 0.2415\n",
      "==========================================================================================\n",
      "Epoch [3029/5000] | Time: 0.40s\n",
      "(Training) Loss: 930302.2868\n",
      "(Validation) Loss: 745844.3829, MAE: 3240.7646, R2: 0.2416\n",
      "==========================================================================================\n",
      "Epoch [3030/5000] | Time: 0.48s\n",
      "(Training) Loss: 932993.0102\n",
      "(Validation) Loss: 745764.7683, MAE: 3232.4121, R2: 0.2416\n",
      "==========================================================================================\n",
      "Epoch [3031/5000] | Time: 0.42s\n",
      "(Training) Loss: 925519.6853\n",
      "(Validation) Loss: 745594.9924, MAE: 3220.3235, R2: 0.2418\n",
      "==========================================================================================\n",
      "Epoch [3032/5000] | Time: 0.39s\n",
      "(Training) Loss: 935075.9448\n",
      "(Validation) Loss: 745520.8717, MAE: 3221.9565, R2: 0.2419\n",
      "==========================================================================================\n",
      "Epoch [3033/5000] | Time: 0.42s\n",
      "(Training) Loss: 925989.7659\n",
      "(Validation) Loss: 745377.2673, MAE: 3220.0325, R2: 0.2420\n",
      "==========================================================================================\n",
      "Epoch [3034/5000] | Time: 0.40s\n",
      "(Training) Loss: 925693.8471\n",
      "(Validation) Loss: 745297.6006, MAE: 3219.8855, R2: 0.2421\n",
      "==========================================================================================\n",
      "Epoch [3035/5000] | Time: 0.44s\n",
      "(Training) Loss: 937133.9575\n",
      "(Validation) Loss: 745267.7841, MAE: 3224.9060, R2: 0.2421\n",
      "==========================================================================================\n",
      "Epoch [3036/5000] | Time: 0.38s\n",
      "(Training) Loss: 929300.3807\n",
      "(Validation) Loss: 745185.9994, MAE: 3223.0042, R2: 0.2422\n",
      "==========================================================================================\n",
      "Epoch [3037/5000] | Time: 0.40s\n",
      "(Training) Loss: 922049.8388\n",
      "(Validation) Loss: 745106.3194, MAE: 3221.0203, R2: 0.2423\n",
      "==========================================================================================\n",
      "Epoch [3038/5000] | Time: 0.40s\n",
      "(Training) Loss: 922538.0565\n",
      "(Validation) Loss: 745023.7784, MAE: 3218.8301, R2: 0.2424\n",
      "==========================================================================================\n",
      "Epoch [3039/5000] | Time: 0.40s\n",
      "(Training) Loss: 922640.6666\n",
      "(Validation) Loss: 744934.6190, MAE: 3210.0486, R2: 0.2425\n",
      "==========================================================================================\n",
      "Epoch [3040/5000] | Time: 0.42s\n",
      "(Training) Loss: 926879.2779\n",
      "(Validation) Loss: 744838.2260, MAE: 3205.2822, R2: 0.2426\n",
      "==========================================================================================\n",
      "Epoch [3041/5000] | Time: 0.40s\n",
      "(Training) Loss: 927079.7081\n",
      "(Validation) Loss: 744762.0781, MAE: 3205.8760, R2: 0.2426\n",
      "==========================================================================================\n",
      "Epoch [3042/5000] | Time: 0.41s\n",
      "(Training) Loss: 923333.5470\n",
      "(Validation) Loss: 744633.2133, MAE: 3201.5137, R2: 0.2428\n",
      "==========================================================================================\n",
      "Epoch [3043/5000] | Time: 0.39s\n",
      "(Training) Loss: 931210.1656\n",
      "(Validation) Loss: 744526.7803, MAE: 3197.2026, R2: 0.2429\n",
      "==========================================================================================\n",
      "Epoch [3044/5000] | Time: 0.41s\n",
      "(Training) Loss: 926503.3369\n",
      "(Validation) Loss: 744452.2400, MAE: 3198.1133, R2: 0.2430\n",
      "==========================================================================================\n",
      "Epoch [3045/5000] | Time: 0.40s\n",
      "(Training) Loss: 920609.1329\n",
      "(Validation) Loss: 744366.1232, MAE: 3196.8606, R2: 0.2430\n",
      "==========================================================================================\n",
      "Epoch [3046/5000] | Time: 0.39s\n",
      "(Training) Loss: 923695.6148\n",
      "(Validation) Loss: 744274.1886, MAE: 3194.9915, R2: 0.2431\n",
      "==========================================================================================\n",
      "Epoch [3047/5000] | Time: 0.34s\n",
      "(Training) Loss: 919828.1063\n",
      "(Validation) Loss: 744213.4140, MAE: 3197.6567, R2: 0.2432\n",
      "==========================================================================================\n",
      "Epoch [3048/5000] | Time: 0.34s\n",
      "(Training) Loss: 927678.8775\n",
      "(Validation) Loss: 744186.6756, MAE: 3208.5183, R2: 0.2432\n",
      "==========================================================================================\n",
      "Epoch [3049/5000] | Time: 0.36s\n",
      "(Training) Loss: 939757.4010\n",
      "(Validation) Loss: 746147.3740, MAE: 3207.9971, R2: 0.2413\n",
      "==========================================================================================\n",
      "Epoch [3050/5000] | Time: 0.36s\n",
      "(Training) Loss: 921549.6615\n",
      "(Validation) Loss: 746032.7917, MAE: 3203.6121, R2: 0.2414\n",
      "==========================================================================================\n",
      "Epoch [3051/5000] | Time: 0.37s\n",
      "(Training) Loss: 932610.6482\n",
      "(Validation) Loss: 745945.4432, MAE: 3202.0405, R2: 0.2415\n",
      "==========================================================================================\n",
      "Epoch [3052/5000] | Time: 0.35s\n",
      "(Training) Loss: 930367.3185\n",
      "(Validation) Loss: 745866.3810, MAE: 3202.0591, R2: 0.2415\n",
      "==========================================================================================\n",
      "Epoch [3053/5000] | Time: 0.36s\n",
      "(Training) Loss: 954481.6466\n",
      "(Validation) Loss: 745786.3378, MAE: 3206.0659, R2: 0.2416\n",
      "==========================================================================================\n",
      "Epoch [3054/5000] | Time: 0.36s\n",
      "(Training) Loss: 925691.1469\n",
      "(Validation) Loss: 745939.7733, MAE: 3212.1489, R2: 0.2415\n",
      "==========================================================================================\n",
      "Epoch [3055/5000] | Time: 0.39s\n",
      "(Training) Loss: 930382.2205\n",
      "(Validation) Loss: 745632.5181, MAE: 3211.0996, R2: 0.2418\n",
      "==========================================================================================\n",
      "Epoch [3056/5000] | Time: 0.39s\n",
      "(Training) Loss: 920721.9978\n",
      "(Validation) Loss: 745541.1397, MAE: 3208.9102, R2: 0.2419\n",
      "==========================================================================================\n",
      "Epoch [3057/5000] | Time: 0.37s\n",
      "(Training) Loss: 920173.0593\n",
      "(Validation) Loss: 745460.6305, MAE: 3216.4609, R2: 0.2419\n",
      "==========================================================================================\n",
      "Epoch [3058/5000] | Time: 0.40s\n",
      "(Training) Loss: 938727.1148\n",
      "(Validation) Loss: 745378.7549, MAE: 3217.0991, R2: 0.2420\n",
      "==========================================================================================\n",
      "Epoch [3059/5000] | Time: 0.37s\n",
      "(Training) Loss: 944609.1123\n",
      "(Validation) Loss: 745299.2603, MAE: 3210.4458, R2: 0.2421\n",
      "==========================================================================================\n",
      "Epoch [3060/5000] | Time: 0.38s\n",
      "(Training) Loss: 931861.1726\n",
      "(Validation) Loss: 745204.4451, MAE: 3204.0112, R2: 0.2422\n",
      "==========================================================================================\n",
      "Epoch [3061/5000] | Time: 0.40s\n",
      "(Training) Loss: 937482.2576\n",
      "(Validation) Loss: 745136.2698, MAE: 3207.4990, R2: 0.2423\n",
      "==========================================================================================\n",
      "Epoch [3062/5000] | Time: 0.41s\n",
      "(Training) Loss: 952953.4251\n",
      "(Validation) Loss: 745039.9086, MAE: 3208.7202, R2: 0.2424\n",
      "==========================================================================================\n",
      "Epoch [3063/5000] | Time: 0.38s\n",
      "(Training) Loss: 925968.8836\n",
      "(Validation) Loss: 744965.4717, MAE: 3207.2910, R2: 0.2424\n",
      "==========================================================================================\n",
      "Epoch [3064/5000] | Time: 0.37s\n",
      "(Training) Loss: 918328.4308\n",
      "(Validation) Loss: 744870.6025, MAE: 3204.4199, R2: 0.2425\n",
      "==========================================================================================\n",
      "Epoch [3065/5000] | Time: 0.37s\n",
      "(Training) Loss: 919803.8760\n",
      "(Validation) Loss: 744793.4724, MAE: 3203.2529, R2: 0.2426\n",
      "==========================================================================================\n",
      "Epoch [3066/5000] | Time: 0.37s\n",
      "(Training) Loss: 935153.5162\n",
      "(Validation) Loss: 744703.7670, MAE: 3200.4312, R2: 0.2427\n",
      "==========================================================================================\n",
      "Epoch [3067/5000] | Time: 0.36s\n",
      "(Training) Loss: 923402.0476\n",
      "(Validation) Loss: 744629.7041, MAE: 3201.8545, R2: 0.2428\n",
      "==========================================================================================\n",
      "Epoch [3068/5000] | Time: 0.38s\n",
      "(Training) Loss: 928599.1237\n",
      "(Validation) Loss: 744537.9727, MAE: 3200.4856, R2: 0.2429\n",
      "==========================================================================================\n",
      "Epoch [3069/5000] | Time: 0.35s\n",
      "(Training) Loss: 926758.4772\n",
      "(Validation) Loss: 744468.1098, MAE: 3202.3110, R2: 0.2429\n",
      "==========================================================================================\n",
      "Epoch [3070/5000] | Time: 0.36s\n",
      "(Training) Loss: 942292.7392\n",
      "(Validation) Loss: 744382.4584, MAE: 3200.9502, R2: 0.2430\n",
      "==========================================================================================\n",
      "Epoch [3071/5000] | Time: 0.37s\n",
      "(Training) Loss: 919792.6066\n",
      "(Validation) Loss: 744296.3911, MAE: 3199.7190, R2: 0.2431\n",
      "==========================================================================================\n",
      "Epoch [3072/5000] | Time: 0.37s\n",
      "(Training) Loss: 924939.2278\n",
      "(Validation) Loss: 744206.4952, MAE: 3199.4368, R2: 0.2432\n",
      "==========================================================================================\n",
      "Epoch [3073/5000] | Time: 0.38s\n",
      "(Training) Loss: 938796.5025\n",
      "(Validation) Loss: 744130.3683, MAE: 3199.2126, R2: 0.2433\n",
      "==========================================================================================\n",
      "Epoch [3074/5000] | Time: 0.36s\n",
      "(Training) Loss: 944993.5051\n",
      "(Validation) Loss: 744045.9175, MAE: 3200.7114, R2: 0.2434\n",
      "==========================================================================================\n",
      "Epoch [3075/5000] | Time: 0.33s\n",
      "(Training) Loss: 925626.8794\n",
      "(Validation) Loss: 743961.2902, MAE: 3198.7263, R2: 0.2435\n",
      "==========================================================================================\n",
      "Epoch [3076/5000] | Time: 0.33s\n",
      "(Training) Loss: 926160.3350\n",
      "(Validation) Loss: 743880.8889, MAE: 3199.3203, R2: 0.2435\n",
      "==========================================================================================\n",
      "Epoch [3077/5000] | Time: 0.38s\n",
      "(Training) Loss: 917673.3374\n",
      "(Validation) Loss: 743799.0787, MAE: 3199.2698, R2: 0.2436\n",
      "==========================================================================================\n",
      "Epoch [3078/5000] | Time: 0.37s\n",
      "(Training) Loss: 947904.9464\n",
      "(Validation) Loss: 743713.7606, MAE: 3197.3848, R2: 0.2437\n",
      "==========================================================================================\n",
      "Epoch [3079/5000] | Time: 0.36s\n",
      "(Training) Loss: 924871.7265\n",
      "(Validation) Loss: 743643.7035, MAE: 3200.0334, R2: 0.2438\n",
      "==========================================================================================\n",
      "Epoch [3080/5000] | Time: 0.35s\n",
      "(Training) Loss: 928736.6977\n",
      "(Validation) Loss: 743548.3981, MAE: 3198.0339, R2: 0.2439\n",
      "==========================================================================================\n",
      "Epoch [3081/5000] | Time: 0.41s\n",
      "(Training) Loss: 924669.7773\n",
      "(Validation) Loss: 743480.7486, MAE: 3199.5039, R2: 0.2439\n",
      "==========================================================================================\n",
      "Epoch [3082/5000] | Time: 0.36s\n",
      "(Training) Loss: 922713.2671\n",
      "(Validation) Loss: 743422.1308, MAE: 3204.9507, R2: 0.2440\n",
      "==========================================================================================\n",
      "Epoch [3083/5000] | Time: 0.39s\n",
      "(Training) Loss: 931331.5140\n",
      "(Validation) Loss: 743336.9638, MAE: 3202.9666, R2: 0.2441\n",
      "==========================================================================================\n",
      "Epoch [3084/5000] | Time: 0.41s\n",
      "(Training) Loss: 926002.9600\n",
      "(Validation) Loss: 743256.7206, MAE: 3203.4558, R2: 0.2442\n",
      "==========================================================================================\n",
      "Epoch [3085/5000] | Time: 0.39s\n",
      "(Training) Loss: 918876.8195\n",
      "(Validation) Loss: 743144.4298, MAE: 3198.2729, R2: 0.2443\n",
      "==========================================================================================\n",
      "Epoch [3086/5000] | Time: 0.35s\n",
      "(Training) Loss: 929065.3902\n",
      "(Validation) Loss: 743060.9994, MAE: 3196.8987, R2: 0.2444\n",
      "==========================================================================================\n",
      "Epoch [3087/5000] | Time: 0.38s\n",
      "(Training) Loss: 945878.1225\n",
      "(Validation) Loss: 743004.0381, MAE: 3200.8511, R2: 0.2444\n",
      "==========================================================================================\n",
      "Epoch [3088/5000] | Time: 0.35s\n",
      "(Training) Loss: 917736.0920\n",
      "(Validation) Loss: 742917.1302, MAE: 3202.2642, R2: 0.2445\n",
      "==========================================================================================\n",
      "Epoch [3089/5000] | Time: 0.34s\n",
      "(Training) Loss: 939519.8192\n",
      "(Validation) Loss: 742812.5981, MAE: 3196.2656, R2: 0.2446\n",
      "==========================================================================================\n",
      "Epoch [3090/5000] | Time: 0.37s\n",
      "(Training) Loss: 928795.8077\n",
      "(Validation) Loss: 742734.0362, MAE: 3197.1311, R2: 0.2447\n",
      "==========================================================================================\n",
      "Epoch [3091/5000] | Time: 0.34s\n",
      "(Training) Loss: 937648.7728\n",
      "(Validation) Loss: 742645.1765, MAE: 3197.6440, R2: 0.2448\n",
      "==========================================================================================\n",
      "Epoch [3092/5000] | Time: 0.33s\n",
      "(Training) Loss: 925848.4556\n",
      "(Validation) Loss: 742561.0216, MAE: 3194.0945, R2: 0.2449\n",
      "==========================================================================================\n",
      "Epoch [3093/5000] | Time: 0.39s\n",
      "(Training) Loss: 926181.3642\n",
      "(Validation) Loss: 742486.8038, MAE: 3196.1963, R2: 0.2449\n",
      "==========================================================================================\n",
      "Epoch [3094/5000] | Time: 0.39s\n",
      "(Training) Loss: 920778.1104\n",
      "(Validation) Loss: 742402.5054, MAE: 3194.8616, R2: 0.2450\n",
      "==========================================================================================\n",
      "Epoch [3095/5000] | Time: 0.38s\n",
      "(Training) Loss: 931998.1574\n",
      "(Validation) Loss: 742322.3930, MAE: 3194.8894, R2: 0.2451\n",
      "==========================================================================================\n",
      "Epoch [3096/5000] | Time: 0.32s\n",
      "(Training) Loss: 925753.9346\n",
      "(Validation) Loss: 742244.2794, MAE: 3197.6780, R2: 0.2452\n",
      "==========================================================================================\n",
      "Epoch [3097/5000] | Time: 0.34s\n",
      "(Training) Loss: 931433.3953\n",
      "(Validation) Loss: 742154.9346, MAE: 3195.6755, R2: 0.2453\n",
      "==========================================================================================\n",
      "Epoch [3098/5000] | Time: 0.34s\n",
      "(Training) Loss: 937183.7329\n",
      "(Validation) Loss: 742109.0959, MAE: 3205.3455, R2: 0.2453\n",
      "==========================================================================================\n",
      "Epoch [3099/5000] | Time: 0.35s\n",
      "(Training) Loss: 928677.4753\n",
      "(Validation) Loss: 742079.3295, MAE: 3212.5652, R2: 0.2454\n",
      "==========================================================================================\n",
      "Epoch [3100/5000] | Time: 0.34s\n",
      "(Training) Loss: 937396.2919\n",
      "(Validation) Loss: 741989.2032, MAE: 3208.0315, R2: 0.2454\n",
      "==========================================================================================\n",
      "Epoch [3101/5000] | Time: 0.32s\n",
      "(Training) Loss: 942019.1865\n",
      "(Validation) Loss: 741882.9448, MAE: 3205.5352, R2: 0.2455\n",
      "==========================================================================================\n",
      "Epoch [3102/5000] | Time: 0.33s\n",
      "(Training) Loss: 941278.4181\n",
      "(Validation) Loss: 741815.9765, MAE: 3204.3171, R2: 0.2456\n",
      "==========================================================================================\n",
      "Epoch [3103/5000] | Time: 0.34s\n",
      "(Training) Loss: 913780.9578\n",
      "(Validation) Loss: 741723.5200, MAE: 3209.5222, R2: 0.2457\n",
      "==========================================================================================\n",
      "Epoch [3104/5000] | Time: 0.36s\n",
      "(Training) Loss: 928316.0463\n",
      "(Validation) Loss: 741655.4616, MAE: 3206.7505, R2: 0.2458\n",
      "==========================================================================================\n",
      "Epoch [3105/5000] | Time: 0.38s\n",
      "(Training) Loss: 923652.0654\n",
      "(Validation) Loss: 741549.2216, MAE: 3200.0784, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [3106/5000] | Time: 0.38s\n",
      "(Training) Loss: 929142.4676\n",
      "(Validation) Loss: 741482.9035, MAE: 3204.2678, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [3107/5000] | Time: 0.34s\n",
      "(Training) Loss: 939298.8972\n",
      "(Validation) Loss: 741383.6508, MAE: 3200.3762, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [3108/5000] | Time: 0.36s\n",
      "(Training) Loss: 938104.1034\n",
      "(Validation) Loss: 741307.8686, MAE: 3199.7153, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [3109/5000] | Time: 0.36s\n",
      "(Training) Loss: 918494.1536\n",
      "(Validation) Loss: 741222.6914, MAE: 3198.2688, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [3110/5000] | Time: 0.37s\n",
      "(Training) Loss: 940055.5527\n",
      "(Validation) Loss: 741143.5759, MAE: 3199.1309, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [3111/5000] | Time: 0.36s\n",
      "(Training) Loss: 927603.3607\n",
      "(Validation) Loss: 741063.9714, MAE: 3199.2180, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [3112/5000] | Time: 0.33s\n",
      "(Training) Loss: 916398.9686\n",
      "(Validation) Loss: 740973.2546, MAE: 3197.2634, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [3113/5000] | Time: 0.31s\n",
      "(Training) Loss: 920269.5286\n",
      "(Validation) Loss: 740885.7581, MAE: 3195.5771, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [3114/5000] | Time: 0.36s\n",
      "(Training) Loss: 919477.9670\n",
      "(Validation) Loss: 740805.9137, MAE: 3196.6282, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [3115/5000] | Time: 0.32s\n",
      "(Training) Loss: 918868.6098\n",
      "(Validation) Loss: 740728.0463, MAE: 3196.8518, R2: 0.2467\n",
      "==========================================================================================\n",
      "Epoch [3116/5000] | Time: 0.33s\n",
      "(Training) Loss: 913313.5757\n",
      "(Validation) Loss: 740661.7759, MAE: 3201.0942, R2: 0.2468\n",
      "==========================================================================================\n",
      "Epoch [3117/5000] | Time: 0.37s\n",
      "(Training) Loss: 935350.1653\n",
      "(Validation) Loss: 740576.1879, MAE: 3198.4673, R2: 0.2469\n",
      "==========================================================================================\n",
      "Epoch [3118/5000] | Time: 0.32s\n",
      "(Training) Loss: 917951.9968\n",
      "(Validation) Loss: 740512.9067, MAE: 3200.9927, R2: 0.2469\n",
      "==========================================================================================\n",
      "Epoch [3119/5000] | Time: 0.37s\n",
      "(Training) Loss: 917519.6117\n",
      "(Validation) Loss: 740405.9556, MAE: 3199.5715, R2: 0.2470\n",
      "==========================================================================================\n",
      "Epoch [3120/5000] | Time: 0.39s\n",
      "(Training) Loss: 933982.3966\n",
      "(Validation) Loss: 740336.8622, MAE: 3198.2698, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [3121/5000] | Time: 0.36s\n",
      "(Training) Loss: 936865.6504\n",
      "(Validation) Loss: 740253.3994, MAE: 3200.0056, R2: 0.2472\n",
      "==========================================================================================\n",
      "Epoch [3122/5000] | Time: 0.35s\n",
      "(Training) Loss: 923843.5216\n",
      "(Validation) Loss: 740159.3384, MAE: 3195.5537, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [3123/5000] | Time: 0.39s\n",
      "(Training) Loss: 913800.0911\n",
      "(Validation) Loss: 740089.4076, MAE: 3197.8818, R2: 0.2474\n",
      "==========================================================================================\n",
      "Epoch [3124/5000] | Time: 0.37s\n",
      "(Training) Loss: 945489.6954\n",
      "(Validation) Loss: 740006.7898, MAE: 3197.3931, R2: 0.2474\n",
      "==========================================================================================\n",
      "Epoch [3125/5000] | Time: 0.36s\n",
      "(Training) Loss: 916320.7062\n",
      "(Validation) Loss: 739913.9886, MAE: 3198.3625, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [3126/5000] | Time: 0.36s\n",
      "(Training) Loss: 917877.1929\n",
      "(Validation) Loss: 739823.7568, MAE: 3195.8181, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [3127/5000] | Time: 0.37s\n",
      "(Training) Loss: 914062.2678\n",
      "(Validation) Loss: 739755.8381, MAE: 3199.3118, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [3128/5000] | Time: 0.40s\n",
      "(Training) Loss: 912486.7341\n",
      "(Validation) Loss: 739688.5771, MAE: 3201.7263, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [3129/5000] | Time: 0.39s\n",
      "(Training) Loss: 939167.8046\n",
      "(Validation) Loss: 739601.9492, MAE: 3197.9089, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [3130/5000] | Time: 0.40s\n",
      "(Training) Loss: 917241.8769\n",
      "(Validation) Loss: 739523.8444, MAE: 3198.5054, R2: 0.2479\n",
      "==========================================================================================\n",
      "Epoch [3131/5000] | Time: 0.33s\n",
      "(Training) Loss: 944586.0901\n",
      "(Validation) Loss: 739448.7568, MAE: 3196.8247, R2: 0.2480\n",
      "==========================================================================================\n",
      "Epoch [3132/5000] | Time: 0.37s\n",
      "(Training) Loss: 922171.7437\n",
      "(Validation) Loss: 739361.7156, MAE: 3197.7947, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [3133/5000] | Time: 0.33s\n",
      "(Training) Loss: 916851.7183\n",
      "(Validation) Loss: 739283.0857, MAE: 3200.0276, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [3134/5000] | Time: 0.38s\n",
      "(Training) Loss: 931127.8058\n",
      "(Validation) Loss: 739257.3562, MAE: 3199.0591, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [3135/5000] | Time: 0.38s\n",
      "(Training) Loss: 935295.0121\n",
      "(Validation) Loss: 739106.4171, MAE: 3194.7051, R2: 0.2483\n",
      "==========================================================================================\n",
      "Epoch [3136/5000] | Time: 0.30s\n",
      "(Training) Loss: 930931.3255\n",
      "(Validation) Loss: 739034.0146, MAE: 3199.7026, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [3137/5000] | Time: 0.37s\n",
      "(Training) Loss: 921568.8249\n",
      "(Validation) Loss: 738974.3517, MAE: 3199.2673, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [3138/5000] | Time: 0.36s\n",
      "(Training) Loss: 943447.2716\n",
      "(Validation) Loss: 738862.7117, MAE: 3193.7666, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [3139/5000] | Time: 0.36s\n",
      "(Training) Loss: 922217.5819\n",
      "(Validation) Loss: 741719.2895, MAE: 3203.8257, R2: 0.2457\n",
      "==========================================================================================\n",
      "Epoch [3140/5000] | Time: 0.39s\n",
      "(Training) Loss: 927596.4759\n",
      "(Validation) Loss: 741633.0521, MAE: 3201.8359, R2: 0.2458\n",
      "==========================================================================================\n",
      "Epoch [3141/5000] | Time: 0.38s\n",
      "(Training) Loss: 921299.4549\n",
      "(Validation) Loss: 741542.7663, MAE: 3199.8369, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [3142/5000] | Time: 0.39s\n",
      "(Training) Loss: 929704.8166\n",
      "(Validation) Loss: 741460.6749, MAE: 3198.9998, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [3143/5000] | Time: 0.38s\n",
      "(Training) Loss: 917543.8306\n",
      "(Validation) Loss: 741404.2063, MAE: 3204.0452, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [3144/5000] | Time: 0.37s\n",
      "(Training) Loss: 938567.5641\n",
      "(Validation) Loss: 741311.8241, MAE: 3199.7993, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [3145/5000] | Time: 0.37s\n",
      "(Training) Loss: 922567.4714\n",
      "(Validation) Loss: 741229.1594, MAE: 3204.2742, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [3146/5000] | Time: 0.35s\n",
      "(Training) Loss: 920810.4759\n",
      "(Validation) Loss: 741149.7308, MAE: 3203.7993, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [3147/5000] | Time: 0.37s\n",
      "(Training) Loss: 945933.7976\n",
      "(Validation) Loss: 741078.0222, MAE: 3207.2397, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [3148/5000] | Time: 0.36s\n",
      "(Training) Loss: 925748.4626\n",
      "(Validation) Loss: 740992.0108, MAE: 3199.7258, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [3149/5000] | Time: 0.34s\n",
      "(Training) Loss: 927875.1529\n",
      "(Validation) Loss: 740910.5543, MAE: 3200.4849, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [3150/5000] | Time: 0.33s\n",
      "(Training) Loss: 927781.6758\n",
      "(Validation) Loss: 740840.0660, MAE: 3201.2905, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [3151/5000] | Time: 0.36s\n",
      "(Training) Loss: 918348.5882\n",
      "(Validation) Loss: 740759.3689, MAE: 3201.7021, R2: 0.2467\n",
      "==========================================================================================\n",
      "Epoch [3152/5000] | Time: 0.34s\n",
      "(Training) Loss: 926249.9010\n",
      "(Validation) Loss: 741400.3562, MAE: 3200.3867, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [3153/5000] | Time: 0.36s\n",
      "(Training) Loss: 931527.7652\n",
      "(Validation) Loss: 741323.2641, MAE: 3208.5320, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [3154/5000] | Time: 0.37s\n",
      "(Training) Loss: 915340.7931\n",
      "(Validation) Loss: 741243.4552, MAE: 3203.3093, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [3155/5000] | Time: 0.37s\n",
      "(Training) Loss: 922556.1701\n",
      "(Validation) Loss: 741152.3568, MAE: 3203.2146, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [3156/5000] | Time: 0.35s\n",
      "(Training) Loss: 922687.0964\n",
      "(Validation) Loss: 741057.0616, MAE: 3200.0881, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [3157/5000] | Time: 0.38s\n",
      "(Training) Loss: 923536.4683\n",
      "(Validation) Loss: 740976.5060, MAE: 3199.3164, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [3158/5000] | Time: 0.35s\n",
      "(Training) Loss: 934098.4124\n",
      "(Validation) Loss: 740886.6260, MAE: 3199.0581, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [3159/5000] | Time: 0.36s\n",
      "(Training) Loss: 919348.4727\n",
      "(Validation) Loss: 740804.7524, MAE: 3198.4094, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [3160/5000] | Time: 0.39s\n",
      "(Training) Loss: 921118.1485\n",
      "(Validation) Loss: 740722.6565, MAE: 3199.7258, R2: 0.2467\n",
      "==========================================================================================\n",
      "Epoch [3161/5000] | Time: 0.39s\n",
      "(Training) Loss: 925206.9105\n",
      "(Validation) Loss: 740649.3632, MAE: 3201.0334, R2: 0.2468\n",
      "==========================================================================================\n",
      "Epoch [3162/5000] | Time: 0.38s\n",
      "(Training) Loss: 929922.1453\n",
      "(Validation) Loss: 740556.1041, MAE: 3198.3381, R2: 0.2469\n",
      "==========================================================================================\n",
      "Epoch [3163/5000] | Time: 0.37s\n",
      "(Training) Loss: 917083.4810\n",
      "(Validation) Loss: 740465.1987, MAE: 3196.0864, R2: 0.2470\n",
      "==========================================================================================\n",
      "Epoch [3164/5000] | Time: 0.37s\n",
      "(Training) Loss: 912496.2631\n",
      "(Validation) Loss: 740385.7689, MAE: 3196.7410, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [3165/5000] | Time: 0.34s\n",
      "(Training) Loss: 918145.4759\n",
      "(Validation) Loss: 740318.7244, MAE: 3200.0720, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [3166/5000] | Time: 0.38s\n",
      "(Training) Loss: 925730.4607\n",
      "(Validation) Loss: 740232.2692, MAE: 3200.7156, R2: 0.2472\n",
      "==========================================================================================\n",
      "Epoch [3167/5000] | Time: 0.34s\n",
      "(Training) Loss: 921971.6272\n",
      "(Validation) Loss: 740144.2476, MAE: 3203.3489, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [3168/5000] | Time: 0.36s\n",
      "(Training) Loss: 919722.8680\n",
      "(Validation) Loss: 740043.1105, MAE: 3193.4524, R2: 0.2474\n",
      "==========================================================================================\n",
      "Epoch [3169/5000] | Time: 0.35s\n",
      "(Training) Loss: 918565.6878\n",
      "(Validation) Loss: 739969.0768, MAE: 3194.9062, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [3170/5000] | Time: 0.37s\n",
      "(Training) Loss: 921057.5368\n",
      "(Validation) Loss: 739887.9746, MAE: 3197.2908, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [3171/5000] | Time: 0.39s\n",
      "(Training) Loss: 923981.0907\n",
      "(Validation) Loss: 739798.7111, MAE: 3194.4563, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [3172/5000] | Time: 0.41s\n",
      "(Training) Loss: 919346.6605\n",
      "(Validation) Loss: 739749.9689, MAE: 3200.8967, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [3173/5000] | Time: 0.39s\n",
      "(Training) Loss: 917508.6662\n",
      "(Validation) Loss: 739634.4597, MAE: 3193.5974, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [3174/5000] | Time: 0.35s\n",
      "(Training) Loss: 915103.0378\n",
      "(Validation) Loss: 739580.4394, MAE: 3197.0293, R2: 0.2479\n",
      "==========================================================================================\n",
      "Epoch [3175/5000] | Time: 0.33s\n",
      "(Training) Loss: 921306.0343\n",
      "(Validation) Loss: 739485.0698, MAE: 3197.9829, R2: 0.2480\n",
      "==========================================================================================\n",
      "Epoch [3176/5000] | Time: 0.36s\n",
      "(Training) Loss: 924924.2398\n",
      "(Validation) Loss: 739385.5321, MAE: 3192.7092, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [3177/5000] | Time: 0.34s\n",
      "(Training) Loss: 930689.3052\n",
      "(Validation) Loss: 739319.8044, MAE: 3196.1724, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [3178/5000] | Time: 0.35s\n",
      "(Training) Loss: 929422.4971\n",
      "(Validation) Loss: 739236.0190, MAE: 3194.7844, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [3179/5000] | Time: 0.35s\n",
      "(Training) Loss: 934603.5171\n",
      "(Validation) Loss: 739148.6610, MAE: 3194.1636, R2: 0.2483\n",
      "==========================================================================================\n",
      "Epoch [3180/5000] | Time: 0.33s\n",
      "(Training) Loss: 933868.4156\n",
      "(Validation) Loss: 739063.9473, MAE: 3194.1394, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [3181/5000] | Time: 0.31s\n",
      "(Training) Loss: 910655.4426\n",
      "(Validation) Loss: 738969.7530, MAE: 3190.7283, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [3182/5000] | Time: 0.34s\n",
      "(Training) Loss: 918105.4169\n",
      "(Validation) Loss: 738893.0476, MAE: 3193.8596, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [3183/5000] | Time: 0.34s\n",
      "(Training) Loss: 939170.8135\n",
      "(Validation) Loss: 738823.9676, MAE: 3193.2964, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [3184/5000] | Time: 0.37s\n",
      "(Training) Loss: 961271.7418\n",
      "(Validation) Loss: 738725.2610, MAE: 3190.8191, R2: 0.2487\n",
      "==========================================================================================\n",
      "Epoch [3185/5000] | Time: 0.33s\n",
      "(Training) Loss: 918298.9029\n",
      "(Validation) Loss: 738650.7822, MAE: 3193.6816, R2: 0.2488\n",
      "==========================================================================================\n",
      "Epoch [3186/5000] | Time: 0.33s\n",
      "(Training) Loss: 940614.6466\n",
      "(Validation) Loss: 738561.2070, MAE: 3189.8267, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [3187/5000] | Time: 0.34s\n",
      "(Training) Loss: 923399.1789\n",
      "(Validation) Loss: 738508.5086, MAE: 3195.1099, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [3188/5000] | Time: 0.33s\n",
      "(Training) Loss: 911092.1894\n",
      "(Validation) Loss: 738402.9410, MAE: 3194.3962, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [3189/5000] | Time: 0.32s\n",
      "(Training) Loss: 915748.4454\n",
      "(Validation) Loss: 738317.2978, MAE: 3190.1311, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [3190/5000] | Time: 0.37s\n",
      "(Training) Loss: 926051.9511\n",
      "(Validation) Loss: 738259.5003, MAE: 3193.6282, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [3191/5000] | Time: 0.37s\n",
      "(Training) Loss: 918834.4467\n",
      "(Validation) Loss: 738182.1416, MAE: 3195.9517, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [3192/5000] | Time: 0.33s\n",
      "(Training) Loss: 919674.9632\n",
      "(Validation) Loss: 738103.7441, MAE: 3195.3115, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [3193/5000] | Time: 0.34s\n",
      "(Training) Loss: 915797.9435\n",
      "(Validation) Loss: 738008.1930, MAE: 3195.0298, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [3194/5000] | Time: 0.38s\n",
      "(Training) Loss: 918505.2814\n",
      "(Validation) Loss: 737916.8724, MAE: 3194.2004, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [3195/5000] | Time: 0.35s\n",
      "(Training) Loss: 919336.9270\n",
      "(Validation) Loss: 737862.0527, MAE: 3195.3188, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [3196/5000] | Time: 0.33s\n",
      "(Training) Loss: 924036.4150\n",
      "(Validation) Loss: 740273.0521, MAE: 3196.2158, R2: 0.2472\n",
      "==========================================================================================\n",
      "Epoch [3197/5000] | Time: 0.32s\n",
      "(Training) Loss: 912197.1215\n",
      "(Validation) Loss: 737471.2152, MAE: 3188.8342, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [3198/5000] | Time: 0.33s\n",
      "(Training) Loss: 917860.8591\n",
      "(Validation) Loss: 737391.1562, MAE: 3188.5508, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [3199/5000] | Time: 0.33s\n",
      "(Training) Loss: 920194.0711\n",
      "(Validation) Loss: 737304.2197, MAE: 3192.0708, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [3200/5000] | Time: 0.31s\n",
      "(Training) Loss: 936356.3141\n",
      "(Validation) Loss: 737223.4159, MAE: 3188.9294, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [3201/5000] | Time: 0.32s\n",
      "(Training) Loss: 932189.6675\n",
      "(Validation) Loss: 737121.4876, MAE: 3186.2273, R2: 0.2503\n",
      "==========================================================================================\n",
      "Epoch [3202/5000] | Time: 0.32s\n",
      "(Training) Loss: 916559.2379\n",
      "(Validation) Loss: 737059.6597, MAE: 3189.0115, R2: 0.2504\n",
      "==========================================================================================\n",
      "Epoch [3203/5000] | Time: 0.33s\n",
      "(Training) Loss: 920570.8363\n",
      "(Validation) Loss: 736957.2298, MAE: 3185.4458, R2: 0.2505\n",
      "==========================================================================================\n",
      "Epoch [3204/5000] | Time: 0.32s\n",
      "(Training) Loss: 941706.0044\n",
      "(Validation) Loss: 736880.2635, MAE: 3186.5403, R2: 0.2506\n",
      "==========================================================================================\n",
      "Epoch [3205/5000] | Time: 0.36s\n",
      "(Training) Loss: 938900.1751\n",
      "(Validation) Loss: 736813.1860, MAE: 3189.5891, R2: 0.2507\n",
      "==========================================================================================\n",
      "Epoch [3206/5000] | Time: 0.35s\n",
      "(Training) Loss: 928074.5190\n",
      "(Validation) Loss: 736726.7365, MAE: 3187.2334, R2: 0.2507\n",
      "==========================================================================================\n",
      "Epoch [3207/5000] | Time: 0.36s\n",
      "(Training) Loss: 923217.0282\n",
      "(Validation) Loss: 736636.3244, MAE: 3188.5784, R2: 0.2508\n",
      "==========================================================================================\n",
      "Epoch [3208/5000] | Time: 0.35s\n",
      "(Training) Loss: 919289.1789\n",
      "(Validation) Loss: 736562.8406, MAE: 3187.7834, R2: 0.2509\n",
      "==========================================================================================\n",
      "Epoch [3209/5000] | Time: 0.32s\n",
      "(Training) Loss: 920489.4638\n",
      "(Validation) Loss: 736475.0895, MAE: 3188.3030, R2: 0.2510\n",
      "==========================================================================================\n",
      "Epoch [3210/5000] | Time: 0.34s\n",
      "(Training) Loss: 926606.0914\n",
      "(Validation) Loss: 736387.7283, MAE: 3188.3523, R2: 0.2511\n",
      "==========================================================================================\n",
      "Epoch [3211/5000] | Time: 0.33s\n",
      "(Training) Loss: 917382.0362\n",
      "(Validation) Loss: 736291.9708, MAE: 3182.8447, R2: 0.2512\n",
      "==========================================================================================\n",
      "Epoch [3212/5000] | Time: 0.32s\n",
      "(Training) Loss: 909101.2947\n",
      "(Validation) Loss: 736227.4914, MAE: 3187.4124, R2: 0.2513\n",
      "==========================================================================================\n",
      "Epoch [3213/5000] | Time: 0.30s\n",
      "(Training) Loss: 907871.7769\n",
      "(Validation) Loss: 736134.9962, MAE: 3187.6060, R2: 0.2513\n",
      "==========================================================================================\n",
      "Epoch [3214/5000] | Time: 0.33s\n",
      "(Training) Loss: 910124.4810\n",
      "(Validation) Loss: 736050.7994, MAE: 3184.1836, R2: 0.2514\n",
      "==========================================================================================\n",
      "Epoch [3215/5000] | Time: 0.32s\n",
      "(Training) Loss: 912067.1288\n",
      "(Validation) Loss: 735995.2248, MAE: 3186.8479, R2: 0.2515\n",
      "==========================================================================================\n",
      "Epoch [3216/5000] | Time: 0.35s\n",
      "(Training) Loss: 919256.6865\n",
      "(Validation) Loss: 735916.0552, MAE: 3189.4004, R2: 0.2516\n",
      "==========================================================================================\n",
      "Epoch [3217/5000] | Time: 0.31s\n",
      "(Training) Loss: 914360.7817\n",
      "(Validation) Loss: 735808.8946, MAE: 3181.6169, R2: 0.2517\n",
      "==========================================================================================\n",
      "Epoch [3218/5000] | Time: 0.35s\n",
      "(Training) Loss: 917677.3058\n",
      "(Validation) Loss: 735731.6971, MAE: 3181.5176, R2: 0.2517\n",
      "==========================================================================================\n",
      "Epoch [3219/5000] | Time: 0.36s\n",
      "(Training) Loss: 913301.7113\n",
      "(Validation) Loss: 735640.4819, MAE: 3181.6067, R2: 0.2518\n",
      "==========================================================================================\n",
      "Epoch [3220/5000] | Time: 0.34s\n",
      "(Training) Loss: 919577.1681\n",
      "(Validation) Loss: 735558.6095, MAE: 3182.2102, R2: 0.2519\n",
      "==========================================================================================\n",
      "Epoch [3221/5000] | Time: 0.32s\n",
      "(Training) Loss: 902820.1599\n",
      "(Validation) Loss: 723793.3676, MAE: 3151.5020, R2: 0.2638\n",
      "==========================================================================================\n",
      "Epoch [3222/5000] | Time: 0.35s\n",
      "(Training) Loss: 893852.2378\n",
      "(Validation) Loss: 723687.2667, MAE: 3146.2029, R2: 0.2639\n",
      "==========================================================================================\n",
      "Epoch [3223/5000] | Time: 0.33s\n",
      "(Training) Loss: 908943.6104\n",
      "(Validation) Loss: 723693.3041, MAE: 3154.3159, R2: 0.2639\n",
      "==========================================================================================\n",
      "Epoch [3224/5000] | Time: 0.32s\n",
      "(Training) Loss: 907548.9530\n",
      "(Validation) Loss: 723596.0984, MAE: 3155.0708, R2: 0.2640\n",
      "==========================================================================================\n",
      "Epoch [3225/5000] | Time: 0.35s\n",
      "(Training) Loss: 897607.5498\n",
      "(Validation) Loss: 723527.2641, MAE: 3155.7126, R2: 0.2641\n",
      "==========================================================================================\n",
      "Epoch [3226/5000] | Time: 0.34s\n",
      "(Training) Loss: 913335.8877\n",
      "(Validation) Loss: 723439.3549, MAE: 3153.0837, R2: 0.2641\n",
      "==========================================================================================\n",
      "Epoch [3227/5000] | Time: 0.30s\n",
      "(Training) Loss: 912134.7494\n",
      "(Validation) Loss: 723343.9867, MAE: 3150.9548, R2: 0.2642\n",
      "==========================================================================================\n",
      "Epoch [3228/5000] | Time: 0.31s\n",
      "(Training) Loss: 898164.3674\n",
      "(Validation) Loss: 723272.3416, MAE: 3152.2136, R2: 0.2643\n",
      "==========================================================================================\n",
      "Epoch [3229/5000] | Time: 0.32s\n",
      "(Training) Loss: 903963.2557\n",
      "(Validation) Loss: 723181.7371, MAE: 3149.7629, R2: 0.2644\n",
      "==========================================================================================\n",
      "Epoch [3230/5000] | Time: 0.32s\n",
      "(Training) Loss: 903444.2792\n",
      "(Validation) Loss: 723096.2121, MAE: 3148.6948, R2: 0.2645\n",
      "==========================================================================================\n",
      "Epoch [3231/5000] | Time: 0.31s\n",
      "(Training) Loss: 908976.8077\n",
      "(Validation) Loss: 723009.7156, MAE: 3146.7036, R2: 0.2646\n",
      "==========================================================================================\n",
      "Epoch [3232/5000] | Time: 0.32s\n",
      "(Training) Loss: 919685.7075\n",
      "(Validation) Loss: 722933.8730, MAE: 3148.8826, R2: 0.2647\n",
      "==========================================================================================\n",
      "Epoch [3233/5000] | Time: 0.31s\n",
      "(Training) Loss: 901183.7506\n",
      "(Validation) Loss: 722843.5816, MAE: 3146.8669, R2: 0.2647\n",
      "==========================================================================================\n",
      "Epoch [3234/5000] | Time: 0.34s\n",
      "(Training) Loss: 910086.0984\n",
      "(Validation) Loss: 722759.0267, MAE: 3144.7483, R2: 0.2648\n",
      "==========================================================================================\n",
      "Epoch [3235/5000] | Time: 0.36s\n",
      "(Training) Loss: 909210.5076\n",
      "(Validation) Loss: 722697.2730, MAE: 3154.3149, R2: 0.2649\n",
      "==========================================================================================\n",
      "Epoch [3236/5000] | Time: 0.32s\n",
      "(Training) Loss: 904672.2113\n",
      "(Validation) Loss: 722603.2622, MAE: 3146.5161, R2: 0.2650\n",
      "==========================================================================================\n",
      "Epoch [3237/5000] | Time: 0.33s\n",
      "(Training) Loss: 904412.6624\n",
      "(Validation) Loss: 722525.2152, MAE: 3150.6663, R2: 0.2651\n",
      "==========================================================================================\n",
      "Epoch [3238/5000] | Time: 0.31s\n",
      "(Training) Loss: 907497.0114\n",
      "(Validation) Loss: 722443.8927, MAE: 3146.9094, R2: 0.2652\n",
      "==========================================================================================\n",
      "Epoch [3239/5000] | Time: 0.32s\n",
      "(Training) Loss: 914527.2132\n",
      "(Validation) Loss: 722373.8260, MAE: 3150.1416, R2: 0.2652\n",
      "==========================================================================================\n",
      "Epoch [3240/5000] | Time: 0.31s\n",
      "(Training) Loss: 900990.0032\n",
      "(Validation) Loss: 722268.5111, MAE: 3144.2556, R2: 0.2653\n",
      "==========================================================================================\n",
      "Epoch [3241/5000] | Time: 0.38s\n",
      "(Training) Loss: 903766.1853\n",
      "(Validation) Loss: 722201.4337, MAE: 3148.8347, R2: 0.2654\n",
      "==========================================================================================\n",
      "Epoch [3242/5000] | Time: 0.32s\n",
      "(Training) Loss: 900986.7265\n",
      "(Validation) Loss: 703972.1486, MAE: 3112.9829, R2: 0.2838\n",
      "==========================================================================================\n",
      "Epoch [3243/5000] | Time: 0.31s\n",
      "(Training) Loss: 878731.9784\n",
      "(Validation) Loss: 703904.5206, MAE: 3103.5654, R2: 0.2839\n",
      "==========================================================================================\n",
      "Epoch [3244/5000] | Time: 0.36s\n",
      "(Training) Loss: 876676.3934\n",
      "(Validation) Loss: 703826.0933, MAE: 3097.8870, R2: 0.2839\n",
      "==========================================================================================\n",
      "Epoch [3245/5000] | Time: 0.35s\n",
      "(Training) Loss: 879271.2145\n",
      "(Validation) Loss: 703757.6413, MAE: 3101.4146, R2: 0.2840\n",
      "==========================================================================================\n",
      "Epoch [3246/5000] | Time: 0.34s\n",
      "(Training) Loss: 878922.2335\n",
      "(Validation) Loss: 703674.5365, MAE: 3096.7117, R2: 0.2841\n",
      "==========================================================================================\n",
      "Epoch [3247/5000] | Time: 0.34s\n",
      "(Training) Loss: 889969.0057\n",
      "(Validation) Loss: 703592.7613, MAE: 3097.1917, R2: 0.2842\n",
      "==========================================================================================\n",
      "Epoch [3248/5000] | Time: 0.35s\n",
      "(Training) Loss: 894051.4334\n",
      "(Validation) Loss: 703516.7879, MAE: 3098.4639, R2: 0.2842\n",
      "==========================================================================================\n",
      "Epoch [3249/5000] | Time: 0.34s\n",
      "(Training) Loss: 884745.2462\n",
      "(Validation) Loss: 703440.7956, MAE: 3097.8433, R2: 0.2843\n",
      "==========================================================================================\n",
      "Epoch [3250/5000] | Time: 0.36s\n",
      "(Training) Loss: 881931.6453\n",
      "(Validation) Loss: 703371.3092, MAE: 3102.1599, R2: 0.2844\n",
      "==========================================================================================\n",
      "Epoch [3251/5000] | Time: 0.38s\n",
      "(Training) Loss: 877989.8718\n",
      "(Validation) Loss: 703287.0324, MAE: 3097.0422, R2: 0.2845\n",
      "==========================================================================================\n",
      "Epoch [3252/5000] | Time: 0.35s\n",
      "(Training) Loss: 877789.7665\n",
      "(Validation) Loss: 703215.4419, MAE: 3097.3164, R2: 0.2846\n",
      "==========================================================================================\n",
      "Epoch [3253/5000] | Time: 0.35s\n",
      "(Training) Loss: 877141.7234\n",
      "(Validation) Loss: 703137.5048, MAE: 3097.2361, R2: 0.2846\n",
      "==========================================================================================\n",
      "Epoch [3254/5000] | Time: 0.37s\n",
      "(Training) Loss: 879256.4873\n",
      "(Validation) Loss: 703051.5429, MAE: 3096.0977, R2: 0.2847\n",
      "==========================================================================================\n",
      "Epoch [3255/5000] | Time: 0.37s\n",
      "(Training) Loss: 873165.5301\n",
      "(Validation) Loss: 702974.5314, MAE: 3094.4893, R2: 0.2848\n",
      "==========================================================================================\n",
      "Epoch [3256/5000] | Time: 0.34s\n",
      "(Training) Loss: 882470.0235\n",
      "(Validation) Loss: 702908.6387, MAE: 3097.0352, R2: 0.2849\n",
      "==========================================================================================\n",
      "Epoch [3257/5000] | Time: 0.31s\n",
      "(Training) Loss: 877177.6155\n",
      "(Validation) Loss: 702827.2425, MAE: 3094.8691, R2: 0.2849\n",
      "==========================================================================================\n",
      "Epoch [3258/5000] | Time: 0.36s\n",
      "(Training) Loss: 870616.6110\n",
      "(Validation) Loss: 702751.9511, MAE: 3096.9482, R2: 0.2850\n",
      "==========================================================================================\n",
      "Epoch [3259/5000] | Time: 0.32s\n",
      "(Training) Loss: 877177.7386\n",
      "(Validation) Loss: 702676.8800, MAE: 3095.9397, R2: 0.2851\n",
      "==========================================================================================\n",
      "Epoch [3260/5000] | Time: 0.30s\n",
      "(Training) Loss: 873346.8325\n",
      "(Validation) Loss: 702593.1917, MAE: 3095.0457, R2: 0.2852\n",
      "==========================================================================================\n",
      "Epoch [3261/5000] | Time: 0.31s\n",
      "(Training) Loss: 878837.5292\n",
      "(Validation) Loss: 702527.0368, MAE: 3095.4565, R2: 0.2852\n",
      "==========================================================================================\n",
      "Epoch [3262/5000] | Time: 0.33s\n",
      "(Training) Loss: 883622.9074\n",
      "(Validation) Loss: 702492.7054, MAE: 3104.2424, R2: 0.2853\n",
      "==========================================================================================\n",
      "Epoch [3263/5000] | Time: 0.33s\n",
      "(Training) Loss: 877024.4264\n",
      "(Validation) Loss: 702388.2552, MAE: 3101.1396, R2: 0.2854\n",
      "==========================================================================================\n",
      "Epoch [3264/5000] | Time: 0.34s\n",
      "(Training) Loss: 868555.9467\n",
      "(Validation) Loss: 702290.0025, MAE: 3096.4536, R2: 0.2855\n",
      "==========================================================================================\n",
      "Epoch [3265/5000] | Time: 0.35s\n",
      "(Training) Loss: 875460.6148\n",
      "(Validation) Loss: 702236.6844, MAE: 3099.0974, R2: 0.2855\n",
      "==========================================================================================\n",
      "Epoch [3266/5000] | Time: 0.41s\n",
      "(Training) Loss: 890416.7046\n",
      "(Validation) Loss: 702151.7149, MAE: 3101.0361, R2: 0.2856\n",
      "==========================================================================================\n",
      "Epoch [3267/5000] | Time: 0.37s\n",
      "(Training) Loss: 868722.7520\n",
      "(Validation) Loss: 702054.3467, MAE: 3093.6287, R2: 0.2857\n",
      "==========================================================================================\n",
      "Epoch [3268/5000] | Time: 0.38s\n",
      "(Training) Loss: 900389.5235\n",
      "(Validation) Loss: 701977.9098, MAE: 3093.4216, R2: 0.2858\n",
      "==========================================================================================\n",
      "Epoch [3269/5000] | Time: 0.35s\n",
      "(Training) Loss: 882571.7646\n",
      "(Validation) Loss: 701903.9403, MAE: 3093.9680, R2: 0.2859\n",
      "==========================================================================================\n",
      "Epoch [3270/5000] | Time: 0.31s\n",
      "(Training) Loss: 886348.2957\n",
      "(Validation) Loss: 701815.8362, MAE: 3092.4490, R2: 0.2860\n",
      "==========================================================================================\n",
      "Epoch [3271/5000] | Time: 0.31s\n",
      "(Training) Loss: 869203.9121\n",
      "(Validation) Loss: 701749.2083, MAE: 3094.8069, R2: 0.2860\n",
      "==========================================================================================\n",
      "Epoch [3272/5000] | Time: 0.31s\n",
      "(Training) Loss: 893172.7370\n",
      "(Validation) Loss: 701672.4343, MAE: 3091.9114, R2: 0.2861\n",
      "==========================================================================================\n",
      "Epoch [3273/5000] | Time: 0.32s\n",
      "(Training) Loss: 879141.8077\n",
      "(Validation) Loss: 701580.9924, MAE: 3089.9321, R2: 0.2862\n",
      "==========================================================================================\n",
      "Epoch [3274/5000] | Time: 0.34s\n",
      "(Training) Loss: 876110.8246\n",
      "(Validation) Loss: 701506.2032, MAE: 3091.5251, R2: 0.2863\n",
      "==========================================================================================\n",
      "Epoch [3275/5000] | Time: 0.30s\n",
      "(Training) Loss: 874217.8547\n",
      "(Validation) Loss: 701423.0692, MAE: 3089.9238, R2: 0.2864\n",
      "==========================================================================================\n",
      "Epoch [3276/5000] | Time: 0.31s\n",
      "(Training) Loss: 867687.5428\n",
      "(Validation) Loss: 701346.7181, MAE: 3090.3713, R2: 0.2864\n",
      "==========================================================================================\n",
      "Epoch [3277/5000] | Time: 0.31s\n",
      "(Training) Loss: 882128.6815\n",
      "(Validation) Loss: 701270.3187, MAE: 3088.5623, R2: 0.2865\n",
      "==========================================================================================\n",
      "Epoch [3278/5000] | Time: 0.32s\n",
      "(Training) Loss: 900113.6837\n",
      "(Validation) Loss: 701197.3314, MAE: 3091.9280, R2: 0.2866\n",
      "==========================================================================================\n",
      "Epoch [3279/5000] | Time: 0.33s\n",
      "(Training) Loss: 867863.4812\n",
      "(Validation) Loss: 701114.5035, MAE: 3088.6335, R2: 0.2867\n",
      "==========================================================================================\n",
      "Epoch [3280/5000] | Time: 0.38s\n",
      "(Training) Loss: 868510.0825\n",
      "(Validation) Loss: 701038.4387, MAE: 3089.2520, R2: 0.2867\n",
      "==========================================================================================\n",
      "Epoch [3281/5000] | Time: 0.31s\n",
      "(Training) Loss: 869434.0476\n",
      "(Validation) Loss: 700990.1048, MAE: 3099.2412, R2: 0.2868\n",
      "==========================================================================================\n",
      "Epoch [3282/5000] | Time: 0.35s\n",
      "(Training) Loss: 881595.8915\n",
      "(Validation) Loss: 700897.6216, MAE: 3093.1082, R2: 0.2869\n",
      "==========================================================================================\n",
      "Epoch [3283/5000] | Time: 0.33s\n",
      "(Training) Loss: 885799.3065\n",
      "(Validation) Loss: 700824.5238, MAE: 3093.3125, R2: 0.2870\n",
      "==========================================================================================\n",
      "Epoch [3284/5000] | Time: 0.30s\n",
      "(Training) Loss: 873147.4905\n",
      "(Validation) Loss: 700748.6057, MAE: 3093.4087, R2: 0.2870\n",
      "==========================================================================================\n",
      "Epoch [3285/5000] | Time: 0.30s\n",
      "(Training) Loss: 895987.2563\n",
      "(Validation) Loss: 700665.6292, MAE: 3090.2974, R2: 0.2871\n",
      "==========================================================================================\n",
      "Epoch [3286/5000] | Time: 0.32s\n",
      "(Training) Loss: 870607.7855\n",
      "(Validation) Loss: 700577.4305, MAE: 3089.0793, R2: 0.2872\n",
      "==========================================================================================\n",
      "Epoch [3287/5000] | Time: 0.36s\n",
      "(Training) Loss: 888908.8503\n",
      "(Validation) Loss: 700508.3632, MAE: 3089.8774, R2: 0.2873\n",
      "==========================================================================================\n",
      "Epoch [3288/5000] | Time: 0.36s\n",
      "(Training) Loss: 868148.8544\n",
      "(Validation) Loss: 700429.0603, MAE: 3091.1077, R2: 0.2874\n",
      "==========================================================================================\n",
      "Epoch [3289/5000] | Time: 0.37s\n",
      "(Training) Loss: 869537.1231\n",
      "(Validation) Loss: 700345.0400, MAE: 3089.2678, R2: 0.2874\n",
      "==========================================================================================\n",
      "Epoch [3290/5000] | Time: 0.35s\n",
      "(Training) Loss: 868094.4780\n",
      "(Validation) Loss: 700270.1543, MAE: 3089.2834, R2: 0.2875\n",
      "==========================================================================================\n",
      "Epoch [3291/5000] | Time: 0.36s\n",
      "(Training) Loss: 900715.7214\n",
      "(Validation) Loss: 700224.3403, MAE: 3097.7810, R2: 0.2876\n",
      "==========================================================================================\n",
      "Epoch [3292/5000] | Time: 0.31s\n",
      "(Training) Loss: 896033.0584\n",
      "(Validation) Loss: 700124.7384, MAE: 3090.6667, R2: 0.2877\n",
      "==========================================================================================\n",
      "Epoch [3293/5000] | Time: 0.29s\n",
      "(Training) Loss: 917202.9803\n",
      "(Validation) Loss: 700046.9048, MAE: 3094.1479, R2: 0.2878\n",
      "==========================================================================================\n",
      "Epoch [3294/5000] | Time: 0.30s\n",
      "(Training) Loss: 877132.5209\n",
      "(Validation) Loss: 699962.6044, MAE: 3089.2957, R2: 0.2878\n",
      "==========================================================================================\n",
      "Epoch [3295/5000] | Time: 0.30s\n",
      "(Training) Loss: 867139.6112\n",
      "(Validation) Loss: 699870.1486, MAE: 3086.3677, R2: 0.2879\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3296/5000] | Time: 0.38s\n",
      "(Training) Loss: 877085.8135\n",
      "(Validation) Loss: 699794.8114, MAE: 3086.1816, R2: 0.2880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3297/5000] | Time: 0.37s\n",
      "(Training) Loss: 882503.7982\n",
      "(Validation) Loss: 699726.0152, MAE: 3087.3396, R2: 0.2881\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3298/5000] | Time: 0.33s\n",
      "(Training) Loss: 874789.1421\n",
      "(Validation) Loss: 699637.1562, MAE: 3085.2131, R2: 0.2882\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3299/5000] | Time: 0.30s\n",
      "(Training) Loss: 866799.7919\n",
      "(Validation) Loss: 699566.0648, MAE: 3088.2546, R2: 0.2882\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3300/5000] | Time: 0.32s\n",
      "(Training) Loss: 882199.5070\n",
      "(Validation) Loss: 699475.7314, MAE: 3084.9460, R2: 0.2883\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3301/5000] | Time: 0.34s\n",
      "(Training) Loss: 866158.5901\n",
      "(Validation) Loss: 693370.0330, MAE: 3091.4600, R2: 0.2945\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3302/5000] | Time: 0.34s\n",
      "(Training) Loss: 865542.9378\n",
      "(Validation) Loss: 693262.9937, MAE: 3068.8223, R2: 0.2946\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3303/5000] | Time: 0.36s\n",
      "(Training) Loss: 870844.6986\n",
      "(Validation) Loss: 693242.9778, MAE: 3087.4373, R2: 0.2946\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3304/5000] | Time: 0.33s\n",
      "(Training) Loss: 870369.6954\n",
      "(Validation) Loss: 693118.7352, MAE: 3069.3132, R2: 0.2947\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3305/5000] | Time: 0.34s\n",
      "(Training) Loss: 869135.7690\n",
      "(Validation) Loss: 693164.8711, MAE: 3122.5369, R2: 0.2947\n",
      "==========================================================================================\n",
      "Epoch [3306/5000] | Time: 0.32s\n",
      "(Training) Loss: 874722.3401\n",
      "(Validation) Loss: 693017.0978, MAE: 3099.3601, R2: 0.2949\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3307/5000] | Time: 0.31s\n",
      "(Training) Loss: 862082.5095\n",
      "(Validation) Loss: 692933.7575, MAE: 3097.4526, R2: 0.2949\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3308/5000] | Time: 0.31s\n",
      "(Training) Loss: 859441.3141\n",
      "(Validation) Loss: 692912.6660, MAE: 3103.8098, R2: 0.2950\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3309/5000] | Time: 0.32s\n",
      "(Training) Loss: 881961.1313\n",
      "(Validation) Loss: 692846.4216, MAE: 3104.7971, R2: 0.2950\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3310/5000] | Time: 0.36s\n",
      "(Training) Loss: 863357.0222\n",
      "(Validation) Loss: 692775.5822, MAE: 3105.0073, R2: 0.2951\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3311/5000] | Time: 0.38s\n",
      "(Training) Loss: 866132.1225\n",
      "(Validation) Loss: 692704.7702, MAE: 3104.0723, R2: 0.2952\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3312/5000] | Time: 0.34s\n",
      "(Training) Loss: 858579.9235\n",
      "(Validation) Loss: 692624.9670, MAE: 3103.2932, R2: 0.2952\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3313/5000] | Time: 0.35s\n",
      "(Training) Loss: 868341.8198\n",
      "(Validation) Loss: 692543.8279, MAE: 3101.6260, R2: 0.2953\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3314/5000] | Time: 0.39s\n",
      "(Training) Loss: 873391.4378\n",
      "(Validation) Loss: 692449.4762, MAE: 3099.6277, R2: 0.2954\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3315/5000] | Time: 0.36s\n",
      "(Training) Loss: 864355.8071\n",
      "(Validation) Loss: 692360.3003, MAE: 3097.5420, R2: 0.2955\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3316/5000] | Time: 0.37s\n",
      "(Training) Loss: 883353.8702\n",
      "(Validation) Loss: 692335.6857, MAE: 3104.2842, R2: 0.2955\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3317/5000] | Time: 0.34s\n",
      "(Training) Loss: 879064.0723\n",
      "(Validation) Loss: 692219.7181, MAE: 3099.2202, R2: 0.2957\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3318/5000] | Time: 0.33s\n",
      "(Training) Loss: 865496.6174\n",
      "(Validation) Loss: 692138.4216, MAE: 3096.9209, R2: 0.2957\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3319/5000] | Time: 0.32s\n",
      "(Training) Loss: 863371.7437\n",
      "(Validation) Loss: 692084.0597, MAE: 3099.4917, R2: 0.2958\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3320/5000] | Time: 0.36s\n",
      "(Training) Loss: 870188.0844\n",
      "(Validation) Loss: 691997.9219, MAE: 3096.7241, R2: 0.2959\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3321/5000] | Time: 0.34s\n",
      "(Training) Loss: 861511.0838\n",
      "(Validation) Loss: 691914.2571, MAE: 3095.3713, R2: 0.2960\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3322/5000] | Time: 0.32s\n",
      "(Training) Loss: 859097.4245\n",
      "(Validation) Loss: 691853.6476, MAE: 3097.0706, R2: 0.2960\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3323/5000] | Time: 0.33s\n",
      "(Training) Loss: 877249.6942\n",
      "(Validation) Loss: 691780.1606, MAE: 3098.1074, R2: 0.2961\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3324/5000] | Time: 0.36s\n",
      "(Training) Loss: 870361.0660\n",
      "(Validation) Loss: 691701.9289, MAE: 3095.8594, R2: 0.2962\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3325/5000] | Time: 0.34s\n",
      "(Training) Loss: 859480.8090\n",
      "(Validation) Loss: 691627.5822, MAE: 3096.0083, R2: 0.2963\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3326/5000] | Time: 0.33s\n",
      "(Training) Loss: 859203.1605\n",
      "(Validation) Loss: 691572.7016, MAE: 3098.3704, R2: 0.2963\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3327/5000] | Time: 0.32s\n",
      "(Training) Loss: 856719.5938\n",
      "(Validation) Loss: 691484.4565, MAE: 3096.9736, R2: 0.2964\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3328/5000] | Time: 0.30s\n",
      "(Training) Loss: 865227.1396\n",
      "(Validation) Loss: 691393.3829, MAE: 3093.0352, R2: 0.2965\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3329/5000] | Time: 0.32s\n",
      "(Training) Loss: 880319.7030\n",
      "(Validation) Loss: 691351.8102, MAE: 3098.5447, R2: 0.2965\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3330/5000] | Time: 0.33s\n",
      "(Training) Loss: 886601.3756\n",
      "(Validation) Loss: 691281.5213, MAE: 3098.6162, R2: 0.2966\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3331/5000] | Time: 0.35s\n",
      "(Training) Loss: 857643.9656\n",
      "(Validation) Loss: 691196.0959, MAE: 3096.9070, R2: 0.2967\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3332/5000] | Time: 0.31s\n",
      "(Training) Loss: 878936.1678\n",
      "(Validation) Loss: 691110.3606, MAE: 3095.1216, R2: 0.2968\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3333/5000] | Time: 0.33s\n",
      "(Training) Loss: 870843.4524\n",
      "(Validation) Loss: 691202.5073, MAE: 3107.1055, R2: 0.2967\n",
      "==========================================================================================\n",
      "Epoch [3334/5000] | Time: 0.29s\n",
      "(Training) Loss: 873138.3217\n",
      "(Validation) Loss: 691129.9117, MAE: 3106.8921, R2: 0.2968\n",
      "==========================================================================================\n",
      "Epoch [3335/5000] | Time: 0.30s\n",
      "(Training) Loss: 866564.5349\n",
      "(Validation) Loss: 691057.7352, MAE: 3107.0564, R2: 0.2968\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3336/5000] | Time: 0.32s\n",
      "(Training) Loss: 858054.0562\n",
      "(Validation) Loss: 690983.2743, MAE: 3107.2815, R2: 0.2969\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3337/5000] | Time: 0.34s\n",
      "(Training) Loss: 861338.5222\n",
      "(Validation) Loss: 690904.4311, MAE: 3105.8638, R2: 0.2970\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3338/5000] | Time: 0.30s\n",
      "(Training) Loss: 864137.9372\n",
      "(Validation) Loss: 690831.9276, MAE: 3105.4089, R2: 0.2971\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3339/5000] | Time: 0.32s\n",
      "(Training) Loss: 856854.7438\n",
      "(Validation) Loss: 690743.3486, MAE: 3102.9443, R2: 0.2971\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3340/5000] | Time: 0.33s\n",
      "(Training) Loss: 865831.5336\n",
      "(Validation) Loss: 690689.2489, MAE: 3107.4436, R2: 0.2972\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3341/5000] | Time: 0.34s\n",
      "(Training) Loss: 855059.6532\n",
      "(Validation) Loss: 690602.9263, MAE: 3105.1921, R2: 0.2973\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3342/5000] | Time: 0.31s\n",
      "(Training) Loss: 856942.1012\n",
      "(Validation) Loss: 690537.7467, MAE: 3106.1482, R2: 0.2974\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3343/5000] | Time: 0.30s\n",
      "(Training) Loss: 878758.4416\n",
      "(Validation) Loss: 690451.2990, MAE: 3103.6001, R2: 0.2974\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3344/5000] | Time: 0.34s\n",
      "(Training) Loss: 870941.7078\n",
      "(Validation) Loss: 690397.6546, MAE: 3107.6013, R2: 0.2975\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3345/5000] | Time: 0.30s\n",
      "(Training) Loss: 878231.1992\n",
      "(Validation) Loss: 690295.1289, MAE: 3099.3115, R2: 0.2976\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3346/5000] | Time: 0.34s\n",
      "(Training) Loss: 874626.9822\n",
      "(Validation) Loss: 690229.0203, MAE: 3101.5779, R2: 0.2977\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3347/5000] | Time: 0.34s\n",
      "(Training) Loss: 873124.3668\n",
      "(Validation) Loss: 690157.3543, MAE: 3102.8728, R2: 0.2977\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3348/5000] | Time: 0.32s\n",
      "(Training) Loss: 857135.5971\n",
      "(Validation) Loss: 690086.3117, MAE: 3102.8799, R2: 0.2978\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3349/5000] | Time: 0.33s\n",
      "(Training) Loss: 875747.3217\n",
      "(Validation) Loss: 690011.5663, MAE: 3103.1267, R2: 0.2979\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3350/5000] | Time: 0.32s\n",
      "(Training) Loss: 875825.8331\n",
      "(Validation) Loss: 689936.1283, MAE: 3102.1416, R2: 0.2980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3351/5000] | Time: 0.36s\n",
      "(Training) Loss: 860307.6900\n",
      "(Validation) Loss: 689895.2483, MAE: 3107.7847, R2: 0.2980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3352/5000] | Time: 0.37s\n",
      "(Training) Loss: 861020.9239\n",
      "(Validation) Loss: 689785.7848, MAE: 3101.2576, R2: 0.2981\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3353/5000] | Time: 0.32s\n",
      "(Training) Loss: 867406.1497\n",
      "(Validation) Loss: 689696.4286, MAE: 3097.4067, R2: 0.2982\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3354/5000] | Time: 0.32s\n",
      "(Training) Loss: 854957.1228\n",
      "(Validation) Loss: 689620.7390, MAE: 3096.2043, R2: 0.2983\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3355/5000] | Time: 0.34s\n",
      "(Training) Loss: 869128.8414\n",
      "(Validation) Loss: 689546.7873, MAE: 3096.1924, R2: 0.2984\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3356/5000] | Time: 0.33s\n",
      "(Training) Loss: 855398.6575\n",
      "(Validation) Loss: 689480.0749, MAE: 3097.7832, R2: 0.2984\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3357/5000] | Time: 0.31s\n",
      "(Training) Loss: 880479.0780\n",
      "(Validation) Loss: 689396.7124, MAE: 3095.7456, R2: 0.2985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3358/5000] | Time: 0.34s\n",
      "(Training) Loss: 866282.2760\n",
      "(Validation) Loss: 689325.0870, MAE: 3095.8506, R2: 0.2986\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3359/5000] | Time: 0.32s\n",
      "(Training) Loss: 855270.3832\n",
      "(Validation) Loss: 689252.4248, MAE: 3097.1216, R2: 0.2987\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3360/5000] | Time: 0.34s\n",
      "(Training) Loss: 865348.5374\n",
      "(Validation) Loss: 689170.5365, MAE: 3093.0784, R2: 0.2987\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3361/5000] | Time: 0.34s\n",
      "(Training) Loss: 860763.8122\n",
      "(Validation) Loss: 689096.1549, MAE: 3093.2012, R2: 0.2988\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3362/5000] | Time: 0.39s\n",
      "(Training) Loss: 860656.2392\n",
      "(Validation) Loss: 689028.6832, MAE: 3093.9272, R2: 0.2989\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3363/5000] | Time: 0.37s\n",
      "(Training) Loss: 870551.0171\n",
      "(Validation) Loss: 688952.0375, MAE: 3092.6162, R2: 0.2990\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3364/5000] | Time: 0.35s\n",
      "(Training) Loss: 864471.2912\n",
      "(Validation) Loss: 688882.6102, MAE: 3092.7104, R2: 0.2990\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3365/5000] | Time: 0.31s\n",
      "(Training) Loss: 856101.6291\n",
      "(Validation) Loss: 688803.6324, MAE: 3091.7905, R2: 0.2991\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3366/5000] | Time: 0.33s\n",
      "(Training) Loss: 863244.0387\n",
      "(Validation) Loss: 688728.1352, MAE: 3091.8945, R2: 0.2992\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3367/5000] | Time: 0.32s\n",
      "(Training) Loss: 866183.5577\n",
      "(Validation) Loss: 688656.2984, MAE: 3091.4417, R2: 0.2993\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3368/5000] | Time: 0.35s\n",
      "(Training) Loss: 864548.3766\n",
      "(Validation) Loss: 688575.5200, MAE: 3089.4163, R2: 0.2993\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3369/5000] | Time: 0.34s\n",
      "(Training) Loss: 864452.0838\n",
      "(Validation) Loss: 688502.7041, MAE: 3089.2092, R2: 0.2994\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3370/5000] | Time: 0.36s\n",
      "(Training) Loss: 858245.8503\n",
      "(Validation) Loss: 688428.3187, MAE: 3089.4314, R2: 0.2995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3371/5000] | Time: 0.35s\n",
      "(Training) Loss: 863514.3547\n",
      "(Validation) Loss: 688357.0635, MAE: 3089.0254, R2: 0.2996\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3372/5000] | Time: 0.32s\n",
      "(Training) Loss: 875818.2443\n",
      "(Validation) Loss: 688289.7079, MAE: 3090.0457, R2: 0.2996\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3373/5000] | Time: 0.32s\n",
      "(Training) Loss: 878722.7176\n",
      "(Validation) Loss: 688202.9092, MAE: 3087.3765, R2: 0.2997\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3374/5000] | Time: 0.33s\n",
      "(Training) Loss: 881540.4270\n",
      "(Validation) Loss: 688158.2508, MAE: 3092.0320, R2: 0.2998\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3375/5000] | Time: 0.35s\n",
      "(Training) Loss: 870417.4296\n",
      "(Validation) Loss: 688054.1644, MAE: 3086.8005, R2: 0.2999\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3376/5000] | Time: 0.33s\n",
      "(Training) Loss: 863089.2989\n",
      "(Validation) Loss: 687977.5549, MAE: 3085.9404, R2: 0.2999\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3377/5000] | Time: 0.35s\n",
      "(Training) Loss: 867743.7973\n",
      "(Validation) Loss: 687925.1587, MAE: 3089.7424, R2: 0.3000\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3378/5000] | Time: 0.33s\n",
      "(Training) Loss: 860889.2931\n",
      "(Validation) Loss: 687839.4984, MAE: 3087.3879, R2: 0.3001\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3379/5000] | Time: 0.32s\n",
      "(Training) Loss: 854875.3969\n",
      "(Validation) Loss: 687768.6044, MAE: 3087.3936, R2: 0.3001\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3380/5000] | Time: 0.36s\n",
      "(Training) Loss: 861796.5146\n",
      "(Validation) Loss: 687706.7321, MAE: 3090.5889, R2: 0.3002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3381/5000] | Time: 0.34s\n",
      "(Training) Loss: 865412.0527\n",
      "(Validation) Loss: 687639.7771, MAE: 3090.0886, R2: 0.3003\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3382/5000] | Time: 0.35s\n",
      "(Training) Loss: 853661.9743\n",
      "(Validation) Loss: 687538.8438, MAE: 3085.9570, R2: 0.3004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3383/5000] | Time: 0.31s\n",
      "(Training) Loss: 864877.7487\n",
      "(Validation) Loss: 687465.6400, MAE: 3084.6641, R2: 0.3005\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3384/5000] | Time: 0.34s\n",
      "(Training) Loss: 858812.3579\n",
      "(Validation) Loss: 687384.7010, MAE: 3082.4131, R2: 0.3005\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3385/5000] | Time: 0.36s\n",
      "(Training) Loss: 853125.2985\n",
      "(Validation) Loss: 687318.9054, MAE: 3083.9690, R2: 0.3006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3386/5000] | Time: 0.30s\n",
      "(Training) Loss: 858118.7773\n",
      "(Validation) Loss: 687244.8432, MAE: 3083.1650, R2: 0.3007\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3387/5000] | Time: 0.35s\n",
      "(Training) Loss: 870748.6345\n",
      "(Validation) Loss: 687174.6946, MAE: 3084.6404, R2: 0.3007\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3388/5000] | Time: 0.34s\n",
      "(Training) Loss: 854722.1053\n",
      "(Validation) Loss: 687100.2019, MAE: 3083.4055, R2: 0.3008\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3389/5000] | Time: 0.35s\n",
      "(Training) Loss: 854109.9302\n",
      "(Validation) Loss: 687022.2152, MAE: 3082.2703, R2: 0.3009\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3390/5000] | Time: 0.32s\n",
      "(Training) Loss: 856707.4975\n",
      "(Validation) Loss: 686945.5752, MAE: 3081.6799, R2: 0.3010\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3391/5000] | Time: 0.34s\n",
      "(Training) Loss: 872678.1701\n",
      "(Validation) Loss: 686872.6279, MAE: 3080.6584, R2: 0.3011\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3392/5000] | Time: 0.35s\n",
      "(Training) Loss: 868346.2843\n",
      "(Validation) Loss: 686811.7556, MAE: 3083.5706, R2: 0.3011\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3393/5000] | Time: 0.35s\n",
      "(Training) Loss: 858569.9473\n",
      "(Validation) Loss: 686726.8165, MAE: 3080.5098, R2: 0.3012\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3394/5000] | Time: 0.33s\n",
      "(Training) Loss: 852504.0752\n",
      "(Validation) Loss: 686646.8343, MAE: 3078.3740, R2: 0.3013\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3395/5000] | Time: 0.33s\n",
      "(Training) Loss: 872114.2069\n",
      "(Validation) Loss: 686604.5276, MAE: 3080.5837, R2: 0.3013\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3396/5000] | Time: 0.32s\n",
      "(Training) Loss: 868172.4826\n",
      "(Validation) Loss: 686506.2457, MAE: 3079.5115, R2: 0.3014\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3397/5000] | Time: 0.32s\n",
      "(Training) Loss: 859573.3541\n",
      "(Validation) Loss: 686435.4825, MAE: 3081.7292, R2: 0.3015\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3398/5000] | Time: 0.38s\n",
      "(Training) Loss: 866839.1999\n",
      "(Validation) Loss: 686355.5581, MAE: 3079.0422, R2: 0.3016\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3399/5000] | Time: 0.33s\n",
      "(Training) Loss: 867465.8490\n",
      "(Validation) Loss: 688619.0178, MAE: 3082.2004, R2: 0.2993\n",
      "==========================================================================================\n",
      "Epoch [3400/5000] | Time: 0.33s\n",
      "(Training) Loss: 858993.0089\n",
      "(Validation) Loss: 688571.9790, MAE: 3088.1260, R2: 0.2993\n",
      "==========================================================================================\n",
      "Epoch [3401/5000] | Time: 0.31s\n",
      "(Training) Loss: 874276.4730\n",
      "(Validation) Loss: 688487.8997, MAE: 3084.6235, R2: 0.2994\n",
      "==========================================================================================\n",
      "Epoch [3402/5000] | Time: 0.42s\n",
      "(Training) Loss: 871443.6161\n",
      "(Validation) Loss: 688419.5676, MAE: 3086.7695, R2: 0.2995\n",
      "==========================================================================================\n",
      "Epoch [3403/5000] | Time: 0.36s\n",
      "(Training) Loss: 859616.0799\n",
      "(Validation) Loss: 688346.2883, MAE: 3085.5278, R2: 0.2996\n",
      "==========================================================================================\n",
      "Epoch [3404/5000] | Time: 0.31s\n",
      "(Training) Loss: 859946.1631\n",
      "(Validation) Loss: 688283.0476, MAE: 3087.0952, R2: 0.2996\n",
      "==========================================================================================\n",
      "Epoch [3405/5000] | Time: 0.37s\n",
      "(Training) Loss: 857351.0355\n",
      "(Validation) Loss: 688197.6235, MAE: 3083.6926, R2: 0.2997\n",
      "==========================================================================================\n",
      "Epoch [3406/5000] | Time: 0.33s\n",
      "(Training) Loss: 867281.8395\n",
      "(Validation) Loss: 688125.3162, MAE: 3083.7537, R2: 0.2998\n",
      "==========================================================================================\n",
      "Epoch [3407/5000] | Time: 0.35s\n",
      "(Training) Loss: 853894.9965\n",
      "(Validation) Loss: 688039.2495, MAE: 3081.0474, R2: 0.2999\n",
      "==========================================================================================\n",
      "Epoch [3408/5000] | Time: 0.37s\n",
      "(Training) Loss: 878083.1859\n",
      "(Validation) Loss: 687965.9283, MAE: 3081.4099, R2: 0.3000\n",
      "==========================================================================================\n",
      "Epoch [3409/5000] | Time: 0.41s\n",
      "(Training) Loss: 875603.5533\n",
      "(Validation) Loss: 687888.3556, MAE: 3079.3433, R2: 0.3000\n",
      "==========================================================================================\n",
      "Epoch [3410/5000] | Time: 0.41s\n",
      "(Training) Loss: 876496.1313\n",
      "(Validation) Loss: 687813.5276, MAE: 3080.4019, R2: 0.3001\n",
      "==========================================================================================\n",
      "Epoch [3411/5000] | Time: 0.39s\n",
      "(Training) Loss: 865912.8306\n",
      "(Validation) Loss: 687738.5060, MAE: 3080.1946, R2: 0.3002\n",
      "==========================================================================================\n",
      "Epoch [3412/5000] | Time: 0.38s\n",
      "(Training) Loss: 854758.2654\n",
      "(Validation) Loss: 705333.6444, MAE: 3122.2419, R2: 0.2824\n",
      "==========================================================================================\n",
      "Epoch [3413/5000] | Time: 0.37s\n",
      "(Training) Loss: 874278.8309\n",
      "(Validation) Loss: 705254.8076, MAE: 3120.5891, R2: 0.2825\n",
      "==========================================================================================\n",
      "Epoch [3414/5000] | Time: 0.33s\n",
      "(Training) Loss: 872490.3479\n",
      "(Validation) Loss: 705182.7930, MAE: 3120.6355, R2: 0.2826\n",
      "==========================================================================================\n",
      "Epoch [3415/5000] | Time: 0.34s\n",
      "(Training) Loss: 890999.7640\n",
      "(Validation) Loss: 705102.4000, MAE: 3119.2456, R2: 0.2826\n",
      "==========================================================================================\n",
      "Epoch [3416/5000] | Time: 0.35s\n",
      "(Training) Loss: 885355.5476\n",
      "(Validation) Loss: 705048.2210, MAE: 3121.7861, R2: 0.2827\n",
      "==========================================================================================\n",
      "Epoch [3417/5000] | Time: 0.36s\n",
      "(Training) Loss: 892751.8376\n",
      "(Validation) Loss: 704948.8000, MAE: 3117.5347, R2: 0.2828\n",
      "==========================================================================================\n",
      "Epoch [3418/5000] | Time: 0.35s\n",
      "(Training) Loss: 881912.1485\n",
      "(Validation) Loss: 704873.8235, MAE: 3118.4575, R2: 0.2829\n",
      "==========================================================================================\n",
      "Epoch [3419/5000] | Time: 0.30s\n",
      "(Training) Loss: 871419.7511\n",
      "(Validation) Loss: 704795.3803, MAE: 3117.6313, R2: 0.2830\n",
      "==========================================================================================\n",
      "Epoch [3420/5000] | Time: 0.31s\n",
      "(Training) Loss: 884303.8471\n",
      "(Validation) Loss: 704717.9441, MAE: 3116.5486, R2: 0.2830\n",
      "==========================================================================================\n",
      "Epoch [3421/5000] | Time: 0.33s\n",
      "(Training) Loss: 899553.6916\n",
      "(Validation) Loss: 704646.2337, MAE: 3116.4473, R2: 0.2831\n",
      "==========================================================================================\n",
      "Epoch [3422/5000] | Time: 0.34s\n",
      "(Training) Loss: 886167.7640\n",
      "(Validation) Loss: 704566.0806, MAE: 3116.4290, R2: 0.2832\n",
      "==========================================================================================\n",
      "Epoch [3423/5000] | Time: 0.34s\n",
      "(Training) Loss: 889339.2208\n",
      "(Validation) Loss: 704491.6286, MAE: 3115.3159, R2: 0.2833\n",
      "==========================================================================================\n",
      "Epoch [3424/5000] | Time: 0.38s\n",
      "(Training) Loss: 885280.0374\n",
      "(Validation) Loss: 704408.9206, MAE: 3113.5051, R2: 0.2833\n",
      "==========================================================================================\n",
      "Epoch [3425/5000] | Time: 0.32s\n",
      "(Training) Loss: 898175.5704\n",
      "(Validation) Loss: 704335.0902, MAE: 3113.6780, R2: 0.2834\n",
      "==========================================================================================\n",
      "Epoch [3426/5000] | Time: 0.34s\n",
      "(Training) Loss: 874837.7386\n",
      "(Validation) Loss: 704265.9213, MAE: 3115.4238, R2: 0.2835\n",
      "==========================================================================================\n",
      "Epoch [3427/5000] | Time: 0.34s\n",
      "(Training) Loss: 880982.6428\n",
      "(Validation) Loss: 704186.1156, MAE: 3113.3181, R2: 0.2836\n",
      "==========================================================================================\n",
      "Epoch [3428/5000] | Time: 0.34s\n",
      "(Training) Loss: 879732.0558\n",
      "(Validation) Loss: 704107.2140, MAE: 3111.8396, R2: 0.2837\n",
      "==========================================================================================\n",
      "Epoch [3429/5000] | Time: 0.33s\n",
      "(Training) Loss: 893792.2373\n",
      "(Validation) Loss: 704034.5987, MAE: 3112.2317, R2: 0.2837\n",
      "==========================================================================================\n",
      "Epoch [3430/5000] | Time: 0.33s\n",
      "(Training) Loss: 882983.6504\n",
      "(Validation) Loss: 703976.5175, MAE: 3115.8796, R2: 0.2838\n",
      "==========================================================================================\n",
      "Epoch [3431/5000] | Time: 0.33s\n",
      "(Training) Loss: 889743.1225\n",
      "(Validation) Loss: 703895.8343, MAE: 3114.4739, R2: 0.2839\n",
      "==========================================================================================\n",
      "Epoch [3432/5000] | Time: 0.35s\n",
      "(Training) Loss: 870333.5965\n",
      "(Validation) Loss: 703812.2254, MAE: 3112.6709, R2: 0.2839\n",
      "==========================================================================================\n",
      "Epoch [3433/5000] | Time: 0.32s\n",
      "(Training) Loss: 880156.8141\n",
      "(Validation) Loss: 703729.3035, MAE: 3110.1169, R2: 0.2840\n",
      "==========================================================================================\n",
      "Epoch [3434/5000] | Time: 0.33s\n",
      "(Training) Loss: 880197.7002\n",
      "(Validation) Loss: 703654.5594, MAE: 3109.2898, R2: 0.2841\n",
      "==========================================================================================\n",
      "Epoch [3435/5000] | Time: 0.36s\n",
      "(Training) Loss: 885226.9010\n",
      "(Validation) Loss: 703581.4673, MAE: 3109.4712, R2: 0.2842\n",
      "==========================================================================================\n",
      "Epoch [3436/5000] | Time: 0.33s\n",
      "(Training) Loss: 893835.5990\n",
      "(Validation) Loss: 703512.6698, MAE: 3110.6182, R2: 0.2843\n",
      "==========================================================================================\n",
      "Epoch [3437/5000] | Time: 0.37s\n",
      "(Training) Loss: 879141.6066\n",
      "(Validation) Loss: 703435.0254, MAE: 3109.3762, R2: 0.2843\n",
      "==========================================================================================\n",
      "Epoch [3438/5000] | Time: 0.38s\n",
      "(Training) Loss: 886429.3782\n",
      "(Validation) Loss: 703362.2089, MAE: 3109.8687, R2: 0.2844\n",
      "==========================================================================================\n",
      "Epoch [3439/5000] | Time: 0.36s\n",
      "(Training) Loss: 879106.9004\n",
      "(Validation) Loss: 703276.1613, MAE: 3107.1240, R2: 0.2845\n",
      "==========================================================================================\n",
      "Epoch [3440/5000] | Time: 0.33s\n",
      "(Training) Loss: 879994.3556\n",
      "(Validation) Loss: 703208.1346, MAE: 3109.0383, R2: 0.2846\n",
      "==========================================================================================\n",
      "Epoch [3441/5000] | Time: 0.35s\n",
      "(Training) Loss: 884248.8147\n",
      "(Validation) Loss: 703133.7930, MAE: 3107.7290, R2: 0.2846\n",
      "==========================================================================================\n",
      "Epoch [3442/5000] | Time: 0.35s\n",
      "(Training) Loss: 897116.3852\n",
      "(Validation) Loss: 703058.9810, MAE: 3108.8164, R2: 0.2847\n",
      "==========================================================================================\n",
      "Epoch [3443/5000] | Time: 0.35s\n",
      "(Training) Loss: 873299.3347\n",
      "(Validation) Loss: 702983.8800, MAE: 3106.8054, R2: 0.2848\n",
      "==========================================================================================\n",
      "Epoch [3444/5000] | Time: 0.36s\n",
      "(Training) Loss: 874757.9296\n",
      "(Validation) Loss: 702910.0863, MAE: 3107.3242, R2: 0.2849\n",
      "==========================================================================================\n",
      "Epoch [3445/5000] | Time: 0.35s\n",
      "(Training) Loss: 884287.8458\n",
      "(Validation) Loss: 702857.9759, MAE: 3110.5771, R2: 0.2849\n",
      "==========================================================================================\n",
      "Epoch [3446/5000] | Time: 0.33s\n",
      "(Training) Loss: 872912.4762\n",
      "(Validation) Loss: 702760.1384, MAE: 3106.2444, R2: 0.2850\n",
      "==========================================================================================\n",
      "Epoch [3447/5000] | Time: 0.32s\n",
      "(Training) Loss: 881586.6840\n",
      "(Validation) Loss: 702683.2819, MAE: 3105.8459, R2: 0.2851\n",
      "==========================================================================================\n",
      "Epoch [3448/5000] | Time: 0.34s\n",
      "(Training) Loss: 876987.5882\n",
      "(Validation) Loss: 702614.0997, MAE: 3106.8718, R2: 0.2852\n",
      "==========================================================================================\n",
      "Epoch [3449/5000] | Time: 0.32s\n",
      "(Training) Loss: 878988.3661\n",
      "(Validation) Loss: 702541.2679, MAE: 3107.2566, R2: 0.2852\n",
      "==========================================================================================\n",
      "Epoch [3450/5000] | Time: 0.35s\n",
      "(Training) Loss: 868706.2462\n",
      "(Validation) Loss: 702468.5956, MAE: 3106.8066, R2: 0.2853\n",
      "==========================================================================================\n",
      "Epoch [3451/5000] | Time: 0.36s\n",
      "(Training) Loss: 869615.3490\n",
      "(Validation) Loss: 702384.5911, MAE: 3104.0547, R2: 0.2854\n",
      "==========================================================================================\n",
      "Epoch [3452/5000] | Time: 0.36s\n",
      "(Training) Loss: 872877.3160\n",
      "(Validation) Loss: 702317.2127, MAE: 3105.6108, R2: 0.2855\n",
      "==========================================================================================\n",
      "Epoch [3453/5000] | Time: 0.35s\n",
      "(Training) Loss: 890152.1827\n",
      "(Validation) Loss: 702279.9746, MAE: 3111.7996, R2: 0.2855\n",
      "==========================================================================================\n",
      "Epoch [3454/5000] | Time: 0.40s\n",
      "(Training) Loss: 883302.4118\n",
      "(Validation) Loss: 702185.7327, MAE: 3110.0076, R2: 0.2856\n",
      "==========================================================================================\n",
      "Epoch [3455/5000] | Time: 0.38s\n",
      "(Training) Loss: 879037.7094\n",
      "(Validation) Loss: 702115.0762, MAE: 3110.6494, R2: 0.2857\n",
      "==========================================================================================\n",
      "Epoch [3456/5000] | Time: 0.39s\n",
      "(Training) Loss: 888349.5051\n",
      "(Validation) Loss: 702036.3663, MAE: 3108.3066, R2: 0.2857\n",
      "==========================================================================================\n",
      "Epoch [3457/5000] | Time: 0.37s\n",
      "(Training) Loss: 882457.4162\n",
      "(Validation) Loss: 701962.2590, MAE: 3107.8030, R2: 0.2858\n",
      "==========================================================================================\n",
      "Epoch [3458/5000] | Time: 0.33s\n",
      "(Training) Loss: 873735.3274\n",
      "(Validation) Loss: 701875.4603, MAE: 3104.0112, R2: 0.2859\n",
      "==========================================================================================\n",
      "Epoch [3459/5000] | Time: 0.32s\n",
      "(Training) Loss: 880595.3458\n",
      "(Validation) Loss: 701802.5549, MAE: 3104.2788, R2: 0.2860\n",
      "==========================================================================================\n",
      "Epoch [3460/5000] | Time: 0.34s\n",
      "(Training) Loss: 876812.0558\n",
      "(Validation) Loss: 701722.0876, MAE: 3102.2727, R2: 0.2861\n",
      "==========================================================================================\n",
      "Epoch [3461/5000] | Time: 0.34s\n",
      "(Training) Loss: 871802.6123\n",
      "(Validation) Loss: 701643.9594, MAE: 3101.5647, R2: 0.2861\n",
      "==========================================================================================\n",
      "Epoch [3462/5000] | Time: 0.33s\n",
      "(Training) Loss: 874961.0780\n",
      "(Validation) Loss: 701574.8540, MAE: 3102.6353, R2: 0.2862\n",
      "==========================================================================================\n",
      "Epoch [3463/5000] | Time: 0.32s\n",
      "(Training) Loss: 883602.8325\n",
      "(Validation) Loss: 701521.9911, MAE: 3107.5845, R2: 0.2863\n",
      "==========================================================================================\n",
      "Epoch [3464/5000] | Time: 0.35s\n",
      "(Training) Loss: 878245.0901\n",
      "(Validation) Loss: 701366.0502, MAE: 3105.3416, R2: 0.2864\n",
      "==========================================================================================\n",
      "Epoch [3465/5000] | Time: 0.36s\n",
      "(Training) Loss: 875110.7665\n",
      "(Validation) Loss: 701353.3505, MAE: 3103.5996, R2: 0.2864\n",
      "==========================================================================================\n",
      "Epoch [3466/5000] | Time: 0.31s\n",
      "(Training) Loss: 867541.2083\n",
      "(Validation) Loss: 701227.8667, MAE: 3097.0962, R2: 0.2866\n",
      "==========================================================================================\n",
      "Epoch [3467/5000] | Time: 0.31s\n",
      "(Training) Loss: 881743.2456\n",
      "(Validation) Loss: 701161.7473, MAE: 3097.7346, R2: 0.2866\n",
      "==========================================================================================\n",
      "Epoch [3468/5000] | Time: 0.32s\n",
      "(Training) Loss: 886297.2532\n",
      "(Validation) Loss: 701084.6832, MAE: 3097.0864, R2: 0.2867\n",
      "==========================================================================================\n",
      "Epoch [3469/5000] | Time: 0.31s\n",
      "(Training) Loss: 888438.6751\n",
      "(Validation) Loss: 701005.3714, MAE: 3095.7336, R2: 0.2868\n",
      "==========================================================================================\n",
      "Epoch [3470/5000] | Time: 0.33s\n",
      "(Training) Loss: 874711.2722\n",
      "(Validation) Loss: 700935.4933, MAE: 3097.2632, R2: 0.2869\n",
      "==========================================================================================\n",
      "Epoch [3471/5000] | Time: 0.31s\n",
      "(Training) Loss: 893865.3439\n",
      "(Validation) Loss: 700871.4711, MAE: 3098.5742, R2: 0.2869\n",
      "==========================================================================================\n",
      "Epoch [3472/5000] | Time: 0.39s\n",
      "(Training) Loss: 874201.1561\n",
      "(Validation) Loss: 700783.9092, MAE: 3094.9727, R2: 0.2870\n",
      "==========================================================================================\n",
      "Epoch [3473/5000] | Time: 0.35s\n",
      "(Training) Loss: 892482.8496\n",
      "(Validation) Loss: 700719.8165, MAE: 3098.3118, R2: 0.2871\n",
      "==========================================================================================\n",
      "Epoch [3474/5000] | Time: 0.37s\n",
      "(Training) Loss: 898257.6396\n",
      "(Validation) Loss: 700643.0597, MAE: 3097.1567, R2: 0.2871\n",
      "==========================================================================================\n",
      "Epoch [3475/5000] | Time: 0.30s\n",
      "(Training) Loss: 883204.9651\n",
      "(Validation) Loss: 700577.5746, MAE: 3099.7307, R2: 0.2872\n",
      "==========================================================================================\n",
      "Epoch [3476/5000] | Time: 0.32s\n",
      "(Training) Loss: 873180.2405\n",
      "(Validation) Loss: 700487.8121, MAE: 3093.4861, R2: 0.2873\n",
      "==========================================================================================\n",
      "Epoch [3477/5000] | Time: 0.33s\n",
      "(Training) Loss: 886211.0333\n",
      "(Validation) Loss: 700419.1549, MAE: 3095.1636, R2: 0.2874\n",
      "==========================================================================================\n",
      "Epoch [3478/5000] | Time: 0.35s\n",
      "(Training) Loss: 881838.0311\n",
      "(Validation) Loss: 700338.3219, MAE: 3093.8945, R2: 0.2875\n",
      "==========================================================================================\n",
      "Epoch [3479/5000] | Time: 0.37s\n",
      "(Training) Loss: 875593.2145\n",
      "(Validation) Loss: 700265.9276, MAE: 3093.9746, R2: 0.2875\n",
      "==========================================================================================\n",
      "Epoch [3480/5000] | Time: 0.33s\n",
      "(Training) Loss: 885794.1218\n",
      "(Validation) Loss: 700193.9270, MAE: 3092.7959, R2: 0.2876\n",
      "==========================================================================================\n",
      "Epoch [3481/5000] | Time: 0.31s\n",
      "(Training) Loss: 882323.0787\n",
      "(Validation) Loss: 698428.1219, MAE: 3088.1519, R2: 0.2894\n",
      "==========================================================================================\n",
      "Epoch [3482/5000] | Time: 0.34s\n",
      "(Training) Loss: 875324.6815\n",
      "(Validation) Loss: 698360.9765, MAE: 3087.7263, R2: 0.2895\n",
      "==========================================================================================\n",
      "Epoch [3483/5000] | Time: 0.30s\n",
      "(Training) Loss: 872091.9480\n",
      "(Validation) Loss: 698284.5327, MAE: 3086.2461, R2: 0.2895\n",
      "==========================================================================================\n",
      "Epoch [3484/5000] | Time: 0.33s\n",
      "(Training) Loss: 887879.0990\n",
      "(Validation) Loss: 698213.8819, MAE: 3087.5198, R2: 0.2896\n",
      "==========================================================================================\n",
      "Epoch [3485/5000] | Time: 0.40s\n",
      "(Training) Loss: 880270.7760\n",
      "(Validation) Loss: 698159.6698, MAE: 3088.2710, R2: 0.2897\n",
      "==========================================================================================\n",
      "Epoch [3486/5000] | Time: 0.33s\n",
      "(Training) Loss: 876707.5635\n",
      "(Validation) Loss: 698070.0584, MAE: 3084.3308, R2: 0.2897\n",
      "==========================================================================================\n",
      "Epoch [3487/5000] | Time: 0.36s\n",
      "(Training) Loss: 863566.9055\n",
      "(Validation) Loss: 697985.9575, MAE: 3080.0303, R2: 0.2898\n",
      "==========================================================================================\n",
      "Epoch [3488/5000] | Time: 0.36s\n",
      "(Training) Loss: 871884.2627\n",
      "(Validation) Loss: 698260.0444, MAE: 3103.3159, R2: 0.2895\n",
      "==========================================================================================\n",
      "Epoch [3489/5000] | Time: 0.31s\n",
      "(Training) Loss: 881995.5850\n",
      "(Validation) Loss: 698182.7638, MAE: 3101.2212, R2: 0.2896\n",
      "==========================================================================================\n",
      "Epoch [3490/5000] | Time: 0.32s\n",
      "(Training) Loss: 871440.0612\n",
      "(Validation) Loss: 698114.8959, MAE: 3102.4834, R2: 0.2897\n",
      "==========================================================================================\n",
      "Epoch [3491/5000] | Time: 0.37s\n",
      "(Training) Loss: 876945.2170\n",
      "(Validation) Loss: 698048.8737, MAE: 3104.2004, R2: 0.2898\n",
      "==========================================================================================\n",
      "Epoch [3492/5000] | Time: 0.37s\n",
      "(Training) Loss: 883327.6009\n",
      "(Validation) Loss: 697981.6743, MAE: 3104.2263, R2: 0.2898\n",
      "==========================================================================================\n",
      "Epoch [3493/5000] | Time: 0.34s\n",
      "(Training) Loss: 876162.2107\n",
      "(Validation) Loss: 697905.0895, MAE: 3102.5117, R2: 0.2899\n",
      "==========================================================================================\n",
      "Epoch [3494/5000] | Time: 0.36s\n",
      "(Training) Loss: 872747.4981\n",
      "(Validation) Loss: 697830.0571, MAE: 3102.0642, R2: 0.2900\n",
      "==========================================================================================\n",
      "Epoch [3495/5000] | Time: 0.32s\n",
      "(Training) Loss: 874546.9632\n",
      "(Validation) Loss: 697757.6546, MAE: 3101.7639, R2: 0.2901\n",
      "==========================================================================================\n",
      "Epoch [3496/5000] | Time: 0.35s\n",
      "(Training) Loss: 893020.5571\n",
      "(Validation) Loss: 697688.2476, MAE: 3101.4299, R2: 0.2901\n",
      "==========================================================================================\n",
      "Epoch [3497/5000] | Time: 0.37s\n",
      "(Training) Loss: 875578.0330\n",
      "(Validation) Loss: 697613.2083, MAE: 3101.3044, R2: 0.2902\n",
      "==========================================================================================\n",
      "Epoch [3498/5000] | Time: 0.36s\n",
      "(Training) Loss: 868441.5901\n",
      "(Validation) Loss: 697543.3365, MAE: 3101.6213, R2: 0.2903\n",
      "==========================================================================================\n",
      "Epoch [3499/5000] | Time: 0.33s\n",
      "(Training) Loss: 867145.8845\n",
      "(Validation) Loss: 697472.7816, MAE: 3101.4045, R2: 0.2903\n",
      "==========================================================================================\n",
      "Epoch [3500/5000] | Time: 0.36s\n",
      "(Training) Loss: 887301.6440\n",
      "(Validation) Loss: 697401.6006, MAE: 3100.9153, R2: 0.2904\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch3500.pth\n",
      "==========================================================================================\n",
      "Epoch [3501/5000] | Time: 0.39s\n",
      "(Training) Loss: 864531.5255\n",
      "(Validation) Loss: 697332.3181, MAE: 3101.5508, R2: 0.2905\n",
      "==========================================================================================\n",
      "Epoch [3502/5000] | Time: 0.40s\n",
      "(Training) Loss: 890697.5178\n",
      "(Validation) Loss: 697258.2241, MAE: 3101.0115, R2: 0.2906\n",
      "==========================================================================================\n",
      "Epoch [3503/5000] | Time: 0.42s\n",
      "(Training) Loss: 869746.9727\n",
      "(Validation) Loss: 697184.8584, MAE: 3099.6841, R2: 0.2906\n",
      "==========================================================================================\n",
      "Epoch [3504/5000] | Time: 0.38s\n",
      "(Training) Loss: 883953.4670\n",
      "(Validation) Loss: 697114.3924, MAE: 3100.3423, R2: 0.2907\n",
      "==========================================================================================\n",
      "Epoch [3505/5000] | Time: 0.35s\n",
      "(Training) Loss: 862693.5916\n",
      "(Validation) Loss: 697043.0089, MAE: 3100.6521, R2: 0.2908\n",
      "==========================================================================================\n",
      "Epoch [3506/5000] | Time: 0.34s\n",
      "(Training) Loss: 864110.0747\n",
      "(Validation) Loss: 696975.9898, MAE: 3101.4153, R2: 0.2908\n",
      "==========================================================================================\n",
      "Epoch [3507/5000] | Time: 0.35s\n",
      "(Training) Loss: 884008.3769\n",
      "(Validation) Loss: 696897.7797, MAE: 3099.4346, R2: 0.2909\n",
      "==========================================================================================\n",
      "Epoch [3508/5000] | Time: 0.36s\n",
      "(Training) Loss: 868639.8414\n",
      "(Validation) Loss: 696827.5321, MAE: 3098.7661, R2: 0.2910\n",
      "==========================================================================================\n",
      "Epoch [3509/5000] | Time: 0.35s\n",
      "(Training) Loss: 876921.4549\n",
      "(Validation) Loss: 696760.3194, MAE: 3100.2312, R2: 0.2911\n",
      "==========================================================================================\n",
      "Epoch [3510/5000] | Time: 0.34s\n",
      "(Training) Loss: 870702.6770\n",
      "(Validation) Loss: 696691.4571, MAE: 3100.3181, R2: 0.2911\n",
      "==========================================================================================\n",
      "Epoch [3511/5000] | Time: 0.33s\n",
      "(Training) Loss: 890677.5882\n",
      "(Validation) Loss: 696619.9333, MAE: 3100.3467, R2: 0.2912\n",
      "==========================================================================================\n",
      "Epoch [3512/5000] | Time: 0.31s\n",
      "(Training) Loss: 871003.6228\n",
      "(Validation) Loss: 696544.2698, MAE: 3099.2566, R2: 0.2913\n",
      "==========================================================================================\n",
      "Epoch [3513/5000] | Time: 0.32s\n",
      "(Training) Loss: 864777.3883\n",
      "(Validation) Loss: 696468.9524, MAE: 3097.3870, R2: 0.2914\n",
      "==========================================================================================\n",
      "Epoch [3514/5000] | Time: 0.35s\n",
      "(Training) Loss: 885828.9638\n",
      "(Validation) Loss: 696399.3283, MAE: 3098.7222, R2: 0.2914\n",
      "==========================================================================================\n",
      "Epoch [3515/5000] | Time: 0.38s\n",
      "(Training) Loss: 869924.4461\n",
      "(Validation) Loss: 696334.1810, MAE: 3101.7729, R2: 0.2915\n",
      "==========================================================================================\n",
      "Epoch [3516/5000] | Time: 0.34s\n",
      "(Training) Loss: 866123.0793\n",
      "(Validation) Loss: 696261.7848, MAE: 3100.8005, R2: 0.2916\n",
      "==========================================================================================\n",
      "Epoch [3517/5000] | Time: 0.33s\n",
      "(Training) Loss: 876025.5571\n",
      "(Validation) Loss: 696188.5530, MAE: 3099.5994, R2: 0.2916\n",
      "==========================================================================================\n",
      "Epoch [3518/5000] | Time: 0.34s\n",
      "(Training) Loss: 882889.0324\n",
      "(Validation) Loss: 696124.7232, MAE: 3102.9038, R2: 0.2917\n",
      "==========================================================================================\n",
      "Epoch [3519/5000] | Time: 0.34s\n",
      "(Training) Loss: 866807.2500\n",
      "(Validation) Loss: 696045.3048, MAE: 3098.6743, R2: 0.2918\n",
      "==========================================================================================\n",
      "Epoch [3520/5000] | Time: 0.34s\n",
      "(Training) Loss: 881404.3287\n",
      "(Validation) Loss: 695977.0965, MAE: 3101.8225, R2: 0.2919\n",
      "==========================================================================================\n",
      "Epoch [3521/5000] | Time: 0.33s\n",
      "(Training) Loss: 866647.8845\n",
      "(Validation) Loss: 695904.7854, MAE: 3100.0171, R2: 0.2919\n",
      "==========================================================================================\n",
      "Epoch [3522/5000] | Time: 0.31s\n",
      "(Training) Loss: 866883.2354\n",
      "(Validation) Loss: 695838.3803, MAE: 3101.1841, R2: 0.2920\n",
      "==========================================================================================\n",
      "Epoch [3523/5000] | Time: 0.31s\n",
      "(Training) Loss: 863905.2084\n",
      "(Validation) Loss: 696279.5041, MAE: 3156.9792, R2: 0.2916\n",
      "==========================================================================================\n",
      "Epoch [3524/5000] | Time: 0.32s\n",
      "(Training) Loss: 867127.5495\n",
      "(Validation) Loss: 695696.1600, MAE: 3102.7588, R2: 0.2921\n",
      "==========================================================================================\n",
      "Epoch [3525/5000] | Time: 0.31s\n",
      "(Training) Loss: 869810.1720\n",
      "(Validation) Loss: 695625.5803, MAE: 3100.5825, R2: 0.2922\n",
      "==========================================================================================\n",
      "Epoch [3526/5000] | Time: 0.37s\n",
      "(Training) Loss: 879382.4004\n",
      "(Validation) Loss: 695551.1695, MAE: 3100.0779, R2: 0.2923\n",
      "==========================================================================================\n",
      "Epoch [3527/5000] | Time: 0.33s\n",
      "(Training) Loss: 865085.9873\n",
      "(Validation) Loss: 695485.3860, MAE: 3101.2356, R2: 0.2924\n",
      "==========================================================================================\n",
      "Epoch [3528/5000] | Time: 0.35s\n",
      "(Training) Loss: 871206.4556\n",
      "(Validation) Loss: 695426.9314, MAE: 3102.8826, R2: 0.2924\n",
      "==========================================================================================\n",
      "Epoch [3529/5000] | Time: 0.37s\n",
      "(Training) Loss: 884828.1212\n",
      "(Validation) Loss: 695337.2140, MAE: 3098.4863, R2: 0.2925\n",
      "==========================================================================================\n",
      "Epoch [3530/5000] | Time: 0.36s\n",
      "(Training) Loss: 876494.1402\n",
      "(Validation) Loss: 695267.3054, MAE: 3097.9866, R2: 0.2926\n",
      "==========================================================================================\n",
      "Epoch [3531/5000] | Time: 0.37s\n",
      "(Training) Loss: 863346.1009\n",
      "(Validation) Loss: 695201.8102, MAE: 3100.8965, R2: 0.2926\n",
      "==========================================================================================\n",
      "Epoch [3532/5000] | Time: 0.37s\n",
      "(Training) Loss: 862729.0543\n",
      "(Validation) Loss: 695126.3067, MAE: 3097.8542, R2: 0.2927\n",
      "==========================================================================================\n",
      "Epoch [3533/5000] | Time: 0.35s\n",
      "(Training) Loss: 868223.0685\n",
      "(Validation) Loss: 695058.5137, MAE: 3098.3958, R2: 0.2928\n",
      "==========================================================================================\n",
      "Epoch [3534/5000] | Time: 0.33s\n",
      "(Training) Loss: 885346.0831\n",
      "(Validation) Loss: 694979.5803, MAE: 3095.6631, R2: 0.2929\n",
      "==========================================================================================\n",
      "Epoch [3535/5000] | Time: 0.33s\n",
      "(Training) Loss: 872382.2119\n",
      "(Validation) Loss: 694907.7498, MAE: 3094.8682, R2: 0.2929\n",
      "==========================================================================================\n",
      "Epoch [3536/5000] | Time: 0.38s\n",
      "(Training) Loss: 866088.8731\n",
      "(Validation) Loss: 694837.5721, MAE: 3095.6382, R2: 0.2930\n",
      "==========================================================================================\n",
      "Epoch [3537/5000] | Time: 0.34s\n",
      "(Training) Loss: 865349.1961\n",
      "(Validation) Loss: 694767.5219, MAE: 3095.5889, R2: 0.2931\n",
      "==========================================================================================\n",
      "Epoch [3538/5000] | Time: 0.33s\n",
      "(Training) Loss: 865371.8496\n",
      "(Validation) Loss: 694704.4235, MAE: 3097.5288, R2: 0.2931\n",
      "==========================================================================================\n",
      "Epoch [3539/5000] | Time: 0.34s\n",
      "(Training) Loss: 869543.0704\n",
      "(Validation) Loss: 694630.3638, MAE: 3094.7896, R2: 0.2932\n",
      "==========================================================================================\n",
      "Epoch [3540/5000] | Time: 0.36s\n",
      "(Training) Loss: 893028.2640\n",
      "(Validation) Loss: 694552.5867, MAE: 3094.3252, R2: 0.2933\n",
      "==========================================================================================\n",
      "Epoch [3541/5000] | Time: 0.31s\n",
      "(Training) Loss: 896717.2811\n",
      "(Validation) Loss: 694484.0292, MAE: 3094.3274, R2: 0.2934\n",
      "==========================================================================================\n",
      "Epoch [3542/5000] | Time: 0.34s\n",
      "(Training) Loss: 868789.5850\n",
      "(Validation) Loss: 694408.5206, MAE: 3093.8191, R2: 0.2934\n",
      "==========================================================================================\n",
      "Epoch [3543/5000] | Time: 0.33s\n",
      "(Training) Loss: 865149.2481\n",
      "(Validation) Loss: 694340.0413, MAE: 3094.3347, R2: 0.2935\n",
      "==========================================================================================\n",
      "Epoch [3544/5000] | Time: 0.37s\n",
      "(Training) Loss: 861562.6996\n",
      "(Validation) Loss: 694268.7911, MAE: 3094.3799, R2: 0.2936\n",
      "==========================================================================================\n",
      "Epoch [3545/5000] | Time: 0.35s\n",
      "(Training) Loss: 870894.7183\n",
      "(Validation) Loss: 694196.9619, MAE: 3092.6990, R2: 0.2937\n",
      "==========================================================================================\n",
      "Epoch [3546/5000] | Time: 0.32s\n",
      "(Training) Loss: 870928.3052\n",
      "(Validation) Loss: 694129.0140, MAE: 3092.8047, R2: 0.2937\n",
      "==========================================================================================\n",
      "Epoch [3547/5000] | Time: 0.34s\n",
      "(Training) Loss: 880290.1574\n",
      "(Validation) Loss: 694062.6610, MAE: 3093.7158, R2: 0.2938\n",
      "==========================================================================================\n",
      "Epoch [3548/5000] | Time: 0.39s\n",
      "(Training) Loss: 870929.5457\n",
      "(Validation) Loss: 693985.7587, MAE: 3091.4797, R2: 0.2939\n",
      "==========================================================================================\n",
      "Epoch [3549/5000] | Time: 0.35s\n",
      "(Training) Loss: 878898.4892\n",
      "(Validation) Loss: 693916.1359, MAE: 3092.2854, R2: 0.2939\n",
      "==========================================================================================\n",
      "Epoch [3550/5000] | Time: 0.35s\n",
      "(Training) Loss: 878341.5539\n",
      "(Validation) Loss: 693842.3454, MAE: 3090.6875, R2: 0.2940\n",
      "==========================================================================================\n",
      "Epoch [3551/5000] | Time: 0.36s\n",
      "(Training) Loss: 859559.3594\n",
      "(Validation) Loss: 693778.1562, MAE: 3092.4133, R2: 0.2941\n",
      "==========================================================================================\n",
      "Epoch [3552/5000] | Time: 0.33s\n",
      "(Training) Loss: 878730.3953\n",
      "(Validation) Loss: 693704.1035, MAE: 3091.2329, R2: 0.2941\n",
      "==========================================================================================\n",
      "Epoch [3553/5000] | Time: 0.36s\n",
      "(Training) Loss: 878361.8537\n",
      "(Validation) Loss: 693631.2330, MAE: 3091.8213, R2: 0.2942\n",
      "==========================================================================================\n",
      "Epoch [3554/5000] | Time: 0.32s\n",
      "(Training) Loss: 865610.5051\n",
      "(Validation) Loss: 693555.9467, MAE: 3089.5737, R2: 0.2943\n",
      "==========================================================================================\n",
      "Epoch [3555/5000] | Time: 0.32s\n",
      "(Training) Loss: 866400.8261\n",
      "(Validation) Loss: 693494.0679, MAE: 3092.1240, R2: 0.2944\n",
      "==========================================================================================\n",
      "Epoch [3556/5000] | Time: 0.33s\n",
      "(Training) Loss: 869122.6593\n",
      "(Validation) Loss: 693424.2330, MAE: 3094.4966, R2: 0.2944\n",
      "==========================================================================================\n",
      "Epoch [3557/5000] | Time: 0.37s\n",
      "(Training) Loss: 871666.4061\n",
      "(Validation) Loss: 693344.9200, MAE: 3089.1614, R2: 0.2945\n",
      "==========================================================================================\n",
      "Epoch [3558/5000] | Time: 0.36s\n",
      "(Training) Loss: 869839.9588\n",
      "(Validation) Loss: 693274.8051, MAE: 3089.3816, R2: 0.2946\n",
      "==========================================================================================\n",
      "Epoch [3559/5000] | Time: 0.37s\n",
      "(Training) Loss: 881905.3420\n",
      "(Validation) Loss: 693210.3759, MAE: 3090.1755, R2: 0.2946\n",
      "==========================================================================================\n",
      "Epoch [3560/5000] | Time: 0.37s\n",
      "(Training) Loss: 859541.2646\n",
      "(Validation) Loss: 693137.2768, MAE: 3090.5225, R2: 0.2947\n",
      "==========================================================================================\n",
      "Epoch [3561/5000] | Time: 0.35s\n",
      "(Training) Loss: 859160.4408\n",
      "(Validation) Loss: 693065.7498, MAE: 3089.2227, R2: 0.2948\n",
      "==========================================================================================\n",
      "Epoch [3562/5000] | Time: 0.38s\n",
      "(Training) Loss: 861242.9664\n",
      "(Validation) Loss: 693005.5879, MAE: 3092.8323, R2: 0.2949\n",
      "==========================================================================================\n",
      "Epoch [3563/5000] | Time: 0.36s\n",
      "(Training) Loss: 863365.1669\n",
      "(Validation) Loss: 692933.6133, MAE: 3092.8669, R2: 0.2949\n",
      "==========================================================================================\n",
      "Epoch [3564/5000] | Time: 0.36s\n",
      "(Training) Loss: 869791.2551\n",
      "(Validation) Loss: 692861.6540, MAE: 3091.9124, R2: 0.2950\n",
      "==========================================================================================\n",
      "Epoch [3565/5000] | Time: 0.36s\n",
      "(Training) Loss: 875982.5425\n",
      "(Validation) Loss: 692793.2146, MAE: 3092.5115, R2: 0.2951\n",
      "==========================================================================================\n",
      "Epoch [3566/5000] | Time: 0.36s\n",
      "(Training) Loss: 861587.9270\n",
      "(Validation) Loss: 692716.9219, MAE: 3090.0911, R2: 0.2951\n",
      "==========================================================================================\n",
      "Epoch [3567/5000] | Time: 0.37s\n",
      "(Training) Loss: 878395.9898\n",
      "(Validation) Loss: 692656.8863, MAE: 3092.5686, R2: 0.2952\n",
      "==========================================================================================\n",
      "Epoch [3568/5000] | Time: 0.34s\n",
      "(Training) Loss: 869166.1954\n",
      "(Validation) Loss: 692574.8317, MAE: 3088.6658, R2: 0.2953\n",
      "==========================================================================================\n",
      "Epoch [3569/5000] | Time: 0.34s\n",
      "(Training) Loss: 871441.0254\n",
      "(Validation) Loss: 692507.6025, MAE: 3090.9504, R2: 0.2954\n",
      "==========================================================================================\n",
      "Epoch [3570/5000] | Time: 0.38s\n",
      "(Training) Loss: 863765.0774\n",
      "(Validation) Loss: 692441.6908, MAE: 3091.6003, R2: 0.2954\n",
      "==========================================================================================\n",
      "Epoch [3571/5000] | Time: 0.37s\n",
      "(Training) Loss: 862320.2671\n",
      "(Validation) Loss: 692367.0197, MAE: 3089.6067, R2: 0.2955\n",
      "==========================================================================================\n",
      "Epoch [3572/5000] | Time: 0.31s\n",
      "(Training) Loss: 891224.0866\n",
      "(Validation) Loss: 692290.5670, MAE: 3086.8069, R2: 0.2956\n",
      "==========================================================================================\n",
      "Epoch [3573/5000] | Time: 0.33s\n",
      "(Training) Loss: 867007.5419\n",
      "(Validation) Loss: 692224.6121, MAE: 3088.7031, R2: 0.2956\n",
      "==========================================================================================\n",
      "Epoch [3574/5000] | Time: 0.38s\n",
      "(Training) Loss: 861092.5622\n",
      "(Validation) Loss: 692152.0654, MAE: 3088.3364, R2: 0.2957\n",
      "==========================================================================================\n",
      "Epoch [3575/5000] | Time: 0.35s\n",
      "(Training) Loss: 857515.1299\n",
      "(Validation) Loss: 692075.9663, MAE: 3087.3901, R2: 0.2958\n",
      "==========================================================================================\n",
      "Epoch [3576/5000] | Time: 0.33s\n",
      "(Training) Loss: 868815.6707\n",
      "(Validation) Loss: 692016.2152, MAE: 3090.1455, R2: 0.2959\n",
      "==========================================================================================\n",
      "Epoch [3577/5000] | Time: 0.32s\n",
      "(Training) Loss: 888979.4956\n",
      "(Validation) Loss: 691943.5822, MAE: 3090.6184, R2: 0.2959\n",
      "==========================================================================================\n",
      "Epoch [3578/5000] | Time: 0.35s\n",
      "(Training) Loss: 873918.6637\n",
      "(Validation) Loss: 691870.6717, MAE: 3088.5762, R2: 0.2960\n",
      "==========================================================================================\n",
      "Epoch [3579/5000] | Time: 0.36s\n",
      "(Training) Loss: 868755.4156\n",
      "(Validation) Loss: 691800.7054, MAE: 3088.3594, R2: 0.2961\n",
      "==========================================================================================\n",
      "Epoch [3580/5000] | Time: 0.36s\n",
      "(Training) Loss: 860571.8407\n",
      "(Validation) Loss: 691724.3606, MAE: 3086.6006, R2: 0.2961\n",
      "==========================================================================================\n",
      "Epoch [3581/5000] | Time: 0.34s\n",
      "(Training) Loss: 871036.0711\n",
      "(Validation) Loss: 691657.6121, MAE: 3087.1733, R2: 0.2962\n",
      "==========================================================================================\n",
      "Epoch [3582/5000] | Time: 0.36s\n",
      "(Training) Loss: 865920.4435\n",
      "(Validation) Loss: 691588.8419, MAE: 3087.0261, R2: 0.2963\n",
      "==========================================================================================\n",
      "Epoch [3583/5000] | Time: 0.33s\n",
      "(Training) Loss: 873452.5787\n",
      "(Validation) Loss: 691519.5467, MAE: 3089.3867, R2: 0.2964\n",
      "==========================================================================================\n",
      "Epoch [3584/5000] | Time: 0.34s\n",
      "(Training) Loss: 892410.7418\n",
      "(Validation) Loss: 691447.9943, MAE: 3087.9172, R2: 0.2964\n",
      "==========================================================================================\n",
      "Epoch [3585/5000] | Time: 0.34s\n",
      "(Training) Loss: 873165.6567\n",
      "(Validation) Loss: 691374.3765, MAE: 3086.5688, R2: 0.2965\n",
      "==========================================================================================\n",
      "Epoch [3586/5000] | Time: 0.32s\n",
      "(Training) Loss: 873415.3623\n",
      "(Validation) Loss: 691300.0863, MAE: 3085.9114, R2: 0.2966\n",
      "==========================================================================================\n",
      "Epoch [3587/5000] | Time: 0.35s\n",
      "(Training) Loss: 871818.4023\n",
      "(Validation) Loss: 691236.8229, MAE: 3088.3528, R2: 0.2966\n",
      "==========================================================================================\n",
      "Epoch [3588/5000] | Time: 0.39s\n",
      "(Training) Loss: 857518.9177\n",
      "(Validation) Loss: 691154.7740, MAE: 3083.8638, R2: 0.2967\n",
      "==========================================================================================\n",
      "Epoch [3589/5000] | Time: 0.37s\n",
      "(Training) Loss: 864246.3484\n",
      "(Validation) Loss: 691106.1854, MAE: 3087.3174, R2: 0.2968\n",
      "==========================================================================================\n",
      "Epoch [3590/5000] | Time: 0.36s\n",
      "(Training) Loss: 875522.5089\n",
      "(Validation) Loss: 691019.9340, MAE: 3085.1033, R2: 0.2969\n",
      "==========================================================================================\n",
      "Epoch [3591/5000] | Time: 0.37s\n",
      "(Training) Loss: 865938.9156\n",
      "(Validation) Loss: 690946.2971, MAE: 3083.8665, R2: 0.2969\n",
      "==========================================================================================\n",
      "Epoch [3592/5000] | Time: 0.41s\n",
      "(Training) Loss: 859798.3433\n",
      "(Validation) Loss: 690873.0330, MAE: 3083.3044, R2: 0.2970\n",
      "==========================================================================================\n",
      "Epoch [3593/5000] | Time: 0.41s\n",
      "(Training) Loss: 866694.7801\n",
      "(Validation) Loss: 690809.8552, MAE: 3083.7749, R2: 0.2971\n",
      "==========================================================================================\n",
      "Epoch [3594/5000] | Time: 0.41s\n",
      "(Training) Loss: 878776.3696\n",
      "(Validation) Loss: 690734.8730, MAE: 3082.4578, R2: 0.2971\n",
      "==========================================================================================\n",
      "Epoch [3595/5000] | Time: 0.38s\n",
      "(Training) Loss: 866644.6523\n",
      "(Validation) Loss: 690662.8876, MAE: 3081.9758, R2: 0.2972\n",
      "==========================================================================================\n",
      "Epoch [3596/5000] | Time: 0.35s\n",
      "(Training) Loss: 861094.1440\n",
      "(Validation) Loss: 690594.5048, MAE: 3083.3232, R2: 0.2973\n",
      "==========================================================================================\n",
      "Epoch [3597/5000] | Time: 0.35s\n",
      "(Training) Loss: 856708.2835\n",
      "(Validation) Loss: 690533.8737, MAE: 3090.6404, R2: 0.2974\n",
      "==========================================================================================\n",
      "Epoch [3598/5000] | Time: 0.35s\n",
      "(Training) Loss: 865606.2046\n",
      "(Validation) Loss: 690464.2730, MAE: 3088.8406, R2: 0.2974\n",
      "==========================================================================================\n",
      "Epoch [3599/5000] | Time: 0.35s\n",
      "(Training) Loss: 874595.9911\n",
      "(Validation) Loss: 690391.7930, MAE: 3087.4546, R2: 0.2975\n",
      "==========================================================================================\n",
      "Epoch [3600/5000] | Time: 0.39s\n",
      "(Training) Loss: 870739.3693\n",
      "(Validation) Loss: 690322.2311, MAE: 3085.5684, R2: 0.2976\n",
      "==========================================================================================\n",
      "Epoch [3601/5000] | Time: 0.41s\n",
      "(Training) Loss: 875799.0393\n",
      "(Validation) Loss: 690250.2159, MAE: 3085.3159, R2: 0.2976\n",
      "==========================================================================================\n",
      "Epoch [3602/5000] | Time: 0.38s\n",
      "(Training) Loss: 875679.7605\n",
      "(Validation) Loss: 690179.4997, MAE: 3085.5698, R2: 0.2977\n",
      "==========================================================================================\n",
      "Epoch [3603/5000] | Time: 0.41s\n",
      "(Training) Loss: 872182.0660\n",
      "(Validation) Loss: 690103.6343, MAE: 3082.6667, R2: 0.2978\n",
      "==========================================================================================\n",
      "Epoch [3604/5000] | Time: 0.43s\n",
      "(Training) Loss: 867791.1421\n",
      "(Validation) Loss: 690042.0908, MAE: 3085.4006, R2: 0.2978\n",
      "==========================================================================================\n",
      "Epoch [3605/5000] | Time: 0.38s\n",
      "(Training) Loss: 864038.7538\n",
      "(Validation) Loss: 689977.4686, MAE: 3085.9036, R2: 0.2979\n",
      "==========================================================================================\n",
      "Epoch [3606/5000] | Time: 0.33s\n",
      "(Training) Loss: 869696.9632\n",
      "(Validation) Loss: 689896.2362, MAE: 3082.6790, R2: 0.2980\n",
      "==========================================================================================\n",
      "Epoch [3607/5000] | Time: 0.35s\n",
      "(Training) Loss: 864348.9762\n",
      "(Validation) Loss: 689825.8921, MAE: 3082.3528, R2: 0.2981\n",
      "==========================================================================================\n",
      "Epoch [3608/5000] | Time: 0.37s\n",
      "(Training) Loss: 869445.0825\n",
      "(Validation) Loss: 689758.7543, MAE: 3082.5425, R2: 0.2981\n",
      "==========================================================================================\n",
      "Epoch [3609/5000] | Time: 0.32s\n",
      "(Training) Loss: 872921.5305\n",
      "(Validation) Loss: 689685.6965, MAE: 3081.2302, R2: 0.2982\n",
      "==========================================================================================\n",
      "Epoch [3610/5000] | Time: 0.36s\n",
      "(Training) Loss: 855528.1701\n",
      "(Validation) Loss: 689615.2800, MAE: 3080.8809, R2: 0.2983\n",
      "==========================================================================================\n",
      "Epoch [3611/5000] | Time: 0.38s\n",
      "(Training) Loss: 867063.8350\n",
      "(Validation) Loss: 689543.7721, MAE: 3080.8953, R2: 0.2984\n",
      "==========================================================================================\n",
      "Epoch [3612/5000] | Time: 0.35s\n",
      "(Training) Loss: 865354.8503\n",
      "(Validation) Loss: 689475.0546, MAE: 3079.7742, R2: 0.2984\n",
      "==========================================================================================\n",
      "Epoch [3613/5000] | Time: 0.39s\n",
      "(Training) Loss: 860105.8236\n",
      "(Validation) Loss: 689402.9289, MAE: 3080.2292, R2: 0.2985\n",
      "==========================================================================================\n",
      "Epoch [3614/5000] | Time: 0.38s\n",
      "(Training) Loss: 861259.7982\n",
      "(Validation) Loss: 689332.2140, MAE: 3080.3206, R2: 0.2986\n",
      "==========================================================================================\n",
      "Epoch [3615/5000] | Time: 0.39s\n",
      "(Training) Loss: 854288.6455\n",
      "(Validation) Loss: 689267.6940, MAE: 3080.6118, R2: 0.2986\n",
      "==========================================================================================\n",
      "Epoch [3616/5000] | Time: 0.33s\n",
      "(Training) Loss: 859203.0749\n",
      "(Validation) Loss: 689199.3079, MAE: 3081.0176, R2: 0.2987\n",
      "==========================================================================================\n",
      "Epoch [3617/5000] | Time: 0.37s\n",
      "(Training) Loss: 862278.8890\n",
      "(Validation) Loss: 689127.6368, MAE: 3079.8333, R2: 0.2988\n",
      "==========================================================================================\n",
      "Epoch [3618/5000] | Time: 0.42s\n",
      "(Training) Loss: 863710.0298\n",
      "(Validation) Loss: 689058.3632, MAE: 3080.1113, R2: 0.2988\n",
      "==========================================================================================\n",
      "Epoch [3619/5000] | Time: 0.42s\n",
      "(Training) Loss: 853594.5966\n",
      "(Validation) Loss: 688995.2394, MAE: 3083.9290, R2: 0.2989\n",
      "==========================================================================================\n",
      "Epoch [3620/5000] | Time: 0.45s\n",
      "(Training) Loss: 859676.2947\n",
      "(Validation) Loss: 688919.5435, MAE: 3081.4470, R2: 0.2990\n",
      "==========================================================================================\n",
      "Epoch [3621/5000] | Time: 0.36s\n",
      "(Training) Loss: 863738.0286\n",
      "(Validation) Loss: 688852.4330, MAE: 3081.9099, R2: 0.2991\n",
      "==========================================================================================\n",
      "Epoch [3622/5000] | Time: 0.35s\n",
      "(Training) Loss: 868444.2798\n",
      "(Validation) Loss: 688781.8902, MAE: 3082.0288, R2: 0.2991\n",
      "==========================================================================================\n",
      "Epoch [3623/5000] | Time: 0.38s\n",
      "(Training) Loss: 863277.8744\n",
      "(Validation) Loss: 688714.6298, MAE: 3081.4724, R2: 0.2992\n",
      "==========================================================================================\n",
      "Epoch [3624/5000] | Time: 0.39s\n",
      "(Training) Loss: 858091.7532\n",
      "(Validation) Loss: 688637.4083, MAE: 3079.4397, R2: 0.2993\n",
      "==========================================================================================\n",
      "Epoch [3625/5000] | Time: 0.38s\n",
      "(Training) Loss: 877980.9457\n",
      "(Validation) Loss: 688566.3219, MAE: 3078.9507, R2: 0.2993\n",
      "==========================================================================================\n",
      "Epoch [3626/5000] | Time: 0.40s\n",
      "(Training) Loss: 868049.2341\n",
      "(Validation) Loss: 688503.0057, MAE: 3081.5437, R2: 0.2994\n",
      "==========================================================================================\n",
      "Epoch [3627/5000] | Time: 0.37s\n",
      "(Training) Loss: 857776.9816\n",
      "(Validation) Loss: 688445.8267, MAE: 3083.7576, R2: 0.2995\n",
      "==========================================================================================\n",
      "Epoch [3628/5000] | Time: 0.38s\n",
      "(Training) Loss: 881534.0717\n",
      "(Validation) Loss: 688362.9702, MAE: 3079.9089, R2: 0.2995\n",
      "==========================================================================================\n",
      "Epoch [3629/5000] | Time: 0.38s\n",
      "(Training) Loss: 864137.4676\n",
      "(Validation) Loss: 688287.4324, MAE: 3079.3613, R2: 0.2996\n",
      "==========================================================================================\n",
      "Epoch [3630/5000] | Time: 0.42s\n",
      "(Training) Loss: 861512.9594\n",
      "(Validation) Loss: 688213.9867, MAE: 3078.3337, R2: 0.2997\n",
      "==========================================================================================\n",
      "Epoch [3631/5000] | Time: 0.36s\n",
      "(Training) Loss: 869782.9607\n",
      "(Validation) Loss: 688153.8997, MAE: 3081.0488, R2: 0.2998\n",
      "==========================================================================================\n",
      "Epoch [3632/5000] | Time: 0.40s\n",
      "(Training) Loss: 871980.8699\n",
      "(Validation) Loss: 688074.3625, MAE: 3078.1384, R2: 0.2998\n",
      "==========================================================================================\n",
      "Epoch [3633/5000] | Time: 0.43s\n",
      "(Training) Loss: 860323.5673\n",
      "(Validation) Loss: 688008.1390, MAE: 3077.9578, R2: 0.2999\n",
      "==========================================================================================\n",
      "Epoch [3634/5000] | Time: 0.49s\n",
      "(Training) Loss: 859393.6916\n",
      "(Validation) Loss: 687938.9175, MAE: 3078.2361, R2: 0.3000\n",
      "==========================================================================================\n",
      "Epoch [3635/5000] | Time: 0.53s\n",
      "(Training) Loss: 857936.3534\n",
      "(Validation) Loss: 687873.1124, MAE: 3078.4187, R2: 0.3000\n",
      "==========================================================================================\n",
      "Epoch [3636/5000] | Time: 0.49s\n",
      "(Training) Loss: 857389.8388\n",
      "(Validation) Loss: 687794.0260, MAE: 3075.9707, R2: 0.3001\n",
      "==========================================================================================\n",
      "Epoch [3637/5000] | Time: 0.45s\n",
      "(Training) Loss: 878731.3712\n",
      "(Validation) Loss: 687728.5778, MAE: 3077.6333, R2: 0.3002\n",
      "==========================================================================================\n",
      "Epoch [3638/5000] | Time: 0.46s\n",
      "(Training) Loss: 861117.2024\n",
      "(Validation) Loss: 687659.5683, MAE: 3077.7581, R2: 0.3003\n",
      "==========================================================================================\n",
      "Epoch [3639/5000] | Time: 0.49s\n",
      "(Training) Loss: 858733.7798\n",
      "(Validation) Loss: 687650.7397, MAE: 3088.1816, R2: 0.3003\n",
      "==========================================================================================\n",
      "Epoch [3640/5000] | Time: 0.34s\n",
      "(Training) Loss: 864423.1631\n",
      "(Validation) Loss: 687514.4406, MAE: 3076.7642, R2: 0.3004\n",
      "==========================================================================================\n",
      "Epoch [3641/5000] | Time: 0.34s\n",
      "(Training) Loss: 866234.9626\n",
      "(Validation) Loss: 687446.2229, MAE: 3077.1987, R2: 0.3005\n",
      "==========================================================================================\n",
      "Epoch [3642/5000] | Time: 0.41s\n",
      "(Training) Loss: 851997.6336\n",
      "(Validation) Loss: 687378.7041, MAE: 3077.7380, R2: 0.3005\n",
      "==========================================================================================\n",
      "Epoch [3643/5000] | Time: 0.44s\n",
      "(Training) Loss: 861020.6602\n",
      "(Validation) Loss: 687313.7181, MAE: 3078.1353, R2: 0.3006\n",
      "==========================================================================================\n",
      "Epoch [3644/5000] | Time: 0.38s\n",
      "(Training) Loss: 868194.0273\n",
      "(Validation) Loss: 687241.2597, MAE: 3076.2517, R2: 0.3007\n",
      "==========================================================================================\n",
      "Epoch [3645/5000] | Time: 0.45s\n",
      "(Training) Loss: 864305.5495\n",
      "(Validation) Loss: 687167.2311, MAE: 3076.0547, R2: 0.3008\n",
      "==========================================================================================\n",
      "Epoch [3646/5000] | Time: 0.40s\n",
      "(Training) Loss: 859995.4381\n",
      "(Validation) Loss: 687097.7441, MAE: 3077.4749, R2: 0.3008\n",
      "==========================================================================================\n",
      "Epoch [3647/5000] | Time: 0.43s\n",
      "(Training) Loss: 880161.9727\n",
      "(Validation) Loss: 724041.5549, MAE: 3193.7239, R2: 0.2635\n",
      "==========================================================================================\n",
      "Epoch [3648/5000] | Time: 0.41s\n",
      "(Training) Loss: 914685.5463\n",
      "(Validation) Loss: 723911.6933, MAE: 3173.4363, R2: 0.2637\n",
      "==========================================================================================\n",
      "Epoch [3649/5000] | Time: 0.37s\n",
      "(Training) Loss: 903710.7614\n",
      "(Validation) Loss: 732715.5683, MAE: 3192.9448, R2: 0.2548\n",
      "==========================================================================================\n",
      "Epoch [3650/5000] | Time: 0.40s\n",
      "(Training) Loss: 913305.5324\n",
      "(Validation) Loss: 732549.9314, MAE: 3182.3291, R2: 0.2550\n",
      "==========================================================================================\n",
      "Epoch [3651/5000] | Time: 0.39s\n",
      "(Training) Loss: 916960.8464\n",
      "(Validation) Loss: 732463.7670, MAE: 3181.2253, R2: 0.2550\n",
      "==========================================================================================\n",
      "Epoch [3652/5000] | Time: 0.44s\n",
      "(Training) Loss: 913192.5406\n",
      "(Validation) Loss: 732376.9149, MAE: 3180.5261, R2: 0.2551\n",
      "==========================================================================================\n",
      "Epoch [3653/5000] | Time: 0.41s\n",
      "(Training) Loss: 910929.1307\n",
      "(Validation) Loss: 732289.9067, MAE: 3178.5605, R2: 0.2552\n",
      "==========================================================================================\n",
      "Epoch [3654/5000] | Time: 0.38s\n",
      "(Training) Loss: 912875.4454\n",
      "(Validation) Loss: 732212.0019, MAE: 3178.1829, R2: 0.2553\n",
      "==========================================================================================\n",
      "Epoch [3655/5000] | Time: 0.39s\n",
      "(Training) Loss: 914603.1358\n",
      "(Validation) Loss: 732128.5244, MAE: 3177.5278, R2: 0.2554\n",
      "==========================================================================================\n",
      "Epoch [3656/5000] | Time: 0.47s\n",
      "(Training) Loss: 919575.4603\n",
      "(Validation) Loss: 732047.6914, MAE: 3177.1777, R2: 0.2555\n",
      "==========================================================================================\n",
      "Epoch [3657/5000] | Time: 0.38s\n",
      "(Training) Loss: 910243.7011\n",
      "(Validation) Loss: 731970.5892, MAE: 3177.1233, R2: 0.2555\n",
      "==========================================================================================\n",
      "Epoch [3658/5000] | Time: 0.41s\n",
      "(Training) Loss: 910673.3750\n",
      "(Validation) Loss: 731891.8254, MAE: 3176.6079, R2: 0.2556\n",
      "==========================================================================================\n",
      "Epoch [3659/5000] | Time: 0.43s\n",
      "(Training) Loss: 917027.4778\n",
      "(Validation) Loss: 731815.7276, MAE: 3177.6746, R2: 0.2557\n",
      "==========================================================================================\n",
      "Epoch [3660/5000] | Time: 0.38s\n",
      "(Training) Loss: 918879.3579\n",
      "(Validation) Loss: 731747.0686, MAE: 3179.6868, R2: 0.2558\n",
      "==========================================================================================\n",
      "Epoch [3661/5000] | Time: 0.38s\n",
      "(Training) Loss: 926547.0022\n",
      "(Validation) Loss: 731657.5187, MAE: 3176.1492, R2: 0.2559\n",
      "==========================================================================================\n",
      "Epoch [3662/5000] | Time: 0.47s\n",
      "(Training) Loss: 912362.9569\n",
      "(Validation) Loss: 736169.9689, MAE: 3194.9702, R2: 0.2513\n",
      "==========================================================================================\n",
      "Epoch [3663/5000] | Time: 0.51s\n",
      "(Training) Loss: 927851.3858\n",
      "(Validation) Loss: 736085.6978, MAE: 3191.8953, R2: 0.2514\n",
      "==========================================================================================\n",
      "Epoch [3664/5000] | Time: 0.45s\n",
      "(Training) Loss: 914794.0990\n",
      "(Validation) Loss: 736008.7867, MAE: 3190.7686, R2: 0.2515\n",
      "==========================================================================================\n",
      "Epoch [3665/5000] | Time: 0.45s\n",
      "(Training) Loss: 934369.9334\n",
      "(Validation) Loss: 735934.3130, MAE: 3189.7788, R2: 0.2515\n",
      "==========================================================================================\n",
      "Epoch [3666/5000] | Time: 0.42s\n",
      "(Training) Loss: 934757.9803\n",
      "(Validation) Loss: 735849.5924, MAE: 3187.8088, R2: 0.2516\n",
      "==========================================================================================\n",
      "Epoch [3667/5000] | Time: 0.45s\n",
      "(Training) Loss: 939293.8109\n",
      "(Validation) Loss: 735782.4305, MAE: 3190.7043, R2: 0.2517\n",
      "==========================================================================================\n",
      "Epoch [3668/5000] | Time: 0.44s\n",
      "(Training) Loss: 921741.8839\n",
      "(Validation) Loss: 735703.4432, MAE: 3189.3679, R2: 0.2518\n",
      "==========================================================================================\n",
      "Epoch [3669/5000] | Time: 0.44s\n",
      "(Training) Loss: 919065.6904\n",
      "(Validation) Loss: 735632.1613, MAE: 3188.9397, R2: 0.2518\n",
      "==========================================================================================\n",
      "Epoch [3670/5000] | Time: 0.50s\n",
      "(Training) Loss: 926205.3185\n",
      "(Validation) Loss: 735552.0686, MAE: 3187.6143, R2: 0.2519\n",
      "==========================================================================================\n",
      "Epoch [3671/5000] | Time: 0.54s\n",
      "(Training) Loss: 928638.3414\n",
      "(Validation) Loss: 735475.0337, MAE: 3187.0286, R2: 0.2520\n",
      "==========================================================================================\n",
      "Epoch [3672/5000] | Time: 0.53s\n",
      "(Training) Loss: 926490.6485\n",
      "(Validation) Loss: 735394.9035, MAE: 3185.7422, R2: 0.2521\n",
      "==========================================================================================\n",
      "Epoch [3673/5000] | Time: 0.42s\n",
      "(Training) Loss: 932055.7259\n",
      "(Validation) Loss: 735321.5359, MAE: 3185.5891, R2: 0.2522\n",
      "==========================================================================================\n",
      "Epoch [3674/5000] | Time: 0.38s\n",
      "(Training) Loss: 926659.5244\n",
      "(Validation) Loss: 735247.3149, MAE: 3185.2781, R2: 0.2522\n",
      "==========================================================================================\n",
      "Epoch [3675/5000] | Time: 0.40s\n",
      "(Training) Loss: 927211.4293\n",
      "(Validation) Loss: 735171.3606, MAE: 3184.7991, R2: 0.2523\n",
      "==========================================================================================\n",
      "Epoch [3676/5000] | Time: 0.41s\n",
      "(Training) Loss: 908802.3112\n",
      "(Validation) Loss: 735110.0571, MAE: 3187.1616, R2: 0.2524\n",
      "==========================================================================================\n",
      "Epoch [3677/5000] | Time: 0.36s\n",
      "(Training) Loss: 927970.5324\n",
      "(Validation) Loss: 735028.5581, MAE: 3185.1450, R2: 0.2525\n",
      "==========================================================================================\n",
      "Epoch [3678/5000] | Time: 0.34s\n",
      "(Training) Loss: 918217.2329\n",
      "(Validation) Loss: 734948.5543, MAE: 3183.8020, R2: 0.2525\n",
      "==========================================================================================\n",
      "Epoch [3679/5000] | Time: 0.35s\n",
      "(Training) Loss: 931005.3223\n",
      "(Validation) Loss: 734891.6343, MAE: 3187.8625, R2: 0.2526\n",
      "==========================================================================================\n",
      "Epoch [3680/5000] | Time: 0.36s\n",
      "(Training) Loss: 916273.7563\n",
      "(Validation) Loss: 734802.1587, MAE: 3184.6653, R2: 0.2527\n",
      "==========================================================================================\n",
      "Epoch [3681/5000] | Time: 0.37s\n",
      "(Training) Loss: 918830.5993\n",
      "(Validation) Loss: 734742.6184, MAE: 3187.8950, R2: 0.2527\n",
      "==========================================================================================\n",
      "Epoch [3682/5000] | Time: 0.36s\n",
      "(Training) Loss: 910099.2976\n",
      "(Validation) Loss: 734664.0229, MAE: 3184.9907, R2: 0.2528\n",
      "==========================================================================================\n",
      "Epoch [3683/5000] | Time: 0.40s\n",
      "(Training) Loss: 924426.1688\n",
      "(Validation) Loss: 734596.3537, MAE: 3188.3086, R2: 0.2529\n",
      "==========================================================================================\n",
      "Epoch [3684/5000] | Time: 0.39s\n",
      "(Training) Loss: 926088.9131\n",
      "(Validation) Loss: 734510.1562, MAE: 3183.5667, R2: 0.2530\n",
      "==========================================================================================\n",
      "Epoch [3685/5000] | Time: 0.41s\n",
      "(Training) Loss: 909828.7005\n",
      "(Validation) Loss: 734439.6660, MAE: 3185.2368, R2: 0.2531\n",
      "==========================================================================================\n",
      "Epoch [3686/5000] | Time: 0.37s\n",
      "(Training) Loss: 931404.8604\n",
      "(Validation) Loss: 734369.5860, MAE: 3184.1699, R2: 0.2531\n",
      "==========================================================================================\n",
      "Epoch [3687/5000] | Time: 0.38s\n",
      "(Training) Loss: 917445.9765\n",
      "(Validation) Loss: 734292.4794, MAE: 3184.3411, R2: 0.2532\n",
      "==========================================================================================\n",
      "Epoch [3688/5000] | Time: 0.35s\n",
      "(Training) Loss: 917489.4575\n",
      "(Validation) Loss: 734227.5359, MAE: 3184.5754, R2: 0.2533\n",
      "==========================================================================================\n",
      "Epoch [3689/5000] | Time: 0.34s\n",
      "(Training) Loss: 918259.7757\n",
      "(Validation) Loss: 734156.3092, MAE: 3186.1692, R2: 0.2533\n",
      "==========================================================================================\n",
      "Epoch [3690/5000] | Time: 0.46s\n",
      "(Training) Loss: 912868.1669\n",
      "(Validation) Loss: 734089.4044, MAE: 3186.9609, R2: 0.2534\n",
      "==========================================================================================\n",
      "Epoch [3691/5000] | Time: 0.40s\n",
      "(Training) Loss: 911392.2995\n",
      "(Validation) Loss: 734010.5479, MAE: 3185.4697, R2: 0.2535\n",
      "==========================================================================================\n",
      "Epoch [3692/5000] | Time: 0.40s\n",
      "(Training) Loss: 912255.2259\n",
      "(Validation) Loss: 733954.5663, MAE: 3187.7122, R2: 0.2535\n",
      "==========================================================================================\n",
      "Epoch [3693/5000] | Time: 0.37s\n",
      "(Training) Loss: 922032.9943\n",
      "(Validation) Loss: 733868.1238, MAE: 3184.6716, R2: 0.2536\n",
      "==========================================================================================\n",
      "Epoch [3694/5000] | Time: 0.37s\n",
      "(Training) Loss: 914082.6643\n",
      "(Validation) Loss: 733791.1105, MAE: 3182.9368, R2: 0.2537\n",
      "==========================================================================================\n",
      "Epoch [3695/5000] | Time: 0.37s\n",
      "(Training) Loss: 919004.9734\n",
      "(Validation) Loss: 733724.5371, MAE: 3185.3645, R2: 0.2538\n",
      "==========================================================================================\n",
      "Epoch [3696/5000] | Time: 0.40s\n",
      "(Training) Loss: 937980.1675\n",
      "(Validation) Loss: 733659.6857, MAE: 3185.0393, R2: 0.2538\n",
      "==========================================================================================\n",
      "Epoch [3697/5000] | Time: 0.42s\n",
      "(Training) Loss: 933813.5895\n",
      "(Validation) Loss: 733591.0000, MAE: 3186.4924, R2: 0.2539\n",
      "==========================================================================================\n",
      "Epoch [3698/5000] | Time: 0.43s\n",
      "(Training) Loss: 913296.6701\n",
      "(Validation) Loss: 733517.4622, MAE: 3187.0320, R2: 0.2540\n",
      "==========================================================================================\n",
      "Epoch [3699/5000] | Time: 0.38s\n",
      "(Training) Loss: 906914.1910\n",
      "(Validation) Loss: 733464.0914, MAE: 3189.4548, R2: 0.2540\n",
      "==========================================================================================\n",
      "Epoch [3700/5000] | Time: 0.42s\n",
      "(Training) Loss: 904690.8656\n",
      "(Validation) Loss: 733352.2781, MAE: 3182.3528, R2: 0.2541\n",
      "==========================================================================================\n",
      "Epoch [3701/5000] | Time: 0.42s\n",
      "(Training) Loss: 950931.9283\n",
      "(Validation) Loss: 733284.7803, MAE: 3184.1936, R2: 0.2542\n",
      "==========================================================================================\n",
      "Epoch [3702/5000] | Time: 0.46s\n",
      "(Training) Loss: 935531.1758\n",
      "(Validation) Loss: 733229.4463, MAE: 3185.3469, R2: 0.2543\n",
      "==========================================================================================\n",
      "Epoch [3703/5000] | Time: 0.41s\n",
      "(Training) Loss: 906378.5974\n",
      "(Validation) Loss: 733135.3175, MAE: 3182.6404, R2: 0.2544\n",
      "==========================================================================================\n",
      "Epoch [3704/5000] | Time: 0.44s\n",
      "(Training) Loss: 914884.2760\n",
      "(Validation) Loss: 733061.4921, MAE: 3182.7507, R2: 0.2544\n",
      "==========================================================================================\n",
      "Epoch [3705/5000] | Time: 0.45s\n",
      "(Training) Loss: 925035.5114\n",
      "(Validation) Loss: 732979.2095, MAE: 3178.5779, R2: 0.2545\n",
      "==========================================================================================\n",
      "Epoch [3706/5000] | Time: 0.46s\n",
      "(Training) Loss: 919159.2094\n",
      "(Validation) Loss: 732921.7403, MAE: 3181.3191, R2: 0.2546\n",
      "==========================================================================================\n",
      "Epoch [3707/5000] | Time: 0.44s\n",
      "(Training) Loss: 907952.0596\n",
      "(Validation) Loss: 732887.2889, MAE: 3188.3206, R2: 0.2546\n",
      "==========================================================================================\n",
      "Epoch [3708/5000] | Time: 0.43s\n",
      "(Training) Loss: 907596.7830\n",
      "(Validation) Loss: 732773.1130, MAE: 3181.1543, R2: 0.2547\n",
      "==========================================================================================\n",
      "Epoch [3709/5000] | Time: 0.32s\n",
      "(Training) Loss: 908178.9549\n",
      "(Validation) Loss: 732691.3822, MAE: 3177.0918, R2: 0.2548\n",
      "==========================================================================================\n",
      "Epoch [3710/5000] | Time: 0.45s\n",
      "(Training) Loss: 905389.9718\n",
      "(Validation) Loss: 732633.0260, MAE: 3179.6841, R2: 0.2549\n",
      "==========================================================================================\n",
      "Epoch [3711/5000] | Time: 0.50s\n",
      "(Training) Loss: 928119.9511\n",
      "(Validation) Loss: 732554.1771, MAE: 3177.5271, R2: 0.2550\n",
      "==========================================================================================\n",
      "Epoch [3712/5000] | Time: 0.47s\n",
      "(Training) Loss: 909667.4829\n",
      "(Validation) Loss: 732485.5949, MAE: 3179.2153, R2: 0.2550\n",
      "==========================================================================================\n",
      "Epoch [3713/5000] | Time: 0.41s\n",
      "(Training) Loss: 914752.3813\n",
      "(Validation) Loss: 732412.8133, MAE: 3177.9304, R2: 0.2551\n",
      "==========================================================================================\n",
      "Epoch [3714/5000] | Time: 0.33s\n",
      "(Training) Loss: 904585.8893\n",
      "(Validation) Loss: 732340.2171, MAE: 3177.1772, R2: 0.2552\n",
      "==========================================================================================\n",
      "Epoch [3715/5000] | Time: 0.38s\n",
      "(Training) Loss: 914197.4892\n",
      "(Validation) Loss: 732299.9733, MAE: 3184.2981, R2: 0.2552\n",
      "==========================================================================================\n",
      "Epoch [3716/5000] | Time: 0.45s\n",
      "(Training) Loss: 918974.9131\n",
      "(Validation) Loss: 732189.7638, MAE: 3177.6042, R2: 0.2553\n",
      "==========================================================================================\n",
      "Epoch [3717/5000] | Time: 0.41s\n",
      "(Training) Loss: 903311.4804\n",
      "(Validation) Loss: 732125.3054, MAE: 3177.3926, R2: 0.2554\n",
      "==========================================================================================\n",
      "Epoch [3718/5000] | Time: 0.42s\n",
      "(Training) Loss: 921773.6904\n",
      "(Validation) Loss: 732051.7213, MAE: 3175.9397, R2: 0.2555\n",
      "==========================================================================================\n",
      "Epoch [3719/5000] | Time: 0.42s\n",
      "(Training) Loss: 912119.0000\n",
      "(Validation) Loss: 731986.1416, MAE: 3178.1882, R2: 0.2555\n",
      "==========================================================================================\n",
      "Epoch [3720/5000] | Time: 0.35s\n",
      "(Training) Loss: 925506.3598\n",
      "(Validation) Loss: 731937.9467, MAE: 3181.7444, R2: 0.2556\n",
      "==========================================================================================\n",
      "Epoch [3721/5000] | Time: 0.42s\n",
      "(Training) Loss: 923713.8509\n",
      "(Validation) Loss: 731846.6133, MAE: 3178.6187, R2: 0.2557\n",
      "==========================================================================================\n",
      "Epoch [3722/5000] | Time: 0.35s\n",
      "(Training) Loss: 913622.4892\n",
      "(Validation) Loss: 731763.6286, MAE: 3179.2480, R2: 0.2557\n",
      "==========================================================================================\n",
      "Epoch [3723/5000] | Time: 0.40s\n",
      "(Training) Loss: 918129.7760\n",
      "(Validation) Loss: 731697.6178, MAE: 3178.0955, R2: 0.2558\n",
      "==========================================================================================\n",
      "Epoch [3724/5000] | Time: 0.32s\n",
      "(Training) Loss: 905925.6355\n",
      "(Validation) Loss: 731612.3917, MAE: 3174.7112, R2: 0.2559\n",
      "==========================================================================================\n",
      "Epoch [3725/5000] | Time: 0.32s\n",
      "(Training) Loss: 910420.4372\n",
      "(Validation) Loss: 731561.0533, MAE: 3179.1577, R2: 0.2560\n",
      "==========================================================================================\n",
      "Epoch [3726/5000] | Time: 0.35s\n",
      "(Training) Loss: 912060.1739\n",
      "(Validation) Loss: 731470.8400, MAE: 3175.0728, R2: 0.2560\n",
      "==========================================================================================\n",
      "Epoch [3727/5000] | Time: 0.35s\n",
      "(Training) Loss: 918868.8426\n",
      "(Validation) Loss: 731413.5683, MAE: 3178.1321, R2: 0.2561\n",
      "==========================================================================================\n",
      "Epoch [3728/5000] | Time: 0.36s\n",
      "(Training) Loss: 933674.1085\n",
      "(Validation) Loss: 731323.4178, MAE: 3172.9092, R2: 0.2562\n",
      "==========================================================================================\n",
      "Epoch [3729/5000] | Time: 0.38s\n",
      "(Training) Loss: 915525.7716\n",
      "(Validation) Loss: 731262.7740, MAE: 3174.3989, R2: 0.2563\n",
      "==========================================================================================\n",
      "Epoch [3730/5000] | Time: 0.37s\n",
      "(Training) Loss: 903059.5771\n",
      "(Validation) Loss: 731191.5860, MAE: 3174.2925, R2: 0.2563\n",
      "==========================================================================================\n",
      "Epoch [3731/5000] | Time: 0.36s\n",
      "(Training) Loss: 910852.2855\n",
      "(Validation) Loss: 731142.7200, MAE: 3176.9648, R2: 0.2564\n",
      "==========================================================================================\n",
      "Epoch [3732/5000] | Time: 0.33s\n",
      "(Training) Loss: 915217.6155\n",
      "(Validation) Loss: 731042.6127, MAE: 3171.8088, R2: 0.2565\n",
      "==========================================================================================\n",
      "Epoch [3733/5000] | Time: 0.36s\n",
      "(Training) Loss: 913952.5543\n",
      "(Validation) Loss: 730969.5041, MAE: 3173.3813, R2: 0.2566\n",
      "==========================================================================================\n",
      "Epoch [3734/5000] | Time: 0.34s\n",
      "(Training) Loss: 932740.2449\n",
      "(Validation) Loss: 730895.2337, MAE: 3170.4136, R2: 0.2566\n",
      "==========================================================================================\n",
      "Epoch [3735/5000] | Time: 0.36s\n",
      "(Training) Loss: 907568.2284\n",
      "(Validation) Loss: 730820.3943, MAE: 3171.1670, R2: 0.2567\n",
      "==========================================================================================\n",
      "Epoch [3736/5000] | Time: 0.33s\n",
      "(Training) Loss: 903492.9140\n",
      "(Validation) Loss: 730768.7232, MAE: 3173.8672, R2: 0.2568\n",
      "==========================================================================================\n",
      "Epoch [3737/5000] | Time: 0.32s\n",
      "(Training) Loss: 912282.3782\n",
      "(Validation) Loss: 730687.8838, MAE: 3171.2815, R2: 0.2568\n",
      "==========================================================================================\n",
      "Epoch [3738/5000] | Time: 0.35s\n",
      "(Training) Loss: 915768.3871\n",
      "(Validation) Loss: 730607.1505, MAE: 3169.3633, R2: 0.2569\n",
      "==========================================================================================\n",
      "Epoch [3739/5000] | Time: 0.36s\n",
      "(Training) Loss: 916025.3344\n",
      "(Validation) Loss: 730540.6514, MAE: 3169.9949, R2: 0.2570\n",
      "==========================================================================================\n",
      "Epoch [3740/5000] | Time: 0.42s\n",
      "(Training) Loss: 906236.9356\n",
      "(Validation) Loss: 730463.3079, MAE: 3168.0403, R2: 0.2571\n",
      "==========================================================================================\n",
      "Epoch [3741/5000] | Time: 0.37s\n",
      "(Training) Loss: 908007.6244\n",
      "(Validation) Loss: 730389.0489, MAE: 3168.1011, R2: 0.2571\n",
      "==========================================================================================\n",
      "Epoch [3742/5000] | Time: 0.33s\n",
      "(Training) Loss: 908746.8055\n",
      "(Validation) Loss: 730322.2343, MAE: 3168.7769, R2: 0.2572\n",
      "==========================================================================================\n",
      "Epoch [3743/5000] | Time: 0.36s\n",
      "(Training) Loss: 908378.8122\n",
      "(Validation) Loss: 730261.1524, MAE: 3171.5051, R2: 0.2573\n",
      "==========================================================================================\n",
      "Epoch [3744/5000] | Time: 0.32s\n",
      "(Training) Loss: 904338.3369\n",
      "(Validation) Loss: 730192.5384, MAE: 3170.1912, R2: 0.2573\n",
      "==========================================================================================\n",
      "Epoch [3745/5000] | Time: 0.33s\n",
      "(Training) Loss: 908173.3287\n",
      "(Validation) Loss: 730115.8990, MAE: 3168.5908, R2: 0.2574\n",
      "==========================================================================================\n",
      "Epoch [3746/5000] | Time: 0.32s\n",
      "(Training) Loss: 914397.4956\n",
      "(Validation) Loss: 730032.4724, MAE: 3167.1494, R2: 0.2575\n",
      "==========================================================================================\n",
      "Epoch [3747/5000] | Time: 0.37s\n",
      "(Training) Loss: 910838.7043\n",
      "(Validation) Loss: 729978.5219, MAE: 3169.2825, R2: 0.2575\n",
      "==========================================================================================\n",
      "Epoch [3748/5000] | Time: 0.34s\n",
      "(Training) Loss: 914003.8845\n",
      "(Validation) Loss: 729884.4902, MAE: 3164.7434, R2: 0.2576\n",
      "==========================================================================================\n",
      "Epoch [3749/5000] | Time: 0.35s\n",
      "(Training) Loss: 908409.6193\n",
      "(Validation) Loss: 729816.9765, MAE: 3165.9565, R2: 0.2577\n",
      "==========================================================================================\n",
      "Epoch [3750/5000] | Time: 0.37s\n",
      "(Training) Loss: 900043.9223\n",
      "(Validation) Loss: 729748.1467, MAE: 3166.7188, R2: 0.2578\n",
      "==========================================================================================\n",
      "Epoch [3751/5000] | Time: 0.34s\n",
      "(Training) Loss: 904566.8560\n",
      "(Validation) Loss: 729680.6057, MAE: 3166.2175, R2: 0.2578\n",
      "==========================================================================================\n",
      "Epoch [3752/5000] | Time: 0.36s\n",
      "(Training) Loss: 920674.5311\n",
      "(Validation) Loss: 729608.8844, MAE: 3166.5813, R2: 0.2579\n",
      "==========================================================================================\n",
      "Epoch [3753/5000] | Time: 0.37s\n",
      "(Training) Loss: 908634.4892\n",
      "(Validation) Loss: 729539.3778, MAE: 3165.6917, R2: 0.2580\n",
      "==========================================================================================\n",
      "Epoch [3754/5000] | Time: 0.34s\n",
      "(Training) Loss: 918273.9010\n",
      "(Validation) Loss: 729468.0927, MAE: 3166.1160, R2: 0.2581\n",
      "==========================================================================================\n",
      "Epoch [3755/5000] | Time: 0.37s\n",
      "(Training) Loss: 922170.9010\n",
      "(Validation) Loss: 729389.5187, MAE: 3164.0591, R2: 0.2581\n",
      "==========================================================================================\n",
      "Epoch [3756/5000] | Time: 0.32s\n",
      "(Training) Loss: 911592.2538\n",
      "(Validation) Loss: 729323.6140, MAE: 3164.9902, R2: 0.2582\n",
      "==========================================================================================\n",
      "Epoch [3757/5000] | Time: 0.34s\n",
      "(Training) Loss: 904970.0825\n",
      "(Validation) Loss: 729252.1625, MAE: 3165.9705, R2: 0.2583\n",
      "==========================================================================================\n",
      "Epoch [3758/5000] | Time: 0.35s\n",
      "(Training) Loss: 911587.8414\n",
      "(Validation) Loss: 729175.5784, MAE: 3164.3545, R2: 0.2584\n",
      "==========================================================================================\n",
      "Epoch [3759/5000] | Time: 0.38s\n",
      "(Training) Loss: 918374.7912\n",
      "(Validation) Loss: 729104.7994, MAE: 3163.6870, R2: 0.2584\n",
      "==========================================================================================\n",
      "Epoch [3760/5000] | Time: 0.36s\n",
      "(Training) Loss: 909040.3756\n",
      "(Validation) Loss: 728976.2908, MAE: 3165.0803, R2: 0.2586\n",
      "==========================================================================================\n",
      "Epoch [3761/5000] | Time: 0.33s\n",
      "(Training) Loss: 904781.5311\n",
      "(Validation) Loss: 728894.7486, MAE: 3160.9353, R2: 0.2586\n",
      "==========================================================================================\n",
      "Epoch [3762/5000] | Time: 0.36s\n",
      "(Training) Loss: 915335.8813\n",
      "(Validation) Loss: 728841.4375, MAE: 3162.9834, R2: 0.2587\n",
      "==========================================================================================\n",
      "Epoch [3763/5000] | Time: 0.34s\n",
      "(Training) Loss: 899769.1499\n",
      "(Validation) Loss: 728798.1244, MAE: 3170.3311, R2: 0.2587\n",
      "==========================================================================================\n",
      "Epoch [3764/5000] | Time: 0.37s\n",
      "(Training) Loss: 902411.3030\n",
      "(Validation) Loss: 728726.8222, MAE: 3164.6272, R2: 0.2588\n",
      "==========================================================================================\n",
      "Epoch [3765/5000] | Time: 0.36s\n",
      "(Training) Loss: 913737.7030\n",
      "(Validation) Loss: 728625.2514, MAE: 3160.1416, R2: 0.2589\n",
      "==========================================================================================\n",
      "Epoch [3766/5000] | Time: 0.35s\n",
      "(Training) Loss: 904162.7744\n",
      "(Validation) Loss: 728562.6406, MAE: 3162.9871, R2: 0.2590\n",
      "==========================================================================================\n",
      "Epoch [3767/5000] | Time: 0.33s\n",
      "(Training) Loss: 904889.1536\n",
      "(Validation) Loss: 728488.6095, MAE: 3160.7368, R2: 0.2591\n",
      "==========================================================================================\n",
      "Epoch [3768/5000] | Time: 0.36s\n",
      "(Training) Loss: 906635.6726\n",
      "(Validation) Loss: 728424.1524, MAE: 3162.5869, R2: 0.2591\n",
      "==========================================================================================\n",
      "Epoch [3769/5000] | Time: 0.35s\n",
      "(Training) Loss: 930439.9854\n",
      "(Validation) Loss: 728350.5613, MAE: 3160.5923, R2: 0.2592\n",
      "==========================================================================================\n",
      "Epoch [3770/5000] | Time: 0.34s\n",
      "(Training) Loss: 902730.9480\n",
      "(Validation) Loss: 728350.4622, MAE: 3167.8728, R2: 0.2592\n",
      "==========================================================================================\n",
      "Epoch [3771/5000] | Time: 0.35s\n",
      "(Training) Loss: 929118.0352\n",
      "(Validation) Loss: 728213.9035, MAE: 3160.4395, R2: 0.2593\n",
      "==========================================================================================\n",
      "Epoch [3772/5000] | Time: 0.33s\n",
      "(Training) Loss: 906617.2208\n",
      "(Validation) Loss: 728139.1276, MAE: 3159.1340, R2: 0.2594\n",
      "==========================================================================================\n",
      "Epoch [3773/5000] | Time: 0.34s\n",
      "(Training) Loss: 918228.8452\n",
      "(Validation) Loss: 728059.3638, MAE: 3156.0710, R2: 0.2595\n",
      "==========================================================================================\n",
      "Epoch [3774/5000] | Time: 0.32s\n",
      "(Training) Loss: 922105.8680\n",
      "(Validation) Loss: 727983.1587, MAE: 3155.8977, R2: 0.2596\n",
      "==========================================================================================\n",
      "Epoch [3775/5000] | Time: 0.31s\n",
      "(Training) Loss: 902550.1853\n",
      "(Validation) Loss: 727987.7441, MAE: 3161.8052, R2: 0.2596\n",
      "==========================================================================================\n",
      "Epoch [3776/5000] | Time: 0.34s\n",
      "(Training) Loss: 911300.1726\n",
      "(Validation) Loss: 727842.8463, MAE: 3155.4629, R2: 0.2597\n",
      "==========================================================================================\n",
      "Epoch [3777/5000] | Time: 0.32s\n",
      "(Training) Loss: 918004.8017\n",
      "(Validation) Loss: 727786.4362, MAE: 3157.4504, R2: 0.2598\n",
      "==========================================================================================\n",
      "Epoch [3778/5000] | Time: 0.34s\n",
      "(Training) Loss: 904026.5907\n",
      "(Validation) Loss: 727793.5422, MAE: 3161.2783, R2: 0.2598\n",
      "==========================================================================================\n",
      "Epoch [3779/5000] | Time: 0.40s\n",
      "(Training) Loss: 913255.1110\n",
      "(Validation) Loss: 727730.2622, MAE: 3162.6206, R2: 0.2598\n",
      "==========================================================================================\n",
      "Epoch [3780/5000] | Time: 0.35s\n",
      "(Training) Loss: 915261.2078\n",
      "(Validation) Loss: 727654.8476, MAE: 3160.9395, R2: 0.2599\n",
      "==========================================================================================\n",
      "Epoch [3781/5000] | Time: 0.37s\n",
      "(Training) Loss: 898008.8295\n",
      "(Validation) Loss: 727592.5613, MAE: 3163.5559, R2: 0.2600\n",
      "==========================================================================================\n",
      "Epoch [3782/5000] | Time: 0.36s\n",
      "(Training) Loss: 899338.5971\n",
      "(Validation) Loss: 727516.7448, MAE: 3162.0171, R2: 0.2600\n",
      "==========================================================================================\n",
      "Epoch [3783/5000] | Time: 0.33s\n",
      "(Training) Loss: 915609.0812\n",
      "(Validation) Loss: 727435.8432, MAE: 3159.9685, R2: 0.2601\n",
      "==========================================================================================\n",
      "Epoch [3784/5000] | Time: 0.35s\n",
      "(Training) Loss: 910606.0863\n",
      "(Validation) Loss: 727362.8578, MAE: 3157.9031, R2: 0.2602\n",
      "==========================================================================================\n",
      "Epoch [3785/5000] | Time: 0.33s\n",
      "(Training) Loss: 931478.0127\n",
      "(Validation) Loss: 727298.1613, MAE: 3159.3784, R2: 0.2603\n",
      "==========================================================================================\n",
      "Epoch [3786/5000] | Time: 0.33s\n",
      "(Training) Loss: 904456.1453\n",
      "(Validation) Loss: 727225.9041, MAE: 3159.6692, R2: 0.2603\n",
      "==========================================================================================\n",
      "Epoch [3787/5000] | Time: 0.32s\n",
      "(Training) Loss: 909656.3198\n",
      "(Validation) Loss: 727155.1333, MAE: 3159.6238, R2: 0.2604\n",
      "==========================================================================================\n",
      "Epoch [3788/5000] | Time: 0.34s\n",
      "(Training) Loss: 908306.2005\n",
      "(Validation) Loss: 727097.9549, MAE: 3162.6912, R2: 0.2605\n",
      "==========================================================================================\n",
      "Epoch [3789/5000] | Time: 0.36s\n",
      "(Training) Loss: 898745.4710\n",
      "(Validation) Loss: 727010.1581, MAE: 3159.6953, R2: 0.2605\n",
      "==========================================================================================\n",
      "Epoch [3790/5000] | Time: 0.34s\n",
      "(Training) Loss: 904103.4169\n",
      "(Validation) Loss: 726939.4603, MAE: 3158.2632, R2: 0.2606\n",
      "==========================================================================================\n",
      "Epoch [3791/5000] | Time: 0.36s\n",
      "(Training) Loss: 903406.3909\n",
      "(Validation) Loss: 726868.9784, MAE: 3158.0325, R2: 0.2607\n",
      "==========================================================================================\n",
      "Epoch [3792/5000] | Time: 0.36s\n",
      "(Training) Loss: 904917.0431\n",
      "(Validation) Loss: 726797.6362, MAE: 3157.6562, R2: 0.2608\n",
      "==========================================================================================\n",
      "Epoch [3793/5000] | Time: 0.34s\n",
      "(Training) Loss: 908178.9340\n",
      "(Validation) Loss: 726749.6076, MAE: 3163.3860, R2: 0.2608\n",
      "==========================================================================================\n",
      "Epoch [3794/5000] | Time: 0.36s\n",
      "(Training) Loss: 922707.1904\n",
      "(Validation) Loss: 726651.0025, MAE: 3156.4292, R2: 0.2609\n",
      "==========================================================================================\n",
      "Epoch [3795/5000] | Time: 0.37s\n",
      "(Training) Loss: 904525.5926\n",
      "(Validation) Loss: 726584.5784, MAE: 3158.0210, R2: 0.2610\n",
      "==========================================================================================\n",
      "Epoch [3796/5000] | Time: 0.34s\n",
      "(Training) Loss: 906317.9664\n",
      "(Validation) Loss: 726523.5917, MAE: 3160.5559, R2: 0.2610\n",
      "==========================================================================================\n",
      "Epoch [3797/5000] | Time: 0.36s\n",
      "(Training) Loss: 921135.6605\n",
      "(Validation) Loss: 726442.4324, MAE: 3157.7520, R2: 0.2611\n",
      "==========================================================================================\n",
      "Epoch [3798/5000] | Time: 0.38s\n",
      "(Training) Loss: 907582.2202\n",
      "(Validation) Loss: 726375.3663, MAE: 3158.7961, R2: 0.2612\n",
      "==========================================================================================\n",
      "Epoch [3799/5000] | Time: 0.33s\n",
      "(Training) Loss: 897766.4515\n",
      "(Validation) Loss: 726305.2476, MAE: 3158.3384, R2: 0.2613\n",
      "==========================================================================================\n",
      "Epoch [3800/5000] | Time: 0.35s\n",
      "(Training) Loss: 904399.6916\n",
      "(Validation) Loss: 726228.8978, MAE: 3156.6255, R2: 0.2613\n",
      "==========================================================================================\n",
      "Epoch [3801/5000] | Time: 0.38s\n",
      "(Training) Loss: 899105.7766\n",
      "(Validation) Loss: 726161.5384, MAE: 3156.5645, R2: 0.2614\n",
      "==========================================================================================\n",
      "Epoch [3802/5000] | Time: 0.38s\n",
      "(Training) Loss: 908122.1732\n",
      "(Validation) Loss: 726083.4565, MAE: 3154.6206, R2: 0.2615\n",
      "==========================================================================================\n",
      "Epoch [3803/5000] | Time: 0.36s\n",
      "(Training) Loss: 908345.1415\n",
      "(Validation) Loss: 726023.7708, MAE: 3157.6763, R2: 0.2615\n",
      "==========================================================================================\n",
      "Epoch [3804/5000] | Time: 0.34s\n",
      "(Training) Loss: 918459.2703\n",
      "(Validation) Loss: 725943.2108, MAE: 3155.6445, R2: 0.2616\n",
      "==========================================================================================\n",
      "Epoch [3805/5000] | Time: 0.38s\n",
      "(Training) Loss: 911092.3687\n",
      "(Validation) Loss: 725872.1378, MAE: 3155.4119, R2: 0.2617\n",
      "==========================================================================================\n",
      "Epoch [3806/5000] | Time: 0.34s\n",
      "(Training) Loss: 900894.9791\n",
      "(Validation) Loss: 725800.3816, MAE: 3156.2095, R2: 0.2618\n",
      "==========================================================================================\n",
      "Epoch [3807/5000] | Time: 0.36s\n",
      "(Training) Loss: 903149.0305\n",
      "(Validation) Loss: 725736.1765, MAE: 3156.7603, R2: 0.2618\n",
      "==========================================================================================\n",
      "Epoch [3808/5000] | Time: 0.37s\n",
      "(Training) Loss: 906612.0127\n",
      "(Validation) Loss: 725660.9333, MAE: 3155.5190, R2: 0.2619\n",
      "==========================================================================================\n",
      "Epoch [3809/5000] | Time: 0.35s\n",
      "(Training) Loss: 906114.7741\n",
      "(Validation) Loss: 725595.8883, MAE: 3157.0325, R2: 0.2620\n",
      "==========================================================================================\n",
      "Epoch [3810/5000] | Time: 0.34s\n",
      "(Training) Loss: 901803.6675\n",
      "(Validation) Loss: 725514.4597, MAE: 3154.3037, R2: 0.2621\n",
      "==========================================================================================\n",
      "Epoch [3811/5000] | Time: 0.34s\n",
      "(Training) Loss: 897824.4756\n",
      "(Validation) Loss: 725462.8451, MAE: 3158.2456, R2: 0.2621\n",
      "==========================================================================================\n",
      "Epoch [3812/5000] | Time: 0.35s\n",
      "(Training) Loss: 916642.2963\n",
      "(Validation) Loss: 725395.9429, MAE: 3157.5942, R2: 0.2622\n",
      "==========================================================================================\n",
      "Epoch [3813/5000] | Time: 0.34s\n",
      "(Training) Loss: 914911.1837\n",
      "(Validation) Loss: 725311.9829, MAE: 3156.1946, R2: 0.2623\n",
      "==========================================================================================\n",
      "Epoch [3814/5000] | Time: 0.37s\n",
      "(Training) Loss: 900614.6161\n",
      "(Validation) Loss: 725241.5244, MAE: 3157.2153, R2: 0.2623\n",
      "==========================================================================================\n",
      "Epoch [3815/5000] | Time: 0.33s\n",
      "(Training) Loss: 914106.9588\n",
      "(Validation) Loss: 725165.1308, MAE: 3154.7090, R2: 0.2624\n",
      "==========================================================================================\n",
      "Epoch [3816/5000] | Time: 0.34s\n",
      "(Training) Loss: 904068.4315\n",
      "(Validation) Loss: 725088.9879, MAE: 3153.9219, R2: 0.2625\n",
      "==========================================================================================\n",
      "Epoch [3817/5000] | Time: 0.35s\n",
      "(Training) Loss: 915906.1117\n",
      "(Validation) Loss: 725024.6629, MAE: 3154.4390, R2: 0.2625\n",
      "==========================================================================================\n",
      "Epoch [3818/5000] | Time: 0.33s\n",
      "(Training) Loss: 916028.1307\n",
      "(Validation) Loss: 724949.4705, MAE: 3154.2878, R2: 0.2626\n",
      "==========================================================================================\n",
      "Epoch [3819/5000] | Time: 0.35s\n",
      "(Training) Loss: 908009.2532\n",
      "(Validation) Loss: 724873.5244, MAE: 3153.1921, R2: 0.2627\n",
      "==========================================================================================\n",
      "Epoch [3820/5000] | Time: 0.38s\n",
      "(Training) Loss: 905472.5717\n",
      "(Validation) Loss: 724807.8165, MAE: 3153.8279, R2: 0.2628\n",
      "==========================================================================================\n",
      "Epoch [3821/5000] | Time: 0.34s\n",
      "(Training) Loss: 912563.0641\n",
      "(Validation) Loss: 724732.1029, MAE: 3152.0750, R2: 0.2628\n",
      "==========================================================================================\n",
      "Epoch [3822/5000] | Time: 0.33s\n",
      "(Training) Loss: 918936.1288\n",
      "(Validation) Loss: 724665.9949, MAE: 3152.5293, R2: 0.2629\n",
      "==========================================================================================\n",
      "Epoch [3823/5000] | Time: 0.35s\n",
      "(Training) Loss: 907787.4105\n",
      "(Validation) Loss: 724599.9975, MAE: 3154.3232, R2: 0.2630\n",
      "==========================================================================================\n",
      "Epoch [3824/5000] | Time: 0.35s\n",
      "(Training) Loss: 910718.4315\n",
      "(Validation) Loss: 724523.9314, MAE: 3154.1387, R2: 0.2631\n",
      "==========================================================================================\n",
      "Epoch [3825/5000] | Time: 0.38s\n",
      "(Training) Loss: 903375.7475\n",
      "(Validation) Loss: 721424.2400, MAE: 3145.3179, R2: 0.2662\n",
      "==========================================================================================\n",
      "Epoch [3826/5000] | Time: 0.36s\n",
      "(Training) Loss: 902797.0317\n",
      "(Validation) Loss: 721347.4768, MAE: 3143.7471, R2: 0.2663\n",
      "==========================================================================================\n",
      "Epoch [3827/5000] | Time: 0.36s\n",
      "(Training) Loss: 908042.0666\n",
      "(Validation) Loss: 721278.9137, MAE: 3146.1201, R2: 0.2663\n",
      "==========================================================================================\n",
      "Epoch [3828/5000] | Time: 0.36s\n",
      "(Training) Loss: 901109.2100\n",
      "(Validation) Loss: 721206.0597, MAE: 3145.6980, R2: 0.2664\n",
      "==========================================================================================\n",
      "Epoch [3829/5000] | Time: 0.35s\n",
      "(Training) Loss: 901569.7824\n",
      "(Validation) Loss: 721130.1333, MAE: 3144.8835, R2: 0.2665\n",
      "==========================================================================================\n",
      "Epoch [3830/5000] | Time: 0.34s\n",
      "(Training) Loss: 894699.4803\n",
      "(Validation) Loss: 721050.5994, MAE: 3143.5168, R2: 0.2666\n",
      "==========================================================================================\n",
      "Epoch [3831/5000] | Time: 0.43s\n",
      "(Training) Loss: 918106.1948\n",
      "(Validation) Loss: 720983.5549, MAE: 3144.2910, R2: 0.2666\n",
      "==========================================================================================\n",
      "Epoch [3832/5000] | Time: 0.38s\n",
      "(Training) Loss: 902346.3353\n",
      "(Validation) Loss: 720907.7841, MAE: 3145.1514, R2: 0.2667\n",
      "==========================================================================================\n",
      "Epoch [3833/5000] | Time: 0.36s\n",
      "(Training) Loss: 894255.5514\n",
      "(Validation) Loss: 720836.4756, MAE: 3143.6248, R2: 0.2668\n",
      "==========================================================================================\n",
      "Epoch [3834/5000] | Time: 0.35s\n",
      "(Training) Loss: 892818.2145\n",
      "(Validation) Loss: 720766.4121, MAE: 3144.5867, R2: 0.2668\n",
      "==========================================================================================\n",
      "Epoch [3835/5000] | Time: 0.33s\n",
      "(Training) Loss: 919714.1701\n",
      "(Validation) Loss: 720707.7683, MAE: 3144.5115, R2: 0.2669\n",
      "==========================================================================================\n",
      "Epoch [3836/5000] | Time: 0.33s\n",
      "(Training) Loss: 903105.5971\n",
      "(Validation) Loss: 720613.7689, MAE: 3140.1604, R2: 0.2670\n",
      "==========================================================================================\n",
      "Epoch [3837/5000] | Time: 0.35s\n",
      "(Training) Loss: 908998.5666\n",
      "(Validation) Loss: 720548.9556, MAE: 3143.1091, R2: 0.2671\n",
      "==========================================================================================\n",
      "Epoch [3838/5000] | Time: 0.35s\n",
      "(Training) Loss: 901377.5749\n",
      "(Validation) Loss: 720479.0629, MAE: 3142.3391, R2: 0.2671\n",
      "==========================================================================================\n",
      "Epoch [3839/5000] | Time: 0.34s\n",
      "(Training) Loss: 901532.7862\n",
      "(Validation) Loss: 720417.4133, MAE: 3144.4998, R2: 0.2672\n",
      "==========================================================================================\n",
      "Epoch [3840/5000] | Time: 0.34s\n",
      "(Training) Loss: 902639.4194\n",
      "(Validation) Loss: 720327.4502, MAE: 3140.6257, R2: 0.2673\n",
      "==========================================================================================\n",
      "Epoch [3841/5000] | Time: 0.34s\n",
      "(Training) Loss: 901084.7779\n",
      "(Validation) Loss: 720296.4108, MAE: 3145.4546, R2: 0.2673\n",
      "==========================================================================================\n",
      "Epoch [3842/5000] | Time: 0.36s\n",
      "(Training) Loss: 919218.4784\n",
      "(Validation) Loss: 720189.5003, MAE: 3138.6077, R2: 0.2674\n",
      "==========================================================================================\n",
      "Epoch [3843/5000] | Time: 0.37s\n",
      "(Training) Loss: 894995.5355\n",
      "(Validation) Loss: 720128.0254, MAE: 3141.5928, R2: 0.2675\n",
      "==========================================================================================\n",
      "Epoch [3844/5000] | Time: 0.35s\n",
      "(Training) Loss: 895239.4353\n",
      "(Validation) Loss: 720045.0413, MAE: 3139.1582, R2: 0.2676\n",
      "==========================================================================================\n",
      "Epoch [3845/5000] | Time: 0.32s\n",
      "(Training) Loss: 895872.9772\n",
      "(Validation) Loss: 719980.7206, MAE: 3139.6943, R2: 0.2676\n",
      "==========================================================================================\n",
      "Epoch [3846/5000] | Time: 0.40s\n",
      "(Training) Loss: 891053.1564\n",
      "(Validation) Loss: 719908.6495, MAE: 3139.6472, R2: 0.2677\n",
      "==========================================================================================\n",
      "Epoch [3847/5000] | Time: 0.39s\n",
      "(Training) Loss: 900514.9074\n",
      "(Validation) Loss: 719835.1067, MAE: 3137.9631, R2: 0.2678\n",
      "==========================================================================================\n",
      "Epoch [3848/5000] | Time: 0.37s\n",
      "(Training) Loss: 917178.4438\n",
      "(Validation) Loss: 719771.6876, MAE: 3139.7488, R2: 0.2678\n",
      "==========================================================================================\n",
      "Epoch [3849/5000] | Time: 0.38s\n",
      "(Training) Loss: 901199.0603\n",
      "(Validation) Loss: 719698.4025, MAE: 3138.4236, R2: 0.2679\n",
      "==========================================================================================\n",
      "Epoch [3850/5000] | Time: 0.37s\n",
      "(Training) Loss: 905795.7989\n",
      "(Validation) Loss: 719624.7740, MAE: 3136.4937, R2: 0.2680\n",
      "==========================================================================================\n",
      "Epoch [3851/5000] | Time: 0.33s\n",
      "(Training) Loss: 889644.6404\n",
      "(Validation) Loss: 719553.3937, MAE: 3136.7607, R2: 0.2681\n",
      "==========================================================================================\n",
      "Epoch [3852/5000] | Time: 0.35s\n",
      "(Training) Loss: 902560.9074\n",
      "(Validation) Loss: 719479.8470, MAE: 3135.5593, R2: 0.2681\n",
      "==========================================================================================\n",
      "Epoch [3853/5000] | Time: 0.32s\n",
      "(Training) Loss: 892646.8997\n",
      "(Validation) Loss: 718700.2914, MAE: 3133.3647, R2: 0.2689\n",
      "==========================================================================================\n",
      "Epoch [3854/5000] | Time: 0.33s\n",
      "(Training) Loss: 895215.1269\n",
      "(Validation) Loss: 718708.7689, MAE: 3147.2927, R2: 0.2689\n",
      "==========================================================================================\n",
      "Epoch [3855/5000] | Time: 0.31s\n",
      "(Training) Loss: 898986.2725\n",
      "(Validation) Loss: 718575.7308, MAE: 3140.0754, R2: 0.2691\n",
      "==========================================================================================\n",
      "Epoch [3856/5000] | Time: 0.35s\n",
      "(Training) Loss: 889416.5146\n",
      "(Validation) Loss: 718486.7175, MAE: 3134.6089, R2: 0.2691\n",
      "==========================================================================================\n",
      "Epoch [3857/5000] | Time: 0.34s\n",
      "(Training) Loss: 904873.7671\n",
      "(Validation) Loss: 718408.9644, MAE: 3134.2524, R2: 0.2692\n",
      "==========================================================================================\n",
      "Epoch [3858/5000] | Time: 0.35s\n",
      "(Training) Loss: 901911.2253\n",
      "(Validation) Loss: 718330.6565, MAE: 3132.2791, R2: 0.2693\n",
      "==========================================================================================\n",
      "Epoch [3859/5000] | Time: 0.34s\n",
      "(Training) Loss: 892982.3515\n",
      "(Validation) Loss: 718265.7625, MAE: 3133.6938, R2: 0.2694\n",
      "==========================================================================================\n",
      "Epoch [3860/5000] | Time: 0.33s\n",
      "(Training) Loss: 893179.6136\n",
      "(Validation) Loss: 718188.0229, MAE: 3133.2122, R2: 0.2694\n",
      "==========================================================================================\n",
      "Epoch [3861/5000] | Time: 0.33s\n",
      "(Training) Loss: 923092.1529\n",
      "(Validation) Loss: 718126.4165, MAE: 3135.6091, R2: 0.2695\n",
      "==========================================================================================\n",
      "Epoch [3862/5000] | Time: 0.33s\n",
      "(Training) Loss: 892647.9239\n",
      "(Validation) Loss: 718101.0863, MAE: 3142.0286, R2: 0.2695\n",
      "==========================================================================================\n",
      "Epoch [3863/5000] | Time: 0.33s\n",
      "(Training) Loss: 899072.6783\n",
      "(Validation) Loss: 717987.1575, MAE: 3135.8142, R2: 0.2696\n",
      "==========================================================================================\n",
      "Epoch [3864/5000] | Time: 0.35s\n",
      "(Training) Loss: 893068.2329\n",
      "(Validation) Loss: 717898.5600, MAE: 3133.2866, R2: 0.2697\n",
      "==========================================================================================\n",
      "Epoch [3865/5000] | Time: 0.33s\n",
      "(Training) Loss: 891797.7075\n",
      "(Validation) Loss: 717826.9105, MAE: 3134.2317, R2: 0.2698\n",
      "==========================================================================================\n",
      "Epoch [3866/5000] | Time: 0.33s\n",
      "(Training) Loss: 894410.0197\n",
      "(Validation) Loss: 717757.5397, MAE: 3134.2981, R2: 0.2699\n",
      "==========================================================================================\n",
      "Epoch [3867/5000] | Time: 0.32s\n",
      "(Training) Loss: 906389.7995\n",
      "(Validation) Loss: 717691.6349, MAE: 3135.1416, R2: 0.2699\n",
      "==========================================================================================\n",
      "Epoch [3868/5000] | Time: 0.32s\n",
      "(Training) Loss: 898605.3338\n",
      "(Validation) Loss: 717613.1308, MAE: 3132.8762, R2: 0.2700\n",
      "==========================================================================================\n",
      "Epoch [3869/5000] | Time: 0.30s\n",
      "(Training) Loss: 917551.5228\n",
      "(Validation) Loss: 717546.6724, MAE: 3133.9189, R2: 0.2701\n",
      "==========================================================================================\n",
      "Epoch [3870/5000] | Time: 0.30s\n",
      "(Training) Loss: 905250.1681\n",
      "(Validation) Loss: 717464.6908, MAE: 3131.6057, R2: 0.2702\n",
      "==========================================================================================\n",
      "Epoch [3871/5000] | Time: 0.38s\n",
      "(Training) Loss: 906465.8963\n",
      "(Validation) Loss: 717389.2305, MAE: 3132.0984, R2: 0.2702\n",
      "==========================================================================================\n",
      "Epoch [3872/5000] | Time: 0.31s\n",
      "(Training) Loss: 906095.8319\n",
      "(Validation) Loss: 717313.0800, MAE: 3131.3633, R2: 0.2703\n",
      "==========================================================================================\n",
      "Epoch [3873/5000] | Time: 0.31s\n",
      "(Training) Loss: 896569.9112\n",
      "(Validation) Loss: 717244.4927, MAE: 3131.6340, R2: 0.2704\n",
      "==========================================================================================\n",
      "Epoch [3874/5000] | Time: 0.33s\n",
      "(Training) Loss: 899885.3363\n",
      "(Validation) Loss: 717174.2381, MAE: 3130.4568, R2: 0.2705\n",
      "==========================================================================================\n",
      "Epoch [3875/5000] | Time: 0.33s\n",
      "(Training) Loss: 916791.4346\n",
      "(Validation) Loss: 717103.7492, MAE: 3132.4121, R2: 0.2705\n",
      "==========================================================================================\n",
      "Epoch [3876/5000] | Time: 0.33s\n",
      "(Training) Loss: 896883.4181\n",
      "(Validation) Loss: 717023.1333, MAE: 3129.2883, R2: 0.2706\n",
      "==========================================================================================\n",
      "Epoch [3877/5000] | Time: 0.34s\n",
      "(Training) Loss: 893820.9822\n",
      "(Validation) Loss: 716953.4946, MAE: 3130.4055, R2: 0.2707\n",
      "==========================================================================================\n",
      "Epoch [3878/5000] | Time: 0.34s\n",
      "(Training) Loss: 903694.2195\n",
      "(Validation) Loss: 716892.9530, MAE: 3131.9153, R2: 0.2708\n",
      "==========================================================================================\n",
      "Epoch [3879/5000] | Time: 0.35s\n",
      "(Training) Loss: 892133.2862\n",
      "(Validation) Loss: 716810.3054, MAE: 3130.1741, R2: 0.2708\n",
      "==========================================================================================\n",
      "Epoch [3880/5000] | Time: 0.37s\n",
      "(Training) Loss: 894634.3363\n",
      "(Validation) Loss: 716738.0622, MAE: 3129.9602, R2: 0.2709\n",
      "==========================================================================================\n",
      "Epoch [3881/5000] | Time: 0.32s\n",
      "(Training) Loss: 886100.2889\n",
      "(Validation) Loss: 716662.1943, MAE: 3128.5264, R2: 0.2710\n",
      "==========================================================================================\n",
      "Epoch [3882/5000] | Time: 0.32s\n",
      "(Training) Loss: 927695.8062\n",
      "(Validation) Loss: 716587.0387, MAE: 3127.1926, R2: 0.2711\n",
      "==========================================================================================\n",
      "Epoch [3883/5000] | Time: 0.33s\n",
      "(Training) Loss: 901263.4296\n",
      "(Validation) Loss: 716518.0279, MAE: 3128.3096, R2: 0.2711\n",
      "==========================================================================================\n",
      "Epoch [3884/5000] | Time: 0.37s\n",
      "(Training) Loss: 897956.5260\n",
      "(Validation) Loss: 716445.9270, MAE: 3127.4109, R2: 0.2712\n",
      "==========================================================================================\n",
      "Epoch [3885/5000] | Time: 0.38s\n",
      "(Training) Loss: 907100.9267\n",
      "(Validation) Loss: 716368.7232, MAE: 3127.3792, R2: 0.2713\n",
      "==========================================================================================\n",
      "Epoch [3886/5000] | Time: 0.35s\n",
      "(Training) Loss: 901446.3953\n",
      "(Validation) Loss: 716299.7130, MAE: 3126.8967, R2: 0.2713\n",
      "==========================================================================================\n",
      "Epoch [3887/5000] | Time: 0.33s\n",
      "(Training) Loss: 892419.1155\n",
      "(Validation) Loss: 716237.3740, MAE: 3129.5845, R2: 0.2714\n",
      "==========================================================================================\n",
      "Epoch [3888/5000] | Time: 0.37s\n",
      "(Training) Loss: 890648.7716\n",
      "(Validation) Loss: 716161.2895, MAE: 3130.1931, R2: 0.2715\n",
      "==========================================================================================\n",
      "Epoch [3889/5000] | Time: 0.38s\n",
      "(Training) Loss: 905159.1142\n",
      "(Validation) Loss: 716082.5168, MAE: 3127.7686, R2: 0.2716\n",
      "==========================================================================================\n",
      "Epoch [3890/5000] | Time: 0.34s\n",
      "(Training) Loss: 896751.7411\n",
      "(Validation) Loss: 716011.0413, MAE: 3127.8740, R2: 0.2716\n",
      "==========================================================================================\n",
      "Epoch [3891/5000] | Time: 0.37s\n",
      "(Training) Loss: 889193.8395\n",
      "(Validation) Loss: 715945.9314, MAE: 3126.7830, R2: 0.2717\n",
      "==========================================================================================\n",
      "Epoch [3892/5000] | Time: 0.38s\n",
      "(Training) Loss: 886069.5822\n",
      "(Validation) Loss: 715911.7543, MAE: 3136.1028, R2: 0.2717\n",
      "==========================================================================================\n",
      "Epoch [3893/5000] | Time: 0.39s\n",
      "(Training) Loss: 886164.9435\n",
      "(Validation) Loss: 715817.2006, MAE: 3131.2153, R2: 0.2718\n",
      "==========================================================================================\n",
      "Epoch [3894/5000] | Time: 0.38s\n",
      "(Training) Loss: 905105.6808\n",
      "(Validation) Loss: 715744.6743, MAE: 3130.0952, R2: 0.2719\n",
      "==========================================================================================\n",
      "Epoch [3895/5000] | Time: 0.38s\n",
      "(Training) Loss: 888502.6789\n",
      "(Validation) Loss: 715662.0546, MAE: 3129.2734, R2: 0.2720\n",
      "==========================================================================================\n",
      "Epoch [3896/5000] | Time: 0.36s\n",
      "(Training) Loss: 920853.1732\n",
      "(Validation) Loss: 723765.2210, MAE: 3148.4553, R2: 0.2638\n",
      "==========================================================================================\n",
      "Epoch [3897/5000] | Time: 0.37s\n",
      "(Training) Loss: 914111.1307\n",
      "(Validation) Loss: 723686.5435, MAE: 3148.0066, R2: 0.2639\n",
      "==========================================================================================\n",
      "Epoch [3898/5000] | Time: 0.34s\n",
      "(Training) Loss: 897106.3039\n",
      "(Validation) Loss: 723607.5346, MAE: 3147.6838, R2: 0.2640\n",
      "==========================================================================================\n",
      "Epoch [3899/5000] | Time: 0.33s\n",
      "(Training) Loss: 893567.7053\n",
      "(Validation) Loss: 723525.6654, MAE: 3144.3679, R2: 0.2641\n",
      "==========================================================================================\n",
      "Epoch [3900/5000] | Time: 0.38s\n",
      "(Training) Loss: 907871.3166\n",
      "(Validation) Loss: 723464.5194, MAE: 3146.0571, R2: 0.2641\n",
      "==========================================================================================\n",
      "Epoch [3901/5000] | Time: 0.37s\n",
      "(Training) Loss: 909025.8312\n",
      "(Validation) Loss: 723380.8806, MAE: 3143.6868, R2: 0.2642\n",
      "==========================================================================================\n",
      "Epoch [3902/5000] | Time: 0.35s\n",
      "(Training) Loss: 902156.5742\n",
      "(Validation) Loss: 723319.9352, MAE: 3147.4739, R2: 0.2643\n",
      "==========================================================================================\n",
      "Epoch [3903/5000] | Time: 0.32s\n",
      "(Training) Loss: 907065.2563\n",
      "(Validation) Loss: 723248.2756, MAE: 3145.2905, R2: 0.2643\n",
      "==========================================================================================\n",
      "Epoch [3904/5000] | Time: 0.35s\n",
      "(Training) Loss: 903337.3052\n",
      "(Validation) Loss: 723175.0210, MAE: 3144.4861, R2: 0.2644\n",
      "==========================================================================================\n",
      "Epoch [3905/5000] | Time: 0.32s\n",
      "(Training) Loss: 917090.4841\n",
      "(Validation) Loss: 723090.6781, MAE: 3141.7048, R2: 0.2645\n",
      "==========================================================================================\n",
      "Epoch [3906/5000] | Time: 0.33s\n",
      "(Training) Loss: 926533.5863\n",
      "(Validation) Loss: 723029.8203, MAE: 3143.9260, R2: 0.2646\n",
      "==========================================================================================\n",
      "Epoch [3907/5000] | Time: 0.33s\n",
      "(Training) Loss: 927687.8477\n",
      "(Validation) Loss: 722977.9759, MAE: 3148.4915, R2: 0.2646\n",
      "==========================================================================================\n",
      "Epoch [3908/5000] | Time: 0.34s\n",
      "(Training) Loss: 911146.1865\n",
      "(Validation) Loss: 722879.4794, MAE: 3141.9580, R2: 0.2647\n",
      "==========================================================================================\n",
      "Epoch [3909/5000] | Time: 0.37s\n",
      "(Training) Loss: 893617.4188\n",
      "(Validation) Loss: 722813.4990, MAE: 3143.5715, R2: 0.2648\n",
      "==========================================================================================\n",
      "Epoch [3910/5000] | Time: 0.37s\n",
      "(Training) Loss: 932758.2189\n",
      "(Validation) Loss: 722783.7898, MAE: 3152.8206, R2: 0.2648\n",
      "==========================================================================================\n",
      "Epoch [3911/5000] | Time: 0.36s\n",
      "(Training) Loss: 902748.9676\n",
      "(Validation) Loss: 722701.8749, MAE: 3149.8184, R2: 0.2649\n",
      "==========================================================================================\n",
      "Epoch [3912/5000] | Time: 0.36s\n",
      "(Training) Loss: 912236.5102\n",
      "(Validation) Loss: 722595.0622, MAE: 3142.6550, R2: 0.2650\n",
      "==========================================================================================\n",
      "Epoch [3913/5000] | Time: 0.34s\n",
      "(Training) Loss: 912685.7291\n",
      "(Validation) Loss: 722599.6946, MAE: 3153.0559, R2: 0.2650\n",
      "==========================================================================================\n",
      "Epoch [3914/5000] | Time: 0.37s\n",
      "(Training) Loss: 902709.3706\n",
      "(Validation) Loss: 722469.6908, MAE: 3145.4749, R2: 0.2651\n",
      "==========================================================================================\n",
      "Epoch [3915/5000] | Time: 0.34s\n",
      "(Training) Loss: 904039.4607\n",
      "(Validation) Loss: 722495.2463, MAE: 3149.9268, R2: 0.2651\n",
      "==========================================================================================\n",
      "Epoch [3916/5000] | Time: 0.33s\n",
      "(Training) Loss: 908074.7069\n",
      "(Validation) Loss: 722321.6527, MAE: 3143.4048, R2: 0.2653\n",
      "==========================================================================================\n",
      "Epoch [3917/5000] | Time: 0.33s\n",
      "(Training) Loss: 893602.0758\n",
      "(Validation) Loss: 722313.7568, MAE: 3148.0200, R2: 0.2653\n",
      "==========================================================================================\n",
      "Epoch [3918/5000] | Time: 0.32s\n",
      "(Training) Loss: 896224.9740\n",
      "(Validation) Loss: 722170.9498, MAE: 3143.6943, R2: 0.2654\n",
      "==========================================================================================\n",
      "Epoch [3919/5000] | Time: 0.33s\n",
      "(Training) Loss: 903893.5749\n",
      "(Validation) Loss: 722118.2571, MAE: 3145.4766, R2: 0.2655\n",
      "==========================================================================================\n",
      "Epoch [3920/5000] | Time: 0.34s\n",
      "(Training) Loss: 911204.9676\n",
      "(Validation) Loss: 722048.4629, MAE: 3143.5452, R2: 0.2655\n",
      "==========================================================================================\n",
      "Epoch [3921/5000] | Time: 0.32s\n",
      "(Training) Loss: 899337.8953\n",
      "(Validation) Loss: 721965.6337, MAE: 3142.9980, R2: 0.2656\n",
      "==========================================================================================\n",
      "Epoch [3922/5000] | Time: 0.35s\n",
      "(Training) Loss: 891341.8241\n",
      "(Validation) Loss: 721901.3651, MAE: 3142.7959, R2: 0.2657\n",
      "==========================================================================================\n",
      "Epoch [3923/5000] | Time: 0.34s\n",
      "(Training) Loss: 906590.5926\n",
      "(Validation) Loss: 721829.3073, MAE: 3144.0811, R2: 0.2658\n",
      "==========================================================================================\n",
      "Epoch [3924/5000] | Time: 0.33s\n",
      "(Training) Loss: 898946.3357\n",
      "(Validation) Loss: 721787.4400, MAE: 3147.4683, R2: 0.2658\n",
      "==========================================================================================\n",
      "Epoch [3925/5000] | Time: 0.34s\n",
      "(Training) Loss: 897789.0673\n",
      "(Validation) Loss: 721816.1663, MAE: 3149.8359, R2: 0.2658\n",
      "==========================================================================================\n",
      "Epoch [3926/5000] | Time: 0.36s\n",
      "(Training) Loss: 897690.9505\n",
      "(Validation) Loss: 721747.6692, MAE: 3152.0469, R2: 0.2659\n",
      "==========================================================================================\n",
      "Epoch [3927/5000] | Time: 0.32s\n",
      "(Training) Loss: 892163.0290\n",
      "(Validation) Loss: 721675.7714, MAE: 3148.8291, R2: 0.2659\n",
      "==========================================================================================\n",
      "Epoch [3928/5000] | Time: 0.33s\n",
      "(Training) Loss: 915667.8845\n",
      "(Validation) Loss: 721605.0673, MAE: 3148.7620, R2: 0.2660\n",
      "==========================================================================================\n",
      "Epoch [3929/5000] | Time: 0.33s\n",
      "(Training) Loss: 896329.4334\n",
      "(Validation) Loss: 721529.6883, MAE: 3147.1035, R2: 0.2661\n",
      "==========================================================================================\n",
      "Epoch [3930/5000] | Time: 0.33s\n",
      "(Training) Loss: 906071.3951\n",
      "(Validation) Loss: 721470.3651, MAE: 3150.3403, R2: 0.2661\n",
      "==========================================================================================\n",
      "Epoch [3931/5000] | Time: 0.38s\n",
      "(Training) Loss: 909538.9486\n",
      "(Validation) Loss: 721389.1283, MAE: 3147.5811, R2: 0.2662\n",
      "==========================================================================================\n",
      "Epoch [3932/5000] | Time: 0.39s\n",
      "(Training) Loss: 909295.1155\n",
      "(Validation) Loss: 720063.5327, MAE: 3134.4458, R2: 0.2676\n",
      "==========================================================================================\n",
      "Epoch [3933/5000] | Time: 0.30s\n",
      "(Training) Loss: 904697.3807\n",
      "(Validation) Loss: 720231.2140, MAE: 3149.8276, R2: 0.2674\n",
      "==========================================================================================\n",
      "Epoch [3934/5000] | Time: 0.30s\n",
      "(Training) Loss: 892877.8315\n",
      "(Validation) Loss: 720077.8127, MAE: 3145.7932, R2: 0.2675\n",
      "==========================================================================================\n",
      "Epoch [3935/5000] | Time: 0.32s\n",
      "(Training) Loss: 922130.3100\n",
      "(Validation) Loss: 720010.0203, MAE: 3145.4951, R2: 0.2676\n",
      "==========================================================================================\n",
      "Epoch [3936/5000] | Time: 0.31s\n",
      "(Training) Loss: 906166.4296\n",
      "(Validation) Loss: 719943.4146, MAE: 3144.5403, R2: 0.2677\n",
      "==========================================================================================\n",
      "Epoch [3937/5000] | Time: 0.31s\n",
      "(Training) Loss: 904735.3490\n",
      "(Validation) Loss: 719879.3105, MAE: 3146.2678, R2: 0.2677\n",
      "==========================================================================================\n",
      "Epoch [3938/5000] | Time: 0.36s\n",
      "(Training) Loss: 891082.4800\n",
      "(Validation) Loss: 719803.9568, MAE: 3145.8647, R2: 0.2678\n",
      "==========================================================================================\n",
      "Epoch [3939/5000] | Time: 0.35s\n",
      "(Training) Loss: 913769.2703\n",
      "(Validation) Loss: 719740.6146, MAE: 3145.2124, R2: 0.2679\n",
      "==========================================================================================\n",
      "Epoch [3940/5000] | Time: 0.36s\n",
      "(Training) Loss: 901865.8826\n",
      "(Validation) Loss: 719667.5568, MAE: 3144.3872, R2: 0.2679\n",
      "==========================================================================================\n",
      "Epoch [3941/5000] | Time: 0.36s\n",
      "(Training) Loss: 895987.2379\n",
      "(Validation) Loss: 719608.7352, MAE: 3145.0547, R2: 0.2680\n",
      "==========================================================================================\n",
      "Epoch [3942/5000] | Time: 0.36s\n",
      "(Training) Loss: 896570.9772\n",
      "(Validation) Loss: 719530.8603, MAE: 3143.2410, R2: 0.2681\n",
      "==========================================================================================\n",
      "Epoch [3943/5000] | Time: 0.31s\n",
      "(Training) Loss: 918187.6726\n",
      "(Validation) Loss: 719303.3663, MAE: 3134.3162, R2: 0.2683\n",
      "==========================================================================================\n",
      "Epoch [3944/5000] | Time: 0.32s\n",
      "(Training) Loss: 889172.8109\n",
      "(Validation) Loss: 719228.6184, MAE: 3130.8867, R2: 0.2684\n",
      "==========================================================================================\n",
      "Epoch [3945/5000] | Time: 0.32s\n",
      "(Training) Loss: 899611.9549\n",
      "(Validation) Loss: 719162.6413, MAE: 3131.4377, R2: 0.2685\n",
      "==========================================================================================\n",
      "Epoch [3946/5000] | Time: 0.33s\n",
      "(Training) Loss: 906163.7640\n",
      "(Validation) Loss: 719092.1194, MAE: 3128.9111, R2: 0.2685\n",
      "==========================================================================================\n",
      "Epoch [3947/5000] | Time: 0.30s\n",
      "(Training) Loss: 903757.4841\n",
      "(Validation) Loss: 719029.3581, MAE: 3131.2324, R2: 0.2686\n",
      "==========================================================================================\n",
      "Epoch [3948/5000] | Time: 0.30s\n",
      "(Training) Loss: 909204.7630\n",
      "(Validation) Loss: 718975.9295, MAE: 3133.2239, R2: 0.2686\n",
      "==========================================================================================\n",
      "Epoch [3949/5000] | Time: 0.34s\n",
      "(Training) Loss: 891336.0451\n",
      "(Validation) Loss: 718903.3835, MAE: 3133.4817, R2: 0.2687\n",
      "==========================================================================================\n",
      "Epoch [3950/5000] | Time: 0.28s\n",
      "(Training) Loss: 894146.2589\n",
      "(Validation) Loss: 718932.6641, MAE: 3142.0974, R2: 0.2687\n",
      "==========================================================================================\n",
      "Epoch [3951/5000] | Time: 0.29s\n",
      "(Training) Loss: 897626.2297\n",
      "(Validation) Loss: 718860.0984, MAE: 3139.3594, R2: 0.2688\n",
      "==========================================================================================\n",
      "Epoch [3952/5000] | Time: 0.35s\n",
      "(Training) Loss: 903132.4315\n",
      "(Validation) Loss: 718772.9181, MAE: 3136.8828, R2: 0.2689\n",
      "==========================================================================================\n",
      "Epoch [3953/5000] | Time: 0.37s\n",
      "(Training) Loss: 905594.6199\n",
      "(Validation) Loss: 718705.9594, MAE: 3135.7749, R2: 0.2689\n",
      "==========================================================================================\n",
      "Epoch [3954/5000] | Time: 0.29s\n",
      "(Training) Loss: 901915.7544\n",
      "(Validation) Loss: 718639.3505, MAE: 3136.4155, R2: 0.2690\n",
      "==========================================================================================\n",
      "Epoch [3955/5000] | Time: 0.31s\n",
      "(Training) Loss: 894230.3547\n",
      "(Validation) Loss: 718571.1067, MAE: 3136.3228, R2: 0.2691\n",
      "==========================================================================================\n",
      "Epoch [3956/5000] | Time: 0.29s\n",
      "(Training) Loss: 907399.2636\n",
      "(Validation) Loss: 718507.0946, MAE: 3136.0220, R2: 0.2691\n",
      "==========================================================================================\n",
      "Epoch [3957/5000] | Time: 0.31s\n",
      "(Training) Loss: 899631.7259\n",
      "(Validation) Loss: 718440.5568, MAE: 3136.8191, R2: 0.2692\n",
      "==========================================================================================\n",
      "Epoch [3958/5000] | Time: 0.30s\n",
      "(Training) Loss: 917224.1612\n",
      "(Validation) Loss: 718362.8946, MAE: 3134.8098, R2: 0.2693\n",
      "==========================================================================================\n",
      "Epoch [3959/5000] | Time: 0.31s\n",
      "(Training) Loss: 911518.1345\n",
      "(Validation) Loss: 718296.4089, MAE: 3134.8350, R2: 0.2693\n",
      "==========================================================================================\n",
      "Epoch [3960/5000] | Time: 0.34s\n",
      "(Training) Loss: 898317.0641\n",
      "(Validation) Loss: 718226.0508, MAE: 3133.9146, R2: 0.2694\n",
      "==========================================================================================\n",
      "Epoch [3961/5000] | Time: 0.33s\n",
      "(Training) Loss: 896204.0520\n",
      "(Validation) Loss: 718160.6610, MAE: 3133.6367, R2: 0.2695\n",
      "==========================================================================================\n",
      "Epoch [3962/5000] | Time: 0.34s\n",
      "(Training) Loss: 892955.1612\n",
      "(Validation) Loss: 718091.9911, MAE: 3135.4299, R2: 0.2695\n",
      "==========================================================================================\n",
      "Epoch [3963/5000] | Time: 0.33s\n",
      "(Training) Loss: 901168.9619\n",
      "(Validation) Loss: 718033.6248, MAE: 3136.1543, R2: 0.2696\n",
      "==========================================================================================\n",
      "Epoch [3964/5000] | Time: 0.34s\n",
      "(Training) Loss: 891448.7678\n",
      "(Validation) Loss: 717954.7124, MAE: 3133.8079, R2: 0.2697\n",
      "==========================================================================================\n",
      "Epoch [3965/5000] | Time: 0.30s\n",
      "(Training) Loss: 894229.0520\n",
      "(Validation) Loss: 717892.3987, MAE: 3135.1492, R2: 0.2697\n",
      "==========================================================================================\n",
      "Epoch [3966/5000] | Time: 0.37s\n",
      "(Training) Loss: 897978.8109\n",
      "(Validation) Loss: 717836.2946, MAE: 3136.5933, R2: 0.2698\n",
      "==========================================================================================\n",
      "Epoch [3967/5000] | Time: 0.32s\n",
      "(Training) Loss: 887820.0644\n",
      "(Validation) Loss: 717772.7689, MAE: 3136.2483, R2: 0.2699\n",
      "==========================================================================================\n",
      "Epoch [3968/5000] | Time: 0.32s\n",
      "(Training) Loss: 887071.4960\n",
      "(Validation) Loss: 717685.6038, MAE: 3131.8057, R2: 0.2699\n",
      "==========================================================================================\n",
      "Epoch [3969/5000] | Time: 0.31s\n",
      "(Training) Loss: 913233.5241\n",
      "(Validation) Loss: 717619.9225, MAE: 3131.8105, R2: 0.2700\n",
      "==========================================================================================\n",
      "Epoch [3970/5000] | Time: 0.32s\n",
      "(Training) Loss: 908849.5336\n",
      "(Validation) Loss: 717548.2838, MAE: 3131.5447, R2: 0.2701\n",
      "==========================================================================================\n",
      "Epoch [3971/5000] | Time: 0.30s\n",
      "(Training) Loss: 909583.2786\n",
      "(Validation) Loss: 717484.2368, MAE: 3132.5317, R2: 0.2702\n",
      "==========================================================================================\n",
      "Epoch [3972/5000] | Time: 0.34s\n",
      "(Training) Loss: 899170.6618\n",
      "(Validation) Loss: 717426.1530, MAE: 3133.7610, R2: 0.2702\n",
      "==========================================================================================\n",
      "Epoch [3973/5000] | Time: 0.32s\n",
      "(Training) Loss: 891716.4949\n",
      "(Validation) Loss: 717362.7041, MAE: 3133.6597, R2: 0.2703\n",
      "==========================================================================================\n",
      "Epoch [3974/5000] | Time: 0.31s\n",
      "(Training) Loss: 903971.5489\n",
      "(Validation) Loss: 717280.8673, MAE: 3132.4124, R2: 0.2704\n",
      "==========================================================================================\n",
      "Epoch [3975/5000] | Time: 0.33s\n",
      "(Training) Loss: 890237.1872\n",
      "(Validation) Loss: 717229.8121, MAE: 3135.8877, R2: 0.2704\n",
      "==========================================================================================\n",
      "Epoch [3976/5000] | Time: 0.32s\n",
      "(Training) Loss: 898676.1942\n",
      "(Validation) Loss: 717159.6451, MAE: 3133.7549, R2: 0.2705\n",
      "==========================================================================================\n",
      "Epoch [3977/5000] | Time: 0.30s\n",
      "(Training) Loss: 905869.3807\n",
      "(Validation) Loss: 717076.2775, MAE: 3130.4045, R2: 0.2706\n",
      "==========================================================================================\n",
      "Epoch [3978/5000] | Time: 0.29s\n",
      "(Training) Loss: 908330.5774\n",
      "(Validation) Loss: 717022.2533, MAE: 3132.2539, R2: 0.2706\n",
      "==========================================================================================\n",
      "Epoch [3979/5000] | Time: 0.34s\n",
      "(Training) Loss: 886050.0535\n",
      "(Validation) Loss: 716943.8832, MAE: 3132.7991, R2: 0.2707\n",
      "==========================================================================================\n",
      "Epoch [3980/5000] | Time: 0.31s\n",
      "(Training) Loss: 899075.8991\n",
      "(Validation) Loss: 716871.3797, MAE: 3129.8064, R2: 0.2708\n",
      "==========================================================================================\n",
      "Epoch [3981/5000] | Time: 0.38s\n",
      "(Training) Loss: 885845.6821\n",
      "(Validation) Loss: 716801.3098, MAE: 3129.4258, R2: 0.2708\n",
      "==========================================================================================\n",
      "Epoch [3982/5000] | Time: 0.33s\n",
      "(Training) Loss: 907463.6574\n",
      "(Validation) Loss: 732723.5225, MAE: 3172.7583, R2: 0.2548\n",
      "==========================================================================================\n",
      "Epoch [3983/5000] | Time: 0.32s\n",
      "(Training) Loss: 909270.8249\n",
      "(Validation) Loss: 732635.8152, MAE: 3167.7981, R2: 0.2549\n",
      "==========================================================================================\n",
      "Epoch [3984/5000] | Time: 0.38s\n",
      "(Training) Loss: 916373.1371\n",
      "(Validation) Loss: 732569.6540, MAE: 3168.1011, R2: 0.2549\n",
      "==========================================================================================\n",
      "Epoch [3985/5000] | Time: 0.35s\n",
      "(Training) Loss: 915090.9457\n",
      "(Validation) Loss: 732494.5124, MAE: 3166.9692, R2: 0.2550\n",
      "==========================================================================================\n",
      "Epoch [3986/5000] | Time: 0.37s\n",
      "(Training) Loss: 926759.8966\n",
      "(Validation) Loss: 732435.3987, MAE: 3168.9163, R2: 0.2551\n",
      "==========================================================================================\n",
      "Epoch [3987/5000] | Time: 0.38s\n",
      "(Training) Loss: 919960.2297\n",
      "(Validation) Loss: 732358.0832, MAE: 3167.2761, R2: 0.2552\n",
      "==========================================================================================\n",
      "Epoch [3988/5000] | Time: 0.37s\n",
      "(Training) Loss: 928175.2970\n",
      "(Validation) Loss: 732287.0978, MAE: 3165.2803, R2: 0.2552\n",
      "==========================================================================================\n",
      "Epoch [3989/5000] | Time: 0.36s\n",
      "(Training) Loss: 927277.5241\n",
      "(Validation) Loss: 732219.6076, MAE: 3164.5232, R2: 0.2553\n",
      "==========================================================================================\n",
      "Epoch [3990/5000] | Time: 0.40s\n",
      "(Training) Loss: 903821.2594\n",
      "(Validation) Loss: 732166.2324, MAE: 3167.0076, R2: 0.2553\n",
      "==========================================================================================\n",
      "Epoch [3991/5000] | Time: 0.39s\n",
      "(Training) Loss: 911597.0971\n",
      "(Validation) Loss: 732078.5581, MAE: 3163.2231, R2: 0.2554\n",
      "==========================================================================================\n",
      "Epoch [3992/5000] | Time: 0.36s\n",
      "(Training) Loss: 917477.5926\n",
      "(Validation) Loss: 732008.5092, MAE: 3163.3765, R2: 0.2555\n",
      "==========================================================================================\n",
      "Epoch [3993/5000] | Time: 0.36s\n",
      "(Training) Loss: 907761.6853\n",
      "(Validation) Loss: 731955.0673, MAE: 3165.8523, R2: 0.2556\n",
      "==========================================================================================\n",
      "Epoch [3994/5000] | Time: 0.33s\n",
      "(Training) Loss: 918193.6501\n",
      "(Validation) Loss: 731874.7924, MAE: 3164.0403, R2: 0.2556\n",
      "==========================================================================================\n",
      "Epoch [3995/5000] | Time: 0.36s\n",
      "(Training) Loss: 908367.7367\n",
      "(Validation) Loss: 731822.7156, MAE: 3168.8799, R2: 0.2557\n",
      "==========================================================================================\n",
      "Epoch [3996/5000] | Time: 0.35s\n",
      "(Training) Loss: 912246.3953\n",
      "(Validation) Loss: 731743.0057, MAE: 3166.7324, R2: 0.2558\n",
      "==========================================================================================\n",
      "Epoch [3997/5000] | Time: 0.31s\n",
      "(Training) Loss: 910302.0298\n",
      "(Validation) Loss: 731674.3873, MAE: 3162.7305, R2: 0.2558\n",
      "==========================================================================================\n",
      "Epoch [3998/5000] | Time: 0.32s\n",
      "(Training) Loss: 914286.5641\n",
      "(Validation) Loss: 731610.5556, MAE: 3162.7068, R2: 0.2559\n",
      "==========================================================================================\n",
      "Epoch [3999/5000] | Time: 0.30s\n",
      "(Training) Loss: 930959.5635\n",
      "(Validation) Loss: 731543.9702, MAE: 3164.3284, R2: 0.2560\n",
      "==========================================================================================\n",
      "Epoch [4000/5000] | Time: 0.35s\n",
      "(Training) Loss: 912037.7887\n",
      "(Validation) Loss: 731472.8470, MAE: 3164.3416, R2: 0.2560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch4000.pth\n",
      "==========================================================================================\n",
      "Epoch [4001/5000] | Time: 0.34s\n",
      "(Training) Loss: 902059.6256\n",
      "(Validation) Loss: 731410.1378, MAE: 3163.8728, R2: 0.2561\n",
      "==========================================================================================\n",
      "Epoch [4002/5000] | Time: 0.36s\n",
      "(Training) Loss: 905159.7002\n",
      "(Validation) Loss: 731338.8235, MAE: 3164.9219, R2: 0.2562\n",
      "==========================================================================================\n",
      "Epoch [4003/5000] | Time: 0.32s\n",
      "(Training) Loss: 939836.7697\n",
      "(Validation) Loss: 731274.1371, MAE: 3164.5833, R2: 0.2562\n",
      "==========================================================================================\n",
      "Epoch [4004/5000] | Time: 0.38s\n",
      "(Training) Loss: 911360.5247\n",
      "(Validation) Loss: 731190.3016, MAE: 3159.6028, R2: 0.2563\n",
      "==========================================================================================\n",
      "Epoch [4005/5000] | Time: 0.30s\n",
      "(Training) Loss: 905585.4860\n",
      "(Validation) Loss: 731128.9790, MAE: 3161.4912, R2: 0.2564\n",
      "==========================================================================================\n",
      "Epoch [4006/5000] | Time: 0.33s\n",
      "(Training) Loss: 912920.5508\n",
      "(Validation) Loss: 731059.3251, MAE: 3160.1279, R2: 0.2565\n",
      "==========================================================================================\n",
      "Epoch [4007/5000] | Time: 0.36s\n",
      "(Training) Loss: 920112.4194\n",
      "(Validation) Loss: 730992.1771, MAE: 3160.8799, R2: 0.2565\n",
      "==========================================================================================\n",
      "Epoch [4008/5000] | Time: 0.34s\n",
      "(Training) Loss: 903292.5216\n",
      "(Validation) Loss: 730936.3219, MAE: 3162.8635, R2: 0.2566\n",
      "==========================================================================================\n",
      "Epoch [4009/5000] | Time: 0.32s\n",
      "(Training) Loss: 935848.4169\n",
      "(Validation) Loss: 730856.1238, MAE: 3159.2305, R2: 0.2567\n",
      "==========================================================================================\n",
      "Epoch [4010/5000] | Time: 0.33s\n",
      "(Training) Loss: 911909.4169\n",
      "(Validation) Loss: 730790.3638, MAE: 3159.3667, R2: 0.2567\n",
      "==========================================================================================\n",
      "Epoch [4011/5000] | Time: 0.33s\n",
      "(Training) Loss: 914221.5980\n",
      "(Validation) Loss: 730737.3949, MAE: 3161.3728, R2: 0.2568\n",
      "==========================================================================================\n",
      "Epoch [4012/5000] | Time: 0.30s\n",
      "(Training) Loss: 906196.1009\n",
      "(Validation) Loss: 730680.3587, MAE: 3161.0391, R2: 0.2568\n",
      "==========================================================================================\n",
      "Epoch [4013/5000] | Time: 0.30s\n",
      "(Training) Loss: 903521.7494\n",
      "(Validation) Loss: 730624.8210, MAE: 3163.0020, R2: 0.2569\n",
      "==========================================================================================\n",
      "Epoch [4014/5000] | Time: 0.35s\n",
      "(Training) Loss: 907934.8880\n",
      "(Validation) Loss: 730550.3892, MAE: 3160.5305, R2: 0.2570\n",
      "==========================================================================================\n",
      "Epoch [4015/5000] | Time: 0.37s\n",
      "(Training) Loss: 915497.1364\n",
      "(Validation) Loss: 730482.5600, MAE: 3165.5730, R2: 0.2570\n",
      "==========================================================================================\n",
      "Epoch [4016/5000] | Time: 0.32s\n",
      "(Training) Loss: 911508.2500\n",
      "(Validation) Loss: 730416.6971, MAE: 3165.1089, R2: 0.2571\n",
      "==========================================================================================\n",
      "Epoch [4017/5000] | Time: 0.31s\n",
      "(Training) Loss: 907546.3725\n",
      "(Validation) Loss: 730351.9168, MAE: 3161.0918, R2: 0.2572\n",
      "==========================================================================================\n",
      "Epoch [4018/5000] | Time: 0.31s\n",
      "(Training) Loss: 909816.4518\n",
      "(Validation) Loss: 730314.0756, MAE: 3165.5422, R2: 0.2572\n",
      "==========================================================================================\n",
      "Epoch [4019/5000] | Time: 0.33s\n",
      "(Training) Loss: 921465.6548\n",
      "(Validation) Loss: 730232.5676, MAE: 3166.2771, R2: 0.2573\n",
      "==========================================================================================\n",
      "Epoch [4020/5000] | Time: 0.34s\n",
      "(Training) Loss: 909324.6681\n",
      "(Validation) Loss: 730148.2952, MAE: 3160.5442, R2: 0.2574\n",
      "==========================================================================================\n",
      "Epoch [4021/5000] | Time: 0.33s\n",
      "(Training) Loss: 903301.9968\n",
      "(Validation) Loss: 730088.9879, MAE: 3162.7769, R2: 0.2574\n",
      "==========================================================================================\n",
      "Epoch [4022/5000] | Time: 0.32s\n",
      "(Training) Loss: 905817.2462\n",
      "(Validation) Loss: 730025.1619, MAE: 3161.6934, R2: 0.2575\n",
      "==========================================================================================\n",
      "Epoch [4023/5000] | Time: 0.32s\n",
      "(Training) Loss: 948350.0863\n",
      "(Validation) Loss: 741623.4025, MAE: 3192.8850, R2: 0.2458\n",
      "==========================================================================================\n",
      "Epoch [4024/5000] | Time: 0.30s\n",
      "(Training) Loss: 913520.2510\n",
      "(Validation) Loss: 741538.1251, MAE: 3188.7019, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [4025/5000] | Time: 0.32s\n",
      "(Training) Loss: 936810.7202\n",
      "(Validation) Loss: 741473.1295, MAE: 3189.1057, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [4026/5000] | Time: 0.34s\n",
      "(Training) Loss: 913818.0972\n",
      "(Validation) Loss: 741406.9156, MAE: 3189.7317, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [4027/5000] | Time: 0.36s\n",
      "(Training) Loss: 925691.2310\n",
      "(Validation) Loss: 741343.5276, MAE: 3187.9607, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [4028/5000] | Time: 0.35s\n",
      "(Training) Loss: 930594.7430\n",
      "(Validation) Loss: 741285.9695, MAE: 3191.6387, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [4029/5000] | Time: 0.35s\n",
      "(Training) Loss: 915267.4638\n",
      "(Validation) Loss: 741202.0546, MAE: 3185.2114, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [4030/5000] | Time: 0.32s\n",
      "(Training) Loss: 922634.6294\n",
      "(Validation) Loss: 741144.2965, MAE: 3187.3640, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [4031/5000] | Time: 0.30s\n",
      "(Training) Loss: 930299.2659\n",
      "(Validation) Loss: 741080.1873, MAE: 3187.7502, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [4032/5000] | Time: 0.31s\n",
      "(Training) Loss: 914746.4653\n",
      "(Validation) Loss: 741004.3937, MAE: 3186.4302, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [4033/5000] | Time: 0.35s\n",
      "(Training) Loss: 917933.9162\n",
      "(Validation) Loss: 740950.4159, MAE: 3189.0706, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [4034/5000] | Time: 0.35s\n",
      "(Training) Loss: 916903.9549\n",
      "(Validation) Loss: 740911.2127, MAE: 3193.6917, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [4035/5000] | Time: 0.41s\n",
      "(Training) Loss: 922148.0635\n",
      "(Validation) Loss: 740810.2438, MAE: 3189.6956, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [4036/5000] | Time: 0.41s\n",
      "(Training) Loss: 934480.9442\n",
      "(Validation) Loss: 740817.0190, MAE: 3200.1392, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [4037/5000] | Time: 0.39s\n",
      "(Training) Loss: 949368.6681\n",
      "(Validation) Loss: 743596.4705, MAE: 3212.0986, R2: 0.2438\n",
      "==========================================================================================\n",
      "Epoch [4038/5000] | Time: 0.40s\n",
      "(Training) Loss: 936232.2906\n",
      "(Validation) Loss: 743520.4267, MAE: 3212.5356, R2: 0.2439\n",
      "==========================================================================================\n",
      "Epoch [4039/5000] | Time: 0.34s\n",
      "(Training) Loss: 938144.1758\n",
      "(Validation) Loss: 743441.9790, MAE: 3209.2710, R2: 0.2440\n",
      "==========================================================================================\n",
      "Epoch [4040/5000] | Time: 0.37s\n",
      "(Training) Loss: 933725.4156\n",
      "(Validation) Loss: 743348.7187, MAE: 3206.2168, R2: 0.2441\n",
      "==========================================================================================\n",
      "Epoch [4041/5000] | Time: 0.34s\n",
      "(Training) Loss: 921717.2481\n",
      "(Validation) Loss: 743294.9556, MAE: 3212.2043, R2: 0.2441\n",
      "==========================================================================================\n",
      "Epoch [4042/5000] | Time: 0.37s\n",
      "(Training) Loss: 920688.5911\n",
      "(Validation) Loss: 743209.4413, MAE: 3209.6472, R2: 0.2442\n",
      "==========================================================================================\n",
      "Epoch [4043/5000] | Time: 0.34s\n",
      "(Training) Loss: 923486.0457\n",
      "(Validation) Loss: 743170.8273, MAE: 3214.7651, R2: 0.2442\n",
      "==========================================================================================\n",
      "Epoch [4044/5000] | Time: 0.33s\n",
      "(Training) Loss: 930344.7138\n",
      "(Validation) Loss: 743070.8095, MAE: 3207.7908, R2: 0.2443\n",
      "==========================================================================================\n",
      "Epoch [4045/5000] | Time: 0.30s\n",
      "(Training) Loss: 926949.9473\n",
      "(Validation) Loss: 743004.5505, MAE: 3208.4163, R2: 0.2444\n",
      "==========================================================================================\n",
      "Epoch [4046/5000] | Time: 0.34s\n",
      "(Training) Loss: 954642.8585\n",
      "(Validation) Loss: 742929.6432, MAE: 3207.7327, R2: 0.2445\n",
      "==========================================================================================\n",
      "Epoch [4047/5000] | Time: 0.32s\n",
      "(Training) Loss: 920045.9359\n",
      "(Validation) Loss: 742870.1162, MAE: 3209.2615, R2: 0.2446\n",
      "==========================================================================================\n",
      "Epoch [4048/5000] | Time: 0.32s\n",
      "(Training) Loss: 926954.4143\n",
      "(Validation) Loss: 742799.6203, MAE: 3207.0159, R2: 0.2446\n",
      "==========================================================================================\n",
      "Epoch [4049/5000] | Time: 0.34s\n",
      "(Training) Loss: 915930.7548\n",
      "(Validation) Loss: 742728.7384, MAE: 3205.1660, R2: 0.2447\n",
      "==========================================================================================\n",
      "Epoch [4050/5000] | Time: 0.33s\n",
      "(Training) Loss: 921682.7049\n",
      "(Validation) Loss: 742666.0095, MAE: 3211.0869, R2: 0.2448\n",
      "==========================================================================================\n",
      "Epoch [4051/5000] | Time: 0.30s\n",
      "(Training) Loss: 920347.6783\n",
      "(Validation) Loss: 742590.4108, MAE: 3206.0657, R2: 0.2448\n",
      "==========================================================================================\n",
      "Epoch [4052/5000] | Time: 0.34s\n",
      "(Training) Loss: 920106.2678\n",
      "(Validation) Loss: 742521.9162, MAE: 3202.9548, R2: 0.2449\n",
      "==========================================================================================\n",
      "Epoch [4053/5000] | Time: 0.35s\n",
      "(Training) Loss: 933693.2513\n",
      "(Validation) Loss: 742463.2381, MAE: 3204.5505, R2: 0.2450\n",
      "==========================================================================================\n",
      "Epoch [4054/5000] | Time: 0.36s\n",
      "(Training) Loss: 946108.8547\n",
      "(Validation) Loss: 742391.6781, MAE: 3202.4797, R2: 0.2450\n",
      "==========================================================================================\n",
      "Epoch [4055/5000] | Time: 0.34s\n",
      "(Training) Loss: 921512.4245\n",
      "(Validation) Loss: 742319.0343, MAE: 3203.5017, R2: 0.2451\n",
      "==========================================================================================\n",
      "Epoch [4056/5000] | Time: 0.32s\n",
      "(Training) Loss: 920620.8642\n",
      "(Validation) Loss: 742247.7537, MAE: 3199.8174, R2: 0.2452\n",
      "==========================================================================================\n",
      "Epoch [4057/5000] | Time: 0.35s\n",
      "(Training) Loss: 933430.4023\n",
      "(Validation) Loss: 742181.4578, MAE: 3206.6375, R2: 0.2452\n",
      "==========================================================================================\n",
      "Epoch [4058/5000] | Time: 0.34s\n",
      "(Training) Loss: 921421.2506\n",
      "(Validation) Loss: 742119.3930, MAE: 3203.2112, R2: 0.2453\n",
      "==========================================================================================\n",
      "Epoch [4059/5000] | Time: 0.33s\n",
      "(Training) Loss: 931956.0298\n",
      "(Validation) Loss: 742044.0248, MAE: 3198.3511, R2: 0.2454\n",
      "==========================================================================================\n",
      "Epoch [4060/5000] | Time: 0.32s\n",
      "(Training) Loss: 941754.2919\n",
      "(Validation) Loss: 741986.8324, MAE: 3200.9785, R2: 0.2454\n",
      "==========================================================================================\n",
      "Epoch [4061/5000] | Time: 0.40s\n",
      "(Training) Loss: 940100.2056\n",
      "(Validation) Loss: 741913.7429, MAE: 3199.8555, R2: 0.2455\n",
      "==========================================================================================\n",
      "Epoch [4062/5000] | Time: 0.34s\n",
      "(Training) Loss: 928939.5260\n",
      "(Validation) Loss: 741858.5981, MAE: 3203.9333, R2: 0.2456\n",
      "==========================================================================================\n",
      "Epoch [4063/5000] | Time: 0.31s\n",
      "(Training) Loss: 918694.5425\n",
      "(Validation) Loss: 741782.0787, MAE: 3199.7766, R2: 0.2456\n",
      "==========================================================================================\n",
      "Epoch [4064/5000] | Time: 0.31s\n",
      "(Training) Loss: 931806.5209\n",
      "(Validation) Loss: 741719.4514, MAE: 3202.1394, R2: 0.2457\n",
      "==========================================================================================\n",
      "Epoch [4065/5000] | Time: 0.32s\n",
      "(Training) Loss: 920779.5660\n",
      "(Validation) Loss: 741643.6095, MAE: 3199.5339, R2: 0.2458\n",
      "==========================================================================================\n",
      "Epoch [4066/5000] | Time: 0.28s\n",
      "(Training) Loss: 924751.8096\n",
      "(Validation) Loss: 741571.4375, MAE: 3197.5520, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [4067/5000] | Time: 0.37s\n",
      "(Training) Loss: 927064.8940\n",
      "(Validation) Loss: 741503.8470, MAE: 3196.5972, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [4068/5000] | Time: 0.35s\n",
      "(Training) Loss: 914301.8163\n",
      "(Validation) Loss: 741453.6470, MAE: 3200.9697, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [4069/5000] | Time: 0.32s\n",
      "(Training) Loss: 929320.4778\n",
      "(Validation) Loss: 741379.6717, MAE: 3200.0625, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [4070/5000] | Time: 0.36s\n",
      "(Training) Loss: 935431.1948\n",
      "(Validation) Loss: 741307.9143, MAE: 3196.6685, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [4071/5000] | Time: 0.31s\n",
      "(Training) Loss: 915370.4629\n",
      "(Validation) Loss: 741242.3416, MAE: 3196.3486, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [4072/5000] | Time: 0.31s\n",
      "(Training) Loss: 926748.3071\n",
      "(Validation) Loss: 741174.1041, MAE: 3195.8687, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [4073/5000] | Time: 0.35s\n",
      "(Training) Loss: 929768.8008\n",
      "(Validation) Loss: 741111.9225, MAE: 3199.6533, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [4074/5000] | Time: 0.33s\n",
      "(Training) Loss: 940775.2621\n",
      "(Validation) Loss: 741042.2914, MAE: 3196.7356, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [4075/5000] | Time: 0.34s\n",
      "(Training) Loss: 924426.9511\n",
      "(Validation) Loss: 740975.6495, MAE: 3196.0796, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [4076/5000] | Time: 0.35s\n",
      "(Training) Loss: 954566.8629\n",
      "(Validation) Loss: 740917.8006, MAE: 3199.3022, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [4077/5000] | Time: 0.33s\n",
      "(Training) Loss: 926553.3813\n",
      "(Validation) Loss: 740838.8578, MAE: 3194.9844, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [4078/5000] | Time: 0.29s\n",
      "(Training) Loss: 923015.5330\n",
      "(Validation) Loss: 740774.5822, MAE: 3193.9790, R2: 0.2467\n",
      "==========================================================================================\n",
      "Epoch [4079/5000] | Time: 0.32s\n",
      "(Training) Loss: 923190.4118\n",
      "(Validation) Loss: 740719.5232, MAE: 3196.3003, R2: 0.2467\n",
      "==========================================================================================\n",
      "Epoch [4080/5000] | Time: 0.29s\n",
      "(Training) Loss: 912616.6701\n",
      "(Validation) Loss: 740636.9060, MAE: 3193.2874, R2: 0.2468\n",
      "==========================================================================================\n",
      "Epoch [4081/5000] | Time: 0.30s\n",
      "(Training) Loss: 918403.8242\n",
      "(Validation) Loss: 740575.1289, MAE: 3193.8467, R2: 0.2469\n",
      "==========================================================================================\n",
      "Epoch [4082/5000] | Time: 0.34s\n",
      "(Training) Loss: 923490.1745\n",
      "(Validation) Loss: 740506.4654, MAE: 3193.4949, R2: 0.2469\n",
      "==========================================================================================\n",
      "Epoch [4083/5000] | Time: 0.39s\n",
      "(Training) Loss: 941172.3274\n",
      "(Validation) Loss: 740449.6286, MAE: 3198.1128, R2: 0.2470\n",
      "==========================================================================================\n",
      "Epoch [4084/5000] | Time: 0.35s\n",
      "(Training) Loss: 941842.2510\n",
      "(Validation) Loss: 740377.3181, MAE: 3194.0295, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [4085/5000] | Time: 0.38s\n",
      "(Training) Loss: 921622.0711\n",
      "(Validation) Loss: 740361.6698, MAE: 3217.6365, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [4086/5000] | Time: 0.33s\n",
      "(Training) Loss: 935284.2989\n",
      "(Validation) Loss: 740263.3689, MAE: 3197.2007, R2: 0.2472\n",
      "==========================================================================================\n",
      "Epoch [4087/5000] | Time: 0.33s\n",
      "(Training) Loss: 922735.9461\n",
      "(Validation) Loss: 740188.2559, MAE: 3197.3701, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [4088/5000] | Time: 0.35s\n",
      "(Training) Loss: 924489.1732\n",
      "(Validation) Loss: 740118.7937, MAE: 3196.4226, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [4089/5000] | Time: 0.34s\n",
      "(Training) Loss: 919486.7824\n",
      "(Validation) Loss: 740061.0946, MAE: 3197.7688, R2: 0.2474\n",
      "==========================================================================================\n",
      "Epoch [4090/5000] | Time: 0.33s\n",
      "(Training) Loss: 924742.9714\n",
      "(Validation) Loss: 739984.8394, MAE: 3194.1067, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [4091/5000] | Time: 0.32s\n",
      "(Training) Loss: 927600.3940\n",
      "(Validation) Loss: 739912.6438, MAE: 3192.5159, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [4092/5000] | Time: 0.36s\n",
      "(Training) Loss: 924150.6764\n",
      "(Validation) Loss: 739846.6762, MAE: 3192.1216, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [4093/5000] | Time: 0.34s\n",
      "(Training) Loss: 918409.4943\n",
      "(Validation) Loss: 739782.6171, MAE: 3193.7234, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [4094/5000] | Time: 0.30s\n",
      "(Training) Loss: 921467.5470\n",
      "(Validation) Loss: 739717.9429, MAE: 3194.8767, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [4095/5000] | Time: 0.37s\n",
      "(Training) Loss: 922464.6047\n",
      "(Validation) Loss: 738510.5968, MAE: 3188.7095, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [4096/5000] | Time: 0.30s\n",
      "(Training) Loss: 930531.9473\n",
      "(Validation) Loss: 738440.0489, MAE: 3190.0828, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [4097/5000] | Time: 0.36s\n",
      "(Training) Loss: 927659.9004\n",
      "(Validation) Loss: 738366.8711, MAE: 3188.5537, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [4098/5000] | Time: 0.35s\n",
      "(Training) Loss: 910722.2107\n",
      "(Validation) Loss: 738296.8622, MAE: 3190.0234, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [4099/5000] | Time: 0.30s\n",
      "(Training) Loss: 910693.3988\n",
      "(Validation) Loss: 738225.6019, MAE: 3189.5813, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [4100/5000] | Time: 0.32s\n",
      "(Training) Loss: 927216.4036\n",
      "(Validation) Loss: 738150.7924, MAE: 3187.8760, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [4101/5000] | Time: 0.34s\n",
      "(Training) Loss: 913011.9070\n",
      "(Validation) Loss: 738092.4533, MAE: 3189.3533, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [4102/5000] | Time: 0.37s\n",
      "(Training) Loss: 919636.9835\n",
      "(Validation) Loss: 738023.8178, MAE: 3191.6035, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [4103/5000] | Time: 0.33s\n",
      "(Training) Loss: 910085.2336\n",
      "(Validation) Loss: 737938.8800, MAE: 3186.0730, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [4104/5000] | Time: 0.34s\n",
      "(Training) Loss: 931860.0178\n",
      "(Validation) Loss: 737877.9752, MAE: 3188.0886, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [4105/5000] | Time: 0.28s\n",
      "(Training) Loss: 929285.1662\n",
      "(Validation) Loss: 737801.5054, MAE: 3186.4722, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [4106/5000] | Time: 0.33s\n",
      "(Training) Loss: 916062.1726\n",
      "(Validation) Loss: 737731.4679, MAE: 3185.9375, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [4107/5000] | Time: 0.33s\n",
      "(Training) Loss: 921790.0032\n",
      "(Validation) Loss: 737668.4832, MAE: 3187.4226, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [4108/5000] | Time: 0.35s\n",
      "(Training) Loss: 912994.3496\n",
      "(Validation) Loss: 737596.1219, MAE: 3187.4304, R2: 0.2499\n",
      "==========================================================================================\n",
      "Epoch [4109/5000] | Time: 0.37s\n",
      "(Training) Loss: 922551.0165\n",
      "(Validation) Loss: 737528.4267, MAE: 3187.1145, R2: 0.2499\n",
      "==========================================================================================\n",
      "Epoch [4110/5000] | Time: 0.31s\n",
      "(Training) Loss: 918300.2316\n",
      "(Validation) Loss: 737443.4203, MAE: 3184.5261, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [4111/5000] | Time: 0.28s\n",
      "(Training) Loss: 940351.6821\n",
      "(Validation) Loss: 737375.3314, MAE: 3187.2476, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [4112/5000] | Time: 0.35s\n",
      "(Training) Loss: 912452.5666\n",
      "(Validation) Loss: 739751.4483, MAE: 3193.6975, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [4113/5000] | Time: 0.31s\n",
      "(Training) Loss: 915308.5079\n",
      "(Validation) Loss: 739686.5016, MAE: 3195.1177, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [4114/5000] | Time: 0.31s\n",
      "(Training) Loss: 924251.9746\n",
      "(Validation) Loss: 739614.0584, MAE: 3192.0835, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [4115/5000] | Time: 0.36s\n",
      "(Training) Loss: 933675.8832\n",
      "(Validation) Loss: 739544.0317, MAE: 3192.5508, R2: 0.2479\n",
      "==========================================================================================\n",
      "Epoch [4116/5000] | Time: 0.35s\n",
      "(Training) Loss: 926243.5393\n",
      "(Validation) Loss: 739490.3270, MAE: 3196.4290, R2: 0.2480\n",
      "==========================================================================================\n",
      "Epoch [4117/5000] | Time: 0.34s\n",
      "(Training) Loss: 923882.9150\n",
      "(Validation) Loss: 739404.2571, MAE: 3198.3149, R2: 0.2480\n",
      "==========================================================================================\n",
      "Epoch [4118/5000] | Time: 0.33s\n",
      "(Training) Loss: 919228.1459\n",
      "(Validation) Loss: 739335.9276, MAE: 3192.8279, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [4119/5000] | Time: 0.35s\n",
      "(Training) Loss: 931904.9664\n",
      "(Validation) Loss: 739265.5854, MAE: 3190.6726, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [4120/5000] | Time: 0.35s\n",
      "(Training) Loss: 929014.0197\n",
      "(Validation) Loss: 739242.7689, MAE: 3197.6807, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [4121/5000] | Time: 0.31s\n",
      "(Training) Loss: 917082.1808\n",
      "(Validation) Loss: 739133.1632, MAE: 3193.5283, R2: 0.2483\n",
      "==========================================================================================\n",
      "Epoch [4122/5000] | Time: 0.34s\n",
      "(Training) Loss: 923142.8883\n",
      "(Validation) Loss: 739063.8705, MAE: 3192.3721, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [4123/5000] | Time: 0.33s\n",
      "(Training) Loss: 914588.0197\n",
      "(Validation) Loss: 738988.2813, MAE: 3191.1646, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [4124/5000] | Time: 0.31s\n",
      "(Training) Loss: 913097.3309\n",
      "(Validation) Loss: 738921.0038, MAE: 3191.0378, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [4125/5000] | Time: 0.31s\n",
      "(Training) Loss: 913676.3664\n",
      "(Validation) Loss: 738849.4063, MAE: 3189.3118, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [4126/5000] | Time: 0.33s\n",
      "(Training) Loss: 934951.6497\n",
      "(Validation) Loss: 745387.3124, MAE: 3212.2837, R2: 0.2420\n",
      "==========================================================================================\n",
      "Epoch [4127/5000] | Time: 0.33s\n",
      "(Training) Loss: 965591.7608\n",
      "(Validation) Loss: 779670.2165, MAE: 3319.2114, R2: 0.2075\n",
      "==========================================================================================\n",
      "Epoch [4128/5000] | Time: 0.35s\n",
      "(Training) Loss: 974873.4569\n",
      "(Validation) Loss: 779490.4603, MAE: 3316.3708, R2: 0.2077\n",
      "==========================================================================================\n",
      "Epoch [4129/5000] | Time: 0.34s\n",
      "(Training) Loss: 966282.5635\n",
      "(Validation) Loss: 779561.6267, MAE: 3325.6921, R2: 0.2076\n",
      "==========================================================================================\n",
      "Epoch [4130/5000] | Time: 0.31s\n",
      "(Training) Loss: 958798.0606\n",
      "(Validation) Loss: 779379.7594, MAE: 3319.5137, R2: 0.2078\n",
      "==========================================================================================\n",
      "Epoch [4131/5000] | Time: 0.38s\n",
      "(Training) Loss: 957459.2993\n",
      "(Validation) Loss: 779300.1371, MAE: 3320.8733, R2: 0.2079\n",
      "==========================================================================================\n",
      "Epoch [4132/5000] | Time: 0.39s\n",
      "(Training) Loss: 970192.4162\n",
      "(Validation) Loss: 764015.4756, MAE: 3274.6807, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [4133/5000] | Time: 0.37s\n",
      "(Training) Loss: 947425.4105\n",
      "(Validation) Loss: 763911.3098, MAE: 3272.8784, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [4134/5000] | Time: 0.35s\n",
      "(Training) Loss: 951282.0013\n",
      "(Validation) Loss: 763844.7581, MAE: 3278.8022, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [4135/5000] | Time: 0.32s\n",
      "(Training) Loss: 959380.2805\n",
      "(Validation) Loss: 763760.8552, MAE: 3276.5796, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [4136/5000] | Time: 0.33s\n",
      "(Training) Loss: 965159.4245\n",
      "(Validation) Loss: 763662.9086, MAE: 3274.1851, R2: 0.2236\n",
      "==========================================================================================\n",
      "Epoch [4137/5000] | Time: 0.32s\n",
      "(Training) Loss: 949352.3706\n",
      "(Validation) Loss: 763592.1702, MAE: 3275.2834, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [4138/5000] | Time: 0.31s\n",
      "(Training) Loss: 946347.9277\n",
      "(Validation) Loss: 763510.9340, MAE: 3274.8052, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [4139/5000] | Time: 0.32s\n",
      "(Training) Loss: 953225.5739\n",
      "(Validation) Loss: 763421.9352, MAE: 3273.0020, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [4140/5000] | Time: 0.38s\n",
      "(Training) Loss: 944890.8407\n",
      "(Validation) Loss: 763338.3244, MAE: 3271.8013, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [4141/5000] | Time: 0.30s\n",
      "(Training) Loss: 950462.4194\n",
      "(Validation) Loss: 763261.6089, MAE: 3276.3413, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [4142/5000] | Time: 0.32s\n",
      "(Training) Loss: 950087.0016\n",
      "(Validation) Loss: 763167.5790, MAE: 3266.0569, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [4143/5000] | Time: 0.34s\n",
      "(Training) Loss: 947221.1402\n",
      "(Validation) Loss: 763092.2298, MAE: 3268.2241, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [4144/5000] | Time: 0.31s\n",
      "(Training) Loss: 966413.8902\n",
      "(Validation) Loss: 763013.4908, MAE: 3267.2058, R2: 0.2243\n",
      "==========================================================================================\n",
      "Epoch [4145/5000] | Time: 0.34s\n",
      "(Training) Loss: 939982.2951\n",
      "(Validation) Loss: 762957.4451, MAE: 3271.4443, R2: 0.2243\n",
      "==========================================================================================\n",
      "Epoch [4146/5000] | Time: 0.33s\n",
      "(Training) Loss: 954223.4911\n",
      "(Validation) Loss: 762861.3987, MAE: 3267.2000, R2: 0.2244\n",
      "==========================================================================================\n",
      "Epoch [4147/5000] | Time: 0.33s\n",
      "(Training) Loss: 949877.1843\n",
      "(Validation) Loss: 762782.9949, MAE: 3266.2090, R2: 0.2245\n",
      "==========================================================================================\n",
      "Epoch [4148/5000] | Time: 0.37s\n",
      "(Training) Loss: 993680.5463\n",
      "(Validation) Loss: 762698.9581, MAE: 3266.9438, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [4149/5000] | Time: 0.39s\n",
      "(Training) Loss: 945997.1358\n",
      "(Validation) Loss: 762623.0552, MAE: 3267.7009, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [4150/5000] | Time: 0.36s\n",
      "(Training) Loss: 945292.8826\n",
      "(Validation) Loss: 762537.8095, MAE: 3265.7424, R2: 0.2247\n",
      "==========================================================================================\n",
      "Epoch [4151/5000] | Time: 0.36s\n",
      "(Training) Loss: 966237.9994\n",
      "(Validation) Loss: 762461.7905, MAE: 3264.7576, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [4152/5000] | Time: 0.34s\n",
      "(Training) Loss: 939314.7370\n",
      "(Validation) Loss: 762395.9676, MAE: 3268.1677, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [4153/5000] | Time: 0.36s\n",
      "(Training) Loss: 951033.4721\n",
      "(Validation) Loss: 762308.1060, MAE: 3264.1423, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [4154/5000] | Time: 0.38s\n",
      "(Training) Loss: 952182.2386\n",
      "(Validation) Loss: 762225.7714, MAE: 3263.2346, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [4155/5000] | Time: 0.43s\n",
      "(Training) Loss: 950162.8306\n",
      "(Validation) Loss: 762156.1105, MAE: 3264.5784, R2: 0.2251\n",
      "==========================================================================================\n",
      "Epoch [4156/5000] | Time: 0.38s\n",
      "(Training) Loss: 947923.1739\n",
      "(Validation) Loss: 762074.2616, MAE: 3262.8323, R2: 0.2252\n",
      "==========================================================================================\n",
      "Epoch [4157/5000] | Time: 0.34s\n",
      "(Training) Loss: 942844.9867\n",
      "(Validation) Loss: 761995.0546, MAE: 3262.3474, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [4158/5000] | Time: 0.32s\n",
      "(Training) Loss: 945642.6329\n",
      "(Validation) Loss: 761935.6457, MAE: 3266.6514, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [4159/5000] | Time: 0.33s\n",
      "(Training) Loss: 948192.5127\n",
      "(Validation) Loss: 761872.4724, MAE: 3267.1045, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [4160/5000] | Time: 0.33s\n",
      "(Training) Loss: 954130.2805\n",
      "(Validation) Loss: 761791.4216, MAE: 3266.5447, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [4161/5000] | Time: 0.37s\n",
      "(Training) Loss: 948907.4169\n",
      "(Validation) Loss: 761696.6813, MAE: 3262.6123, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [4162/5000] | Time: 0.34s\n",
      "(Training) Loss: 961929.3135\n",
      "(Validation) Loss: 761624.0914, MAE: 3262.4617, R2: 0.2257\n",
      "==========================================================================================\n",
      "Epoch [4163/5000] | Time: 0.30s\n",
      "(Training) Loss: 955675.8046\n",
      "(Validation) Loss: 761529.7416, MAE: 3259.5637, R2: 0.2257\n",
      "==========================================================================================\n",
      "Epoch [4164/5000] | Time: 0.33s\n",
      "(Training) Loss: 941280.6345\n",
      "(Validation) Loss: 761459.0305, MAE: 3261.2217, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [4165/5000] | Time: 0.33s\n",
      "(Training) Loss: 946556.3039\n",
      "(Validation) Loss: 761385.8375, MAE: 3261.3733, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [4166/5000] | Time: 0.30s\n",
      "(Training) Loss: 968553.3845\n",
      "(Validation) Loss: 761315.2889, MAE: 3261.6514, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [4167/5000] | Time: 0.31s\n",
      "(Training) Loss: 967793.0508\n",
      "(Validation) Loss: 761224.3968, MAE: 3259.5610, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [4168/5000] | Time: 0.33s\n",
      "(Training) Loss: 942162.4365\n",
      "(Validation) Loss: 761146.8749, MAE: 3260.8655, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [4169/5000] | Time: 0.36s\n",
      "(Training) Loss: 940542.7043\n",
      "(Validation) Loss: 761072.4514, MAE: 3258.5093, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [4170/5000] | Time: 0.32s\n",
      "(Training) Loss: 954733.4734\n",
      "(Validation) Loss: 761013.3156, MAE: 3263.3105, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [4171/5000] | Time: 0.35s\n",
      "(Training) Loss: 937602.8604\n",
      "(Validation) Loss: 760972.1454, MAE: 3264.3296, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [4172/5000] | Time: 0.37s\n",
      "(Training) Loss: 959410.2503\n",
      "(Validation) Loss: 760872.3067, MAE: 3263.6921, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [4173/5000] | Time: 0.38s\n",
      "(Training) Loss: 953074.3591\n",
      "(Validation) Loss: 760784.1956, MAE: 3263.8909, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [4174/5000] | Time: 0.31s\n",
      "(Training) Loss: 972831.7747\n",
      "(Validation) Loss: 786963.6514, MAE: 3391.8562, R2: 0.2001\n",
      "==========================================================================================\n",
      "Epoch [4175/5000] | Time: 0.33s\n",
      "(Training) Loss: 980246.6523\n",
      "(Validation) Loss: 786736.7022, MAE: 3367.4280, R2: 0.2004\n",
      "==========================================================================================\n",
      "Epoch [4176/5000] | Time: 0.33s\n",
      "(Training) Loss: 975371.3541\n",
      "(Validation) Loss: 786648.4133, MAE: 3366.6931, R2: 0.2004\n",
      "==========================================================================================\n",
      "Epoch [4177/5000] | Time: 0.37s\n",
      "(Training) Loss: 970262.1098\n",
      "(Validation) Loss: 786566.3340, MAE: 3367.5232, R2: 0.2005\n",
      "==========================================================================================\n",
      "Epoch [4178/5000] | Time: 0.38s\n",
      "(Training) Loss: 968937.3490\n",
      "(Validation) Loss: 786476.2971, MAE: 3365.7271, R2: 0.2006\n",
      "==========================================================================================\n",
      "Epoch [4179/5000] | Time: 0.39s\n",
      "(Training) Loss: 971889.7119\n",
      "(Validation) Loss: 786395.2146, MAE: 3362.6797, R2: 0.2007\n",
      "==========================================================================================\n",
      "Epoch [4180/5000] | Time: 0.37s\n",
      "(Training) Loss: 970702.7989\n",
      "(Validation) Loss: 786313.4133, MAE: 3362.5972, R2: 0.2008\n",
      "==========================================================================================\n",
      "Epoch [4181/5000] | Time: 0.35s\n",
      "(Training) Loss: 976185.6288\n",
      "(Validation) Loss: 786232.0667, MAE: 3361.8594, R2: 0.2009\n",
      "==========================================================================================\n",
      "Epoch [4182/5000] | Time: 0.32s\n",
      "(Training) Loss: 982535.1707\n",
      "(Validation) Loss: 786149.7581, MAE: 3361.6011, R2: 0.2010\n",
      "==========================================================================================\n",
      "Epoch [4183/5000] | Time: 0.34s\n",
      "(Training) Loss: 972043.4039\n",
      "(Validation) Loss: 786067.0832, MAE: 3360.7209, R2: 0.2010\n",
      "==========================================================================================\n",
      "Epoch [4184/5000] | Time: 0.33s\n",
      "(Training) Loss: 985220.7398\n",
      "(Validation) Loss: 785987.5537, MAE: 3361.7646, R2: 0.2011\n",
      "==========================================================================================\n",
      "Epoch [4185/5000] | Time: 0.32s\n",
      "(Training) Loss: 991824.0159\n",
      "(Validation) Loss: 785906.6743, MAE: 3361.0569, R2: 0.2012\n",
      "==========================================================================================\n",
      "Epoch [4186/5000] | Time: 0.31s\n",
      "(Training) Loss: 985289.6827\n",
      "(Validation) Loss: 785824.9511, MAE: 3363.7385, R2: 0.2013\n",
      "==========================================================================================\n",
      "Epoch [4187/5000] | Time: 0.31s\n",
      "(Training) Loss: 976545.0857\n",
      "(Validation) Loss: 785740.9175, MAE: 3360.1487, R2: 0.2014\n",
      "==========================================================================================\n",
      "Epoch [4188/5000] | Time: 0.34s\n",
      "(Training) Loss: 972772.5742\n",
      "(Validation) Loss: 785665.2406, MAE: 3360.9143, R2: 0.2014\n",
      "==========================================================================================\n",
      "Epoch [4189/5000] | Time: 0.34s\n",
      "(Training) Loss: 977174.4683\n",
      "(Validation) Loss: 785583.0870, MAE: 3361.2346, R2: 0.2015\n",
      "==========================================================================================\n",
      "Epoch [4190/5000] | Time: 0.32s\n",
      "(Training) Loss: 974160.0051\n",
      "(Validation) Loss: 785510.2971, MAE: 3361.8379, R2: 0.2016\n",
      "==========================================================================================\n",
      "Epoch [4191/5000] | Time: 0.35s\n",
      "(Training) Loss: 979023.2912\n",
      "(Validation) Loss: 785417.3283, MAE: 3357.6882, R2: 0.2017\n",
      "==========================================================================================\n",
      "Epoch [4192/5000] | Time: 0.33s\n",
      "(Training) Loss: 980218.0876\n",
      "(Validation) Loss: 785337.2444, MAE: 3359.9534, R2: 0.2018\n",
      "==========================================================================================\n",
      "Epoch [4193/5000] | Time: 0.32s\n",
      "(Training) Loss: 969401.5654\n",
      "(Validation) Loss: 785272.2140, MAE: 3366.1165, R2: 0.2018\n",
      "==========================================================================================\n",
      "Epoch [4194/5000] | Time: 0.36s\n",
      "(Training) Loss: 976192.0181\n",
      "(Validation) Loss: 785178.5505, MAE: 3358.4648, R2: 0.2019\n",
      "==========================================================================================\n",
      "Epoch [4195/5000] | Time: 0.35s\n",
      "(Training) Loss: 974171.9156\n",
      "(Validation) Loss: 785097.9562, MAE: 3358.2654, R2: 0.2020\n",
      "==========================================================================================\n",
      "Epoch [4196/5000] | Time: 0.37s\n",
      "(Training) Loss: 962901.2814\n",
      "(Validation) Loss: 785017.5422, MAE: 3358.5374, R2: 0.2021\n",
      "==========================================================================================\n",
      "Epoch [4197/5000] | Time: 0.31s\n",
      "(Training) Loss: 980504.3813\n",
      "(Validation) Loss: 784941.4089, MAE: 3360.7666, R2: 0.2022\n",
      "==========================================================================================\n",
      "Epoch [4198/5000] | Time: 0.35s\n",
      "(Training) Loss: 972975.3439\n",
      "(Validation) Loss: 784859.6622, MAE: 3361.6912, R2: 0.2022\n",
      "==========================================================================================\n",
      "Epoch [4199/5000] | Time: 0.36s\n",
      "(Training) Loss: 973301.8128\n",
      "(Validation) Loss: 784771.9022, MAE: 3354.5388, R2: 0.2023\n",
      "==========================================================================================\n",
      "Epoch [4200/5000] | Time: 0.32s\n",
      "(Training) Loss: 1004689.3985\n",
      "(Validation) Loss: 784704.9200, MAE: 3356.8711, R2: 0.2024\n",
      "==========================================================================================\n",
      "Epoch [4201/5000] | Time: 0.35s\n",
      "(Training) Loss: 974195.6263\n",
      "(Validation) Loss: 784639.2737, MAE: 3367.1794, R2: 0.2025\n",
      "==========================================================================================\n",
      "Epoch [4202/5000] | Time: 0.34s\n",
      "(Training) Loss: 974131.6999\n",
      "(Validation) Loss: 781108.2787, MAE: 3332.1714, R2: 0.2060\n",
      "==========================================================================================\n",
      "Epoch [4203/5000] | Time: 0.36s\n",
      "(Training) Loss: 969233.4220\n",
      "(Validation) Loss: 781242.3587, MAE: 3341.6587, R2: 0.2059\n",
      "==========================================================================================\n",
      "Epoch [4204/5000] | Time: 0.36s\n",
      "(Training) Loss: 968650.1923\n",
      "(Validation) Loss: 781157.2489, MAE: 3341.4504, R2: 0.2060\n",
      "==========================================================================================\n",
      "Epoch [4205/5000] | Time: 0.34s\n",
      "(Training) Loss: 962583.4308\n",
      "(Validation) Loss: 781078.2273, MAE: 3342.5251, R2: 0.2061\n",
      "==========================================================================================\n",
      "Epoch [4206/5000] | Time: 0.36s\n",
      "(Training) Loss: 971412.4137\n",
      "(Validation) Loss: 780990.4679, MAE: 3341.3054, R2: 0.2061\n",
      "==========================================================================================\n",
      "Epoch [4207/5000] | Time: 0.38s\n",
      "(Training) Loss: 975242.5717\n",
      "(Validation) Loss: 780898.8711, MAE: 3338.6487, R2: 0.2062\n",
      "==========================================================================================\n",
      "Epoch [4208/5000] | Time: 0.34s\n",
      "(Training) Loss: 967855.0635\n",
      "(Validation) Loss: 780817.1683, MAE: 3339.3835, R2: 0.2063\n",
      "==========================================================================================\n",
      "Epoch [4209/5000] | Time: 0.37s\n",
      "(Training) Loss: 962255.4207\n",
      "(Validation) Loss: 780730.7067, MAE: 3339.4197, R2: 0.2064\n",
      "==========================================================================================\n",
      "Epoch [4210/5000] | Time: 0.34s\n",
      "(Training) Loss: 962409.8604\n",
      "(Validation) Loss: 780465.1244, MAE: 3335.1123, R2: 0.2067\n",
      "==========================================================================================\n",
      "Epoch [4211/5000] | Time: 0.35s\n",
      "(Training) Loss: 975250.3947\n",
      "(Validation) Loss: 780379.6895, MAE: 3334.9707, R2: 0.2068\n",
      "==========================================================================================\n",
      "Epoch [4212/5000] | Time: 0.36s\n",
      "(Training) Loss: 968444.5311\n",
      "(Validation) Loss: 780252.4997, MAE: 3323.7544, R2: 0.2069\n",
      "==========================================================================================\n",
      "Epoch [4213/5000] | Time: 0.37s\n",
      "(Training) Loss: 972388.0203\n",
      "(Validation) Loss: 780143.0927, MAE: 3318.9277, R2: 0.2070\n",
      "==========================================================================================\n",
      "Epoch [4214/5000] | Time: 0.37s\n",
      "(Training) Loss: 974689.9175\n",
      "(Validation) Loss: 780065.0438, MAE: 3319.6091, R2: 0.2071\n",
      "==========================================================================================\n",
      "Epoch [4215/5000] | Time: 0.37s\n",
      "(Training) Loss: 959170.8049\n",
      "(Validation) Loss: 779984.9016, MAE: 3320.1536, R2: 0.2072\n",
      "==========================================================================================\n",
      "Epoch [4216/5000] | Time: 0.38s\n",
      "(Training) Loss: 967932.4670\n",
      "(Validation) Loss: 779896.4051, MAE: 3316.5923, R2: 0.2073\n",
      "==========================================================================================\n",
      "Epoch [4217/5000] | Time: 0.34s\n",
      "(Training) Loss: 964495.1720\n",
      "(Validation) Loss: 779823.1549, MAE: 3318.5422, R2: 0.2073\n",
      "==========================================================================================\n",
      "Epoch [4218/5000] | Time: 0.33s\n",
      "(Training) Loss: 991092.7119\n",
      "(Validation) Loss: 779738.0997, MAE: 3319.0864, R2: 0.2074\n",
      "==========================================================================================\n",
      "Epoch [4219/5000] | Time: 0.37s\n",
      "(Training) Loss: 964082.4042\n",
      "(Validation) Loss: 779669.8686, MAE: 3320.1472, R2: 0.2075\n",
      "==========================================================================================\n",
      "Epoch [4220/5000] | Time: 0.35s\n",
      "(Training) Loss: 972252.9194\n",
      "(Validation) Loss: 779572.1105, MAE: 3316.1416, R2: 0.2076\n",
      "==========================================================================================\n",
      "Epoch [4221/5000] | Time: 0.36s\n",
      "(Training) Loss: 963117.9150\n",
      "(Validation) Loss: 779498.2457, MAE: 3317.4641, R2: 0.2077\n",
      "==========================================================================================\n",
      "Epoch [4222/5000] | Time: 0.38s\n",
      "(Training) Loss: 981608.3890\n",
      "(Validation) Loss: 779416.0406, MAE: 3318.7139, R2: 0.2077\n",
      "==========================================================================================\n",
      "Epoch [4223/5000] | Time: 0.40s\n",
      "(Training) Loss: 970631.0520\n",
      "(Validation) Loss: 779325.0006, MAE: 3314.6841, R2: 0.2078\n",
      "==========================================================================================\n",
      "Epoch [4224/5000] | Time: 0.37s\n",
      "(Training) Loss: 968387.8293\n",
      "(Validation) Loss: 779244.3829, MAE: 3314.2371, R2: 0.2079\n",
      "==========================================================================================\n",
      "Epoch [4225/5000] | Time: 0.40s\n",
      "(Training) Loss: 972644.5857\n",
      "(Validation) Loss: 779164.0438, MAE: 3314.3464, R2: 0.2080\n",
      "==========================================================================================\n",
      "Epoch [4226/5000] | Time: 0.34s\n",
      "(Training) Loss: 1007703.4340\n",
      "(Validation) Loss: 779093.6813, MAE: 3315.5762, R2: 0.2081\n",
      "==========================================================================================\n",
      "Epoch [4227/5000] | Time: 0.34s\n",
      "(Training) Loss: 982190.1282\n",
      "(Validation) Loss: 778998.8971, MAE: 3314.5276, R2: 0.2082\n",
      "==========================================================================================\n",
      "Epoch [4228/5000] | Time: 0.34s\n",
      "(Training) Loss: 960279.6472\n",
      "(Validation) Loss: 778941.9924, MAE: 3317.7009, R2: 0.2082\n",
      "==========================================================================================\n",
      "Epoch [4229/5000] | Time: 0.35s\n",
      "(Training) Loss: 974004.5349\n",
      "(Validation) Loss: 778837.5505, MAE: 3313.2209, R2: 0.2083\n",
      "==========================================================================================\n",
      "Epoch [4230/5000] | Time: 0.34s\n",
      "(Training) Loss: 972935.2107\n",
      "(Validation) Loss: 778792.2489, MAE: 3320.1270, R2: 0.2084\n",
      "==========================================================================================\n",
      "Epoch [4231/5000] | Time: 0.31s\n",
      "(Training) Loss: 971897.5178\n",
      "(Validation) Loss: 778678.9041, MAE: 3317.2546, R2: 0.2085\n",
      "==========================================================================================\n",
      "Epoch [4232/5000] | Time: 0.33s\n",
      "(Training) Loss: 963233.9480\n",
      "(Validation) Loss: 778595.9390, MAE: 3313.6970, R2: 0.2086\n",
      "==========================================================================================\n",
      "Epoch [4233/5000] | Time: 0.36s\n",
      "(Training) Loss: 976536.3309\n",
      "(Validation) Loss: 778513.2851, MAE: 3311.8760, R2: 0.2086\n",
      "==========================================================================================\n",
      "Epoch [4234/5000] | Time: 0.34s\n",
      "(Training) Loss: 963246.0152\n",
      "(Validation) Loss: 778440.1587, MAE: 3313.0901, R2: 0.2087\n",
      "==========================================================================================\n",
      "Epoch [4235/5000] | Time: 0.39s\n",
      "(Training) Loss: 959388.8547\n",
      "(Validation) Loss: 778362.8127, MAE: 3315.1851, R2: 0.2088\n",
      "==========================================================================================\n",
      "Epoch [4236/5000] | Time: 0.37s\n",
      "(Training) Loss: 976457.8484\n",
      "(Validation) Loss: 778271.9524, MAE: 3310.3213, R2: 0.2089\n",
      "==========================================================================================\n",
      "Epoch [4237/5000] | Time: 0.35s\n",
      "(Training) Loss: 972130.4346\n",
      "(Validation) Loss: 778210.9511, MAE: 3317.0085, R2: 0.2090\n",
      "==========================================================================================\n",
      "Epoch [4238/5000] | Time: 0.36s\n",
      "(Training) Loss: 966610.8166\n",
      "(Validation) Loss: 778123.5581, MAE: 3312.3318, R2: 0.2090\n",
      "==========================================================================================\n",
      "Epoch [4239/5000] | Time: 0.36s\n",
      "(Training) Loss: 982121.3547\n",
      "(Validation) Loss: 778041.8292, MAE: 3313.5845, R2: 0.2091\n",
      "==========================================================================================\n",
      "Epoch [4240/5000] | Time: 0.38s\n",
      "(Training) Loss: 963464.3401\n",
      "(Validation) Loss: 777962.5270, MAE: 3313.3889, R2: 0.2092\n",
      "==========================================================================================\n",
      "Epoch [4241/5000] | Time: 0.38s\n",
      "(Training) Loss: 978010.7449\n",
      "(Validation) Loss: 777870.1835, MAE: 3312.8323, R2: 0.2093\n",
      "==========================================================================================\n",
      "Epoch [4242/5000] | Time: 0.35s\n",
      "(Training) Loss: 970133.2049\n",
      "(Validation) Loss: 777805.3905, MAE: 3312.5540, R2: 0.2094\n",
      "==========================================================================================\n",
      "Epoch [4243/5000] | Time: 0.35s\n",
      "(Training) Loss: 974208.6631\n",
      "(Validation) Loss: 777710.2235, MAE: 3310.2629, R2: 0.2095\n",
      "==========================================================================================\n",
      "Epoch [4244/5000] | Time: 0.35s\n",
      "(Training) Loss: 975028.6440\n",
      "(Validation) Loss: 777639.6895, MAE: 3312.3201, R2: 0.2095\n",
      "==========================================================================================\n",
      "Epoch [4245/5000] | Time: 0.38s\n",
      "(Training) Loss: 974840.5387\n",
      "(Validation) Loss: 777551.7873, MAE: 3309.6797, R2: 0.2096\n",
      "==========================================================================================\n",
      "Epoch [4246/5000] | Time: 0.36s\n",
      "(Training) Loss: 976962.2354\n",
      "(Validation) Loss: 777479.5175, MAE: 3314.8584, R2: 0.2097\n",
      "==========================================================================================\n",
      "Epoch [4247/5000] | Time: 0.38s\n",
      "(Training) Loss: 960327.9765\n",
      "(Validation) Loss: 777398.6013, MAE: 3310.9919, R2: 0.2098\n",
      "==========================================================================================\n",
      "Epoch [4248/5000] | Time: 0.37s\n",
      "(Training) Loss: 990496.3312\n",
      "(Validation) Loss: 777313.7898, MAE: 3309.6123, R2: 0.2099\n",
      "==========================================================================================\n",
      "Epoch [4249/5000] | Time: 0.37s\n",
      "(Training) Loss: 982428.8008\n",
      "(Validation) Loss: 777232.1181, MAE: 3311.4895, R2: 0.2099\n",
      "==========================================================================================\n",
      "Epoch [4250/5000] | Time: 0.36s\n",
      "(Training) Loss: 973016.0343\n",
      "(Validation) Loss: 777151.7225, MAE: 3310.2783, R2: 0.2100\n",
      "==========================================================================================\n",
      "Epoch [4251/5000] | Time: 0.38s\n",
      "(Training) Loss: 954905.1824\n",
      "(Validation) Loss: 777071.9327, MAE: 3308.7742, R2: 0.2101\n",
      "==========================================================================================\n",
      "Epoch [4252/5000] | Time: 0.37s\n",
      "(Training) Loss: 975966.3877\n",
      "(Validation) Loss: 776987.6717, MAE: 3308.2349, R2: 0.2102\n",
      "==========================================================================================\n",
      "Epoch [4253/5000] | Time: 0.33s\n",
      "(Training) Loss: 967768.6294\n",
      "(Validation) Loss: 776921.4292, MAE: 3310.6826, R2: 0.2102\n",
      "==========================================================================================\n",
      "Epoch [4254/5000] | Time: 0.33s\n",
      "(Training) Loss: 959328.3122\n",
      "(Validation) Loss: 776831.7543, MAE: 3307.3560, R2: 0.2103\n",
      "==========================================================================================\n",
      "Epoch [4255/5000] | Time: 0.34s\n",
      "(Training) Loss: 969274.9181\n",
      "(Validation) Loss: 776762.5873, MAE: 3326.6392, R2: 0.2104\n",
      "==========================================================================================\n",
      "Epoch [4256/5000] | Time: 0.36s\n",
      "(Training) Loss: 958417.1967\n",
      "(Validation) Loss: 776667.8254, MAE: 3309.0708, R2: 0.2105\n",
      "==========================================================================================\n",
      "Epoch [4257/5000] | Time: 0.33s\n",
      "(Training) Loss: 986521.3147\n",
      "(Validation) Loss: 776585.3968, MAE: 3306.7146, R2: 0.2106\n",
      "==========================================================================================\n",
      "Epoch [4258/5000] | Time: 0.33s\n",
      "(Training) Loss: 983528.3027\n",
      "(Validation) Loss: 776499.9003, MAE: 3306.0129, R2: 0.2107\n",
      "==========================================================================================\n",
      "Epoch [4259/5000] | Time: 0.33s\n",
      "(Training) Loss: 961632.9067\n",
      "(Validation) Loss: 776444.1352, MAE: 3308.2153, R2: 0.2107\n",
      "==========================================================================================\n",
      "Epoch [4260/5000] | Time: 0.34s\n",
      "(Training) Loss: 960366.1034\n",
      "(Validation) Loss: 776342.1194, MAE: 3303.9937, R2: 0.2108\n",
      "==========================================================================================\n",
      "Epoch [4261/5000] | Time: 0.35s\n",
      "(Training) Loss: 954040.2725\n",
      "(Validation) Loss: 776266.6311, MAE: 3304.8523, R2: 0.2109\n",
      "==========================================================================================\n",
      "Epoch [4262/5000] | Time: 0.34s\n",
      "(Training) Loss: 959639.4378\n",
      "(Validation) Loss: 776234.6527, MAE: 3312.6848, R2: 0.2109\n",
      "==========================================================================================\n",
      "Epoch [4263/5000] | Time: 0.37s\n",
      "(Training) Loss: 965530.7760\n",
      "(Validation) Loss: 776170.9968, MAE: 3313.6245, R2: 0.2110\n",
      "==========================================================================================\n",
      "Epoch [4264/5000] | Time: 0.37s\n",
      "(Training) Loss: 972990.6015\n",
      "(Validation) Loss: 776088.5524, MAE: 3311.9062, R2: 0.2111\n",
      "==========================================================================================\n",
      "Epoch [4265/5000] | Time: 0.34s\n",
      "(Training) Loss: 965246.7468\n",
      "(Validation) Loss: 775935.7137, MAE: 3302.3054, R2: 0.2112\n",
      "==========================================================================================\n",
      "Epoch [4266/5000] | Time: 0.36s\n",
      "(Training) Loss: 963943.0000\n",
      "(Validation) Loss: 775854.4000, MAE: 3300.5239, R2: 0.2113\n",
      "==========================================================================================\n",
      "Epoch [4267/5000] | Time: 0.36s\n",
      "(Training) Loss: 970467.6009\n",
      "(Validation) Loss: 775775.3994, MAE: 3300.2329, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [4268/5000] | Time: 0.40s\n",
      "(Training) Loss: 975523.5635\n",
      "(Validation) Loss: 775721.3181, MAE: 3303.8447, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [4269/5000] | Time: 0.40s\n",
      "(Training) Loss: 959179.7684\n",
      "(Validation) Loss: 775619.5333, MAE: 3299.7720, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [4270/5000] | Time: 0.42s\n",
      "(Training) Loss: 961798.8319\n",
      "(Validation) Loss: 775538.4438, MAE: 3301.8672, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [4271/5000] | Time: 0.35s\n",
      "(Training) Loss: 973873.4632\n",
      "(Validation) Loss: 775461.9416, MAE: 3300.0310, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [4272/5000] | Time: 0.35s\n",
      "(Training) Loss: 973014.8687\n",
      "(Validation) Loss: 775384.5162, MAE: 3300.2185, R2: 0.2118\n",
      "==========================================================================================\n",
      "Epoch [4273/5000] | Time: 0.39s\n",
      "(Training) Loss: 965911.7297\n",
      "(Validation) Loss: 775298.6216, MAE: 3299.0886, R2: 0.2119\n",
      "==========================================================================================\n",
      "Epoch [4274/5000] | Time: 0.32s\n",
      "(Training) Loss: 958783.3290\n",
      "(Validation) Loss: 775221.9352, MAE: 3301.5730, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [4275/5000] | Time: 0.33s\n",
      "(Training) Loss: 966438.1301\n",
      "(Validation) Loss: 775179.6813, MAE: 3305.4216, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [4276/5000] | Time: 0.31s\n",
      "(Training) Loss: 959089.8928\n",
      "(Validation) Loss: 775065.5860, MAE: 3301.2886, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [4277/5000] | Time: 0.35s\n",
      "(Training) Loss: 967076.5349\n",
      "(Validation) Loss: 774980.3257, MAE: 3300.4817, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [4278/5000] | Time: 0.38s\n",
      "(Training) Loss: 966403.1034\n",
      "(Validation) Loss: 774901.7810, MAE: 3306.5369, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [4279/5000] | Time: 0.36s\n",
      "(Training) Loss: 959829.7627\n",
      "(Validation) Loss: 774837.3441, MAE: 3300.7908, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [4280/5000] | Time: 0.36s\n",
      "(Training) Loss: 968575.2544\n",
      "(Validation) Loss: 774740.7225, MAE: 3297.4026, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [4281/5000] | Time: 0.32s\n",
      "(Training) Loss: 984195.5159\n",
      "(Validation) Loss: 774662.8959, MAE: 3299.7527, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [4282/5000] | Time: 0.32s\n",
      "(Training) Loss: 974243.0755\n",
      "(Validation) Loss: 774576.0857, MAE: 3297.2908, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [4283/5000] | Time: 0.32s\n",
      "(Training) Loss: 961306.8820\n",
      "(Validation) Loss: 774496.2603, MAE: 3296.2283, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [4284/5000] | Time: 0.35s\n",
      "(Training) Loss: 957892.3008\n",
      "(Validation) Loss: 774435.2616, MAE: 3301.9490, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [4285/5000] | Time: 0.36s\n",
      "(Training) Loss: 957361.0127\n",
      "(Validation) Loss: 774350.1492, MAE: 3298.3743, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [4286/5000] | Time: 0.39s\n",
      "(Training) Loss: 964292.5539\n",
      "(Validation) Loss: 774275.6432, MAE: 3302.2104, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [4287/5000] | Time: 0.37s\n",
      "(Training) Loss: 963174.3147\n",
      "(Validation) Loss: 774174.4629, MAE: 3296.8213, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [4288/5000] | Time: 0.40s\n",
      "(Training) Loss: 953346.6424\n",
      "(Validation) Loss: 774102.7181, MAE: 3295.7134, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [4289/5000] | Time: 0.41s\n",
      "(Training) Loss: 977300.1225\n",
      "(Validation) Loss: 774040.6921, MAE: 3298.6279, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [4290/5000] | Time: 0.34s\n",
      "(Training) Loss: 968044.5425\n",
      "(Validation) Loss: 773964.4063, MAE: 3302.3867, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [4291/5000] | Time: 0.39s\n",
      "(Training) Loss: 974571.6834\n",
      "(Validation) Loss: 773856.7010, MAE: 3293.7942, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [4292/5000] | Time: 0.38s\n",
      "(Training) Loss: 960826.3997\n",
      "(Validation) Loss: 773778.4876, MAE: 3297.7290, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [4293/5000] | Time: 0.38s\n",
      "(Training) Loss: 955471.2487\n",
      "(Validation) Loss: 773695.6756, MAE: 3293.4126, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [4294/5000] | Time: 0.37s\n",
      "(Training) Loss: 951290.1902\n",
      "(Validation) Loss: 773624.3549, MAE: 3294.8274, R2: 0.2136\n",
      "==========================================================================================\n",
      "Epoch [4295/5000] | Time: 0.36s\n",
      "(Training) Loss: 964543.7107\n",
      "(Validation) Loss: 773539.0133, MAE: 3292.9055, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [4296/5000] | Time: 0.36s\n",
      "(Training) Loss: 952022.0178\n",
      "(Validation) Loss: 773473.5219, MAE: 3296.6550, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [4297/5000] | Time: 0.35s\n",
      "(Training) Loss: 959953.1967\n",
      "(Validation) Loss: 773398.9270, MAE: 3307.1018, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [4298/5000] | Time: 0.33s\n",
      "(Training) Loss: 958918.2652\n",
      "(Validation) Loss: 773320.0781, MAE: 3311.2693, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [4299/5000] | Time: 0.36s\n",
      "(Training) Loss: 957757.6802\n",
      "(Validation) Loss: 773223.4800, MAE: 3293.6018, R2: 0.2140\n",
      "==========================================================================================\n",
      "Epoch [4300/5000] | Time: 0.33s\n",
      "(Training) Loss: 954832.8528\n",
      "(Validation) Loss: 773142.7689, MAE: 3293.1609, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [4301/5000] | Time: 0.37s\n",
      "(Training) Loss: 949961.8915\n",
      "(Validation) Loss: 773063.5784, MAE: 3292.9807, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [4302/5000] | Time: 0.36s\n",
      "(Training) Loss: 979780.9518\n",
      "(Validation) Loss: 772997.1619, MAE: 3295.9104, R2: 0.2142\n",
      "==========================================================================================\n",
      "Epoch [4303/5000] | Time: 0.36s\n",
      "(Training) Loss: 967063.2690\n",
      "(Validation) Loss: 772922.7308, MAE: 3296.3892, R2: 0.2143\n",
      "==========================================================================================\n",
      "Epoch [4304/5000] | Time: 0.40s\n",
      "(Training) Loss: 969672.0159\n",
      "(Validation) Loss: 772838.0032, MAE: 3294.5732, R2: 0.2144\n",
      "==========================================================================================\n",
      "Epoch [4305/5000] | Time: 0.39s\n",
      "(Training) Loss: 979219.6688\n",
      "(Validation) Loss: 772742.3943, MAE: 3291.2551, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [4306/5000] | Time: 0.33s\n",
      "(Training) Loss: 988288.1091\n",
      "(Validation) Loss: 772677.1003, MAE: 3295.6980, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [4307/5000] | Time: 0.35s\n",
      "(Training) Loss: 952784.2811\n",
      "(Validation) Loss: 772587.7289, MAE: 3293.9639, R2: 0.2146\n",
      "==========================================================================================\n",
      "Epoch [4308/5000] | Time: 0.34s\n",
      "(Training) Loss: 960703.6675\n",
      "(Validation) Loss: 772501.8514, MAE: 3289.6860, R2: 0.2147\n",
      "==========================================================================================\n",
      "Epoch [4309/5000] | Time: 0.40s\n",
      "(Training) Loss: 968281.2798\n",
      "(Validation) Loss: 772429.7778, MAE: 3290.5391, R2: 0.2148\n",
      "==========================================================================================\n",
      "Epoch [4310/5000] | Time: 0.33s\n",
      "(Training) Loss: 961861.3972\n",
      "(Validation) Loss: 772346.1956, MAE: 3289.6765, R2: 0.2149\n",
      "==========================================================================================\n",
      "Epoch [4311/5000] | Time: 0.38s\n",
      "(Training) Loss: 964947.1117\n",
      "(Validation) Loss: 772272.0063, MAE: 3291.2339, R2: 0.2149\n",
      "==========================================================================================\n",
      "Epoch [4312/5000] | Time: 0.39s\n",
      "(Training) Loss: 961021.7024\n",
      "(Validation) Loss: 772190.4222, MAE: 3292.0188, R2: 0.2150\n",
      "==========================================================================================\n",
      "Epoch [4313/5000] | Time: 0.39s\n",
      "(Training) Loss: 974808.4943\n",
      "(Validation) Loss: 772106.0260, MAE: 3288.4856, R2: 0.2151\n",
      "==========================================================================================\n",
      "Epoch [4314/5000] | Time: 0.41s\n",
      "(Training) Loss: 964858.2246\n",
      "(Validation) Loss: 772030.0952, MAE: 3290.5786, R2: 0.2152\n",
      "==========================================================================================\n",
      "Epoch [4315/5000] | Time: 0.34s\n",
      "(Training) Loss: 949878.0966\n",
      "(Validation) Loss: 771955.1657, MAE: 3293.4690, R2: 0.2152\n",
      "==========================================================================================\n",
      "Epoch [4316/5000] | Time: 0.35s\n",
      "(Training) Loss: 967697.8065\n",
      "(Validation) Loss: 771880.4667, MAE: 3293.1885, R2: 0.2153\n",
      "==========================================================================================\n",
      "Epoch [4317/5000] | Time: 0.40s\n",
      "(Training) Loss: 960433.9010\n",
      "(Validation) Loss: 771799.8483, MAE: 3290.9958, R2: 0.2154\n",
      "==========================================================================================\n",
      "Epoch [4318/5000] | Time: 0.33s\n",
      "(Training) Loss: 966449.4397\n",
      "(Validation) Loss: 771719.0419, MAE: 3289.7583, R2: 0.2155\n",
      "==========================================================================================\n",
      "Epoch [4319/5000] | Time: 0.35s\n",
      "(Training) Loss: 949062.9857\n",
      "(Validation) Loss: 771642.4603, MAE: 3290.8879, R2: 0.2156\n",
      "==========================================================================================\n",
      "Epoch [4320/5000] | Time: 0.33s\n",
      "(Training) Loss: 961776.9594\n",
      "(Validation) Loss: 771554.9549, MAE: 3287.7734, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [4321/5000] | Time: 0.33s\n",
      "(Training) Loss: 949939.6850\n",
      "(Validation) Loss: 771471.8463, MAE: 3289.0549, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [4322/5000] | Time: 0.37s\n",
      "(Training) Loss: 964338.3344\n",
      "(Validation) Loss: 771408.0794, MAE: 3291.2239, R2: 0.2158\n",
      "==========================================================================================\n",
      "Epoch [4323/5000] | Time: 0.34s\n",
      "(Training) Loss: 957748.4962\n",
      "(Validation) Loss: 771318.5283, MAE: 3288.1716, R2: 0.2159\n",
      "==========================================================================================\n",
      "Epoch [4324/5000] | Time: 0.38s\n",
      "(Training) Loss: 954035.1853\n",
      "(Validation) Loss: 771233.6070, MAE: 3287.9041, R2: 0.2160\n",
      "==========================================================================================\n",
      "Epoch [4325/5000] | Time: 0.39s\n",
      "(Training) Loss: 949863.5492\n",
      "(Validation) Loss: 771155.1124, MAE: 3286.8254, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [4326/5000] | Time: 0.39s\n",
      "(Training) Loss: 973379.8439\n",
      "(Validation) Loss: 771092.1194, MAE: 3288.5986, R2: 0.2161\n",
      "==========================================================================================\n",
      "Epoch [4327/5000] | Time: 0.35s\n",
      "(Training) Loss: 956513.2735\n",
      "(Validation) Loss: 771001.3594, MAE: 3287.7952, R2: 0.2162\n",
      "==========================================================================================\n",
      "Epoch [4328/5000] | Time: 0.35s\n",
      "(Training) Loss: 970708.5266\n",
      "(Validation) Loss: 770915.2216, MAE: 3285.5896, R2: 0.2163\n",
      "==========================================================================================\n",
      "Epoch [4329/5000] | Time: 0.36s\n",
      "(Training) Loss: 956638.7240\n",
      "(Validation) Loss: 770845.3587, MAE: 3290.0542, R2: 0.2164\n",
      "==========================================================================================\n",
      "Epoch [4330/5000] | Time: 0.33s\n",
      "(Training) Loss: 950950.4181\n",
      "(Validation) Loss: 770762.7968, MAE: 3285.6631, R2: 0.2165\n",
      "==========================================================================================\n",
      "Epoch [4331/5000] | Time: 0.36s\n",
      "(Training) Loss: 955503.9346\n",
      "(Validation) Loss: 770686.1124, MAE: 3285.8159, R2: 0.2165\n",
      "==========================================================================================\n",
      "Epoch [4332/5000] | Time: 0.34s\n",
      "(Training) Loss: 950760.4283\n",
      "(Validation) Loss: 770604.5759, MAE: 3286.8962, R2: 0.2166\n",
      "==========================================================================================\n",
      "Epoch [4333/5000] | Time: 0.35s\n",
      "(Training) Loss: 956624.9264\n",
      "(Validation) Loss: 770527.0844, MAE: 3285.1670, R2: 0.2167\n",
      "==========================================================================================\n",
      "Epoch [4334/5000] | Time: 0.34s\n",
      "(Training) Loss: 968638.3813\n",
      "(Validation) Loss: 770441.8495, MAE: 3286.4775, R2: 0.2168\n",
      "==========================================================================================\n",
      "Epoch [4335/5000] | Time: 0.33s\n",
      "(Training) Loss: 957323.4600\n",
      "(Validation) Loss: 770360.7263, MAE: 3284.3848, R2: 0.2169\n",
      "==========================================================================================\n",
      "Epoch [4336/5000] | Time: 0.34s\n",
      "(Training) Loss: 948025.2129\n",
      "(Validation) Loss: 770292.3727, MAE: 3285.0940, R2: 0.2169\n",
      "==========================================================================================\n",
      "Epoch [4337/5000] | Time: 0.39s\n",
      "(Training) Loss: 946596.2122\n",
      "(Validation) Loss: 770210.8590, MAE: 3286.9580, R2: 0.2170\n",
      "==========================================================================================\n",
      "Epoch [4338/5000] | Time: 0.36s\n",
      "(Training) Loss: 946135.1186\n",
      "(Validation) Loss: 770128.9181, MAE: 3284.0977, R2: 0.2171\n",
      "==========================================================================================\n",
      "Epoch [4339/5000] | Time: 0.34s\n",
      "(Training) Loss: 946486.2568\n",
      "(Validation) Loss: 770042.1587, MAE: 3282.0149, R2: 0.2172\n",
      "==========================================================================================\n",
      "Epoch [4340/5000] | Time: 0.36s\n",
      "(Training) Loss: 966916.5063\n",
      "(Validation) Loss: 769973.8597, MAE: 3284.2822, R2: 0.2172\n",
      "==========================================================================================\n",
      "Epoch [4341/5000] | Time: 0.39s\n",
      "(Training) Loss: 965222.5844\n",
      "(Validation) Loss: 769890.9232, MAE: 3282.3474, R2: 0.2173\n",
      "==========================================================================================\n",
      "Epoch [4342/5000] | Time: 0.37s\n",
      "(Training) Loss: 952454.4607\n",
      "(Validation) Loss: 769810.6800, MAE: 3283.2253, R2: 0.2174\n",
      "==========================================================================================\n",
      "Epoch [4343/5000] | Time: 0.34s\n",
      "(Training) Loss: 970762.1472\n",
      "(Validation) Loss: 769767.4908, MAE: 3287.4038, R2: 0.2175\n",
      "==========================================================================================\n",
      "Epoch [4344/5000] | Time: 0.36s\n",
      "(Training) Loss: 965379.0704\n",
      "(Validation) Loss: 769662.2419, MAE: 3283.3149, R2: 0.2176\n",
      "==========================================================================================\n",
      "Epoch [4345/5000] | Time: 0.39s\n",
      "(Training) Loss: 972260.6332\n",
      "(Validation) Loss: 769573.0857, MAE: 3282.9331, R2: 0.2176\n",
      "==========================================================================================\n",
      "Epoch [4346/5000] | Time: 0.35s\n",
      "(Training) Loss: 950508.5844\n",
      "(Validation) Loss: 769530.2902, MAE: 3286.5229, R2: 0.2177\n",
      "==========================================================================================\n",
      "Epoch [4347/5000] | Time: 0.33s\n",
      "(Training) Loss: 955966.1637\n",
      "(Validation) Loss: 769425.3054, MAE: 3282.5347, R2: 0.2178\n",
      "==========================================================================================\n",
      "Epoch [4348/5000] | Time: 0.35s\n",
      "(Training) Loss: 956664.6650\n",
      "(Validation) Loss: 769335.9422, MAE: 3280.9695, R2: 0.2179\n",
      "==========================================================================================\n",
      "Epoch [4349/5000] | Time: 0.33s\n",
      "(Training) Loss: 954105.7944\n",
      "(Validation) Loss: 769264.6324, MAE: 3281.5493, R2: 0.2180\n",
      "==========================================================================================\n",
      "Epoch [4350/5000] | Time: 0.36s\n",
      "(Training) Loss: 959716.2138\n",
      "(Validation) Loss: 769183.9498, MAE: 3281.7925, R2: 0.2180\n",
      "==========================================================================================\n",
      "Epoch [4351/5000] | Time: 0.35s\n",
      "(Training) Loss: 952632.2976\n",
      "(Validation) Loss: 769110.7848, MAE: 3282.6743, R2: 0.2181\n",
      "==========================================================================================\n",
      "Epoch [4352/5000] | Time: 0.36s\n",
      "(Training) Loss: 946376.5728\n",
      "(Validation) Loss: 769019.7905, MAE: 3279.9019, R2: 0.2182\n",
      "==========================================================================================\n",
      "Epoch [4353/5000] | Time: 0.38s\n",
      "(Training) Loss: 962370.4543\n",
      "(Validation) Loss: 768947.2311, MAE: 3281.3276, R2: 0.2183\n",
      "==========================================================================================\n",
      "Epoch [4354/5000] | Time: 0.35s\n",
      "(Training) Loss: 963125.4461\n",
      "(Validation) Loss: 768859.8800, MAE: 3279.3479, R2: 0.2184\n",
      "==========================================================================================\n",
      "Epoch [4355/5000] | Time: 0.35s\n",
      "(Training) Loss: 974040.9638\n",
      "(Validation) Loss: 768776.9841, MAE: 3278.0466, R2: 0.2185\n",
      "==========================================================================================\n",
      "Epoch [4356/5000] | Time: 0.36s\n",
      "(Training) Loss: 978351.9879\n",
      "(Validation) Loss: 768708.4413, MAE: 3284.6177, R2: 0.2185\n",
      "==========================================================================================\n",
      "Epoch [4357/5000] | Time: 0.37s\n",
      "(Training) Loss: 950978.7912\n",
      "(Validation) Loss: 768626.7816, MAE: 3279.5156, R2: 0.2186\n",
      "==========================================================================================\n",
      "Epoch [4358/5000] | Time: 0.37s\n",
      "(Training) Loss: 965304.7805\n",
      "(Validation) Loss: 768547.9886, MAE: 3281.0044, R2: 0.2187\n",
      "==========================================================================================\n",
      "Epoch [4359/5000] | Time: 0.39s\n",
      "(Training) Loss: 957547.2500\n",
      "(Validation) Loss: 768467.9397, MAE: 3279.9280, R2: 0.2188\n",
      "==========================================================================================\n",
      "Epoch [4360/5000] | Time: 0.36s\n",
      "(Training) Loss: 973190.1161\n",
      "(Validation) Loss: 768385.8286, MAE: 3278.6870, R2: 0.2188\n",
      "==========================================================================================\n",
      "Epoch [4361/5000] | Time: 0.36s\n",
      "(Training) Loss: 970475.9404\n",
      "(Validation) Loss: 768335.4857, MAE: 3286.2485, R2: 0.2189\n",
      "==========================================================================================\n",
      "Epoch [4362/5000] | Time: 0.41s\n",
      "(Training) Loss: 954153.9835\n",
      "(Validation) Loss: 768235.0400, MAE: 3286.1882, R2: 0.2190\n",
      "==========================================================================================\n",
      "Epoch [4363/5000] | Time: 0.35s\n",
      "(Training) Loss: 955997.9867\n",
      "(Validation) Loss: 768161.0222, MAE: 3282.8423, R2: 0.2191\n",
      "==========================================================================================\n",
      "Epoch [4364/5000] | Time: 0.35s\n",
      "(Training) Loss: 955768.5292\n",
      "(Validation) Loss: 768084.4724, MAE: 3284.8792, R2: 0.2191\n",
      "==========================================================================================\n",
      "Epoch [4365/5000] | Time: 0.36s\n",
      "(Training) Loss: 961672.8458\n",
      "(Validation) Loss: 768000.2038, MAE: 3281.0454, R2: 0.2192\n",
      "==========================================================================================\n",
      "Epoch [4366/5000] | Time: 0.36s\n",
      "(Training) Loss: 948815.7855\n",
      "(Validation) Loss: 767911.5219, MAE: 3277.3442, R2: 0.2193\n",
      "==========================================================================================\n",
      "Epoch [4367/5000] | Time: 0.36s\n",
      "(Training) Loss: 964642.4277\n",
      "(Validation) Loss: 767836.3175, MAE: 3277.4785, R2: 0.2194\n",
      "==========================================================================================\n",
      "Epoch [4368/5000] | Time: 0.35s\n",
      "(Training) Loss: 953125.9569\n",
      "(Validation) Loss: 767757.7505, MAE: 3283.7715, R2: 0.2195\n",
      "==========================================================================================\n",
      "Epoch [4369/5000] | Time: 0.35s\n",
      "(Training) Loss: 950100.0857\n",
      "(Validation) Loss: 767677.7365, MAE: 3280.0559, R2: 0.2196\n",
      "==========================================================================================\n",
      "Epoch [4370/5000] | Time: 0.35s\n",
      "(Training) Loss: 953000.6574\n",
      "(Validation) Loss: 767604.7886, MAE: 3280.0571, R2: 0.2196\n",
      "==========================================================================================\n",
      "Epoch [4371/5000] | Time: 0.35s\n",
      "(Training) Loss: 946657.8372\n",
      "(Validation) Loss: 767528.3771, MAE: 3280.3582, R2: 0.2197\n",
      "==========================================================================================\n",
      "Epoch [4372/5000] | Time: 0.36s\n",
      "(Training) Loss: 943069.5872\n",
      "(Validation) Loss: 767447.4330, MAE: 3277.0095, R2: 0.2198\n",
      "==========================================================================================\n",
      "Epoch [4373/5000] | Time: 0.36s\n",
      "(Training) Loss: 947818.6973\n",
      "(Validation) Loss: 767364.3765, MAE: 3277.0933, R2: 0.2199\n",
      "==========================================================================================\n",
      "Epoch [4374/5000] | Time: 0.35s\n",
      "(Training) Loss: 956081.1770\n",
      "(Validation) Loss: 767300.2317, MAE: 3283.1819, R2: 0.2199\n",
      "==========================================================================================\n",
      "Epoch [4375/5000] | Time: 0.36s\n",
      "(Training) Loss: 951607.1827\n",
      "(Validation) Loss: 767210.3460, MAE: 3277.9314, R2: 0.2200\n",
      "==========================================================================================\n",
      "Epoch [4376/5000] | Time: 0.34s\n",
      "(Training) Loss: 960707.4651\n",
      "(Validation) Loss: 767146.1016, MAE: 3290.1106, R2: 0.2201\n",
      "==========================================================================================\n",
      "Epoch [4377/5000] | Time: 0.33s\n",
      "(Training) Loss: 961463.0324\n",
      "(Validation) Loss: 767045.1327, MAE: 3278.2292, R2: 0.2202\n",
      "==========================================================================================\n",
      "Epoch [4378/5000] | Time: 0.38s\n",
      "(Training) Loss: 948422.9201\n",
      "(Validation) Loss: 766986.9892, MAE: 3278.2275, R2: 0.2203\n",
      "==========================================================================================\n",
      "Epoch [4379/5000] | Time: 0.37s\n",
      "(Training) Loss: 957177.1117\n",
      "(Validation) Loss: 766894.5702, MAE: 3275.5825, R2: 0.2203\n",
      "==========================================================================================\n",
      "Epoch [4380/5000] | Time: 0.37s\n",
      "(Training) Loss: 956588.1872\n",
      "(Validation) Loss: 766813.1460, MAE: 3274.8477, R2: 0.2204\n",
      "==========================================================================================\n",
      "Epoch [4381/5000] | Time: 0.38s\n",
      "(Training) Loss: 967933.8350\n",
      "(Validation) Loss: 766747.2794, MAE: 3281.1458, R2: 0.2205\n",
      "==========================================================================================\n",
      "Epoch [4382/5000] | Time: 0.38s\n",
      "(Training) Loss: 955642.1859\n",
      "(Validation) Loss: 766662.1537, MAE: 3277.4363, R2: 0.2206\n",
      "==========================================================================================\n",
      "Epoch [4383/5000] | Time: 0.39s\n",
      "(Training) Loss: 955097.0117\n",
      "(Validation) Loss: 766577.7746, MAE: 3274.7354, R2: 0.2207\n",
      "==========================================================================================\n",
      "Epoch [4384/5000] | Time: 0.38s\n",
      "(Training) Loss: 954175.2316\n",
      "(Validation) Loss: 766499.0171, MAE: 3279.8792, R2: 0.2207\n",
      "==========================================================================================\n",
      "Epoch [4385/5000] | Time: 0.36s\n",
      "(Training) Loss: 958116.9803\n",
      "(Validation) Loss: 766415.1702, MAE: 3274.6208, R2: 0.2208\n",
      "==========================================================================================\n",
      "Epoch [4386/5000] | Time: 0.37s\n",
      "(Training) Loss: 944767.3928\n",
      "(Validation) Loss: 766332.7860, MAE: 3272.2632, R2: 0.2209\n",
      "==========================================================================================\n",
      "Epoch [4387/5000] | Time: 0.35s\n",
      "(Training) Loss: 959633.0051\n",
      "(Validation) Loss: 766257.0032, MAE: 3276.8096, R2: 0.2210\n",
      "==========================================================================================\n",
      "Epoch [4388/5000] | Time: 0.36s\n",
      "(Training) Loss: 941726.8912\n",
      "(Validation) Loss: 766181.9848, MAE: 3275.1868, R2: 0.2211\n",
      "==========================================================================================\n",
      "Epoch [4389/5000] | Time: 0.37s\n",
      "(Training) Loss: 950797.4594\n",
      "(Validation) Loss: 766111.1441, MAE: 3276.5063, R2: 0.2211\n",
      "==========================================================================================\n",
      "Epoch [4390/5000] | Time: 0.38s\n",
      "(Training) Loss: 972715.5006\n",
      "(Validation) Loss: 766034.5549, MAE: 3275.3857, R2: 0.2212\n",
      "==========================================================================================\n",
      "Epoch [4391/5000] | Time: 0.36s\n",
      "(Training) Loss: 948058.7021\n",
      "(Validation) Loss: 765951.3156, MAE: 3273.8625, R2: 0.2213\n",
      "==========================================================================================\n",
      "Epoch [4392/5000] | Time: 0.37s\n",
      "(Training) Loss: 960586.2944\n",
      "(Validation) Loss: 765885.9835, MAE: 3276.5806, R2: 0.2214\n",
      "==========================================================================================\n",
      "Epoch [4393/5000] | Time: 0.37s\n",
      "(Training) Loss: 945654.7652\n",
      "(Validation) Loss: 765817.9467, MAE: 3273.5610, R2: 0.2214\n",
      "==========================================================================================\n",
      "Epoch [4394/5000] | Time: 0.40s\n",
      "(Training) Loss: 982474.8756\n",
      "(Validation) Loss: 765721.4102, MAE: 3274.5442, R2: 0.2215\n",
      "==========================================================================================\n",
      "Epoch [4395/5000] | Time: 0.39s\n",
      "(Training) Loss: 957179.5723\n",
      "(Validation) Loss: 765637.0552, MAE: 3273.9849, R2: 0.2216\n",
      "==========================================================================================\n",
      "Epoch [4396/5000] | Time: 0.40s\n",
      "(Training) Loss: 956873.2075\n",
      "(Validation) Loss: 765559.3016, MAE: 3274.5667, R2: 0.2217\n",
      "==========================================================================================\n",
      "Epoch [4397/5000] | Time: 0.35s\n",
      "(Training) Loss: 962659.9334\n",
      "(Validation) Loss: 765486.7575, MAE: 3271.4004, R2: 0.2218\n",
      "==========================================================================================\n",
      "Epoch [4398/5000] | Time: 0.38s\n",
      "(Training) Loss: 963594.3852\n",
      "(Validation) Loss: 765389.0635, MAE: 3268.7693, R2: 0.2219\n",
      "==========================================================================================\n",
      "Epoch [4399/5000] | Time: 0.35s\n",
      "(Training) Loss: 957014.7094\n",
      "(Validation) Loss: 765328.7149, MAE: 3273.0308, R2: 0.2219\n",
      "==========================================================================================\n",
      "Epoch [4400/5000] | Time: 0.39s\n",
      "(Training) Loss: 946021.4032\n",
      "(Validation) Loss: 765239.1676, MAE: 3270.5593, R2: 0.2220\n",
      "==========================================================================================\n",
      "Epoch [4401/5000] | Time: 0.38s\n",
      "(Training) Loss: 981778.6821\n",
      "(Validation) Loss: 765161.1524, MAE: 3269.0359, R2: 0.2221\n",
      "==========================================================================================\n",
      "Epoch [4402/5000] | Time: 0.41s\n",
      "(Training) Loss: 944988.9588\n",
      "(Validation) Loss: 765087.4013, MAE: 3271.4426, R2: 0.2222\n",
      "==========================================================================================\n",
      "Epoch [4403/5000] | Time: 0.40s\n",
      "(Training) Loss: 943093.4001\n",
      "(Validation) Loss: 765014.5790, MAE: 3272.5701, R2: 0.2222\n",
      "==========================================================================================\n",
      "Epoch [4404/5000] | Time: 0.36s\n",
      "(Training) Loss: 952005.2329\n",
      "(Validation) Loss: 764923.2292, MAE: 3272.8188, R2: 0.2223\n",
      "==========================================================================================\n",
      "Epoch [4405/5000] | Time: 0.37s\n",
      "(Training) Loss: 970556.7817\n",
      "(Validation) Loss: 764844.8692, MAE: 3268.7988, R2: 0.2224\n",
      "==========================================================================================\n",
      "Epoch [4406/5000] | Time: 0.37s\n",
      "(Training) Loss: 955143.2164\n",
      "(Validation) Loss: 764766.0324, MAE: 3271.4133, R2: 0.2225\n",
      "==========================================================================================\n",
      "Epoch [4407/5000] | Time: 0.38s\n",
      "(Training) Loss: 948332.8217\n",
      "(Validation) Loss: 764687.4679, MAE: 3269.8762, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [4408/5000] | Time: 0.37s\n",
      "(Training) Loss: 946339.6129\n",
      "(Validation) Loss: 764608.1594, MAE: 3267.5923, R2: 0.2226\n",
      "==========================================================================================\n",
      "Epoch [4409/5000] | Time: 0.34s\n",
      "(Training) Loss: 970625.5260\n",
      "(Validation) Loss: 764530.7467, MAE: 3267.5654, R2: 0.2227\n",
      "==========================================================================================\n",
      "Epoch [4410/5000] | Time: 0.35s\n",
      "(Training) Loss: 945658.1218\n",
      "(Validation) Loss: 764457.9162, MAE: 3278.7549, R2: 0.2228\n",
      "==========================================================================================\n",
      "Epoch [4411/5000] | Time: 0.34s\n",
      "(Training) Loss: 950791.6129\n",
      "(Validation) Loss: 764384.7067, MAE: 3268.1975, R2: 0.2229\n",
      "==========================================================================================\n",
      "Epoch [4412/5000] | Time: 0.37s\n",
      "(Training) Loss: 943655.7989\n",
      "(Validation) Loss: 764294.3778, MAE: 3266.1140, R2: 0.2230\n",
      "==========================================================================================\n",
      "Epoch [4413/5000] | Time: 0.35s\n",
      "(Training) Loss: 975845.0238\n",
      "(Validation) Loss: 764211.4159, MAE: 3262.0811, R2: 0.2230\n",
      "==========================================================================================\n",
      "Epoch [4414/5000] | Time: 0.35s\n",
      "(Training) Loss: 941051.5803\n",
      "(Validation) Loss: 764139.8419, MAE: 3264.6160, R2: 0.2231\n",
      "==========================================================================================\n",
      "Epoch [4415/5000] | Time: 0.36s\n",
      "(Training) Loss: 949989.5863\n",
      "(Validation) Loss: 764065.5962, MAE: 3269.7947, R2: 0.2232\n",
      "==========================================================================================\n",
      "Epoch [4416/5000] | Time: 0.42s\n",
      "(Training) Loss: 942392.3452\n",
      "(Validation) Loss: 763980.1778, MAE: 3266.2634, R2: 0.2233\n",
      "==========================================================================================\n",
      "Epoch [4417/5000] | Time: 0.41s\n",
      "(Training) Loss: 946852.5685\n",
      "(Validation) Loss: 763895.6990, MAE: 3261.0308, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [4418/5000] | Time: 0.39s\n",
      "(Training) Loss: 962691.2671\n",
      "(Validation) Loss: 763833.2883, MAE: 3262.4299, R2: 0.2234\n",
      "==========================================================================================\n",
      "Epoch [4419/5000] | Time: 0.36s\n",
      "(Training) Loss: 956546.8528\n",
      "(Validation) Loss: 763759.0076, MAE: 3264.0024, R2: 0.2235\n",
      "==========================================================================================\n",
      "Epoch [4420/5000] | Time: 0.44s\n",
      "(Training) Loss: 968064.5603\n",
      "(Validation) Loss: 763664.7105, MAE: 3267.1013, R2: 0.2236\n",
      "==========================================================================================\n",
      "Epoch [4421/5000] | Time: 0.43s\n",
      "(Training) Loss: 950786.7103\n",
      "(Validation) Loss: 763591.8019, MAE: 3261.5691, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [4422/5000] | Time: 0.38s\n",
      "(Training) Loss: 981872.8820\n",
      "(Validation) Loss: 763539.5416, MAE: 3266.2329, R2: 0.2237\n",
      "==========================================================================================\n",
      "Epoch [4423/5000] | Time: 0.39s\n",
      "(Training) Loss: 955037.1396\n",
      "(Validation) Loss: 763431.2603, MAE: 3258.9553, R2: 0.2238\n",
      "==========================================================================================\n",
      "Epoch [4424/5000] | Time: 0.39s\n",
      "(Training) Loss: 954969.0609\n",
      "(Validation) Loss: 763358.3860, MAE: 3261.6299, R2: 0.2239\n",
      "==========================================================================================\n",
      "Epoch [4425/5000] | Time: 0.34s\n",
      "(Training) Loss: 954499.6618\n",
      "(Validation) Loss: 763266.9460, MAE: 3260.2146, R2: 0.2240\n",
      "==========================================================================================\n",
      "Epoch [4426/5000] | Time: 0.35s\n",
      "(Training) Loss: 945561.5717\n",
      "(Validation) Loss: 763195.8622, MAE: 3261.0571, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [4427/5000] | Time: 0.35s\n",
      "(Training) Loss: 947577.7646\n",
      "(Validation) Loss: 763120.5448, MAE: 3259.6353, R2: 0.2241\n",
      "==========================================================================================\n",
      "Epoch [4428/5000] | Time: 0.36s\n",
      "(Training) Loss: 945148.9258\n",
      "(Validation) Loss: 763040.1505, MAE: 3258.6489, R2: 0.2242\n",
      "==========================================================================================\n",
      "Epoch [4429/5000] | Time: 0.33s\n",
      "(Training) Loss: 944401.1935\n",
      "(Validation) Loss: 762958.2184, MAE: 3259.8892, R2: 0.2243\n",
      "==========================================================================================\n",
      "Epoch [4430/5000] | Time: 0.37s\n",
      "(Training) Loss: 948999.8585\n",
      "(Validation) Loss: 762879.7886, MAE: 3257.0007, R2: 0.2244\n",
      "==========================================================================================\n",
      "Epoch [4431/5000] | Time: 0.35s\n",
      "(Training) Loss: 950020.3674\n",
      "(Validation) Loss: 762807.2356, MAE: 3259.2905, R2: 0.2245\n",
      "==========================================================================================\n",
      "Epoch [4432/5000] | Time: 0.33s\n",
      "(Training) Loss: 960152.6929\n",
      "(Validation) Loss: 762739.8463, MAE: 3261.0540, R2: 0.2245\n",
      "==========================================================================================\n",
      "Epoch [4433/5000] | Time: 0.35s\n",
      "(Training) Loss: 955850.0114\n",
      "(Validation) Loss: 762649.8597, MAE: 3258.8115, R2: 0.2246\n",
      "==========================================================================================\n",
      "Epoch [4434/5000] | Time: 0.31s\n",
      "(Training) Loss: 939405.1718\n",
      "(Validation) Loss: 762578.4292, MAE: 3258.5994, R2: 0.2247\n",
      "==========================================================================================\n",
      "Epoch [4435/5000] | Time: 0.37s\n",
      "(Training) Loss: 944976.1954\n",
      "(Validation) Loss: 762491.6305, MAE: 3258.9854, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [4436/5000] | Time: 0.36s\n",
      "(Training) Loss: 954525.0793\n",
      "(Validation) Loss: 762427.9302, MAE: 3259.2693, R2: 0.2248\n",
      "==========================================================================================\n",
      "Epoch [4437/5000] | Time: 0.34s\n",
      "(Training) Loss: 941982.6726\n",
      "(Validation) Loss: 762338.6495, MAE: 3258.3523, R2: 0.2249\n",
      "==========================================================================================\n",
      "Epoch [4438/5000] | Time: 0.36s\n",
      "(Training) Loss: 962204.7462\n",
      "(Validation) Loss: 762281.4286, MAE: 3260.3999, R2: 0.2250\n",
      "==========================================================================================\n",
      "Epoch [4439/5000] | Time: 0.35s\n",
      "(Training) Loss: 944268.2240\n",
      "(Validation) Loss: 762176.5625, MAE: 3255.0203, R2: 0.2251\n",
      "==========================================================================================\n",
      "Epoch [4440/5000] | Time: 0.34s\n",
      "(Training) Loss: 959505.6129\n",
      "(Validation) Loss: 762100.0286, MAE: 3257.2866, R2: 0.2252\n",
      "==========================================================================================\n",
      "Epoch [4441/5000] | Time: 0.37s\n",
      "(Training) Loss: 944903.9036\n",
      "(Validation) Loss: 762022.9149, MAE: 3255.7354, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [4442/5000] | Time: 0.35s\n",
      "(Training) Loss: 949744.1364\n",
      "(Validation) Loss: 761945.7860, MAE: 3255.4736, R2: 0.2253\n",
      "==========================================================================================\n",
      "Epoch [4443/5000] | Time: 0.33s\n",
      "(Training) Loss: 936701.2145\n",
      "(Validation) Loss: 761873.8032, MAE: 3266.2466, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [4444/5000] | Time: 0.40s\n",
      "(Training) Loss: 952435.3455\n",
      "(Validation) Loss: 761789.0844, MAE: 3256.2017, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [4445/5000] | Time: 0.39s\n",
      "(Training) Loss: 967418.4378\n",
      "(Validation) Loss: 761880.1429, MAE: 3267.0454, R2: 0.2254\n",
      "==========================================================================================\n",
      "Epoch [4446/5000] | Time: 0.42s\n",
      "(Training) Loss: 942489.5768\n",
      "(Validation) Loss: 761799.4533, MAE: 3265.7498, R2: 0.2255\n",
      "==========================================================================================\n",
      "Epoch [4447/5000] | Time: 0.40s\n",
      "(Training) Loss: 954570.8280\n",
      "(Validation) Loss: 761724.2698, MAE: 3265.7969, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [4448/5000] | Time: 0.37s\n",
      "(Training) Loss: 960655.1656\n",
      "(Validation) Loss: 761646.6197, MAE: 3267.0085, R2: 0.2256\n",
      "==========================================================================================\n",
      "Epoch [4449/5000] | Time: 0.36s\n",
      "(Training) Loss: 939249.0939\n",
      "(Validation) Loss: 761571.8838, MAE: 3265.7981, R2: 0.2257\n",
      "==========================================================================================\n",
      "Epoch [4450/5000] | Time: 0.35s\n",
      "(Training) Loss: 956599.4746\n",
      "(Validation) Loss: 761488.7892, MAE: 3265.6196, R2: 0.2258\n",
      "==========================================================================================\n",
      "Epoch [4451/5000] | Time: 0.39s\n",
      "(Training) Loss: 949192.3890\n",
      "(Validation) Loss: 761413.8603, MAE: 3264.8086, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [4452/5000] | Time: 0.37s\n",
      "(Training) Loss: 955047.3166\n",
      "(Validation) Loss: 761337.0317, MAE: 3268.5779, R2: 0.2259\n",
      "==========================================================================================\n",
      "Epoch [4453/5000] | Time: 0.37s\n",
      "(Training) Loss: 953615.9619\n",
      "(Validation) Loss: 761264.5797, MAE: 3271.8252, R2: 0.2260\n",
      "==========================================================================================\n",
      "Epoch [4454/5000] | Time: 0.35s\n",
      "(Training) Loss: 955794.2640\n",
      "(Validation) Loss: 761178.9517, MAE: 3266.0964, R2: 0.2261\n",
      "==========================================================================================\n",
      "Epoch [4455/5000] | Time: 0.34s\n",
      "(Training) Loss: 941963.1187\n",
      "(Validation) Loss: 761107.7270, MAE: 3265.5286, R2: 0.2262\n",
      "==========================================================================================\n",
      "Epoch [4456/5000] | Time: 0.36s\n",
      "(Training) Loss: 944846.7443\n",
      "(Validation) Loss: 761021.1314, MAE: 3264.5215, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [4457/5000] | Time: 0.38s\n",
      "(Training) Loss: 958638.0286\n",
      "(Validation) Loss: 760943.3010, MAE: 3269.5049, R2: 0.2263\n",
      "==========================================================================================\n",
      "Epoch [4458/5000] | Time: 0.32s\n",
      "(Training) Loss: 944152.6485\n",
      "(Validation) Loss: 760863.4838, MAE: 3263.2878, R2: 0.2264\n",
      "==========================================================================================\n",
      "Epoch [4459/5000] | Time: 0.33s\n",
      "(Training) Loss: 953039.1789\n",
      "(Validation) Loss: 760779.1956, MAE: 3262.9348, R2: 0.2265\n",
      "==========================================================================================\n",
      "Epoch [4460/5000] | Time: 0.35s\n",
      "(Training) Loss: 945007.9156\n",
      "(Validation) Loss: 760703.8425, MAE: 3262.7830, R2: 0.2266\n",
      "==========================================================================================\n",
      "Epoch [4461/5000] | Time: 0.33s\n",
      "(Training) Loss: 940098.1701\n",
      "(Validation) Loss: 760624.9517, MAE: 3266.0342, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [4462/5000] | Time: 0.32s\n",
      "(Training) Loss: 959039.1117\n",
      "(Validation) Loss: 760546.4584, MAE: 3261.1318, R2: 0.2267\n",
      "==========================================================================================\n",
      "Epoch [4463/5000] | Time: 0.37s\n",
      "(Training) Loss: 952772.6117\n",
      "(Validation) Loss: 760470.5867, MAE: 3264.5437, R2: 0.2268\n",
      "==========================================================================================\n",
      "Epoch [4464/5000] | Time: 0.33s\n",
      "(Training) Loss: 944849.9492\n",
      "(Validation) Loss: 767417.7930, MAE: 3278.6333, R2: 0.2198\n",
      "==========================================================================================\n",
      "Epoch [4465/5000] | Time: 0.33s\n",
      "(Training) Loss: 963361.6091\n",
      "(Validation) Loss: 756413.0902, MAE: 3236.4331, R2: 0.2309\n",
      "==========================================================================================\n",
      "Epoch [4466/5000] | Time: 0.34s\n",
      "(Training) Loss: 962437.2195\n",
      "(Validation) Loss: 756326.5435, MAE: 3236.4885, R2: 0.2310\n",
      "==========================================================================================\n",
      "Epoch [4467/5000] | Time: 0.37s\n",
      "(Training) Loss: 958146.8591\n",
      "(Validation) Loss: 756295.5810, MAE: 3241.8181, R2: 0.2310\n",
      "==========================================================================================\n",
      "Epoch [4468/5000] | Time: 0.30s\n",
      "(Training) Loss: 943848.1523\n",
      "(Validation) Loss: 756227.9549, MAE: 3241.4143, R2: 0.2311\n",
      "==========================================================================================\n",
      "Epoch [4469/5000] | Time: 0.31s\n",
      "(Training) Loss: 953097.4080\n",
      "(Validation) Loss: 756253.4514, MAE: 3250.2869, R2: 0.2311\n",
      "==========================================================================================\n",
      "Epoch [4470/5000] | Time: 0.35s\n",
      "(Training) Loss: 938522.5571\n",
      "(Validation) Loss: 756064.8889, MAE: 3243.6416, R2: 0.2313\n",
      "==========================================================================================\n",
      "Epoch [4471/5000] | Time: 0.33s\n",
      "(Training) Loss: 943386.3464\n",
      "(Validation) Loss: 755992.9860, MAE: 3242.0251, R2: 0.2313\n",
      "==========================================================================================\n",
      "Epoch [4472/5000] | Time: 0.39s\n",
      "(Training) Loss: 943571.9181\n",
      "(Validation) Loss: 755922.7568, MAE: 3246.0886, R2: 0.2314\n",
      "==========================================================================================\n",
      "Epoch [4473/5000] | Time: 0.37s\n",
      "(Training) Loss: 947232.9359\n",
      "(Validation) Loss: 755833.8165, MAE: 3243.3528, R2: 0.2315\n",
      "==========================================================================================\n",
      "Epoch [4474/5000] | Time: 0.36s\n",
      "(Training) Loss: 960217.3255\n",
      "(Validation) Loss: 755756.1194, MAE: 3240.1235, R2: 0.2316\n",
      "==========================================================================================\n",
      "Epoch [4475/5000] | Time: 0.38s\n",
      "(Training) Loss: 941618.8263\n",
      "(Validation) Loss: 755716.7003, MAE: 3249.9470, R2: 0.2316\n",
      "==========================================================================================\n",
      "Epoch [4476/5000] | Time: 0.34s\n",
      "(Training) Loss: 961160.0888\n",
      "(Validation) Loss: 755597.9524, MAE: 3241.0938, R2: 0.2317\n",
      "==========================================================================================\n",
      "Epoch [4477/5000] | Time: 0.40s\n",
      "(Training) Loss: 942250.0178\n",
      "(Validation) Loss: 755525.3943, MAE: 3240.2693, R2: 0.2318\n",
      "==========================================================================================\n",
      "Epoch [4478/5000] | Time: 0.37s\n",
      "(Training) Loss: 939403.5647\n",
      "(Validation) Loss: 755437.5289, MAE: 3238.3391, R2: 0.2319\n",
      "==========================================================================================\n",
      "Epoch [4479/5000] | Time: 0.32s\n",
      "(Training) Loss: 931293.1120\n",
      "(Validation) Loss: 755363.1041, MAE: 3238.9038, R2: 0.2320\n",
      "==========================================================================================\n",
      "Epoch [4480/5000] | Time: 0.36s\n",
      "(Training) Loss: 941038.7411\n",
      "(Validation) Loss: 755285.3346, MAE: 3237.8997, R2: 0.2320\n",
      "==========================================================================================\n",
      "Epoch [4481/5000] | Time: 0.33s\n",
      "(Training) Loss: 942331.8826\n",
      "(Validation) Loss: 755202.7048, MAE: 3238.1741, R2: 0.2321\n",
      "==========================================================================================\n",
      "Epoch [4482/5000] | Time: 0.32s\n",
      "(Training) Loss: 961134.3198\n",
      "(Validation) Loss: 755125.4952, MAE: 3238.5652, R2: 0.2322\n",
      "==========================================================================================\n",
      "Epoch [4483/5000] | Time: 0.34s\n",
      "(Training) Loss: 935261.7836\n",
      "(Validation) Loss: 755045.1333, MAE: 3234.6140, R2: 0.2323\n",
      "==========================================================================================\n",
      "Epoch [4484/5000] | Time: 0.32s\n",
      "(Training) Loss: 939921.6098\n",
      "(Validation) Loss: 754970.0476, MAE: 3235.5508, R2: 0.2324\n",
      "==========================================================================================\n",
      "Epoch [4485/5000] | Time: 0.35s\n",
      "(Training) Loss: 936899.8915\n",
      "(Validation) Loss: 752837.4387, MAE: 3231.4094, R2: 0.2345\n",
      "==========================================================================================\n",
      "Epoch [4486/5000] | Time: 0.31s\n",
      "(Training) Loss: 932182.0235\n",
      "(Validation) Loss: 752749.6571, MAE: 3230.2812, R2: 0.2346\n",
      "==========================================================================================\n",
      "Epoch [4487/5000] | Time: 0.31s\n",
      "(Training) Loss: 941839.9727\n",
      "(Validation) Loss: 752669.0019, MAE: 3231.3584, R2: 0.2347\n",
      "==========================================================================================\n",
      "Epoch [4488/5000] | Time: 0.35s\n",
      "(Training) Loss: 933522.3668\n",
      "(Validation) Loss: 752572.5987, MAE: 3227.1462, R2: 0.2348\n",
      "==========================================================================================\n",
      "Epoch [4489/5000] | Time: 0.37s\n",
      "(Training) Loss: 958519.7843\n",
      "(Validation) Loss: 752498.8019, MAE: 3229.2568, R2: 0.2348\n",
      "==========================================================================================\n",
      "Epoch [4490/5000] | Time: 0.37s\n",
      "(Training) Loss: 940615.7189\n",
      "(Validation) Loss: 752411.5098, MAE: 3227.3511, R2: 0.2349\n",
      "==========================================================================================\n",
      "Epoch [4491/5000] | Time: 0.39s\n",
      "(Training) Loss: 932207.4683\n",
      "(Validation) Loss: 752330.6330, MAE: 3227.6841, R2: 0.2350\n",
      "==========================================================================================\n",
      "Epoch [4492/5000] | Time: 0.41s\n",
      "(Training) Loss: 930888.2232\n",
      "(Validation) Loss: 752369.1302, MAE: 3236.3291, R2: 0.2350\n",
      "==========================================================================================\n",
      "Epoch [4493/5000] | Time: 0.35s\n",
      "(Training) Loss: 950262.6326\n",
      "(Validation) Loss: 752287.1606, MAE: 3237.1836, R2: 0.2351\n",
      "==========================================================================================\n",
      "Epoch [4494/5000] | Time: 0.40s\n",
      "(Training) Loss: 930357.6561\n",
      "(Validation) Loss: 752199.0743, MAE: 3233.5686, R2: 0.2351\n",
      "==========================================================================================\n",
      "Epoch [4495/5000] | Time: 0.42s\n",
      "(Training) Loss: 938853.6504\n",
      "(Validation) Loss: 752121.9397, MAE: 3233.5818, R2: 0.2352\n",
      "==========================================================================================\n",
      "Epoch [4496/5000] | Time: 0.38s\n",
      "(Training) Loss: 940579.7335\n",
      "(Validation) Loss: 752035.1575, MAE: 3233.1562, R2: 0.2353\n",
      "==========================================================================================\n",
      "Epoch [4497/5000] | Time: 0.42s\n",
      "(Training) Loss: 930984.5127\n",
      "(Validation) Loss: 751974.4876, MAE: 3236.6069, R2: 0.2354\n",
      "==========================================================================================\n",
      "Epoch [4498/5000] | Time: 0.42s\n",
      "(Training) Loss: 957353.5546\n",
      "(Validation) Loss: 751878.8140, MAE: 3233.0847, R2: 0.2355\n",
      "==========================================================================================\n",
      "Epoch [4499/5000] | Time: 0.38s\n",
      "(Training) Loss: 958619.6935\n",
      "(Validation) Loss: 751801.2857, MAE: 3233.3911, R2: 0.2356\n",
      "==========================================================================================\n",
      "Epoch [4500/5000] | Time: 0.40s\n",
      "(Training) Loss: 934661.5501\n",
      "(Validation) Loss: 751711.7549, MAE: 3232.5715, R2: 0.2356\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch4500.pth\n",
      "==========================================================================================\n",
      "Epoch [4501/5000] | Time: 0.41s\n",
      "(Training) Loss: 926019.1431\n",
      "(Validation) Loss: 751635.6057, MAE: 3232.2314, R2: 0.2357\n",
      "==========================================================================================\n",
      "Epoch [4502/5000] | Time: 0.40s\n",
      "(Training) Loss: 939640.9695\n",
      "(Validation) Loss: 751561.2571, MAE: 3232.8552, R2: 0.2358\n",
      "==========================================================================================\n",
      "Epoch [4503/5000] | Time: 0.42s\n",
      "(Training) Loss: 930897.9239\n",
      "(Validation) Loss: 751473.0648, MAE: 3229.7209, R2: 0.2359\n",
      "==========================================================================================\n",
      "Epoch [4504/5000] | Time: 0.39s\n",
      "(Training) Loss: 955238.6837\n",
      "(Validation) Loss: 751391.8959, MAE: 3230.3784, R2: 0.2360\n",
      "==========================================================================================\n",
      "Epoch [4505/5000] | Time: 0.34s\n",
      "(Training) Loss: 936100.7970\n",
      "(Validation) Loss: 751313.1016, MAE: 3230.3982, R2: 0.2360\n",
      "==========================================================================================\n",
      "Epoch [4506/5000] | Time: 0.36s\n",
      "(Training) Loss: 933051.7548\n",
      "(Validation) Loss: 751235.0921, MAE: 3230.2036, R2: 0.2361\n",
      "==========================================================================================\n",
      "Epoch [4507/5000] | Time: 0.38s\n",
      "(Training) Loss: 938760.7544\n",
      "(Validation) Loss: 751153.3289, MAE: 3230.6904, R2: 0.2362\n",
      "==========================================================================================\n",
      "Epoch [4508/5000] | Time: 0.34s\n",
      "(Training) Loss: 936849.2621\n",
      "(Validation) Loss: 751077.8571, MAE: 3229.8879, R2: 0.2363\n",
      "==========================================================================================\n",
      "Epoch [4509/5000] | Time: 0.40s\n",
      "(Training) Loss: 935973.9029\n",
      "(Validation) Loss: 751008.9232, MAE: 3232.3760, R2: 0.2364\n",
      "==========================================================================================\n",
      "Epoch [4510/5000] | Time: 0.44s\n",
      "(Training) Loss: 934567.7367\n",
      "(Validation) Loss: 750926.4844, MAE: 3230.9680, R2: 0.2364\n",
      "==========================================================================================\n",
      "Epoch [4511/5000] | Time: 0.36s\n",
      "(Training) Loss: 927072.8192\n",
      "(Validation) Loss: 750846.6311, MAE: 3230.7888, R2: 0.2365\n",
      "==========================================================================================\n",
      "Epoch [4512/5000] | Time: 0.37s\n",
      "(Training) Loss: 926142.5543\n",
      "(Validation) Loss: 750755.8381, MAE: 3228.8416, R2: 0.2366\n",
      "==========================================================================================\n",
      "Epoch [4513/5000] | Time: 0.42s\n",
      "(Training) Loss: 932204.0279\n",
      "(Validation) Loss: 750684.2292, MAE: 3229.5940, R2: 0.2367\n",
      "==========================================================================================\n",
      "Epoch [4514/5000] | Time: 0.38s\n",
      "(Training) Loss: 930827.7500\n",
      "(Validation) Loss: 750604.4648, MAE: 3230.9756, R2: 0.2368\n",
      "==========================================================================================\n",
      "Epoch [4515/5000] | Time: 0.36s\n",
      "(Training) Loss: 945241.9016\n",
      "(Validation) Loss: 750525.7079, MAE: 3229.2800, R2: 0.2368\n",
      "==========================================================================================\n",
      "Epoch [4516/5000] | Time: 0.38s\n",
      "(Training) Loss: 944212.8763\n",
      "(Validation) Loss: 750439.2559, MAE: 3227.4880, R2: 0.2369\n",
      "==========================================================================================\n",
      "Epoch [4517/5000] | Time: 0.35s\n",
      "(Training) Loss: 929555.4264\n",
      "(Validation) Loss: 750359.3098, MAE: 3228.5137, R2: 0.2370\n",
      "==========================================================================================\n",
      "Epoch [4518/5000] | Time: 0.34s\n",
      "(Training) Loss: 928177.9289\n",
      "(Validation) Loss: 750279.9232, MAE: 3227.0144, R2: 0.2371\n",
      "==========================================================================================\n",
      "Epoch [4519/5000] | Time: 0.38s\n",
      "(Training) Loss: 928479.9121\n",
      "(Validation) Loss: 750201.3429, MAE: 3225.4771, R2: 0.2372\n",
      "==========================================================================================\n",
      "Epoch [4520/5000] | Time: 0.38s\n",
      "(Training) Loss: 932573.3953\n",
      "(Validation) Loss: 750123.3898, MAE: 3226.5654, R2: 0.2372\n",
      "==========================================================================================\n",
      "Epoch [4521/5000] | Time: 0.34s\n",
      "(Training) Loss: 959902.1428\n",
      "(Validation) Loss: 750048.4673, MAE: 3226.8374, R2: 0.2373\n",
      "==========================================================================================\n",
      "Epoch [4522/5000] | Time: 0.33s\n",
      "(Training) Loss: 935515.4562\n",
      "(Validation) Loss: 749959.1137, MAE: 3223.8767, R2: 0.2374\n",
      "==========================================================================================\n",
      "Epoch [4523/5000] | Time: 0.32s\n",
      "(Training) Loss: 931645.3204\n",
      "(Validation) Loss: 749882.8083, MAE: 3224.9824, R2: 0.2375\n",
      "==========================================================================================\n",
      "Epoch [4524/5000] | Time: 0.38s\n",
      "(Training) Loss: 931634.2157\n",
      "(Validation) Loss: 749808.0584, MAE: 3225.6892, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [4525/5000] | Time: 0.33s\n",
      "(Training) Loss: 942905.4854\n",
      "(Validation) Loss: 749726.9759, MAE: 3225.9854, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [4526/5000] | Time: 0.39s\n",
      "(Training) Loss: 924791.1367\n",
      "(Validation) Loss: 749649.7543, MAE: 3229.5112, R2: 0.2377\n",
      "==========================================================================================\n",
      "Epoch [4527/5000] | Time: 0.39s\n",
      "(Training) Loss: 929036.9657\n",
      "(Validation) Loss: 749569.7498, MAE: 3224.9617, R2: 0.2378\n",
      "==========================================================================================\n",
      "Epoch [4528/5000] | Time: 0.35s\n",
      "(Training) Loss: 931668.5514\n",
      "(Validation) Loss: 749494.9594, MAE: 3227.7209, R2: 0.2379\n",
      "==========================================================================================\n",
      "Epoch [4529/5000] | Time: 0.32s\n",
      "(Training) Loss: 932078.1174\n",
      "(Validation) Loss: 749411.4178, MAE: 3224.8594, R2: 0.2380\n",
      "==========================================================================================\n",
      "Epoch [4530/5000] | Time: 0.38s\n",
      "(Training) Loss: 928969.1453\n",
      "(Validation) Loss: 749329.0781, MAE: 3222.6074, R2: 0.2380\n",
      "==========================================================================================\n",
      "Epoch [4531/5000] | Time: 0.35s\n",
      "(Training) Loss: 931854.3115\n",
      "(Validation) Loss: 749250.1975, MAE: 3221.9521, R2: 0.2381\n",
      "==========================================================================================\n",
      "Epoch [4532/5000] | Time: 0.39s\n",
      "(Training) Loss: 926771.9613\n",
      "(Validation) Loss: 749222.8590, MAE: 3244.7634, R2: 0.2382\n",
      "==========================================================================================\n",
      "Epoch [4533/5000] | Time: 0.37s\n",
      "(Training) Loss: 934344.6041\n",
      "(Validation) Loss: 749109.2692, MAE: 3234.1504, R2: 0.2383\n",
      "==========================================================================================\n",
      "Epoch [4534/5000] | Time: 0.39s\n",
      "(Training) Loss: 936276.5178\n",
      "(Validation) Loss: 730406.4210, MAE: 3179.5688, R2: 0.2571\n",
      "==========================================================================================\n",
      "Epoch [4535/5000] | Time: 0.40s\n",
      "(Training) Loss: 903005.8648\n",
      "(Validation) Loss: 729148.7187, MAE: 3169.4380, R2: 0.2584\n",
      "==========================================================================================\n",
      "Epoch [4536/5000] | Time: 0.35s\n",
      "(Training) Loss: 902617.6459\n",
      "(Validation) Loss: 729100.8717, MAE: 3171.5134, R2: 0.2584\n",
      "==========================================================================================\n",
      "Epoch [4537/5000] | Time: 0.37s\n",
      "(Training) Loss: 901913.9124\n",
      "(Validation) Loss: 729024.1479, MAE: 3169.2910, R2: 0.2585\n",
      "==========================================================================================\n",
      "Epoch [4538/5000] | Time: 0.39s\n",
      "(Training) Loss: 931879.6561\n",
      "(Validation) Loss: 728922.3054, MAE: 3166.6362, R2: 0.2586\n",
      "==========================================================================================\n",
      "Epoch [4539/5000] | Time: 0.38s\n",
      "(Training) Loss: 903271.7094\n",
      "(Validation) Loss: 728824.6190, MAE: 3163.5823, R2: 0.2587\n",
      "==========================================================================================\n",
      "Epoch [4540/5000] | Time: 0.35s\n",
      "(Training) Loss: 932981.6586\n",
      "(Validation) Loss: 728751.0819, MAE: 3164.0210, R2: 0.2588\n",
      "==========================================================================================\n",
      "Epoch [4541/5000] | Time: 0.35s\n",
      "(Training) Loss: 923443.2633\n",
      "(Validation) Loss: 728835.6343, MAE: 3184.6907, R2: 0.2587\n",
      "==========================================================================================\n",
      "Epoch [4542/5000] | Time: 0.38s\n",
      "(Training) Loss: 925698.1770\n",
      "(Validation) Loss: 728603.0806, MAE: 3164.9458, R2: 0.2589\n",
      "==========================================================================================\n",
      "Epoch [4543/5000] | Time: 0.37s\n",
      "(Training) Loss: 898722.4808\n",
      "(Validation) Loss: 728513.9105, MAE: 3163.2607, R2: 0.2590\n",
      "==========================================================================================\n",
      "Epoch [4544/5000] | Time: 0.36s\n",
      "(Training) Loss: 907505.1218\n",
      "(Validation) Loss: 728437.4381, MAE: 3163.7271, R2: 0.2591\n",
      "==========================================================================================\n",
      "Epoch [4545/5000] | Time: 0.33s\n",
      "(Training) Loss: 898789.0888\n",
      "(Validation) Loss: 728348.3657, MAE: 3160.6733, R2: 0.2592\n",
      "==========================================================================================\n",
      "Epoch [4546/5000] | Time: 0.34s\n",
      "(Training) Loss: 912735.2081\n",
      "(Validation) Loss: 728287.4171, MAE: 3162.9658, R2: 0.2593\n",
      "==========================================================================================\n",
      "Epoch [4547/5000] | Time: 0.36s\n",
      "(Training) Loss: 904984.3008\n",
      "(Validation) Loss: 728208.8203, MAE: 3162.9114, R2: 0.2593\n",
      "==========================================================================================\n",
      "Epoch [4548/5000] | Time: 0.34s\n",
      "(Training) Loss: 911867.4404\n",
      "(Validation) Loss: 728126.6451, MAE: 3162.6128, R2: 0.2594\n",
      "==========================================================================================\n",
      "Epoch [4549/5000] | Time: 0.33s\n",
      "(Training) Loss: 899926.5190\n",
      "(Validation) Loss: 728053.3276, MAE: 3162.8691, R2: 0.2595\n",
      "==========================================================================================\n",
      "Epoch [4550/5000] | Time: 0.38s\n",
      "(Training) Loss: 902862.6961\n",
      "(Validation) Loss: 727983.3111, MAE: 3163.0881, R2: 0.2596\n",
      "==========================================================================================\n",
      "Epoch [4551/5000] | Time: 0.35s\n",
      "(Training) Loss: 909609.2024\n",
      "(Validation) Loss: 727891.4095, MAE: 3160.4736, R2: 0.2597\n",
      "==========================================================================================\n",
      "Epoch [4552/5000] | Time: 0.35s\n",
      "(Training) Loss: 915582.3503\n",
      "(Validation) Loss: 727804.2083, MAE: 3157.6597, R2: 0.2597\n",
      "==========================================================================================\n",
      "Epoch [4553/5000] | Time: 0.38s\n",
      "(Training) Loss: 899233.9822\n",
      "(Validation) Loss: 727729.8857, MAE: 3158.8682, R2: 0.2598\n",
      "==========================================================================================\n",
      "Epoch [4554/5000] | Time: 0.32s\n",
      "(Training) Loss: 907799.8135\n",
      "(Validation) Loss: 727659.5054, MAE: 3159.2793, R2: 0.2599\n",
      "==========================================================================================\n",
      "Epoch [4555/5000] | Time: 0.40s\n",
      "(Training) Loss: 909648.0146\n",
      "(Validation) Loss: 727574.1657, MAE: 3157.4504, R2: 0.2600\n",
      "==========================================================================================\n",
      "Epoch [4556/5000] | Time: 0.31s\n",
      "(Training) Loss: 899189.6667\n",
      "(Validation) Loss: 727497.6724, MAE: 3158.2896, R2: 0.2601\n",
      "==========================================================================================\n",
      "Epoch [4557/5000] | Time: 0.30s\n",
      "(Training) Loss: 910339.4226\n",
      "(Validation) Loss: 727435.1308, MAE: 3159.7124, R2: 0.2601\n",
      "==========================================================================================\n",
      "Epoch [4558/5000] | Time: 0.33s\n",
      "(Training) Loss: 899569.2709\n",
      "(Validation) Loss: 727361.0959, MAE: 3161.7000, R2: 0.2602\n",
      "==========================================================================================\n",
      "Epoch [4559/5000] | Time: 0.31s\n",
      "(Training) Loss: 908536.5419\n",
      "(Validation) Loss: 727265.3708, MAE: 3156.5879, R2: 0.2603\n",
      "==========================================================================================\n",
      "Epoch [4560/5000] | Time: 0.34s\n",
      "(Training) Loss: 909372.1117\n",
      "(Validation) Loss: 727191.5390, MAE: 3157.2261, R2: 0.2604\n",
      "==========================================================================================\n",
      "Epoch [4561/5000] | Time: 0.36s\n",
      "(Training) Loss: 905107.5168\n",
      "(Validation) Loss: 727117.3930, MAE: 3156.7307, R2: 0.2604\n",
      "==========================================================================================\n",
      "Epoch [4562/5000] | Time: 0.36s\n",
      "(Training) Loss: 897584.8611\n",
      "(Validation) Loss: 727034.5625, MAE: 3155.3232, R2: 0.2605\n",
      "==========================================================================================\n",
      "Epoch [4563/5000] | Time: 0.34s\n",
      "(Training) Loss: 906534.2881\n",
      "(Validation) Loss: 726964.6267, MAE: 3155.5366, R2: 0.2606\n",
      "==========================================================================================\n",
      "Epoch [4564/5000] | Time: 0.38s\n",
      "(Training) Loss: 910144.0362\n",
      "(Validation) Loss: 726879.7530, MAE: 3154.2473, R2: 0.2607\n",
      "==========================================================================================\n",
      "Epoch [4565/5000] | Time: 0.32s\n",
      "(Training) Loss: 918585.8617\n",
      "(Validation) Loss: 726802.1594, MAE: 3154.9915, R2: 0.2608\n",
      "==========================================================================================\n",
      "Epoch [4566/5000] | Time: 0.32s\n",
      "(Training) Loss: 909813.7456\n",
      "(Validation) Loss: 726739.2273, MAE: 3156.0422, R2: 0.2608\n",
      "==========================================================================================\n",
      "Epoch [4567/5000] | Time: 0.38s\n",
      "(Training) Loss: 913642.6237\n",
      "(Validation) Loss: 726653.2622, MAE: 3154.8486, R2: 0.2609\n",
      "==========================================================================================\n",
      "Epoch [4568/5000] | Time: 0.33s\n",
      "(Training) Loss: 901233.8959\n",
      "(Validation) Loss: 726580.6641, MAE: 3154.9292, R2: 0.2610\n",
      "==========================================================================================\n",
      "Epoch [4569/5000] | Time: 0.34s\n",
      "(Training) Loss: 906803.6358\n",
      "(Validation) Loss: 726508.6235, MAE: 3155.3608, R2: 0.2610\n",
      "==========================================================================================\n",
      "Epoch [4570/5000] | Time: 0.33s\n",
      "(Training) Loss: 906294.5971\n",
      "(Validation) Loss: 726419.0610, MAE: 3153.5325, R2: 0.2611\n",
      "==========================================================================================\n",
      "Epoch [4571/5000] | Time: 0.31s\n",
      "(Training) Loss: 898563.2370\n",
      "(Validation) Loss: 726335.3644, MAE: 3152.4199, R2: 0.2612\n",
      "==========================================================================================\n",
      "Epoch [4572/5000] | Time: 0.34s\n",
      "(Training) Loss: 914345.6434\n",
      "(Validation) Loss: 726263.2006, MAE: 3152.5728, R2: 0.2613\n",
      "==========================================================================================\n",
      "Epoch [4573/5000] | Time: 0.32s\n",
      "(Training) Loss: 927383.3528\n",
      "(Validation) Loss: 726180.6927, MAE: 3152.3545, R2: 0.2614\n",
      "==========================================================================================\n",
      "Epoch [4574/5000] | Time: 0.30s\n",
      "(Training) Loss: 906370.1256\n",
      "(Validation) Loss: 726112.1035, MAE: 3153.1372, R2: 0.2614\n",
      "==========================================================================================\n",
      "Epoch [4575/5000] | Time: 0.34s\n",
      "(Training) Loss: 914081.9772\n",
      "(Validation) Loss: 726047.5657, MAE: 3154.4453, R2: 0.2615\n",
      "==========================================================================================\n",
      "Epoch [4576/5000] | Time: 0.33s\n",
      "(Training) Loss: 910270.8626\n",
      "(Validation) Loss: 725959.3790, MAE: 3152.3618, R2: 0.2616\n",
      "==========================================================================================\n",
      "Epoch [4577/5000] | Time: 0.31s\n",
      "(Training) Loss: 902645.4042\n",
      "(Validation) Loss: 725870.7651, MAE: 3150.5283, R2: 0.2617\n",
      "==========================================================================================\n",
      "Epoch [4578/5000] | Time: 0.34s\n",
      "(Training) Loss: 897815.6342\n",
      "(Validation) Loss: 725791.2235, MAE: 3149.8513, R2: 0.2618\n",
      "==========================================================================================\n",
      "Epoch [4579/5000] | Time: 0.32s\n",
      "(Training) Loss: 910455.9873\n",
      "(Validation) Loss: 725721.2654, MAE: 3151.0081, R2: 0.2618\n",
      "==========================================================================================\n",
      "Epoch [4580/5000] | Time: 0.35s\n",
      "(Training) Loss: 904282.2868\n",
      "(Validation) Loss: 725640.3587, MAE: 3150.3301, R2: 0.2619\n",
      "==========================================================================================\n",
      "Epoch [4581/5000] | Time: 0.34s\n",
      "(Training) Loss: 917247.7348\n",
      "(Validation) Loss: 725579.9981, MAE: 3152.4470, R2: 0.2620\n",
      "==========================================================================================\n",
      "Epoch [4582/5000] | Time: 0.30s\n",
      "(Training) Loss: 917823.2132\n",
      "(Validation) Loss: 725486.2717, MAE: 3150.2993, R2: 0.2621\n",
      "==========================================================================================\n",
      "Epoch [4583/5000] | Time: 0.32s\n",
      "(Training) Loss: 921320.8737\n",
      "(Validation) Loss: 725406.3098, MAE: 3149.1309, R2: 0.2622\n",
      "==========================================================================================\n",
      "Epoch [4584/5000] | Time: 0.33s\n",
      "(Training) Loss: 899748.2189\n",
      "(Validation) Loss: 725343.5771, MAE: 3152.4915, R2: 0.2622\n",
      "==========================================================================================\n",
      "Epoch [4585/5000] | Time: 0.32s\n",
      "(Training) Loss: 904223.7589\n",
      "(Validation) Loss: 725285.5924, MAE: 3153.1882, R2: 0.2623\n",
      "==========================================================================================\n",
      "Epoch [4586/5000] | Time: 0.38s\n",
      "(Training) Loss: 916157.9296\n",
      "(Validation) Loss: 725184.4337, MAE: 3150.8062, R2: 0.2624\n",
      "==========================================================================================\n",
      "Epoch [4587/5000] | Time: 0.42s\n",
      "(Training) Loss: 906212.1561\n",
      "(Validation) Loss: 725097.9467, MAE: 3149.0654, R2: 0.2625\n",
      "==========================================================================================\n",
      "Epoch [4588/5000] | Time: 0.33s\n",
      "(Training) Loss: 922628.9416\n",
      "(Validation) Loss: 725026.8775, MAE: 3149.8582, R2: 0.2625\n",
      "==========================================================================================\n",
      "Epoch [4589/5000] | Time: 0.33s\n",
      "(Training) Loss: 897365.2265\n",
      "(Validation) Loss: 724936.2806, MAE: 3147.1670, R2: 0.2626\n",
      "==========================================================================================\n",
      "Epoch [4590/5000] | Time: 0.33s\n",
      "(Training) Loss: 909075.6694\n",
      "(Validation) Loss: 724862.7987, MAE: 3147.7651, R2: 0.2627\n",
      "==========================================================================================\n",
      "Epoch [4591/5000] | Time: 0.37s\n",
      "(Training) Loss: 916728.9245\n",
      "(Validation) Loss: 724782.7454, MAE: 3146.3022, R2: 0.2628\n",
      "==========================================================================================\n",
      "Epoch [4592/5000] | Time: 0.34s\n",
      "(Training) Loss: 907184.9454\n",
      "(Validation) Loss: 724709.6089, MAE: 3148.4958, R2: 0.2629\n",
      "==========================================================================================\n",
      "Epoch [4593/5000] | Time: 0.33s\n",
      "(Training) Loss: 915491.3445\n",
      "(Validation) Loss: 724630.9568, MAE: 3147.3232, R2: 0.2629\n",
      "==========================================================================================\n",
      "Epoch [4594/5000] | Time: 0.36s\n",
      "(Training) Loss: 904057.5577\n",
      "(Validation) Loss: 724601.9035, MAE: 3155.7158, R2: 0.2630\n",
      "==========================================================================================\n",
      "Epoch [4595/5000] | Time: 0.31s\n",
      "(Training) Loss: 909680.3763\n",
      "(Validation) Loss: 724498.3676, MAE: 3150.5542, R2: 0.2631\n",
      "==========================================================================================\n",
      "Epoch [4596/5000] | Time: 0.33s\n",
      "(Training) Loss: 915896.9442\n",
      "(Validation) Loss: 724393.3098, MAE: 3145.4893, R2: 0.2632\n",
      "==========================================================================================\n",
      "Epoch [4597/5000] | Time: 0.36s\n",
      "(Training) Loss: 896122.8956\n",
      "(Validation) Loss: 724325.6317, MAE: 3147.3457, R2: 0.2633\n",
      "==========================================================================================\n",
      "Epoch [4598/5000] | Time: 0.33s\n",
      "(Training) Loss: 907888.9562\n",
      "(Validation) Loss: 724255.2076, MAE: 3147.2588, R2: 0.2633\n",
      "==========================================================================================\n",
      "Epoch [4599/5000] | Time: 0.31s\n",
      "(Training) Loss: 897934.3553\n",
      "(Validation) Loss: 724161.0438, MAE: 3143.9546, R2: 0.2634\n",
      "==========================================================================================\n",
      "Epoch [4600/5000] | Time: 0.38s\n",
      "(Training) Loss: 900174.5635\n",
      "(Validation) Loss: 724098.9905, MAE: 3146.4824, R2: 0.2635\n",
      "==========================================================================================\n",
      "Epoch [4601/5000] | Time: 0.40s\n",
      "(Training) Loss: 899537.2870\n",
      "(Validation) Loss: 724017.8330, MAE: 3145.0854, R2: 0.2636\n",
      "==========================================================================================\n",
      "Epoch [4602/5000] | Time: 0.37s\n",
      "(Training) Loss: 898913.8388\n",
      "(Validation) Loss: 723933.6622, MAE: 3144.7026, R2: 0.2636\n",
      "==========================================================================================\n",
      "Epoch [4603/5000] | Time: 0.33s\n",
      "(Training) Loss: 915928.1383\n",
      "(Validation) Loss: 723857.0362, MAE: 3144.3604, R2: 0.2637\n",
      "==========================================================================================\n",
      "Epoch [4604/5000] | Time: 0.33s\n",
      "(Training) Loss: 895738.6155\n",
      "(Validation) Loss: 723783.0857, MAE: 3145.1963, R2: 0.2638\n",
      "==========================================================================================\n",
      "Epoch [4605/5000] | Time: 0.32s\n",
      "(Training) Loss: 897432.7119\n",
      "(Validation) Loss: 723710.7302, MAE: 3145.1035, R2: 0.2639\n",
      "==========================================================================================\n",
      "Epoch [4606/5000] | Time: 0.37s\n",
      "(Training) Loss: 896675.2586\n",
      "(Validation) Loss: 723639.1841, MAE: 3146.2295, R2: 0.2639\n",
      "==========================================================================================\n",
      "Epoch [4607/5000] | Time: 0.31s\n",
      "(Training) Loss: 896647.2278\n",
      "(Validation) Loss: 723574.3187, MAE: 3147.4004, R2: 0.2640\n",
      "==========================================================================================\n",
      "Epoch [4608/5000] | Time: 0.37s\n",
      "(Training) Loss: 907222.5044\n",
      "(Validation) Loss: 723527.0076, MAE: 3149.3840, R2: 0.2641\n",
      "==========================================================================================\n",
      "Epoch [4609/5000] | Time: 0.32s\n",
      "(Training) Loss: 909880.7792\n",
      "(Validation) Loss: 723418.9143, MAE: 3145.9951, R2: 0.2642\n",
      "==========================================================================================\n",
      "Epoch [4610/5000] | Time: 0.34s\n",
      "(Training) Loss: 904819.2357\n",
      "(Validation) Loss: 723317.4000, MAE: 3142.8545, R2: 0.2643\n",
      "==========================================================================================\n",
      "Epoch [4611/5000] | Time: 0.36s\n",
      "(Training) Loss: 912943.3515\n",
      "(Validation) Loss: 723233.4635, MAE: 3140.9521, R2: 0.2644\n",
      "==========================================================================================\n",
      "Epoch [4612/5000] | Time: 0.38s\n",
      "(Training) Loss: 914264.2874\n",
      "(Validation) Loss: 723176.8305, MAE: 3145.1975, R2: 0.2644\n",
      "==========================================================================================\n",
      "Epoch [4613/5000] | Time: 0.32s\n",
      "(Training) Loss: 904295.9746\n",
      "(Validation) Loss: 723086.2800, MAE: 3142.6812, R2: 0.2645\n",
      "==========================================================================================\n",
      "Epoch [4614/5000] | Time: 0.35s\n",
      "(Training) Loss: 908959.0216\n",
      "(Validation) Loss: 723021.6419, MAE: 3145.4460, R2: 0.2646\n",
      "==========================================================================================\n",
      "Epoch [4615/5000] | Time: 0.33s\n",
      "(Training) Loss: 912293.6548\n",
      "(Validation) Loss: 722954.2413, MAE: 3145.4526, R2: 0.2646\n",
      "==========================================================================================\n",
      "Epoch [4616/5000] | Time: 0.34s\n",
      "(Training) Loss: 897142.4410\n",
      "(Validation) Loss: 722853.7276, MAE: 3140.8257, R2: 0.2647\n",
      "==========================================================================================\n",
      "Epoch [4617/5000] | Time: 0.33s\n",
      "(Training) Loss: 907690.5596\n",
      "(Validation) Loss: 722778.5073, MAE: 3141.8889, R2: 0.2648\n",
      "==========================================================================================\n",
      "Epoch [4618/5000] | Time: 0.30s\n",
      "(Training) Loss: 904891.7779\n",
      "(Validation) Loss: 722697.2470, MAE: 3140.9692, R2: 0.2649\n",
      "==========================================================================================\n",
      "Epoch [4619/5000] | Time: 0.32s\n",
      "(Training) Loss: 922304.0742\n",
      "(Validation) Loss: 722635.2889, MAE: 3143.6340, R2: 0.2650\n",
      "==========================================================================================\n",
      "Epoch [4620/5000] | Time: 0.32s\n",
      "(Training) Loss: 902083.2979\n",
      "(Validation) Loss: 722540.6952, MAE: 3141.7810, R2: 0.2651\n",
      "==========================================================================================\n",
      "Epoch [4621/5000] | Time: 0.33s\n",
      "(Training) Loss: 902458.0511\n",
      "(Validation) Loss: 722476.3790, MAE: 3141.4104, R2: 0.2651\n",
      "==========================================================================================\n",
      "Epoch [4622/5000] | Time: 0.31s\n",
      "(Training) Loss: 911999.4867\n",
      "(Validation) Loss: 722391.2260, MAE: 3140.0103, R2: 0.2652\n",
      "==========================================================================================\n",
      "Epoch [4623/5000] | Time: 0.33s\n",
      "(Training) Loss: 926814.0343\n",
      "(Validation) Loss: 722330.7441, MAE: 3144.4907, R2: 0.2653\n",
      "==========================================================================================\n",
      "Epoch [4624/5000] | Time: 0.34s\n",
      "(Training) Loss: 895732.2805\n",
      "(Validation) Loss: 722230.0984, MAE: 3139.2856, R2: 0.2654\n",
      "==========================================================================================\n",
      "Epoch [4625/5000] | Time: 0.36s\n",
      "(Training) Loss: 913923.4670\n",
      "(Validation) Loss: 722163.4870, MAE: 3140.5769, R2: 0.2654\n",
      "==========================================================================================\n",
      "Epoch [4626/5000] | Time: 0.38s\n",
      "(Training) Loss: 893396.8731\n",
      "(Validation) Loss: 722112.1390, MAE: 3145.0352, R2: 0.2655\n",
      "==========================================================================================\n",
      "Epoch [4627/5000] | Time: 0.40s\n",
      "(Training) Loss: 917792.5809\n",
      "(Validation) Loss: 722002.5041, MAE: 3140.5146, R2: 0.2656\n",
      "==========================================================================================\n",
      "Epoch [4628/5000] | Time: 0.39s\n",
      "(Training) Loss: 909599.8230\n",
      "(Validation) Loss: 721926.5530, MAE: 3139.8079, R2: 0.2657\n",
      "==========================================================================================\n",
      "Epoch [4629/5000] | Time: 0.32s\n",
      "(Training) Loss: 897867.8103\n",
      "(Validation) Loss: 721847.0635, MAE: 3139.3711, R2: 0.2658\n",
      "==========================================================================================\n",
      "Epoch [4630/5000] | Time: 0.30s\n",
      "(Training) Loss: 900125.2221\n",
      "(Validation) Loss: 721782.8908, MAE: 3141.0105, R2: 0.2658\n",
      "==========================================================================================\n",
      "Epoch [4631/5000] | Time: 0.31s\n",
      "(Training) Loss: 899105.4727\n",
      "(Validation) Loss: 721719.0933, MAE: 3142.3618, R2: 0.2659\n",
      "==========================================================================================\n",
      "Epoch [4632/5000] | Time: 0.37s\n",
      "(Training) Loss: 897135.5393\n",
      "(Validation) Loss: 721614.3086, MAE: 3137.4463, R2: 0.2660\n",
      "==========================================================================================\n",
      "Epoch [4633/5000] | Time: 0.37s\n",
      "(Training) Loss: 890725.4449\n",
      "(Validation) Loss: 721538.8546, MAE: 3138.2021, R2: 0.2661\n",
      "==========================================================================================\n",
      "Epoch [4634/5000] | Time: 0.31s\n",
      "(Training) Loss: 915928.5317\n",
      "(Validation) Loss: 721477.3149, MAE: 3139.5500, R2: 0.2661\n",
      "==========================================================================================\n",
      "Epoch [4635/5000] | Time: 0.35s\n",
      "(Training) Loss: 902317.2532\n",
      "(Validation) Loss: 721393.6794, MAE: 3138.5859, R2: 0.2662\n",
      "==========================================================================================\n",
      "Epoch [4636/5000] | Time: 0.29s\n",
      "(Training) Loss: 895509.9511\n",
      "(Validation) Loss: 721320.1759, MAE: 3139.9929, R2: 0.2663\n",
      "==========================================================================================\n",
      "Epoch [4637/5000] | Time: 0.32s\n",
      "(Training) Loss: 890347.7588\n",
      "(Validation) Loss: 721235.0495, MAE: 3137.4531, R2: 0.2664\n",
      "==========================================================================================\n",
      "Epoch [4638/5000] | Time: 0.38s\n",
      "(Training) Loss: 899607.2735\n",
      "(Validation) Loss: 721168.3790, MAE: 3138.4375, R2: 0.2664\n",
      "==========================================================================================\n",
      "Epoch [4639/5000] | Time: 0.35s\n",
      "(Training) Loss: 890457.2063\n",
      "(Validation) Loss: 721087.0368, MAE: 3138.0129, R2: 0.2665\n",
      "==========================================================================================\n",
      "Epoch [4640/5000] | Time: 0.32s\n",
      "(Training) Loss: 897324.9093\n",
      "(Validation) Loss: 721031.1308, MAE: 3140.3079, R2: 0.2666\n",
      "==========================================================================================\n",
      "Epoch [4641/5000] | Time: 0.30s\n",
      "(Training) Loss: 914856.6507\n",
      "(Validation) Loss: 720943.1937, MAE: 3139.1409, R2: 0.2667\n",
      "==========================================================================================\n",
      "Epoch [4642/5000] | Time: 0.33s\n",
      "(Training) Loss: 899242.1307\n",
      "(Validation) Loss: 720879.8578, MAE: 3141.0073, R2: 0.2667\n",
      "==========================================================================================\n",
      "Epoch [4643/5000] | Time: 0.32s\n",
      "(Training) Loss: 905054.1980\n",
      "(Validation) Loss: 720794.0165, MAE: 3140.4443, R2: 0.2668\n",
      "==========================================================================================\n",
      "Epoch [4644/5000] | Time: 0.32s\n",
      "(Training) Loss: 890420.2554\n",
      "(Validation) Loss: 720705.0286, MAE: 3137.8713, R2: 0.2669\n",
      "==========================================================================================\n",
      "Epoch [4645/5000] | Time: 0.33s\n",
      "(Training) Loss: 891814.9467\n",
      "(Validation) Loss: 720635.3702, MAE: 3137.9580, R2: 0.2670\n",
      "==========================================================================================\n",
      "Epoch [4646/5000] | Time: 0.33s\n",
      "(Training) Loss: 894894.2595\n",
      "(Validation) Loss: 720563.9911, MAE: 3139.5847, R2: 0.2670\n",
      "==========================================================================================\n",
      "Epoch [4647/5000] | Time: 0.33s\n",
      "(Training) Loss: 896664.5939\n",
      "(Validation) Loss: 720475.2248, MAE: 3137.2375, R2: 0.2671\n",
      "==========================================================================================\n",
      "Epoch [4648/5000] | Time: 0.33s\n",
      "(Training) Loss: 909017.9695\n",
      "(Validation) Loss: 720409.0203, MAE: 3137.9395, R2: 0.2672\n",
      "==========================================================================================\n",
      "Epoch [4649/5000] | Time: 0.34s\n",
      "(Training) Loss: 895536.4537\n",
      "(Validation) Loss: 720322.5137, MAE: 3137.1936, R2: 0.2673\n",
      "==========================================================================================\n",
      "Epoch [4650/5000] | Time: 0.33s\n",
      "(Training) Loss: 895377.1485\n",
      "(Validation) Loss: 720246.5860, MAE: 3135.8975, R2: 0.2674\n",
      "==========================================================================================\n",
      "Epoch [4651/5000] | Time: 0.37s\n",
      "(Training) Loss: 890034.2065\n",
      "(Validation) Loss: 720179.1486, MAE: 3136.6658, R2: 0.2674\n",
      "==========================================================================================\n",
      "Epoch [4652/5000] | Time: 0.32s\n",
      "(Training) Loss: 899154.3268\n",
      "(Validation) Loss: 720098.2279, MAE: 3136.8259, R2: 0.2675\n",
      "==========================================================================================\n",
      "Epoch [4653/5000] | Time: 0.30s\n",
      "(Training) Loss: 904073.1320\n",
      "(Validation) Loss: 720012.6667, MAE: 3134.3435, R2: 0.2676\n",
      "==========================================================================================\n",
      "Epoch [4654/5000] | Time: 0.34s\n",
      "(Training) Loss: 908736.8407\n",
      "(Validation) Loss: 719937.2895, MAE: 3134.7908, R2: 0.2677\n",
      "==========================================================================================\n",
      "Epoch [4655/5000] | Time: 0.35s\n",
      "(Training) Loss: 895273.4937\n",
      "(Validation) Loss: 719892.3397, MAE: 3138.9602, R2: 0.2677\n",
      "==========================================================================================\n",
      "Epoch [4656/5000] | Time: 0.39s\n",
      "(Training) Loss: 902439.3858\n",
      "(Validation) Loss: 719822.2952, MAE: 3139.7229, R2: 0.2678\n",
      "==========================================================================================\n",
      "Epoch [4657/5000] | Time: 0.40s\n",
      "(Training) Loss: 888661.2295\n",
      "(Validation) Loss: 719704.6844, MAE: 3133.2830, R2: 0.2679\n",
      "==========================================================================================\n",
      "Epoch [4658/5000] | Time: 0.33s\n",
      "(Training) Loss: 912945.2411\n",
      "(Validation) Loss: 719630.0311, MAE: 3133.7874, R2: 0.2680\n",
      "==========================================================================================\n",
      "Epoch [4659/5000] | Time: 0.32s\n",
      "(Training) Loss: 890531.7398\n",
      "(Validation) Loss: 719553.9054, MAE: 3134.4775, R2: 0.2681\n",
      "==========================================================================================\n",
      "Epoch [4660/5000] | Time: 0.34s\n",
      "(Training) Loss: 908405.7484\n",
      "(Validation) Loss: 719484.0222, MAE: 3135.1533, R2: 0.2681\n",
      "==========================================================================================\n",
      "Epoch [4661/5000] | Time: 0.32s\n",
      "(Training) Loss: 899750.3484\n",
      "(Validation) Loss: 719418.7549, MAE: 3136.0754, R2: 0.2682\n",
      "==========================================================================================\n",
      "Epoch [4662/5000] | Time: 0.36s\n",
      "(Training) Loss: 927599.0952\n",
      "(Validation) Loss: 719341.2667, MAE: 3135.3083, R2: 0.2683\n",
      "==========================================================================================\n",
      "Epoch [4663/5000] | Time: 0.36s\n",
      "(Training) Loss: 894226.3033\n",
      "(Validation) Loss: 719266.5994, MAE: 3136.3318, R2: 0.2684\n",
      "==========================================================================================\n",
      "Epoch [4664/5000] | Time: 0.32s\n",
      "(Training) Loss: 899369.5495\n",
      "(Validation) Loss: 719173.5302, MAE: 3133.2598, R2: 0.2684\n",
      "==========================================================================================\n",
      "Epoch [4665/5000] | Time: 0.30s\n",
      "(Training) Loss: 894384.2582\n",
      "(Validation) Loss: 719093.1956, MAE: 3132.9792, R2: 0.2685\n",
      "==========================================================================================\n",
      "Epoch [4666/5000] | Time: 0.31s\n",
      "(Training) Loss: 906388.3115\n",
      "(Validation) Loss: 719017.0863, MAE: 3133.8945, R2: 0.2686\n",
      "==========================================================================================\n",
      "Epoch [4667/5000] | Time: 0.34s\n",
      "(Training) Loss: 912058.4524\n",
      "(Validation) Loss: 718953.7670, MAE: 3134.9131, R2: 0.2687\n",
      "==========================================================================================\n",
      "Epoch [4668/5000] | Time: 0.33s\n",
      "(Training) Loss: 894420.4429\n",
      "(Validation) Loss: 718863.6178, MAE: 3133.7874, R2: 0.2688\n",
      "==========================================================================================\n",
      "Epoch [4669/5000] | Time: 0.39s\n",
      "(Training) Loss: 903382.6072\n",
      "(Validation) Loss: 718789.8337, MAE: 3133.9568, R2: 0.2688\n",
      "==========================================================================================\n",
      "Epoch [4670/5000] | Time: 0.35s\n",
      "(Training) Loss: 889001.1604\n",
      "(Validation) Loss: 718723.3365, MAE: 3135.9282, R2: 0.2689\n",
      "==========================================================================================\n",
      "Epoch [4671/5000] | Time: 0.35s\n",
      "(Training) Loss: 892230.8306\n",
      "(Validation) Loss: 718636.7289, MAE: 3132.5183, R2: 0.2690\n",
      "==========================================================================================\n",
      "Epoch [4672/5000] | Time: 0.36s\n",
      "(Training) Loss: 896933.7062\n",
      "(Validation) Loss: 718614.1117, MAE: 3139.3955, R2: 0.2690\n",
      "==========================================================================================\n",
      "Epoch [4673/5000] | Time: 0.40s\n",
      "(Training) Loss: 907545.5457\n",
      "(Validation) Loss: 718474.8057, MAE: 3129.9373, R2: 0.2692\n",
      "==========================================================================================\n",
      "Epoch [4674/5000] | Time: 0.40s\n",
      "(Training) Loss: 895070.1859\n",
      "(Validation) Loss: 718403.7854, MAE: 3132.0198, R2: 0.2692\n",
      "==========================================================================================\n",
      "Epoch [4675/5000] | Time: 0.40s\n",
      "(Training) Loss: 905450.2253\n",
      "(Validation) Loss: 718326.5124, MAE: 3130.8586, R2: 0.2693\n",
      "==========================================================================================\n",
      "Epoch [4676/5000] | Time: 0.32s\n",
      "(Training) Loss: 904277.0000\n",
      "(Validation) Loss: 718244.7721, MAE: 3129.7349, R2: 0.2694\n",
      "==========================================================================================\n",
      "Epoch [4677/5000] | Time: 0.33s\n",
      "(Training) Loss: 903504.0025\n",
      "(Validation) Loss: 718257.6279, MAE: 3139.0352, R2: 0.2694\n",
      "==========================================================================================\n",
      "Epoch [4678/5000] | Time: 0.37s\n",
      "(Training) Loss: 906913.1402\n",
      "(Validation) Loss: 718114.0629, MAE: 3133.4619, R2: 0.2695\n",
      "==========================================================================================\n",
      "Epoch [4679/5000] | Time: 0.41s\n",
      "(Training) Loss: 888484.4987\n",
      "(Validation) Loss: 718094.7994, MAE: 3138.2883, R2: 0.2695\n",
      "==========================================================================================\n",
      "Epoch [4680/5000] | Time: 0.37s\n",
      "(Training) Loss: 894676.8503\n",
      "(Validation) Loss: 717965.1797, MAE: 3133.0540, R2: 0.2697\n",
      "==========================================================================================\n",
      "Epoch [4681/5000] | Time: 0.36s\n",
      "(Training) Loss: 886982.9548\n",
      "(Validation) Loss: 717890.5968, MAE: 3134.5457, R2: 0.2697\n",
      "==========================================================================================\n",
      "Epoch [4682/5000] | Time: 0.40s\n",
      "(Training) Loss: 913587.3388\n",
      "(Validation) Loss: 717819.4673, MAE: 3135.2600, R2: 0.2698\n",
      "==========================================================================================\n",
      "Epoch [4683/5000] | Time: 0.35s\n",
      "(Training) Loss: 894514.2938\n",
      "(Validation) Loss: 717881.4990, MAE: 3142.3232, R2: 0.2698\n",
      "==========================================================================================\n",
      "Epoch [4684/5000] | Time: 0.32s\n",
      "(Training) Loss: 897108.6409\n",
      "(Validation) Loss: 717800.2121, MAE: 3140.2834, R2: 0.2698\n",
      "==========================================================================================\n",
      "Epoch [4685/5000] | Time: 0.32s\n",
      "(Training) Loss: 895855.2069\n",
      "(Validation) Loss: 717727.7898, MAE: 3140.9023, R2: 0.2699\n",
      "==========================================================================================\n",
      "Epoch [4686/5000] | Time: 0.34s\n",
      "(Training) Loss: 895433.6497\n",
      "(Validation) Loss: 717697.1321, MAE: 3146.9531, R2: 0.2699\n",
      "==========================================================================================\n",
      "Epoch [4687/5000] | Time: 0.36s\n",
      "(Training) Loss: 906327.0806\n",
      "(Validation) Loss: 717601.7911, MAE: 3142.7896, R2: 0.2700\n",
      "==========================================================================================\n",
      "Epoch [4688/5000] | Time: 0.31s\n",
      "(Training) Loss: 895536.4213\n",
      "(Validation) Loss: 717494.7092, MAE: 3139.0308, R2: 0.2701\n",
      "==========================================================================================\n",
      "Epoch [4689/5000] | Time: 0.34s\n",
      "(Training) Loss: 895296.4093\n",
      "(Validation) Loss: 717418.6083, MAE: 3138.8291, R2: 0.2702\n",
      "==========================================================================================\n",
      "Epoch [4690/5000] | Time: 0.32s\n",
      "(Training) Loss: 900997.1986\n",
      "(Validation) Loss: 717366.1029, MAE: 3142.1250, R2: 0.2703\n",
      "==========================================================================================\n",
      "Epoch [4691/5000] | Time: 0.36s\n",
      "(Training) Loss: 892036.2157\n",
      "(Validation) Loss: 717262.7917, MAE: 3138.1272, R2: 0.2704\n",
      "==========================================================================================\n",
      "Epoch [4692/5000] | Time: 0.27s\n",
      "(Training) Loss: 911703.4105\n",
      "(Validation) Loss: 717194.5517, MAE: 3139.8894, R2: 0.2704\n",
      "==========================================================================================\n",
      "Epoch [4693/5000] | Time: 0.36s\n",
      "(Training) Loss: 893651.8490\n",
      "(Validation) Loss: 717109.4076, MAE: 3137.8933, R2: 0.2705\n",
      "==========================================================================================\n",
      "Epoch [4694/5000] | Time: 0.35s\n",
      "(Training) Loss: 899872.7427\n",
      "(Validation) Loss: 717047.9702, MAE: 3142.4453, R2: 0.2706\n",
      "==========================================================================================\n",
      "Epoch [4695/5000] | Time: 0.33s\n",
      "(Training) Loss: 894052.3261\n",
      "(Validation) Loss: 716953.3492, MAE: 3136.7461, R2: 0.2707\n",
      "==========================================================================================\n",
      "Epoch [4696/5000] | Time: 0.32s\n",
      "(Training) Loss: 911553.5907\n",
      "(Validation) Loss: 716886.0502, MAE: 3138.0054, R2: 0.2708\n",
      "==========================================================================================\n",
      "Epoch [4697/5000] | Time: 0.38s\n",
      "(Training) Loss: 894692.5863\n",
      "(Validation) Loss: 716803.6470, MAE: 3136.6509, R2: 0.2708\n",
      "==========================================================================================\n",
      "Epoch [4698/5000] | Time: 0.42s\n",
      "(Training) Loss: 903266.6003\n",
      "(Validation) Loss: 716725.5543, MAE: 3135.1978, R2: 0.2709\n",
      "==========================================================================================\n",
      "Epoch [4699/5000] | Time: 0.32s\n",
      "(Training) Loss: 920249.5019\n",
      "(Validation) Loss: 716645.4241, MAE: 3135.2295, R2: 0.2710\n",
      "==========================================================================================\n",
      "Epoch [4700/5000] | Time: 0.34s\n",
      "(Training) Loss: 893812.6206\n",
      "(Validation) Loss: 716567.6375, MAE: 3135.6118, R2: 0.2711\n",
      "==========================================================================================\n",
      "Epoch [4701/5000] | Time: 0.36s\n",
      "(Training) Loss: 923415.1707\n",
      "(Validation) Loss: 716513.0019, MAE: 3138.1492, R2: 0.2711\n",
      "==========================================================================================\n",
      "Epoch [4702/5000] | Time: 0.38s\n",
      "(Training) Loss: 885674.0823\n",
      "(Validation) Loss: 716415.0286, MAE: 3135.4512, R2: 0.2712\n",
      "==========================================================================================\n",
      "Epoch [4703/5000] | Time: 0.38s\n",
      "(Training) Loss: 886244.3694\n",
      "(Validation) Loss: 716343.0235, MAE: 3136.1064, R2: 0.2713\n",
      "==========================================================================================\n",
      "Epoch [4704/5000] | Time: 0.32s\n",
      "(Training) Loss: 905571.5343\n",
      "(Validation) Loss: 716271.7079, MAE: 3136.3374, R2: 0.2714\n",
      "==========================================================================================\n",
      "Epoch [4705/5000] | Time: 0.35s\n",
      "(Training) Loss: 890095.8769\n",
      "(Validation) Loss: 716191.6063, MAE: 3135.7068, R2: 0.2715\n",
      "==========================================================================================\n",
      "Epoch [4706/5000] | Time: 0.34s\n",
      "(Training) Loss: 905595.8249\n",
      "(Validation) Loss: 716113.5232, MAE: 3134.9607, R2: 0.2715\n",
      "==========================================================================================\n",
      "Epoch [4707/5000] | Time: 0.33s\n",
      "(Training) Loss: 902175.1415\n",
      "(Validation) Loss: 716042.0203, MAE: 3135.5198, R2: 0.2716\n",
      "==========================================================================================\n",
      "Epoch [4708/5000] | Time: 0.34s\n",
      "(Training) Loss: 902625.0647\n",
      "(Validation) Loss: 715964.7943, MAE: 3135.8784, R2: 0.2717\n",
      "==========================================================================================\n",
      "Epoch [4709/5000] | Time: 0.38s\n",
      "(Training) Loss: 888639.1694\n",
      "(Validation) Loss: 715886.4819, MAE: 3134.6755, R2: 0.2718\n",
      "==========================================================================================\n",
      "Epoch [4710/5000] | Time: 0.31s\n",
      "(Training) Loss: 902805.9353\n",
      "(Validation) Loss: 715809.9454, MAE: 3133.9177, R2: 0.2718\n",
      "==========================================================================================\n",
      "Epoch [4711/5000] | Time: 0.29s\n",
      "(Training) Loss: 898959.3991\n",
      "(Validation) Loss: 715735.5168, MAE: 3134.1423, R2: 0.2719\n",
      "==========================================================================================\n",
      "Epoch [4712/5000] | Time: 0.33s\n",
      "(Training) Loss: 888810.1390\n",
      "(Validation) Loss: 715652.9352, MAE: 3133.0088, R2: 0.2720\n",
      "==========================================================================================\n",
      "Epoch [4713/5000] | Time: 0.34s\n",
      "(Training) Loss: 906939.4829\n",
      "(Validation) Loss: 715588.2400, MAE: 3134.3164, R2: 0.2721\n",
      "==========================================================================================\n",
      "Epoch [4714/5000] | Time: 0.34s\n",
      "(Training) Loss: 896023.3058\n",
      "(Validation) Loss: 715515.9746, MAE: 3134.9197, R2: 0.2721\n",
      "==========================================================================================\n",
      "Epoch [4715/5000] | Time: 0.36s\n",
      "(Training) Loss: 888772.9886\n",
      "(Validation) Loss: 715423.5263, MAE: 3130.9597, R2: 0.2722\n",
      "==========================================================================================\n",
      "Epoch [4716/5000] | Time: 0.32s\n",
      "(Training) Loss: 907411.5114\n",
      "(Validation) Loss: 715348.1492, MAE: 3131.2751, R2: 0.2723\n",
      "==========================================================================================\n",
      "Epoch [4717/5000] | Time: 0.35s\n",
      "(Training) Loss: 887137.8068\n",
      "(Validation) Loss: 715275.4476, MAE: 3133.6404, R2: 0.2724\n",
      "==========================================================================================\n",
      "Epoch [4718/5000] | Time: 0.35s\n",
      "(Training) Loss: 885388.7313\n",
      "(Validation) Loss: 715193.0197, MAE: 3130.7048, R2: 0.2725\n",
      "==========================================================================================\n",
      "Epoch [4719/5000] | Time: 0.39s\n",
      "(Training) Loss: 901043.0013\n",
      "(Validation) Loss: 715120.6381, MAE: 3132.2312, R2: 0.2725\n",
      "==========================================================================================\n",
      "Epoch [4720/5000] | Time: 0.39s\n",
      "(Training) Loss: 897445.7659\n",
      "(Validation) Loss: 715045.1695, MAE: 3130.8989, R2: 0.2726\n",
      "==========================================================================================\n",
      "Epoch [4721/5000] | Time: 0.33s\n",
      "(Training) Loss: 890040.0869\n",
      "(Validation) Loss: 714972.2610, MAE: 3131.4412, R2: 0.2727\n",
      "==========================================================================================\n",
      "Epoch [4722/5000] | Time: 0.31s\n",
      "(Training) Loss: 890459.7722\n",
      "(Validation) Loss: 714892.3225, MAE: 3131.2749, R2: 0.2728\n",
      "==========================================================================================\n",
      "Epoch [4723/5000] | Time: 0.35s\n",
      "(Training) Loss: 916691.9086\n",
      "(Validation) Loss: 714824.9905, MAE: 3133.1462, R2: 0.2728\n",
      "==========================================================================================\n",
      "Epoch [4724/5000] | Time: 0.33s\n",
      "(Training) Loss: 908544.1992\n",
      "(Validation) Loss: 714746.6610, MAE: 3132.0430, R2: 0.2729\n",
      "==========================================================================================\n",
      "Epoch [4725/5000] | Time: 0.31s\n",
      "(Training) Loss: 897856.5152\n",
      "(Validation) Loss: 714662.0406, MAE: 3130.3101, R2: 0.2730\n",
      "==========================================================================================\n",
      "Epoch [4726/5000] | Time: 0.33s\n",
      "(Training) Loss: 883012.9209\n",
      "(Validation) Loss: 714584.8159, MAE: 3129.9895, R2: 0.2731\n",
      "==========================================================================================\n",
      "Epoch [4727/5000] | Time: 0.35s\n",
      "(Training) Loss: 894463.4898\n",
      "(Validation) Loss: 714534.6927, MAE: 3132.2305, R2: 0.2731\n",
      "==========================================================================================\n",
      "Epoch [4728/5000] | Time: 0.38s\n",
      "(Training) Loss: 889237.1915\n",
      "(Validation) Loss: 714443.9289, MAE: 3131.1514, R2: 0.2732\n",
      "==========================================================================================\n",
      "Epoch [4729/5000] | Time: 0.34s\n",
      "(Training) Loss: 903947.3940\n",
      "(Validation) Loss: 714357.6610, MAE: 3128.7876, R2: 0.2733\n",
      "==========================================================================================\n",
      "Epoch [4730/5000] | Time: 0.33s\n",
      "(Training) Loss: 909548.6098\n",
      "(Validation) Loss: 714281.4343, MAE: 3128.6174, R2: 0.2734\n",
      "==========================================================================================\n",
      "Epoch [4731/5000] | Time: 0.34s\n",
      "(Training) Loss: 891889.1447\n",
      "(Validation) Loss: 714212.6711, MAE: 3130.4314, R2: 0.2735\n",
      "==========================================================================================\n",
      "Epoch [4732/5000] | Time: 0.37s\n",
      "(Training) Loss: 897091.1764\n",
      "(Validation) Loss: 714136.1949, MAE: 3129.3777, R2: 0.2735\n",
      "==========================================================================================\n",
      "Epoch [4733/5000] | Time: 0.34s\n",
      "(Training) Loss: 887951.8487\n",
      "(Validation) Loss: 714052.6343, MAE: 3127.7800, R2: 0.2736\n",
      "==========================================================================================\n",
      "Epoch [4734/5000] | Time: 0.31s\n",
      "(Training) Loss: 881908.2014\n",
      "(Validation) Loss: 713981.7702, MAE: 3128.6121, R2: 0.2737\n",
      "==========================================================================================\n",
      "Epoch [4735/5000] | Time: 0.34s\n",
      "(Training) Loss: 891239.4385\n",
      "(Validation) Loss: 713903.8235, MAE: 3128.6975, R2: 0.2738\n",
      "==========================================================================================\n",
      "Epoch [4736/5000] | Time: 0.34s\n",
      "(Training) Loss: 894252.7100\n",
      "(Validation) Loss: 713835.5340, MAE: 3129.6958, R2: 0.2738\n",
      "==========================================================================================\n",
      "Epoch [4737/5000] | Time: 0.35s\n",
      "(Training) Loss: 894665.7544\n",
      "(Validation) Loss: 713750.9314, MAE: 3127.5288, R2: 0.2739\n",
      "==========================================================================================\n",
      "Epoch [4738/5000] | Time: 0.34s\n",
      "(Training) Loss: 884484.6215\n",
      "(Validation) Loss: 713678.3841, MAE: 3129.1980, R2: 0.2740\n",
      "==========================================================================================\n",
      "Epoch [4739/5000] | Time: 0.38s\n",
      "(Training) Loss: 895567.6929\n",
      "(Validation) Loss: 713599.1562, MAE: 3126.7729, R2: 0.2741\n",
      "==========================================================================================\n",
      "Epoch [4740/5000] | Time: 0.36s\n",
      "(Training) Loss: 882032.7572\n",
      "(Validation) Loss: 713527.1194, MAE: 3126.8276, R2: 0.2741\n",
      "==========================================================================================\n",
      "Epoch [4741/5000] | Time: 0.34s\n",
      "(Training) Loss: 895948.6187\n",
      "(Validation) Loss: 713468.0159, MAE: 3129.8838, R2: 0.2742\n",
      "==========================================================================================\n",
      "Epoch [4742/5000] | Time: 0.32s\n",
      "(Training) Loss: 927440.8141\n",
      "(Validation) Loss: 713379.1111, MAE: 3126.9771, R2: 0.2743\n",
      "==========================================================================================\n",
      "Epoch [4743/5000] | Time: 0.34s\n",
      "(Training) Loss: 895426.5121\n",
      "(Validation) Loss: 713292.0768, MAE: 3125.3665, R2: 0.2744\n",
      "==========================================================================================\n",
      "Epoch [4744/5000] | Time: 0.33s\n",
      "(Training) Loss: 885139.0819\n",
      "(Validation) Loss: 713223.9257, MAE: 3126.3445, R2: 0.2744\n",
      "==========================================================================================\n",
      "Epoch [4745/5000] | Time: 0.27s\n",
      "(Training) Loss: 892281.7043\n",
      "(Validation) Loss: 713149.2470, MAE: 3125.8945, R2: 0.2745\n",
      "==========================================================================================\n",
      "Epoch [4746/5000] | Time: 0.35s\n",
      "(Training) Loss: 887354.5799\n",
      "(Validation) Loss: 713066.5657, MAE: 3125.4092, R2: 0.2746\n",
      "==========================================================================================\n",
      "Epoch [4747/5000] | Time: 0.33s\n",
      "(Training) Loss: 893721.2456\n",
      "(Validation) Loss: 713002.7803, MAE: 3129.3740, R2: 0.2747\n",
      "==========================================================================================\n",
      "Epoch [4748/5000] | Time: 0.29s\n",
      "(Training) Loss: 890101.6123\n",
      "(Validation) Loss: 712920.8514, MAE: 3127.3794, R2: 0.2748\n",
      "==========================================================================================\n",
      "Epoch [4749/5000] | Time: 0.33s\n",
      "(Training) Loss: 893962.0266\n",
      "(Validation) Loss: 712850.5949, MAE: 3126.7285, R2: 0.2748\n",
      "==========================================================================================\n",
      "Epoch [4750/5000] | Time: 0.36s\n",
      "(Training) Loss: 881987.8450\n",
      "(Validation) Loss: 712768.5359, MAE: 3123.7422, R2: 0.2749\n",
      "==========================================================================================\n",
      "Epoch [4751/5000] | Time: 0.31s\n",
      "(Training) Loss: 887928.1256\n",
      "(Validation) Loss: 712691.5594, MAE: 3124.5144, R2: 0.2750\n",
      "==========================================================================================\n",
      "Epoch [4752/5000] | Time: 0.29s\n",
      "(Training) Loss: 904528.1206\n",
      "(Validation) Loss: 712616.0184, MAE: 3124.3037, R2: 0.2751\n",
      "==========================================================================================\n",
      "Epoch [4753/5000] | Time: 0.32s\n",
      "(Training) Loss: 888554.3832\n",
      "(Validation) Loss: 712544.4038, MAE: 3126.8096, R2: 0.2751\n",
      "==========================================================================================\n",
      "Epoch [4754/5000] | Time: 0.36s\n",
      "(Training) Loss: 903545.6662\n",
      "(Validation) Loss: 712471.4686, MAE: 3125.3386, R2: 0.2752\n",
      "==========================================================================================\n",
      "Epoch [4755/5000] | Time: 0.31s\n",
      "(Training) Loss: 901911.2379\n",
      "(Validation) Loss: 712386.2768, MAE: 3123.3857, R2: 0.2753\n",
      "==========================================================================================\n",
      "Epoch [4756/5000] | Time: 0.33s\n",
      "(Training) Loss: 892412.0596\n",
      "(Validation) Loss: 712307.9505, MAE: 3122.6597, R2: 0.2754\n",
      "==========================================================================================\n",
      "Epoch [4757/5000] | Time: 0.31s\n",
      "(Training) Loss: 896969.4816\n",
      "(Validation) Loss: 712238.0127, MAE: 3124.9346, R2: 0.2754\n",
      "==========================================================================================\n",
      "Epoch [4758/5000] | Time: 0.35s\n",
      "(Training) Loss: 893917.0533\n",
      "(Validation) Loss: 712160.6038, MAE: 3120.9714, R2: 0.2755\n",
      "==========================================================================================\n",
      "Epoch [4759/5000] | Time: 0.36s\n",
      "(Training) Loss: 889221.5609\n",
      "(Validation) Loss: 712081.3600, MAE: 3122.7012, R2: 0.2756\n",
      "==========================================================================================\n",
      "Epoch [4760/5000] | Time: 0.33s\n",
      "(Training) Loss: 891592.1701\n",
      "(Validation) Loss: 712003.3448, MAE: 3119.7878, R2: 0.2757\n",
      "==========================================================================================\n",
      "Epoch [4761/5000] | Time: 0.35s\n",
      "(Training) Loss: 904215.9207\n",
      "(Validation) Loss: 711957.6057, MAE: 3123.3381, R2: 0.2757\n",
      "==========================================================================================\n",
      "Epoch [4762/5000] | Time: 0.35s\n",
      "(Training) Loss: 884012.7798\n",
      "(Validation) Loss: 711851.7721, MAE: 3119.4099, R2: 0.2758\n",
      "==========================================================================================\n",
      "Epoch [4763/5000] | Time: 0.34s\n",
      "(Training) Loss: 891104.1104\n",
      "(Validation) Loss: 711779.5930, MAE: 3121.0095, R2: 0.2759\n",
      "==========================================================================================\n",
      "Epoch [4764/5000] | Time: 0.31s\n",
      "(Training) Loss: 889695.6352\n",
      "(Validation) Loss: 711704.4133, MAE: 3120.5225, R2: 0.2760\n",
      "==========================================================================================\n",
      "Epoch [4765/5000] | Time: 0.37s\n",
      "(Training) Loss: 896626.0698\n",
      "(Validation) Loss: 711631.6552, MAE: 3121.7729, R2: 0.2761\n",
      "==========================================================================================\n",
      "Epoch [4766/5000] | Time: 0.35s\n",
      "(Training) Loss: 886515.2760\n",
      "(Validation) Loss: 711551.3225, MAE: 3120.2661, R2: 0.2761\n",
      "==========================================================================================\n",
      "Epoch [4767/5000] | Time: 0.35s\n",
      "(Training) Loss: 882504.2154\n",
      "(Validation) Loss: 711479.4971, MAE: 3121.0876, R2: 0.2762\n",
      "==========================================================================================\n",
      "Epoch [4768/5000] | Time: 0.35s\n",
      "(Training) Loss: 884817.9365\n",
      "(Validation) Loss: 711405.6368, MAE: 3120.4055, R2: 0.2763\n",
      "==========================================================================================\n",
      "Epoch [4769/5000] | Time: 0.35s\n",
      "(Training) Loss: 895171.1095\n",
      "(Validation) Loss: 711326.6089, MAE: 3118.5251, R2: 0.2764\n",
      "==========================================================================================\n",
      "Epoch [4770/5000] | Time: 0.36s\n",
      "(Training) Loss: 907692.8328\n",
      "(Validation) Loss: 711251.2730, MAE: 3120.2969, R2: 0.2764\n",
      "==========================================================================================\n",
      "Epoch [4771/5000] | Time: 0.39s\n",
      "(Training) Loss: 894218.5882\n",
      "(Validation) Loss: 711184.8825, MAE: 3120.0000, R2: 0.2765\n",
      "==========================================================================================\n",
      "Epoch [4772/5000] | Time: 0.40s\n",
      "(Training) Loss: 881604.1932\n",
      "(Validation) Loss: 711102.0749, MAE: 3119.4990, R2: 0.2766\n",
      "==========================================================================================\n",
      "Epoch [4773/5000] | Time: 0.37s\n",
      "(Training) Loss: 890897.1999\n",
      "(Validation) Loss: 711021.7924, MAE: 3118.6304, R2: 0.2767\n",
      "==========================================================================================\n",
      "Epoch [4774/5000] | Time: 0.34s\n",
      "(Training) Loss: 888566.0622\n",
      "(Validation) Loss: 710950.4241, MAE: 3118.3762, R2: 0.2767\n",
      "==========================================================================================\n",
      "Epoch [4775/5000] | Time: 0.37s\n",
      "(Training) Loss: 882382.3775\n",
      "(Validation) Loss: 710875.8908, MAE: 3118.5515, R2: 0.2768\n",
      "==========================================================================================\n",
      "Epoch [4776/5000] | Time: 0.38s\n",
      "(Training) Loss: 894070.6110\n",
      "(Validation) Loss: 710800.2775, MAE: 3118.3940, R2: 0.2769\n",
      "==========================================================================================\n",
      "Epoch [4777/5000] | Time: 0.33s\n",
      "(Training) Loss: 881583.8058\n",
      "(Validation) Loss: 710733.2902, MAE: 3120.3989, R2: 0.2770\n",
      "==========================================================================================\n",
      "Epoch [4778/5000] | Time: 0.32s\n",
      "(Training) Loss: 910408.1612\n",
      "(Validation) Loss: 710662.4038, MAE: 3119.7429, R2: 0.2770\n",
      "==========================================================================================\n",
      "Epoch [4779/5000] | Time: 0.38s\n",
      "(Training) Loss: 879872.7002\n",
      "(Validation) Loss: 710577.6273, MAE: 3118.5557, R2: 0.2771\n",
      "==========================================================================================\n",
      "Epoch [4780/5000] | Time: 0.38s\n",
      "(Training) Loss: 892823.9886\n",
      "(Validation) Loss: 710497.1365, MAE: 3117.1741, R2: 0.2772\n",
      "==========================================================================================\n",
      "Epoch [4781/5000] | Time: 0.34s\n",
      "(Training) Loss: 898420.8188\n",
      "(Validation) Loss: 710428.9467, MAE: 3118.4150, R2: 0.2773\n",
      "==========================================================================================\n",
      "Epoch [4782/5000] | Time: 0.33s\n",
      "(Training) Loss: 905872.0787\n",
      "(Validation) Loss: 710343.3175, MAE: 3116.9924, R2: 0.2774\n",
      "==========================================================================================\n",
      "Epoch [4783/5000] | Time: 0.32s\n",
      "(Training) Loss: 900200.6174\n",
      "(Validation) Loss: 710271.3898, MAE: 3118.0432, R2: 0.2774\n",
      "==========================================================================================\n",
      "Epoch [4784/5000] | Time: 0.31s\n",
      "(Training) Loss: 903721.7608\n",
      "(Validation) Loss: 710200.1054, MAE: 3116.8608, R2: 0.2775\n",
      "==========================================================================================\n",
      "Epoch [4785/5000] | Time: 0.34s\n",
      "(Training) Loss: 895110.4143\n",
      "(Validation) Loss: 710119.8559, MAE: 3116.8032, R2: 0.2776\n",
      "==========================================================================================\n",
      "Epoch [4786/5000] | Time: 0.34s\n",
      "(Training) Loss: 890209.8071\n",
      "(Validation) Loss: 710038.1676, MAE: 3115.4231, R2: 0.2777\n",
      "==========================================================================================\n",
      "Epoch [4787/5000] | Time: 0.34s\n",
      "(Training) Loss: 890899.0977\n",
      "(Validation) Loss: 709969.6971, MAE: 3117.5603, R2: 0.2777\n",
      "==========================================================================================\n",
      "Epoch [4788/5000] | Time: 0.35s\n",
      "(Training) Loss: 889449.4150\n",
      "(Validation) Loss: 709889.1371, MAE: 3115.6091, R2: 0.2778\n",
      "==========================================================================================\n",
      "Epoch [4789/5000] | Time: 0.31s\n",
      "(Training) Loss: 893378.9010\n",
      "(Validation) Loss: 709820.5505, MAE: 3116.6892, R2: 0.2779\n",
      "==========================================================================================\n",
      "Epoch [4790/5000] | Time: 0.32s\n",
      "(Training) Loss: 923107.0006\n",
      "(Validation) Loss: 709739.7359, MAE: 3117.4453, R2: 0.2780\n",
      "==========================================================================================\n",
      "Epoch [4791/5000] | Time: 0.36s\n",
      "(Training) Loss: 891697.2779\n",
      "(Validation) Loss: 709665.2635, MAE: 3116.1162, R2: 0.2780\n",
      "==========================================================================================\n",
      "Epoch [4792/5000] | Time: 0.34s\n",
      "(Training) Loss: 902691.5393\n",
      "(Validation) Loss: 709583.4514, MAE: 3114.8530, R2: 0.2781\n",
      "==========================================================================================\n",
      "Epoch [4793/5000] | Time: 0.33s\n",
      "(Training) Loss: 890945.9530\n",
      "(Validation) Loss: 709507.7467, MAE: 3115.0144, R2: 0.2782\n",
      "==========================================================================================\n",
      "Epoch [4794/5000] | Time: 0.31s\n",
      "(Training) Loss: 898398.9753\n",
      "(Validation) Loss: 709436.6990, MAE: 3115.7727, R2: 0.2783\n",
      "==========================================================================================\n",
      "Epoch [4795/5000] | Time: 0.32s\n",
      "(Training) Loss: 880084.8598\n",
      "(Validation) Loss: 709360.3003, MAE: 3116.4285, R2: 0.2783\n",
      "==========================================================================================\n",
      "Epoch [4796/5000] | Time: 0.31s\n",
      "(Training) Loss: 887739.0482\n",
      "(Validation) Loss: 709286.9600, MAE: 3115.0115, R2: 0.2784\n",
      "==========================================================================================\n",
      "Epoch [4797/5000] | Time: 0.32s\n",
      "(Training) Loss: 883789.1307\n",
      "(Validation) Loss: 709213.3283, MAE: 3116.8159, R2: 0.2785\n",
      "==========================================================================================\n",
      "Epoch [4798/5000] | Time: 0.31s\n",
      "(Training) Loss: 881797.9074\n",
      "(Validation) Loss: 709151.0540, MAE: 3117.5698, R2: 0.2786\n",
      "==========================================================================================\n",
      "Epoch [4799/5000] | Time: 0.33s\n",
      "(Training) Loss: 882161.7360\n",
      "(Validation) Loss: 709058.7003, MAE: 3113.2800, R2: 0.2787\n",
      "==========================================================================================\n",
      "Epoch [4800/5000] | Time: 0.33s\n",
      "(Training) Loss: 887322.0964\n",
      "(Validation) Loss: 708990.3549, MAE: 3114.8972, R2: 0.2787\n",
      "==========================================================================================\n",
      "Epoch [4801/5000] | Time: 0.33s\n",
      "(Training) Loss: 882544.4810\n",
      "(Validation) Loss: 708910.2965, MAE: 3113.5361, R2: 0.2788\n",
      "==========================================================================================\n",
      "Epoch [4802/5000] | Time: 0.31s\n",
      "(Training) Loss: 897747.7043\n",
      "(Validation) Loss: 708847.2190, MAE: 3114.4136, R2: 0.2789\n",
      "==========================================================================================\n",
      "Epoch [4803/5000] | Time: 0.32s\n",
      "(Training) Loss: 875978.7564\n",
      "(Validation) Loss: 708759.7784, MAE: 3113.2517, R2: 0.2790\n",
      "==========================================================================================\n",
      "Epoch [4804/5000] | Time: 0.30s\n",
      "(Training) Loss: 879435.9610\n",
      "(Validation) Loss: 708697.9460, MAE: 3115.6614, R2: 0.2790\n",
      "==========================================================================================\n",
      "Epoch [4805/5000] | Time: 0.29s\n",
      "(Training) Loss: 881993.1072\n",
      "(Validation) Loss: 708616.5956, MAE: 3114.0066, R2: 0.2791\n",
      "==========================================================================================\n",
      "Epoch [4806/5000] | Time: 0.33s\n",
      "(Training) Loss: 876134.3652\n",
      "(Validation) Loss: 708544.0679, MAE: 3117.4058, R2: 0.2792\n",
      "==========================================================================================\n",
      "Epoch [4807/5000] | Time: 0.34s\n",
      "(Training) Loss: 886288.5673\n",
      "(Validation) Loss: 708466.4990, MAE: 3113.9866, R2: 0.2793\n",
      "==========================================================================================\n",
      "Epoch [4808/5000] | Time: 0.32s\n",
      "(Training) Loss: 880890.5536\n",
      "(Validation) Loss: 708389.8330, MAE: 3111.2883, R2: 0.2793\n",
      "==========================================================================================\n",
      "Epoch [4809/5000] | Time: 0.32s\n",
      "(Training) Loss: 882399.7265\n",
      "(Validation) Loss: 708329.0356, MAE: 3114.3391, R2: 0.2794\n",
      "==========================================================================================\n",
      "Epoch [4810/5000] | Time: 0.37s\n",
      "(Training) Loss: 883353.8794\n",
      "(Validation) Loss: 708237.3835, MAE: 3109.9778, R2: 0.2795\n",
      "==========================================================================================\n",
      "Epoch [4811/5000] | Time: 0.31s\n",
      "(Training) Loss: 886969.4023\n",
      "(Validation) Loss: 708228.7270, MAE: 3120.7361, R2: 0.2795\n",
      "==========================================================================================\n",
      "Epoch [4812/5000] | Time: 0.32s\n",
      "(Training) Loss: 878309.8924\n",
      "(Validation) Loss: 708087.4114, MAE: 3110.1816, R2: 0.2796\n",
      "==========================================================================================\n",
      "Epoch [4813/5000] | Time: 0.38s\n",
      "(Training) Loss: 884862.5025\n",
      "(Validation) Loss: 708021.6432, MAE: 3110.7896, R2: 0.2797\n",
      "==========================================================================================\n",
      "Epoch [4814/5000] | Time: 0.37s\n",
      "(Training) Loss: 886603.7475\n",
      "(Validation) Loss: 707949.6813, MAE: 3111.4480, R2: 0.2798\n",
      "==========================================================================================\n",
      "Epoch [4815/5000] | Time: 0.38s\n",
      "(Training) Loss: 885085.0552\n",
      "(Validation) Loss: 707862.7397, MAE: 3108.9058, R2: 0.2799\n",
      "==========================================================================================\n",
      "Epoch [4816/5000] | Time: 0.36s\n",
      "(Training) Loss: 877717.9553\n",
      "(Validation) Loss: 707788.2679, MAE: 3110.6467, R2: 0.2799\n",
      "==========================================================================================\n",
      "Epoch [4817/5000] | Time: 0.32s\n",
      "(Training) Loss: 885610.3547\n",
      "(Validation) Loss: 707713.4908, MAE: 3112.1460, R2: 0.2800\n",
      "==========================================================================================\n",
      "Epoch [4818/5000] | Time: 0.33s\n",
      "(Training) Loss: 875301.5414\n",
      "(Validation) Loss: 707636.2521, MAE: 3109.0488, R2: 0.2801\n",
      "==========================================================================================\n",
      "Epoch [4819/5000] | Time: 0.30s\n",
      "(Training) Loss: 892903.5673\n",
      "(Validation) Loss: 707565.7606, MAE: 3108.5334, R2: 0.2802\n",
      "==========================================================================================\n",
      "Epoch [4820/5000] | Time: 0.32s\n",
      "(Training) Loss: 880643.6104\n",
      "(Validation) Loss: 707488.0768, MAE: 3108.4988, R2: 0.2802\n",
      "==========================================================================================\n",
      "Epoch [4821/5000] | Time: 0.34s\n",
      "(Training) Loss: 893480.5178\n",
      "(Validation) Loss: 707430.8051, MAE: 3111.4004, R2: 0.2803\n",
      "==========================================================================================\n",
      "Epoch [4822/5000] | Time: 0.33s\n",
      "(Training) Loss: 884590.4042\n",
      "(Validation) Loss: 707341.3270, MAE: 3109.5559, R2: 0.2804\n",
      "==========================================================================================\n",
      "Epoch [4823/5000] | Time: 0.33s\n",
      "(Training) Loss: 882467.6726\n",
      "(Validation) Loss: 707261.2851, MAE: 3108.6372, R2: 0.2805\n",
      "==========================================================================================\n",
      "Epoch [4824/5000] | Time: 0.33s\n",
      "(Training) Loss: 886358.6196\n",
      "(Validation) Loss: 707207.7587, MAE: 3111.9961, R2: 0.2805\n",
      "==========================================================================================\n",
      "Epoch [4825/5000] | Time: 0.29s\n",
      "(Training) Loss: 898866.3135\n",
      "(Validation) Loss: 707116.0749, MAE: 3107.6445, R2: 0.2806\n",
      "==========================================================================================\n",
      "Epoch [4826/5000] | Time: 0.30s\n",
      "(Training) Loss: 877715.1923\n",
      "(Validation) Loss: 707045.0317, MAE: 3109.4341, R2: 0.2807\n",
      "==========================================================================================\n",
      "Epoch [4827/5000] | Time: 0.32s\n",
      "(Training) Loss: 876925.6640\n",
      "(Validation) Loss: 706967.6806, MAE: 3108.3955, R2: 0.2808\n",
      "==========================================================================================\n",
      "Epoch [4828/5000] | Time: 0.33s\n",
      "(Training) Loss: 874278.7406\n",
      "(Validation) Loss: 706889.6413, MAE: 3108.2666, R2: 0.2808\n",
      "==========================================================================================\n",
      "Epoch [4829/5000] | Time: 0.33s\n",
      "(Training) Loss: 884926.3490\n",
      "(Validation) Loss: 706816.4063, MAE: 3108.4429, R2: 0.2809\n",
      "==========================================================================================\n",
      "Epoch [4830/5000] | Time: 0.35s\n",
      "(Training) Loss: 877485.3382\n",
      "(Validation) Loss: 706745.3778, MAE: 3108.1599, R2: 0.2810\n",
      "==========================================================================================\n",
      "Epoch [4831/5000] | Time: 0.34s\n",
      "(Training) Loss: 893630.3433\n",
      "(Validation) Loss: 706668.9067, MAE: 3106.6709, R2: 0.2811\n",
      "==========================================================================================\n",
      "Epoch [4832/5000] | Time: 0.33s\n",
      "(Training) Loss: 890121.2951\n",
      "(Validation) Loss: 706608.9397, MAE: 3109.7993, R2: 0.2811\n",
      "==========================================================================================\n",
      "Epoch [4833/5000] | Time: 0.32s\n",
      "(Training) Loss: 879808.6567\n",
      "(Validation) Loss: 706523.5206, MAE: 3108.5913, R2: 0.2812\n",
      "==========================================================================================\n",
      "Epoch [4834/5000] | Time: 0.35s\n",
      "(Training) Loss: 876870.1894\n",
      "(Validation) Loss: 706436.6216, MAE: 3104.3623, R2: 0.2813\n",
      "==========================================================================================\n",
      "Epoch [4835/5000] | Time: 0.39s\n",
      "(Training) Loss: 878559.3154\n",
      "(Validation) Loss: 706364.7594, MAE: 3105.2483, R2: 0.2814\n",
      "==========================================================================================\n",
      "Epoch [4836/5000] | Time: 0.35s\n",
      "(Training) Loss: 886315.1853\n",
      "(Validation) Loss: 706317.5835, MAE: 3110.8188, R2: 0.2814\n",
      "==========================================================================================\n",
      "Epoch [4837/5000] | Time: 0.37s\n",
      "(Training) Loss: 895617.9226\n",
      "(Validation) Loss: 706245.3517, MAE: 3112.1289, R2: 0.2815\n",
      "==========================================================================================\n",
      "Epoch [4838/5000] | Time: 0.35s\n",
      "(Training) Loss: 903490.6085\n",
      "(Validation) Loss: 706170.3010, MAE: 3110.8328, R2: 0.2816\n",
      "==========================================================================================\n",
      "Epoch [4839/5000] | Time: 0.35s\n",
      "(Training) Loss: 894619.9400\n",
      "(Validation) Loss: 706070.0883, MAE: 3106.1780, R2: 0.2817\n",
      "==========================================================================================\n",
      "Epoch [4840/5000] | Time: 0.38s\n",
      "(Training) Loss: 889440.3046\n",
      "(Validation) Loss: 705988.8686, MAE: 3105.8804, R2: 0.2818\n",
      "==========================================================================================\n",
      "Epoch [4841/5000] | Time: 0.35s\n",
      "(Training) Loss: 919798.4784\n",
      "(Validation) Loss: 749820.0178, MAE: 3226.3735, R2: 0.2375\n",
      "==========================================================================================\n",
      "Epoch [4842/5000] | Time: 0.33s\n",
      "(Training) Loss: 925958.3978\n",
      "(Validation) Loss: 749723.4622, MAE: 3224.4231, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [4843/5000] | Time: 0.43s\n",
      "(Training) Loss: 924236.3820\n",
      "(Validation) Loss: 749645.2730, MAE: 3225.0532, R2: 0.2377\n",
      "==========================================================================================\n",
      "Epoch [4844/5000] | Time: 0.39s\n",
      "(Training) Loss: 938943.9670\n",
      "(Validation) Loss: 749560.3575, MAE: 3224.7461, R2: 0.2378\n",
      "==========================================================================================\n",
      "Epoch [4845/5000] | Time: 0.42s\n",
      "(Training) Loss: 935201.1472\n",
      "(Validation) Loss: 749472.3543, MAE: 3224.2061, R2: 0.2379\n",
      "==========================================================================================\n",
      "Epoch [4846/5000] | Time: 0.35s\n",
      "(Training) Loss: 936687.4258\n",
      "(Validation) Loss: 749383.3289, MAE: 3223.4771, R2: 0.2380\n",
      "==========================================================================================\n",
      "Epoch [4847/5000] | Time: 0.36s\n",
      "(Training) Loss: 925659.7716\n",
      "(Validation) Loss: 749295.5460, MAE: 3222.4412, R2: 0.2381\n",
      "==========================================================================================\n",
      "Epoch [4848/5000] | Time: 0.33s\n",
      "(Training) Loss: 937352.7322\n",
      "(Validation) Loss: 749211.4317, MAE: 3223.1553, R2: 0.2382\n",
      "==========================================================================================\n",
      "Epoch [4849/5000] | Time: 0.37s\n",
      "(Training) Loss: 936117.0102\n",
      "(Validation) Loss: 749131.3010, MAE: 3222.3054, R2: 0.2382\n",
      "==========================================================================================\n",
      "Epoch [4850/5000] | Time: 0.32s\n",
      "(Training) Loss: 957818.9759\n",
      "(Validation) Loss: 749054.9733, MAE: 3222.1064, R2: 0.2383\n",
      "==========================================================================================\n",
      "Epoch [4851/5000] | Time: 0.40s\n",
      "(Training) Loss: 932602.4505\n",
      "(Validation) Loss: 748974.1790, MAE: 3223.1138, R2: 0.2384\n",
      "==========================================================================================\n",
      "Epoch [4852/5000] | Time: 0.38s\n",
      "(Training) Loss: 938402.0571\n",
      "(Validation) Loss: 748884.3098, MAE: 3222.3179, R2: 0.2385\n",
      "==========================================================================================\n",
      "Epoch [4853/5000] | Time: 0.38s\n",
      "(Training) Loss: 941909.3522\n",
      "(Validation) Loss: 748793.6895, MAE: 3221.4885, R2: 0.2386\n",
      "==========================================================================================\n",
      "Epoch [4854/5000] | Time: 0.35s\n",
      "(Training) Loss: 932734.1694\n",
      "(Validation) Loss: 748697.4095, MAE: 3218.6133, R2: 0.2387\n",
      "==========================================================================================\n",
      "Epoch [4855/5000] | Time: 0.36s\n",
      "(Training) Loss: 948602.6942\n",
      "(Validation) Loss: 748615.3790, MAE: 3219.4834, R2: 0.2388\n",
      "==========================================================================================\n",
      "Epoch [4856/5000] | Time: 0.37s\n",
      "(Training) Loss: 927461.1653\n",
      "(Validation) Loss: 748550.6216, MAE: 3223.2656, R2: 0.2388\n",
      "==========================================================================================\n",
      "Epoch [4857/5000] | Time: 0.33s\n",
      "(Training) Loss: 960332.8471\n",
      "(Validation) Loss: 748448.8571, MAE: 3219.6917, R2: 0.2389\n",
      "==========================================================================================\n",
      "Epoch [4858/5000] | Time: 0.39s\n",
      "(Training) Loss: 938695.2430\n",
      "(Validation) Loss: 748374.5911, MAE: 3221.9111, R2: 0.2390\n",
      "==========================================================================================\n",
      "Epoch [4859/5000] | Time: 0.43s\n",
      "(Training) Loss: 935464.9905\n",
      "(Validation) Loss: 745569.4368, MAE: 3211.6216, R2: 0.2418\n",
      "==========================================================================================\n",
      "Epoch [4860/5000] | Time: 0.40s\n",
      "(Training) Loss: 915651.3729\n",
      "(Validation) Loss: 741713.6108, MAE: 3200.9082, R2: 0.2457\n",
      "==========================================================================================\n",
      "Epoch [4861/5000] | Time: 0.39s\n",
      "(Training) Loss: 914850.5108\n",
      "(Validation) Loss: 741622.8902, MAE: 3196.5603, R2: 0.2458\n",
      "==========================================================================================\n",
      "Epoch [4862/5000] | Time: 0.36s\n",
      "(Training) Loss: 932289.0482\n",
      "(Validation) Loss: 741536.7975, MAE: 3193.9727, R2: 0.2459\n",
      "==========================================================================================\n",
      "Epoch [4863/5000] | Time: 0.34s\n",
      "(Training) Loss: 926669.7138\n",
      "(Validation) Loss: 741455.9295, MAE: 3193.3855, R2: 0.2460\n",
      "==========================================================================================\n",
      "Epoch [4864/5000] | Time: 0.37s\n",
      "(Training) Loss: 917123.2674\n",
      "(Validation) Loss: 741379.5524, MAE: 3192.8115, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [4865/5000] | Time: 0.32s\n",
      "(Training) Loss: 935542.6878\n",
      "(Validation) Loss: 741307.5124, MAE: 3194.5774, R2: 0.2461\n",
      "==========================================================================================\n",
      "Epoch [4866/5000] | Time: 0.38s\n",
      "(Training) Loss: 916140.4016\n",
      "(Validation) Loss: 741220.8483, MAE: 3192.7180, R2: 0.2462\n",
      "==========================================================================================\n",
      "Epoch [4867/5000] | Time: 0.35s\n",
      "(Training) Loss: 914104.9497\n",
      "(Validation) Loss: 741148.3600, MAE: 3193.3264, R2: 0.2463\n",
      "==========================================================================================\n",
      "Epoch [4868/5000] | Time: 0.36s\n",
      "(Training) Loss: 924369.6136\n",
      "(Validation) Loss: 741083.2679, MAE: 3197.5520, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [4869/5000] | Time: 0.36s\n",
      "(Training) Loss: 913133.7822\n",
      "(Validation) Loss: 740991.8743, MAE: 3193.2588, R2: 0.2464\n",
      "==========================================================================================\n",
      "Epoch [4870/5000] | Time: 0.40s\n",
      "(Training) Loss: 924832.9470\n",
      "(Validation) Loss: 740910.6597, MAE: 3193.1418, R2: 0.2465\n",
      "==========================================================================================\n",
      "Epoch [4871/5000] | Time: 0.42s\n",
      "(Training) Loss: 922875.7919\n",
      "(Validation) Loss: 740837.1657, MAE: 3192.3381, R2: 0.2466\n",
      "==========================================================================================\n",
      "Epoch [4872/5000] | Time: 0.38s\n",
      "(Training) Loss: 932731.9543\n",
      "(Validation) Loss: 740752.9263, MAE: 3190.1218, R2: 0.2467\n",
      "==========================================================================================\n",
      "Epoch [4873/5000] | Time: 0.38s\n",
      "(Training) Loss: 915855.4321\n",
      "(Validation) Loss: 740686.0076, MAE: 3194.9517, R2: 0.2468\n",
      "==========================================================================================\n",
      "Epoch [4874/5000] | Time: 0.37s\n",
      "(Training) Loss: 929008.3988\n",
      "(Validation) Loss: 740600.8546, MAE: 3192.5537, R2: 0.2468\n",
      "==========================================================================================\n",
      "Epoch [4875/5000] | Time: 0.34s\n",
      "(Training) Loss: 950052.3915\n",
      "(Validation) Loss: 740524.1473, MAE: 3193.0737, R2: 0.2469\n",
      "==========================================================================================\n",
      "Epoch [4876/5000] | Time: 0.36s\n",
      "(Training) Loss: 943421.4296\n",
      "(Validation) Loss: 740439.7886, MAE: 3192.8667, R2: 0.2470\n",
      "==========================================================================================\n",
      "Epoch [4877/5000] | Time: 0.36s\n",
      "(Training) Loss: 913350.6004\n",
      "(Validation) Loss: 740358.4552, MAE: 3190.0728, R2: 0.2471\n",
      "==========================================================================================\n",
      "Epoch [4878/5000] | Time: 0.36s\n",
      "(Training) Loss: 914844.7218\n",
      "(Validation) Loss: 740292.1683, MAE: 3191.0571, R2: 0.2472\n",
      "==========================================================================================\n",
      "Epoch [4879/5000] | Time: 0.36s\n",
      "(Training) Loss: 919489.4429\n",
      "(Validation) Loss: 740223.6248, MAE: 3191.8904, R2: 0.2472\n",
      "==========================================================================================\n",
      "Epoch [4880/5000] | Time: 0.34s\n",
      "(Training) Loss: 932871.3585\n",
      "(Validation) Loss: 740133.1270, MAE: 3190.7053, R2: 0.2473\n",
      "==========================================================================================\n",
      "Epoch [4881/5000] | Time: 0.33s\n",
      "(Training) Loss: 917267.8763\n",
      "(Validation) Loss: 740055.8330, MAE: 3190.7061, R2: 0.2474\n",
      "==========================================================================================\n",
      "Epoch [4882/5000] | Time: 0.33s\n",
      "(Training) Loss: 926000.5990\n",
      "(Validation) Loss: 739973.5244, MAE: 3188.7324, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [4883/5000] | Time: 0.34s\n",
      "(Training) Loss: 935689.5844\n",
      "(Validation) Loss: 739920.3086, MAE: 3192.1328, R2: 0.2475\n",
      "==========================================================================================\n",
      "Epoch [4884/5000] | Time: 0.37s\n",
      "(Training) Loss: 924826.5431\n",
      "(Validation) Loss: 739825.8184, MAE: 3191.7715, R2: 0.2476\n",
      "==========================================================================================\n",
      "Epoch [4885/5000] | Time: 0.36s\n",
      "(Training) Loss: 919448.9451\n",
      "(Validation) Loss: 739748.8762, MAE: 3190.8918, R2: 0.2477\n",
      "==========================================================================================\n",
      "Epoch [4886/5000] | Time: 0.37s\n",
      "(Training) Loss: 933869.2316\n",
      "(Validation) Loss: 739668.1460, MAE: 3191.3403, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [4887/5000] | Time: 0.35s\n",
      "(Training) Loss: 926528.3547\n",
      "(Validation) Loss: 739607.3829, MAE: 3190.6472, R2: 0.2478\n",
      "==========================================================================================\n",
      "Epoch [4888/5000] | Time: 0.33s\n",
      "(Training) Loss: 946730.4048\n",
      "(Validation) Loss: 739555.4521, MAE: 3200.6912, R2: 0.2479\n",
      "==========================================================================================\n",
      "Epoch [4889/5000] | Time: 0.37s\n",
      "(Training) Loss: 923689.9829\n",
      "(Validation) Loss: 739438.3295, MAE: 3191.1904, R2: 0.2480\n",
      "==========================================================================================\n",
      "Epoch [4890/5000] | Time: 0.36s\n",
      "(Training) Loss: 920748.6155\n",
      "(Validation) Loss: 739352.6552, MAE: 3189.1006, R2: 0.2481\n",
      "==========================================================================================\n",
      "Epoch [4891/5000] | Time: 0.35s\n",
      "(Training) Loss: 933980.2189\n",
      "(Validation) Loss: 739283.5378, MAE: 3191.3647, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [4892/5000] | Time: 0.39s\n",
      "(Training) Loss: 916552.2538\n",
      "(Validation) Loss: 739203.2438, MAE: 3191.0527, R2: 0.2482\n",
      "==========================================================================================\n",
      "Epoch [4893/5000] | Time: 0.38s\n",
      "(Training) Loss: 918797.2227\n",
      "(Validation) Loss: 739126.6597, MAE: 3189.1863, R2: 0.2483\n",
      "==========================================================================================\n",
      "Epoch [4894/5000] | Time: 0.35s\n",
      "(Training) Loss: 936660.4137\n",
      "(Validation) Loss: 739046.4197, MAE: 3189.5801, R2: 0.2484\n",
      "==========================================================================================\n",
      "Epoch [4895/5000] | Time: 0.41s\n",
      "(Training) Loss: 916153.4220\n",
      "(Validation) Loss: 738977.0921, MAE: 3191.0247, R2: 0.2485\n",
      "==========================================================================================\n",
      "Epoch [4896/5000] | Time: 0.40s\n",
      "(Training) Loss: 923447.7589\n",
      "(Validation) Loss: 738892.5924, MAE: 3190.6384, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [4897/5000] | Time: 0.36s\n",
      "(Training) Loss: 916035.4423\n",
      "(Validation) Loss: 738811.0356, MAE: 3188.2993, R2: 0.2486\n",
      "==========================================================================================\n",
      "Epoch [4898/5000] | Time: 0.38s\n",
      "(Training) Loss: 913009.9296\n",
      "(Validation) Loss: 738734.7257, MAE: 3186.9756, R2: 0.2487\n",
      "==========================================================================================\n",
      "Epoch [4899/5000] | Time: 0.38s\n",
      "(Training) Loss: 924219.6263\n",
      "(Validation) Loss: 738657.7587, MAE: 3187.6638, R2: 0.2488\n",
      "==========================================================================================\n",
      "Epoch [4900/5000] | Time: 0.38s\n",
      "(Training) Loss: 931325.3268\n",
      "(Validation) Loss: 738589.5924, MAE: 3188.8796, R2: 0.2489\n",
      "==========================================================================================\n",
      "Epoch [4901/5000] | Time: 0.35s\n",
      "(Training) Loss: 924722.8242\n",
      "(Validation) Loss: 738501.2337, MAE: 3186.6926, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [4902/5000] | Time: 0.37s\n",
      "(Training) Loss: 924082.5063\n",
      "(Validation) Loss: 738461.0863, MAE: 3191.8340, R2: 0.2490\n",
      "==========================================================================================\n",
      "Epoch [4903/5000] | Time: 0.40s\n",
      "(Training) Loss: 923781.8160\n",
      "(Validation) Loss: 738340.8279, MAE: 3184.5710, R2: 0.2491\n",
      "==========================================================================================\n",
      "Epoch [4904/5000] | Time: 0.41s\n",
      "(Training) Loss: 916906.6516\n",
      "(Validation) Loss: 738271.5683, MAE: 3186.9470, R2: 0.2492\n",
      "==========================================================================================\n",
      "Epoch [4905/5000] | Time: 0.36s\n",
      "(Training) Loss: 910442.8510\n",
      "(Validation) Loss: 738191.2273, MAE: 3186.7329, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [4906/5000] | Time: 0.35s\n",
      "(Training) Loss: 928880.7544\n",
      "(Validation) Loss: 738179.8622, MAE: 3193.8196, R2: 0.2493\n",
      "==========================================================================================\n",
      "Epoch [4907/5000] | Time: 0.39s\n",
      "(Training) Loss: 937235.1497\n",
      "(Validation) Loss: 738036.2914, MAE: 3185.2822, R2: 0.2494\n",
      "==========================================================================================\n",
      "Epoch [4908/5000] | Time: 0.36s\n",
      "(Training) Loss: 910292.3122\n",
      "(Validation) Loss: 737989.9479, MAE: 3188.3115, R2: 0.2495\n",
      "==========================================================================================\n",
      "Epoch [4909/5000] | Time: 0.35s\n",
      "(Training) Loss: 918649.4549\n",
      "(Validation) Loss: 737880.5543, MAE: 3183.6250, R2: 0.2496\n",
      "==========================================================================================\n",
      "Epoch [4910/5000] | Time: 0.38s\n",
      "(Training) Loss: 934970.7405\n",
      "(Validation) Loss: 737800.5587, MAE: 3183.7271, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [4911/5000] | Time: 0.37s\n",
      "(Training) Loss: 914255.1225\n",
      "(Validation) Loss: 737724.6927, MAE: 3183.4736, R2: 0.2497\n",
      "==========================================================================================\n",
      "Epoch [4912/5000] | Time: 0.37s\n",
      "(Training) Loss: 931294.2773\n",
      "(Validation) Loss: 737685.4343, MAE: 3189.6440, R2: 0.2498\n",
      "==========================================================================================\n",
      "Epoch [4913/5000] | Time: 0.36s\n",
      "(Training) Loss: 914628.6358\n",
      "(Validation) Loss: 737573.6419, MAE: 3185.8489, R2: 0.2499\n",
      "==========================================================================================\n",
      "Epoch [4914/5000] | Time: 0.35s\n",
      "(Training) Loss: 920396.6320\n",
      "(Validation) Loss: 737497.9371, MAE: 3184.7334, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [4915/5000] | Time: 0.35s\n",
      "(Training) Loss: 940529.4283\n",
      "(Validation) Loss: 737416.3022, MAE: 3183.6377, R2: 0.2501\n",
      "==========================================================================================\n",
      "Epoch [4916/5000] | Time: 0.35s\n",
      "(Training) Loss: 923768.4626\n",
      "(Validation) Loss: 737455.4406, MAE: 3208.5273, R2: 0.2500\n",
      "==========================================================================================\n",
      "Epoch [4917/5000] | Time: 0.41s\n",
      "(Training) Loss: 935524.9879\n",
      "(Validation) Loss: 737263.7289, MAE: 3184.1055, R2: 0.2502\n",
      "==========================================================================================\n",
      "Epoch [4918/5000] | Time: 0.37s\n",
      "(Training) Loss: 909883.6699\n",
      "(Validation) Loss: 737185.8933, MAE: 3185.3469, R2: 0.2503\n",
      "==========================================================================================\n",
      "Epoch [4919/5000] | Time: 0.37s\n",
      "(Training) Loss: 927146.0933\n",
      "(Validation) Loss: 737131.0286, MAE: 3184.8284, R2: 0.2503\n",
      "==========================================================================================\n",
      "Epoch [4920/5000] | Time: 0.35s\n",
      "(Training) Loss: 914963.5596\n",
      "(Validation) Loss: 737029.8546, MAE: 3182.6890, R2: 0.2504\n",
      "==========================================================================================\n",
      "Epoch [4921/5000] | Time: 0.37s\n",
      "(Training) Loss: 912547.2893\n",
      "(Validation) Loss: 736950.3340, MAE: 3182.7234, R2: 0.2505\n",
      "==========================================================================================\n",
      "Epoch [4922/5000] | Time: 0.37s\n",
      "(Training) Loss: 937501.6593\n",
      "(Validation) Loss: 736881.9524, MAE: 3182.6677, R2: 0.2506\n",
      "==========================================================================================\n",
      "Epoch [4923/5000] | Time: 0.36s\n",
      "(Training) Loss: 913095.2906\n",
      "(Validation) Loss: 736806.0590, MAE: 3182.1851, R2: 0.2507\n",
      "==========================================================================================\n",
      "Epoch [4924/5000] | Time: 0.38s\n",
      "(Training) Loss: 925299.1497\n",
      "(Validation) Loss: 736720.4819, MAE: 3180.9502, R2: 0.2508\n",
      "==========================================================================================\n",
      "Epoch [4925/5000] | Time: 0.36s\n",
      "(Training) Loss: 910514.6329\n",
      "(Validation) Loss: 736643.0635, MAE: 3180.7207, R2: 0.2508\n",
      "==========================================================================================\n",
      "Epoch [4926/5000] | Time: 0.37s\n",
      "(Training) Loss: 919807.2107\n",
      "(Validation) Loss: 736568.6641, MAE: 3181.4136, R2: 0.2509\n",
      "==========================================================================================\n",
      "Epoch [4927/5000] | Time: 0.38s\n",
      "(Training) Loss: 922159.2411\n",
      "(Validation) Loss: 736490.5079, MAE: 3181.2983, R2: 0.2510\n",
      "==========================================================================================\n",
      "Epoch [4928/5000] | Time: 0.34s\n",
      "(Training) Loss: 919464.3477\n",
      "(Validation) Loss: 736414.2876, MAE: 3181.8660, R2: 0.2511\n",
      "==========================================================================================\n",
      "Epoch [4929/5000] | Time: 0.37s\n",
      "(Training) Loss: 915875.1789\n",
      "(Validation) Loss: 736339.9911, MAE: 3183.7029, R2: 0.2511\n",
      "==========================================================================================\n",
      "Epoch [4930/5000] | Time: 0.36s\n",
      "(Training) Loss: 912762.2773\n",
      "(Validation) Loss: 736259.4470, MAE: 3181.0405, R2: 0.2512\n",
      "==========================================================================================\n",
      "Epoch [4931/5000] | Time: 0.37s\n",
      "(Training) Loss: 907544.5802\n",
      "(Validation) Loss: 736184.4203, MAE: 3181.4961, R2: 0.2513\n",
      "==========================================================================================\n",
      "Epoch [4932/5000] | Time: 0.35s\n",
      "(Training) Loss: 911794.9676\n",
      "(Validation) Loss: 736110.7003, MAE: 3180.6670, R2: 0.2514\n",
      "==========================================================================================\n",
      "Epoch [4933/5000] | Time: 0.32s\n",
      "(Training) Loss: 932931.7348\n",
      "(Validation) Loss: 736033.3048, MAE: 3180.1987, R2: 0.2514\n",
      "==========================================================================================\n",
      "Epoch [4934/5000] | Time: 0.34s\n",
      "(Training) Loss: 927229.9286\n",
      "(Validation) Loss: 735951.4425, MAE: 3179.9133, R2: 0.2515\n",
      "==========================================================================================\n",
      "Epoch [4935/5000] | Time: 0.38s\n",
      "(Training) Loss: 925361.9029\n",
      "(Validation) Loss: 735882.9486, MAE: 3181.5381, R2: 0.2516\n",
      "==========================================================================================\n",
      "Epoch [4936/5000] | Time: 0.40s\n",
      "(Training) Loss: 910960.2874\n",
      "(Validation) Loss: 735813.9829, MAE: 3183.5303, R2: 0.2517\n",
      "==========================================================================================\n",
      "Epoch [4937/5000] | Time: 0.35s\n",
      "(Training) Loss: 911388.4727\n",
      "(Validation) Loss: 735743.9143, MAE: 3184.8936, R2: 0.2517\n",
      "==========================================================================================\n",
      "Epoch [4938/5000] | Time: 0.35s\n",
      "(Training) Loss: 922633.3852\n",
      "(Validation) Loss: 735659.0133, MAE: 3180.9104, R2: 0.2518\n",
      "==========================================================================================\n",
      "Epoch [4939/5000] | Time: 0.37s\n",
      "(Training) Loss: 910004.6183\n",
      "(Validation) Loss: 735564.9759, MAE: 3177.5151, R2: 0.2519\n",
      "==========================================================================================\n",
      "Epoch [4940/5000] | Time: 0.38s\n",
      "(Training) Loss: 928858.3128\n",
      "(Validation) Loss: 735488.5562, MAE: 3180.1638, R2: 0.2520\n",
      "==========================================================================================\n",
      "Epoch [4941/5000] | Time: 0.34s\n",
      "(Training) Loss: 920882.5958\n",
      "(Validation) Loss: 735426.7543, MAE: 3181.3850, R2: 0.2521\n",
      "==========================================================================================\n",
      "Epoch [4942/5000] | Time: 0.36s\n",
      "(Training) Loss: 917098.1618\n",
      "(Validation) Loss: 735334.9879, MAE: 3178.4368, R2: 0.2521\n",
      "==========================================================================================\n",
      "Epoch [4943/5000] | Time: 0.35s\n",
      "(Training) Loss: 920795.1885\n",
      "(Validation) Loss: 735263.3035, MAE: 3179.1536, R2: 0.2522\n",
      "==========================================================================================\n",
      "Epoch [4944/5000] | Time: 0.36s\n",
      "(Training) Loss: 925035.3471\n",
      "(Validation) Loss: 735189.8267, MAE: 3180.2664, R2: 0.2523\n",
      "==========================================================================================\n",
      "Epoch [4945/5000] | Time: 0.38s\n",
      "(Training) Loss: 936832.9743\n",
      "(Validation) Loss: 735104.9905, MAE: 3178.8574, R2: 0.2524\n",
      "==========================================================================================\n",
      "Epoch [4946/5000] | Time: 0.38s\n",
      "(Training) Loss: 933361.2728\n",
      "(Validation) Loss: 735073.7911, MAE: 3184.5964, R2: 0.2524\n",
      "==========================================================================================\n",
      "Epoch [4947/5000] | Time: 0.40s\n",
      "(Training) Loss: 933293.1850\n",
      "(Validation) Loss: 734956.4330, MAE: 3179.4905, R2: 0.2525\n",
      "==========================================================================================\n",
      "Epoch [4948/5000] | Time: 0.32s\n",
      "(Training) Loss: 913063.0406\n",
      "(Validation) Loss: 734876.1733, MAE: 3177.8213, R2: 0.2526\n",
      "==========================================================================================\n",
      "Epoch [4949/5000] | Time: 0.32s\n",
      "(Training) Loss: 925422.4359\n",
      "(Validation) Loss: 734803.3378, MAE: 3178.7766, R2: 0.2527\n",
      "==========================================================================================\n",
      "Epoch [4950/5000] | Time: 0.32s\n",
      "(Training) Loss: 920971.8261\n",
      "(Validation) Loss: 734720.1613, MAE: 3176.8555, R2: 0.2528\n",
      "==========================================================================================\n",
      "Epoch [4951/5000] | Time: 0.32s\n",
      "(Training) Loss: 930205.2043\n",
      "(Validation) Loss: 734646.6597, MAE: 3177.6848, R2: 0.2528\n",
      "==========================================================================================\n",
      "Epoch [4952/5000] | Time: 0.33s\n",
      "(Training) Loss: 909907.0692\n",
      "(Validation) Loss: 734560.8540, MAE: 3175.4209, R2: 0.2529\n",
      "==========================================================================================\n",
      "Epoch [4953/5000] | Time: 0.34s\n",
      "(Training) Loss: 909595.6701\n",
      "(Validation) Loss: 734489.4940, MAE: 3176.5288, R2: 0.2530\n",
      "==========================================================================================\n",
      "Epoch [4954/5000] | Time: 0.35s\n",
      "(Training) Loss: 920831.4819\n",
      "(Validation) Loss: 734412.4635, MAE: 3175.3467, R2: 0.2531\n",
      "==========================================================================================\n",
      "Epoch [4955/5000] | Time: 0.38s\n",
      "(Training) Loss: 917085.0831\n",
      "(Validation) Loss: 734341.7117, MAE: 3175.5208, R2: 0.2532\n",
      "==========================================================================================\n",
      "Epoch [4956/5000] | Time: 0.37s\n",
      "(Training) Loss: 937049.4226\n",
      "(Validation) Loss: 734256.3752, MAE: 3173.9348, R2: 0.2532\n",
      "==========================================================================================\n",
      "Epoch [4957/5000] | Time: 0.36s\n",
      "(Training) Loss: 919876.0330\n",
      "(Validation) Loss: 734213.9168, MAE: 3180.0400, R2: 0.2533\n",
      "==========================================================================================\n",
      "Epoch [4958/5000] | Time: 0.37s\n",
      "(Training) Loss: 932165.8464\n",
      "(Validation) Loss: 734103.1575, MAE: 3176.9114, R2: 0.2534\n",
      "==========================================================================================\n",
      "Epoch [4959/5000] | Time: 0.38s\n",
      "(Training) Loss: 906587.0785\n",
      "(Validation) Loss: 734026.1657, MAE: 3175.0784, R2: 0.2535\n",
      "==========================================================================================\n",
      "Epoch [4960/5000] | Time: 0.34s\n",
      "(Training) Loss: 912022.3655\n",
      "(Validation) Loss: 733947.3232, MAE: 3172.6472, R2: 0.2535\n",
      "==========================================================================================\n",
      "Epoch [4961/5000] | Time: 0.33s\n",
      "(Training) Loss: 931294.4067\n",
      "(Validation) Loss: 733874.7073, MAE: 3175.1140, R2: 0.2536\n",
      "==========================================================================================\n",
      "Epoch [4962/5000] | Time: 0.36s\n",
      "(Training) Loss: 916294.4886\n",
      "(Validation) Loss: 733790.1016, MAE: 3172.9526, R2: 0.2537\n",
      "==========================================================================================\n",
      "Epoch [4963/5000] | Time: 0.39s\n",
      "(Training) Loss: 922187.0400\n",
      "(Validation) Loss: 733729.2375, MAE: 3175.7366, R2: 0.2538\n",
      "==========================================================================================\n",
      "Epoch [4964/5000] | Time: 0.36s\n",
      "(Training) Loss: 930190.8452\n",
      "(Validation) Loss: 733669.4813, MAE: 3176.1663, R2: 0.2538\n",
      "==========================================================================================\n",
      "Epoch [4965/5000] | Time: 0.37s\n",
      "(Training) Loss: 921768.2602\n",
      "(Validation) Loss: 733565.1467, MAE: 3173.5857, R2: 0.2539\n",
      "==========================================================================================\n",
      "Epoch [4966/5000] | Time: 0.36s\n",
      "(Training) Loss: 928791.8274\n",
      "(Validation) Loss: 733485.8762, MAE: 3171.4495, R2: 0.2540\n",
      "==========================================================================================\n",
      "Epoch [4967/5000] | Time: 0.33s\n",
      "(Training) Loss: 910260.9004\n",
      "(Validation) Loss: 733421.2787, MAE: 3179.0981, R2: 0.2541\n",
      "==========================================================================================\n",
      "Epoch [4968/5000] | Time: 0.33s\n",
      "(Training) Loss: 928688.4759\n",
      "(Validation) Loss: 733330.6171, MAE: 3170.7905, R2: 0.2542\n",
      "==========================================================================================\n",
      "Epoch [4969/5000] | Time: 0.34s\n",
      "(Training) Loss: 904181.5842\n",
      "(Validation) Loss: 733249.8527, MAE: 3171.6074, R2: 0.2543\n",
      "==========================================================================================\n",
      "Epoch [4970/5000] | Time: 0.33s\n",
      "(Training) Loss: 932496.1735\n",
      "(Validation) Loss: 733205.3295, MAE: 3173.2122, R2: 0.2543\n",
      "==========================================================================================\n",
      "Epoch [4971/5000] | Time: 0.35s\n",
      "(Training) Loss: 910052.5317\n",
      "(Validation) Loss: 733104.9143, MAE: 3169.7207, R2: 0.2544\n",
      "==========================================================================================\n",
      "Epoch [4972/5000] | Time: 0.33s\n",
      "(Training) Loss: 916037.7046\n",
      "(Validation) Loss: 733025.0413, MAE: 3169.3232, R2: 0.2545\n",
      "==========================================================================================\n",
      "Epoch [4973/5000] | Time: 0.33s\n",
      "(Training) Loss: 910478.4042\n",
      "(Validation) Loss: 732947.1879, MAE: 3168.6714, R2: 0.2546\n",
      "==========================================================================================\n",
      "Epoch [4974/5000] | Time: 0.38s\n",
      "(Training) Loss: 914635.5228\n",
      "(Validation) Loss: 732885.4775, MAE: 3170.5261, R2: 0.2546\n",
      "==========================================================================================\n",
      "Epoch [4975/5000] | Time: 0.36s\n",
      "(Training) Loss: 921499.1834\n",
      "(Validation) Loss: 732804.3029, MAE: 3171.5811, R2: 0.2547\n",
      "==========================================================================================\n",
      "Epoch [4976/5000] | Time: 0.34s\n",
      "(Training) Loss: 908381.5044\n",
      "(Validation) Loss: 732875.9429, MAE: 3182.2202, R2: 0.2546\n",
      "==========================================================================================\n",
      "Epoch [4977/5000] | Time: 0.37s\n",
      "(Training) Loss: 912065.5799\n",
      "(Validation) Loss: 732636.9524, MAE: 3167.5750, R2: 0.2549\n",
      "==========================================================================================\n",
      "Epoch [4978/5000] | Time: 0.39s\n",
      "(Training) Loss: 914709.4118\n",
      "(Validation) Loss: 732570.8032, MAE: 3168.8689, R2: 0.2549\n",
      "==========================================================================================\n",
      "Epoch [4979/5000] | Time: 0.37s\n",
      "(Training) Loss: 909822.1491\n",
      "(Validation) Loss: 732494.0032, MAE: 3167.7349, R2: 0.2550\n",
      "==========================================================================================\n",
      "Epoch [4980/5000] | Time: 0.36s\n",
      "(Training) Loss: 925635.3591\n",
      "(Validation) Loss: 732410.8629, MAE: 3166.6956, R2: 0.2551\n",
      "==========================================================================================\n",
      "Epoch [4981/5000] | Time: 0.34s\n",
      "(Training) Loss: 924246.5565\n",
      "(Validation) Loss: 732352.3695, MAE: 3168.7349, R2: 0.2552\n",
      "==========================================================================================\n",
      "Epoch [4982/5000] | Time: 0.35s\n",
      "(Training) Loss: 903610.8721\n",
      "(Validation) Loss: 732260.5581, MAE: 3167.0098, R2: 0.2552\n",
      "==========================================================================================\n",
      "Epoch [4983/5000] | Time: 0.37s\n",
      "(Training) Loss: 922464.0063\n",
      "(Validation) Loss: 732184.0425, MAE: 3167.6177, R2: 0.2553\n",
      "==========================================================================================\n",
      "Epoch [4984/5000] | Time: 0.41s\n",
      "(Training) Loss: 918029.2589\n",
      "(Validation) Loss: 732103.3035, MAE: 3165.4104, R2: 0.2554\n",
      "==========================================================================================\n",
      "Epoch [4985/5000] | Time: 0.40s\n",
      "(Training) Loss: 909951.3744\n",
      "(Validation) Loss: 732030.7168, MAE: 3165.5278, R2: 0.2555\n",
      "==========================================================================================\n",
      "Epoch [4986/5000] | Time: 0.35s\n",
      "(Training) Loss: 912617.2418\n",
      "(Validation) Loss: 731954.9625, MAE: 3166.0879, R2: 0.2556\n",
      "==========================================================================================\n",
      "Epoch [4987/5000] | Time: 0.45s\n",
      "(Training) Loss: 915381.5876\n",
      "(Validation) Loss: 731876.8654, MAE: 3164.6182, R2: 0.2556\n",
      "==========================================================================================\n",
      "Epoch [4988/5000] | Time: 0.36s\n",
      "(Training) Loss: 906101.0292\n",
      "(Validation) Loss: 731810.3848, MAE: 3166.0923, R2: 0.2557\n",
      "==========================================================================================\n",
      "Epoch [4989/5000] | Time: 0.40s\n",
      "(Training) Loss: 906795.5666\n",
      "(Validation) Loss: 731730.8444, MAE: 3164.5911, R2: 0.2558\n",
      "==========================================================================================\n",
      "Epoch [4990/5000] | Time: 0.35s\n",
      "(Training) Loss: 916214.6155\n",
      "(Validation) Loss: 731675.9816, MAE: 3167.8826, R2: 0.2558\n",
      "==========================================================================================\n",
      "Epoch [4991/5000] | Time: 0.41s\n",
      "(Training) Loss: 909145.0596\n",
      "(Validation) Loss: 731569.9740, MAE: 3163.2185, R2: 0.2559\n",
      "==========================================================================================\n",
      "Epoch [4992/5000] | Time: 0.40s\n",
      "(Training) Loss: 908566.7386\n",
      "(Validation) Loss: 731507.2476, MAE: 3164.9136, R2: 0.2560\n",
      "==========================================================================================\n",
      "Epoch [4993/5000] | Time: 0.40s\n",
      "(Training) Loss: 906867.4877\n",
      "(Validation) Loss: 750102.5962, MAE: 3215.7410, R2: 0.2373\n",
      "==========================================================================================\n",
      "Epoch [4994/5000] | Time: 0.34s\n",
      "(Training) Loss: 932833.7614\n",
      "(Validation) Loss: 750017.7943, MAE: 3215.6843, R2: 0.2374\n",
      "==========================================================================================\n",
      "Epoch [4995/5000] | Time: 0.35s\n",
      "(Training) Loss: 938970.3620\n",
      "(Validation) Loss: 749930.6317, MAE: 3213.7747, R2: 0.2374\n",
      "==========================================================================================\n",
      "Epoch [4996/5000] | Time: 0.33s\n",
      "(Training) Loss: 934836.0990\n",
      "(Validation) Loss: 749854.8483, MAE: 3215.7773, R2: 0.2375\n",
      "==========================================================================================\n",
      "Epoch [4997/5000] | Time: 0.37s\n",
      "(Training) Loss: 935166.0489\n",
      "(Validation) Loss: 749839.0292, MAE: 3222.1362, R2: 0.2375\n",
      "==========================================================================================\n",
      "Epoch [4998/5000] | Time: 0.33s\n",
      "(Training) Loss: 934747.9968\n",
      "(Validation) Loss: 749753.4330, MAE: 3221.5198, R2: 0.2376\n",
      "==========================================================================================\n",
      "Epoch [4999/5000] | Time: 0.33s\n",
      "(Training) Loss: 929204.0774\n",
      "(Validation) Loss: 749652.9771, MAE: 3222.7888, R2: 0.2377\n",
      "==========================================================================================\n",
      "Epoch [5000/5000] | Time: 0.36s\n",
      "(Training) Loss: 935151.5368\n",
      "(Validation) Loss: 749541.9638, MAE: 3214.9607, R2: 0.2378\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_21-30-14\\CryptoGRU_epoch5000.pth\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load model parameters\n",
    "model_save_path = \"saved_models/CryptoGRU_2025-03-16_20-57-42/CryptoGRU_BEST_R2.pth\"\n",
    "model = CryptoGRU(input_size=4, embed_dim=4, hidden_size=64, num_layers=1)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "training_loss_history, validation_loss_history, mae_history, r2_history = train_model(\n",
    "    model, optimizer, train_loader, val_loader,\n",
    "    num_epochs=num_epochs, save_interval=save_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3397, 0.30157655477523804)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_r2 = max(r2_history)\n",
    "max_index = r2_history.index(max_r2)\n",
    "max_index, max_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_epochs = range(1, len(training_loss_history) + 1)\n",
    "eval_metrics = {\n",
    "    \"Training Loss History\": training_loss_history,\n",
    "    \"Validation Loss History\": validation_loss_history,\n",
    "    \"Mean Absolute Error History\": mae_history,\n",
    "    \"R2 Score History\": r2_history\n",
    "}\n",
    "\n",
    "for metric, metric_history in eval_metrics.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(total_epochs, metric_history, label=metric, color=\"red\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"{metric} Over Epochs\")\n",
    "    \n",
    "# Note that retraining happened from model after 5000 epochs after"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "term6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
