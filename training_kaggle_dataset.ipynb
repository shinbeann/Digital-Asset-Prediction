{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for Kaggle Dataset\n",
    "Using this [Cryptocurrency Price Analysis Dataset from Kaggle](https://www.kaggle.com/datasets/adityamhaske/cryptocurrency-price-analysis-dataset/data) as proof-of-concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ryan Lee\\.conda\\envs\\term6\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Required Modules #\n",
    "####################\n",
    "\n",
    "# Libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Custom\n",
    "from src.dataset import *\n",
    "from src.models import *\n",
    "from src.train_eval import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "Download the dataset from the Kaggle [page](https://www.kaggle.com/datasets/adityamhaske/cryptocurrency-price-analysis-dataset/data). Alternatively, you can use the following `kagglehub` to download the dataset:\n",
    "\n",
    "```python\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "csv_path = kagglehub.dataset_download(\"adityamhaske/cryptocurrency-price-analysis-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ryan Lee\\Desktop\\50.038 Computational Data Science\\Digital-Asset-Prediction\\src\\dataset.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df['Date'] = pd.to_datetime(self.df['Date']) # Datetime conversion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 7879\n",
      "Crypto mapping: {'BTC': 0, 'ETH': 1, 'LTC': 2, 'XRP': 3}\n"
     ]
    }
   ],
   "source": [
    "# Update the path to the `crypto_combine.csv` file below:\n",
    "csv_path = \"data/kaggle_crypto_price_prediction/crypto_combine.csv\"\n",
    "seq_length = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Create the dataset\n",
    "dataset = CryptoDataset(csv_path, seq_length=seq_length)\n",
    "\n",
    "print(f\"Total sequences: {len(dataset)}\")\n",
    "print(\"Crypto mapping:\", dataset.crypto_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation set\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "`train_model` will save model parameters to `saved_models` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryptoGRU model loaded on cuda.\n",
      "Epoch [1/5000] | Time: 1.38s\n",
      "(Training) Loss: 1390000.2126\n",
      "(Validation) Loss: 1439565.3587, MAE: 5493.0205, R2: -0.2104\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2/5000] | Time: 0.24s\n",
      "(Training) Loss: 1372912.9429\n",
      "(Validation) Loss: 1439236.3073, MAE: 5490.3779, R2: -0.2101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3/5000] | Time: 0.19s\n",
      "(Training) Loss: 1383858.9759\n",
      "(Validation) Loss: 1438906.9054, MAE: 5487.6553, R2: -0.2099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4/5000] | Time: 0.18s\n",
      "(Training) Loss: 1386313.6701\n",
      "(Validation) Loss: 1438574.0394, MAE: 5484.9429, R2: -0.2096\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [5/5000] | Time: 0.18s\n",
      "(Training) Loss: 1407402.9137\n",
      "(Validation) Loss: 1438265.4273, MAE: 5482.4185, R2: -0.2093\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [6/5000] | Time: 0.17s\n",
      "(Training) Loss: 1380637.1929\n",
      "(Validation) Loss: 1437966.0800, MAE: 5479.9580, R2: -0.2091\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [7/5000] | Time: 0.18s\n",
      "(Training) Loss: 1394004.1967\n",
      "(Validation) Loss: 1437679.3549, MAE: 5477.6177, R2: -0.2088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [8/5000] | Time: 0.23s\n",
      "(Training) Loss: 1402521.0876\n",
      "(Validation) Loss: 1437367.8984, MAE: 5475.1177, R2: -0.2086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [9/5000] | Time: 0.20s\n",
      "(Training) Loss: 1397204.4239\n",
      "(Validation) Loss: 1437058.3111, MAE: 5472.6631, R2: -0.2083\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [10/5000] | Time: 0.22s\n",
      "(Training) Loss: 1376074.7094\n",
      "(Validation) Loss: 1436744.4267, MAE: 5470.2012, R2: -0.2081\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [11/5000] | Time: 0.19s\n",
      "(Training) Loss: 1372981.1802\n",
      "(Validation) Loss: 1436434.0063, MAE: 5467.7173, R2: -0.2078\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [12/5000] | Time: 0.17s\n",
      "(Training) Loss: 1399780.4442\n",
      "(Validation) Loss: 1436127.5124, MAE: 5465.2544, R2: -0.2075\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [13/5000] | Time: 0.17s\n",
      "(Training) Loss: 1373959.2843\n",
      "(Validation) Loss: 1435825.7625, MAE: 5462.8735, R2: -0.2073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [14/5000] | Time: 0.17s\n",
      "(Training) Loss: 1385133.7056\n",
      "(Validation) Loss: 1435529.1479, MAE: 5460.6089, R2: -0.2070\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [15/5000] | Time: 0.18s\n",
      "(Training) Loss: 1405020.2538\n",
      "(Validation) Loss: 1435231.0857, MAE: 5458.3618, R2: -0.2068\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [16/5000] | Time: 0.21s\n",
      "(Training) Loss: 1382348.0457\n",
      "(Validation) Loss: 1434937.5035, MAE: 5456.1885, R2: -0.2065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [17/5000] | Time: 0.18s\n",
      "(Training) Loss: 1374058.9124\n",
      "(Validation) Loss: 1434641.0159, MAE: 5454.0151, R2: -0.2063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [18/5000] | Time: 0.17s\n",
      "(Training) Loss: 1398155.4112\n",
      "(Validation) Loss: 1434346.7124, MAE: 5451.9023, R2: -0.2061\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [19/5000] | Time: 0.21s\n",
      "(Training) Loss: 1367981.5888\n",
      "(Validation) Loss: 1434053.5975, MAE: 5449.8364, R2: -0.2058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [20/5000] | Time: 0.18s\n",
      "(Training) Loss: 1367921.8807\n",
      "(Validation) Loss: 1433767.2076, MAE: 5447.8179, R2: -0.2056\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [21/5000] | Time: 0.19s\n",
      "(Training) Loss: 1374171.7360\n",
      "(Validation) Loss: 1433445.5365, MAE: 5445.5938, R2: -0.2053\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [22/5000] | Time: 0.20s\n",
      "(Training) Loss: 1396919.1091\n",
      "(Validation) Loss: 1433147.4083, MAE: 5443.5732, R2: -0.2051\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [23/5000] | Time: 0.18s\n",
      "(Training) Loss: 1417763.0520\n",
      "(Validation) Loss: 1432847.9797, MAE: 5441.5176, R2: -0.2048\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [24/5000] | Time: 0.18s\n",
      "(Training) Loss: 1376429.3947\n",
      "(Validation) Loss: 1432540.4800, MAE: 5439.4224, R2: -0.2045\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [25/5000] | Time: 0.18s\n",
      "(Training) Loss: 1379502.2246\n",
      "(Validation) Loss: 1432245.1200, MAE: 5437.4570, R2: -0.2043\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [26/5000] | Time: 0.19s\n",
      "(Training) Loss: 1375520.4194\n",
      "(Validation) Loss: 1431952.0610, MAE: 5435.4785, R2: -0.2041\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [27/5000] | Time: 0.24s\n",
      "(Training) Loss: 1370036.9594\n",
      "(Validation) Loss: 1431656.7517, MAE: 5433.5913, R2: -0.2038\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [28/5000] | Time: 0.21s\n",
      "(Training) Loss: 1359882.9661\n",
      "(Validation) Loss: 1431368.0305, MAE: 5431.6470, R2: -0.2036\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [29/5000] | Time: 0.22s\n",
      "(Training) Loss: 1403071.5216\n",
      "(Validation) Loss: 1431078.5727, MAE: 5429.7637, R2: -0.2033\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [30/5000] | Time: 0.19s\n",
      "(Training) Loss: 1363520.4365\n",
      "(Validation) Loss: 1430780.5105, MAE: 5427.8672, R2: -0.2031\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [31/5000] | Time: 0.21s\n",
      "(Training) Loss: 1375612.3617\n",
      "(Validation) Loss: 1430491.7994, MAE: 5425.9658, R2: -0.2028\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [32/5000] | Time: 0.23s\n",
      "(Training) Loss: 1373295.5850\n",
      "(Validation) Loss: 1430200.1930, MAE: 5424.0640, R2: -0.2026\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [33/5000] | Time: 0.26s\n",
      "(Training) Loss: 1380863.6104\n",
      "(Validation) Loss: 1429908.4241, MAE: 5422.2109, R2: -0.2024\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [34/5000] | Time: 0.20s\n",
      "(Training) Loss: 1383416.7830\n",
      "(Validation) Loss: 1429615.7714, MAE: 5420.2944, R2: -0.2021\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [35/5000] | Time: 0.21s\n",
      "(Training) Loss: 1376395.5508\n",
      "(Validation) Loss: 1429328.6298, MAE: 5418.5259, R2: -0.2019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [36/5000] | Time: 0.20s\n",
      "(Training) Loss: 1368165.3135\n",
      "(Validation) Loss: 1429035.5098, MAE: 5416.6948, R2: -0.2016\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [37/5000] | Time: 0.21s\n",
      "(Training) Loss: 1377616.6396\n",
      "(Validation) Loss: 1428748.4851, MAE: 5414.9175, R2: -0.2014\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [38/5000] | Time: 0.20s\n",
      "(Training) Loss: 1389057.8198\n",
      "(Validation) Loss: 1428460.0787, MAE: 5413.2617, R2: -0.2011\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [39/5000] | Time: 0.19s\n",
      "(Training) Loss: 1373566.7278\n",
      "(Validation) Loss: 1428165.2267, MAE: 5411.3750, R2: -0.2009\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [40/5000] | Time: 0.23s\n",
      "(Training) Loss: 1385580.1269\n",
      "(Validation) Loss: 1427878.8521, MAE: 5409.6001, R2: -0.2007\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [41/5000] | Time: 0.23s\n",
      "(Training) Loss: 1380766.2462\n",
      "(Validation) Loss: 1427589.6737, MAE: 5407.9053, R2: -0.2004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [42/5000] | Time: 0.20s\n",
      "(Training) Loss: 1376945.8376\n",
      "(Validation) Loss: 1427301.0997, MAE: 5406.2280, R2: -0.2002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [43/5000] | Time: 0.26s\n",
      "(Training) Loss: 1362950.5190\n",
      "(Validation) Loss: 1427011.0730, MAE: 5404.4888, R2: -0.1999\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [44/5000] | Time: 0.25s\n",
      "(Training) Loss: 1372928.0996\n",
      "(Validation) Loss: 1426726.1613, MAE: 5402.9321, R2: -0.1997\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [45/5000] | Time: 0.27s\n",
      "(Training) Loss: 1364426.1244\n",
      "(Validation) Loss: 1426437.4095, MAE: 5401.2324, R2: -0.1995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [46/5000] | Time: 0.29s\n",
      "(Training) Loss: 1362678.1764\n",
      "(Validation) Loss: 1426151.5276, MAE: 5399.7139, R2: -0.1992\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [47/5000] | Time: 0.26s\n",
      "(Training) Loss: 1358566.7817\n",
      "(Validation) Loss: 1425864.4775, MAE: 5397.8936, R2: -0.1990\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [48/5000] | Time: 0.30s\n",
      "(Training) Loss: 1385585.9150\n",
      "(Validation) Loss: 1425581.9530, MAE: 5396.7407, R2: -0.1987\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [49/5000] | Time: 0.26s\n",
      "(Training) Loss: 1355008.4442\n",
      "(Validation) Loss: 1425286.0902, MAE: 5394.7949, R2: -0.1985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [50/5000] | Time: 0.30s\n",
      "(Training) Loss: 1370897.0140\n",
      "(Validation) Loss: 1425002.0419, MAE: 5393.1982, R2: -0.1983\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [51/5000] | Time: 0.29s\n",
      "(Training) Loss: 1372997.6675\n",
      "(Validation) Loss: 1424715.9416, MAE: 5391.6611, R2: -0.1980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [52/5000] | Time: 0.21s\n",
      "(Training) Loss: 1371697.1612\n",
      "(Validation) Loss: 1424433.4121, MAE: 5390.0259, R2: -0.1978\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [53/5000] | Time: 0.20s\n",
      "(Training) Loss: 1365153.8832\n",
      "(Validation) Loss: 1424143.3244, MAE: 5388.4277, R2: -0.1975\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [54/5000] | Time: 0.21s\n",
      "(Training) Loss: 1367314.8706\n",
      "(Validation) Loss: 1423855.6089, MAE: 5386.9199, R2: -0.1973\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [55/5000] | Time: 0.17s\n",
      "(Training) Loss: 1375507.6688\n",
      "(Validation) Loss: 1423569.2394, MAE: 5385.6768, R2: -0.1971\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [56/5000] | Time: 0.17s\n",
      "(Training) Loss: 1365250.5736\n",
      "(Validation) Loss: 1423283.7079, MAE: 5383.9668, R2: -0.1968\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [57/5000] | Time: 0.23s\n",
      "(Training) Loss: 1396215.6041\n",
      "(Validation) Loss: 1422996.3378, MAE: 5382.4087, R2: -0.1966\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [58/5000] | Time: 0.21s\n",
      "(Training) Loss: 1375088.2665\n",
      "(Validation) Loss: 1422708.9727, MAE: 5380.9023, R2: -0.1964\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [59/5000] | Time: 0.20s\n",
      "(Training) Loss: 1367412.5711\n",
      "(Validation) Loss: 1422422.9587, MAE: 5379.4214, R2: -0.1961\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [60/5000] | Time: 0.18s\n",
      "(Training) Loss: 1399658.3211\n",
      "(Validation) Loss: 1422139.5759, MAE: 5378.1821, R2: -0.1959\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [61/5000] | Time: 0.18s\n",
      "(Training) Loss: 1356105.3750\n",
      "(Validation) Loss: 1421845.9937, MAE: 5376.9224, R2: -0.1956\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [62/5000] | Time: 0.21s\n",
      "(Training) Loss: 1359355.7525\n",
      "(Validation) Loss: 1421563.7994, MAE: 5375.2451, R2: -0.1954\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [63/5000] | Time: 0.21s\n",
      "(Training) Loss: 1400728.9289\n",
      "(Validation) Loss: 1421282.0571, MAE: 5373.7646, R2: -0.1952\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [64/5000] | Time: 0.17s\n",
      "(Training) Loss: 1351433.1634\n",
      "(Validation) Loss: 1420989.7549, MAE: 5372.4438, R2: -0.1949\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [65/5000] | Time: 0.21s\n",
      "(Training) Loss: 1364400.6980\n",
      "(Validation) Loss: 1420711.3702, MAE: 5371.0698, R2: -0.1947\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [66/5000] | Time: 0.18s\n",
      "(Training) Loss: 1381086.6066\n",
      "(Validation) Loss: 1420424.0102, MAE: 5369.5894, R2: -0.1944\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [67/5000] | Time: 0.19s\n",
      "(Training) Loss: 1377453.7525\n",
      "(Validation) Loss: 1420136.9854, MAE: 5368.5034, R2: -0.1942\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [68/5000] | Time: 0.19s\n",
      "(Training) Loss: 1369955.5673\n",
      "(Validation) Loss: 1419848.7060, MAE: 5366.9014, R2: -0.1940\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [69/5000] | Time: 0.19s\n",
      "(Training) Loss: 1356492.6497\n",
      "(Validation) Loss: 1419564.6527, MAE: 5365.3828, R2: -0.1937\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [70/5000] | Time: 0.17s\n",
      "(Training) Loss: 1358834.7386\n",
      "(Validation) Loss: 1419284.6679, MAE: 5364.1646, R2: -0.1935\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [71/5000] | Time: 0.18s\n",
      "(Training) Loss: 1375968.5838\n",
      "(Validation) Loss: 1418998.6844, MAE: 5362.8286, R2: -0.1933\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [72/5000] | Time: 0.17s\n",
      "(Training) Loss: 1366742.8338\n",
      "(Validation) Loss: 1418715.5606, MAE: 5361.5005, R2: -0.1930\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [73/5000] | Time: 0.23s\n",
      "(Training) Loss: 1369968.7551\n",
      "(Validation) Loss: 1418428.4190, MAE: 5360.2817, R2: -0.1928\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [74/5000] | Time: 0.24s\n",
      "(Training) Loss: 1363531.1142\n",
      "(Validation) Loss: 1418140.1244, MAE: 5358.6899, R2: -0.1925\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [75/5000] | Time: 0.19s\n",
      "(Training) Loss: 1374840.6612\n",
      "(Validation) Loss: 1417857.3816, MAE: 5358.1157, R2: -0.1923\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [76/5000] | Time: 0.19s\n",
      "(Training) Loss: 1360812.5508\n",
      "(Validation) Loss: 1417572.5968, MAE: 5355.9976, R2: -0.1921\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [77/5000] | Time: 0.20s\n",
      "(Training) Loss: 1366754.9137\n",
      "(Validation) Loss: 1417291.3879, MAE: 5354.9067, R2: -0.1918\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [78/5000] | Time: 0.20s\n",
      "(Training) Loss: 1354860.4746\n",
      "(Validation) Loss: 1417002.4686, MAE: 5353.8452, R2: -0.1916\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [79/5000] | Time: 0.21s\n",
      "(Training) Loss: 1357469.0622\n",
      "(Validation) Loss: 1416724.4292, MAE: 5352.1826, R2: -0.1914\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [80/5000] | Time: 0.24s\n",
      "(Training) Loss: 1387919.4987\n",
      "(Validation) Loss: 1416439.3752, MAE: 5350.7935, R2: -0.1911\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [81/5000] | Time: 0.23s\n",
      "(Training) Loss: 1381206.0013\n",
      "(Validation) Loss: 1416152.3251, MAE: 5349.4849, R2: -0.1909\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [82/5000] | Time: 0.21s\n",
      "(Training) Loss: 1368736.0406\n",
      "(Validation) Loss: 1415863.3549, MAE: 5348.1685, R2: -0.1906\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [83/5000] | Time: 0.21s\n",
      "(Training) Loss: 1357845.1472\n",
      "(Validation) Loss: 1415578.1943, MAE: 5346.8843, R2: -0.1904\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [84/5000] | Time: 0.22s\n",
      "(Training) Loss: 1348249.4353\n",
      "(Validation) Loss: 1415296.1778, MAE: 5346.0234, R2: -0.1902\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [85/5000] | Time: 0.26s\n",
      "(Training) Loss: 1349057.5279\n",
      "(Validation) Loss: 1415013.0946, MAE: 5344.2817, R2: -0.1899\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [86/5000] | Time: 0.23s\n",
      "(Training) Loss: 1349552.9321\n",
      "(Validation) Loss: 1414732.7187, MAE: 5342.8901, R2: -0.1897\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [87/5000] | Time: 0.23s\n",
      "(Training) Loss: 1389521.4746\n",
      "(Validation) Loss: 1414454.5168, MAE: 5341.6519, R2: -0.1895\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [88/5000] | Time: 0.22s\n",
      "(Training) Loss: 1359637.7582\n",
      "(Validation) Loss: 1414169.4375, MAE: 5340.4692, R2: -0.1892\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [89/5000] | Time: 0.21s\n",
      "(Training) Loss: 1351179.1142\n",
      "(Validation) Loss: 1413884.6019, MAE: 5338.9512, R2: -0.1890\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [90/5000] | Time: 0.21s\n",
      "(Training) Loss: 1384593.4315\n",
      "(Validation) Loss: 1413604.8610, MAE: 5337.7573, R2: -0.1888\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [91/5000] | Time: 0.21s\n",
      "(Training) Loss: 1373219.0241\n",
      "(Validation) Loss: 1413320.7010, MAE: 5336.3716, R2: -0.1885\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [92/5000] | Time: 0.20s\n",
      "(Training) Loss: 1370361.3629\n",
      "(Validation) Loss: 1413032.6654, MAE: 5335.1313, R2: -0.1883\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [93/5000] | Time: 0.19s\n",
      "(Training) Loss: 1351582.7500\n",
      "(Validation) Loss: 1412750.7454, MAE: 5333.7339, R2: -0.1880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [94/5000] | Time: 0.18s\n",
      "(Training) Loss: 1363623.1003\n",
      "(Validation) Loss: 1412467.4489, MAE: 5332.5205, R2: -0.1878\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [95/5000] | Time: 0.24s\n",
      "(Training) Loss: 1365774.7284\n",
      "(Validation) Loss: 1412185.6863, MAE: 5331.2690, R2: -0.1876\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [96/5000] | Time: 0.28s\n",
      "(Training) Loss: 1366004.4277\n",
      "(Validation) Loss: 1411901.6533, MAE: 5329.8877, R2: -0.1873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [97/5000] | Time: 0.22s\n",
      "(Training) Loss: 1362914.7246\n",
      "(Validation) Loss: 1411618.3010, MAE: 5329.0176, R2: -0.1871\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [98/5000] | Time: 0.22s\n",
      "(Training) Loss: 1344355.4816\n",
      "(Validation) Loss: 1411337.4070, MAE: 5327.4507, R2: -0.1869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [99/5000] | Time: 0.23s\n",
      "(Training) Loss: 1366607.4657\n",
      "(Validation) Loss: 1411055.7308, MAE: 5326.0522, R2: -0.1866\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [100/5000] | Time: 0.26s\n",
      "(Training) Loss: 1341384.9188\n",
      "(Validation) Loss: 1410774.4051, MAE: 5325.0439, R2: -0.1864\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [101/5000] | Time: 0.27s\n",
      "(Training) Loss: 1346446.5590\n",
      "(Validation) Loss: 1410492.7949, MAE: 5323.6104, R2: -0.1862\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [102/5000] | Time: 0.23s\n",
      "(Training) Loss: 1371656.7500\n",
      "(Validation) Loss: 1410213.9886, MAE: 5322.6299, R2: -0.1859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [103/5000] | Time: 0.21s\n",
      "(Training) Loss: 1359914.2411\n",
      "(Validation) Loss: 1409929.0108, MAE: 5320.9058, R2: -0.1857\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [104/5000] | Time: 0.22s\n",
      "(Training) Loss: 1355702.0558\n",
      "(Validation) Loss: 1409644.9676, MAE: 5319.5713, R2: -0.1855\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [105/5000] | Time: 0.26s\n",
      "(Training) Loss: 1359137.9943\n",
      "(Validation) Loss: 1409365.6584, MAE: 5318.6440, R2: -0.1852\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [106/5000] | Time: 0.20s\n",
      "(Training) Loss: 1351335.8668\n",
      "(Validation) Loss: 1409084.1295, MAE: 5317.3369, R2: -0.1850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [107/5000] | Time: 0.20s\n",
      "(Training) Loss: 1338630.4470\n",
      "(Validation) Loss: 1408801.6610, MAE: 5315.7471, R2: -0.1848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [108/5000] | Time: 0.20s\n",
      "(Training) Loss: 1378563.8261\n",
      "(Validation) Loss: 1408525.2521, MAE: 5314.9946, R2: -0.1845\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [109/5000] | Time: 0.20s\n",
      "(Training) Loss: 1351618.1421\n",
      "(Validation) Loss: 1408238.3848, MAE: 5313.5903, R2: -0.1843\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [110/5000] | Time: 0.21s\n",
      "(Training) Loss: 1356855.1967\n",
      "(Validation) Loss: 1407958.6184, MAE: 5311.9995, R2: -0.1841\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [111/5000] | Time: 0.21s\n",
      "(Training) Loss: 1345104.9772\n",
      "(Validation) Loss: 1407677.8006, MAE: 5310.8682, R2: -0.1838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [112/5000] | Time: 0.22s\n",
      "(Training) Loss: 1353349.6066\n",
      "(Validation) Loss: 1407398.5879, MAE: 5309.5522, R2: -0.1836\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [113/5000] | Time: 0.20s\n",
      "(Training) Loss: 1350869.8211\n",
      "(Validation) Loss: 1407115.0019, MAE: 5308.2588, R2: -0.1833\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [114/5000] | Time: 0.25s\n",
      "(Training) Loss: 1350225.4543\n",
      "(Validation) Loss: 1406834.6006, MAE: 5307.1138, R2: -0.1831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [115/5000] | Time: 0.24s\n",
      "(Training) Loss: 1373356.8046\n",
      "(Validation) Loss: 1406553.2698, MAE: 5305.5601, R2: -0.1829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [116/5000] | Time: 0.26s\n",
      "(Training) Loss: 1355125.9721\n",
      "(Validation) Loss: 1406269.5111, MAE: 5304.5522, R2: -0.1826\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [117/5000] | Time: 0.25s\n",
      "(Training) Loss: 1357900.2322\n",
      "(Validation) Loss: 1405987.8095, MAE: 5303.3755, R2: -0.1824\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [118/5000] | Time: 0.26s\n",
      "(Training) Loss: 1358489.2766\n",
      "(Validation) Loss: 1405705.2343, MAE: 5301.7964, R2: -0.1822\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [119/5000] | Time: 0.22s\n",
      "(Training) Loss: 1358553.6536\n",
      "(Validation) Loss: 1405424.1371, MAE: 5301.1304, R2: -0.1819\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [120/5000] | Time: 0.21s\n",
      "(Training) Loss: 1346215.7792\n",
      "(Validation) Loss: 1405142.4406, MAE: 5299.4126, R2: -0.1817\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [121/5000] | Time: 0.19s\n",
      "(Training) Loss: 1344448.7538\n",
      "(Validation) Loss: 1404862.5930, MAE: 5298.1655, R2: -0.1815\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [122/5000] | Time: 0.21s\n",
      "(Training) Loss: 1355915.8084\n",
      "(Validation) Loss: 1404585.4273, MAE: 5296.9648, R2: -0.1812\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [123/5000] | Time: 0.21s\n",
      "(Training) Loss: 1349015.9569\n",
      "(Validation) Loss: 1404302.9384, MAE: 5295.4824, R2: -0.1810\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [124/5000] | Time: 0.25s\n",
      "(Training) Loss: 1345385.6345\n",
      "(Validation) Loss: 1404021.9683, MAE: 5294.2764, R2: -0.1808\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [125/5000] | Time: 0.21s\n",
      "(Training) Loss: 1344253.0952\n",
      "(Validation) Loss: 1403744.6705, MAE: 5293.3252, R2: -0.1805\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [126/5000] | Time: 0.20s\n",
      "(Training) Loss: 1352067.8591\n",
      "(Validation) Loss: 1403464.0914, MAE: 5291.8623, R2: -0.1803\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [127/5000] | Time: 0.20s\n",
      "(Training) Loss: 1367691.6345\n",
      "(Validation) Loss: 1403184.8940, MAE: 5290.9917, R2: -0.1801\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [128/5000] | Time: 0.19s\n",
      "(Training) Loss: 1392000.5025\n",
      "(Validation) Loss: 1402900.6375, MAE: 5289.3413, R2: -0.1798\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [129/5000] | Time: 0.20s\n",
      "(Training) Loss: 1340634.2398\n",
      "(Validation) Loss: 1402615.1263, MAE: 5288.7339, R2: -0.1796\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [130/5000] | Time: 0.21s\n",
      "(Training) Loss: 1359876.9822\n",
      "(Validation) Loss: 1402340.4444, MAE: 5286.8398, R2: -0.1794\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [131/5000] | Time: 0.20s\n",
      "(Training) Loss: 1337434.1656\n",
      "(Validation) Loss: 1402057.6305, MAE: 5285.5103, R2: -0.1791\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [132/5000] | Time: 0.21s\n",
      "(Training) Loss: 1341829.0431\n",
      "(Validation) Loss: 1401775.7816, MAE: 5284.5078, R2: -0.1789\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [133/5000] | Time: 0.19s\n",
      "(Training) Loss: 1337105.6732\n",
      "(Validation) Loss: 1401502.0089, MAE: 5282.9688, R2: -0.1787\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [134/5000] | Time: 0.23s\n",
      "(Training) Loss: 1348392.5819\n",
      "(Validation) Loss: 1401219.8756, MAE: 5281.7773, R2: -0.1784\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [135/5000] | Time: 0.24s\n",
      "(Training) Loss: 1346860.7716\n",
      "(Validation) Loss: 1400940.8965, MAE: 5280.8223, R2: -0.1782\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [136/5000] | Time: 0.20s\n",
      "(Training) Loss: 1354833.7906\n",
      "(Validation) Loss: 1400662.6133, MAE: 5279.2627, R2: -0.1780\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [137/5000] | Time: 0.21s\n",
      "(Training) Loss: 1336041.3109\n",
      "(Validation) Loss: 1400377.8895, MAE: 5278.3677, R2: -0.1777\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [138/5000] | Time: 0.21s\n",
      "(Training) Loss: 1364589.9365\n",
      "(Validation) Loss: 1400101.6330, MAE: 5277.4341, R2: -0.1775\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [139/5000] | Time: 0.23s\n",
      "(Training) Loss: 1338515.1091\n",
      "(Validation) Loss: 1399821.1810, MAE: 5275.6597, R2: -0.1773\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [140/5000] | Time: 0.20s\n",
      "(Training) Loss: 1354849.4949\n",
      "(Validation) Loss: 1399542.4000, MAE: 5274.6782, R2: -0.1770\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [141/5000] | Time: 0.23s\n",
      "(Training) Loss: 1333826.6396\n",
      "(Validation) Loss: 1399260.4851, MAE: 5273.2314, R2: -0.1768\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [142/5000] | Time: 0.21s\n",
      "(Training) Loss: 1339928.9759\n",
      "(Validation) Loss: 1398983.8070, MAE: 5272.0469, R2: -0.1766\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [143/5000] | Time: 0.23s\n",
      "(Training) Loss: 1368606.5939\n",
      "(Validation) Loss: 1398704.5333, MAE: 5270.8926, R2: -0.1763\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [144/5000] | Time: 0.20s\n",
      "(Training) Loss: 1369674.1980\n",
      "(Validation) Loss: 1398425.1784, MAE: 5269.3633, R2: -0.1761\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [145/5000] | Time: 0.25s\n",
      "(Training) Loss: 1338044.2982\n",
      "(Validation) Loss: 1398142.6540, MAE: 5268.5776, R2: -0.1759\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [146/5000] | Time: 0.24s\n",
      "(Training) Loss: 1349378.7398\n",
      "(Validation) Loss: 1397865.0616, MAE: 5266.9209, R2: -0.1756\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [147/5000] | Time: 0.29s\n",
      "(Training) Loss: 1369842.3604\n",
      "(Validation) Loss: 1397582.8571, MAE: 5265.7354, R2: -0.1754\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [148/5000] | Time: 0.24s\n",
      "(Training) Loss: 1334559.0406\n",
      "(Validation) Loss: 1397300.3327, MAE: 5264.5142, R2: -0.1752\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [149/5000] | Time: 0.24s\n",
      "(Training) Loss: 1347921.5133\n",
      "(Validation) Loss: 1397024.8076, MAE: 5263.0923, R2: -0.1749\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [150/5000] | Time: 0.23s\n",
      "(Training) Loss: 1329508.9004\n",
      "(Validation) Loss: 1396742.1765, MAE: 5262.0669, R2: -0.1747\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [151/5000] | Time: 0.20s\n",
      "(Training) Loss: 1343047.1098\n",
      "(Validation) Loss: 1396468.8762, MAE: 5261.0771, R2: -0.1745\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [152/5000] | Time: 0.21s\n",
      "(Training) Loss: 1346620.3319\n",
      "(Validation) Loss: 1396190.6438, MAE: 5259.5820, R2: -0.1742\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [153/5000] | Time: 0.22s\n",
      "(Training) Loss: 1357509.9099\n",
      "(Validation) Loss: 1395913.1835, MAE: 5258.5894, R2: -0.1740\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [154/5000] | Time: 0.34s\n",
      "(Training) Loss: 1338497.6053\n",
      "(Validation) Loss: 1395630.2425, MAE: 5257.1919, R2: -0.1738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [155/5000] | Time: 0.25s\n",
      "(Training) Loss: 1361594.7576\n",
      "(Validation) Loss: 1395352.9346, MAE: 5255.9434, R2: -0.1735\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [156/5000] | Time: 0.30s\n",
      "(Training) Loss: 1342352.9695\n",
      "(Validation) Loss: 1395072.4622, MAE: 5255.0444, R2: -0.1733\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [157/5000] | Time: 0.32s\n",
      "(Training) Loss: 1377597.0470\n",
      "(Validation) Loss: 1394793.0768, MAE: 5253.8022, R2: -0.1731\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [158/5000] | Time: 0.26s\n",
      "(Training) Loss: 1340695.5990\n",
      "(Validation) Loss: 1394514.3721, MAE: 5252.6758, R2: -0.1728\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [159/5000] | Time: 0.25s\n",
      "(Training) Loss: 1347562.9702\n",
      "(Validation) Loss: 1394233.4222, MAE: 5251.2734, R2: -0.1726\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [160/5000] | Time: 0.26s\n",
      "(Training) Loss: 1349213.9670\n",
      "(Validation) Loss: 1393955.4184, MAE: 5250.2065, R2: -0.1724\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [161/5000] | Time: 0.23s\n",
      "(Training) Loss: 1339643.8325\n",
      "(Validation) Loss: 1393680.9194, MAE: 5248.8296, R2: -0.1721\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [162/5000] | Time: 0.26s\n",
      "(Training) Loss: 1343203.5343\n",
      "(Validation) Loss: 1393396.7187, MAE: 5247.4995, R2: -0.1719\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [163/5000] | Time: 0.25s\n",
      "(Training) Loss: 1341816.2462\n",
      "(Validation) Loss: 1393123.5251, MAE: 5246.4678, R2: -0.1717\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [164/5000] | Time: 0.22s\n",
      "(Training) Loss: 1356177.5152\n",
      "(Validation) Loss: 1392843.8095, MAE: 5245.2344, R2: -0.1715\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [165/5000] | Time: 0.25s\n",
      "(Training) Loss: 1336938.1345\n",
      "(Validation) Loss: 1392565.6737, MAE: 5244.0454, R2: -0.1712\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [166/5000] | Time: 0.27s\n",
      "(Training) Loss: 1330208.6967\n",
      "(Validation) Loss: 1392356.7848, MAE: 5243.5356, R2: -0.1710\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [167/5000] | Time: 0.28s\n",
      "(Training) Loss: 1333741.5901\n",
      "(Validation) Loss: 1392011.2305, MAE: 5241.7515, R2: -0.1708\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [168/5000] | Time: 0.27s\n",
      "(Training) Loss: 1331863.6599\n",
      "(Validation) Loss: 1391734.8114, MAE: 5240.6426, R2: -0.1705\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [169/5000] | Time: 0.27s\n",
      "(Training) Loss: 1336956.9975\n",
      "(Validation) Loss: 1391970.6565, MAE: 5243.3086, R2: -0.1707\n",
      "==========================================================================================\n",
      "Epoch [170/5000] | Time: 0.24s\n",
      "(Training) Loss: 1341334.0711\n",
      "(Validation) Loss: 1391177.4883, MAE: 5237.9473, R2: -0.1701\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [171/5000] | Time: 0.31s\n",
      "(Training) Loss: 1332050.6789\n",
      "(Validation) Loss: 1390902.2222, MAE: 5236.6567, R2: -0.1698\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [172/5000] | Time: 0.26s\n",
      "(Training) Loss: 1335687.1142\n",
      "(Validation) Loss: 1390625.1479, MAE: 5235.6294, R2: -0.1696\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [173/5000] | Time: 0.32s\n",
      "(Training) Loss: 1345313.9734\n",
      "(Validation) Loss: 1390344.4419, MAE: 5234.6655, R2: -0.1694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [174/5000] | Time: 0.25s\n",
      "(Training) Loss: 1347863.9962\n",
      "(Validation) Loss: 1390068.3225, MAE: 5233.2109, R2: -0.1691\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [175/5000] | Time: 0.28s\n",
      "(Training) Loss: 1341350.9645\n",
      "(Validation) Loss: 1389791.2838, MAE: 5231.8457, R2: -0.1689\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [176/5000] | Time: 0.27s\n",
      "(Training) Loss: 1319773.7350\n",
      "(Validation) Loss: 1389513.8438, MAE: 5231.3623, R2: -0.1687\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [177/5000] | Time: 0.25s\n",
      "(Training) Loss: 1323952.1326\n",
      "(Validation) Loss: 1389241.5949, MAE: 5230.0859, R2: -0.1684\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [178/5000] | Time: 0.25s\n",
      "(Training) Loss: 1341253.4492\n",
      "(Validation) Loss: 1388964.2210, MAE: 5228.4263, R2: -0.1682\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [179/5000] | Time: 0.25s\n",
      "(Training) Loss: 1351039.7322\n",
      "(Validation) Loss: 1388685.9632, MAE: 5227.0591, R2: -0.1680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [180/5000] | Time: 0.24s\n",
      "(Training) Loss: 1321112.1342\n",
      "(Validation) Loss: 1388408.3606, MAE: 5226.5381, R2: -0.1678\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [181/5000] | Time: 0.27s\n",
      "(Training) Loss: 1347007.4949\n",
      "(Validation) Loss: 1388132.3886, MAE: 5225.3779, R2: -0.1675\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [182/5000] | Time: 0.28s\n",
      "(Training) Loss: 1340209.0393\n",
      "(Validation) Loss: 1387849.8946, MAE: 5223.6255, R2: -0.1673\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [183/5000] | Time: 0.37s\n",
      "(Training) Loss: 1326512.9594\n",
      "(Validation) Loss: 1387575.1822, MAE: 5222.6899, R2: -0.1671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [184/5000] | Time: 0.33s\n",
      "(Training) Loss: 1346727.9645\n",
      "(Validation) Loss: 1387299.7841, MAE: 5221.2378, R2: -0.1668\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [185/5000] | Time: 0.25s\n",
      "(Training) Loss: 1336541.9302\n",
      "(Validation) Loss: 1387021.3790, MAE: 5220.0708, R2: -0.1666\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [186/5000] | Time: 0.21s\n",
      "(Training) Loss: 1331033.3617\n",
      "(Validation) Loss: 1386742.0444, MAE: 5218.8735, R2: -0.1664\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [187/5000] | Time: 0.20s\n",
      "(Training) Loss: 1320571.6409\n",
      "(Validation) Loss: 1386467.2203, MAE: 5217.7153, R2: -0.1661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [188/5000] | Time: 0.23s\n",
      "(Training) Loss: 1331949.9239\n",
      "(Validation) Loss: 1386193.9505, MAE: 5216.4561, R2: -0.1659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [189/5000] | Time: 0.19s\n",
      "(Training) Loss: 1326143.8769\n",
      "(Validation) Loss: 1385917.0641, MAE: 5215.6602, R2: -0.1657\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [190/5000] | Time: 0.20s\n",
      "(Training) Loss: 1350150.0190\n",
      "(Validation) Loss: 1385638.5676, MAE: 5214.1538, R2: -0.1654\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [191/5000] | Time: 0.20s\n",
      "(Training) Loss: 1355813.4289\n",
      "(Validation) Loss: 1385360.7314, MAE: 5212.8774, R2: -0.1652\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [192/5000] | Time: 0.19s\n",
      "(Training) Loss: 1336314.9175\n",
      "(Validation) Loss: 1385086.3695, MAE: 5212.0635, R2: -0.1650\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [193/5000] | Time: 0.20s\n",
      "(Training) Loss: 1326090.0063\n",
      "(Validation) Loss: 1384805.7448, MAE: 5211.4126, R2: -0.1648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [194/5000] | Time: 0.19s\n",
      "(Training) Loss: 1339058.5863\n",
      "(Validation) Loss: 1384533.4248, MAE: 5209.5000, R2: -0.1645\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [195/5000] | Time: 0.22s\n",
      "(Training) Loss: 1331884.0812\n",
      "(Validation) Loss: 1384257.1632, MAE: 5207.9951, R2: -0.1643\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [196/5000] | Time: 0.19s\n",
      "(Training) Loss: 1343568.9594\n",
      "(Validation) Loss: 1383978.0368, MAE: 5206.8999, R2: -0.1641\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [197/5000] | Time: 0.21s\n",
      "(Training) Loss: 1330550.1701\n",
      "(Validation) Loss: 1383697.8235, MAE: 5205.7808, R2: -0.1638\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [198/5000] | Time: 0.22s\n",
      "(Training) Loss: 1353400.0926\n",
      "(Validation) Loss: 1383426.4635, MAE: 5204.5859, R2: -0.1636\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [199/5000] | Time: 0.23s\n",
      "(Training) Loss: 1349902.1739\n",
      "(Validation) Loss: 1383147.6317, MAE: 5203.3208, R2: -0.1634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [200/5000] | Time: 0.20s\n",
      "(Training) Loss: 1325442.6371\n",
      "(Validation) Loss: 1382868.1549, MAE: 5201.9629, R2: -0.1631\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [201/5000] | Time: 0.19s\n",
      "(Training) Loss: 1339691.2957\n",
      "(Validation) Loss: 1382592.0000, MAE: 5200.8062, R2: -0.1629\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [202/5000] | Time: 0.23s\n",
      "(Training) Loss: 1334638.5787\n",
      "(Validation) Loss: 1382313.5898, MAE: 5199.9673, R2: -0.1627\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [203/5000] | Time: 0.24s\n",
      "(Training) Loss: 1321789.9201\n",
      "(Validation) Loss: 1382040.4622, MAE: 5198.6938, R2: -0.1624\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [204/5000] | Time: 0.21s\n",
      "(Training) Loss: 1325106.8718\n",
      "(Validation) Loss: 1381765.5924, MAE: 5197.4941, R2: -0.1622\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [205/5000] | Time: 0.21s\n",
      "(Training) Loss: 1375695.6891\n",
      "(Validation) Loss: 1381491.2711, MAE: 5196.5483, R2: -0.1620\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [206/5000] | Time: 0.22s\n",
      "(Training) Loss: 1359553.6472\n",
      "(Validation) Loss: 1381209.5594, MAE: 5195.0630, R2: -0.1618\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [207/5000] | Time: 0.21s\n",
      "(Training) Loss: 1330251.4518\n",
      "(Validation) Loss: 1380931.1594, MAE: 5193.4609, R2: -0.1615\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [208/5000] | Time: 0.22s\n",
      "(Training) Loss: 1336517.9492\n",
      "(Validation) Loss: 1380653.2419, MAE: 5192.6055, R2: -0.1613\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [209/5000] | Time: 0.25s\n",
      "(Training) Loss: 1313006.0701\n",
      "(Validation) Loss: 1380383.4717, MAE: 5192.2339, R2: -0.1611\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [210/5000] | Time: 0.23s\n",
      "(Training) Loss: 1336297.7576\n",
      "(Validation) Loss: 1380111.5022, MAE: 5190.6016, R2: -0.1608\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [211/5000] | Time: 0.22s\n",
      "(Training) Loss: 1328080.8864\n",
      "(Validation) Loss: 1379836.0025, MAE: 5189.9004, R2: -0.1606\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [212/5000] | Time: 0.25s\n",
      "(Training) Loss: 1335356.8020\n",
      "(Validation) Loss: 1379563.5759, MAE: 5188.4175, R2: -0.1604\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [213/5000] | Time: 0.26s\n",
      "(Training) Loss: 1342013.8782\n",
      "(Validation) Loss: 1379287.3244, MAE: 5186.8174, R2: -0.1602\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [214/5000] | Time: 0.37s\n",
      "(Training) Loss: 1330565.9397\n",
      "(Validation) Loss: 1379009.3562, MAE: 5185.6411, R2: -0.1599\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [215/5000] | Time: 0.25s\n",
      "(Training) Loss: 1330670.1764\n",
      "(Validation) Loss: 1378734.1816, MAE: 5184.6592, R2: -0.1597\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [216/5000] | Time: 0.26s\n",
      "(Training) Loss: 1325055.1003\n",
      "(Validation) Loss: 1378461.0489, MAE: 5182.9580, R2: -0.1595\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [217/5000] | Time: 0.29s\n",
      "(Training) Loss: 1340704.7525\n",
      "(Validation) Loss: 1378187.6165, MAE: 5182.0693, R2: -0.1592\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [218/5000] | Time: 0.34s\n",
      "(Training) Loss: 1320944.1294\n",
      "(Validation) Loss: 1377911.9543, MAE: 5180.4370, R2: -0.1590\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [219/5000] | Time: 0.28s\n",
      "(Training) Loss: 1348618.9353\n",
      "(Validation) Loss: 1377638.9943, MAE: 5179.5659, R2: -0.1588\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [220/5000] | Time: 0.32s\n",
      "(Training) Loss: 1329642.7843\n",
      "(Validation) Loss: 1377361.0971, MAE: 5178.2305, R2: -0.1585\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [221/5000] | Time: 0.23s\n",
      "(Training) Loss: 1318589.3344\n",
      "(Validation) Loss: 1377084.4190, MAE: 5177.3462, R2: -0.1583\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [222/5000] | Time: 0.28s\n",
      "(Training) Loss: 1331368.8109\n",
      "(Validation) Loss: 1376810.6463, MAE: 5175.9424, R2: -0.1581\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [223/5000] | Time: 0.25s\n",
      "(Training) Loss: 1334986.5926\n",
      "(Validation) Loss: 1376539.5048, MAE: 5174.8540, R2: -0.1579\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [224/5000] | Time: 0.23s\n",
      "(Training) Loss: 1315985.0184\n",
      "(Validation) Loss: 1376264.4216, MAE: 5173.4717, R2: -0.1576\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [225/5000] | Time: 0.20s\n",
      "(Training) Loss: 1328346.7868\n",
      "(Validation) Loss: 1375992.4317, MAE: 5172.4756, R2: -0.1574\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [226/5000] | Time: 0.23s\n",
      "(Training) Loss: 1320760.9442\n",
      "(Validation) Loss: 1375716.0381, MAE: 5171.5195, R2: -0.1572\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [227/5000] | Time: 0.26s\n",
      "(Training) Loss: 1354110.3864\n",
      "(Validation) Loss: 1375445.7397, MAE: 5170.2969, R2: -0.1569\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [228/5000] | Time: 0.22s\n",
      "(Training) Loss: 1340254.1865\n",
      "(Validation) Loss: 1375167.6546, MAE: 5169.1255, R2: -0.1567\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [229/5000] | Time: 0.19s\n",
      "(Training) Loss: 1317942.0863\n",
      "(Validation) Loss: 1374890.7530, MAE: 5167.6328, R2: -0.1565\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [230/5000] | Time: 0.21s\n",
      "(Training) Loss: 1318960.4010\n",
      "(Validation) Loss: 1374620.4292, MAE: 5167.1641, R2: -0.1563\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [231/5000] | Time: 0.20s\n",
      "(Training) Loss: 1339839.2538\n",
      "(Validation) Loss: 1374345.8794, MAE: 5166.0571, R2: -0.1560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [232/5000] | Time: 0.19s\n",
      "(Training) Loss: 1324128.1523\n",
      "(Validation) Loss: 1374072.7365, MAE: 5164.6860, R2: -0.1558\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [233/5000] | Time: 0.19s\n",
      "(Training) Loss: 1336416.7881\n",
      "(Validation) Loss: 1373801.0108, MAE: 5163.7266, R2: -0.1556\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [234/5000] | Time: 0.23s\n",
      "(Training) Loss: 1342967.3642\n",
      "(Validation) Loss: 1373525.1098, MAE: 5162.3452, R2: -0.1553\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [235/5000] | Time: 0.21s\n",
      "(Training) Loss: 1320857.2563\n",
      "(Validation) Loss: 1373248.0203, MAE: 5160.8301, R2: -0.1551\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [236/5000] | Time: 0.22s\n",
      "(Training) Loss: 1333556.5292\n",
      "(Validation) Loss: 1372975.9441, MAE: 5160.3770, R2: -0.1549\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [237/5000] | Time: 0.21s\n",
      "(Training) Loss: 1332010.6472\n",
      "(Validation) Loss: 1372699.8298, MAE: 5159.1382, R2: -0.1547\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [238/5000] | Time: 0.31s\n",
      "(Training) Loss: 1333032.1751\n",
      "(Validation) Loss: 1372425.5543, MAE: 5157.6836, R2: -0.1544\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [239/5000] | Time: 0.25s\n",
      "(Training) Loss: 1315854.9594\n",
      "(Validation) Loss: 1372156.2565, MAE: 5156.5522, R2: -0.1542\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [240/5000] | Time: 0.25s\n",
      "(Training) Loss: 1329894.7538\n",
      "(Validation) Loss: 1371882.1283, MAE: 5155.0288, R2: -0.1540\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [241/5000] | Time: 0.28s\n",
      "(Training) Loss: 1326781.6536\n",
      "(Validation) Loss: 1371607.7105, MAE: 5153.9170, R2: -0.1538\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [242/5000] | Time: 0.30s\n",
      "(Training) Loss: 1327009.0190\n",
      "(Validation) Loss: 1371336.0356, MAE: 5152.8804, R2: -0.1535\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [243/5000] | Time: 0.25s\n",
      "(Training) Loss: 1313854.3198\n",
      "(Validation) Loss: 1371063.4565, MAE: 5151.3750, R2: -0.1533\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [244/5000] | Time: 0.26s\n",
      "(Training) Loss: 1335513.6352\n",
      "(Validation) Loss: 1370792.1676, MAE: 5150.2500, R2: -0.1531\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [245/5000] | Time: 0.29s\n",
      "(Training) Loss: 1325962.6548\n",
      "(Validation) Loss: 1370515.1441, MAE: 5149.0088, R2: -0.1528\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [246/5000] | Time: 0.32s\n",
      "(Training) Loss: 1341291.3852\n",
      "(Validation) Loss: 1370238.5168, MAE: 5147.8237, R2: -0.1526\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [247/5000] | Time: 0.35s\n",
      "(Training) Loss: 1308785.7062\n",
      "(Validation) Loss: 1369967.7562, MAE: 5146.5415, R2: -0.1524\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [248/5000] | Time: 0.32s\n",
      "(Training) Loss: 1316542.6739\n",
      "(Validation) Loss: 1369695.4717, MAE: 5145.3569, R2: -0.1522\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [249/5000] | Time: 0.29s\n",
      "(Training) Loss: 1306270.9175\n",
      "(Validation) Loss: 1369423.4463, MAE: 5144.3398, R2: -0.1519\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [250/5000] | Time: 0.31s\n",
      "(Training) Loss: 1322865.2475\n",
      "(Validation) Loss: 1369156.1651, MAE: 5143.1772, R2: -0.1517\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [251/5000] | Time: 0.36s\n",
      "(Training) Loss: 1330869.1853\n",
      "(Validation) Loss: 1368882.0470, MAE: 5141.7900, R2: -0.1515\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [252/5000] | Time: 0.29s\n",
      "(Training) Loss: 1310621.1865\n",
      "(Validation) Loss: 1368605.4349, MAE: 5141.3364, R2: -0.1512\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [253/5000] | Time: 0.30s\n",
      "(Training) Loss: 1322874.5825\n",
      "(Validation) Loss: 1368336.6857, MAE: 5139.9111, R2: -0.1510\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [254/5000] | Time: 0.31s\n",
      "(Training) Loss: 1300286.5048\n",
      "(Validation) Loss: 1368063.4616, MAE: 5138.3916, R2: -0.1508\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [255/5000] | Time: 0.34s\n",
      "(Training) Loss: 1316904.9543\n",
      "(Validation) Loss: 1367793.4832, MAE: 5137.3770, R2: -0.1506\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [256/5000] | Time: 0.28s\n",
      "(Training) Loss: 1351574.1751\n",
      "(Validation) Loss: 1367523.5048, MAE: 5136.0127, R2: -0.1503\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [257/5000] | Time: 0.27s\n",
      "(Training) Loss: 1307606.7893\n",
      "(Validation) Loss: 1367245.6381, MAE: 5135.2490, R2: -0.1501\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [258/5000] | Time: 0.28s\n",
      "(Training) Loss: 1308395.9619\n",
      "(Validation) Loss: 1366979.8400, MAE: 5133.9956, R2: -0.1499\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [259/5000] | Time: 0.32s\n",
      "(Training) Loss: 1326217.7874\n",
      "(Validation) Loss: 1366707.5556, MAE: 5132.6348, R2: -0.1497\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [260/5000] | Time: 0.24s\n",
      "(Training) Loss: 1337899.0495\n",
      "(Validation) Loss: 1366435.7587, MAE: 5131.4185, R2: -0.1494\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [261/5000] | Time: 0.25s\n",
      "(Training) Loss: 1313944.9835\n",
      "(Validation) Loss: 1366159.5175, MAE: 5130.1313, R2: -0.1492\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [262/5000] | Time: 0.28s\n",
      "(Training) Loss: 1301080.9740\n",
      "(Validation) Loss: 1365891.3625, MAE: 5129.0259, R2: -0.1490\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [263/5000] | Time: 0.28s\n",
      "(Training) Loss: 1300936.4312\n",
      "(Validation) Loss: 1365620.4851, MAE: 5128.1099, R2: -0.1488\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [264/5000] | Time: 0.28s\n",
      "(Training) Loss: 1311094.8788\n",
      "(Validation) Loss: 1365353.7727, MAE: 5126.6147, R2: -0.1485\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [265/5000] | Time: 0.26s\n",
      "(Training) Loss: 1318421.1409\n",
      "(Validation) Loss: 1365079.9848, MAE: 5125.5923, R2: -0.1483\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [266/5000] | Time: 0.27s\n",
      "(Training) Loss: 1299424.7164\n",
      "(Validation) Loss: 1364810.9968, MAE: 5124.5059, R2: -0.1481\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [267/5000] | Time: 0.26s\n",
      "(Training) Loss: 1334256.8223\n",
      "(Validation) Loss: 1364540.6476, MAE: 5122.9893, R2: -0.1479\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [268/5000] | Time: 0.28s\n",
      "(Training) Loss: 1325098.3947\n",
      "(Validation) Loss: 1364268.2260, MAE: 5122.0386, R2: -0.1476\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [269/5000] | Time: 0.24s\n",
      "(Training) Loss: 1306776.2386\n",
      "(Validation) Loss: 1363994.1689, MAE: 5120.6450, R2: -0.1474\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [270/5000] | Time: 0.27s\n",
      "(Training) Loss: 1322958.9270\n",
      "(Validation) Loss: 1363722.0622, MAE: 5119.5942, R2: -0.1472\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [271/5000] | Time: 0.27s\n",
      "(Training) Loss: 1321031.8883\n",
      "(Validation) Loss: 1363449.9911, MAE: 5118.5430, R2: -0.1470\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [272/5000] | Time: 0.29s\n",
      "(Training) Loss: 1315754.3871\n",
      "(Validation) Loss: 1363176.1016, MAE: 5117.2642, R2: -0.1467\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [273/5000] | Time: 0.28s\n",
      "(Training) Loss: 1319901.4264\n",
      "(Validation) Loss: 1362909.0489, MAE: 5116.7666, R2: -0.1465\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [274/5000] | Time: 0.32s\n",
      "(Training) Loss: 1307027.3109\n",
      "(Validation) Loss: 1362636.1397, MAE: 5115.3311, R2: -0.1463\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [275/5000] | Time: 0.26s\n",
      "(Training) Loss: 1300464.8718\n",
      "(Validation) Loss: 1362365.6940, MAE: 5114.0312, R2: -0.1460\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [276/5000] | Time: 0.31s\n",
      "(Training) Loss: 1309988.6256\n",
      "(Validation) Loss: 1362098.0521, MAE: 5112.6729, R2: -0.1458\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [277/5000] | Time: 0.28s\n",
      "(Training) Loss: 1326296.8706\n",
      "(Validation) Loss: 1361828.6730, MAE: 5111.4839, R2: -0.1456\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [278/5000] | Time: 0.29s\n",
      "(Training) Loss: 1308570.6726\n",
      "(Validation) Loss: 1361554.4990, MAE: 5110.6338, R2: -0.1454\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [279/5000] | Time: 0.29s\n",
      "(Training) Loss: 1313419.5774\n",
      "(Validation) Loss: 1361283.2508, MAE: 5109.0854, R2: -0.1451\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [280/5000] | Time: 0.29s\n",
      "(Training) Loss: 1303509.9911\n",
      "(Validation) Loss: 1361016.4419, MAE: 5107.8716, R2: -0.1449\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [281/5000] | Time: 0.33s\n",
      "(Training) Loss: 1310821.6701\n",
      "(Validation) Loss: 1360742.7606, MAE: 5106.6899, R2: -0.1447\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [282/5000] | Time: 0.40s\n",
      "(Training) Loss: 1306465.1878\n",
      "(Validation) Loss: 1360473.1378, MAE: 5105.6187, R2: -0.1445\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [283/5000] | Time: 0.32s\n",
      "(Training) Loss: 1295527.1056\n",
      "(Validation) Loss: 1360205.7448, MAE: 5104.4399, R2: -0.1442\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [284/5000] | Time: 0.36s\n",
      "(Training) Loss: 1313917.5964\n",
      "(Validation) Loss: 1359936.2184, MAE: 5103.3330, R2: -0.1440\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [285/5000] | Time: 0.26s\n",
      "(Training) Loss: 1306239.4150\n",
      "(Validation) Loss: 1359665.7016, MAE: 5102.0293, R2: -0.1438\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [286/5000] | Time: 0.36s\n",
      "(Training) Loss: 1314124.0964\n",
      "(Validation) Loss: 1359395.8806, MAE: 5101.2710, R2: -0.1436\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [287/5000] | Time: 0.32s\n",
      "(Training) Loss: 1317641.9569\n",
      "(Validation) Loss: 1359123.0730, MAE: 5100.0718, R2: -0.1433\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [288/5000] | Time: 0.32s\n",
      "(Training) Loss: 1314862.6085\n",
      "(Validation) Loss: 1358853.4806, MAE: 5098.4414, R2: -0.1431\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [289/5000] | Time: 0.26s\n",
      "(Training) Loss: 1307268.6396\n",
      "(Validation) Loss: 1358584.3048, MAE: 5097.5874, R2: -0.1429\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [290/5000] | Time: 0.32s\n",
      "(Training) Loss: 1296886.8832\n",
      "(Validation) Loss: 1358317.7346, MAE: 5096.4106, R2: -0.1427\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [291/5000] | Time: 0.38s\n",
      "(Training) Loss: 1310981.8135\n",
      "(Validation) Loss: 1358049.2800, MAE: 5095.3101, R2: -0.1425\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [292/5000] | Time: 0.34s\n",
      "(Training) Loss: 1306107.9607\n",
      "(Validation) Loss: 1357776.7060, MAE: 5094.8071, R2: -0.1422\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [293/5000] | Time: 0.28s\n",
      "(Training) Loss: 1303006.7716\n",
      "(Validation) Loss: 1357504.0914, MAE: 5093.0151, R2: -0.1420\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [294/5000] | Time: 0.27s\n",
      "(Training) Loss: 1292029.5701\n",
      "(Validation) Loss: 1357236.1651, MAE: 5091.8418, R2: -0.1418\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [295/5000] | Time: 0.24s\n",
      "(Training) Loss: 1303362.0977\n",
      "(Validation) Loss: 1356966.9994, MAE: 5090.3940, R2: -0.1415\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [296/5000] | Time: 0.24s\n",
      "(Training) Loss: 1299556.5736\n",
      "(Validation) Loss: 1356699.8146, MAE: 5089.3623, R2: -0.1413\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [297/5000] | Time: 0.26s\n",
      "(Training) Loss: 1316498.1155\n",
      "(Validation) Loss: 1356432.3454, MAE: 5088.4014, R2: -0.1411\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [298/5000] | Time: 0.29s\n",
      "(Training) Loss: 1319660.1168\n",
      "(Validation) Loss: 1356161.9149, MAE: 5087.4746, R2: -0.1409\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [299/5000] | Time: 0.40s\n",
      "(Training) Loss: 1331095.7805\n",
      "(Validation) Loss: 1355885.9987, MAE: 5085.9146, R2: -0.1406\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [300/5000] | Time: 0.38s\n",
      "(Training) Loss: 1307024.9061\n",
      "(Validation) Loss: 1355613.6940, MAE: 5085.1846, R2: -0.1404\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [301/5000] | Time: 0.38s\n",
      "(Training) Loss: 1297892.4429\n",
      "(Validation) Loss: 1355344.2438, MAE: 5083.5503, R2: -0.1402\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [302/5000] | Time: 0.28s\n",
      "(Training) Loss: 1293668.3617\n",
      "(Validation) Loss: 1355076.3530, MAE: 5082.2129, R2: -0.1400\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [303/5000] | Time: 0.32s\n",
      "(Training) Loss: 1314341.0660\n",
      "(Validation) Loss: 1354810.4483, MAE: 5081.1650, R2: -0.1398\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [304/5000] | Time: 0.33s\n",
      "(Training) Loss: 1299632.6878\n",
      "(Validation) Loss: 1354541.5010, MAE: 5081.2051, R2: -0.1395\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [305/5000] | Time: 0.33s\n",
      "(Training) Loss: 1294907.6929\n",
      "(Validation) Loss: 1354270.5270, MAE: 5080.1484, R2: -0.1393\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [306/5000] | Time: 0.38s\n",
      "(Training) Loss: 1321150.8852\n",
      "(Validation) Loss: 1354002.4990, MAE: 5078.7173, R2: -0.1391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [307/5000] | Time: 0.33s\n",
      "(Training) Loss: 1298222.8997\n",
      "(Validation) Loss: 1353727.6800, MAE: 5076.7734, R2: -0.1388\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [308/5000] | Time: 0.41s\n",
      "(Training) Loss: 1299911.5292\n",
      "(Validation) Loss: 1353462.9892, MAE: 5075.6484, R2: -0.1386\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [309/5000] | Time: 0.44s\n",
      "(Training) Loss: 1321902.1751\n",
      "(Validation) Loss: 1353193.1886, MAE: 5074.6523, R2: -0.1384\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [310/5000] | Time: 0.40s\n",
      "(Training) Loss: 1322263.0343\n",
      "(Validation) Loss: 1354216.5283, MAE: 5079.1714, R2: -0.1393\n",
      "==========================================================================================\n",
      "Epoch [311/5000] | Time: 0.36s\n",
      "(Training) Loss: 1292429.1707\n",
      "(Validation) Loss: 1352648.7010, MAE: 5072.1904, R2: -0.1380\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [312/5000] | Time: 0.36s\n",
      "(Training) Loss: 1308609.1967\n",
      "(Validation) Loss: 1352386.4432, MAE: 5071.5845, R2: -0.1377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [313/5000] | Time: 0.33s\n",
      "(Training) Loss: 1307822.1072\n",
      "(Validation) Loss: 1352121.5441, MAE: 5069.8364, R2: -0.1375\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [314/5000] | Time: 0.28s\n",
      "(Training) Loss: 1328661.0723\n",
      "(Validation) Loss: 1351844.8356, MAE: 5068.4868, R2: -0.1373\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [315/5000] | Time: 0.27s\n",
      "(Training) Loss: 1289873.7646\n",
      "(Validation) Loss: 1351576.3403, MAE: 5067.8716, R2: -0.1371\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [316/5000] | Time: 0.29s\n",
      "(Training) Loss: 1291628.6117\n",
      "(Validation) Loss: 1351306.8800, MAE: 5066.3862, R2: -0.1368\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [317/5000] | Time: 0.29s\n",
      "(Training) Loss: 1306329.9714\n",
      "(Validation) Loss: 1351040.9041, MAE: 5064.9155, R2: -0.1366\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [318/5000] | Time: 0.27s\n",
      "(Training) Loss: 1294421.3744\n",
      "(Validation) Loss: 1350772.6222, MAE: 5063.9155, R2: -0.1364\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [319/5000] | Time: 0.38s\n",
      "(Training) Loss: 1294848.8439\n",
      "(Validation) Loss: 1350508.4140, MAE: 5062.7920, R2: -0.1362\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [320/5000] | Time: 0.45s\n",
      "(Training) Loss: 1284462.0143\n",
      "(Validation) Loss: 1350238.9029, MAE: 5061.7192, R2: -0.1359\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [321/5000] | Time: 0.41s\n",
      "(Training) Loss: 1294873.5190\n",
      "(Validation) Loss: 1349972.6679, MAE: 5060.4487, R2: -0.1357\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [322/5000] | Time: 0.25s\n",
      "(Training) Loss: 1292088.9670\n",
      "(Validation) Loss: 1349705.7575, MAE: 5059.6221, R2: -0.1355\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [323/5000] | Time: 0.41s\n",
      "(Training) Loss: 1293284.3706\n",
      "(Validation) Loss: 1349440.0356, MAE: 5058.9976, R2: -0.1353\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [324/5000] | Time: 0.34s\n",
      "(Training) Loss: 1299162.0673\n",
      "(Validation) Loss: 1349172.1092, MAE: 5056.9795, R2: -0.1351\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [325/5000] | Time: 0.27s\n",
      "(Training) Loss: 1282931.5159\n",
      "(Validation) Loss: 1348903.2330, MAE: 5056.4072, R2: -0.1348\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [326/5000] | Time: 0.30s\n",
      "(Training) Loss: 1298585.4156\n",
      "(Validation) Loss: 1348638.1308, MAE: 5054.7788, R2: -0.1346\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [327/5000] | Time: 0.26s\n",
      "(Training) Loss: 1318764.7440\n",
      "(Validation) Loss: 1348370.7683, MAE: 5053.7969, R2: -0.1344\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [328/5000] | Time: 0.31s\n",
      "(Training) Loss: 1305680.7513\n",
      "(Validation) Loss: 1348101.7549, MAE: 5052.4541, R2: -0.1342\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [329/5000] | Time: 0.36s\n",
      "(Training) Loss: 1285158.5133\n",
      "(Validation) Loss: 1347835.0679, MAE: 5051.5938, R2: -0.1339\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [330/5000] | Time: 0.34s\n",
      "(Training) Loss: 1296368.6079\n",
      "(Validation) Loss: 1347564.3479, MAE: 5050.2437, R2: -0.1337\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [331/5000] | Time: 0.30s\n",
      "(Training) Loss: 1302249.9575\n",
      "(Validation) Loss: 1347297.1530, MAE: 5049.3423, R2: -0.1335\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [332/5000] | Time: 0.31s\n",
      "(Training) Loss: 1308247.3617\n",
      "(Validation) Loss: 1347032.5029, MAE: 5047.7300, R2: -0.1333\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [333/5000] | Time: 0.34s\n",
      "(Training) Loss: 1320845.8718\n",
      "(Validation) Loss: 1346762.3314, MAE: 5047.2290, R2: -0.1330\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [334/5000] | Time: 0.29s\n",
      "(Training) Loss: 1302225.5241\n",
      "(Validation) Loss: 1346493.3994, MAE: 5046.0459, R2: -0.1328\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [335/5000] | Time: 0.32s\n",
      "(Training) Loss: 1294419.7062\n",
      "(Validation) Loss: 1346223.8324, MAE: 5044.8135, R2: -0.1326\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [336/5000] | Time: 0.27s\n",
      "(Training) Loss: 1299116.8820\n",
      "(Validation) Loss: 1345954.8343, MAE: 5043.4678, R2: -0.1324\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [337/5000] | Time: 0.26s\n",
      "(Training) Loss: 1335167.3947\n",
      "(Validation) Loss: 1345689.7981, MAE: 5042.2090, R2: -0.1322\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [338/5000] | Time: 0.26s\n",
      "(Training) Loss: 1303184.9524\n",
      "(Validation) Loss: 1345418.8648, MAE: 5041.1401, R2: -0.1319\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [339/5000] | Time: 0.30s\n",
      "(Training) Loss: 1299420.9258\n",
      "(Validation) Loss: 1345150.7708, MAE: 5039.9272, R2: -0.1317\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [340/5000] | Time: 0.27s\n",
      "(Training) Loss: 1301407.2525\n",
      "(Validation) Loss: 1344882.3619, MAE: 5038.8887, R2: -0.1315\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [341/5000] | Time: 0.29s\n",
      "(Training) Loss: 1279337.0504\n",
      "(Validation) Loss: 1344615.7410, MAE: 5037.4019, R2: -0.1313\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [342/5000] | Time: 0.28s\n",
      "(Training) Loss: 1295538.9239\n",
      "(Validation) Loss: 1344350.4813, MAE: 5036.5151, R2: -0.1310\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [343/5000] | Time: 0.32s\n",
      "(Training) Loss: 1310749.6485\n",
      "(Validation) Loss: 1344088.2083, MAE: 5037.0024, R2: -0.1308\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [344/5000] | Time: 0.36s\n",
      "(Training) Loss: 1307325.0086\n",
      "(Validation) Loss: 1343816.6248, MAE: 5034.1338, R2: -0.1306\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [345/5000] | Time: 0.31s\n",
      "(Training) Loss: 1312625.0038\n",
      "(Validation) Loss: 1343547.3575, MAE: 5033.0923, R2: -0.1304\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [346/5000] | Time: 0.28s\n",
      "(Training) Loss: 1295885.8477\n",
      "(Validation) Loss: 1343279.3752, MAE: 5032.6938, R2: -0.1301\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [347/5000] | Time: 0.28s\n",
      "(Training) Loss: 1279279.5105\n",
      "(Validation) Loss: 1343015.4260, MAE: 5030.8604, R2: -0.1299\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [348/5000] | Time: 0.25s\n",
      "(Training) Loss: 1322068.2056\n",
      "(Validation) Loss: 1342755.0883, MAE: 5029.5840, R2: -0.1297\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [349/5000] | Time: 0.26s\n",
      "(Training) Loss: 1281909.5051\n",
      "(Validation) Loss: 1342478.6794, MAE: 5028.6577, R2: -0.1295\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [350/5000] | Time: 0.30s\n",
      "(Training) Loss: 1300116.6802\n",
      "(Validation) Loss: 1342216.9905, MAE: 5027.2129, R2: -0.1293\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [351/5000] | Time: 0.31s\n",
      "(Training) Loss: 1291266.0102\n",
      "(Validation) Loss: 1341952.4013, MAE: 5027.2695, R2: -0.1290\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [352/5000] | Time: 0.32s\n",
      "(Training) Loss: 1299772.0089\n",
      "(Validation) Loss: 1341683.4133, MAE: 5024.7500, R2: -0.1288\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [353/5000] | Time: 0.31s\n",
      "(Training) Loss: 1285412.3350\n",
      "(Validation) Loss: 1341416.7517, MAE: 5023.9331, R2: -0.1286\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [354/5000] | Time: 0.32s\n",
      "(Training) Loss: 1284044.0603\n",
      "(Validation) Loss: 1341152.2286, MAE: 5023.1431, R2: -0.1284\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [355/5000] | Time: 0.27s\n",
      "(Training) Loss: 1304115.1339\n",
      "(Validation) Loss: 1340886.9333, MAE: 5022.6802, R2: -0.1281\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [356/5000] | Time: 0.26s\n",
      "(Training) Loss: 1305146.4099\n",
      "(Validation) Loss: 1340625.5390, MAE: 5020.8662, R2: -0.1279\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [357/5000] | Time: 0.28s\n",
      "(Training) Loss: 1285738.3629\n",
      "(Validation) Loss: 1340357.2267, MAE: 5019.3765, R2: -0.1277\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [358/5000] | Time: 0.28s\n",
      "(Training) Loss: 1302743.3553\n",
      "(Validation) Loss: 1340091.8044, MAE: 5018.3525, R2: -0.1275\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [359/5000] | Time: 0.28s\n",
      "(Training) Loss: 1285959.5412\n",
      "(Validation) Loss: 1339820.2971, MAE: 5016.9136, R2: -0.1273\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [360/5000] | Time: 0.26s\n",
      "(Training) Loss: 1297689.7348\n",
      "(Validation) Loss: 1339559.4260, MAE: 5015.8823, R2: -0.1270\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [361/5000] | Time: 0.26s\n",
      "(Training) Loss: 1301524.1358\n",
      "(Validation) Loss: 1339293.3537, MAE: 5014.7544, R2: -0.1268\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [362/5000] | Time: 0.29s\n",
      "(Training) Loss: 1283645.7887\n",
      "(Validation) Loss: 1339027.4946, MAE: 5014.0303, R2: -0.1266\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [363/5000] | Time: 0.27s\n",
      "(Training) Loss: 1309512.7766\n",
      "(Validation) Loss: 1338762.9105, MAE: 5012.4839, R2: -0.1264\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [364/5000] | Time: 0.26s\n",
      "(Training) Loss: 1303994.3921\n",
      "(Validation) Loss: 1338493.5162, MAE: 5011.0317, R2: -0.1262\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [365/5000] | Time: 0.28s\n",
      "(Training) Loss: 1284170.0520\n",
      "(Validation) Loss: 1338227.0425, MAE: 5010.2148, R2: -0.1259\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [366/5000] | Time: 0.27s\n",
      "(Training) Loss: 1320405.3452\n",
      "(Validation) Loss: 1337967.9238, MAE: 5010.0317, R2: -0.1257\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [367/5000] | Time: 0.28s\n",
      "(Training) Loss: 1280382.1282\n",
      "(Validation) Loss: 1337695.0959, MAE: 5007.9102, R2: -0.1255\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [368/5000] | Time: 0.27s\n",
      "(Training) Loss: 1284167.7367\n",
      "(Validation) Loss: 1337433.0463, MAE: 5006.9390, R2: -0.1253\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [369/5000] | Time: 0.27s\n",
      "(Training) Loss: 1286882.2145\n",
      "(Validation) Loss: 1337166.4152, MAE: 5005.3901, R2: -0.1250\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [370/5000] | Time: 0.30s\n",
      "(Training) Loss: 1283517.4829\n",
      "(Validation) Loss: 1336904.7365, MAE: 5004.6021, R2: -0.1248\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [371/5000] | Time: 0.29s\n",
      "(Training) Loss: 1285965.4315\n",
      "(Validation) Loss: 1336639.5429, MAE: 5004.0596, R2: -0.1246\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [372/5000] | Time: 0.30s\n",
      "(Training) Loss: 1287769.8388\n",
      "(Validation) Loss: 1336382.1410, MAE: 5003.5039, R2: -0.1244\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [373/5000] | Time: 0.28s\n",
      "(Training) Loss: 1311770.6459\n",
      "(Validation) Loss: 1336109.9581, MAE: 5001.2559, R2: -0.1242\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [374/5000] | Time: 0.28s\n",
      "(Training) Loss: 1312209.4315\n",
      "(Validation) Loss: 1335846.3949, MAE: 5000.4087, R2: -0.1239\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [375/5000] | Time: 0.41s\n",
      "(Training) Loss: 1296641.3934\n",
      "(Validation) Loss: 1335579.7130, MAE: 4998.7837, R2: -0.1237\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [376/5000] | Time: 0.26s\n",
      "(Training) Loss: 1287298.1123\n",
      "(Validation) Loss: 1335312.0152, MAE: 4998.4028, R2: -0.1235\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [377/5000] | Time: 0.27s\n",
      "(Training) Loss: 1294641.5317\n",
      "(Validation) Loss: 1335047.8730, MAE: 4996.6411, R2: -0.1233\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [378/5000] | Time: 0.29s\n",
      "(Training) Loss: 1275519.2557\n",
      "(Validation) Loss: 1334784.5740, MAE: 4996.0347, R2: -0.1231\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [379/5000] | Time: 0.25s\n",
      "(Training) Loss: 1288082.0470\n",
      "(Validation) Loss: 1334520.3048, MAE: 4995.0229, R2: -0.1228\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [380/5000] | Time: 0.27s\n",
      "(Training) Loss: 1296087.4822\n",
      "(Validation) Loss: 1334255.6800, MAE: 4993.6328, R2: -0.1226\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [381/5000] | Time: 0.33s\n",
      "(Training) Loss: 1284197.7766\n",
      "(Validation) Loss: 1333990.3187, MAE: 4992.5205, R2: -0.1224\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [382/5000] | Time: 0.33s\n",
      "(Training) Loss: 1287646.3211\n",
      "(Validation) Loss: 1333728.1270, MAE: 4991.0542, R2: -0.1222\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [383/5000] | Time: 0.25s\n",
      "(Training) Loss: 1298508.6485\n",
      "(Validation) Loss: 1333461.1098, MAE: 4989.9756, R2: -0.1220\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [384/5000] | Time: 0.25s\n",
      "(Training) Loss: 1271669.6129\n",
      "(Validation) Loss: 1333196.8660, MAE: 4989.6050, R2: -0.1217\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [385/5000] | Time: 0.27s\n",
      "(Training) Loss: 1275762.4353\n",
      "(Validation) Loss: 1332935.9898, MAE: 4988.4219, R2: -0.1215\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [386/5000] | Time: 0.31s\n",
      "(Training) Loss: 1282113.1561\n",
      "(Validation) Loss: 1332672.0102, MAE: 4986.6064, R2: -0.1213\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [387/5000] | Time: 0.26s\n",
      "(Training) Loss: 1269239.4800\n",
      "(Validation) Loss: 1332407.6343, MAE: 4985.4897, R2: -0.1211\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [388/5000] | Time: 0.25s\n",
      "(Training) Loss: 1278450.9086\n",
      "(Validation) Loss: 1332149.8565, MAE: 4984.4038, R2: -0.1209\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [389/5000] | Time: 0.26s\n",
      "(Training) Loss: 1276518.2005\n",
      "(Validation) Loss: 1331887.1010, MAE: 4984.3384, R2: -0.1207\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [390/5000] | Time: 0.26s\n",
      "(Training) Loss: 1301554.8230\n",
      "(Validation) Loss: 1331621.9073, MAE: 4982.9888, R2: -0.1204\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [391/5000] | Time: 0.25s\n",
      "(Training) Loss: 1278521.2107\n",
      "(Validation) Loss: 1331359.2990, MAE: 4981.2524, R2: -0.1202\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [392/5000] | Time: 0.22s\n",
      "(Training) Loss: 1290996.7322\n",
      "(Validation) Loss: 1331095.4108, MAE: 4980.1919, R2: -0.1200\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [393/5000] | Time: 0.24s\n",
      "(Training) Loss: 1275680.5654\n",
      "(Validation) Loss: 1330830.1816, MAE: 4978.9814, R2: -0.1198\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [394/5000] | Time: 0.30s\n",
      "(Training) Loss: 1298766.2449\n",
      "(Validation) Loss: 1330566.2476, MAE: 4977.8623, R2: -0.1195\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [395/5000] | Time: 0.31s\n",
      "(Training) Loss: 1279111.6561\n",
      "(Validation) Loss: 1330303.4006, MAE: 4976.8413, R2: -0.1193\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [396/5000] | Time: 0.24s\n",
      "(Training) Loss: 1283339.8401\n",
      "(Validation) Loss: 1330042.1587, MAE: 4976.6079, R2: -0.1191\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [397/5000] | Time: 0.21s\n",
      "(Training) Loss: 1286663.6485\n",
      "(Validation) Loss: 1329777.6406, MAE: 4974.8843, R2: -0.1189\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [398/5000] | Time: 0.37s\n",
      "(Training) Loss: 1286980.4835\n",
      "(Validation) Loss: 1329514.8343, MAE: 4974.4575, R2: -0.1187\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [399/5000] | Time: 0.23s\n",
      "(Training) Loss: 1293526.6282\n",
      "(Validation) Loss: 1329249.0565, MAE: 4972.2148, R2: -0.1185\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [400/5000] | Time: 0.21s\n",
      "(Training) Loss: 1277754.1091\n",
      "(Validation) Loss: 1328983.0756, MAE: 4971.3975, R2: -0.1182\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [401/5000] | Time: 0.21s\n",
      "(Training) Loss: 1276978.2221\n",
      "(Validation) Loss: 1328719.2330, MAE: 4970.8999, R2: -0.1180\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [402/5000] | Time: 0.21s\n",
      "(Training) Loss: 1281267.8490\n",
      "(Validation) Loss: 1328459.8451, MAE: 4969.5605, R2: -0.1178\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [403/5000] | Time: 0.21s\n",
      "(Training) Loss: 1281209.3388\n",
      "(Validation) Loss: 1328193.7524, MAE: 4967.8115, R2: -0.1176\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [404/5000] | Time: 0.23s\n",
      "(Training) Loss: 1299444.5114\n",
      "(Validation) Loss: 1327932.5562, MAE: 4967.2944, R2: -0.1174\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [405/5000] | Time: 0.22s\n",
      "(Training) Loss: 1288956.4353\n",
      "(Validation) Loss: 1327667.2863, MAE: 4965.9771, R2: -0.1171\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [406/5000] | Time: 0.21s\n",
      "(Training) Loss: 1284584.8154\n",
      "(Validation) Loss: 1327404.6730, MAE: 4964.8833, R2: -0.1169\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [407/5000] | Time: 0.22s\n",
      "(Training) Loss: 1271537.4023\n",
      "(Validation) Loss: 1327140.9117, MAE: 4963.7266, R2: -0.1167\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [408/5000] | Time: 0.23s\n",
      "(Training) Loss: 1280695.7195\n",
      "(Validation) Loss: 1326878.8927, MAE: 4962.7974, R2: -0.1165\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [409/5000] | Time: 0.26s\n",
      "(Training) Loss: 1276229.9556\n",
      "(Validation) Loss: 1326615.8679, MAE: 4962.2046, R2: -0.1163\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [410/5000] | Time: 0.29s\n",
      "(Training) Loss: 1279420.0470\n",
      "(Validation) Loss: 1326356.1194, MAE: 4960.3813, R2: -0.1160\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [411/5000] | Time: 0.28s\n",
      "(Training) Loss: 1286973.7627\n",
      "(Validation) Loss: 1326091.7841, MAE: 4959.0161, R2: -0.1158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [412/5000] | Time: 0.27s\n",
      "(Training) Loss: 1288715.4315\n",
      "(Validation) Loss: 1325826.5600, MAE: 4958.0679, R2: -0.1156\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [413/5000] | Time: 0.29s\n",
      "(Training) Loss: 1281113.8553\n",
      "(Validation) Loss: 1325572.9778, MAE: 4957.8018, R2: -0.1154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [414/5000] | Time: 0.28s\n",
      "(Training) Loss: 1263321.2319\n",
      "(Validation) Loss: 1325304.7670, MAE: 4956.8398, R2: -0.1152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [415/5000] | Time: 0.30s\n",
      "(Training) Loss: 1272848.8192\n",
      "(Validation) Loss: 1325045.0489, MAE: 4955.4082, R2: -0.1149\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [416/5000] | Time: 0.28s\n",
      "(Training) Loss: 1266340.2183\n",
      "(Validation) Loss: 1324783.9949, MAE: 4954.0942, R2: -0.1147\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [417/5000] | Time: 0.26s\n",
      "(Training) Loss: 1288058.6681\n",
      "(Validation) Loss: 1324527.2889, MAE: 4954.0605, R2: -0.1145\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [418/5000] | Time: 0.27s\n",
      "(Training) Loss: 1267341.6041\n",
      "(Validation) Loss: 1324258.4584, MAE: 4952.9194, R2: -0.1143\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [419/5000] | Time: 0.28s\n",
      "(Training) Loss: 1263122.2272\n",
      "(Validation) Loss: 1323997.6838, MAE: 4951.4141, R2: -0.1141\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [420/5000] | Time: 0.29s\n",
      "(Training) Loss: 1274627.3579\n",
      "(Validation) Loss: 1323739.6470, MAE: 4949.5894, R2: -0.1139\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [421/5000] | Time: 0.30s\n",
      "(Training) Loss: 1266854.1472\n",
      "(Validation) Loss: 1323476.4038, MAE: 4948.5322, R2: -0.1136\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [422/5000] | Time: 0.28s\n",
      "(Training) Loss: 1272219.3426\n",
      "(Validation) Loss: 1323214.8114, MAE: 4947.3960, R2: -0.1134\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [423/5000] | Time: 0.28s\n",
      "(Training) Loss: 1288637.2779\n",
      "(Validation) Loss: 1322954.9714, MAE: 4947.1758, R2: -0.1132\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [424/5000] | Time: 0.28s\n",
      "(Training) Loss: 1273453.2221\n",
      "(Validation) Loss: 1322693.0641, MAE: 4945.6475, R2: -0.1130\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [425/5000] | Time: 0.28s\n",
      "(Training) Loss: 1271174.1066\n",
      "(Validation) Loss: 1322429.6584, MAE: 4944.5103, R2: -0.1128\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [426/5000] | Time: 0.28s\n",
      "(Training) Loss: 1293354.1307\n",
      "(Validation) Loss: 1322167.4921, MAE: 4943.0146, R2: -0.1126\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [427/5000] | Time: 0.28s\n",
      "(Training) Loss: 1269733.3236\n",
      "(Validation) Loss: 1321905.9302, MAE: 4942.1987, R2: -0.1123\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [428/5000] | Time: 0.36s\n",
      "(Training) Loss: 1269942.0463\n",
      "(Validation) Loss: 1321644.7238, MAE: 4941.9141, R2: -0.1121\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [429/5000] | Time: 0.32s\n",
      "(Training) Loss: 1262822.4841\n",
      "(Validation) Loss: 1321384.0965, MAE: 4940.9907, R2: -0.1119\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [430/5000] | Time: 0.31s\n",
      "(Training) Loss: 1267952.4683\n",
      "(Validation) Loss: 1321122.7124, MAE: 4939.6167, R2: -0.1117\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [431/5000] | Time: 0.30s\n",
      "(Training) Loss: 1283866.0102\n",
      "(Validation) Loss: 1320864.1778, MAE: 4938.3496, R2: -0.1115\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [432/5000] | Time: 0.37s\n",
      "(Training) Loss: 1268915.7310\n",
      "(Validation) Loss: 1320600.5587, MAE: 4937.7148, R2: -0.1112\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [433/5000] | Time: 0.46s\n",
      "(Training) Loss: 1263390.9213\n",
      "(Validation) Loss: 1320341.0387, MAE: 4935.6455, R2: -0.1110\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [434/5000] | Time: 0.25s\n",
      "(Training) Loss: 1255876.0046\n",
      "(Validation) Loss: 1320080.1625, MAE: 4935.4741, R2: -0.1108\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [435/5000] | Time: 0.39s\n",
      "(Training) Loss: 1271382.6650\n",
      "(Validation) Loss: 1319821.5467, MAE: 4933.8184, R2: -0.1106\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [436/5000] | Time: 0.25s\n",
      "(Training) Loss: 1273397.9137\n",
      "(Validation) Loss: 1319559.9543, MAE: 4932.6016, R2: -0.1104\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [437/5000] | Time: 0.28s\n",
      "(Training) Loss: 1266524.3185\n",
      "(Validation) Loss: 1319298.0114, MAE: 4931.6699, R2: -0.1102\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [438/5000] | Time: 0.28s\n",
      "(Training) Loss: 1264414.2766\n",
      "(Validation) Loss: 1319036.2210, MAE: 4930.7544, R2: -0.1099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [439/5000] | Time: 0.35s\n",
      "(Training) Loss: 1274523.8997\n",
      "(Validation) Loss: 1318778.6870, MAE: 4929.6899, R2: -0.1097\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [440/5000] | Time: 0.33s\n",
      "(Training) Loss: 1253849.1931\n",
      "(Validation) Loss: 1318520.9346, MAE: 4929.3643, R2: -0.1095\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [441/5000] | Time: 0.29s\n",
      "(Training) Loss: 1285142.3636\n",
      "(Validation) Loss: 1318259.8044, MAE: 4927.6074, R2: -0.1093\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [442/5000] | Time: 0.25s\n",
      "(Training) Loss: 1262939.3896\n",
      "(Validation) Loss: 1317995.7740, MAE: 4926.0752, R2: -0.1091\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [443/5000] | Time: 0.28s\n",
      "(Training) Loss: 1269978.3109\n",
      "(Validation) Loss: 1317738.1790, MAE: 4925.3481, R2: -0.1089\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [444/5000] | Time: 0.27s\n",
      "(Training) Loss: 1266584.6618\n",
      "(Validation) Loss: 1317477.4908, MAE: 4924.0532, R2: -0.1086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [445/5000] | Time: 0.25s\n",
      "(Training) Loss: 1278592.7766\n",
      "(Validation) Loss: 1317216.5841, MAE: 4923.3091, R2: -0.1084\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [446/5000] | Time: 0.30s\n",
      "(Training) Loss: 1287313.0926\n",
      "(Validation) Loss: 1316956.9371, MAE: 4922.7349, R2: -0.1082\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [447/5000] | Time: 0.27s\n",
      "(Training) Loss: 1258289.4911\n",
      "(Validation) Loss: 1316692.4648, MAE: 4922.1484, R2: -0.1080\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [448/5000] | Time: 0.30s\n",
      "(Training) Loss: 1267425.7919\n",
      "(Validation) Loss: 1316429.9276, MAE: 4920.5366, R2: -0.1078\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [449/5000] | Time: 0.42s\n",
      "(Training) Loss: 1267439.8947\n",
      "(Validation) Loss: 1316178.9765, MAE: 4920.6255, R2: -0.1076\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [450/5000] | Time: 0.30s\n",
      "(Training) Loss: 1267441.2830\n",
      "(Validation) Loss: 1315909.3892, MAE: 4918.3936, R2: -0.1073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [451/5000] | Time: 0.26s\n",
      "(Training) Loss: 1271783.9695\n",
      "(Validation) Loss: 1315651.5302, MAE: 4917.4072, R2: -0.1071\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [452/5000] | Time: 0.32s\n",
      "(Training) Loss: 1269738.8490\n",
      "(Validation) Loss: 1315418.6616, MAE: 4921.0405, R2: -0.1069\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [453/5000] | Time: 0.41s\n",
      "(Training) Loss: 1258163.3452\n",
      "(Validation) Loss: 1315130.8241, MAE: 4914.7910, R2: -0.1067\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [454/5000] | Time: 0.32s\n",
      "(Training) Loss: 1271494.5102\n",
      "(Validation) Loss: 1314872.9041, MAE: 4914.2461, R2: -0.1065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [455/5000] | Time: 0.42s\n",
      "(Training) Loss: 1263718.0888\n",
      "(Validation) Loss: 1314610.3060, MAE: 4912.8569, R2: -0.1063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [456/5000] | Time: 0.25s\n",
      "(Training) Loss: 1264095.7779\n",
      "(Validation) Loss: 1314353.2749, MAE: 4911.1074, R2: -0.1060\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [457/5000] | Time: 0.42s\n",
      "(Training) Loss: 1259185.1256\n",
      "(Validation) Loss: 1314093.0235, MAE: 4911.4028, R2: -0.1058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [458/5000] | Time: 0.38s\n",
      "(Training) Loss: 1274264.2957\n",
      "(Validation) Loss: 1313829.1860, MAE: 4908.8325, R2: -0.1056\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [459/5000] | Time: 0.36s\n",
      "(Training) Loss: 1266778.9302\n",
      "(Validation) Loss: 1313570.9511, MAE: 4907.9370, R2: -0.1054\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [460/5000] | Time: 0.31s\n",
      "(Training) Loss: 1251651.3950\n",
      "(Validation) Loss: 1313307.1441, MAE: 4906.8530, R2: -0.1052\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [461/5000] | Time: 0.37s\n",
      "(Training) Loss: 1263307.7081\n",
      "(Validation) Loss: 1313052.9778, MAE: 4905.5869, R2: -0.1050\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [462/5000] | Time: 0.30s\n",
      "(Training) Loss: 1266043.5114\n",
      "(Validation) Loss: 1312788.2057, MAE: 4905.0400, R2: -0.1047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [463/5000] | Time: 0.27s\n",
      "(Training) Loss: 1248295.9569\n",
      "(Validation) Loss: 1312529.5695, MAE: 4904.0151, R2: -0.1045\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [464/5000] | Time: 0.29s\n",
      "(Training) Loss: 1267021.2322\n",
      "(Validation) Loss: 1312268.5308, MAE: 4902.4922, R2: -0.1043\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [465/5000] | Time: 0.27s\n",
      "(Training) Loss: 1269049.4251\n",
      "(Validation) Loss: 1312012.2819, MAE: 4902.2017, R2: -0.1041\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [466/5000] | Time: 0.40s\n",
      "(Training) Loss: 1255930.6929\n",
      "(Validation) Loss: 1311746.9257, MAE: 4900.6782, R2: -0.1039\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [467/5000] | Time: 0.36s\n",
      "(Training) Loss: 1262362.1383\n",
      "(Validation) Loss: 1311488.0813, MAE: 4898.9683, R2: -0.1037\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [468/5000] | Time: 0.30s\n",
      "(Training) Loss: 1261532.1332\n",
      "(Validation) Loss: 1311231.6343, MAE: 4898.5864, R2: -0.1034\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [469/5000] | Time: 0.27s\n",
      "(Training) Loss: 1260777.6117\n",
      "(Validation) Loss: 1310973.7854, MAE: 4897.4380, R2: -0.1032\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [470/5000] | Time: 0.26s\n",
      "(Training) Loss: 1266837.8173\n",
      "(Validation) Loss: 1310712.0965, MAE: 4896.3442, R2: -0.1030\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [471/5000] | Time: 0.33s\n",
      "(Training) Loss: 1260829.4162\n",
      "(Validation) Loss: 1310453.0794, MAE: 4894.9775, R2: -0.1028\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [472/5000] | Time: 0.27s\n",
      "(Training) Loss: 1260297.9010\n",
      "(Validation) Loss: 1310195.8654, MAE: 4896.0493, R2: -0.1026\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [473/5000] | Time: 0.24s\n",
      "(Training) Loss: 1246309.8203\n",
      "(Validation) Loss: 1309935.0400, MAE: 4893.1938, R2: -0.1024\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [474/5000] | Time: 0.25s\n",
      "(Training) Loss: 1269771.6472\n",
      "(Validation) Loss: 1309675.9416, MAE: 4892.1670, R2: -0.1021\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [475/5000] | Time: 0.25s\n",
      "(Training) Loss: 1261865.3604\n",
      "(Validation) Loss: 1309417.2952, MAE: 4891.4111, R2: -0.1019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [476/5000] | Time: 0.27s\n",
      "(Training) Loss: 1252858.5457\n",
      "(Validation) Loss: 1309160.8279, MAE: 4891.1953, R2: -0.1017\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [477/5000] | Time: 0.39s\n",
      "(Training) Loss: 1265439.3528\n",
      "(Validation) Loss: 1308898.8698, MAE: 4888.9990, R2: -0.1015\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [478/5000] | Time: 0.25s\n",
      "(Training) Loss: 1263793.8452\n",
      "(Validation) Loss: 1308638.9994, MAE: 4889.9243, R2: -0.1013\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [479/5000] | Time: 0.28s\n",
      "(Training) Loss: 1252968.9359\n",
      "(Validation) Loss: 1308376.2540, MAE: 4887.1382, R2: -0.1011\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [480/5000] | Time: 0.25s\n",
      "(Training) Loss: 1282326.4505\n",
      "(Validation) Loss: 1308122.0622, MAE: 4885.7861, R2: -0.1008\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [481/5000] | Time: 0.28s\n",
      "(Training) Loss: 1251660.7855\n",
      "(Validation) Loss: 1307855.3600, MAE: 4884.9521, R2: -0.1006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [482/5000] | Time: 0.29s\n",
      "(Training) Loss: 1268470.6789\n",
      "(Validation) Loss: 1307595.8959, MAE: 4884.1558, R2: -0.1004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [483/5000] | Time: 0.34s\n",
      "(Training) Loss: 1263246.2018\n",
      "(Validation) Loss: 1307340.1397, MAE: 4884.2773, R2: -0.1002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [484/5000] | Time: 0.29s\n",
      "(Training) Loss: 1277187.0330\n",
      "(Validation) Loss: 1307079.4616, MAE: 4881.7969, R2: -0.1000\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [485/5000] | Time: 0.36s\n",
      "(Training) Loss: 1280153.8096\n",
      "(Validation) Loss: 1306820.7644, MAE: 4881.1025, R2: -0.0998\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [486/5000] | Time: 0.30s\n",
      "(Training) Loss: 1272288.7747\n",
      "(Validation) Loss: 1306556.8660, MAE: 4879.7266, R2: -0.0995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [487/5000] | Time: 0.30s\n",
      "(Training) Loss: 1246913.8598\n",
      "(Validation) Loss: 1306299.7537, MAE: 4878.8828, R2: -0.0993\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [488/5000] | Time: 0.27s\n",
      "(Training) Loss: 1249321.4353\n",
      "(Validation) Loss: 1306045.9124, MAE: 4879.4023, R2: -0.0991\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [489/5000] | Time: 0.27s\n",
      "(Training) Loss: 1276050.3629\n",
      "(Validation) Loss: 1305789.7956, MAE: 4877.9668, R2: -0.0989\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [490/5000] | Time: 0.26s\n",
      "(Training) Loss: 1252492.9048\n",
      "(Validation) Loss: 1305526.7149, MAE: 4876.3101, R2: -0.0987\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [491/5000] | Time: 0.26s\n",
      "(Training) Loss: 1271431.1586\n",
      "(Validation) Loss: 1305270.2324, MAE: 4875.3428, R2: -0.0985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [492/5000] | Time: 0.38s\n",
      "(Training) Loss: 1268915.5273\n",
      "(Validation) Loss: 1305008.2184, MAE: 4874.7876, R2: -0.0983\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [493/5000] | Time: 0.31s\n",
      "(Training) Loss: 1255436.9093\n",
      "(Validation) Loss: 1304747.9568, MAE: 4872.1836, R2: -0.0980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [494/5000] | Time: 0.27s\n",
      "(Training) Loss: 1252028.4010\n",
      "(Validation) Loss: 1304495.9137, MAE: 4872.1562, R2: -0.0978\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [495/5000] | Time: 0.27s\n",
      "(Training) Loss: 1250295.3991\n",
      "(Validation) Loss: 1304233.2089, MAE: 4870.4189, R2: -0.0976\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [496/5000] | Time: 0.25s\n",
      "(Training) Loss: 1271741.3249\n",
      "(Validation) Loss: 1303977.4629, MAE: 4869.5303, R2: -0.0974\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [497/5000] | Time: 0.26s\n",
      "(Training) Loss: 1263079.9454\n",
      "(Validation) Loss: 1303717.6279, MAE: 4869.0537, R2: -0.0972\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [498/5000] | Time: 0.26s\n",
      "(Training) Loss: 1240025.3728\n",
      "(Validation) Loss: 1303458.9714, MAE: 4867.1792, R2: -0.0970\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [499/5000] | Time: 0.35s\n",
      "(Training) Loss: 1245106.0933\n",
      "(Validation) Loss: 1303206.7606, MAE: 4866.5459, R2: -0.0968\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [500/5000] | Time: 0.26s\n",
      "(Training) Loss: 1251789.2132\n",
      "(Validation) Loss: 1302946.8444, MAE: 4865.6411, R2: -0.0965\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch500.pth\n",
      "==========================================================================================\n",
      "Epoch [501/5000] | Time: 0.27s\n",
      "(Training) Loss: 1280743.5584\n",
      "(Validation) Loss: 1302692.8610, MAE: 4864.8921, R2: -0.0963\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [502/5000] | Time: 0.28s\n",
      "(Training) Loss: 1252838.8249\n",
      "(Validation) Loss: 1302437.2673, MAE: 4864.6089, R2: -0.0961\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [503/5000] | Time: 0.28s\n",
      "(Training) Loss: 1258045.7259\n",
      "(Validation) Loss: 1302172.9321, MAE: 4862.2026, R2: -0.0959\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [504/5000] | Time: 0.32s\n",
      "(Training) Loss: 1250178.4670\n",
      "(Validation) Loss: 1301918.5575, MAE: 4861.2310, R2: -0.0957\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [505/5000] | Time: 0.31s\n",
      "(Training) Loss: 1248256.9898\n",
      "(Validation) Loss: 1301666.9968, MAE: 4860.3696, R2: -0.0955\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [506/5000] | Time: 0.29s\n",
      "(Training) Loss: 1256277.3452\n",
      "(Validation) Loss: 1301404.2413, MAE: 4859.8447, R2: -0.0953\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [507/5000] | Time: 0.30s\n",
      "(Training) Loss: 1246406.2589\n",
      "(Validation) Loss: 1301146.7022, MAE: 4858.0840, R2: -0.0950\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [508/5000] | Time: 0.29s\n",
      "(Training) Loss: 1261215.7043\n",
      "(Validation) Loss: 1300890.3365, MAE: 4856.9985, R2: -0.0948\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [509/5000] | Time: 0.34s\n",
      "(Training) Loss: 1258744.0260\n",
      "(Validation) Loss: 1300632.9600, MAE: 4856.6914, R2: -0.0946\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [510/5000] | Time: 0.40s\n",
      "(Training) Loss: 1258092.7069\n",
      "(Validation) Loss: 1300374.1562, MAE: 4855.5239, R2: -0.0944\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [511/5000] | Time: 0.32s\n",
      "(Training) Loss: 1246772.9264\n",
      "(Validation) Loss: 1300117.3689, MAE: 4854.7607, R2: -0.0942\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [512/5000] | Time: 0.32s\n",
      "(Training) Loss: 1270114.7500\n",
      "(Validation) Loss: 1299860.8965, MAE: 4852.8442, R2: -0.0940\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [513/5000] | Time: 0.29s\n",
      "(Training) Loss: 1251528.4762\n",
      "(Validation) Loss: 1299607.0146, MAE: 4852.6240, R2: -0.0938\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [514/5000] | Time: 0.28s\n",
      "(Training) Loss: 1237335.6732\n",
      "(Validation) Loss: 1299347.4133, MAE: 4852.0874, R2: -0.0935\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [515/5000] | Time: 0.29s\n",
      "(Training) Loss: 1258255.5266\n",
      "(Validation) Loss: 1299096.3098, MAE: 4852.3354, R2: -0.0933\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [516/5000] | Time: 0.26s\n",
      "(Training) Loss: 1260801.2614\n",
      "(Validation) Loss: 1298837.4654, MAE: 4849.2300, R2: -0.0931\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [517/5000] | Time: 0.34s\n",
      "(Training) Loss: 1253142.8147\n",
      "(Validation) Loss: 1298576.4673, MAE: 4848.7998, R2: -0.0929\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [518/5000] | Time: 0.29s\n",
      "(Training) Loss: 1251212.4575\n",
      "(Validation) Loss: 1298321.9149, MAE: 4848.2378, R2: -0.0927\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [519/5000] | Time: 0.27s\n",
      "(Training) Loss: 1254192.2855\n",
      "(Validation) Loss: 1298066.1130, MAE: 4846.1748, R2: -0.0925\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [520/5000] | Time: 0.29s\n",
      "(Training) Loss: 1261286.1948\n",
      "(Validation) Loss: 1297813.0692, MAE: 4846.9326, R2: -0.0923\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [521/5000] | Time: 0.27s\n",
      "(Training) Loss: 1244406.5228\n",
      "(Validation) Loss: 1297550.0292, MAE: 4845.2705, R2: -0.0920\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [522/5000] | Time: 0.27s\n",
      "(Training) Loss: 1245310.2690\n",
      "(Validation) Loss: 1297297.1784, MAE: 4845.4976, R2: -0.0918\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [523/5000] | Time: 0.28s\n",
      "(Training) Loss: 1248563.7951\n",
      "(Validation) Loss: 1297035.6927, MAE: 4842.0239, R2: -0.0916\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [524/5000] | Time: 0.28s\n",
      "(Training) Loss: 1247832.0749\n",
      "(Validation) Loss: 1296779.3727, MAE: 4840.9829, R2: -0.0914\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [525/5000] | Time: 0.42s\n",
      "(Training) Loss: 1260532.1320\n",
      "(Validation) Loss: 1296524.6070, MAE: 4841.6675, R2: -0.0912\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [526/5000] | Time: 0.25s\n",
      "(Training) Loss: 1248412.8046\n",
      "(Validation) Loss: 1296266.2248, MAE: 4840.2280, R2: -0.0910\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [527/5000] | Time: 0.25s\n",
      "(Training) Loss: 1244193.3503\n",
      "(Validation) Loss: 1296011.7943, MAE: 4838.6230, R2: -0.0908\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [528/5000] | Time: 0.25s\n",
      "(Training) Loss: 1238684.5863\n",
      "(Validation) Loss: 1295760.5638, MAE: 4838.9932, R2: -0.0906\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [529/5000] | Time: 0.25s\n",
      "(Training) Loss: 1239564.6485\n",
      "(Validation) Loss: 1295502.2019, MAE: 4836.3506, R2: -0.0903\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [530/5000] | Time: 0.24s\n",
      "(Training) Loss: 1260282.7944\n",
      "(Validation) Loss: 1295243.6978, MAE: 4834.9053, R2: -0.0901\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [531/5000] | Time: 0.25s\n",
      "(Training) Loss: 1245828.9074\n",
      "(Validation) Loss: 1294990.7251, MAE: 4834.3384, R2: -0.0899\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [532/5000] | Time: 0.25s\n",
      "(Training) Loss: 1267622.0799\n",
      "(Validation) Loss: 1294733.9022, MAE: 4832.9624, R2: -0.0897\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [533/5000] | Time: 0.25s\n",
      "(Training) Loss: 1246775.2805\n",
      "(Validation) Loss: 1294472.3810, MAE: 4832.5186, R2: -0.0895\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [534/5000] | Time: 0.29s\n",
      "(Training) Loss: 1257543.3940\n",
      "(Validation) Loss: 1294216.2641, MAE: 4830.9800, R2: -0.0893\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [535/5000] | Time: 0.26s\n",
      "(Training) Loss: 1264072.8782\n",
      "(Validation) Loss: 1293966.1968, MAE: 4833.2109, R2: -0.0891\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [536/5000] | Time: 0.28s\n",
      "(Training) Loss: 1266104.7766\n",
      "(Validation) Loss: 1293703.9340, MAE: 4831.7383, R2: -0.0888\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [537/5000] | Time: 0.38s\n",
      "(Training) Loss: 1239010.8522\n",
      "(Validation) Loss: 1293447.0349, MAE: 4830.6401, R2: -0.0886\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [538/5000] | Time: 0.28s\n",
      "(Training) Loss: 1239785.0939\n",
      "(Validation) Loss: 1293191.8629, MAE: 4828.3447, R2: -0.0884\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [539/5000] | Time: 0.25s\n",
      "(Training) Loss: 1249270.3376\n",
      "(Validation) Loss: 1292936.9600, MAE: 4827.2988, R2: -0.0882\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [540/5000] | Time: 0.26s\n",
      "(Training) Loss: 1246021.0146\n",
      "(Validation) Loss: 1292684.0838, MAE: 4826.4233, R2: -0.0880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [541/5000] | Time: 0.27s\n",
      "(Training) Loss: 1247300.7005\n",
      "(Validation) Loss: 1292425.8286, MAE: 4825.0381, R2: -0.0878\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [542/5000] | Time: 0.25s\n",
      "(Training) Loss: 1250786.9841\n",
      "(Validation) Loss: 1292172.1854, MAE: 4824.3950, R2: -0.0876\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [543/5000] | Time: 0.27s\n",
      "(Training) Loss: 1231354.2640\n",
      "(Validation) Loss: 1291914.7683, MAE: 4824.8291, R2: -0.0873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [544/5000] | Time: 0.28s\n",
      "(Training) Loss: 1242551.9848\n",
      "(Validation) Loss: 1291665.2292, MAE: 4823.5542, R2: -0.0871\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [545/5000] | Time: 0.28s\n",
      "(Training) Loss: 1255852.3109\n",
      "(Validation) Loss: 1291413.0641, MAE: 4823.0947, R2: -0.0869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [546/5000] | Time: 0.29s\n",
      "(Training) Loss: 1240319.9124\n",
      "(Validation) Loss: 1291152.9803, MAE: 4820.4062, R2: -0.0867\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [547/5000] | Time: 0.30s\n",
      "(Training) Loss: 1239883.1377\n",
      "(Validation) Loss: 1290902.0140, MAE: 4821.3662, R2: -0.0865\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [548/5000] | Time: 0.40s\n",
      "(Training) Loss: 1259638.7919\n",
      "(Validation) Loss: 1290643.5505, MAE: 4817.4746, R2: -0.0863\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [549/5000] | Time: 0.30s\n",
      "(Training) Loss: 1234643.0952\n",
      "(Validation) Loss: 1290389.6990, MAE: 4817.7407, R2: -0.0861\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [550/5000] | Time: 0.25s\n",
      "(Training) Loss: 1264105.9645\n",
      "(Validation) Loss: 1290141.7803, MAE: 4818.0200, R2: -0.0859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [551/5000] | Time: 0.26s\n",
      "(Training) Loss: 1270011.8921\n",
      "(Validation) Loss: 1289881.1022, MAE: 4814.6128, R2: -0.0857\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [552/5000] | Time: 0.26s\n",
      "(Training) Loss: 1259714.9461\n",
      "(Validation) Loss: 1289618.4330, MAE: 4813.4702, R2: -0.0854\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [553/5000] | Time: 0.27s\n",
      "(Training) Loss: 1267497.7919\n",
      "(Validation) Loss: 1289362.9663, MAE: 4812.8545, R2: -0.0852\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [554/5000] | Time: 0.29s\n",
      "(Training) Loss: 1254420.2208\n",
      "(Validation) Loss: 1289106.1994, MAE: 4812.6899, R2: -0.0850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [555/5000] | Time: 0.30s\n",
      "(Training) Loss: 1244549.4061\n",
      "(Validation) Loss: 1288851.1949, MAE: 4811.8276, R2: -0.0848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [556/5000] | Time: 0.33s\n",
      "(Training) Loss: 1238809.8820\n",
      "(Validation) Loss: 1288599.2584, MAE: 4812.2964, R2: -0.0846\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [557/5000] | Time: 0.31s\n",
      "(Training) Loss: 1252266.3712\n",
      "(Validation) Loss: 1288336.6451, MAE: 4809.1689, R2: -0.0844\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [558/5000] | Time: 0.39s\n",
      "(Training) Loss: 1263671.0673\n",
      "(Validation) Loss: 1288087.1314, MAE: 4808.5400, R2: -0.0842\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [559/5000] | Time: 0.28s\n",
      "(Training) Loss: 1237690.2056\n",
      "(Validation) Loss: 1287833.6254, MAE: 4807.1211, R2: -0.0839\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [560/5000] | Time: 0.28s\n",
      "(Training) Loss: 1233868.8185\n",
      "(Validation) Loss: 1287578.6108, MAE: 4806.4663, R2: -0.0837\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [561/5000] | Time: 0.28s\n",
      "(Training) Loss: 1228348.4023\n",
      "(Validation) Loss: 1287331.1086, MAE: 4807.9785, R2: -0.0835\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [562/5000] | Time: 0.26s\n",
      "(Training) Loss: 1252363.9175\n",
      "(Validation) Loss: 1287072.4368, MAE: 4804.0103, R2: -0.0833\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [563/5000] | Time: 0.26s\n",
      "(Training) Loss: 1235092.0673\n",
      "(Validation) Loss: 1286817.4527, MAE: 4803.1401, R2: -0.0831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [564/5000] | Time: 0.28s\n",
      "(Training) Loss: 1252708.1364\n",
      "(Validation) Loss: 1286566.6337, MAE: 4803.1929, R2: -0.0829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [565/5000] | Time: 0.29s\n",
      "(Training) Loss: 1232773.9822\n",
      "(Validation) Loss: 1286311.3702, MAE: 4802.4497, R2: -0.0827\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [566/5000] | Time: 0.26s\n",
      "(Training) Loss: 1231359.3490\n",
      "(Validation) Loss: 1286059.4337, MAE: 4801.7681, R2: -0.0825\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [567/5000] | Time: 0.27s\n",
      "(Training) Loss: 1234674.2855\n",
      "(Validation) Loss: 1285802.7175, MAE: 4798.3838, R2: -0.0823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [568/5000] | Time: 0.26s\n",
      "(Training) Loss: 1240975.0349\n",
      "(Validation) Loss: 1285552.1625, MAE: 4798.9531, R2: -0.0820\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [569/5000] | Time: 0.33s\n",
      "(Training) Loss: 1233994.6536\n",
      "(Validation) Loss: 1285299.8451, MAE: 4798.2812, R2: -0.0818\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [570/5000] | Time: 0.38s\n",
      "(Training) Loss: 1251511.4391\n",
      "(Validation) Loss: 1285048.0457, MAE: 4798.0015, R2: -0.0816\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [571/5000] | Time: 0.30s\n",
      "(Training) Loss: 1226856.5533\n",
      "(Validation) Loss: 1284788.2921, MAE: 4795.0518, R2: -0.0814\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [572/5000] | Time: 0.34s\n",
      "(Training) Loss: 1232690.4632\n",
      "(Validation) Loss: 1284537.1276, MAE: 4794.4595, R2: -0.0812\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [573/5000] | Time: 0.37s\n",
      "(Training) Loss: 1222350.9235\n",
      "(Validation) Loss: 1284283.4997, MAE: 4794.1650, R2: -0.0810\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [574/5000] | Time: 0.31s\n",
      "(Training) Loss: 1245643.9188\n",
      "(Validation) Loss: 1284039.1467, MAE: 4794.0166, R2: -0.0808\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [575/5000] | Time: 0.28s\n",
      "(Training) Loss: 1246023.8921\n",
      "(Validation) Loss: 1283787.4489, MAE: 4793.7944, R2: -0.0806\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [576/5000] | Time: 0.32s\n",
      "(Training) Loss: 1244161.5926\n",
      "(Validation) Loss: 1283524.0432, MAE: 4791.2173, R2: -0.0804\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [577/5000] | Time: 0.41s\n",
      "(Training) Loss: 1248078.3249\n",
      "(Validation) Loss: 1283268.7289, MAE: 4789.5542, R2: -0.0801\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [578/5000] | Time: 0.28s\n",
      "(Training) Loss: 1228647.5964\n",
      "(Validation) Loss: 1283015.5276, MAE: 4788.8081, R2: -0.0799\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [579/5000] | Time: 0.28s\n",
      "(Training) Loss: 1241291.7665\n",
      "(Validation) Loss: 1284930.5295, MAE: 4798.7715, R2: -0.0815\n",
      "==========================================================================================\n",
      "Epoch [580/5000] | Time: 0.27s\n",
      "(Training) Loss: 1228002.8522\n",
      "(Validation) Loss: 1282512.0508, MAE: 4787.5889, R2: -0.0795\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [581/5000] | Time: 0.25s\n",
      "(Training) Loss: 1251040.8731\n",
      "(Validation) Loss: 1282265.9302, MAE: 4789.0366, R2: -0.0793\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [582/5000] | Time: 0.25s\n",
      "(Training) Loss: 1232385.2741\n",
      "(Validation) Loss: 1282007.5581, MAE: 4787.0498, R2: -0.0791\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [583/5000] | Time: 0.25s\n",
      "(Training) Loss: 1239510.9162\n",
      "(Validation) Loss: 1281750.6286, MAE: 4784.6528, R2: -0.0789\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [584/5000] | Time: 0.26s\n",
      "(Training) Loss: 1229661.0197\n",
      "(Validation) Loss: 1281503.2381, MAE: 4785.4507, R2: -0.0787\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [585/5000] | Time: 0.24s\n",
      "(Training) Loss: 1270883.4061\n",
      "(Validation) Loss: 1281246.8013, MAE: 4782.3999, R2: -0.0785\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [586/5000] | Time: 0.27s\n",
      "(Training) Loss: 1226397.2386\n",
      "(Validation) Loss: 1285555.8959, MAE: 4799.9639, R2: -0.0820\n",
      "==========================================================================================\n",
      "Epoch [587/5000] | Time: 0.41s\n",
      "(Training) Loss: 1226194.5736\n",
      "(Validation) Loss: 1285301.6787, MAE: 4797.1519, R2: -0.0818\n",
      "==========================================================================================\n",
      "Epoch [588/5000] | Time: 0.36s\n",
      "(Training) Loss: 1243136.5825\n",
      "(Validation) Loss: 1285052.9676, MAE: 4796.6021, R2: -0.0816\n",
      "==========================================================================================\n",
      "Epoch [589/5000] | Time: 0.25s\n",
      "(Training) Loss: 1246850.6396\n",
      "(Validation) Loss: 1284792.7365, MAE: 4794.7964, R2: -0.0814\n",
      "==========================================================================================\n",
      "Epoch [590/5000] | Time: 0.33s\n",
      "(Training) Loss: 1243083.6701\n",
      "(Validation) Loss: 1284540.5359, MAE: 4794.3472, R2: -0.0812\n",
      "==========================================================================================\n",
      "Epoch [591/5000] | Time: 0.35s\n",
      "(Training) Loss: 1235496.7462\n",
      "(Validation) Loss: 1284287.0095, MAE: 4793.6504, R2: -0.0810\n",
      "==========================================================================================\n",
      "Epoch [592/5000] | Time: 0.33s\n",
      "(Training) Loss: 1229620.1656\n",
      "(Validation) Loss: 1284040.7721, MAE: 4792.9888, R2: -0.0808\n",
      "==========================================================================================\n",
      "Epoch [593/5000] | Time: 0.30s\n",
      "(Training) Loss: 1238676.9949\n",
      "(Validation) Loss: 1283781.9378, MAE: 4792.0479, R2: -0.0806\n",
      "==========================================================================================\n",
      "Epoch [594/5000] | Time: 0.28s\n",
      "(Training) Loss: 1223440.2824\n",
      "(Validation) Loss: 1283527.1924, MAE: 4790.9033, R2: -0.0804\n",
      "==========================================================================================\n",
      "Epoch [595/5000] | Time: 0.33s\n",
      "(Training) Loss: 1248075.8832\n",
      "(Validation) Loss: 1283274.2806, MAE: 4790.1558, R2: -0.0801\n",
      "==========================================================================================\n",
      "Epoch [596/5000] | Time: 0.37s\n",
      "(Training) Loss: 1267590.7494\n",
      "(Validation) Loss: 1283019.8908, MAE: 4788.9761, R2: -0.0799\n",
      "==========================================================================================\n",
      "Epoch [597/5000] | Time: 0.37s\n",
      "(Training) Loss: 1242410.7614\n",
      "(Validation) Loss: 1282770.7225, MAE: 4792.5908, R2: -0.0797\n",
      "==========================================================================================\n",
      "Epoch [598/5000] | Time: 0.27s\n",
      "(Training) Loss: 1227134.4860\n",
      "(Validation) Loss: 1282510.7403, MAE: 4788.1045, R2: -0.0795\n",
      "==========================================================================================\n",
      "Epoch [599/5000] | Time: 0.25s\n",
      "(Training) Loss: 1227893.8966\n",
      "(Validation) Loss: 1282262.0495, MAE: 4789.5732, R2: -0.0793\n",
      "==========================================================================================\n",
      "Epoch [600/5000] | Time: 0.26s\n",
      "(Training) Loss: 1241995.7246\n",
      "(Validation) Loss: 1282005.1048, MAE: 4785.5137, R2: -0.0791\n",
      "==========================================================================================\n",
      "Epoch [601/5000] | Time: 0.25s\n",
      "(Training) Loss: 1239092.4150\n",
      "(Validation) Loss: 1281754.1587, MAE: 4784.5605, R2: -0.0789\n",
      "==========================================================================================\n",
      "Epoch [602/5000] | Time: 0.31s\n",
      "(Training) Loss: 1255445.5241\n",
      "(Validation) Loss: 1281500.5257, MAE: 4783.4395, R2: -0.0787\n",
      "==========================================================================================\n",
      "Epoch [603/5000] | Time: 0.28s\n",
      "(Training) Loss: 1249055.0355\n",
      "(Validation) Loss: 1281242.9410, MAE: 4782.8813, R2: -0.0785\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [604/5000] | Time: 0.35s\n",
      "(Training) Loss: 1229448.8484\n",
      "(Validation) Loss: 1280998.2171, MAE: 4782.8306, R2: -0.0783\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [605/5000] | Time: 0.37s\n",
      "(Training) Loss: 1255010.1764\n",
      "(Validation) Loss: 1280736.5638, MAE: 4782.3667, R2: -0.0780\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [606/5000] | Time: 0.44s\n",
      "(Training) Loss: 1240006.7195\n",
      "(Validation) Loss: 1280477.5111, MAE: 4778.9561, R2: -0.0778\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [607/5000] | Time: 0.36s\n",
      "(Training) Loss: 1229666.1066\n",
      "(Validation) Loss: 1280224.4063, MAE: 4780.0669, R2: -0.0776\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [608/5000] | Time: 0.29s\n",
      "(Training) Loss: 1245447.2195\n",
      "(Validation) Loss: 1279971.9365, MAE: 4777.0630, R2: -0.0774\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [609/5000] | Time: 0.29s\n",
      "(Training) Loss: 1240503.3388\n",
      "(Validation) Loss: 1279719.3092, MAE: 4776.9341, R2: -0.0772\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [610/5000] | Time: 0.29s\n",
      "(Training) Loss: 1247834.6041\n",
      "(Validation) Loss: 1279465.2902, MAE: 4777.0986, R2: -0.0770\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [611/5000] | Time: 0.26s\n",
      "(Training) Loss: 1234356.3642\n",
      "(Validation) Loss: 1279218.2959, MAE: 4776.8188, R2: -0.0768\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [612/5000] | Time: 0.27s\n",
      "(Training) Loss: 1230884.8991\n",
      "(Validation) Loss: 1278958.1410, MAE: 4774.8652, R2: -0.0766\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [613/5000] | Time: 0.23s\n",
      "(Training) Loss: 1234799.7322\n",
      "(Validation) Loss: 1278704.6197, MAE: 4774.6245, R2: -0.0763\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [614/5000] | Time: 0.24s\n",
      "(Training) Loss: 1231230.9315\n",
      "(Validation) Loss: 1278458.0521, MAE: 4774.6143, R2: -0.0761\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [615/5000] | Time: 0.27s\n",
      "(Training) Loss: 1228667.2500\n",
      "(Validation) Loss: 1278201.2698, MAE: 4771.5801, R2: -0.0759\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [616/5000] | Time: 0.25s\n",
      "(Training) Loss: 1233281.4740\n",
      "(Validation) Loss: 1277951.2076, MAE: 4770.4160, R2: -0.0757\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [617/5000] | Time: 0.32s\n",
      "(Training) Loss: 1226875.2500\n",
      "(Validation) Loss: 1277696.3556, MAE: 4769.4912, R2: -0.0755\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [618/5000] | Time: 0.24s\n",
      "(Training) Loss: 1225962.9810\n",
      "(Validation) Loss: 1277447.2229, MAE: 4768.3813, R2: -0.0753\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [619/5000] | Time: 0.24s\n",
      "(Training) Loss: 1248294.9734\n",
      "(Validation) Loss: 1277198.2629, MAE: 4767.5947, R2: -0.0751\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [620/5000] | Time: 0.27s\n",
      "(Training) Loss: 1231147.4048\n",
      "(Validation) Loss: 1276942.5067, MAE: 4766.6904, R2: -0.0749\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [621/5000] | Time: 0.25s\n",
      "(Training) Loss: 1224624.3769\n",
      "(Validation) Loss: 1276688.1270, MAE: 4765.1274, R2: -0.0747\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [622/5000] | Time: 0.26s\n",
      "(Training) Loss: 1236809.4962\n",
      "(Validation) Loss: 1276439.8933, MAE: 4764.9819, R2: -0.0745\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [623/5000] | Time: 0.26s\n",
      "(Training) Loss: 1214480.5531\n",
      "(Validation) Loss: 1276198.7606, MAE: 4765.5903, R2: -0.0743\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [624/5000] | Time: 0.32s\n",
      "(Training) Loss: 1217976.4124\n",
      "(Validation) Loss: 1275934.6794, MAE: 4762.9189, R2: -0.0740\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [625/5000] | Time: 0.37s\n",
      "(Training) Loss: 1240202.3274\n",
      "(Validation) Loss: 1275683.7283, MAE: 4761.2749, R2: -0.0738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [626/5000] | Time: 0.28s\n",
      "(Training) Loss: 1241576.0222\n",
      "(Validation) Loss: 1275434.1435, MAE: 4760.9995, R2: -0.0736\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [627/5000] | Time: 0.27s\n",
      "(Training) Loss: 1214696.4156\n",
      "(Validation) Loss: 1275178.6260, MAE: 4759.0386, R2: -0.0734\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [628/5000] | Time: 0.54s\n",
      "(Training) Loss: 1217277.0939\n",
      "(Validation) Loss: 1274929.1733, MAE: 4758.1611, R2: -0.0732\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [629/5000] | Time: 0.55s\n",
      "(Training) Loss: 1255542.8185\n",
      "(Validation) Loss: 1274684.8610, MAE: 4758.9351, R2: -0.0730\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [630/5000] | Time: 0.50s\n",
      "(Training) Loss: 1224573.6193\n",
      "(Validation) Loss: 1274428.8000, MAE: 4756.7798, R2: -0.0728\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [631/5000] | Time: 0.36s\n",
      "(Training) Loss: 1236642.7995\n",
      "(Validation) Loss: 1274179.4235, MAE: 4757.0840, R2: -0.0726\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [632/5000] | Time: 0.27s\n",
      "(Training) Loss: 1219159.2113\n",
      "(Validation) Loss: 1273924.3886, MAE: 4754.6157, R2: -0.0724\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [633/5000] | Time: 0.29s\n",
      "(Training) Loss: 1219307.7456\n",
      "(Validation) Loss: 1273680.6603, MAE: 4756.6401, R2: -0.0722\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [634/5000] | Time: 0.24s\n",
      "(Training) Loss: 1244672.1561\n",
      "(Validation) Loss: 1273425.1276, MAE: 4753.9985, R2: -0.0719\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [635/5000] | Time: 0.22s\n",
      "(Training) Loss: 1234169.7246\n",
      "(Validation) Loss: 1273174.8063, MAE: 4752.7920, R2: -0.0717\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [636/5000] | Time: 0.28s\n",
      "(Training) Loss: 1240391.4683\n",
      "(Validation) Loss: 1272926.6946, MAE: 4753.5063, R2: -0.0715\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [637/5000] | Time: 0.25s\n",
      "(Training) Loss: 1234922.9467\n",
      "(Validation) Loss: 1272671.2635, MAE: 4751.0850, R2: -0.0713\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [638/5000] | Time: 0.23s\n",
      "(Training) Loss: 1216171.4588\n",
      "(Validation) Loss: 1272415.0705, MAE: 4749.6826, R2: -0.0711\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [639/5000] | Time: 0.26s\n",
      "(Training) Loss: 1225034.2043\n",
      "(Validation) Loss: 1272171.3930, MAE: 4750.4692, R2: -0.0709\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [640/5000] | Time: 0.26s\n",
      "(Training) Loss: 1218821.4657\n",
      "(Validation) Loss: 1271920.4825, MAE: 4747.1929, R2: -0.0707\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [641/5000] | Time: 0.25s\n",
      "(Training) Loss: 1214300.2722\n",
      "(Validation) Loss: 1271671.7156, MAE: 4748.7495, R2: -0.0705\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [642/5000] | Time: 0.25s\n",
      "(Training) Loss: 1237194.1536\n",
      "(Validation) Loss: 1271425.2190, MAE: 4748.4565, R2: -0.0703\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [643/5000] | Time: 0.26s\n",
      "(Training) Loss: 1215107.4251\n",
      "(Validation) Loss: 1271169.9352, MAE: 4746.7798, R2: -0.0701\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [644/5000] | Time: 0.31s\n",
      "(Training) Loss: 1224561.3871\n",
      "(Validation) Loss: 1270919.9848, MAE: 4744.7305, R2: -0.0699\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [645/5000] | Time: 0.28s\n",
      "(Training) Loss: 1228227.9619\n",
      "(Validation) Loss: 1270679.0806, MAE: 4747.7754, R2: -0.0697\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [646/5000] | Time: 0.25s\n",
      "(Training) Loss: 1213819.2145\n",
      "(Validation) Loss: 1270420.8813, MAE: 4744.6216, R2: -0.0694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [647/5000] | Time: 0.27s\n",
      "(Training) Loss: 1227013.6085\n",
      "(Validation) Loss: 1270343.1619, MAE: 4745.0947, R2: -0.0694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [648/5000] | Time: 0.25s\n",
      "(Training) Loss: 1228383.4613\n",
      "(Validation) Loss: 1274937.7524, MAE: 4759.5127, R2: -0.0732\n",
      "==========================================================================================\n",
      "Epoch [649/5000] | Time: 0.26s\n",
      "(Training) Loss: 1219116.9308\n",
      "(Validation) Loss: 1274687.4667, MAE: 4758.6401, R2: -0.0730\n",
      "==========================================================================================\n",
      "Epoch [650/5000] | Time: 0.26s\n",
      "(Training) Loss: 1256635.2113\n",
      "(Validation) Loss: 1274436.2514, MAE: 4757.1104, R2: -0.0728\n",
      "==========================================================================================\n",
      "Epoch [651/5000] | Time: 0.28s\n",
      "(Training) Loss: 1229177.4670\n",
      "(Validation) Loss: 1274179.8400, MAE: 4756.4526, R2: -0.0726\n",
      "==========================================================================================\n",
      "Epoch [652/5000] | Time: 0.34s\n",
      "(Training) Loss: 1218947.7703\n",
      "(Validation) Loss: 1273930.0876, MAE: 4756.3047, R2: -0.0724\n",
      "==========================================================================================\n",
      "Epoch [653/5000] | Time: 0.36s\n",
      "(Training) Loss: 1212933.6098\n",
      "(Validation) Loss: 1273681.5238, MAE: 4755.7612, R2: -0.0722\n",
      "==========================================================================================\n",
      "Epoch [654/5000] | Time: 0.28s\n",
      "(Training) Loss: 1220196.0292\n",
      "(Validation) Loss: 1273431.2584, MAE: 4753.9360, R2: -0.0719\n",
      "==========================================================================================\n",
      "Epoch [655/5000] | Time: 0.30s\n",
      "(Training) Loss: 1235766.1129\n",
      "(Validation) Loss: 1273178.2603, MAE: 4754.1914, R2: -0.0717\n",
      "==========================================================================================\n",
      "Epoch [656/5000] | Time: 0.26s\n",
      "(Training) Loss: 1224847.3058\n",
      "(Validation) Loss: 1272923.3981, MAE: 4752.3853, R2: -0.0715\n",
      "==========================================================================================\n",
      "Epoch [657/5000] | Time: 0.28s\n",
      "(Training) Loss: 1226057.9232\n",
      "(Validation) Loss: 1272674.8190, MAE: 4750.3350, R2: -0.0713\n",
      "==========================================================================================\n",
      "Epoch [658/5000] | Time: 0.23s\n",
      "(Training) Loss: 1233621.8008\n",
      "(Validation) Loss: 1272429.1860, MAE: 4754.4243, R2: -0.0711\n",
      "==========================================================================================\n",
      "Epoch [659/5000] | Time: 0.29s\n",
      "(Training) Loss: 1225936.7183\n",
      "(Validation) Loss: 1272168.0762, MAE: 4749.2314, R2: -0.0709\n",
      "==========================================================================================\n",
      "Epoch [660/5000] | Time: 0.25s\n",
      "(Training) Loss: 1227800.5025\n",
      "(Validation) Loss: 1271923.6368, MAE: 4750.9214, R2: -0.0707\n",
      "==========================================================================================\n",
      "Epoch [661/5000] | Time: 0.24s\n",
      "(Training) Loss: 1229489.9569\n",
      "(Validation) Loss: 1271668.1346, MAE: 4747.5352, R2: -0.0705\n",
      "==========================================================================================\n",
      "Epoch [662/5000] | Time: 0.26s\n",
      "(Training) Loss: 1230554.9074\n",
      "(Validation) Loss: 1271417.3714, MAE: 4747.0542, R2: -0.0703\n",
      "==========================================================================================\n",
      "Epoch [663/5000] | Time: 0.28s\n",
      "(Training) Loss: 1209978.5510\n",
      "(Validation) Loss: 1271161.9759, MAE: 4744.5859, R2: -0.0701\n",
      "==========================================================================================\n",
      "Epoch [664/5000] | Time: 0.27s\n",
      "(Training) Loss: 1235621.1453\n",
      "(Validation) Loss: 1270916.4902, MAE: 4743.2817, R2: -0.0699\n",
      "==========================================================================================\n",
      "Epoch [665/5000] | Time: 0.25s\n",
      "(Training) Loss: 1226445.4810\n",
      "(Validation) Loss: 1270663.2229, MAE: 4743.7427, R2: -0.0696\n",
      "==========================================================================================\n",
      "Epoch [666/5000] | Time: 0.22s\n",
      "(Training) Loss: 1227940.2354\n",
      "(Validation) Loss: 1270415.7562, MAE: 4743.5693, R2: -0.0694\n",
      "==========================================================================================\n",
      "Epoch [667/5000] | Time: 0.24s\n",
      "(Training) Loss: 1216971.7830\n",
      "(Validation) Loss: 1270159.2330, MAE: 4741.0396, R2: -0.0692\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [668/5000] | Time: 0.26s\n",
      "(Training) Loss: 1241464.2195\n",
      "(Validation) Loss: 1269909.9683, MAE: 4740.6245, R2: -0.0690\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [669/5000] | Time: 0.26s\n",
      "(Training) Loss: 1224872.9201\n",
      "(Validation) Loss: 1269673.1835, MAE: 4741.1860, R2: -0.0688\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [670/5000] | Time: 0.26s\n",
      "(Training) Loss: 1225147.8655\n",
      "(Validation) Loss: 1269408.0762, MAE: 4741.1357, R2: -0.0686\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [671/5000] | Time: 0.37s\n",
      "(Training) Loss: 1257867.6713\n",
      "(Validation) Loss: 1269163.7029, MAE: 4741.0278, R2: -0.0684\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [672/5000] | Time: 0.25s\n",
      "(Training) Loss: 1222791.9201\n",
      "(Validation) Loss: 1268904.0203, MAE: 4737.5820, R2: -0.0682\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [673/5000] | Time: 0.23s\n",
      "(Training) Loss: 1233422.2322\n",
      "(Validation) Loss: 1268651.0832, MAE: 4736.4644, R2: -0.0680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [674/5000] | Time: 0.23s\n",
      "(Training) Loss: 1217704.3331\n",
      "(Validation) Loss: 1268399.0248, MAE: 4735.7808, R2: -0.0678\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [675/5000] | Time: 0.27s\n",
      "(Training) Loss: 1234350.7221\n",
      "(Validation) Loss: 1268150.4254, MAE: 4734.4951, R2: -0.0676\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [676/5000] | Time: 0.33s\n",
      "(Training) Loss: 1215176.0558\n",
      "(Validation) Loss: 1267897.3105, MAE: 4733.4536, R2: -0.0673\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [677/5000] | Time: 0.34s\n",
      "(Training) Loss: 1206674.9602\n",
      "(Validation) Loss: 1267647.2533, MAE: 4731.1284, R2: -0.0671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [678/5000] | Time: 0.31s\n",
      "(Training) Loss: 1214191.5266\n",
      "(Validation) Loss: 1267401.7422, MAE: 4733.4883, R2: -0.0669\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [679/5000] | Time: 0.37s\n",
      "(Training) Loss: 1238976.4772\n",
      "(Validation) Loss: 1267156.0178, MAE: 4730.8789, R2: -0.0667\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [680/5000] | Time: 0.33s\n",
      "(Training) Loss: 1219167.6675\n",
      "(Validation) Loss: 1266904.7060, MAE: 4731.5522, R2: -0.0665\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [681/5000] | Time: 0.39s\n",
      "(Training) Loss: 1222474.7538\n",
      "(Validation) Loss: 1266650.2603, MAE: 4728.6582, R2: -0.0663\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [682/5000] | Time: 0.32s\n",
      "(Training) Loss: 1228496.7919\n",
      "(Validation) Loss: 1266407.0451, MAE: 4730.1392, R2: -0.0661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [683/5000] | Time: 0.29s\n",
      "(Training) Loss: 1220119.1929\n",
      "(Validation) Loss: 1266149.9276, MAE: 4726.0166, R2: -0.0659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [684/5000] | Time: 0.26s\n",
      "(Training) Loss: 1231173.6041\n",
      "(Validation) Loss: 1265902.9029, MAE: 4725.4297, R2: -0.0657\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [685/5000] | Time: 0.27s\n",
      "(Training) Loss: 1221860.6789\n",
      "(Validation) Loss: 1265652.6832, MAE: 4724.7061, R2: -0.0655\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [686/5000] | Time: 0.22s\n",
      "(Training) Loss: 1227058.4930\n",
      "(Validation) Loss: 1265402.8952, MAE: 4724.0322, R2: -0.0653\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [687/5000] | Time: 0.23s\n",
      "(Training) Loss: 1210119.2246\n",
      "(Validation) Loss: 1265150.1613, MAE: 4724.1846, R2: -0.0651\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [688/5000] | Time: 0.29s\n",
      "(Training) Loss: 1222003.8287\n",
      "(Validation) Loss: 1264900.7289, MAE: 4721.0654, R2: -0.0648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [689/5000] | Time: 0.25s\n",
      "(Training) Loss: 1209404.0431\n",
      "(Validation) Loss: 1264655.2584, MAE: 4721.7583, R2: -0.0646\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [690/5000] | Time: 0.33s\n",
      "(Training) Loss: 1208208.4607\n",
      "(Validation) Loss: 1264405.6635, MAE: 4719.5889, R2: -0.0644\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [691/5000] | Time: 0.26s\n",
      "(Training) Loss: 1240204.1745\n",
      "(Validation) Loss: 1264157.2775, MAE: 4718.9673, R2: -0.0642\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [692/5000] | Time: 0.28s\n",
      "(Training) Loss: 1238616.5051\n",
      "(Validation) Loss: 1263906.2959, MAE: 4718.6836, R2: -0.0640\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [693/5000] | Time: 0.29s\n",
      "(Training) Loss: 1239790.2614\n",
      "(Validation) Loss: 1263654.8368, MAE: 4717.9263, R2: -0.0638\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [694/5000] | Time: 0.25s\n",
      "(Training) Loss: 1212079.1497\n",
      "(Validation) Loss: 1263405.0946, MAE: 4718.3442, R2: -0.0636\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [695/5000] | Time: 0.26s\n",
      "(Training) Loss: 1221681.1015\n",
      "(Validation) Loss: 1263155.7130, MAE: 4717.4951, R2: -0.0634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [696/5000] | Time: 0.27s\n",
      "(Training) Loss: 1230783.1980\n",
      "(Validation) Loss: 1262910.5676, MAE: 4716.5669, R2: -0.0632\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [697/5000] | Time: 0.26s\n",
      "(Training) Loss: 1206064.5755\n",
      "(Validation) Loss: 1262660.3784, MAE: 4719.2158, R2: -0.0630\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [698/5000] | Time: 0.27s\n",
      "(Training) Loss: 1233137.8997\n",
      "(Validation) Loss: 1262413.8565, MAE: 4716.5850, R2: -0.0628\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [699/5000] | Time: 0.38s\n",
      "(Training) Loss: 1215266.5635\n",
      "(Validation) Loss: 1267535.2025, MAE: 4731.3838, R2: -0.0670\n",
      "==========================================================================================\n",
      "Epoch [700/5000] | Time: 0.29s\n",
      "(Training) Loss: 1215041.1599\n",
      "(Validation) Loss: 1267286.3949, MAE: 4731.2661, R2: -0.0668\n",
      "==========================================================================================\n",
      "Epoch [701/5000] | Time: 0.26s\n",
      "(Training) Loss: 1247005.7081\n",
      "(Validation) Loss: 1267038.9181, MAE: 4730.8145, R2: -0.0666\n",
      "==========================================================================================\n",
      "Epoch [702/5000] | Time: 0.29s\n",
      "(Training) Loss: 1206807.4164\n",
      "(Validation) Loss: 1266781.0997, MAE: 4729.1494, R2: -0.0664\n",
      "==========================================================================================\n",
      "Epoch [703/5000] | Time: 0.32s\n",
      "(Training) Loss: 1241121.4975\n",
      "(Validation) Loss: 1266534.1714, MAE: 4728.5898, R2: -0.0662\n",
      "==========================================================================================\n",
      "Epoch [704/5000] | Time: 0.27s\n",
      "(Training) Loss: 1227270.8972\n",
      "(Validation) Loss: 1266296.2743, MAE: 4732.0396, R2: -0.0660\n",
      "==========================================================================================\n",
      "Epoch [705/5000] | Time: 0.27s\n",
      "(Training) Loss: 1226649.5444\n",
      "(Validation) Loss: 1266033.3613, MAE: 4726.6909, R2: -0.0658\n",
      "==========================================================================================\n",
      "Epoch [706/5000] | Time: 0.26s\n",
      "(Training) Loss: 1208367.9327\n",
      "(Validation) Loss: 1265780.0127, MAE: 4724.8364, R2: -0.0656\n",
      "==========================================================================================\n",
      "Epoch [707/5000] | Time: 0.24s\n",
      "(Training) Loss: 1232460.8934\n",
      "(Validation) Loss: 1265531.5657, MAE: 4724.8643, R2: -0.0654\n",
      "==========================================================================================\n",
      "Epoch [708/5000] | Time: 0.27s\n",
      "(Training) Loss: 1213047.6491\n",
      "(Validation) Loss: 1265286.4863, MAE: 4725.3662, R2: -0.0652\n",
      "==========================================================================================\n",
      "Epoch [709/5000] | Time: 0.27s\n",
      "(Training) Loss: 1204157.3589\n",
      "(Validation) Loss: 1265028.7340, MAE: 4723.6572, R2: -0.0650\n",
      "==========================================================================================\n",
      "Epoch [710/5000] | Time: 0.31s\n",
      "(Training) Loss: 1230106.1637\n",
      "(Validation) Loss: 1264782.4863, MAE: 4721.3062, R2: -0.0647\n",
      "==========================================================================================\n",
      "Epoch [711/5000] | Time: 0.28s\n",
      "(Training) Loss: 1204156.6004\n",
      "(Validation) Loss: 1264530.6210, MAE: 4720.6641, R2: -0.0645\n",
      "==========================================================================================\n",
      "Epoch [712/5000] | Time: 0.29s\n",
      "(Training) Loss: 1208759.0844\n",
      "(Validation) Loss: 1264283.0425, MAE: 4719.9004, R2: -0.0643\n",
      "==========================================================================================\n",
      "Epoch [713/5000] | Time: 0.25s\n",
      "(Training) Loss: 1215152.5647\n",
      "(Validation) Loss: 1264038.3441, MAE: 4720.6060, R2: -0.0641\n",
      "==========================================================================================\n",
      "Epoch [714/5000] | Time: 0.25s\n",
      "(Training) Loss: 1213673.6694\n",
      "(Validation) Loss: 1263787.4032, MAE: 4718.7725, R2: -0.0639\n",
      "==========================================================================================\n",
      "Epoch [715/5000] | Time: 0.26s\n",
      "(Training) Loss: 1207279.4613\n",
      "(Validation) Loss: 1263536.1016, MAE: 4717.0522, R2: -0.0637\n",
      "==========================================================================================\n",
      "Epoch [716/5000] | Time: 0.27s\n",
      "(Training) Loss: 1210546.9822\n",
      "(Validation) Loss: 1263286.6235, MAE: 4716.3325, R2: -0.0635\n",
      "==========================================================================================\n",
      "Epoch [717/5000] | Time: 0.28s\n",
      "(Training) Loss: 1231456.4569\n",
      "(Validation) Loss: 1263039.7867, MAE: 4715.6265, R2: -0.0633\n",
      "==========================================================================================\n",
      "Epoch [718/5000] | Time: 0.29s\n",
      "(Training) Loss: 1210234.3027\n",
      "(Validation) Loss: 1262793.4933, MAE: 4716.3027, R2: -0.0631\n",
      "==========================================================================================\n",
      "Epoch [719/5000] | Time: 0.33s\n",
      "(Training) Loss: 1233424.5393\n",
      "(Validation) Loss: 1262540.4902, MAE: 4713.8032, R2: -0.0629\n",
      "==========================================================================================\n",
      "Epoch [720/5000] | Time: 0.32s\n",
      "(Training) Loss: 1205596.3852\n",
      "(Validation) Loss: 1262283.5352, MAE: 4711.8457, R2: -0.0627\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [721/5000] | Time: 0.28s\n",
      "(Training) Loss: 1221429.0393\n",
      "(Validation) Loss: 1262041.9860, MAE: 4711.6758, R2: -0.0625\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [722/5000] | Time: 0.27s\n",
      "(Training) Loss: 1234961.7284\n",
      "(Validation) Loss: 1261796.0025, MAE: 4712.5171, R2: -0.0623\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [723/5000] | Time: 0.27s\n",
      "(Training) Loss: 1201303.1480\n",
      "(Validation) Loss: 1261541.1556, MAE: 4711.3037, R2: -0.0620\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [724/5000] | Time: 0.29s\n",
      "(Training) Loss: 1212303.6815\n",
      "(Validation) Loss: 1261289.0921, MAE: 4708.6328, R2: -0.0618\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [725/5000] | Time: 0.30s\n",
      "(Training) Loss: 1224354.2754\n",
      "(Validation) Loss: 1261045.6889, MAE: 4708.8657, R2: -0.0616\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [726/5000] | Time: 0.25s\n",
      "(Training) Loss: 1204486.0279\n",
      "(Validation) Loss: 1260794.2044, MAE: 4707.9097, R2: -0.0614\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [727/5000] | Time: 0.29s\n",
      "(Training) Loss: 1212970.4829\n",
      "(Validation) Loss: 1260544.5587, MAE: 4705.9307, R2: -0.0612\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [728/5000] | Time: 0.29s\n",
      "(Training) Loss: 1209692.6815\n",
      "(Validation) Loss: 1260307.5911, MAE: 4710.2329, R2: -0.0610\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [729/5000] | Time: 0.27s\n",
      "(Training) Loss: 1222389.3909\n",
      "(Validation) Loss: 1260049.0108, MAE: 4703.9087, R2: -0.0608\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [730/5000] | Time: 0.30s\n",
      "(Training) Loss: 1205137.8477\n",
      "(Validation) Loss: 1259797.6940, MAE: 4703.6099, R2: -0.0606\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [731/5000] | Time: 0.26s\n",
      "(Training) Loss: 1220134.6650\n",
      "(Validation) Loss: 1259549.2317, MAE: 4702.5947, R2: -0.0604\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [732/5000] | Time: 0.31s\n",
      "(Training) Loss: 1216251.2132\n",
      "(Validation) Loss: 1259300.2311, MAE: 4701.9243, R2: -0.0602\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [733/5000] | Time: 0.29s\n",
      "(Training) Loss: 1232233.8464\n",
      "(Validation) Loss: 1259052.9422, MAE: 4700.6455, R2: -0.0600\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [734/5000] | Time: 0.36s\n",
      "(Training) Loss: 1213899.2538\n",
      "(Validation) Loss: 1258801.3359, MAE: 4699.7393, R2: -0.0598\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [735/5000] | Time: 0.34s\n",
      "(Training) Loss: 1224063.8737\n",
      "(Validation) Loss: 1258554.3111, MAE: 4698.0449, R2: -0.0596\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [736/5000] | Time: 0.30s\n",
      "(Training) Loss: 1237757.1028\n",
      "(Validation) Loss: 1261175.8578, MAE: 4714.7446, R2: -0.0617\n",
      "==========================================================================================\n",
      "Epoch [737/5000] | Time: 0.28s\n",
      "(Training) Loss: 1212450.0514\n",
      "(Validation) Loss: 1258057.6457, MAE: 4698.6240, R2: -0.0591\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [738/5000] | Time: 0.31s\n",
      "(Training) Loss: 1231809.2132\n",
      "(Validation) Loss: 1257813.9835, MAE: 4700.1284, R2: -0.0589\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [739/5000] | Time: 0.35s\n",
      "(Training) Loss: 1222131.2779\n",
      "(Validation) Loss: 1257557.5111, MAE: 4697.3145, R2: -0.0587\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [740/5000] | Time: 0.27s\n",
      "(Training) Loss: 1202056.8160\n",
      "(Validation) Loss: 1257301.4298, MAE: 4693.6338, R2: -0.0585\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [741/5000] | Time: 0.23s\n",
      "(Training) Loss: 1219077.2741\n",
      "(Validation) Loss: 1257062.9435, MAE: 4695.0913, R2: -0.0583\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [742/5000] | Time: 0.24s\n",
      "(Training) Loss: 1211699.1751\n",
      "(Validation) Loss: 1256812.1905, MAE: 4693.5879, R2: -0.0581\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [743/5000] | Time: 0.25s\n",
      "(Training) Loss: 1235593.2640\n",
      "(Validation) Loss: 1256561.4984, MAE: 4692.1475, R2: -0.0579\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [744/5000] | Time: 0.26s\n",
      "(Training) Loss: 1221775.5799\n",
      "(Validation) Loss: 1256316.0990, MAE: 4692.5605, R2: -0.0577\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [745/5000] | Time: 0.26s\n",
      "(Training) Loss: 1226672.9359\n",
      "(Validation) Loss: 1256062.3238, MAE: 4689.7686, R2: -0.0575\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [746/5000] | Time: 0.25s\n",
      "(Training) Loss: 1203776.9302\n",
      "(Validation) Loss: 1255813.4197, MAE: 4690.0386, R2: -0.0573\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [747/5000] | Time: 0.25s\n",
      "(Training) Loss: 1202296.0533\n",
      "(Validation) Loss: 1255570.5448, MAE: 4690.3564, R2: -0.0571\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [748/5000] | Time: 0.28s\n",
      "(Training) Loss: 1217595.5457\n",
      "(Validation) Loss: 1255315.5962, MAE: 4686.4243, R2: -0.0569\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [749/5000] | Time: 0.33s\n",
      "(Training) Loss: 1207429.0381\n",
      "(Validation) Loss: 1255070.4965, MAE: 4685.7764, R2: -0.0567\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [750/5000] | Time: 0.30s\n",
      "(Training) Loss: 1223618.6846\n",
      "(Validation) Loss: 1254822.4559, MAE: 4685.0806, R2: -0.0564\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [751/5000] | Time: 0.28s\n",
      "(Training) Loss: 1226364.3528\n",
      "(Validation) Loss: 1254579.4489, MAE: 4686.1147, R2: -0.0562\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [752/5000] | Time: 0.28s\n",
      "(Training) Loss: 1198613.2544\n",
      "(Validation) Loss: 1254327.6749, MAE: 4683.3560, R2: -0.0560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [753/5000] | Time: 0.27s\n",
      "(Training) Loss: 1220589.5006\n",
      "(Validation) Loss: 1254079.1568, MAE: 4682.5029, R2: -0.0558\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [754/5000] | Time: 0.27s\n",
      "(Training) Loss: 1207696.7678\n",
      "(Validation) Loss: 1253837.2622, MAE: 4682.4062, R2: -0.0556\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [755/5000] | Time: 0.26s\n",
      "(Training) Loss: 1195791.7291\n",
      "(Validation) Loss: 1253589.2622, MAE: 4682.0005, R2: -0.0554\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [756/5000] | Time: 0.27s\n",
      "(Training) Loss: 1223303.4150\n",
      "(Validation) Loss: 1253347.3117, MAE: 4682.4224, R2: -0.0552\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [757/5000] | Time: 0.30s\n",
      "(Training) Loss: 1210151.1206\n",
      "(Validation) Loss: 1253090.9359, MAE: 4679.5864, R2: -0.0550\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [758/5000] | Time: 0.27s\n",
      "(Training) Loss: 1205363.3579\n",
      "(Validation) Loss: 1252848.9498, MAE: 4679.2988, R2: -0.0548\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [759/5000] | Time: 0.30s\n",
      "(Training) Loss: 1208947.9289\n",
      "(Validation) Loss: 1252595.9416, MAE: 4677.4658, R2: -0.0546\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [760/5000] | Time: 0.29s\n",
      "(Training) Loss: 1211452.6428\n",
      "(Validation) Loss: 1252351.6241, MAE: 4675.8604, R2: -0.0544\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [761/5000] | Time: 0.26s\n",
      "(Training) Loss: 1199906.3541\n",
      "(Validation) Loss: 1252103.0044, MAE: 4674.0479, R2: -0.0542\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [762/5000] | Time: 0.28s\n",
      "(Training) Loss: 1197088.2824\n",
      "(Validation) Loss: 1251858.0521, MAE: 4675.0947, R2: -0.0540\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [763/5000] | Time: 0.28s\n",
      "(Training) Loss: 1192551.9597\n",
      "(Validation) Loss: 1251610.8851, MAE: 4673.4023, R2: -0.0538\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [764/5000] | Time: 0.29s\n",
      "(Training) Loss: 1208252.7738\n",
      "(Validation) Loss: 1251372.0127, MAE: 4675.1592, R2: -0.0536\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [765/5000] | Time: 0.30s\n",
      "(Training) Loss: 1194870.7024\n",
      "(Validation) Loss: 1251122.5498, MAE: 4672.0439, R2: -0.0534\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [766/5000] | Time: 0.24s\n",
      "(Training) Loss: 1211482.5501\n",
      "(Validation) Loss: 1250876.5714, MAE: 4669.7949, R2: -0.0532\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [767/5000] | Time: 0.25s\n",
      "(Training) Loss: 1208952.4918\n",
      "(Validation) Loss: 1250628.5613, MAE: 4671.1592, R2: -0.0530\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [768/5000] | Time: 0.29s\n",
      "(Training) Loss: 1218095.2005\n",
      "(Validation) Loss: 1250379.9314, MAE: 4668.7515, R2: -0.0527\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [769/5000] | Time: 0.22s\n",
      "(Training) Loss: 1213206.5102\n",
      "(Validation) Loss: 1250128.9702, MAE: 4666.9053, R2: -0.0525\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [770/5000] | Time: 0.24s\n",
      "(Training) Loss: 1202313.4099\n",
      "(Validation) Loss: 1249888.5689, MAE: 4668.6001, R2: -0.0523\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [771/5000] | Time: 0.27s\n",
      "(Training) Loss: 1193183.6999\n",
      "(Validation) Loss: 1249642.4127, MAE: 4667.5332, R2: -0.0521\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [772/5000] | Time: 0.26s\n",
      "(Training) Loss: 1199338.2335\n",
      "(Validation) Loss: 1249395.9975, MAE: 4666.3408, R2: -0.0519\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [773/5000] | Time: 0.25s\n",
      "(Training) Loss: 1198246.2373\n",
      "(Validation) Loss: 1249151.5378, MAE: 4665.9370, R2: -0.0517\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [774/5000] | Time: 0.26s\n",
      "(Training) Loss: 1204338.5438\n",
      "(Validation) Loss: 1248901.3740, MAE: 4664.2329, R2: -0.0515\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [775/5000] | Time: 0.27s\n",
      "(Training) Loss: 1219335.7681\n",
      "(Validation) Loss: 1248659.1187, MAE: 4662.7192, R2: -0.0513\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [776/5000] | Time: 0.28s\n",
      "(Training) Loss: 1205595.2944\n",
      "(Validation) Loss: 1248407.8730, MAE: 4661.3652, R2: -0.0511\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [777/5000] | Time: 0.29s\n",
      "(Training) Loss: 1209449.3503\n",
      "(Validation) Loss: 1248163.8197, MAE: 4660.2988, R2: -0.0509\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [778/5000] | Time: 0.23s\n",
      "(Training) Loss: 1191620.4949\n",
      "(Validation) Loss: 1247922.5956, MAE: 4663.2227, R2: -0.0507\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [779/5000] | Time: 0.25s\n",
      "(Training) Loss: 1192847.5482\n",
      "(Validation) Loss: 1247673.7981, MAE: 4659.1382, R2: -0.0505\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [780/5000] | Time: 0.24s\n",
      "(Training) Loss: 1229288.5279\n",
      "(Validation) Loss: 1247422.5422, MAE: 4657.4097, R2: -0.0503\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [781/5000] | Time: 0.23s\n",
      "(Training) Loss: 1192434.1447\n",
      "(Validation) Loss: 1247182.4762, MAE: 4659.5034, R2: -0.0501\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [782/5000] | Time: 0.21s\n",
      "(Training) Loss: 1200219.2360\n",
      "(Validation) Loss: 1246933.9784, MAE: 4658.4907, R2: -0.0499\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [783/5000] | Time: 0.23s\n",
      "(Training) Loss: 1228884.6783\n",
      "(Validation) Loss: 1246684.2159, MAE: 4654.8799, R2: -0.0497\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [784/5000] | Time: 0.27s\n",
      "(Training) Loss: 1200985.9562\n",
      "(Validation) Loss: 1246440.7924, MAE: 4655.0674, R2: -0.0495\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [785/5000] | Time: 0.24s\n",
      "(Training) Loss: 1193520.5850\n",
      "(Validation) Loss: 1246188.5613, MAE: 4652.0288, R2: -0.0493\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [786/5000] | Time: 0.27s\n",
      "(Training) Loss: 1195033.1802\n",
      "(Validation) Loss: 1245949.8717, MAE: 4652.8169, R2: -0.0491\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [787/5000] | Time: 0.21s\n",
      "(Training) Loss: 1188375.0317\n",
      "(Validation) Loss: 1245704.0203, MAE: 4652.8535, R2: -0.0489\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [788/5000] | Time: 0.24s\n",
      "(Training) Loss: 1199835.9848\n",
      "(Validation) Loss: 1245461.2013, MAE: 4650.5986, R2: -0.0487\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [789/5000] | Time: 0.31s\n",
      "(Training) Loss: 1211408.7690\n",
      "(Validation) Loss: 1245217.2190, MAE: 4651.0112, R2: -0.0484\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [790/5000] | Time: 0.22s\n",
      "(Training) Loss: 1188061.4749\n",
      "(Validation) Loss: 1244966.0190, MAE: 4648.6191, R2: -0.0482\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [791/5000] | Time: 0.31s\n",
      "(Training) Loss: 1203602.5926\n",
      "(Validation) Loss: 1244723.1492, MAE: 4648.4917, R2: -0.0480\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [792/5000] | Time: 0.25s\n",
      "(Training) Loss: 1195295.4277\n",
      "(Validation) Loss: 1244484.4546, MAE: 4648.0342, R2: -0.0478\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [793/5000] | Time: 0.24s\n",
      "(Training) Loss: 1208230.5209\n",
      "(Validation) Loss: 1244238.8470, MAE: 4650.1372, R2: -0.0476\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [794/5000] | Time: 0.27s\n",
      "(Training) Loss: 1207036.8122\n",
      "(Validation) Loss: 1243984.2032, MAE: 4645.7290, R2: -0.0474\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [795/5000] | Time: 0.31s\n",
      "(Training) Loss: 1199240.5305\n",
      "(Validation) Loss: 1243741.2622, MAE: 4645.2529, R2: -0.0472\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [796/5000] | Time: 0.28s\n",
      "(Training) Loss: 1192903.0089\n",
      "(Validation) Loss: 1243494.1054, MAE: 4644.5884, R2: -0.0470\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [797/5000] | Time: 0.25s\n",
      "(Training) Loss: 1193523.6434\n",
      "(Validation) Loss: 1243249.8337, MAE: 4644.6504, R2: -0.0468\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [798/5000] | Time: 0.24s\n",
      "(Training) Loss: 1193913.9480\n",
      "(Validation) Loss: 1243007.3803, MAE: 4644.4116, R2: -0.0466\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [799/5000] | Time: 0.23s\n",
      "(Training) Loss: 1189103.6250\n",
      "(Validation) Loss: 1242755.7537, MAE: 4641.4331, R2: -0.0464\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [800/5000] | Time: 0.23s\n",
      "(Training) Loss: 1184247.1729\n",
      "(Validation) Loss: 1242518.7759, MAE: 4641.4248, R2: -0.0462\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [801/5000] | Time: 0.21s\n",
      "(Training) Loss: 1191745.3718\n",
      "(Validation) Loss: 1242272.8584, MAE: 4640.9253, R2: -0.0460\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [802/5000] | Time: 0.23s\n",
      "(Training) Loss: 1186574.6846\n",
      "(Validation) Loss: 1242034.3975, MAE: 4641.4385, R2: -0.0458\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [803/5000] | Time: 0.23s\n",
      "(Training) Loss: 1198854.8528\n",
      "(Validation) Loss: 1241785.9860, MAE: 4639.3281, R2: -0.0456\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [804/5000] | Time: 0.28s\n",
      "(Training) Loss: 1193475.2665\n",
      "(Validation) Loss: 1241538.1587, MAE: 4636.3647, R2: -0.0454\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [805/5000] | Time: 0.27s\n",
      "(Training) Loss: 1206830.0330\n",
      "(Validation) Loss: 1241293.5213, MAE: 4635.7661, R2: -0.0452\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [806/5000] | Time: 0.25s\n",
      "(Training) Loss: 1190734.0622\n",
      "(Validation) Loss: 1241052.3327, MAE: 4636.2856, R2: -0.0450\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [807/5000] | Time: 0.24s\n",
      "(Training) Loss: 1208356.1091\n",
      "(Validation) Loss: 1240801.6356, MAE: 4634.1108, R2: -0.0448\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [808/5000] | Time: 0.24s\n",
      "(Training) Loss: 1213153.0228\n",
      "(Validation) Loss: 1240557.7549, MAE: 4634.0640, R2: -0.0446\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [809/5000] | Time: 0.26s\n",
      "(Training) Loss: 1203682.4645\n",
      "(Validation) Loss: 1243382.5981, MAE: 4646.1172, R2: -0.0469\n",
      "==========================================================================================\n",
      "Epoch [810/5000] | Time: 0.26s\n",
      "(Training) Loss: 1196933.7291\n",
      "(Validation) Loss: 1243136.6908, MAE: 4642.8496, R2: -0.0467\n",
      "==========================================================================================\n",
      "Epoch [811/5000] | Time: 0.24s\n",
      "(Training) Loss: 1201505.2297\n",
      "(Validation) Loss: 1242901.3029, MAE: 4643.6699, R2: -0.0465\n",
      "==========================================================================================\n",
      "Epoch [812/5000] | Time: 0.26s\n",
      "(Training) Loss: 1218577.3344\n",
      "(Validation) Loss: 1242654.2883, MAE: 4642.2891, R2: -0.0463\n",
      "==========================================================================================\n",
      "Epoch [813/5000] | Time: 0.33s\n",
      "(Training) Loss: 1188873.4778\n",
      "(Validation) Loss: 1242445.4400, MAE: 4644.2031, R2: -0.0461\n",
      "==========================================================================================\n",
      "Epoch [814/5000] | Time: 0.24s\n",
      "(Training) Loss: 1190979.6003\n",
      "(Validation) Loss: 1242171.9467, MAE: 4643.4224, R2: -0.0459\n",
      "==========================================================================================\n",
      "Epoch [815/5000] | Time: 0.24s\n",
      "(Training) Loss: 1189023.4632\n",
      "(Validation) Loss: 1241927.7968, MAE: 4638.6963, R2: -0.0457\n",
      "==========================================================================================\n",
      "Epoch [816/5000] | Time: 0.28s\n",
      "(Training) Loss: 1214344.6599\n",
      "(Validation) Loss: 1241690.7276, MAE: 4638.6235, R2: -0.0455\n",
      "==========================================================================================\n",
      "Epoch [817/5000] | Time: 0.27s\n",
      "(Training) Loss: 1206692.4442\n",
      "(Validation) Loss: 1241440.9041, MAE: 4636.3589, R2: -0.0453\n",
      "==========================================================================================\n",
      "Epoch [818/5000] | Time: 0.26s\n",
      "(Training) Loss: 1190335.6015\n",
      "(Validation) Loss: 1241201.2698, MAE: 4635.5967, R2: -0.0451\n",
      "==========================================================================================\n",
      "Epoch [819/5000] | Time: 0.26s\n",
      "(Training) Loss: 1222484.2513\n",
      "(Validation) Loss: 1240959.0400, MAE: 4634.6934, R2: -0.0449\n",
      "==========================================================================================\n",
      "Epoch [820/5000] | Time: 0.36s\n",
      "(Training) Loss: 1188378.5127\n",
      "(Validation) Loss: 1240715.6470, MAE: 4634.3369, R2: -0.0447\n",
      "==========================================================================================\n",
      "Epoch [821/5000] | Time: 0.25s\n",
      "(Training) Loss: 1182430.8268\n",
      "(Validation) Loss: 1240473.1225, MAE: 4633.6040, R2: -0.0445\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [822/5000] | Time: 0.24s\n",
      "(Training) Loss: 1205183.7405\n",
      "(Validation) Loss: 1240238.8216, MAE: 4632.3872, R2: -0.0443\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [823/5000] | Time: 0.28s\n",
      "(Training) Loss: 1197408.3655\n",
      "(Validation) Loss: 1239990.6997, MAE: 4630.6948, R2: -0.0441\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [824/5000] | Time: 0.26s\n",
      "(Training) Loss: 1180362.8263\n",
      "(Validation) Loss: 1239753.1784, MAE: 4631.6118, R2: -0.0439\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [825/5000] | Time: 0.24s\n",
      "(Training) Loss: 1200327.8725\n",
      "(Validation) Loss: 1239512.4775, MAE: 4629.8101, R2: -0.0437\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [826/5000] | Time: 0.28s\n",
      "(Training) Loss: 1200565.3731\n",
      "(Validation) Loss: 1239289.1022, MAE: 4636.0947, R2: -0.0435\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [827/5000] | Time: 0.24s\n",
      "(Training) Loss: 1191334.2811\n",
      "(Validation) Loss: 1239031.2584, MAE: 4630.2715, R2: -0.0433\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [828/5000] | Time: 0.30s\n",
      "(Training) Loss: 1192605.4734\n",
      "(Validation) Loss: 1238792.1422, MAE: 4626.8735, R2: -0.0431\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [829/5000] | Time: 0.30s\n",
      "(Training) Loss: 1196241.3388\n",
      "(Validation) Loss: 1238547.2000, MAE: 4626.2954, R2: -0.0429\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [830/5000] | Time: 0.26s\n",
      "(Training) Loss: 1181468.0720\n",
      "(Validation) Loss: 1238306.5143, MAE: 4626.6055, R2: -0.0427\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [831/5000] | Time: 0.26s\n",
      "(Training) Loss: 1190055.9188\n",
      "(Validation) Loss: 1238068.1803, MAE: 4624.6836, R2: -0.0425\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [832/5000] | Time: 0.29s\n",
      "(Training) Loss: 1182550.1345\n",
      "(Validation) Loss: 1237827.8654, MAE: 4624.5176, R2: -0.0423\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [833/5000] | Time: 0.28s\n",
      "(Training) Loss: 1199908.8287\n",
      "(Validation) Loss: 1237586.7429, MAE: 4623.4648, R2: -0.0421\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [834/5000] | Time: 0.25s\n",
      "(Training) Loss: 1178794.0611\n",
      "(Validation) Loss: 1237347.5302, MAE: 4622.2881, R2: -0.0419\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [835/5000] | Time: 0.24s\n",
      "(Training) Loss: 1189803.9435\n",
      "(Validation) Loss: 1237108.4495, MAE: 4621.8276, R2: -0.0417\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [836/5000] | Time: 0.27s\n",
      "(Training) Loss: 1189590.3223\n",
      "(Validation) Loss: 1236865.4781, MAE: 4619.9253, R2: -0.0415\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [837/5000] | Time: 0.33s\n",
      "(Training) Loss: 1195190.9150\n",
      "(Validation) Loss: 1236629.7956, MAE: 4619.8428, R2: -0.0413\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [838/5000] | Time: 0.25s\n",
      "(Training) Loss: 1185681.7525\n",
      "(Validation) Loss: 1236385.5797, MAE: 4619.4248, R2: -0.0411\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [839/5000] | Time: 0.28s\n",
      "(Training) Loss: 1197143.8566\n",
      "(Validation) Loss: 1236145.4324, MAE: 4616.9985, R2: -0.0409\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [840/5000] | Time: 0.26s\n",
      "(Training) Loss: 1202681.8642\n",
      "(Validation) Loss: 1235914.9816, MAE: 4619.8706, R2: -0.0407\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [841/5000] | Time: 0.29s\n",
      "(Training) Loss: 1187692.5228\n",
      "(Validation) Loss: 1235663.0603, MAE: 4616.6772, R2: -0.0405\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [842/5000] | Time: 0.28s\n",
      "(Training) Loss: 1190479.3312\n",
      "(Validation) Loss: 1235423.2178, MAE: 4614.8789, R2: -0.0403\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [843/5000] | Time: 0.25s\n",
      "(Training) Loss: 1197729.1516\n",
      "(Validation) Loss: 1235189.2165, MAE: 4616.8550, R2: -0.0401\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [844/5000] | Time: 0.30s\n",
      "(Training) Loss: 1206688.3585\n",
      "(Validation) Loss: 1234966.9994, MAE: 4617.3179, R2: -0.0399\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [845/5000] | Time: 0.29s\n",
      "(Training) Loss: 1209417.9048\n",
      "(Validation) Loss: 1234702.7860, MAE: 4613.6211, R2: -0.0397\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [846/5000] | Time: 0.28s\n",
      "(Training) Loss: 1194148.2487\n",
      "(Validation) Loss: 1234459.6825, MAE: 4612.7461, R2: -0.0395\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [847/5000] | Time: 0.27s\n",
      "(Training) Loss: 1181522.6104\n",
      "(Validation) Loss: 1234214.7860, MAE: 4610.4722, R2: -0.0393\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [848/5000] | Time: 0.28s\n",
      "(Training) Loss: 1187086.2805\n",
      "(Validation) Loss: 1234006.9638, MAE: 4614.0303, R2: -0.0391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [849/5000] | Time: 0.24s\n",
      "(Training) Loss: 1199547.5793\n",
      "(Validation) Loss: 1233746.4533, MAE: 4610.6797, R2: -0.0389\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [850/5000] | Time: 0.23s\n",
      "(Training) Loss: 1180192.7678\n",
      "(Validation) Loss: 1233503.8730, MAE: 4611.1074, R2: -0.0387\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [851/5000] | Time: 0.27s\n",
      "(Training) Loss: 1178141.0520\n",
      "(Validation) Loss: 1233273.3562, MAE: 4612.6631, R2: -0.0385\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [852/5000] | Time: 0.31s\n",
      "(Training) Loss: 1191674.2392\n",
      "(Validation) Loss: 1233022.3949, MAE: 4606.3662, R2: -0.0383\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [853/5000] | Time: 0.29s\n",
      "(Training) Loss: 1202890.0368\n",
      "(Validation) Loss: 1232780.8203, MAE: 4605.4243, R2: -0.0381\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [854/5000] | Time: 0.35s\n",
      "(Training) Loss: 1218226.4251\n",
      "(Validation) Loss: 1232556.9422, MAE: 4605.6890, R2: -0.0379\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [855/5000] | Time: 0.32s\n",
      "(Training) Loss: 1190522.3401\n",
      "(Validation) Loss: 1232298.1283, MAE: 4604.1953, R2: -0.0377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [856/5000] | Time: 0.33s\n",
      "(Training) Loss: 1180212.8179\n",
      "(Validation) Loss: 1232060.6171, MAE: 4603.5752, R2: -0.0375\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [857/5000] | Time: 0.29s\n",
      "(Training) Loss: 1175936.3030\n",
      "(Validation) Loss: 1231834.4076, MAE: 4608.4619, R2: -0.0373\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [858/5000] | Time: 0.25s\n",
      "(Training) Loss: 1194744.2069\n",
      "(Validation) Loss: 1231582.1765, MAE: 4601.4170, R2: -0.0371\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [859/5000] | Time: 0.25s\n",
      "(Training) Loss: 1209930.1961\n",
      "(Validation) Loss: 1231344.0356, MAE: 4601.8193, R2: -0.0369\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [860/5000] | Time: 0.23s\n",
      "(Training) Loss: 1179563.4803\n",
      "(Validation) Loss: 1231100.8711, MAE: 4599.3545, R2: -0.0367\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [861/5000] | Time: 0.21s\n",
      "(Training) Loss: 1179556.4505\n",
      "(Validation) Loss: 1230864.0863, MAE: 4597.6392, R2: -0.0365\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [862/5000] | Time: 0.26s\n",
      "(Training) Loss: 1205398.6421\n",
      "(Validation) Loss: 1230625.5289, MAE: 4598.1582, R2: -0.0363\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [863/5000] | Time: 0.22s\n",
      "(Training) Loss: 1190042.8388\n",
      "(Validation) Loss: 1230388.4394, MAE: 4597.7671, R2: -0.0361\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [864/5000] | Time: 0.25s\n",
      "(Training) Loss: 1214358.0546\n",
      "(Validation) Loss: 1230143.3956, MAE: 4595.9316, R2: -0.0359\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [865/5000] | Time: 0.27s\n",
      "(Training) Loss: 1207323.0926\n",
      "(Validation) Loss: 1229905.4984, MAE: 4595.7871, R2: -0.0357\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [866/5000] | Time: 0.27s\n",
      "(Training) Loss: 1179838.5945\n",
      "(Validation) Loss: 1229660.5562, MAE: 4594.5635, R2: -0.0355\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [867/5000] | Time: 0.27s\n",
      "(Training) Loss: 1219968.9315\n",
      "(Validation) Loss: 1229422.3187, MAE: 4593.6973, R2: -0.0353\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [868/5000] | Time: 0.25s\n",
      "(Training) Loss: 1176486.3452\n",
      "(Validation) Loss: 1229182.7048, MAE: 4594.0649, R2: -0.0351\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [869/5000] | Time: 0.24s\n",
      "(Training) Loss: 1185886.2208\n",
      "(Validation) Loss: 1228965.6940, MAE: 4592.4424, R2: -0.0349\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [870/5000] | Time: 0.25s\n",
      "(Training) Loss: 1192505.6180\n",
      "(Validation) Loss: 1228706.4686, MAE: 4590.4517, R2: -0.0347\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [871/5000] | Time: 0.27s\n",
      "(Training) Loss: 1183211.4473\n",
      "(Validation) Loss: 1228467.7841, MAE: 4590.5894, R2: -0.0345\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [872/5000] | Time: 0.28s\n",
      "(Training) Loss: 1186896.3877\n",
      "(Validation) Loss: 1228227.4946, MAE: 4588.5542, R2: -0.0343\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [873/5000] | Time: 0.23s\n",
      "(Training) Loss: 1212443.5768\n",
      "(Validation) Loss: 1227992.1270, MAE: 4588.0024, R2: -0.0341\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [874/5000] | Time: 0.24s\n",
      "(Training) Loss: 1190145.3591\n",
      "(Validation) Loss: 1227766.4914, MAE: 4591.7148, R2: -0.0339\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [875/5000] | Time: 0.28s\n",
      "(Training) Loss: 1202815.9607\n",
      "(Validation) Loss: 1227515.2762, MAE: 4587.3540, R2: -0.0337\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [876/5000] | Time: 0.27s\n",
      "(Training) Loss: 1171317.3693\n",
      "(Validation) Loss: 1227277.0641, MAE: 4588.2769, R2: -0.0335\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [877/5000] | Time: 0.43s\n",
      "(Training) Loss: 1176532.1085\n",
      "(Validation) Loss: 1227031.7765, MAE: 4584.3604, R2: -0.0333\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [878/5000] | Time: 0.59s\n",
      "(Training) Loss: 1193689.7855\n",
      "(Validation) Loss: 1226810.4737, MAE: 4586.1499, R2: -0.0331\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [879/5000] | Time: 0.54s\n",
      "(Training) Loss: 1178410.7627\n",
      "(Validation) Loss: 1226558.5778, MAE: 4583.3257, R2: -0.0329\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [880/5000] | Time: 0.45s\n",
      "(Training) Loss: 1191426.8388\n",
      "(Validation) Loss: 1226321.7473, MAE: 4581.8931, R2: -0.0327\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [881/5000] | Time: 0.44s\n",
      "(Training) Loss: 1170946.3972\n",
      "(Validation) Loss: 1226085.8768, MAE: 4582.0913, R2: -0.0325\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [882/5000] | Time: 0.29s\n",
      "(Training) Loss: 1183544.1739\n",
      "(Validation) Loss: 1225850.3721, MAE: 4582.3218, R2: -0.0323\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [883/5000] | Time: 0.36s\n",
      "(Training) Loss: 1182959.9378\n",
      "(Validation) Loss: 1225612.3937, MAE: 4579.5693, R2: -0.0321\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [884/5000] | Time: 0.30s\n",
      "(Training) Loss: 1177586.5457\n",
      "(Validation) Loss: 1225374.7200, MAE: 4578.3291, R2: -0.0319\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [885/5000] | Time: 0.27s\n",
      "(Training) Loss: 1170710.3103\n",
      "(Validation) Loss: 1225136.2133, MAE: 4578.6025, R2: -0.0317\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [886/5000] | Time: 0.26s\n",
      "(Training) Loss: 1173590.8331\n",
      "(Validation) Loss: 1224901.0337, MAE: 4578.6382, R2: -0.0315\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [887/5000] | Time: 0.22s\n",
      "(Training) Loss: 1196673.8966\n",
      "(Validation) Loss: 1224745.2800, MAE: 4583.8325, R2: -0.0314\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [888/5000] | Time: 0.21s\n",
      "(Training) Loss: 1184859.6421\n",
      "(Validation) Loss: 1224431.3803, MAE: 4579.1582, R2: -0.0311\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [889/5000] | Time: 0.19s\n",
      "(Training) Loss: 1173524.6821\n",
      "(Validation) Loss: 1224192.8635, MAE: 4577.6011, R2: -0.0309\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [890/5000] | Time: 0.21s\n",
      "(Training) Loss: 1203841.8871\n",
      "(Validation) Loss: 1223951.4565, MAE: 4574.7109, R2: -0.0307\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [891/5000] | Time: 0.23s\n",
      "(Training) Loss: 1212691.3388\n",
      "(Validation) Loss: 1223708.6222, MAE: 4571.7285, R2: -0.0305\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [892/5000] | Time: 0.26s\n",
      "(Training) Loss: 1165191.2456\n",
      "(Validation) Loss: 1223465.2190, MAE: 4571.5054, R2: -0.0303\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [893/5000] | Time: 0.24s\n",
      "(Training) Loss: 1185977.2919\n",
      "(Validation) Loss: 1223239.9390, MAE: 4571.7163, R2: -0.0301\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [894/5000] | Time: 0.27s\n",
      "(Training) Loss: 1196593.7462\n",
      "(Validation) Loss: 1222996.2006, MAE: 4568.7998, R2: -0.0299\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [895/5000] | Time: 0.29s\n",
      "(Training) Loss: 1172166.6409\n",
      "(Validation) Loss: 1222762.4787, MAE: 4570.6655, R2: -0.0297\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [896/5000] | Time: 0.24s\n",
      "(Training) Loss: 1165616.5293\n",
      "(Validation) Loss: 1222523.1746, MAE: 4569.8965, R2: -0.0295\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [897/5000] | Time: 0.22s\n",
      "(Training) Loss: 1178964.0127\n",
      "(Validation) Loss: 1222289.9708, MAE: 4567.1567, R2: -0.0294\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [898/5000] | Time: 0.24s\n",
      "(Training) Loss: 1186048.8566\n",
      "(Validation) Loss: 1222060.6425, MAE: 4570.4453, R2: -0.0292\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [899/5000] | Time: 0.21s\n",
      "(Training) Loss: 1203317.0152\n",
      "(Validation) Loss: 1221814.6235, MAE: 4566.3989, R2: -0.0290\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [900/5000] | Time: 0.27s\n",
      "(Training) Loss: 1175782.9308\n",
      "(Validation) Loss: 1221571.1086, MAE: 4564.3008, R2: -0.0288\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [901/5000] | Time: 0.24s\n",
      "(Training) Loss: 1181394.7335\n",
      "(Validation) Loss: 1221334.6844, MAE: 4564.0991, R2: -0.0286\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [902/5000] | Time: 0.29s\n",
      "(Training) Loss: 1173970.5533\n",
      "(Validation) Loss: 1221097.1429, MAE: 4562.6299, R2: -0.0284\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [903/5000] | Time: 0.31s\n",
      "(Training) Loss: 1169836.2449\n",
      "(Validation) Loss: 1220862.9029, MAE: 4562.8413, R2: -0.0282\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [904/5000] | Time: 0.24s\n",
      "(Training) Loss: 1174720.8058\n",
      "(Validation) Loss: 1220625.3663, MAE: 4561.1094, R2: -0.0280\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [905/5000] | Time: 0.23s\n",
      "(Training) Loss: 1178602.8122\n",
      "(Validation) Loss: 1220393.2444, MAE: 4561.0278, R2: -0.0278\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [906/5000] | Time: 0.24s\n",
      "(Training) Loss: 1190221.9898\n",
      "(Validation) Loss: 1220157.4654, MAE: 4560.6177, R2: -0.0276\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [907/5000] | Time: 0.23s\n",
      "(Training) Loss: 1199014.7037\n",
      "(Validation) Loss: 1219918.1359, MAE: 4559.3643, R2: -0.0274\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [908/5000] | Time: 0.26s\n",
      "(Training) Loss: 1170221.0133\n",
      "(Validation) Loss: 1219676.8305, MAE: 4559.6045, R2: -0.0272\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [909/5000] | Time: 0.24s\n",
      "(Training) Loss: 1172873.6129\n",
      "(Validation) Loss: 1219442.2248, MAE: 4557.6284, R2: -0.0270\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [910/5000] | Time: 0.30s\n",
      "(Training) Loss: 1182539.7519\n",
      "(Validation) Loss: 1219214.6540, MAE: 4562.0229, R2: -0.0268\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [911/5000] | Time: 0.32s\n",
      "(Training) Loss: 1209288.8452\n",
      "(Validation) Loss: 1218976.4876, MAE: 4559.8081, R2: -0.0266\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [912/5000] | Time: 0.50s\n",
      "(Training) Loss: 1178392.9734\n",
      "(Validation) Loss: 1218728.1727, MAE: 4556.1465, R2: -0.0264\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [913/5000] | Time: 0.28s\n",
      "(Training) Loss: 1177505.4232\n",
      "(Validation) Loss: 1218490.4432, MAE: 4553.7554, R2: -0.0262\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [914/5000] | Time: 0.25s\n",
      "(Training) Loss: 1166271.3261\n",
      "(Validation) Loss: 1218255.6089, MAE: 4552.9678, R2: -0.0260\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [915/5000] | Time: 0.21s\n",
      "(Training) Loss: 1167197.4416\n",
      "(Validation) Loss: 1218018.4940, MAE: 4552.2705, R2: -0.0258\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [916/5000] | Time: 0.27s\n",
      "(Training) Loss: 1163585.5044\n",
      "(Validation) Loss: 1217788.0279, MAE: 4552.7119, R2: -0.0256\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [917/5000] | Time: 0.32s\n",
      "(Training) Loss: 1168407.7037\n",
      "(Validation) Loss: 1217554.3670, MAE: 4553.0654, R2: -0.0254\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [918/5000] | Time: 0.22s\n",
      "(Training) Loss: 1186528.6440\n",
      "(Validation) Loss: 1217311.2229, MAE: 4549.7754, R2: -0.0252\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [919/5000] | Time: 0.22s\n",
      "(Training) Loss: 1185483.1478\n",
      "(Validation) Loss: 1217081.8387, MAE: 4551.7197, R2: -0.0250\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [920/5000] | Time: 0.25s\n",
      "(Training) Loss: 1203022.2297\n",
      "(Validation) Loss: 1216838.0140, MAE: 4548.2646, R2: -0.0248\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [921/5000] | Time: 0.21s\n",
      "(Training) Loss: 1173833.4372\n",
      "(Validation) Loss: 1216598.0394, MAE: 4547.4937, R2: -0.0246\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [922/5000] | Time: 0.23s\n",
      "(Training) Loss: 1180937.2735\n",
      "(Validation) Loss: 1216363.7740, MAE: 4546.2773, R2: -0.0244\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [923/5000] | Time: 0.23s\n",
      "(Training) Loss: 1167422.4435\n",
      "(Validation) Loss: 1216124.6425, MAE: 4544.5396, R2: -0.0242\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [924/5000] | Time: 0.19s\n",
      "(Training) Loss: 1168112.0425\n",
      "(Validation) Loss: 1215892.7340, MAE: 4544.0913, R2: -0.0240\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [925/5000] | Time: 0.18s\n",
      "(Training) Loss: 1158871.9757\n",
      "(Validation) Loss: 1215656.8483, MAE: 4544.6357, R2: -0.0238\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [926/5000] | Time: 0.22s\n",
      "(Training) Loss: 1166929.1650\n",
      "(Validation) Loss: 1215424.9803, MAE: 4542.8643, R2: -0.0236\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [927/5000] | Time: 0.31s\n",
      "(Training) Loss: 1159222.6580\n",
      "(Validation) Loss: 1215188.6273, MAE: 4541.8599, R2: -0.0234\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [928/5000] | Time: 0.22s\n",
      "(Training) Loss: 1166989.0799\n",
      "(Validation) Loss: 1214966.6692, MAE: 4547.6313, R2: -0.0233\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [929/5000] | Time: 0.26s\n",
      "(Training) Loss: 1175213.5406\n",
      "(Validation) Loss: 1214721.7829, MAE: 4541.1182, R2: -0.0230\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [930/5000] | Time: 0.24s\n",
      "(Training) Loss: 1159418.6060\n",
      "(Validation) Loss: 1214489.5238, MAE: 4542.3237, R2: -0.0229\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [931/5000] | Time: 0.20s\n",
      "(Training) Loss: 1163969.9930\n",
      "(Validation) Loss: 1214248.8635, MAE: 4538.8662, R2: -0.0227\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [932/5000] | Time: 0.20s\n",
      "(Training) Loss: 1179878.6294\n",
      "(Validation) Loss: 1214014.4965, MAE: 4538.4854, R2: -0.0225\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [933/5000] | Time: 0.24s\n",
      "(Training) Loss: 1163589.7373\n",
      "(Validation) Loss: 1213777.9251, MAE: 4537.2583, R2: -0.0223\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [934/5000] | Time: 0.20s\n",
      "(Training) Loss: 1168620.8109\n",
      "(Validation) Loss: 1213546.1994, MAE: 4537.2935, R2: -0.0221\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [935/5000] | Time: 0.25s\n",
      "(Training) Loss: 1176019.5438\n",
      "(Validation) Loss: 1213313.9759, MAE: 4536.7979, R2: -0.0219\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [936/5000] | Time: 0.30s\n",
      "(Training) Loss: 1196437.9480\n",
      "(Validation) Loss: 1213075.1848, MAE: 4535.2939, R2: -0.0217\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [937/5000] | Time: 0.26s\n",
      "(Training) Loss: 1163680.2284\n",
      "(Validation) Loss: 1212845.4705, MAE: 4538.1162, R2: -0.0215\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [938/5000] | Time: 0.28s\n",
      "(Training) Loss: 1175342.0317\n",
      "(Validation) Loss: 1212601.3511, MAE: 4533.9741, R2: -0.0213\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [939/5000] | Time: 0.22s\n",
      "(Training) Loss: 1171646.1155\n",
      "(Validation) Loss: 1212360.4724, MAE: 4532.2554, R2: -0.0211\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [940/5000] | Time: 0.18s\n",
      "(Training) Loss: 1174634.6028\n",
      "(Validation) Loss: 1212128.3048, MAE: 4532.3984, R2: -0.0209\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [941/5000] | Time: 0.19s\n",
      "(Training) Loss: 1183568.5685\n",
      "(Validation) Loss: 1211893.8159, MAE: 4531.9282, R2: -0.0207\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [942/5000] | Time: 0.20s\n",
      "(Training) Loss: 1175493.6053\n",
      "(Validation) Loss: 1211652.9270, MAE: 4528.7539, R2: -0.0205\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [943/5000] | Time: 0.31s\n",
      "(Training) Loss: 1174830.1472\n",
      "(Validation) Loss: 1211416.6146, MAE: 4528.2935, R2: -0.0203\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [944/5000] | Time: 0.24s\n",
      "(Training) Loss: 1169569.5990\n",
      "(Validation) Loss: 1211180.2260, MAE: 4527.4829, R2: -0.0201\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [945/5000] | Time: 0.21s\n",
      "(Training) Loss: 1175433.1567\n",
      "(Validation) Loss: 1210948.2768, MAE: 4529.0796, R2: -0.0199\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [946/5000] | Time: 0.20s\n",
      "(Training) Loss: 1178058.4581\n",
      "(Validation) Loss: 1210733.3689, MAE: 4535.9316, R2: -0.0197\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [947/5000] | Time: 0.22s\n",
      "(Training) Loss: 1177691.7906\n",
      "(Validation) Loss: 1210475.0425, MAE: 4527.0728, R2: -0.0195\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [948/5000] | Time: 0.21s\n",
      "(Training) Loss: 1166872.0901\n",
      "(Validation) Loss: 1210242.0622, MAE: 4525.8623, R2: -0.0193\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [949/5000] | Time: 0.21s\n",
      "(Training) Loss: 1163547.2481\n",
      "(Validation) Loss: 1210010.2044, MAE: 4526.4155, R2: -0.0191\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [950/5000] | Time: 0.23s\n",
      "(Training) Loss: 1190835.1878\n",
      "(Validation) Loss: 1209784.7416, MAE: 4528.3403, R2: -0.0189\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [951/5000] | Time: 0.22s\n",
      "(Training) Loss: 1155682.5673\n",
      "(Validation) Loss: 1209528.9651, MAE: 4523.1274, R2: -0.0187\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [952/5000] | Time: 0.22s\n",
      "(Training) Loss: 1167363.9023\n",
      "(Validation) Loss: 1209296.2083, MAE: 4521.3008, R2: -0.0185\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [953/5000] | Time: 0.21s\n",
      "(Training) Loss: 1179545.8947\n",
      "(Validation) Loss: 1209058.1333, MAE: 4519.2012, R2: -0.0183\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [954/5000] | Time: 0.21s\n",
      "(Training) Loss: 1167565.6015\n",
      "(Validation) Loss: 1208824.5740, MAE: 4518.3784, R2: -0.0181\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [955/5000] | Time: 0.24s\n",
      "(Training) Loss: 1159531.7976\n",
      "(Validation) Loss: 1208591.4768, MAE: 4519.2202, R2: -0.0179\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [956/5000] | Time: 0.21s\n",
      "(Training) Loss: 1169483.7893\n",
      "(Validation) Loss: 1208360.9752, MAE: 4519.6006, R2: -0.0177\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [957/5000] | Time: 0.26s\n",
      "(Training) Loss: 1161348.0844\n",
      "(Validation) Loss: 1208127.1517, MAE: 4519.0566, R2: -0.0176\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [958/5000] | Time: 0.21s\n",
      "(Training) Loss: 1173074.1434\n",
      "(Validation) Loss: 1207893.5568, MAE: 4516.3525, R2: -0.0174\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [959/5000] | Time: 0.20s\n",
      "(Training) Loss: 1159875.1827\n",
      "(Validation) Loss: 1207681.9962, MAE: 4518.3643, R2: -0.0172\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [960/5000] | Time: 0.18s\n",
      "(Training) Loss: 1168113.0076\n",
      "(Validation) Loss: 1207419.5759, MAE: 4515.4624, R2: -0.0170\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [961/5000] | Time: 0.18s\n",
      "(Training) Loss: 1170603.3096\n",
      "(Validation) Loss: 1207185.1022, MAE: 4513.2798, R2: -0.0168\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [962/5000] | Time: 0.19s\n",
      "(Training) Loss: 1171016.1986\n",
      "(Validation) Loss: 1206947.4286, MAE: 4511.8770, R2: -0.0166\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [963/5000] | Time: 0.20s\n",
      "(Training) Loss: 1180656.6269\n",
      "(Validation) Loss: 1206791.1416, MAE: 4517.5278, R2: -0.0164\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [964/5000] | Time: 0.20s\n",
      "(Training) Loss: 1169232.4036\n",
      "(Validation) Loss: 1206481.8032, MAE: 4512.4790, R2: -0.0162\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [965/5000] | Time: 0.23s\n",
      "(Training) Loss: 1170789.9442\n",
      "(Validation) Loss: 1206247.4362, MAE: 4511.8247, R2: -0.0160\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [966/5000] | Time: 0.33s\n",
      "(Training) Loss: 1162186.8528\n",
      "(Validation) Loss: 1206015.6698, MAE: 4510.5186, R2: -0.0158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [967/5000] | Time: 0.23s\n",
      "(Training) Loss: 1156580.0888\n",
      "(Validation) Loss: 1205772.4190, MAE: 4507.5640, R2: -0.0156\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [968/5000] | Time: 0.24s\n",
      "(Training) Loss: 1160752.1732\n",
      "(Validation) Loss: 1205539.5759, MAE: 4507.4692, R2: -0.0154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [969/5000] | Time: 0.21s\n",
      "(Training) Loss: 1175602.9365\n",
      "(Validation) Loss: 1205316.3276, MAE: 4508.4771, R2: -0.0152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [970/5000] | Time: 0.19s\n",
      "(Training) Loss: 1166598.1923\n",
      "(Validation) Loss: 1205077.0895, MAE: 4507.4019, R2: -0.0150\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [971/5000] | Time: 0.18s\n",
      "(Training) Loss: 1164960.6834\n",
      "(Validation) Loss: 1204843.7740, MAE: 4507.0449, R2: -0.0148\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [972/5000] | Time: 0.19s\n",
      "(Training) Loss: 1166622.2602\n",
      "(Validation) Loss: 1204603.8552, MAE: 4503.7837, R2: -0.0146\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [973/5000] | Time: 0.20s\n",
      "(Training) Loss: 1168092.2849\n",
      "(Validation) Loss: 1204375.5022, MAE: 4505.0991, R2: -0.0144\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [974/5000] | Time: 0.20s\n",
      "(Training) Loss: 1169361.1701\n",
      "(Validation) Loss: 1204135.4260, MAE: 4504.3022, R2: -0.0142\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [975/5000] | Time: 0.21s\n",
      "(Training) Loss: 1166642.7786\n",
      "(Validation) Loss: 1203920.4521, MAE: 4503.9341, R2: -0.0141\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [976/5000] | Time: 0.19s\n",
      "(Training) Loss: 1155558.3610\n",
      "(Validation) Loss: 1203663.7765, MAE: 4500.7036, R2: -0.0138\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [977/5000] | Time: 0.19s\n",
      "(Training) Loss: 1159622.1701\n",
      "(Validation) Loss: 1203434.3060, MAE: 4499.8560, R2: -0.0136\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [978/5000] | Time: 0.34s\n",
      "(Training) Loss: 1146089.5356\n",
      "(Validation) Loss: 1203200.5587, MAE: 4498.5850, R2: -0.0135\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [979/5000] | Time: 0.28s\n",
      "(Training) Loss: 1150625.3813\n",
      "(Validation) Loss: 1202970.3365, MAE: 4498.2656, R2: -0.0133\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [980/5000] | Time: 0.23s\n",
      "(Training) Loss: 1160912.8566\n",
      "(Validation) Loss: 1202747.2660, MAE: 4498.4805, R2: -0.0131\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [981/5000] | Time: 0.25s\n",
      "(Training) Loss: 1168654.5241\n",
      "(Validation) Loss: 1202517.3841, MAE: 4501.1318, R2: -0.0129\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [982/5000] | Time: 0.30s\n",
      "(Training) Loss: 1159877.9721\n",
      "(Validation) Loss: 1202275.4997, MAE: 4498.2114, R2: -0.0127\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [983/5000] | Time: 0.26s\n",
      "(Training) Loss: 1173845.0914\n",
      "(Validation) Loss: 1202036.4749, MAE: 4494.1831, R2: -0.0125\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [984/5000] | Time: 0.24s\n",
      "(Training) Loss: 1159325.7957\n",
      "(Validation) Loss: 1201823.2381, MAE: 4495.3813, R2: -0.0123\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [985/5000] | Time: 0.25s\n",
      "(Training) Loss: 1176642.3414\n",
      "(Validation) Loss: 1201570.2857, MAE: 4494.5586, R2: -0.0121\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [986/5000] | Time: 0.45s\n",
      "(Training) Loss: 1145264.2443\n",
      "(Validation) Loss: 1201335.0806, MAE: 4492.8608, R2: -0.0119\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [987/5000] | Time: 0.44s\n",
      "(Training) Loss: 1171398.4562\n",
      "(Validation) Loss: 1201110.0597, MAE: 4493.1797, R2: -0.0117\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [988/5000] | Time: 0.87s\n",
      "(Training) Loss: 1153087.5742\n",
      "(Validation) Loss: 1200869.3892, MAE: 4492.3394, R2: -0.0115\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [989/5000] | Time: 1.12s\n",
      "(Training) Loss: 1175492.2957\n",
      "(Validation) Loss: 1200637.7295, MAE: 4490.4570, R2: -0.0113\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [990/5000] | Time: 0.95s\n",
      "(Training) Loss: 1157271.9803\n",
      "(Validation) Loss: 1200406.6692, MAE: 4491.8379, R2: -0.0111\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [991/5000] | Time: 0.91s\n",
      "(Training) Loss: 1156774.6516\n",
      "(Validation) Loss: 1200168.0254, MAE: 4488.2363, R2: -0.0109\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [992/5000] | Time: 0.63s\n",
      "(Training) Loss: 1175886.1345\n",
      "(Validation) Loss: 1200009.7727, MAE: 4490.7041, R2: -0.0108\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [993/5000] | Time: 0.70s\n",
      "(Training) Loss: 1161261.7297\n",
      "(Validation) Loss: 1199704.5232, MAE: 4487.5435, R2: -0.0105\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [994/5000] | Time: 0.33s\n",
      "(Training) Loss: 1160963.5197\n",
      "(Validation) Loss: 1199464.8889, MAE: 4485.5874, R2: -0.0103\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [995/5000] | Time: 0.32s\n",
      "(Training) Loss: 1156477.8071\n",
      "(Validation) Loss: 1199229.4857, MAE: 4484.1846, R2: -0.0101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [996/5000] | Time: 0.33s\n",
      "(Training) Loss: 1155565.2608\n",
      "(Validation) Loss: 1198995.9924, MAE: 4482.6968, R2: -0.0099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [997/5000] | Time: 0.36s\n",
      "(Training) Loss: 1179353.3864\n",
      "(Validation) Loss: 1198768.4317, MAE: 4483.5093, R2: -0.0098\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [998/5000] | Time: 0.30s\n",
      "(Training) Loss: 1161402.7354\n",
      "(Validation) Loss: 1198527.8781, MAE: 4481.7817, R2: -0.0096\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [999/5000] | Time: 0.65s\n",
      "(Training) Loss: 1183022.1973\n",
      "(Validation) Loss: 1198298.7835, MAE: 4481.1519, R2: -0.0094\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1000/5000] | Time: 0.92s\n",
      "(Training) Loss: 1150830.3579\n",
      "(Validation) Loss: 1198060.6730, MAE: 4481.4712, R2: -0.0092\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch1000.pth\n",
      "==========================================================================================\n",
      "Epoch [1001/5000] | Time: 0.79s\n",
      "(Training) Loss: 1164630.0203\n",
      "(Validation) Loss: 1197835.3575, MAE: 4480.6479, R2: -0.0090\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1002/5000] | Time: 0.46s\n",
      "(Training) Loss: 1160751.9404\n",
      "(Validation) Loss: 1197645.7041, MAE: 4488.6714, R2: -0.0088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1003/5000] | Time: 0.37s\n",
      "(Training) Loss: 1149308.9365\n",
      "(Validation) Loss: 1197363.0375, MAE: 4478.0967, R2: -0.0086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1004/5000] | Time: 0.38s\n",
      "(Training) Loss: 1149539.1383\n",
      "(Validation) Loss: 1197134.3187, MAE: 4477.4673, R2: -0.0084\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1005/5000] | Time: 0.48s\n",
      "(Training) Loss: 1140461.9725\n",
      "(Validation) Loss: 1196907.2457, MAE: 4477.4595, R2: -0.0082\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1006/5000] | Time: 0.32s\n",
      "(Training) Loss: 1168103.5146\n",
      "(Validation) Loss: 1200363.4438, MAE: 4490.9111, R2: -0.0111\n",
      "==========================================================================================\n",
      "Epoch [1007/5000] | Time: 0.49s\n",
      "(Training) Loss: 1153238.5241\n",
      "(Validation) Loss: 1200136.1270, MAE: 4489.2637, R2: -0.0109\n",
      "==========================================================================================\n",
      "Epoch [1008/5000] | Time: 0.97s\n",
      "(Training) Loss: 1154387.0355\n",
      "(Validation) Loss: 1199898.5295, MAE: 4487.5811, R2: -0.0107\n",
      "==========================================================================================\n",
      "Epoch [1009/5000] | Time: 0.35s\n",
      "(Training) Loss: 1157271.4213\n",
      "(Validation) Loss: 1199672.7111, MAE: 4489.5557, R2: -0.0105\n",
      "==========================================================================================\n",
      "Epoch [1010/5000] | Time: 1.03s\n",
      "(Training) Loss: 1184354.4734\n",
      "(Validation) Loss: 1199435.4133, MAE: 4484.3711, R2: -0.0103\n",
      "==========================================================================================\n",
      "Epoch [1011/5000] | Time: 0.93s\n",
      "(Training) Loss: 1142836.5600\n",
      "(Validation) Loss: 1199219.3981, MAE: 4489.8389, R2: -0.0101\n",
      "==========================================================================================\n",
      "Epoch [1012/5000] | Time: 0.56s\n",
      "(Training) Loss: 1151714.8046\n",
      "(Validation) Loss: 1198993.8997, MAE: 4490.0400, R2: -0.0099\n",
      "==========================================================================================\n",
      "Epoch [1013/5000] | Time: 0.89s\n",
      "(Training) Loss: 1161213.7728\n",
      "(Validation) Loss: 1199096.7467, MAE: 4486.5361, R2: -0.0101\n",
      "==========================================================================================\n",
      "Epoch [1014/5000] | Time: 0.27s\n",
      "(Training) Loss: 1164453.7348\n",
      "(Validation) Loss: 1198520.9702, MAE: 4482.5522, R2: -0.0096\n",
      "==========================================================================================\n",
      "Epoch [1015/5000] | Time: 0.27s\n",
      "(Training) Loss: 1141696.3107\n",
      "(Validation) Loss: 1198287.7968, MAE: 4480.1328, R2: -0.0094\n",
      "==========================================================================================\n",
      "Epoch [1016/5000] | Time: 0.24s\n",
      "(Training) Loss: 1149276.6307\n",
      "(Validation) Loss: 1198069.1352, MAE: 4482.4150, R2: -0.0092\n",
      "==========================================================================================\n",
      "Epoch [1017/5000] | Time: 0.23s\n",
      "(Training) Loss: 1146237.4575\n",
      "(Validation) Loss: 1197835.8451, MAE: 4480.7471, R2: -0.0090\n",
      "==========================================================================================\n",
      "Epoch [1018/5000] | Time: 0.24s\n",
      "(Training) Loss: 1148070.7418\n",
      "(Validation) Loss: 1197621.7854, MAE: 4480.3291, R2: -0.0088\n",
      "==========================================================================================\n",
      "Epoch [1019/5000] | Time: 0.25s\n",
      "(Training) Loss: 1147647.6091\n",
      "(Validation) Loss: 1197390.6590, MAE: 4478.5259, R2: -0.0086\n",
      "==========================================================================================\n",
      "Epoch [1020/5000] | Time: 0.21s\n",
      "(Training) Loss: 1146887.4429\n",
      "(Validation) Loss: 1197150.1054, MAE: 4476.3979, R2: -0.0084\n",
      "==========================================================================================\n",
      "Epoch [1021/5000] | Time: 0.24s\n",
      "(Training) Loss: 1159796.8306\n",
      "(Validation) Loss: 1196921.6457, MAE: 4476.6221, R2: -0.0082\n",
      "==========================================================================================\n",
      "Epoch [1022/5000] | Time: 0.24s\n",
      "(Training) Loss: 1141486.2484\n",
      "(Validation) Loss: 1196692.2006, MAE: 4478.0483, R2: -0.0080\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1023/5000] | Time: 0.20s\n",
      "(Training) Loss: 1164029.6409\n",
      "(Validation) Loss: 1196473.4019, MAE: 4479.2881, R2: -0.0078\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1024/5000] | Time: 0.22s\n",
      "(Training) Loss: 1140323.5462\n",
      "(Validation) Loss: 1196236.6832, MAE: 4476.2476, R2: -0.0077\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1025/5000] | Time: 0.22s\n",
      "(Training) Loss: 1153858.2525\n",
      "(Validation) Loss: 1196013.2724, MAE: 4474.0264, R2: -0.0075\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1026/5000] | Time: 0.24s\n",
      "(Training) Loss: 1158324.3867\n",
      "(Validation) Loss: 1195783.1619, MAE: 4474.7100, R2: -0.0073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1027/5000] | Time: 0.26s\n",
      "(Training) Loss: 1163913.4156\n",
      "(Validation) Loss: 1195546.5752, MAE: 4471.9976, R2: -0.0071\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1028/5000] | Time: 0.30s\n",
      "(Training) Loss: 1160505.9334\n",
      "(Validation) Loss: 1195319.1568, MAE: 4472.1494, R2: -0.0069\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1029/5000] | Time: 0.24s\n",
      "(Training) Loss: 1151294.1720\n",
      "(Validation) Loss: 1195084.0279, MAE: 4469.2915, R2: -0.0067\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1030/5000] | Time: 0.21s\n",
      "(Training) Loss: 1145224.9898\n",
      "(Validation) Loss: 1194859.0527, MAE: 4470.5132, R2: -0.0065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1031/5000] | Time: 0.23s\n",
      "(Training) Loss: 1146350.3052\n",
      "(Validation) Loss: 1194638.3492, MAE: 4471.4170, R2: -0.0063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1032/5000] | Time: 0.20s\n",
      "(Training) Loss: 1148775.5882\n",
      "(Validation) Loss: 1194401.8387, MAE: 4466.9316, R2: -0.0061\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1033/5000] | Time: 0.25s\n",
      "(Training) Loss: 1166037.1510\n",
      "(Validation) Loss: 1194190.7657, MAE: 4470.8931, R2: -0.0059\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1034/5000] | Time: 0.26s\n",
      "(Training) Loss: 1168422.9410\n",
      "(Validation) Loss: 1193941.2114, MAE: 4464.9834, R2: -0.0057\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1035/5000] | Time: 0.24s\n",
      "(Training) Loss: 1150000.3477\n",
      "(Validation) Loss: 1193712.2641, MAE: 4464.4717, R2: -0.0055\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1036/5000] | Time: 0.22s\n",
      "(Training) Loss: 1144742.8921\n",
      "(Validation) Loss: 1193496.4521, MAE: 4466.5259, R2: -0.0054\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1037/5000] | Time: 0.23s\n",
      "(Training) Loss: 1147775.7951\n",
      "(Validation) Loss: 1193315.9060, MAE: 4467.4487, R2: -0.0052\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1038/5000] | Time: 0.23s\n",
      "(Training) Loss: 1160413.5324\n",
      "(Validation) Loss: 1193035.1492, MAE: 4463.2734, R2: -0.0050\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1039/5000] | Time: 0.23s\n",
      "(Training) Loss: 1157094.3274\n",
      "(Validation) Loss: 1192803.2559, MAE: 4462.5605, R2: -0.0048\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1040/5000] | Time: 0.23s\n",
      "(Training) Loss: 1158835.0292\n",
      "(Validation) Loss: 1192588.7594, MAE: 4464.3271, R2: -0.0046\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1041/5000] | Time: 0.21s\n",
      "(Training) Loss: 1141263.9721\n",
      "(Validation) Loss: 1192347.9721, MAE: 4460.9326, R2: -0.0044\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1042/5000] | Time: 0.22s\n",
      "(Training) Loss: 1153408.4162\n",
      "(Validation) Loss: 1192135.1873, MAE: 4460.0649, R2: -0.0042\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1043/5000] | Time: 0.19s\n",
      "(Training) Loss: 1153797.3471\n",
      "(Validation) Loss: 1191892.6984, MAE: 4459.6128, R2: -0.0040\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1044/5000] | Time: 0.25s\n",
      "(Training) Loss: 1145589.8268\n",
      "(Validation) Loss: 1191657.9251, MAE: 4458.1323, R2: -0.0038\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1045/5000] | Time: 0.30s\n",
      "(Training) Loss: 1164623.5336\n",
      "(Validation) Loss: 1191447.2584, MAE: 4462.4858, R2: -0.0037\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1046/5000] | Time: 0.26s\n",
      "(Training) Loss: 1157270.4645\n",
      "(Validation) Loss: 1191202.4229, MAE: 4456.8428, R2: -0.0035\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1047/5000] | Time: 0.30s\n",
      "(Training) Loss: 1154150.4505\n",
      "(Validation) Loss: 1190979.6165, MAE: 4456.2041, R2: -0.0033\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1048/5000] | Time: 0.25s\n",
      "(Training) Loss: 1144275.4607\n",
      "(Validation) Loss: 1190741.2317, MAE: 4453.1440, R2: -0.0031\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1049/5000] | Time: 0.26s\n",
      "(Training) Loss: 1155189.6713\n",
      "(Validation) Loss: 1190514.6514, MAE: 4453.0498, R2: -0.0029\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1050/5000] | Time: 0.29s\n",
      "(Training) Loss: 1164301.0235\n",
      "(Validation) Loss: 1190307.2457, MAE: 4455.2886, R2: -0.0027\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1051/5000] | Time: 0.35s\n",
      "(Training) Loss: 1136561.7199\n",
      "(Validation) Loss: 1190074.2197, MAE: 4458.0195, R2: -0.0025\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1052/5000] | Time: 0.37s\n",
      "(Training) Loss: 1148137.0866\n",
      "(Validation) Loss: 1189831.8019, MAE: 4450.8164, R2: -0.0023\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1053/5000] | Time: 0.41s\n",
      "(Training) Loss: 1149459.9188\n",
      "(Validation) Loss: 1189607.2279, MAE: 4451.6821, R2: -0.0021\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1054/5000] | Time: 0.50s\n",
      "(Training) Loss: 1168413.7081\n",
      "(Validation) Loss: 1189384.0152, MAE: 4450.2173, R2: -0.0019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1055/5000] | Time: 0.49s\n",
      "(Training) Loss: 1148253.0901\n",
      "(Validation) Loss: 1189151.7410, MAE: 4449.3071, R2: -0.0017\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1056/5000] | Time: 0.53s\n",
      "(Training) Loss: 1149251.9867\n",
      "(Validation) Loss: 1188925.9683, MAE: 4449.4956, R2: -0.0016\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1057/5000] | Time: 0.48s\n",
      "(Training) Loss: 1153550.4632\n",
      "(Validation) Loss: 1188690.6057, MAE: 4446.9810, R2: -0.0014\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1058/5000] | Time: 0.33s\n",
      "(Training) Loss: 1154271.3880\n",
      "(Validation) Loss: 1188461.2978, MAE: 4445.0938, R2: -0.0012\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1059/5000] | Time: 0.28s\n",
      "(Training) Loss: 1160586.3731\n",
      "(Validation) Loss: 1188236.7289, MAE: 4445.0972, R2: -0.0010\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1060/5000] | Time: 0.30s\n",
      "(Training) Loss: 1172259.4055\n",
      "(Validation) Loss: 1188006.3086, MAE: 4443.6206, R2: -0.0008\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1061/5000] | Time: 0.38s\n",
      "(Training) Loss: 1164397.7449\n",
      "(Validation) Loss: 1187777.5340, MAE: 4443.3403, R2: -0.0006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1062/5000] | Time: 0.33s\n",
      "(Training) Loss: 1136599.6808\n",
      "(Validation) Loss: 1187547.2203, MAE: 4442.8359, R2: -0.0004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1063/5000] | Time: 0.31s\n",
      "(Training) Loss: 1144257.5133\n",
      "(Validation) Loss: 1187346.6514, MAE: 4444.0073, R2: -0.0002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1064/5000] | Time: 0.27s\n",
      "(Training) Loss: 1141325.4569\n",
      "(Validation) Loss: 1194820.9829, MAE: 4470.2769, R2: -0.0065\n",
      "==========================================================================================\n",
      "Epoch [1065/5000] | Time: 0.32s\n",
      "(Training) Loss: 1158512.4784\n",
      "(Validation) Loss: 1194604.6070, MAE: 4472.4873, R2: -0.0063\n",
      "==========================================================================================\n",
      "Epoch [1066/5000] | Time: 0.30s\n",
      "(Training) Loss: 1153420.7240\n",
      "(Validation) Loss: 1194361.4883, MAE: 4466.8730, R2: -0.0061\n",
      "==========================================================================================\n",
      "Epoch [1067/5000] | Time: 0.31s\n",
      "(Training) Loss: 1138664.7510\n",
      "(Validation) Loss: 1194132.5968, MAE: 4466.6035, R2: -0.0059\n",
      "==========================================================================================\n",
      "Epoch [1068/5000] | Time: 0.32s\n",
      "(Training) Loss: 1162802.6104\n",
      "(Validation) Loss: 1193911.0095, MAE: 4467.3467, R2: -0.0057\n",
      "==========================================================================================\n",
      "Epoch [1069/5000] | Time: 0.36s\n",
      "(Training) Loss: 1149046.3033\n",
      "(Validation) Loss: 1193683.0984, MAE: 4466.6895, R2: -0.0055\n",
      "==========================================================================================\n",
      "Epoch [1070/5000] | Time: 0.29s\n",
      "(Training) Loss: 1147966.3750\n",
      "(Validation) Loss: 1193447.1162, MAE: 4464.5381, R2: -0.0053\n",
      "==========================================================================================\n",
      "Epoch [1071/5000] | Time: 0.28s\n",
      "(Training) Loss: 1164111.0406\n",
      "(Validation) Loss: 1193215.4463, MAE: 4462.9575, R2: -0.0051\n",
      "==========================================================================================\n",
      "Epoch [1072/5000] | Time: 0.33s\n",
      "(Training) Loss: 1138467.1872\n",
      "(Validation) Loss: 1192990.7149, MAE: 4463.0000, R2: -0.0049\n",
      "==========================================================================================\n",
      "Epoch [1073/5000] | Time: 0.34s\n",
      "(Training) Loss: 1147975.2646\n",
      "(Validation) Loss: 1192766.0800, MAE: 4462.2803, R2: -0.0048\n",
      "==========================================================================================\n",
      "Epoch [1074/5000] | Time: 0.40s\n",
      "(Training) Loss: 1149029.9708\n",
      "(Validation) Loss: 1192536.8787, MAE: 4462.8345, R2: -0.0046\n",
      "==========================================================================================\n",
      "Epoch [1075/5000] | Time: 0.45s\n",
      "(Training) Loss: 1162293.1789\n",
      "(Validation) Loss: 1192305.9200, MAE: 4460.4233, R2: -0.0044\n",
      "==========================================================================================\n",
      "Epoch [1076/5000] | Time: 0.32s\n",
      "(Training) Loss: 1174142.7030\n",
      "(Validation) Loss: 1192075.6368, MAE: 4460.1826, R2: -0.0042\n",
      "==========================================================================================\n",
      "Epoch [1077/5000] | Time: 0.30s\n",
      "(Training) Loss: 1145312.7684\n",
      "(Validation) Loss: 1191847.1771, MAE: 4459.7627, R2: -0.0040\n",
      "==========================================================================================\n",
      "Epoch [1078/5000] | Time: 0.32s\n",
      "(Training) Loss: 1138771.9692\n",
      "(Validation) Loss: 1191613.8667, MAE: 4457.1318, R2: -0.0038\n",
      "==========================================================================================\n",
      "Epoch [1079/5000] | Time: 0.31s\n",
      "(Training) Loss: 1156206.1485\n",
      "(Validation) Loss: 1191384.7416, MAE: 4456.9912, R2: -0.0036\n",
      "==========================================================================================\n",
      "Epoch [1080/5000] | Time: 0.29s\n",
      "(Training) Loss: 1160548.2189\n",
      "(Validation) Loss: 1191174.4914, MAE: 4458.7188, R2: -0.0034\n",
      "==========================================================================================\n",
      "Epoch [1081/5000] | Time: 0.27s\n",
      "(Training) Loss: 1162770.6440\n",
      "(Validation) Loss: 1190934.7759, MAE: 4456.6182, R2: -0.0032\n",
      "==========================================================================================\n",
      "Epoch [1082/5000] | Time: 0.29s\n",
      "(Training) Loss: 1148012.9340\n",
      "(Validation) Loss: 1190696.9092, MAE: 4453.6914, R2: -0.0030\n",
      "==========================================================================================\n",
      "Epoch [1083/5000] | Time: 0.31s\n",
      "(Training) Loss: 1142893.2157\n",
      "(Validation) Loss: 1190476.9473, MAE: 4455.5356, R2: -0.0029\n",
      "==========================================================================================\n",
      "Epoch [1084/5000] | Time: 0.29s\n",
      "(Training) Loss: 1157221.6364\n",
      "(Validation) Loss: 1190246.8368, MAE: 4453.8652, R2: -0.0027\n",
      "==========================================================================================\n",
      "Epoch [1085/5000] | Time: 0.29s\n",
      "(Training) Loss: 1141979.8014\n",
      "(Validation) Loss: 1190014.9638, MAE: 4451.4946, R2: -0.0025\n",
      "==========================================================================================\n",
      "Epoch [1086/5000] | Time: 0.28s\n",
      "(Training) Loss: 1144483.3820\n",
      "(Validation) Loss: 1189805.9733, MAE: 4455.9141, R2: -0.0023\n",
      "==========================================================================================\n",
      "Epoch [1087/5000] | Time: 0.29s\n",
      "(Training) Loss: 1135708.4029\n",
      "(Validation) Loss: 1189576.1270, MAE: 4450.9604, R2: -0.0021\n",
      "==========================================================================================\n",
      "Epoch [1088/5000] | Time: 0.27s\n",
      "(Training) Loss: 1149146.6003\n",
      "(Validation) Loss: 1189335.3346, MAE: 4449.7607, R2: -0.0019\n",
      "==========================================================================================\n",
      "Epoch [1089/5000] | Time: 0.28s\n",
      "(Training) Loss: 1162999.3598\n",
      "(Validation) Loss: 1189109.2775, MAE: 4450.6631, R2: -0.0017\n",
      "==========================================================================================\n",
      "Epoch [1090/5000] | Time: 0.28s\n",
      "(Training) Loss: 1161559.5292\n",
      "(Validation) Loss: 1188876.7390, MAE: 4447.6929, R2: -0.0015\n",
      "==========================================================================================\n",
      "Epoch [1091/5000] | Time: 0.24s\n",
      "(Training) Loss: 1143043.4175\n",
      "(Validation) Loss: 1188679.8425, MAE: 4451.8682, R2: -0.0014\n",
      "==========================================================================================\n",
      "Epoch [1092/5000] | Time: 0.24s\n",
      "(Training) Loss: 1153144.2386\n",
      "(Validation) Loss: 1188432.8635, MAE: 4450.2280, R2: -0.0011\n",
      "==========================================================================================\n",
      "Epoch [1093/5000] | Time: 0.23s\n",
      "(Training) Loss: 1159291.1586\n",
      "(Validation) Loss: 1188208.1575, MAE: 4451.2153, R2: -0.0010\n",
      "==========================================================================================\n",
      "Epoch [1094/5000] | Time: 0.30s\n",
      "(Training) Loss: 1159834.6282\n",
      "(Validation) Loss: 1187973.1403, MAE: 4448.2656, R2: -0.0008\n",
      "==========================================================================================\n",
      "Epoch [1095/5000] | Time: 0.28s\n",
      "(Training) Loss: 1160114.2576\n",
      "(Validation) Loss: 1187760.0254, MAE: 4448.9434, R2: -0.0006\n",
      "==========================================================================================\n",
      "Epoch [1096/5000] | Time: 0.23s\n",
      "(Training) Loss: 1163554.6942\n",
      "(Validation) Loss: 1187511.7613, MAE: 4444.3950, R2: -0.0004\n",
      "==========================================================================================\n",
      "Epoch [1097/5000] | Time: 0.22s\n",
      "(Training) Loss: 1146339.9086\n",
      "(Validation) Loss: 1187282.0267, MAE: 4444.0664, R2: -0.0002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1098/5000] | Time: 0.27s\n",
      "(Training) Loss: 1172155.0317\n",
      "(Validation) Loss: 1187054.0851, MAE: 4442.7344, R2: -0.0000\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1099/5000] | Time: 0.27s\n",
      "(Training) Loss: 1130758.3988\n",
      "(Validation) Loss: 1186831.1619, MAE: 4442.3428, R2: 0.0002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1100/5000] | Time: 0.24s\n",
      "(Training) Loss: 1142737.3959\n",
      "(Validation) Loss: 1186598.3492, MAE: 4440.1885, R2: 0.0004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1101/5000] | Time: 0.26s\n",
      "(Training) Loss: 1160560.2525\n",
      "(Validation) Loss: 1186371.7587, MAE: 4438.4517, R2: 0.0006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1102/5000] | Time: 0.27s\n",
      "(Training) Loss: 1142838.1294\n",
      "(Validation) Loss: 1186151.1873, MAE: 4442.8301, R2: 0.0008\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1103/5000] | Time: 0.24s\n",
      "(Training) Loss: 1148291.9137\n",
      "(Validation) Loss: 1185918.1917, MAE: 4437.0835, R2: 0.0009\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1104/5000] | Time: 0.27s\n",
      "(Training) Loss: 1165723.2855\n",
      "(Validation) Loss: 1185693.1860, MAE: 4437.4038, R2: 0.0011\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1105/5000] | Time: 0.25s\n",
      "(Training) Loss: 1155576.4860\n",
      "(Validation) Loss: 1185464.3962, MAE: 4436.7134, R2: 0.0013\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1106/5000] | Time: 0.23s\n",
      "(Training) Loss: 1144632.8807\n",
      "(Validation) Loss: 1185234.3213, MAE: 4434.2808, R2: 0.0015\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1107/5000] | Time: 0.23s\n",
      "(Training) Loss: 1153981.7589\n",
      "(Validation) Loss: 1185005.5568, MAE: 4432.9907, R2: 0.0017\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1108/5000] | Time: 0.26s\n",
      "(Training) Loss: 1144325.6225\n",
      "(Validation) Loss: 1184784.8533, MAE: 4433.0522, R2: 0.0019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1109/5000] | Time: 0.24s\n",
      "(Training) Loss: 1147998.3541\n",
      "(Validation) Loss: 1184558.7454, MAE: 4432.6260, R2: 0.0021\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1110/5000] | Time: 0.25s\n",
      "(Training) Loss: 1131866.3039\n",
      "(Validation) Loss: 1184368.1930, MAE: 4439.1270, R2: 0.0022\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1111/5000] | Time: 0.25s\n",
      "(Training) Loss: 1144575.0013\n",
      "(Validation) Loss: 1184110.3644, MAE: 4433.9272, R2: 0.0025\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1112/5000] | Time: 0.28s\n",
      "(Training) Loss: 1158079.0343\n",
      "(Validation) Loss: 1183880.4927, MAE: 4429.9253, R2: 0.0026\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1113/5000] | Time: 0.28s\n",
      "(Training) Loss: 1141789.2970\n",
      "(Validation) Loss: 1183663.1619, MAE: 4433.0093, R2: 0.0028\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1114/5000] | Time: 0.24s\n",
      "(Training) Loss: 1140024.5032\n",
      "(Validation) Loss: 1183425.8590, MAE: 4429.0317, R2: 0.0030\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1115/5000] | Time: 0.26s\n",
      "(Training) Loss: 1164145.8363\n",
      "(Validation) Loss: 1183201.9505, MAE: 4427.9053, R2: 0.0032\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1116/5000] | Time: 0.28s\n",
      "(Training) Loss: 1134539.5501\n",
      "(Validation) Loss: 1182982.3035, MAE: 4430.1909, R2: 0.0034\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1117/5000] | Time: 0.26s\n",
      "(Training) Loss: 1151046.5711\n",
      "(Validation) Loss: 1182743.5429, MAE: 4425.4287, R2: 0.0036\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1118/5000] | Time: 0.27s\n",
      "(Training) Loss: 1145557.9334\n",
      "(Validation) Loss: 1182516.7797, MAE: 4424.5430, R2: 0.0038\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1119/5000] | Time: 0.28s\n",
      "(Training) Loss: 1139295.5987\n",
      "(Validation) Loss: 1182295.0908, MAE: 4425.6230, R2: 0.0040\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1120/5000] | Time: 0.25s\n",
      "(Training) Loss: 1133664.6555\n",
      "(Validation) Loss: 1182064.9854, MAE: 4422.3989, R2: 0.0042\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1121/5000] | Time: 0.24s\n",
      "(Training) Loss: 1154166.0444\n",
      "(Validation) Loss: 1181873.3257, MAE: 4426.4956, R2: 0.0043\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1122/5000] | Time: 0.25s\n",
      "(Training) Loss: 1135238.4924\n",
      "(Validation) Loss: 1181626.8343, MAE: 4424.9756, R2: 0.0045\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1123/5000] | Time: 0.23s\n",
      "(Training) Loss: 1142992.7126\n",
      "(Validation) Loss: 1181396.4648, MAE: 4422.7119, R2: 0.0047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1124/5000] | Time: 0.29s\n",
      "(Training) Loss: 1171772.5317\n",
      "(Validation) Loss: 1181168.9600, MAE: 4420.5898, R2: 0.0049\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1125/5000] | Time: 0.24s\n",
      "(Training) Loss: 1132945.0127\n",
      "(Validation) Loss: 1180936.9092, MAE: 4420.4263, R2: 0.0051\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1126/5000] | Time: 0.25s\n",
      "(Training) Loss: 1134768.2817\n",
      "(Validation) Loss: 1180726.8216, MAE: 4420.9585, R2: 0.0053\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1127/5000] | Time: 0.25s\n",
      "(Training) Loss: 1136879.3039\n",
      "(Validation) Loss: 1180506.8952, MAE: 4422.9473, R2: 0.0055\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1128/5000] | Time: 0.26s\n",
      "(Training) Loss: 1151545.8706\n",
      "(Validation) Loss: 1180264.6756, MAE: 4417.6602, R2: 0.0057\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1129/5000] | Time: 0.26s\n",
      "(Training) Loss: 1142259.9359\n",
      "(Validation) Loss: 1180060.3378, MAE: 4419.4927, R2: 0.0058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1130/5000] | Time: 0.29s\n",
      "(Training) Loss: 1124391.3121\n",
      "(Validation) Loss: 1179809.6914, MAE: 4415.3076, R2: 0.0060\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1131/5000] | Time: 0.25s\n",
      "(Training) Loss: 1161006.4156\n",
      "(Validation) Loss: 1179631.7968, MAE: 4418.3145, R2: 0.0062\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1132/5000] | Time: 0.26s\n",
      "(Training) Loss: 1151603.2805\n",
      "(Validation) Loss: 1179397.6889, MAE: 4425.0903, R2: 0.0064\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1133/5000] | Time: 0.27s\n",
      "(Training) Loss: 1152919.8496\n",
      "(Validation) Loss: 1179141.2267, MAE: 4415.5186, R2: 0.0066\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1134/5000] | Time: 0.24s\n",
      "(Training) Loss: 1135167.8401\n",
      "(Validation) Loss: 1178907.7181, MAE: 4413.3545, R2: 0.0068\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1135/5000] | Time: 0.27s\n",
      "(Training) Loss: 1167011.4651\n",
      "(Validation) Loss: 1178689.2952, MAE: 4412.7310, R2: 0.0070\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1136/5000] | Time: 0.28s\n",
      "(Training) Loss: 1132910.3858\n",
      "(Validation) Loss: 1178449.6356, MAE: 4409.6748, R2: 0.0072\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1137/5000] | Time: 0.28s\n",
      "(Training) Loss: 1143356.9258\n",
      "(Validation) Loss: 1178229.7702, MAE: 4409.8599, R2: 0.0074\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1138/5000] | Time: 0.27s\n",
      "(Training) Loss: 1149678.8978\n",
      "(Validation) Loss: 1178018.2349, MAE: 4410.6602, R2: 0.0075\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1139/5000] | Time: 0.28s\n",
      "(Training) Loss: 1163224.1110\n",
      "(Validation) Loss: 1177807.2838, MAE: 4412.5586, R2: 0.0077\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1140/5000] | Time: 0.29s\n",
      "(Training) Loss: 1122279.8837\n",
      "(Validation) Loss: 1177562.9816, MAE: 4413.8232, R2: 0.0079\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1141/5000] | Time: 0.26s\n",
      "(Training) Loss: 1131371.0768\n",
      "(Validation) Loss: 1177335.8629, MAE: 4408.2925, R2: 0.0081\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1142/5000] | Time: 0.29s\n",
      "(Training) Loss: 1133371.0057\n",
      "(Validation) Loss: 1177125.1403, MAE: 4411.8765, R2: 0.0083\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1143/5000] | Time: 0.27s\n",
      "(Training) Loss: 1127255.2398\n",
      "(Validation) Loss: 1176893.2673, MAE: 4409.6709, R2: 0.0085\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1144/5000] | Time: 0.27s\n",
      "(Training) Loss: 1132213.0279\n",
      "(Validation) Loss: 1176658.5092, MAE: 4405.4331, R2: 0.0087\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1145/5000] | Time: 0.29s\n",
      "(Training) Loss: 1122217.3219\n",
      "(Validation) Loss: 1176454.7352, MAE: 4410.3110, R2: 0.0088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1146/5000] | Time: 0.27s\n",
      "(Training) Loss: 1140612.7754\n",
      "(Validation) Loss: 1176214.1308, MAE: 4403.6050, R2: 0.0090\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1147/5000] | Time: 0.31s\n",
      "(Training) Loss: 1123181.5022\n",
      "(Validation) Loss: 1175988.0229, MAE: 4402.9849, R2: 0.0092\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1148/5000] | Time: 0.26s\n",
      "(Training) Loss: 1147098.9023\n",
      "(Validation) Loss: 1175762.3416, MAE: 4401.8247, R2: 0.0094\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1149/5000] | Time: 0.25s\n",
      "(Training) Loss: 1122096.2933\n",
      "(Validation) Loss: 1175545.7727, MAE: 4403.3320, R2: 0.0096\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1150/5000] | Time: 0.28s\n",
      "(Training) Loss: 1136495.7671\n",
      "(Validation) Loss: 1175320.4825, MAE: 4402.4697, R2: 0.0098\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1151/5000] | Time: 0.27s\n",
      "(Training) Loss: 1122608.3065\n",
      "(Validation) Loss: 1175095.7562, MAE: 4400.3096, R2: 0.0100\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1152/5000] | Time: 0.26s\n",
      "(Training) Loss: 1130551.9753\n",
      "(Validation) Loss: 1174891.8197, MAE: 4401.1035, R2: 0.0101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1153/5000] | Time: 0.25s\n",
      "(Training) Loss: 1130061.3211\n",
      "(Validation) Loss: 1174647.5886, MAE: 4397.8223, R2: 0.0103\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1154/5000] | Time: 0.26s\n",
      "(Training) Loss: 1138936.2678\n",
      "(Validation) Loss: 1174422.8267, MAE: 4396.6230, R2: 0.0105\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1155/5000] | Time: 0.30s\n",
      "(Training) Loss: 1127914.3255\n",
      "(Validation) Loss: 1174196.8000, MAE: 4395.0776, R2: 0.0107\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1156/5000] | Time: 0.23s\n",
      "(Training) Loss: 1123107.8528\n",
      "(Validation) Loss: 1173970.3162, MAE: 4393.9722, R2: 0.0109\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1157/5000] | Time: 0.26s\n",
      "(Training) Loss: 1155720.4588\n",
      "(Validation) Loss: 1173747.4032, MAE: 4393.8218, R2: 0.0111\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1158/5000] | Time: 0.27s\n",
      "(Training) Loss: 1138839.7697\n",
      "(Validation) Loss: 1173524.9168, MAE: 4395.4614, R2: 0.0113\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1159/5000] | Time: 0.28s\n",
      "(Training) Loss: 1134179.9074\n",
      "(Validation) Loss: 1173297.3511, MAE: 4391.6074, R2: 0.0115\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1160/5000] | Time: 0.36s\n",
      "(Training) Loss: 1124225.6294\n",
      "(Validation) Loss: 1173099.6317, MAE: 4393.0669, R2: 0.0116\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1161/5000] | Time: 0.25s\n",
      "(Training) Loss: 1119244.8875\n",
      "(Validation) Loss: 1172852.8203, MAE: 4391.7476, R2: 0.0118\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1162/5000] | Time: 0.25s\n",
      "(Training) Loss: 1139013.2094\n",
      "(Validation) Loss: 1172629.2317, MAE: 4390.6304, R2: 0.0120\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1163/5000] | Time: 0.23s\n",
      "(Training) Loss: 1154452.4442\n",
      "(Validation) Loss: 1172398.1257, MAE: 4388.3423, R2: 0.0122\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1164/5000] | Time: 0.27s\n",
      "(Training) Loss: 1132266.7684\n",
      "(Validation) Loss: 1172172.0584, MAE: 4388.6338, R2: 0.0124\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1165/5000] | Time: 0.26s\n",
      "(Training) Loss: 1140930.0926\n",
      "(Validation) Loss: 1171949.3537, MAE: 4387.6631, R2: 0.0126\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1166/5000] | Time: 0.24s\n",
      "(Training) Loss: 1132377.4074\n",
      "(Validation) Loss: 1171754.9765, MAE: 4389.4541, R2: 0.0127\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1167/5000] | Time: 0.25s\n",
      "(Training) Loss: 1121413.9905\n",
      "(Validation) Loss: 1171501.7092, MAE: 4385.8120, R2: 0.0130\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1168/5000] | Time: 0.28s\n",
      "(Training) Loss: 1140937.3718\n",
      "(Validation) Loss: 1171278.4863, MAE: 4386.4541, R2: 0.0131\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1169/5000] | Time: 0.26s\n",
      "(Training) Loss: 1136615.6789\n",
      "(Validation) Loss: 1171053.0641, MAE: 4384.0327, R2: 0.0133\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1170/5000] | Time: 0.27s\n",
      "(Training) Loss: 1123762.5152\n",
      "(Validation) Loss: 1171501.5670, MAE: 4404.0068, R2: 0.0130\n",
      "==========================================================================================\n",
      "Epoch [1171/5000] | Time: 0.25s\n",
      "(Training) Loss: 1144168.8135\n",
      "(Validation) Loss: 1178992.7517, MAE: 4419.6387, R2: 0.0067\n",
      "==========================================================================================\n",
      "Epoch [1172/5000] | Time: 0.29s\n",
      "(Training) Loss: 1149230.9467\n",
      "(Validation) Loss: 1178760.0660, MAE: 4415.7803, R2: 0.0069\n",
      "==========================================================================================\n",
      "Epoch [1173/5000] | Time: 0.27s\n",
      "(Training) Loss: 1129650.7931\n",
      "(Validation) Loss: 1178531.1390, MAE: 4414.1860, R2: 0.0071\n",
      "==========================================================================================\n",
      "Epoch [1174/5000] | Time: 0.34s\n",
      "(Training) Loss: 1132161.8902\n",
      "(Validation) Loss: 1174145.9302, MAE: 4399.8091, R2: 0.0108\n",
      "==========================================================================================\n",
      "Epoch [1175/5000] | Time: 0.32s\n",
      "(Training) Loss: 1129178.8439\n",
      "(Validation) Loss: 1173920.3454, MAE: 4398.7646, R2: 0.0109\n",
      "==========================================================================================\n",
      "Epoch [1176/5000] | Time: 0.31s\n",
      "(Training) Loss: 1125391.0095\n",
      "(Validation) Loss: 1173669.3029, MAE: 4392.5176, R2: 0.0111\n",
      "==========================================================================================\n",
      "Epoch [1177/5000] | Time: 0.34s\n",
      "(Training) Loss: 1155810.3782\n",
      "(Validation) Loss: 1173453.6076, MAE: 4393.7119, R2: 0.0113\n",
      "==========================================================================================\n",
      "Epoch [1178/5000] | Time: 0.31s\n",
      "(Training) Loss: 1139889.2449\n",
      "(Validation) Loss: 1173226.3162, MAE: 4392.0117, R2: 0.0115\n",
      "==========================================================================================\n",
      "Epoch [1179/5000] | Time: 0.32s\n",
      "(Training) Loss: 1138941.3655\n",
      "(Validation) Loss: 1177272.2235, MAE: 4411.3262, R2: 0.0081\n",
      "==========================================================================================\n",
      "Epoch [1180/5000] | Time: 0.29s\n",
      "(Training) Loss: 1133201.0254\n",
      "(Validation) Loss: 1177005.9683, MAE: 4406.0488, R2: 0.0084\n",
      "==========================================================================================\n",
      "Epoch [1181/5000] | Time: 0.29s\n",
      "(Training) Loss: 1128388.4676\n",
      "(Validation) Loss: 1176788.2819, MAE: 4405.3887, R2: 0.0086\n",
      "==========================================================================================\n",
      "Epoch [1182/5000] | Time: 0.26s\n",
      "(Training) Loss: 1134979.8249\n",
      "(Validation) Loss: 1176570.1689, MAE: 4404.9595, R2: 0.0087\n",
      "==========================================================================================\n",
      "Epoch [1183/5000] | Time: 0.28s\n",
      "(Training) Loss: 1124087.8004\n",
      "(Validation) Loss: 1176352.0965, MAE: 4403.9443, R2: 0.0089\n",
      "==========================================================================================\n",
      "Epoch [1184/5000] | Time: 0.27s\n",
      "(Training) Loss: 1149481.5431\n",
      "(Validation) Loss: 1176135.5327, MAE: 4403.9468, R2: 0.0091\n",
      "==========================================================================================\n",
      "Epoch [1185/5000] | Time: 0.34s\n",
      "(Training) Loss: 1133521.0241\n",
      "(Validation) Loss: 1175915.9010, MAE: 4403.2466, R2: 0.0093\n",
      "==========================================================================================\n",
      "Epoch [1186/5000] | Time: 0.31s\n",
      "(Training) Loss: 1139677.5025\n",
      "(Validation) Loss: 1175698.0317, MAE: 4402.5347, R2: 0.0095\n",
      "==========================================================================================\n",
      "Epoch [1187/5000] | Time: 0.30s\n",
      "(Training) Loss: 1139154.4105\n",
      "(Validation) Loss: 1175483.7689, MAE: 4403.1406, R2: 0.0096\n",
      "==========================================================================================\n",
      "Epoch [1188/5000] | Time: 0.27s\n",
      "(Training) Loss: 1134550.4346\n",
      "(Validation) Loss: 1175271.7765, MAE: 4402.8491, R2: 0.0098\n",
      "==========================================================================================\n",
      "Epoch [1189/5000] | Time: 0.28s\n",
      "(Training) Loss: 1123097.9727\n",
      "(Validation) Loss: 1175050.3365, MAE: 4399.7251, R2: 0.0100\n",
      "==========================================================================================\n",
      "Epoch [1190/5000] | Time: 0.30s\n",
      "(Training) Loss: 1145518.8566\n",
      "(Validation) Loss: 1175383.8629, MAE: 4403.6113, R2: 0.0097\n",
      "==========================================================================================\n",
      "Epoch [1191/5000] | Time: 0.28s\n",
      "(Training) Loss: 1131332.3223\n",
      "(Validation) Loss: 1174601.9810, MAE: 4397.5376, R2: 0.0104\n",
      "==========================================================================================\n",
      "Epoch [1192/5000] | Time: 0.25s\n",
      "(Training) Loss: 1156069.0603\n",
      "(Validation) Loss: 1174502.3187, MAE: 4410.7441, R2: 0.0104\n",
      "==========================================================================================\n",
      "Epoch [1193/5000] | Time: 0.34s\n",
      "(Training) Loss: 1133020.5076\n",
      "(Validation) Loss: 1174182.2883, MAE: 4399.7925, R2: 0.0107\n",
      "==========================================================================================\n",
      "Epoch [1194/5000] | Time: 0.29s\n",
      "(Training) Loss: 1151402.1815\n",
      "(Validation) Loss: 1173947.3168, MAE: 4395.0620, R2: 0.0109\n",
      "==========================================================================================\n",
      "Epoch [1195/5000] | Time: 0.32s\n",
      "(Training) Loss: 1146542.1256\n",
      "(Validation) Loss: 1173724.9117, MAE: 4394.1328, R2: 0.0111\n",
      "==========================================================================================\n",
      "Epoch [1196/5000] | Time: 0.27s\n",
      "(Training) Loss: 1139626.6402\n",
      "(Validation) Loss: 1173512.2946, MAE: 4393.9346, R2: 0.0113\n",
      "==========================================================================================\n",
      "Epoch [1197/5000] | Time: 0.27s\n",
      "(Training) Loss: 1140909.1345\n",
      "(Validation) Loss: 1173286.7708, MAE: 4391.8242, R2: 0.0115\n",
      "==========================================================================================\n",
      "Epoch [1198/5000] | Time: 0.33s\n",
      "(Training) Loss: 1121050.0984\n",
      "(Validation) Loss: 1173066.7530, MAE: 4390.8438, R2: 0.0117\n",
      "==========================================================================================\n",
      "Epoch [1199/5000] | Time: 0.30s\n",
      "(Training) Loss: 1157624.0584\n",
      "(Validation) Loss: 1172877.5314, MAE: 4392.5552, R2: 0.0118\n",
      "==========================================================================================\n",
      "Epoch [1200/5000] | Time: 0.31s\n",
      "(Training) Loss: 1135743.4797\n",
      "(Validation) Loss: 1172681.1276, MAE: 4394.4116, R2: 0.0120\n",
      "==========================================================================================\n",
      "Epoch [1201/5000] | Time: 0.26s\n",
      "(Training) Loss: 1139364.1726\n",
      "(Validation) Loss: 1172439.5683, MAE: 4394.1768, R2: 0.0122\n",
      "==========================================================================================\n",
      "Epoch [1202/5000] | Time: 0.27s\n",
      "(Training) Loss: 1136530.6168\n",
      "(Validation) Loss: 1172245.9987, MAE: 4398.7593, R2: 0.0123\n",
      "==========================================================================================\n",
      "Epoch [1203/5000] | Time: 0.29s\n",
      "(Training) Loss: 1143868.7094\n",
      "(Validation) Loss: 1172046.2070, MAE: 4395.3936, R2: 0.0125\n",
      "==========================================================================================\n",
      "Epoch [1204/5000] | Time: 0.25s\n",
      "(Training) Loss: 1134855.1916\n",
      "(Validation) Loss: 1171791.5124, MAE: 4393.3462, R2: 0.0127\n",
      "==========================================================================================\n",
      "Epoch [1205/5000] | Time: 0.25s\n",
      "(Training) Loss: 1130248.3997\n",
      "(Validation) Loss: 1171571.0781, MAE: 4388.9346, R2: 0.0129\n",
      "==========================================================================================\n",
      "Epoch [1206/5000] | Time: 0.27s\n",
      "(Training) Loss: 1136055.9194\n",
      "(Validation) Loss: 1171354.5448, MAE: 4388.7290, R2: 0.0131\n",
      "==========================================================================================\n",
      "Epoch [1207/5000] | Time: 0.27s\n",
      "(Training) Loss: 1129007.5146\n",
      "(Validation) Loss: 1171153.4425, MAE: 4387.6270, R2: 0.0132\n",
      "==========================================================================================\n",
      "Epoch [1208/5000] | Time: 0.29s\n",
      "(Training) Loss: 1144309.7329\n",
      "(Validation) Loss: 1170929.5086, MAE: 4390.6421, R2: 0.0134\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1209/5000] | Time: 0.31s\n",
      "(Training) Loss: 1140066.5102\n",
      "(Validation) Loss: 1170717.3587, MAE: 4389.6548, R2: 0.0136\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1210/5000] | Time: 0.32s\n",
      "(Training) Loss: 1120069.8509\n",
      "(Validation) Loss: 1170483.6368, MAE: 4384.1694, R2: 0.0138\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1211/5000] | Time: 0.30s\n",
      "(Training) Loss: 1150091.7195\n",
      "(Validation) Loss: 1170267.5708, MAE: 4384.2793, R2: 0.0140\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1212/5000] | Time: 0.31s\n",
      "(Training) Loss: 1116947.7614\n",
      "(Validation) Loss: 1170046.7048, MAE: 4382.7563, R2: 0.0142\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1213/5000] | Time: 0.36s\n",
      "(Training) Loss: 1124399.9810\n",
      "(Validation) Loss: 1169837.8260, MAE: 4383.1904, R2: 0.0143\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1214/5000] | Time: 0.44s\n",
      "(Training) Loss: 1144816.9886\n",
      "(Validation) Loss: 1169618.7632, MAE: 4380.6353, R2: 0.0145\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1215/5000] | Time: 0.37s\n",
      "(Training) Loss: 1134705.5761\n",
      "(Validation) Loss: 1169395.2660, MAE: 4378.6484, R2: 0.0147\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1216/5000] | Time: 0.29s\n",
      "(Training) Loss: 1128839.7265\n",
      "(Validation) Loss: 1169177.7778, MAE: 4380.3257, R2: 0.0149\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1217/5000] | Time: 0.28s\n",
      "(Training) Loss: 1119684.9778\n",
      "(Validation) Loss: 1168994.0165, MAE: 4384.3979, R2: 0.0150\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1218/5000] | Time: 0.21s\n",
      "(Training) Loss: 1145089.0971\n",
      "(Validation) Loss: 1168781.4959, MAE: 4383.0747, R2: 0.0152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1219/5000] | Time: 0.30s\n",
      "(Training) Loss: 1159376.9657\n",
      "(Validation) Loss: 1168553.5848, MAE: 4379.3887, R2: 0.0154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1220/5000] | Time: 0.26s\n",
      "(Training) Loss: 1157733.9220\n",
      "(Validation) Loss: 1168322.7987, MAE: 4378.5508, R2: 0.0156\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1221/5000] | Time: 0.27s\n",
      "(Training) Loss: 1146782.9619\n",
      "(Validation) Loss: 1168150.1968, MAE: 4389.9155, R2: 0.0157\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1222/5000] | Time: 0.25s\n",
      "(Training) Loss: 1117577.7582\n",
      "(Validation) Loss: 1167877.9784, MAE: 4377.4038, R2: 0.0160\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1223/5000] | Time: 0.23s\n",
      "(Training) Loss: 1124757.1104\n",
      "(Validation) Loss: 1167684.1041, MAE: 4378.6831, R2: 0.0161\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1224/5000] | Time: 0.27s\n",
      "(Training) Loss: 1131462.5558\n",
      "(Validation) Loss: 1167442.5346, MAE: 4371.4849, R2: 0.0163\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1225/5000] | Time: 0.27s\n",
      "(Training) Loss: 1134661.9239\n",
      "(Validation) Loss: 1167228.8508, MAE: 4372.3887, R2: 0.0165\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1226/5000] | Time: 0.25s\n",
      "(Training) Loss: 1123112.8096\n",
      "(Validation) Loss: 1167016.0305, MAE: 4371.6064, R2: 0.0167\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1227/5000] | Time: 0.25s\n",
      "(Training) Loss: 1130106.6187\n",
      "(Validation) Loss: 1166829.7346, MAE: 4375.3350, R2: 0.0168\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1228/5000] | Time: 0.32s\n",
      "(Training) Loss: 1115193.9873\n",
      "(Validation) Loss: 1166589.2724, MAE: 4371.2192, R2: 0.0170\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1229/5000] | Time: 0.25s\n",
      "(Training) Loss: 1137343.1789\n",
      "(Validation) Loss: 1166365.0387, MAE: 4368.7573, R2: 0.0172\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1230/5000] | Time: 0.26s\n",
      "(Training) Loss: 1119120.8617\n",
      "(Validation) Loss: 1166152.4978, MAE: 4369.0405, R2: 0.0174\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1231/5000] | Time: 0.25s\n",
      "(Training) Loss: 1128026.0419\n",
      "(Validation) Loss: 1165945.3613, MAE: 4369.0522, R2: 0.0176\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1232/5000] | Time: 0.26s\n",
      "(Training) Loss: 1137677.0863\n",
      "(Validation) Loss: 1165731.3727, MAE: 4367.8101, R2: 0.0178\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1233/5000] | Time: 0.24s\n",
      "(Training) Loss: 1157338.4143\n",
      "(Validation) Loss: 1165504.1727, MAE: 4365.1729, R2: 0.0179\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1234/5000] | Time: 0.26s\n",
      "(Training) Loss: 1113897.6053\n",
      "(Validation) Loss: 1165314.3060, MAE: 4368.1660, R2: 0.0181\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1235/5000] | Time: 0.26s\n",
      "(Training) Loss: 1141921.2418\n",
      "(Validation) Loss: 1165074.6819, MAE: 4364.8896, R2: 0.0183\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1236/5000] | Time: 0.30s\n",
      "(Training) Loss: 1123625.5102\n",
      "(Validation) Loss: 1164875.8400, MAE: 4367.6616, R2: 0.0185\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1237/5000] | Time: 0.27s\n",
      "(Training) Loss: 1123398.9797\n",
      "(Validation) Loss: 1164670.8724, MAE: 4367.2100, R2: 0.0186\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1238/5000] | Time: 0.28s\n",
      "(Training) Loss: 1129860.0032\n",
      "(Validation) Loss: 1164426.4483, MAE: 4362.1650, R2: 0.0188\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1239/5000] | Time: 0.28s\n",
      "(Training) Loss: 1144764.0984\n",
      "(Validation) Loss: 1164208.9803, MAE: 4362.1104, R2: 0.0190\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1240/5000] | Time: 0.27s\n",
      "(Training) Loss: 1116767.1599\n",
      "(Validation) Loss: 1164014.0140, MAE: 4362.6377, R2: 0.0192\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1241/5000] | Time: 0.30s\n",
      "(Training) Loss: 1118624.3553\n",
      "(Validation) Loss: 1163797.6127, MAE: 4361.5288, R2: 0.0194\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1242/5000] | Time: 0.29s\n",
      "(Training) Loss: 1113795.6345\n",
      "(Validation) Loss: 1163593.0921, MAE: 4362.5864, R2: 0.0195\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1243/5000] | Time: 0.32s\n",
      "(Training) Loss: 1114311.7005\n",
      "(Validation) Loss: 1163371.4489, MAE: 4361.2715, R2: 0.0197\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1244/5000] | Time: 0.26s\n",
      "(Training) Loss: 1135350.5876\n",
      "(Validation) Loss: 1163167.7917, MAE: 4366.1304, R2: 0.0199\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1245/5000] | Time: 0.26s\n",
      "(Training) Loss: 1134467.4911\n",
      "(Validation) Loss: 1167362.2806, MAE: 4375.2700, R2: 0.0164\n",
      "==========================================================================================\n",
      "Epoch [1246/5000] | Time: 0.34s\n",
      "(Training) Loss: 1129975.9137\n",
      "(Validation) Loss: 1167150.0292, MAE: 4376.8379, R2: 0.0166\n",
      "==========================================================================================\n",
      "Epoch [1247/5000] | Time: 0.29s\n",
      "(Training) Loss: 1131955.6713\n",
      "(Validation) Loss: 1166933.3943, MAE: 4373.6772, R2: 0.0168\n",
      "==========================================================================================\n",
      "Epoch [1248/5000] | Time: 0.27s\n",
      "(Training) Loss: 1125550.4975\n",
      "(Validation) Loss: 1166721.8946, MAE: 4373.1509, R2: 0.0169\n",
      "==========================================================================================\n",
      "Epoch [1249/5000] | Time: 0.32s\n",
      "(Training) Loss: 1112798.9882\n",
      "(Validation) Loss: 1166507.6165, MAE: 4372.5537, R2: 0.0171\n",
      "==========================================================================================\n",
      "Epoch [1250/5000] | Time: 0.34s\n",
      "(Training) Loss: 1116622.0527\n",
      "(Validation) Loss: 1166296.6603, MAE: 4371.4805, R2: 0.0173\n",
      "==========================================================================================\n",
      "Epoch [1251/5000] | Time: 0.31s\n",
      "(Training) Loss: 1114740.7814\n",
      "(Validation) Loss: 1166083.4286, MAE: 4370.7002, R2: 0.0175\n",
      "==========================================================================================\n",
      "Epoch [1252/5000] | Time: 0.30s\n",
      "(Training) Loss: 1136718.1256\n",
      "(Validation) Loss: 1165871.0654, MAE: 4368.3472, R2: 0.0176\n",
      "==========================================================================================\n",
      "Epoch [1253/5000] | Time: 0.28s\n",
      "(Training) Loss: 1124349.1954\n",
      "(Validation) Loss: 1165658.6006, MAE: 4368.3999, R2: 0.0178\n",
      "==========================================================================================\n",
      "Epoch [1254/5000] | Time: 0.26s\n",
      "(Training) Loss: 1142123.5860\n",
      "(Validation) Loss: 1165447.5429, MAE: 4367.8037, R2: 0.0180\n",
      "==========================================================================================\n",
      "Epoch [1255/5000] | Time: 0.26s\n",
      "(Training) Loss: 1131474.5774\n",
      "(Validation) Loss: 1165259.9213, MAE: 4368.3682, R2: 0.0182\n",
      "==========================================================================================\n",
      "Epoch [1256/5000] | Time: 0.25s\n",
      "(Training) Loss: 1131627.4137\n",
      "(Validation) Loss: 1165057.9403, MAE: 4369.1328, R2: 0.0183\n",
      "==========================================================================================\n",
      "Epoch [1257/5000] | Time: 0.26s\n",
      "(Training) Loss: 1118040.9588\n",
      "(Validation) Loss: 1164843.6165, MAE: 4371.5278, R2: 0.0185\n",
      "==========================================================================================\n",
      "Epoch [1258/5000] | Time: 0.26s\n",
      "(Training) Loss: 1131204.4099\n",
      "(Validation) Loss: 1164623.1517, MAE: 4367.7251, R2: 0.0187\n",
      "==========================================================================================\n",
      "Epoch [1259/5000] | Time: 0.28s\n",
      "(Training) Loss: 1117420.1815\n",
      "(Validation) Loss: 1164408.1879, MAE: 4365.7095, R2: 0.0189\n",
      "==========================================================================================\n",
      "Epoch [1260/5000] | Time: 0.28s\n",
      "(Training) Loss: 1111037.8058\n",
      "(Validation) Loss: 1164174.6895, MAE: 4365.1113, R2: 0.0191\n",
      "==========================================================================================\n",
      "Epoch [1261/5000] | Time: 0.26s\n",
      "(Training) Loss: 1136407.6371\n",
      "(Validation) Loss: 1163961.8946, MAE: 4362.6206, R2: 0.0192\n",
      "==========================================================================================\n",
      "Epoch [1262/5000] | Time: 0.31s\n",
      "(Training) Loss: 1124005.6967\n",
      "(Validation) Loss: 1163778.2552, MAE: 4366.3789, R2: 0.0194\n",
      "==========================================================================================\n",
      "Epoch [1263/5000] | Time: 0.28s\n",
      "(Training) Loss: 1118388.1536\n",
      "(Validation) Loss: 1163532.8914, MAE: 4360.0679, R2: 0.0196\n",
      "==========================================================================================\n",
      "Epoch [1264/5000] | Time: 0.33s\n",
      "(Training) Loss: 1131472.7259\n",
      "(Validation) Loss: 1163327.2889, MAE: 4360.7217, R2: 0.0198\n",
      "==========================================================================================\n",
      "Epoch [1265/5000] | Time: 0.31s\n",
      "(Training) Loss: 1126687.4803\n",
      "(Validation) Loss: 1163087.4108, MAE: 4358.8452, R2: 0.0200\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1266/5000] | Time: 0.29s\n",
      "(Training) Loss: 1129884.0679\n",
      "(Validation) Loss: 1162875.2965, MAE: 4356.8740, R2: 0.0201\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1267/5000] | Time: 0.34s\n",
      "(Training) Loss: 1111097.6171\n",
      "(Validation) Loss: 1162694.8063, MAE: 4362.3135, R2: 0.0203\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1268/5000] | Time: 0.30s\n",
      "(Training) Loss: 1128704.9343\n",
      "(Validation) Loss: 1162453.2775, MAE: 4357.3706, R2: 0.0205\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1269/5000] | Time: 0.30s\n",
      "(Training) Loss: 1120732.0000\n",
      "(Validation) Loss: 1162239.4667, MAE: 4356.0308, R2: 0.0207\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1270/5000] | Time: 0.28s\n",
      "(Training) Loss: 1131475.8033\n",
      "(Validation) Loss: 1162085.4044, MAE: 4358.3320, R2: 0.0208\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1271/5000] | Time: 0.30s\n",
      "(Training) Loss: 1112977.3331\n",
      "(Validation) Loss: 1161835.8400, MAE: 4355.7793, R2: 0.0210\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1272/5000] | Time: 0.30s\n",
      "(Training) Loss: 1110273.9689\n",
      "(Validation) Loss: 1161653.1251, MAE: 4363.6348, R2: 0.0212\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1273/5000] | Time: 0.28s\n",
      "(Training) Loss: 1122212.3522\n",
      "(Validation) Loss: 1161418.0927, MAE: 4353.7861, R2: 0.0214\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1274/5000] | Time: 0.26s\n",
      "(Training) Loss: 1115726.4194\n",
      "(Validation) Loss: 1161204.1092, MAE: 4352.3940, R2: 0.0215\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1275/5000] | Time: 0.28s\n",
      "(Training) Loss: 1124926.5838\n",
      "(Validation) Loss: 1161002.7683, MAE: 4355.7129, R2: 0.0217\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1276/5000] | Time: 0.34s\n",
      "(Training) Loss: 1113145.6821\n",
      "(Validation) Loss: 1160809.5949, MAE: 4358.9048, R2: 0.0219\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1277/5000] | Time: 0.29s\n",
      "(Training) Loss: 1109589.2310\n",
      "(Validation) Loss: 1160571.9619, MAE: 4350.8203, R2: 0.0221\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1278/5000] | Time: 0.29s\n",
      "(Training) Loss: 1129084.5133\n",
      "(Validation) Loss: 1160370.4127, MAE: 4350.8477, R2: 0.0222\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1279/5000] | Time: 0.28s\n",
      "(Training) Loss: 1147498.5406\n",
      "(Validation) Loss: 1160147.1340, MAE: 4349.3506, R2: 0.0224\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1280/5000] | Time: 0.33s\n",
      "(Training) Loss: 1117721.4968\n",
      "(Validation) Loss: 1159941.0489, MAE: 4349.4985, R2: 0.0226\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1281/5000] | Time: 0.31s\n",
      "(Training) Loss: 1127705.0571\n",
      "(Validation) Loss: 1159726.6590, MAE: 4350.2715, R2: 0.0228\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1282/5000] | Time: 0.31s\n",
      "(Training) Loss: 1119135.2868\n",
      "(Validation) Loss: 1159514.2756, MAE: 4347.3652, R2: 0.0229\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1283/5000] | Time: 0.34s\n",
      "(Training) Loss: 1119451.2195\n",
      "(Validation) Loss: 1159315.9873, MAE: 4348.0386, R2: 0.0231\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1284/5000] | Time: 0.33s\n",
      "(Training) Loss: 1122985.8909\n",
      "(Validation) Loss: 1159085.4197, MAE: 4344.9390, R2: 0.0233\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1285/5000] | Time: 0.35s\n",
      "(Training) Loss: 1116485.0799\n",
      "(Validation) Loss: 1158886.9994, MAE: 4346.5557, R2: 0.0235\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1286/5000] | Time: 0.42s\n",
      "(Training) Loss: 1137603.7386\n",
      "(Validation) Loss: 1158668.7492, MAE: 4345.9292, R2: 0.0236\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1287/5000] | Time: 0.31s\n",
      "(Training) Loss: 1122531.4619\n",
      "(Validation) Loss: 1159348.4902, MAE: 4356.3633, R2: 0.0230\n",
      "==========================================================================================\n",
      "Epoch [1288/5000] | Time: 0.31s\n",
      "(Training) Loss: 1107278.2379\n",
      "(Validation) Loss: 1158242.6159, MAE: 4342.4517, R2: 0.0240\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1289/5000] | Time: 0.32s\n",
      "(Training) Loss: 1110115.1910\n",
      "(Validation) Loss: 1158029.7702, MAE: 4340.8491, R2: 0.0242\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1290/5000] | Time: 0.30s\n",
      "(Training) Loss: 1118826.3395\n",
      "(Validation) Loss: 1157803.0578, MAE: 4340.5654, R2: 0.0244\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1291/5000] | Time: 0.32s\n",
      "(Training) Loss: 1136898.6640\n",
      "(Validation) Loss: 1157597.4806, MAE: 4340.9321, R2: 0.0245\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1292/5000] | Time: 0.38s\n",
      "(Training) Loss: 1118225.1123\n",
      "(Validation) Loss: 1157376.2590, MAE: 4336.6382, R2: 0.0247\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1293/5000] | Time: 0.34s\n",
      "(Training) Loss: 1111353.1992\n",
      "(Validation) Loss: 1157171.8248, MAE: 4337.7974, R2: 0.0249\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1294/5000] | Time: 0.24s\n",
      "(Training) Loss: 1113365.5520\n",
      "(Validation) Loss: 1156956.6273, MAE: 4336.4624, R2: 0.0251\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1295/5000] | Time: 0.35s\n",
      "(Training) Loss: 1109972.0895\n",
      "(Validation) Loss: 1156778.7581, MAE: 4339.7095, R2: 0.0252\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1296/5000] | Time: 0.32s\n",
      "(Training) Loss: 1112524.6256\n",
      "(Validation) Loss: 1156532.1651, MAE: 4333.1714, R2: 0.0254\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1297/5000] | Time: 0.35s\n",
      "(Training) Loss: 1121680.7056\n",
      "(Validation) Loss: 1156339.1543, MAE: 4334.3696, R2: 0.0256\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1298/5000] | Time: 0.26s\n",
      "(Training) Loss: 1109101.6174\n",
      "(Validation) Loss: 1156125.8413, MAE: 4333.4155, R2: 0.0258\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1299/5000] | Time: 0.26s\n",
      "(Training) Loss: 1114089.3414\n",
      "(Validation) Loss: 1155904.2844, MAE: 4332.1294, R2: 0.0259\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1300/5000] | Time: 0.35s\n",
      "(Training) Loss: 1108251.4365\n",
      "(Validation) Loss: 1155692.2159, MAE: 4331.9307, R2: 0.0261\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1301/5000] | Time: 0.33s\n",
      "(Training) Loss: 1107942.7253\n",
      "(Validation) Loss: 1155483.4032, MAE: 4329.3940, R2: 0.0263\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1302/5000] | Time: 0.26s\n",
      "(Training) Loss: 1117626.7462\n",
      "(Validation) Loss: 1155289.1073, MAE: 4332.2153, R2: 0.0265\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1303/5000] | Time: 0.26s\n",
      "(Training) Loss: 1125027.2925\n",
      "(Validation) Loss: 1155094.1003, MAE: 4334.0688, R2: 0.0266\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1304/5000] | Time: 0.23s\n",
      "(Training) Loss: 1107235.2056\n",
      "(Validation) Loss: 1164133.3537, MAE: 4375.0903, R2: 0.0191\n",
      "==========================================================================================\n",
      "Epoch [1305/5000] | Time: 0.28s\n",
      "(Training) Loss: 1125118.8217\n",
      "(Validation) Loss: 1163903.3498, MAE: 4368.8950, R2: 0.0193\n",
      "==========================================================================================\n",
      "Epoch [1306/5000] | Time: 0.49s\n",
      "(Training) Loss: 1122177.4740\n",
      "(Validation) Loss: 1163665.4679, MAE: 4363.2964, R2: 0.0195\n",
      "==========================================================================================\n",
      "Epoch [1307/5000] | Time: 0.39s\n",
      "(Training) Loss: 1147971.4074\n",
      "(Validation) Loss: 1163441.1632, MAE: 4360.2407, R2: 0.0197\n",
      "==========================================================================================\n",
      "Epoch [1308/5000] | Time: 0.80s\n",
      "(Training) Loss: 1115123.3871\n",
      "(Validation) Loss: 1163222.2476, MAE: 4357.7432, R2: 0.0199\n",
      "==========================================================================================\n",
      "Epoch [1309/5000] | Time: 0.70s\n",
      "(Training) Loss: 1130495.2348\n",
      "(Validation) Loss: 1163017.3206, MAE: 4359.5479, R2: 0.0200\n",
      "==========================================================================================\n",
      "Epoch [1310/5000] | Time: 0.69s\n",
      "(Training) Loss: 1120360.9937\n",
      "(Validation) Loss: 1162820.8965, MAE: 4359.7202, R2: 0.0202\n",
      "==========================================================================================\n",
      "Epoch [1311/5000] | Time: 0.32s\n",
      "(Training) Loss: 1114267.7487\n",
      "(Validation) Loss: 1162607.2330, MAE: 4358.4932, R2: 0.0204\n",
      "==========================================================================================\n",
      "Epoch [1312/5000] | Time: 0.34s\n",
      "(Training) Loss: 1136830.1853\n",
      "(Validation) Loss: 1162377.4730, MAE: 4357.5620, R2: 0.0206\n",
      "==========================================================================================\n",
      "Epoch [1313/5000] | Time: 0.80s\n",
      "(Training) Loss: 1138572.0387\n",
      "(Validation) Loss: 1162162.5295, MAE: 4357.6338, R2: 0.0207\n",
      "==========================================================================================\n",
      "Epoch [1314/5000] | Time: 0.90s\n",
      "(Training) Loss: 1125370.9860\n",
      "(Validation) Loss: 1161943.6648, MAE: 4353.5293, R2: 0.0209\n",
      "==========================================================================================\n",
      "Epoch [1315/5000] | Time: 1.04s\n",
      "(Training) Loss: 1123673.5774\n",
      "(Validation) Loss: 1161738.1435, MAE: 4354.7456, R2: 0.0211\n",
      "==========================================================================================\n",
      "Epoch [1316/5000] | Time: 0.90s\n",
      "(Training) Loss: 1131075.3718\n",
      "(Validation) Loss: 1161517.4654, MAE: 4352.3960, R2: 0.0213\n",
      "==========================================================================================\n",
      "Epoch [1317/5000] | Time: 0.66s\n",
      "(Training) Loss: 1113478.6390\n",
      "(Validation) Loss: 1161305.6914, MAE: 4352.2622, R2: 0.0214\n",
      "==========================================================================================\n",
      "Epoch [1318/5000] | Time: 0.26s\n",
      "(Training) Loss: 1124005.5266\n",
      "(Validation) Loss: 1161090.9511, MAE: 4351.0420, R2: 0.0216\n",
      "==========================================================================================\n",
      "Epoch [1319/5000] | Time: 0.29s\n",
      "(Training) Loss: 1120268.4010\n",
      "(Validation) Loss: 1160877.1911, MAE: 4349.0332, R2: 0.0218\n",
      "==========================================================================================\n",
      "Epoch [1320/5000] | Time: 0.29s\n",
      "(Training) Loss: 1125598.0019\n",
      "(Validation) Loss: 1160667.7841, MAE: 4349.0942, R2: 0.0220\n",
      "==========================================================================================\n",
      "Epoch [1321/5000] | Time: 0.29s\n",
      "(Training) Loss: 1127309.5952\n",
      "(Validation) Loss: 1160464.1270, MAE: 4351.2866, R2: 0.0221\n",
      "==========================================================================================\n",
      "Epoch [1322/5000] | Time: 0.25s\n",
      "(Training) Loss: 1122973.5768\n",
      "(Validation) Loss: 1160257.4476, MAE: 4353.5400, R2: 0.0223\n",
      "==========================================================================================\n",
      "Epoch [1323/5000] | Time: 0.29s\n",
      "(Training) Loss: 1133707.3858\n",
      "(Validation) Loss: 1160051.6114, MAE: 4350.0405, R2: 0.0225\n",
      "==========================================================================================\n",
      "Epoch [1324/5000] | Time: 0.26s\n",
      "(Training) Loss: 1128325.3135\n",
      "(Validation) Loss: 1159821.2927, MAE: 4346.9502, R2: 0.0227\n",
      "==========================================================================================\n",
      "Epoch [1325/5000] | Time: 0.33s\n",
      "(Training) Loss: 1136391.8794\n",
      "(Validation) Loss: 1159612.8813, MAE: 4346.8916, R2: 0.0229\n",
      "==========================================================================================\n",
      "Epoch [1326/5000] | Time: 0.26s\n",
      "(Training) Loss: 1126956.7456\n",
      "(Validation) Loss: 1159418.3010, MAE: 4347.4644, R2: 0.0230\n",
      "==========================================================================================\n",
      "Epoch [1327/5000] | Time: 0.25s\n",
      "(Training) Loss: 1117090.2221\n",
      "(Validation) Loss: 1159196.3073, MAE: 4349.8164, R2: 0.0232\n",
      "==========================================================================================\n",
      "Epoch [1328/5000] | Time: 0.32s\n",
      "(Training) Loss: 1130787.4981\n",
      "(Validation) Loss: 1158990.5879, MAE: 4344.1587, R2: 0.0234\n",
      "==========================================================================================\n",
      "Epoch [1329/5000] | Time: 0.23s\n",
      "(Training) Loss: 1154320.1155\n",
      "(Validation) Loss: 1158781.4857, MAE: 4344.2671, R2: 0.0235\n",
      "==========================================================================================\n",
      "Epoch [1330/5000] | Time: 0.26s\n",
      "(Training) Loss: 1110553.5190\n",
      "(Validation) Loss: 1158580.6070, MAE: 4345.2827, R2: 0.0237\n",
      "==========================================================================================\n",
      "Epoch [1331/5000] | Time: 0.28s\n",
      "(Training) Loss: 1127846.0292\n",
      "(Validation) Loss: 1158360.3759, MAE: 4344.5747, R2: 0.0239\n",
      "==========================================================================================\n",
      "Epoch [1332/5000] | Time: 0.24s\n",
      "(Training) Loss: 1112123.0266\n",
      "(Validation) Loss: 1158144.3098, MAE: 4342.5649, R2: 0.0241\n",
      "==========================================================================================\n",
      "Epoch [1333/5000] | Time: 0.32s\n",
      "(Training) Loss: 1128680.0381\n",
      "(Validation) Loss: 1157960.7060, MAE: 4344.6118, R2: 0.0242\n",
      "==========================================================================================\n",
      "Epoch [1334/5000] | Time: 0.36s\n",
      "(Training) Loss: 1109894.4898\n",
      "(Validation) Loss: 1157744.6806, MAE: 4342.1660, R2: 0.0244\n",
      "==========================================================================================\n",
      "Epoch [1335/5000] | Time: 0.28s\n",
      "(Training) Loss: 1119764.6447\n",
      "(Validation) Loss: 1157571.5556, MAE: 4354.2217, R2: 0.0246\n",
      "==========================================================================================\n",
      "Epoch [1336/5000] | Time: 0.27s\n",
      "(Training) Loss: 1124869.8839\n",
      "(Validation) Loss: 1157318.1816, MAE: 4341.7988, R2: 0.0248\n",
      "==========================================================================================\n",
      "Epoch [1337/5000] | Time: 0.34s\n",
      "(Training) Loss: 1112902.3464\n",
      "(Validation) Loss: 1157084.6171, MAE: 4337.6445, R2: 0.0250\n",
      "==========================================================================================\n",
      "Epoch [1338/5000] | Time: 0.31s\n",
      "(Training) Loss: 1104951.4502\n",
      "(Validation) Loss: 1156869.9530, MAE: 4337.5342, R2: 0.0251\n",
      "==========================================================================================\n",
      "Epoch [1339/5000] | Time: 0.28s\n",
      "(Training) Loss: 1127311.5241\n",
      "(Validation) Loss: 1156670.1562, MAE: 4338.5957, R2: 0.0253\n",
      "==========================================================================================\n",
      "Epoch [1340/5000] | Time: 0.39s\n",
      "(Training) Loss: 1126673.9277\n",
      "(Validation) Loss: 1156451.0070, MAE: 4336.2275, R2: 0.0255\n",
      "==========================================================================================\n",
      "Epoch [1341/5000] | Time: 0.32s\n",
      "(Training) Loss: 1132629.1777\n",
      "(Validation) Loss: 1156254.5016, MAE: 4336.4614, R2: 0.0257\n",
      "==========================================================================================\n",
      "Epoch [1342/5000] | Time: 0.28s\n",
      "(Training) Loss: 1134262.7735\n",
      "(Validation) Loss: 1156031.4463, MAE: 4336.4189, R2: 0.0258\n",
      "==========================================================================================\n",
      "Epoch [1343/5000] | Time: 0.28s\n",
      "(Training) Loss: 1103550.6152\n",
      "(Validation) Loss: 1155818.4025, MAE: 4335.1118, R2: 0.0260\n",
      "==========================================================================================\n",
      "Epoch [1344/5000] | Time: 0.38s\n",
      "(Training) Loss: 1104980.6967\n",
      "(Validation) Loss: 1155607.0400, MAE: 4333.5913, R2: 0.0262\n",
      "==========================================================================================\n",
      "Epoch [1345/5000] | Time: 0.27s\n",
      "(Training) Loss: 1120016.2475\n",
      "(Validation) Loss: 1155395.6724, MAE: 4331.7153, R2: 0.0264\n",
      "==========================================================================================\n",
      "Epoch [1346/5000] | Time: 0.33s\n",
      "(Training) Loss: 1109730.5463\n",
      "(Validation) Loss: 1155183.2990, MAE: 4330.1641, R2: 0.0265\n",
      "==========================================================================================\n",
      "Epoch [1347/5000] | Time: 0.27s\n",
      "(Training) Loss: 1110554.2563\n",
      "(Validation) Loss: 1154975.7867, MAE: 4330.6284, R2: 0.0267\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1348/5000] | Time: 0.22s\n",
      "(Training) Loss: 1115711.3572\n",
      "(Validation) Loss: 1154772.3886, MAE: 4332.4619, R2: 0.0269\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1349/5000] | Time: 0.21s\n",
      "(Training) Loss: 1137061.1104\n",
      "(Validation) Loss: 1154549.0032, MAE: 4328.5835, R2: 0.0271\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1350/5000] | Time: 0.23s\n",
      "(Training) Loss: 1122586.8458\n",
      "(Validation) Loss: 1154369.3460, MAE: 4331.4243, R2: 0.0272\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1351/5000] | Time: 0.28s\n",
      "(Training) Loss: 1106685.2437\n",
      "(Validation) Loss: 1154157.7702, MAE: 4332.2490, R2: 0.0274\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1352/5000] | Time: 0.25s\n",
      "(Training) Loss: 1117458.0457\n",
      "(Validation) Loss: 1153946.1181, MAE: 4329.5273, R2: 0.0276\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1353/5000] | Time: 0.25s\n",
      "(Training) Loss: 1111802.7418\n",
      "(Validation) Loss: 1153732.6019, MAE: 4327.7017, R2: 0.0278\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1354/5000] | Time: 0.26s\n",
      "(Training) Loss: 1116638.4226\n",
      "(Validation) Loss: 1153549.0540, MAE: 4329.1582, R2: 0.0279\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1355/5000] | Time: 0.22s\n",
      "(Training) Loss: 1122292.3807\n",
      "(Validation) Loss: 1153340.7797, MAE: 4330.2656, R2: 0.0281\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1356/5000] | Time: 0.23s\n",
      "(Training) Loss: 1113698.5914\n",
      "(Validation) Loss: 1153126.0038, MAE: 4328.4346, R2: 0.0283\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1357/5000] | Time: 0.24s\n",
      "(Training) Loss: 1129655.8249\n",
      "(Validation) Loss: 1152913.0311, MAE: 4326.4653, R2: 0.0284\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1358/5000] | Time: 0.22s\n",
      "(Training) Loss: 1122667.6015\n",
      "(Validation) Loss: 1152751.3905, MAE: 4329.7822, R2: 0.0286\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1359/5000] | Time: 0.23s\n",
      "(Training) Loss: 1116842.7018\n",
      "(Validation) Loss: 1152501.1911, MAE: 4327.3159, R2: 0.0288\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1360/5000] | Time: 0.22s\n",
      "(Training) Loss: 1112540.2925\n",
      "(Validation) Loss: 1152281.9657, MAE: 4326.2837, R2: 0.0290\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1361/5000] | Time: 0.26s\n",
      "(Training) Loss: 1119538.4385\n",
      "(Validation) Loss: 1152080.2946, MAE: 4327.1997, R2: 0.0291\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1362/5000] | Time: 0.21s\n",
      "(Training) Loss: 1109341.8471\n",
      "(Validation) Loss: 1151862.4559, MAE: 4324.4888, R2: 0.0293\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1363/5000] | Time: 0.22s\n",
      "(Training) Loss: 1102277.6218\n",
      "(Validation) Loss: 1151686.7606, MAE: 4326.6411, R2: 0.0295\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1364/5000] | Time: 0.25s\n",
      "(Training) Loss: 1113244.3217\n",
      "(Validation) Loss: 1151478.5575, MAE: 4324.6294, R2: 0.0296\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1365/5000] | Time: 0.21s\n",
      "(Training) Loss: 1134712.5825\n",
      "(Validation) Loss: 1151279.1162, MAE: 4327.4019, R2: 0.0298\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1366/5000] | Time: 0.27s\n",
      "(Training) Loss: 1098733.8049\n",
      "(Validation) Loss: 1151063.9898, MAE: 4327.1802, R2: 0.0300\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1367/5000] | Time: 0.25s\n",
      "(Training) Loss: 1122160.1586\n",
      "(Validation) Loss: 1150848.5994, MAE: 4323.1924, R2: 0.0302\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1368/5000] | Time: 0.23s\n",
      "(Training) Loss: 1101840.7944\n",
      "(Validation) Loss: 1150641.6102, MAE: 4323.6421, R2: 0.0303\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1369/5000] | Time: 0.27s\n",
      "(Training) Loss: 1108945.2354\n",
      "(Validation) Loss: 1150431.6038, MAE: 4323.6709, R2: 0.0305\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1370/5000] | Time: 0.24s\n",
      "(Training) Loss: 1121912.5952\n",
      "(Validation) Loss: 1150221.9835, MAE: 4322.3369, R2: 0.0307\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1371/5000] | Time: 0.26s\n",
      "(Training) Loss: 1122700.7272\n",
      "(Validation) Loss: 1150004.6730, MAE: 4320.5396, R2: 0.0309\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1372/5000] | Time: 0.22s\n",
      "(Training) Loss: 1110982.9099\n",
      "(Validation) Loss: 1149805.6990, MAE: 4324.5879, R2: 0.0310\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1373/5000] | Time: 0.23s\n",
      "(Training) Loss: 1098171.8139\n",
      "(Validation) Loss: 1149595.3016, MAE: 4322.3662, R2: 0.0312\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1374/5000] | Time: 0.25s\n",
      "(Training) Loss: 1101700.7373\n",
      "(Validation) Loss: 1149419.5200, MAE: 4322.5039, R2: 0.0313\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1375/5000] | Time: 0.23s\n",
      "(Training) Loss: 1119378.8779\n",
      "(Validation) Loss: 1149206.6946, MAE: 4319.0186, R2: 0.0315\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1376/5000] | Time: 0.29s\n",
      "(Training) Loss: 1112437.9657\n",
      "(Validation) Loss: 1148997.6889, MAE: 4319.3125, R2: 0.0317\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1377/5000] | Time: 0.26s\n",
      "(Training) Loss: 1099554.9943\n",
      "(Validation) Loss: 1148834.1435, MAE: 4321.5684, R2: 0.0318\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1378/5000] | Time: 0.30s\n",
      "(Training) Loss: 1120286.7893\n",
      "(Validation) Loss: 1148574.8673, MAE: 4317.5317, R2: 0.0320\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1379/5000] | Time: 0.35s\n",
      "(Training) Loss: 1124233.3769\n",
      "(Validation) Loss: 1148372.6832, MAE: 4319.5024, R2: 0.0322\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1380/5000] | Time: 0.31s\n",
      "(Training) Loss: 1111031.9975\n",
      "(Validation) Loss: 1148160.8990, MAE: 4318.4443, R2: 0.0324\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1381/5000] | Time: 0.35s\n",
      "(Training) Loss: 1128778.2912\n",
      "(Validation) Loss: 1147949.9479, MAE: 4315.0889, R2: 0.0326\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1382/5000] | Time: 0.28s\n",
      "(Training) Loss: 1114631.6275\n",
      "(Validation) Loss: 1147736.4368, MAE: 4314.1538, R2: 0.0327\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1383/5000] | Time: 0.31s\n",
      "(Training) Loss: 1105060.4004\n",
      "(Validation) Loss: 1147523.2203, MAE: 4313.3770, R2: 0.0329\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1384/5000] | Time: 0.28s\n",
      "(Training) Loss: 1097722.1098\n",
      "(Validation) Loss: 1147322.3670, MAE: 4314.1240, R2: 0.0331\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1385/5000] | Time: 0.29s\n",
      "(Training) Loss: 1136217.9004\n",
      "(Validation) Loss: 1147138.2095, MAE: 4320.3809, R2: 0.0332\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1386/5000] | Time: 0.28s\n",
      "(Training) Loss: 1120131.8363\n",
      "(Validation) Loss: 1146903.9390, MAE: 4313.4858, R2: 0.0334\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1387/5000] | Time: 0.30s\n",
      "(Training) Loss: 1105114.8096\n",
      "(Validation) Loss: 1146686.7911, MAE: 4311.1060, R2: 0.0336\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1388/5000] | Time: 0.30s\n",
      "(Training) Loss: 1117082.9181\n",
      "(Validation) Loss: 1146482.0317, MAE: 4311.4678, R2: 0.0338\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1389/5000] | Time: 0.27s\n",
      "(Training) Loss: 1114283.2424\n",
      "(Validation) Loss: 1146272.3149, MAE: 4311.7988, R2: 0.0340\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1390/5000] | Time: 0.28s\n",
      "(Training) Loss: 1125199.7398\n",
      "(Validation) Loss: 1146062.5879, MAE: 4310.0562, R2: 0.0341\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1391/5000] | Time: 0.30s\n",
      "(Training) Loss: 1143811.4619\n",
      "(Validation) Loss: 1145852.7289, MAE: 4310.4092, R2: 0.0343\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1392/5000] | Time: 0.29s\n",
      "(Training) Loss: 1117315.8331\n",
      "(Validation) Loss: 1145631.1060, MAE: 4306.7104, R2: 0.0345\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1393/5000] | Time: 0.33s\n",
      "(Training) Loss: 1106709.3820\n",
      "(Validation) Loss: 1145421.3740, MAE: 4305.5796, R2: 0.0347\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1394/5000] | Time: 0.28s\n",
      "(Training) Loss: 1125070.1923\n",
      "(Validation) Loss: 1145217.6406, MAE: 4306.1465, R2: 0.0348\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1395/5000] | Time: 0.30s\n",
      "(Training) Loss: 1100897.2259\n",
      "(Validation) Loss: 1145005.4451, MAE: 4305.8413, R2: 0.0350\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1396/5000] | Time: 0.32s\n",
      "(Training) Loss: 1107590.2697\n",
      "(Validation) Loss: 1144794.2146, MAE: 4304.1675, R2: 0.0352\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1397/5000] | Time: 0.33s\n",
      "(Training) Loss: 1099786.4914\n",
      "(Validation) Loss: 1144590.8775, MAE: 4305.3398, R2: 0.0354\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1398/5000] | Time: 0.27s\n",
      "(Training) Loss: 1107939.6466\n",
      "(Validation) Loss: 1144379.7384, MAE: 4302.5215, R2: 0.0355\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1399/5000] | Time: 0.41s\n",
      "(Training) Loss: 1105459.3014\n",
      "(Validation) Loss: 1144171.1238, MAE: 4301.5737, R2: 0.0357\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1400/5000] | Time: 0.27s\n",
      "(Training) Loss: 1096602.2633\n",
      "(Validation) Loss: 1143961.4527, MAE: 4300.9175, R2: 0.0359\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1401/5000] | Time: 0.30s\n",
      "(Training) Loss: 1106768.3788\n",
      "(Validation) Loss: 1143756.9473, MAE: 4301.0825, R2: 0.0361\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1402/5000] | Time: 0.27s\n",
      "(Training) Loss: 1103467.2329\n",
      "(Validation) Loss: 1143549.8921, MAE: 4300.9731, R2: 0.0362\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1403/5000] | Time: 0.26s\n",
      "(Training) Loss: 1094220.5879\n",
      "(Validation) Loss: 1143336.5384, MAE: 4300.5757, R2: 0.0364\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1404/5000] | Time: 0.28s\n",
      "(Training) Loss: 1105615.3090\n",
      "(Validation) Loss: 1143100.3073, MAE: 4304.4072, R2: 0.0366\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1405/5000] | Time: 0.28s\n",
      "(Training) Loss: 1109749.3794\n",
      "(Validation) Loss: 1142876.6781, MAE: 4299.1455, R2: 0.0368\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1406/5000] | Time: 0.28s\n",
      "(Training) Loss: 1115418.5711\n",
      "(Validation) Loss: 1142634.0063, MAE: 4289.7944, R2: 0.0370\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1407/5000] | Time: 0.36s\n",
      "(Training) Loss: 1119640.8591\n",
      "(Validation) Loss: 1142430.9181, MAE: 4294.0459, R2: 0.0372\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1408/5000] | Time: 0.39s\n",
      "(Training) Loss: 1105672.3731\n",
      "(Validation) Loss: 1142235.0832, MAE: 4296.9780, R2: 0.0373\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1409/5000] | Time: 0.26s\n",
      "(Training) Loss: 1096030.2525\n",
      "(Validation) Loss: 1142007.8883, MAE: 4291.3818, R2: 0.0375\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1410/5000] | Time: 0.26s\n",
      "(Training) Loss: 1092513.9004\n",
      "(Validation) Loss: 1141789.3994, MAE: 4286.6890, R2: 0.0377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1411/5000] | Time: 0.25s\n",
      "(Training) Loss: 1127812.6282\n",
      "(Validation) Loss: 1141618.6413, MAE: 4291.6050, R2: 0.0378\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1412/5000] | Time: 0.29s\n",
      "(Training) Loss: 1103447.2989\n",
      "(Validation) Loss: 1141365.1048, MAE: 4283.3711, R2: 0.0381\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1413/5000] | Time: 0.25s\n",
      "(Training) Loss: 1101425.6358\n",
      "(Validation) Loss: 1141164.0787, MAE: 4285.3125, R2: 0.0382\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1414/5000] | Time: 0.24s\n",
      "(Training) Loss: 1090937.4702\n",
      "(Validation) Loss: 1140952.4317, MAE: 4282.5205, R2: 0.0384\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1415/5000] | Time: 0.22s\n",
      "(Training) Loss: 1105510.1028\n",
      "(Validation) Loss: 1140734.5321, MAE: 4282.0898, R2: 0.0386\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1416/5000] | Time: 0.22s\n",
      "(Training) Loss: 1097726.7418\n",
      "(Validation) Loss: 1140518.6590, MAE: 4279.9185, R2: 0.0388\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1417/5000] | Time: 0.23s\n",
      "(Training) Loss: 1088352.3425\n",
      "(Validation) Loss: 1140333.8514, MAE: 4286.1924, R2: 0.0389\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1418/5000] | Time: 0.23s\n",
      "(Training) Loss: 1118210.1383\n",
      "(Validation) Loss: 1140138.7632, MAE: 4283.9683, R2: 0.0391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1419/5000] | Time: 0.20s\n",
      "(Training) Loss: 1103318.0057\n",
      "(Validation) Loss: 1139952.8432, MAE: 4284.9087, R2: 0.0392\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1420/5000] | Time: 0.21s\n",
      "(Training) Loss: 1098142.6548\n",
      "(Validation) Loss: 1139715.0222, MAE: 4280.4458, R2: 0.0394\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1421/5000] | Time: 0.21s\n",
      "(Training) Loss: 1098074.0730\n",
      "(Validation) Loss: 1139520.9194, MAE: 4283.9268, R2: 0.0396\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1422/5000] | Time: 0.24s\n",
      "(Training) Loss: 1088383.5630\n",
      "(Validation) Loss: 1139297.9606, MAE: 4276.9121, R2: 0.0398\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1423/5000] | Time: 0.24s\n",
      "(Training) Loss: 1130504.8909\n",
      "(Validation) Loss: 1139092.1600, MAE: 4275.1719, R2: 0.0400\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1424/5000] | Time: 0.22s\n",
      "(Training) Loss: 1104842.5869\n",
      "(Validation) Loss: 1138882.1537, MAE: 4276.1401, R2: 0.0401\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1425/5000] | Time: 0.24s\n",
      "(Training) Loss: 1100621.0381\n",
      "(Validation) Loss: 1138710.3695, MAE: 4281.9707, R2: 0.0403\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1426/5000] | Time: 0.22s\n",
      "(Training) Loss: 1098538.5463\n",
      "(Validation) Loss: 1138465.8997, MAE: 4274.6411, R2: 0.0405\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1427/5000] | Time: 0.24s\n",
      "(Training) Loss: 1119332.0054\n",
      "(Validation) Loss: 1138292.5003, MAE: 4274.8232, R2: 0.0406\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1428/5000] | Time: 0.21s\n",
      "(Training) Loss: 1098510.2221\n",
      "(Validation) Loss: 1138102.2476, MAE: 4278.3291, R2: 0.0408\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1429/5000] | Time: 0.22s\n",
      "(Training) Loss: 1102860.9518\n",
      "(Validation) Loss: 1137922.2298, MAE: 4286.6621, R2: 0.0409\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1430/5000] | Time: 0.22s\n",
      "(Training) Loss: 1119108.6656\n",
      "(Validation) Loss: 1137671.8984, MAE: 4274.0469, R2: 0.0411\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1431/5000] | Time: 0.24s\n",
      "(Training) Loss: 1104384.3122\n",
      "(Validation) Loss: 1137458.5346, MAE: 4271.7026, R2: 0.0413\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1432/5000] | Time: 0.28s\n",
      "(Training) Loss: 1095076.4029\n",
      "(Validation) Loss: 1137256.6349, MAE: 4271.8936, R2: 0.0415\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1433/5000] | Time: 0.25s\n",
      "(Training) Loss: 1099371.5850\n",
      "(Validation) Loss: 1137058.2502, MAE: 4273.6709, R2: 0.0416\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1434/5000] | Time: 0.25s\n",
      "(Training) Loss: 1105196.8287\n",
      "(Validation) Loss: 1136839.4159, MAE: 4269.8374, R2: 0.0418\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1435/5000] | Time: 0.31s\n",
      "(Training) Loss: 1098561.0926\n",
      "(Validation) Loss: 1136630.2883, MAE: 4269.3374, R2: 0.0420\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1436/5000] | Time: 0.29s\n",
      "(Training) Loss: 1111116.4829\n",
      "(Validation) Loss: 1136433.3765, MAE: 4271.5205, R2: 0.0422\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1437/5000] | Time: 0.24s\n",
      "(Training) Loss: 1087300.9898\n",
      "(Validation) Loss: 1136219.5352, MAE: 4268.8442, R2: 0.0423\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1438/5000] | Time: 0.28s\n",
      "(Training) Loss: 1087746.5355\n",
      "(Validation) Loss: 1136014.8470, MAE: 4267.7935, R2: 0.0425\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1439/5000] | Time: 0.27s\n",
      "(Training) Loss: 1126985.5977\n",
      "(Validation) Loss: 1135815.1771, MAE: 4267.1123, R2: 0.0427\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1440/5000] | Time: 0.25s\n",
      "(Training) Loss: 1109304.7081\n",
      "(Validation) Loss: 1135605.1098, MAE: 4266.4775, R2: 0.0429\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1441/5000] | Time: 0.27s\n",
      "(Training) Loss: 1094397.7951\n",
      "(Validation) Loss: 1135393.2952, MAE: 4267.4141, R2: 0.0430\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1442/5000] | Time: 0.30s\n",
      "(Training) Loss: 1091567.7234\n",
      "(Validation) Loss: 1135184.9702, MAE: 4264.1953, R2: 0.0432\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1443/5000] | Time: 0.32s\n",
      "(Training) Loss: 1090765.0159\n",
      "(Validation) Loss: 1134984.3708, MAE: 4265.0742, R2: 0.0434\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1444/5000] | Time: 0.33s\n",
      "(Training) Loss: 1085863.4851\n",
      "(Validation) Loss: 1134810.5244, MAE: 4270.5557, R2: 0.0435\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1445/5000] | Time: 0.26s\n",
      "(Training) Loss: 1084151.1886\n",
      "(Validation) Loss: 1134596.9778, MAE: 4264.8979, R2: 0.0437\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1446/5000] | Time: 0.26s\n",
      "(Training) Loss: 1094808.5355\n",
      "(Validation) Loss: 1134390.3441, MAE: 4263.5889, R2: 0.0439\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1447/5000] | Time: 0.23s\n",
      "(Training) Loss: 1106823.2836\n",
      "(Validation) Loss: 1134186.1537, MAE: 4262.3057, R2: 0.0440\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1448/5000] | Time: 0.26s\n",
      "(Training) Loss: 1090297.0838\n",
      "(Validation) Loss: 1133981.7498, MAE: 4263.5933, R2: 0.0442\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1449/5000] | Time: 0.32s\n",
      "(Training) Loss: 1094629.6656\n",
      "(Validation) Loss: 1133773.5111, MAE: 4261.6504, R2: 0.0444\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1450/5000] | Time: 0.27s\n",
      "(Training) Loss: 1088944.1390\n",
      "(Validation) Loss: 1133566.5778, MAE: 4260.0054, R2: 0.0446\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1451/5000] | Time: 0.28s\n",
      "(Training) Loss: 1083620.4562\n",
      "(Validation) Loss: 1133365.7905, MAE: 4260.8550, R2: 0.0447\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1452/5000] | Time: 0.34s\n",
      "(Training) Loss: 1083613.8718\n",
      "(Validation) Loss: 1133155.9771, MAE: 4259.5630, R2: 0.0449\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1453/5000] | Time: 0.30s\n",
      "(Training) Loss: 1102635.0761\n",
      "(Validation) Loss: 1132990.9892, MAE: 4264.3110, R2: 0.0450\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1454/5000] | Time: 0.33s\n",
      "(Training) Loss: 1088878.6713\n",
      "(Validation) Loss: 1132755.2000, MAE: 4260.5693, R2: 0.0452\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1455/5000] | Time: 0.32s\n",
      "(Training) Loss: 1093606.4886\n",
      "(Validation) Loss: 1132543.3702, MAE: 4259.6865, R2: 0.0454\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1456/5000] | Time: 0.25s\n",
      "(Training) Loss: 1108540.7985\n",
      "(Validation) Loss: 1132335.4311, MAE: 4257.7949, R2: 0.0456\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1457/5000] | Time: 0.30s\n",
      "(Training) Loss: 1087735.8890\n",
      "(Validation) Loss: 1132130.3416, MAE: 4257.8916, R2: 0.0457\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1458/5000] | Time: 0.25s\n",
      "(Training) Loss: 1080541.1416\n",
      "(Validation) Loss: 1131920.9194, MAE: 4256.9897, R2: 0.0459\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1459/5000] | Time: 0.27s\n",
      "(Training) Loss: 1110676.8388\n",
      "(Validation) Loss: 1131716.1498, MAE: 4255.3384, R2: 0.0461\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1460/5000] | Time: 0.28s\n",
      "(Training) Loss: 1101015.9315\n",
      "(Validation) Loss: 1131508.4190, MAE: 4253.7085, R2: 0.0463\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1461/5000] | Time: 0.25s\n",
      "(Training) Loss: 1112234.9683\n",
      "(Validation) Loss: 1131300.7898, MAE: 4253.0806, R2: 0.0464\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1462/5000] | Time: 0.39s\n",
      "(Training) Loss: 1093646.6542\n",
      "(Validation) Loss: 1131094.1359, MAE: 4254.6084, R2: 0.0466\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1463/5000] | Time: 0.30s\n",
      "(Training) Loss: 1102605.7062\n",
      "(Validation) Loss: 1130834.5600, MAE: 4249.1357, R2: 0.0468\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1464/5000] | Time: 0.31s\n",
      "(Training) Loss: 1086668.4302\n",
      "(Validation) Loss: 1130644.0990, MAE: 4249.1460, R2: 0.0470\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1465/5000] | Time: 0.31s\n",
      "(Training) Loss: 1090505.5888\n",
      "(Validation) Loss: 1134948.2006, MAE: 4273.5034, R2: 0.0435\n",
      "==========================================================================================\n",
      "Epoch [1466/5000] | Time: 0.21s\n",
      "(Training) Loss: 1107050.2043\n",
      "(Validation) Loss: 1130234.5448, MAE: 4248.3462, R2: 0.0473\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1467/5000] | Time: 0.29s\n",
      "(Training) Loss: 1088430.9626\n",
      "(Validation) Loss: 1130029.7295, MAE: 4248.0171, R2: 0.0475\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1468/5000] | Time: 0.26s\n",
      "(Training) Loss: 1094300.9524\n",
      "(Validation) Loss: 1129856.2692, MAE: 4249.6455, R2: 0.0476\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1469/5000] | Time: 0.24s\n",
      "(Training) Loss: 1077962.7688\n",
      "(Validation) Loss: 1129659.9213, MAE: 4250.0996, R2: 0.0478\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1470/5000] | Time: 0.23s\n",
      "(Training) Loss: 1099151.8445\n",
      "(Validation) Loss: 1129454.4152, MAE: 4248.1538, R2: 0.0480\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1471/5000] | Time: 0.22s\n",
      "(Training) Loss: 1098946.2005\n",
      "(Validation) Loss: 1129274.3619, MAE: 4249.4614, R2: 0.0481\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1472/5000] | Time: 0.24s\n",
      "(Training) Loss: 1084233.2468\n",
      "(Validation) Loss: 1129042.7276, MAE: 4248.6011, R2: 0.0483\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1473/5000] | Time: 0.22s\n",
      "(Training) Loss: 1092503.2602\n",
      "(Validation) Loss: 1128825.8337, MAE: 4244.4053, R2: 0.0485\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1474/5000] | Time: 0.22s\n",
      "(Training) Loss: 1088602.5184\n",
      "(Validation) Loss: 1128628.5105, MAE: 4246.5112, R2: 0.0487\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1475/5000] | Time: 0.21s\n",
      "(Training) Loss: 1108472.7779\n",
      "(Validation) Loss: 1128423.4819, MAE: 4244.5659, R2: 0.0488\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1476/5000] | Time: 0.20s\n",
      "(Training) Loss: 1084503.8585\n",
      "(Validation) Loss: 1128211.3575, MAE: 4243.6450, R2: 0.0490\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1477/5000] | Time: 0.23s\n",
      "(Training) Loss: 1094342.9772\n",
      "(Validation) Loss: 1128009.3206, MAE: 4243.4746, R2: 0.0492\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1478/5000] | Time: 0.21s\n",
      "(Training) Loss: 1094492.3192\n",
      "(Validation) Loss: 1127809.7778, MAE: 4244.5342, R2: 0.0493\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1479/5000] | Time: 0.33s\n",
      "(Training) Loss: 1094350.5102\n",
      "(Validation) Loss: 1127603.8298, MAE: 4243.4116, R2: 0.0495\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1480/5000] | Time: 0.23s\n",
      "(Training) Loss: 1097176.2494\n",
      "(Validation) Loss: 1127388.1651, MAE: 4239.5928, R2: 0.0497\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1481/5000] | Time: 0.19s\n",
      "(Training) Loss: 1087592.4131\n",
      "(Validation) Loss: 1127212.5308, MAE: 4242.7827, R2: 0.0498\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1482/5000] | Time: 0.19s\n",
      "(Training) Loss: 1114357.2145\n",
      "(Validation) Loss: 1127000.7467, MAE: 4243.0610, R2: 0.0500\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1483/5000] | Time: 0.70s\n",
      "(Training) Loss: 1085518.7246\n",
      "(Validation) Loss: 1126804.0838, MAE: 4241.2329, R2: 0.0502\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1484/5000] | Time: 0.28s\n",
      "(Training) Loss: 1089516.2132\n",
      "(Validation) Loss: 1126568.1575, MAE: 4239.5103, R2: 0.0504\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1485/5000] | Time: 0.39s\n",
      "(Training) Loss: 1075412.6161\n",
      "(Validation) Loss: 1126362.0724, MAE: 4237.8242, R2: 0.0506\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1486/5000] | Time: 0.73s\n",
      "(Training) Loss: 1079296.7132\n",
      "(Validation) Loss: 1126159.1111, MAE: 4237.1094, R2: 0.0507\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1487/5000] | Time: 0.76s\n",
      "(Training) Loss: 1087928.0133\n",
      "(Validation) Loss: 1125957.7397, MAE: 4236.9697, R2: 0.0509\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1488/5000] | Time: 0.76s\n",
      "(Training) Loss: 1084036.2684\n",
      "(Validation) Loss: 1125751.5022, MAE: 4235.1333, R2: 0.0511\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1489/5000] | Time: 0.82s\n",
      "(Training) Loss: 1086394.7678\n",
      "(Validation) Loss: 1125544.6044, MAE: 4233.5117, R2: 0.0512\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1490/5000] | Time: 0.80s\n",
      "(Training) Loss: 1074950.5539\n",
      "(Validation) Loss: 1125342.2476, MAE: 4234.2202, R2: 0.0514\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1491/5000] | Time: 0.70s\n",
      "(Training) Loss: 1083574.7944\n",
      "(Validation) Loss: 1125177.3511, MAE: 4234.6377, R2: 0.0515\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1492/5000] | Time: 0.41s\n",
      "(Training) Loss: 1100903.0051\n",
      "(Validation) Loss: 1124931.8502, MAE: 4231.9331, R2: 0.0517\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1493/5000] | Time: 0.73s\n",
      "(Training) Loss: 1079134.3357\n",
      "(Validation) Loss: 1124737.2800, MAE: 4235.1973, R2: 0.0519\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1494/5000] | Time: 0.70s\n",
      "(Training) Loss: 1089899.0812\n",
      "(Validation) Loss: 1124527.3092, MAE: 4233.4170, R2: 0.0521\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1495/5000] | Time: 0.80s\n",
      "(Training) Loss: 1086899.9778\n",
      "(Validation) Loss: 1124313.9708, MAE: 4228.8081, R2: 0.0523\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1496/5000] | Time: 0.74s\n",
      "(Training) Loss: 1082032.5793\n",
      "(Validation) Loss: 1124107.4184, MAE: 4228.7461, R2: 0.0524\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1497/5000] | Time: 0.72s\n",
      "(Training) Loss: 1079855.9879\n",
      "(Validation) Loss: 1123906.7632, MAE: 4229.0781, R2: 0.0526\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1498/5000] | Time: 0.72s\n",
      "(Training) Loss: 1087179.3350\n",
      "(Validation) Loss: 1123703.2381, MAE: 4227.2012, R2: 0.0528\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1499/5000] | Time: 0.75s\n",
      "(Training) Loss: 1084422.6066\n",
      "(Validation) Loss: 1123497.4273, MAE: 4228.8833, R2: 0.0529\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1500/5000] | Time: 0.76s\n",
      "(Training) Loss: 1093096.3452\n",
      "(Validation) Loss: 1123303.7308, MAE: 4229.0049, R2: 0.0531\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch1500.pth\n",
      "==========================================================================================\n",
      "Epoch [1501/5000] | Time: 0.84s\n",
      "(Training) Loss: 1090860.5552\n",
      "(Validation) Loss: 1123055.8933, MAE: 4224.3110, R2: 0.0533\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1502/5000] | Time: 0.91s\n",
      "(Training) Loss: 1103392.8344\n",
      "(Validation) Loss: 1122878.2425, MAE: 4225.6528, R2: 0.0535\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1503/5000] | Time: 0.81s\n",
      "(Training) Loss: 1082002.0431\n",
      "(Validation) Loss: 1122635.7943, MAE: 4224.0142, R2: 0.0537\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1504/5000] | Time: 0.78s\n",
      "(Training) Loss: 1096387.2341\n",
      "(Validation) Loss: 1122452.8000, MAE: 4226.2524, R2: 0.0538\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1505/5000] | Time: 0.73s\n",
      "(Training) Loss: 1075406.7259\n",
      "(Validation) Loss: 1122233.1327, MAE: 4220.7690, R2: 0.0540\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1506/5000] | Time: 0.80s\n",
      "(Training) Loss: 1080978.0324\n",
      "(Validation) Loss: 1122018.5346, MAE: 4222.8433, R2: 0.0542\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1507/5000] | Time: 0.71s\n",
      "(Training) Loss: 1078957.2107\n",
      "(Validation) Loss: 1121810.5244, MAE: 4218.8667, R2: 0.0543\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1508/5000] | Time: 0.67s\n",
      "(Training) Loss: 1098736.7164\n",
      "(Validation) Loss: 1121606.3340, MAE: 4217.0596, R2: 0.0545\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1509/5000] | Time: 0.72s\n",
      "(Training) Loss: 1088778.2595\n",
      "(Validation) Loss: 1121403.3321, MAE: 4218.2778, R2: 0.0547\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1510/5000] | Time: 0.78s\n",
      "(Training) Loss: 1082628.8109\n",
      "(Validation) Loss: 1121191.7816, MAE: 4214.6348, R2: 0.0549\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1511/5000] | Time: 0.61s\n",
      "(Training) Loss: 1076725.3534\n",
      "(Validation) Loss: 1120994.2908, MAE: 4216.5356, R2: 0.0550\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1512/5000] | Time: 0.33s\n",
      "(Training) Loss: 1110800.2075\n",
      "(Validation) Loss: 1120790.0952, MAE: 4214.0596, R2: 0.0552\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1513/5000] | Time: 0.28s\n",
      "(Training) Loss: 1084078.3985\n",
      "(Validation) Loss: 1120598.2375, MAE: 4216.0400, R2: 0.0554\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1514/5000] | Time: 0.28s\n",
      "(Training) Loss: 1092144.7110\n",
      "(Validation) Loss: 1120375.3651, MAE: 4213.5386, R2: 0.0555\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1515/5000] | Time: 0.36s\n",
      "(Training) Loss: 1082678.0673\n",
      "(Validation) Loss: 1120166.4254, MAE: 4211.2998, R2: 0.0557\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1516/5000] | Time: 0.28s\n",
      "(Training) Loss: 1086910.7944\n",
      "(Validation) Loss: 1119965.9987, MAE: 4212.6821, R2: 0.0559\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1517/5000] | Time: 0.78s\n",
      "(Training) Loss: 1076982.0990\n",
      "(Validation) Loss: 1119773.5975, MAE: 4210.9688, R2: 0.0560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1518/5000] | Time: 0.82s\n",
      "(Training) Loss: 1096553.3344\n",
      "(Validation) Loss: 1119573.0438, MAE: 4211.5127, R2: 0.0562\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1519/5000] | Time: 0.92s\n",
      "(Training) Loss: 1076396.7811\n",
      "(Validation) Loss: 1119370.4025, MAE: 4211.2607, R2: 0.0564\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1520/5000] | Time: 0.63s\n",
      "(Training) Loss: 1068672.7148\n",
      "(Validation) Loss: 1119181.9479, MAE: 4211.7710, R2: 0.0565\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1521/5000] | Time: 0.31s\n",
      "(Training) Loss: 1068357.9761\n",
      "(Validation) Loss: 1119007.8476, MAE: 4213.3950, R2: 0.0567\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1522/5000] | Time: 0.28s\n",
      "(Training) Loss: 1078020.4714\n",
      "(Validation) Loss: 1118808.3149, MAE: 4213.8481, R2: 0.0568\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1523/5000] | Time: 0.29s\n",
      "(Training) Loss: 1090601.8883\n",
      "(Validation) Loss: 1118609.8692, MAE: 4215.1401, R2: 0.0570\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1524/5000] | Time: 0.26s\n",
      "(Training) Loss: 1086330.8832\n",
      "(Validation) Loss: 1118426.9917, MAE: 4213.5171, R2: 0.0572\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1525/5000] | Time: 0.29s\n",
      "(Training) Loss: 1075102.3541\n",
      "(Validation) Loss: 1118237.3130, MAE: 4216.6602, R2: 0.0573\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1526/5000] | Time: 0.30s\n",
      "(Training) Loss: 1078959.4816\n",
      "(Validation) Loss: 1118024.1321, MAE: 4213.8594, R2: 0.0575\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1527/5000] | Time: 0.28s\n",
      "(Training) Loss: 1097412.6529\n",
      "(Validation) Loss: 1117817.8946, MAE: 4212.7437, R2: 0.0577\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1528/5000] | Time: 0.27s\n",
      "(Training) Loss: 1079265.2398\n",
      "(Validation) Loss: 1117610.5448, MAE: 4212.1763, R2: 0.0578\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1529/5000] | Time: 0.30s\n",
      "(Training) Loss: 1074013.6377\n",
      "(Validation) Loss: 1117411.4083, MAE: 4211.8164, R2: 0.0580\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1530/5000] | Time: 0.30s\n",
      "(Training) Loss: 1075065.5400\n",
      "(Validation) Loss: 1117204.2768, MAE: 4211.0669, R2: 0.0582\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1531/5000] | Time: 0.30s\n",
      "(Training) Loss: 1066742.9095\n",
      "(Validation) Loss: 1117002.8241, MAE: 4209.4141, R2: 0.0583\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1532/5000] | Time: 0.28s\n",
      "(Training) Loss: 1087256.1789\n",
      "(Validation) Loss: 1116797.4603, MAE: 4208.4458, R2: 0.0585\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1533/5000] | Time: 0.30s\n",
      "(Training) Loss: 1077022.6599\n",
      "(Validation) Loss: 1116592.8076, MAE: 4209.2456, R2: 0.0587\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1534/5000] | Time: 0.29s\n",
      "(Training) Loss: 1094027.2817\n",
      "(Validation) Loss: 1116389.0844, MAE: 4207.6753, R2: 0.0589\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1535/5000] | Time: 0.31s\n",
      "(Training) Loss: 1079542.2982\n",
      "(Validation) Loss: 1116182.3187, MAE: 4206.5098, R2: 0.0590\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1536/5000] | Time: 0.32s\n",
      "(Training) Loss: 1088954.3744\n",
      "(Validation) Loss: 1115997.2978, MAE: 4210.3369, R2: 0.0592\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1537/5000] | Time: 0.28s\n",
      "(Training) Loss: 1075858.7411\n",
      "(Validation) Loss: 1115806.9638, MAE: 4206.8164, R2: 0.0593\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1538/5000] | Time: 0.28s\n",
      "(Training) Loss: 1101736.6669\n",
      "(Validation) Loss: 1115599.1568, MAE: 4207.3833, R2: 0.0595\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1539/5000] | Time: 0.27s\n",
      "(Training) Loss: 1078368.1548\n",
      "(Validation) Loss: 1115375.2076, MAE: 4206.3940, R2: 0.0597\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1540/5000] | Time: 0.30s\n",
      "(Training) Loss: 1092375.5590\n",
      "(Validation) Loss: 1115163.8857, MAE: 4203.5225, R2: 0.0599\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1541/5000] | Time: 0.33s\n",
      "(Training) Loss: 1083695.5184\n",
      "(Validation) Loss: 1114958.2578, MAE: 4202.7627, R2: 0.0601\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1542/5000] | Time: 0.31s\n",
      "(Training) Loss: 1070888.1009\n",
      "(Validation) Loss: 1114755.5454, MAE: 4203.0449, R2: 0.0602\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1543/5000] | Time: 0.25s\n",
      "(Training) Loss: 1074518.1332\n",
      "(Validation) Loss: 1114560.1727, MAE: 4203.4912, R2: 0.0604\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1544/5000] | Time: 0.26s\n",
      "(Training) Loss: 1085578.9220\n",
      "(Validation) Loss: 1114355.7841, MAE: 4203.1782, R2: 0.0606\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1545/5000] | Time: 0.26s\n",
      "(Training) Loss: 1078512.7221\n",
      "(Validation) Loss: 1114109.7498, MAE: 4196.5879, R2: 0.0608\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1546/5000] | Time: 0.28s\n",
      "(Training) Loss: 1084766.1751\n",
      "(Validation) Loss: 1113964.5816, MAE: 4201.4639, R2: 0.0609\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1547/5000] | Time: 0.25s\n",
      "(Training) Loss: 1081665.4505\n",
      "(Validation) Loss: 1113739.5759, MAE: 4200.0928, R2: 0.0611\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1548/5000] | Time: 0.30s\n",
      "(Training) Loss: 1073995.2310\n",
      "(Validation) Loss: 1113537.2190, MAE: 4199.4624, R2: 0.0612\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1549/5000] | Time: 0.26s\n",
      "(Training) Loss: 1076155.0235\n",
      "(Validation) Loss: 1113327.4210, MAE: 4197.3599, R2: 0.0614\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1550/5000] | Time: 0.26s\n",
      "(Training) Loss: 1071245.2373\n",
      "(Validation) Loss: 1113128.6248, MAE: 4197.8452, R2: 0.0616\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1551/5000] | Time: 0.26s\n",
      "(Training) Loss: 1072633.5025\n",
      "(Validation) Loss: 1112924.5511, MAE: 4196.3843, R2: 0.0617\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1552/5000] | Time: 0.25s\n",
      "(Training) Loss: 1080710.2690\n",
      "(Validation) Loss: 1112721.9657, MAE: 4195.5073, R2: 0.0619\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1553/5000] | Time: 0.26s\n",
      "(Training) Loss: 1093755.0831\n",
      "(Validation) Loss: 1112517.6990, MAE: 4194.4185, R2: 0.0621\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1554/5000] | Time: 0.32s\n",
      "(Training) Loss: 1070593.1612\n",
      "(Validation) Loss: 1112319.3092, MAE: 4194.5322, R2: 0.0622\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1555/5000] | Time: 0.28s\n",
      "(Training) Loss: 1064978.6846\n",
      "(Validation) Loss: 1112129.3663, MAE: 4198.8599, R2: 0.0624\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1556/5000] | Time: 0.27s\n",
      "(Training) Loss: 1083409.9492\n",
      "(Validation) Loss: 1111950.0190, MAE: 4196.4087, R2: 0.0626\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1557/5000] | Time: 0.31s\n",
      "(Training) Loss: 1073170.8426\n",
      "(Validation) Loss: 1111745.5543, MAE: 4195.1465, R2: 0.0627\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1558/5000] | Time: 0.30s\n",
      "(Training) Loss: 1086663.9131\n",
      "(Validation) Loss: 1111538.7073, MAE: 4194.9404, R2: 0.0629\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1559/5000] | Time: 0.27s\n",
      "(Training) Loss: 1070182.4829\n",
      "(Validation) Loss: 1111338.1029, MAE: 4194.7290, R2: 0.0631\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1560/5000] | Time: 0.28s\n",
      "(Training) Loss: 1072852.6701\n",
      "(Validation) Loss: 1111136.7060, MAE: 4194.1938, R2: 0.0632\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1561/5000] | Time: 0.28s\n",
      "(Training) Loss: 1061809.1948\n",
      "(Validation) Loss: 1110936.0711, MAE: 4193.8965, R2: 0.0634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1562/5000] | Time: 0.43s\n",
      "(Training) Loss: 1103787.0558\n",
      "(Validation) Loss: 1116061.1149, MAE: 4214.7109, R2: 0.0591\n",
      "==========================================================================================\n",
      "Epoch [1563/5000] | Time: 0.26s\n",
      "(Training) Loss: 1088751.8471\n",
      "(Validation) Loss: 1110532.5054, MAE: 4193.5430, R2: 0.0637\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1564/5000] | Time: 0.25s\n",
      "(Training) Loss: 1082150.8109\n",
      "(Validation) Loss: 1110324.5460, MAE: 4193.0342, R2: 0.0639\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1565/5000] | Time: 0.28s\n",
      "(Training) Loss: 1085227.9213\n",
      "(Validation) Loss: 1110123.1898, MAE: 4191.1201, R2: 0.0641\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1566/5000] | Time: 0.28s\n",
      "(Training) Loss: 1084643.6136\n",
      "(Validation) Loss: 1109921.2749, MAE: 4190.6230, R2: 0.0642\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1567/5000] | Time: 0.38s\n",
      "(Training) Loss: 1063757.7900\n",
      "(Validation) Loss: 1109718.1663, MAE: 4189.1665, R2: 0.0644\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1568/5000] | Time: 0.24s\n",
      "(Training) Loss: 1080334.3953\n",
      "(Validation) Loss: 1109516.9168, MAE: 4189.0645, R2: 0.0646\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1569/5000] | Time: 0.27s\n",
      "(Training) Loss: 1102706.0013\n",
      "(Validation) Loss: 1109308.5156, MAE: 4187.3057, R2: 0.0648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1570/5000] | Time: 0.25s\n",
      "(Training) Loss: 1080677.7944\n",
      "(Validation) Loss: 1109104.0508, MAE: 4186.2432, R2: 0.0649\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1571/5000] | Time: 0.24s\n",
      "(Training) Loss: 1064622.5876\n",
      "(Validation) Loss: 1108904.8229, MAE: 4186.7065, R2: 0.0651\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1572/5000] | Time: 0.26s\n",
      "(Training) Loss: 1069181.0374\n",
      "(Validation) Loss: 1108702.6844, MAE: 4186.0913, R2: 0.0653\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1573/5000] | Time: 0.23s\n",
      "(Training) Loss: 1068235.2246\n",
      "(Validation) Loss: 1108520.2083, MAE: 4193.2021, R2: 0.0654\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1574/5000] | Time: 0.24s\n",
      "(Training) Loss: 1059477.0823\n",
      "(Validation) Loss: 1108298.7530, MAE: 4185.8926, R2: 0.0656\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1575/5000] | Time: 0.31s\n",
      "(Training) Loss: 1076598.4461\n",
      "(Validation) Loss: 1108102.8419, MAE: 4184.9600, R2: 0.0658\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1576/5000] | Time: 0.31s\n",
      "(Training) Loss: 1064064.3179\n",
      "(Validation) Loss: 1107902.3898, MAE: 4183.2471, R2: 0.0659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1577/5000] | Time: 0.25s\n",
      "(Training) Loss: 1058564.7070\n",
      "(Validation) Loss: 1107698.2705, MAE: 4182.9438, R2: 0.0661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1578/5000] | Time: 0.26s\n",
      "(Training) Loss: 1064444.9277\n",
      "(Validation) Loss: 1107490.1892, MAE: 4180.5576, R2: 0.0663\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1579/5000] | Time: 0.26s\n",
      "(Training) Loss: 1070517.0774\n",
      "(Validation) Loss: 1107337.7473, MAE: 4183.8794, R2: 0.0664\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1580/5000] | Time: 0.54s\n",
      "(Training) Loss: 1085410.7576\n",
      "(Validation) Loss: 1107103.3346, MAE: 4183.3989, R2: 0.0666\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1581/5000] | Time: 0.35s\n",
      "(Training) Loss: 1059202.8997\n",
      "(Validation) Loss: 1106889.8184, MAE: 4180.2358, R2: 0.0668\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1582/5000] | Time: 0.31s\n",
      "(Training) Loss: 1074582.1345\n",
      "(Validation) Loss: 1106683.5606, MAE: 4177.7837, R2: 0.0669\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1583/5000] | Time: 0.29s\n",
      "(Training) Loss: 1062683.7208\n",
      "(Validation) Loss: 1106482.2857, MAE: 4177.0693, R2: 0.0671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1584/5000] | Time: 0.29s\n",
      "(Training) Loss: 1072598.4010\n",
      "(Validation) Loss: 1106284.8102, MAE: 4178.1357, R2: 0.0673\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1585/5000] | Time: 0.37s\n",
      "(Training) Loss: 1081450.4340\n",
      "(Validation) Loss: 1106076.3175, MAE: 4175.5195, R2: 0.0674\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1586/5000] | Time: 0.74s\n",
      "(Training) Loss: 1065692.5806\n",
      "(Validation) Loss: 1105878.3695, MAE: 4175.5312, R2: 0.0676\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1587/5000] | Time: 0.57s\n",
      "(Training) Loss: 1059370.9695\n",
      "(Validation) Loss: 1105671.7460, MAE: 4172.8955, R2: 0.0678\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1588/5000] | Time: 0.83s\n",
      "(Training) Loss: 1079549.8211\n",
      "(Validation) Loss: 1105474.7530, MAE: 4174.6631, R2: 0.0680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1589/5000] | Time: 0.84s\n",
      "(Training) Loss: 1062761.1935\n",
      "(Validation) Loss: 1105282.1283, MAE: 4174.8174, R2: 0.0681\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1590/5000] | Time: 0.92s\n",
      "(Training) Loss: 1061671.8217\n",
      "(Validation) Loss: 1105083.8298, MAE: 4177.3589, R2: 0.0683\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1591/5000] | Time: 0.91s\n",
      "(Training) Loss: 1057275.2088\n",
      "(Validation) Loss: 1104909.4603, MAE: 4174.3345, R2: 0.0684\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1592/5000] | Time: 0.77s\n",
      "(Training) Loss: 1058522.2747\n",
      "(Validation) Loss: 1104712.8432, MAE: 4174.3516, R2: 0.0686\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1593/5000] | Time: 0.32s\n",
      "(Training) Loss: 1063965.0999\n",
      "(Validation) Loss: 1104529.2089, MAE: 4177.0811, R2: 0.0687\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1594/5000] | Time: 0.25s\n",
      "(Training) Loss: 1076059.6916\n",
      "(Validation) Loss: 1104305.9403, MAE: 4172.0679, R2: 0.0689\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1595/5000] | Time: 0.21s\n",
      "(Training) Loss: 1074608.3077\n",
      "(Validation) Loss: 1104102.8521, MAE: 4170.8711, R2: 0.0691\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1596/5000] | Time: 0.27s\n",
      "(Training) Loss: 1059442.5787\n",
      "(Validation) Loss: 1103900.0229, MAE: 4170.4985, R2: 0.0693\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1597/5000] | Time: 0.25s\n",
      "(Training) Loss: 1055144.5025\n",
      "(Validation) Loss: 1103702.6641, MAE: 4170.6548, R2: 0.0694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1598/5000] | Time: 0.24s\n",
      "(Training) Loss: 1062223.4549\n",
      "(Validation) Loss: 1103504.7670, MAE: 4170.0640, R2: 0.0696\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1599/5000] | Time: 0.23s\n",
      "(Training) Loss: 1064575.2481\n",
      "(Validation) Loss: 1103301.1454, MAE: 4170.1064, R2: 0.0698\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1600/5000] | Time: 0.26s\n",
      "(Training) Loss: 1058956.6567\n",
      "(Validation) Loss: 1103094.8419, MAE: 4167.2456, R2: 0.0699\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1601/5000] | Time: 0.23s\n",
      "(Training) Loss: 1058580.6060\n",
      "(Validation) Loss: 1102893.7600, MAE: 4166.6431, R2: 0.0701\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1602/5000] | Time: 0.30s\n",
      "(Training) Loss: 1057546.3668\n",
      "(Validation) Loss: 1102696.0610, MAE: 4167.0640, R2: 0.0703\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1603/5000] | Time: 0.31s\n",
      "(Training) Loss: 1067266.7088\n",
      "(Validation) Loss: 1102492.7238, MAE: 4165.3276, R2: 0.0704\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1604/5000] | Time: 0.30s\n",
      "(Training) Loss: 1077826.5711\n",
      "(Validation) Loss: 1102289.4781, MAE: 4165.4106, R2: 0.0706\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1605/5000] | Time: 0.26s\n",
      "(Training) Loss: 1070981.2931\n",
      "(Validation) Loss: 1102089.0159, MAE: 4165.4175, R2: 0.0708\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1606/5000] | Time: 0.25s\n",
      "(Training) Loss: 1076523.1999\n",
      "(Validation) Loss: 1098503.3498, MAE: 4155.3467, R2: 0.0738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1607/5000] | Time: 0.27s\n",
      "(Training) Loss: 1052028.0089\n",
      "(Validation) Loss: 1098300.3073, MAE: 4152.9043, R2: 0.0739\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1608/5000] | Time: 0.23s\n",
      "(Training) Loss: 1053026.8420\n",
      "(Validation) Loss: 1098076.3886, MAE: 4152.4053, R2: 0.0741\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1609/5000] | Time: 0.22s\n",
      "(Training) Loss: 1056028.1662\n",
      "(Validation) Loss: 1097877.9378, MAE: 4150.9053, R2: 0.0743\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1610/5000] | Time: 0.22s\n",
      "(Training) Loss: 1076868.3598\n",
      "(Validation) Loss: 1097680.3810, MAE: 4150.0269, R2: 0.0744\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1611/5000] | Time: 0.22s\n",
      "(Training) Loss: 1079908.3033\n",
      "(Validation) Loss: 1097452.7238, MAE: 4145.5225, R2: 0.0746\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1612/5000] | Time: 0.48s\n",
      "(Training) Loss: 1054088.9334\n",
      "(Validation) Loss: 1097253.4400, MAE: 4145.4775, R2: 0.0748\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1613/5000] | Time: 0.24s\n",
      "(Training) Loss: 1054091.9657\n",
      "(Validation) Loss: 1097064.1930, MAE: 4152.8726, R2: 0.0750\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1614/5000] | Time: 0.25s\n",
      "(Training) Loss: 1058278.7931\n",
      "(Validation) Loss: 1096897.0108, MAE: 4148.6357, R2: 0.0751\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1615/5000] | Time: 0.24s\n",
      "(Training) Loss: 1049138.0068\n",
      "(Validation) Loss: 1096690.0063, MAE: 4144.3330, R2: 0.0753\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1616/5000] | Time: 0.24s\n",
      "(Training) Loss: 1051801.1206\n",
      "(Validation) Loss: 1096493.9683, MAE: 4144.0903, R2: 0.0754\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1617/5000] | Time: 0.22s\n",
      "(Training) Loss: 1048605.6196\n",
      "(Validation) Loss: 1096298.5549, MAE: 4143.5400, R2: 0.0756\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1618/5000] | Time: 0.23s\n",
      "(Training) Loss: 1060625.0533\n",
      "(Validation) Loss: 1096118.5930, MAE: 4145.8823, R2: 0.0757\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1619/5000] | Time: 0.22s\n",
      "(Training) Loss: 1053392.3115\n",
      "(Validation) Loss: 1095906.9714, MAE: 4140.7783, R2: 0.0759\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1620/5000] | Time: 0.23s\n",
      "(Training) Loss: 1053555.4359\n",
      "(Validation) Loss: 1095712.7010, MAE: 4140.3506, R2: 0.0761\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1621/5000] | Time: 0.22s\n",
      "(Training) Loss: 1056444.6402\n",
      "(Validation) Loss: 1095516.2971, MAE: 4139.1792, R2: 0.0762\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1622/5000] | Time: 0.25s\n",
      "(Training) Loss: 1058056.7525\n",
      "(Validation) Loss: 1095321.8286, MAE: 4139.7554, R2: 0.0764\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1623/5000] | Time: 0.23s\n",
      "(Training) Loss: 1052126.5108\n",
      "(Validation) Loss: 1095149.1962, MAE: 4145.5356, R2: 0.0766\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1624/5000] | Time: 0.21s\n",
      "(Training) Loss: 1059804.8871\n",
      "(Validation) Loss: 1094927.6648, MAE: 4137.9419, R2: 0.0767\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1625/5000] | Time: 0.27s\n",
      "(Training) Loss: 1056813.8585\n",
      "(Validation) Loss: 1094732.7340, MAE: 4138.2373, R2: 0.0769\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1626/5000] | Time: 0.25s\n",
      "(Training) Loss: 1059753.3338\n",
      "(Validation) Loss: 1094532.7695, MAE: 4135.5430, R2: 0.0771\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1627/5000] | Time: 0.26s\n",
      "(Training) Loss: 1057660.6434\n",
      "(Validation) Loss: 1094348.9575, MAE: 4138.5161, R2: 0.0772\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1628/5000] | Time: 0.29s\n",
      "(Training) Loss: 1048486.0121\n",
      "(Validation) Loss: 1094167.2178, MAE: 4143.4790, R2: 0.0774\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1629/5000] | Time: 0.27s\n",
      "(Training) Loss: 1065396.0133\n",
      "(Validation) Loss: 1093948.0838, MAE: 4135.0225, R2: 0.0776\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1630/5000] | Time: 0.26s\n",
      "(Training) Loss: 1079637.9708\n",
      "(Validation) Loss: 1093746.2197, MAE: 4131.4805, R2: 0.0777\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1631/5000] | Time: 0.29s\n",
      "(Training) Loss: 1056915.2113\n",
      "(Validation) Loss: 1093555.0222, MAE: 4133.5293, R2: 0.0779\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1632/5000] | Time: 0.27s\n",
      "(Training) Loss: 1047637.2611\n",
      "(Validation) Loss: 1093360.5079, MAE: 4133.2759, R2: 0.0780\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1633/5000] | Time: 0.25s\n",
      "(Training) Loss: 1052036.2081\n",
      "(Validation) Loss: 1093156.8356, MAE: 4130.8101, R2: 0.0782\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1634/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046300.9689\n",
      "(Validation) Loss: 1092963.0781, MAE: 4130.3809, R2: 0.0784\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1635/5000] | Time: 0.30s\n",
      "(Training) Loss: 1071628.2963\n",
      "(Validation) Loss: 1092777.4070, MAE: 4130.8608, R2: 0.0785\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1636/5000] | Time: 0.24s\n",
      "(Training) Loss: 1065259.8668\n",
      "(Validation) Loss: 1092569.9860, MAE: 4129.0083, R2: 0.0787\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1637/5000] | Time: 0.23s\n",
      "(Training) Loss: 1043851.2635\n",
      "(Validation) Loss: 1092375.8425, MAE: 4129.0698, R2: 0.0789\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1638/5000] | Time: 0.24s\n",
      "(Training) Loss: 1083980.1802\n",
      "(Validation) Loss: 1092184.8990, MAE: 4128.1890, R2: 0.0790\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1639/5000] | Time: 0.24s\n",
      "(Training) Loss: 1085105.3991\n",
      "(Validation) Loss: 1091983.9644, MAE: 4127.1685, R2: 0.0792\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1640/5000] | Time: 0.24s\n",
      "(Training) Loss: 1044324.3717\n",
      "(Validation) Loss: 1091790.2629, MAE: 4127.6899, R2: 0.0794\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1641/5000] | Time: 0.22s\n",
      "(Training) Loss: 1050804.2868\n",
      "(Validation) Loss: 1091610.7632, MAE: 4129.1924, R2: 0.0795\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1642/5000] | Time: 0.20s\n",
      "(Training) Loss: 1059759.2970\n",
      "(Validation) Loss: 1091396.0330, MAE: 4126.0542, R2: 0.0797\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1643/5000] | Time: 0.22s\n",
      "(Training) Loss: 1045309.7011\n",
      "(Validation) Loss: 1091207.3143, MAE: 4126.6230, R2: 0.0798\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1644/5000] | Time: 0.23s\n",
      "(Training) Loss: 1082557.8769\n",
      "(Validation) Loss: 1090998.6387, MAE: 4124.0840, R2: 0.0800\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1645/5000] | Time: 0.26s\n",
      "(Training) Loss: 1059373.7329\n",
      "(Validation) Loss: 1090807.8679, MAE: 4123.8052, R2: 0.0802\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1646/5000] | Time: 0.22s\n",
      "(Training) Loss: 1066021.8915\n",
      "(Validation) Loss: 1090606.1359, MAE: 4121.9907, R2: 0.0803\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1647/5000] | Time: 0.24s\n",
      "(Training) Loss: 1052370.4708\n",
      "(Validation) Loss: 1090413.9225, MAE: 4121.6494, R2: 0.0805\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1648/5000] | Time: 0.23s\n",
      "(Training) Loss: 1047176.6015\n",
      "(Validation) Loss: 1090219.9010, MAE: 4122.0527, R2: 0.0807\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1649/5000] | Time: 0.28s\n",
      "(Training) Loss: 1064939.7189\n",
      "(Validation) Loss: 1090022.7911, MAE: 4120.1938, R2: 0.0808\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1650/5000] | Time: 0.27s\n",
      "(Training) Loss: 1068905.7716\n",
      "(Validation) Loss: 1089826.1638, MAE: 4119.6152, R2: 0.0810\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1651/5000] | Time: 0.32s\n",
      "(Training) Loss: 1053079.2176\n",
      "(Validation) Loss: 1089631.8425, MAE: 4119.7744, R2: 0.0812\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1652/5000] | Time: 0.30s\n",
      "(Training) Loss: 1054549.0831\n",
      "(Validation) Loss: 1089428.7797, MAE: 4117.2383, R2: 0.0813\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1653/5000] | Time: 0.28s\n",
      "(Training) Loss: 1050464.1345\n",
      "(Validation) Loss: 1089240.2540, MAE: 4118.2051, R2: 0.0815\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1654/5000] | Time: 0.28s\n",
      "(Training) Loss: 1052278.8008\n",
      "(Validation) Loss: 1089040.8229, MAE: 4116.8135, R2: 0.0816\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1655/5000] | Time: 0.32s\n",
      "(Training) Loss: 1045607.8490\n",
      "(Validation) Loss: 1088848.5638, MAE: 4116.7344, R2: 0.0818\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1656/5000] | Time: 0.33s\n",
      "(Training) Loss: 1041921.3093\n",
      "(Validation) Loss: 1088652.3581, MAE: 4116.7173, R2: 0.0820\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1657/5000] | Time: 0.31s\n",
      "(Training) Loss: 1046528.8750\n",
      "(Validation) Loss: 1088459.5352, MAE: 4114.4023, R2: 0.0821\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1658/5000] | Time: 0.31s\n",
      "(Training) Loss: 1052295.8484\n",
      "(Validation) Loss: 1088271.8171, MAE: 4116.3813, R2: 0.0823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1659/5000] | Time: 0.30s\n",
      "(Training) Loss: 1058208.1935\n",
      "(Validation) Loss: 1093628.8762, MAE: 4140.9165, R2: 0.0778\n",
      "==========================================================================================\n",
      "Epoch [1660/5000] | Time: 0.29s\n",
      "(Training) Loss: 1066530.4302\n",
      "(Validation) Loss: 1093438.7098, MAE: 4139.1201, R2: 0.0780\n",
      "==========================================================================================\n",
      "Epoch [1661/5000] | Time: 0.26s\n",
      "(Training) Loss: 1058105.5584\n",
      "(Validation) Loss: 1093232.0813, MAE: 4133.0107, R2: 0.0782\n",
      "==========================================================================================\n",
      "Epoch [1662/5000] | Time: 0.26s\n",
      "(Training) Loss: 1062501.1478\n",
      "(Validation) Loss: 1093043.5708, MAE: 4132.2412, R2: 0.0783\n",
      "==========================================================================================\n",
      "Epoch [1663/5000] | Time: 0.36s\n",
      "(Training) Loss: 1043807.5523\n",
      "(Validation) Loss: 1092845.0489, MAE: 4129.9678, R2: 0.0785\n",
      "==========================================================================================\n",
      "Epoch [1664/5000] | Time: 0.29s\n",
      "(Training) Loss: 1050696.0945\n",
      "(Validation) Loss: 1092653.4349, MAE: 4129.3643, R2: 0.0786\n",
      "==========================================================================================\n",
      "Epoch [1665/5000] | Time: 0.30s\n",
      "(Training) Loss: 1050471.0368\n",
      "(Validation) Loss: 1092462.6997, MAE: 4129.1509, R2: 0.0788\n",
      "==========================================================================================\n",
      "Epoch [1666/5000] | Time: 0.30s\n",
      "(Training) Loss: 1066503.0501\n",
      "(Validation) Loss: 1092271.2787, MAE: 4128.9263, R2: 0.0790\n",
      "==========================================================================================\n",
      "Epoch [1667/5000] | Time: 0.31s\n",
      "(Training) Loss: 1064573.9867\n",
      "(Validation) Loss: 1092074.3771, MAE: 4127.9854, R2: 0.0791\n",
      "==========================================================================================\n",
      "Epoch [1668/5000] | Time: 0.26s\n",
      "(Training) Loss: 1068010.4619\n",
      "(Validation) Loss: 1091918.2883, MAE: 4130.2671, R2: 0.0792\n",
      "==========================================================================================\n",
      "Epoch [1669/5000] | Time: 0.28s\n",
      "(Training) Loss: 1051450.9975\n",
      "(Validation) Loss: 1091722.4889, MAE: 4129.1348, R2: 0.0794\n",
      "==========================================================================================\n",
      "Epoch [1670/5000] | Time: 0.26s\n",
      "(Training) Loss: 1053108.1802\n",
      "(Validation) Loss: 1091530.0165, MAE: 4129.4883, R2: 0.0796\n",
      "==========================================================================================\n",
      "Epoch [1671/5000] | Time: 0.26s\n",
      "(Training) Loss: 1055263.3845\n",
      "(Validation) Loss: 1091339.0832, MAE: 4127.8076, R2: 0.0797\n",
      "==========================================================================================\n",
      "Epoch [1672/5000] | Time: 0.26s\n",
      "(Training) Loss: 1064875.8274\n",
      "(Validation) Loss: 1091150.3594, MAE: 4128.3589, R2: 0.0799\n",
      "==========================================================================================\n",
      "Epoch [1673/5000] | Time: 0.26s\n",
      "(Training) Loss: 1071894.3173\n",
      "(Validation) Loss: 1090959.1619, MAE: 4130.2153, R2: 0.0800\n",
      "==========================================================================================\n",
      "Epoch [1674/5000] | Time: 0.29s\n",
      "(Training) Loss: 1055960.3147\n",
      "(Validation) Loss: 1090759.3092, MAE: 4127.5132, R2: 0.0802\n",
      "==========================================================================================\n",
      "Epoch [1675/5000] | Time: 0.26s\n",
      "(Training) Loss: 1046470.9004\n",
      "(Validation) Loss: 1090563.5098, MAE: 4127.4927, R2: 0.0804\n",
      "==========================================================================================\n",
      "Epoch [1676/5000] | Time: 0.26s\n",
      "(Training) Loss: 1055442.4105\n",
      "(Validation) Loss: 1090370.3467, MAE: 4126.0273, R2: 0.0805\n",
      "==========================================================================================\n",
      "Epoch [1677/5000] | Time: 0.31s\n",
      "(Training) Loss: 1047393.5286\n",
      "(Validation) Loss: 1090186.7479, MAE: 4125.8398, R2: 0.0807\n",
      "==========================================================================================\n",
      "Epoch [1678/5000] | Time: 0.33s\n",
      "(Training) Loss: 1048141.9416\n",
      "(Validation) Loss: 1089981.1860, MAE: 4123.6357, R2: 0.0809\n",
      "==========================================================================================\n",
      "Epoch [1679/5000] | Time: 0.28s\n",
      "(Training) Loss: 1066193.7906\n",
      "(Validation) Loss: 1089793.7422, MAE: 4123.1304, R2: 0.0810\n",
      "==========================================================================================\n",
      "Epoch [1680/5000] | Time: 0.31s\n",
      "(Training) Loss: 1051672.0546\n",
      "(Validation) Loss: 1089604.3733, MAE: 4123.1509, R2: 0.0812\n",
      "==========================================================================================\n",
      "Epoch [1681/5000] | Time: 0.30s\n",
      "(Training) Loss: 1053964.9175\n",
      "(Validation) Loss: 1089403.8857, MAE: 4122.3018, R2: 0.0813\n",
      "==========================================================================================\n",
      "Epoch [1682/5000] | Time: 0.31s\n",
      "(Training) Loss: 1059777.5977\n",
      "(Validation) Loss: 1089210.7987, MAE: 4120.4653, R2: 0.0815\n",
      "==========================================================================================\n",
      "Epoch [1683/5000] | Time: 0.28s\n",
      "(Training) Loss: 1057925.7272\n",
      "(Validation) Loss: 1089019.2203, MAE: 4120.0195, R2: 0.0817\n",
      "==========================================================================================\n",
      "Epoch [1684/5000] | Time: 0.27s\n",
      "(Training) Loss: 1064605.5076\n",
      "(Validation) Loss: 1088824.5790, MAE: 4118.4224, R2: 0.0818\n",
      "==========================================================================================\n",
      "Epoch [1685/5000] | Time: 0.34s\n",
      "(Training) Loss: 1042426.7437\n",
      "(Validation) Loss: 1088630.7200, MAE: 4118.5605, R2: 0.0820\n",
      "==========================================================================================\n",
      "Epoch [1686/5000] | Time: 0.23s\n",
      "(Training) Loss: 1072340.9134\n",
      "(Validation) Loss: 1088440.8076, MAE: 4117.6216, R2: 0.0821\n",
      "==========================================================================================\n",
      "Epoch [1687/5000] | Time: 0.24s\n",
      "(Training) Loss: 1059678.6929\n",
      "(Validation) Loss: 1088245.0286, MAE: 4117.1582, R2: 0.0823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1688/5000] | Time: 0.35s\n",
      "(Training) Loss: 1083025.9708\n",
      "(Validation) Loss: 1088051.3829, MAE: 4115.9507, R2: 0.0825\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1689/5000] | Time: 0.34s\n",
      "(Training) Loss: 1055900.2468\n",
      "(Validation) Loss: 1087865.7219, MAE: 4118.6948, R2: 0.0826\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1690/5000] | Time: 0.22s\n",
      "(Training) Loss: 1061456.7652\n",
      "(Validation) Loss: 1087665.4171, MAE: 4116.1865, R2: 0.0828\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1691/5000] | Time: 0.21s\n",
      "(Training) Loss: 1069939.0546\n",
      "(Validation) Loss: 1087475.0222, MAE: 4114.9131, R2: 0.0829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1692/5000] | Time: 0.20s\n",
      "(Training) Loss: 1063734.1028\n",
      "(Validation) Loss: 1087287.4565, MAE: 4116.2661, R2: 0.0831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1693/5000] | Time: 0.18s\n",
      "(Training) Loss: 1064402.6942\n",
      "(Validation) Loss: 1087084.9321, MAE: 4112.9526, R2: 0.0833\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1694/5000] | Time: 0.20s\n",
      "(Training) Loss: 1054094.5057\n",
      "(Validation) Loss: 1086889.6711, MAE: 4113.2817, R2: 0.0834\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1695/5000] | Time: 0.20s\n",
      "(Training) Loss: 1052194.2640\n",
      "(Validation) Loss: 1086702.1257, MAE: 4112.7593, R2: 0.0836\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1696/5000] | Time: 0.20s\n",
      "(Training) Loss: 1070255.7005\n",
      "(Validation) Loss: 1086506.3771, MAE: 4110.5376, R2: 0.0838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1697/5000] | Time: 0.19s\n",
      "(Training) Loss: 1038295.8636\n",
      "(Validation) Loss: 1086312.3098, MAE: 4110.3232, R2: 0.0839\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1698/5000] | Time: 0.19s\n",
      "(Training) Loss: 1049533.6409\n",
      "(Validation) Loss: 1086129.5441, MAE: 4110.9995, R2: 0.0841\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1699/5000] | Time: 0.21s\n",
      "(Training) Loss: 1041639.3274\n",
      "(Validation) Loss: 1085934.7556, MAE: 4109.9678, R2: 0.0842\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1700/5000] | Time: 0.19s\n",
      "(Training) Loss: 1044825.2703\n",
      "(Validation) Loss: 1085756.7797, MAE: 4113.1992, R2: 0.0844\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1701/5000] | Time: 0.18s\n",
      "(Training) Loss: 1056347.8065\n",
      "(Validation) Loss: 1085554.7987, MAE: 4109.2139, R2: 0.0845\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1702/5000] | Time: 0.26s\n",
      "(Training) Loss: 1042535.8598\n",
      "(Validation) Loss: 1085425.0413, MAE: 4116.6650, R2: 0.0847\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1703/5000] | Time: 0.27s\n",
      "(Training) Loss: 1047689.5666\n",
      "(Validation) Loss: 1085213.8159, MAE: 4109.3125, R2: 0.0848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1704/5000] | Time: 0.18s\n",
      "(Training) Loss: 1055960.4099\n",
      "(Validation) Loss: 1085024.2794, MAE: 4109.1167, R2: 0.0850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1705/5000] | Time: 0.20s\n",
      "(Training) Loss: 1049029.1022\n",
      "(Validation) Loss: 1084836.8406, MAE: 4109.8462, R2: 0.0851\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1706/5000] | Time: 0.21s\n",
      "(Training) Loss: 1041493.7874\n",
      "(Validation) Loss: 1084641.8438, MAE: 4108.5864, R2: 0.0853\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1707/5000] | Time: 0.23s\n",
      "(Training) Loss: 1052454.4442\n",
      "(Validation) Loss: 1084450.7835, MAE: 4106.7383, R2: 0.0855\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1708/5000] | Time: 0.66s\n",
      "(Training) Loss: 1041124.8334\n",
      "(Validation) Loss: 1084261.2013, MAE: 4107.8398, R2: 0.0856\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1709/5000] | Time: 0.31s\n",
      "(Training) Loss: 1059541.0419\n",
      "(Validation) Loss: 1084069.6889, MAE: 4107.0874, R2: 0.0858\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1710/5000] | Time: 0.40s\n",
      "(Training) Loss: 1055826.2189\n",
      "(Validation) Loss: 1083873.2851, MAE: 4104.9722, R2: 0.0859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1711/5000] | Time: 0.94s\n",
      "(Training) Loss: 1068462.5565\n",
      "(Validation) Loss: 1083683.3981, MAE: 4104.8965, R2: 0.0861\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1712/5000] | Time: 0.80s\n",
      "(Training) Loss: 1062979.5095\n",
      "(Validation) Loss: 1083486.9841, MAE: 4103.3535, R2: 0.0863\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1713/5000] | Time: 0.77s\n",
      "(Training) Loss: 1053549.8096\n",
      "(Validation) Loss: 1083304.3149, MAE: 4106.1675, R2: 0.0864\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1714/5000] | Time: 0.87s\n",
      "(Training) Loss: 1036262.6004\n",
      "(Validation) Loss: 1083105.1632, MAE: 4103.0977, R2: 0.0866\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1715/5000] | Time: 0.99s\n",
      "(Training) Loss: 1074669.9826\n",
      "(Validation) Loss: 1082917.8108, MAE: 4103.8726, R2: 0.0867\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1716/5000] | Time: 0.87s\n",
      "(Training) Loss: 1068617.6294\n",
      "(Validation) Loss: 1082777.9962, MAE: 4106.0381, R2: 0.0869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1717/5000] | Time: 0.80s\n",
      "(Training) Loss: 1051310.3591\n",
      "(Validation) Loss: 1082583.3448, MAE: 4105.5586, R2: 0.0870\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1718/5000] | Time: 0.87s\n",
      "(Training) Loss: 1040402.3642\n",
      "(Validation) Loss: 1082390.6692, MAE: 4104.0352, R2: 0.0872\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1719/5000] | Time: 0.86s\n",
      "(Training) Loss: 1039836.1853\n",
      "(Validation) Loss: 1082203.3981, MAE: 4104.2119, R2: 0.0873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1720/5000] | Time: 0.84s\n",
      "(Training) Loss: 1046713.6599\n",
      "(Validation) Loss: 1082012.4597, MAE: 4103.0151, R2: 0.0875\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1721/5000] | Time: 0.73s\n",
      "(Training) Loss: 1052597.2982\n",
      "(Validation) Loss: 1081824.4622, MAE: 4102.6675, R2: 0.0877\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1722/5000] | Time: 0.78s\n",
      "(Training) Loss: 1051105.4886\n",
      "(Validation) Loss: 1081634.2248, MAE: 4103.1924, R2: 0.0878\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1723/5000] | Time: 0.83s\n",
      "(Training) Loss: 1056517.6371\n",
      "(Validation) Loss: 1081439.5276, MAE: 4101.3672, R2: 0.0880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1724/5000] | Time: 0.83s\n",
      "(Training) Loss: 1035352.8658\n",
      "(Validation) Loss: 1081245.8565, MAE: 4100.3457, R2: 0.0881\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1725/5000] | Time: 0.82s\n",
      "(Training) Loss: 1039240.9918\n",
      "(Validation) Loss: 1081056.7060, MAE: 4099.2437, R2: 0.0883\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1726/5000] | Time: 0.91s\n",
      "(Training) Loss: 1037363.4258\n",
      "(Validation) Loss: 1080866.2248, MAE: 4098.0850, R2: 0.0884\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1727/5000] | Time: 0.98s\n",
      "(Training) Loss: 1042517.8020\n",
      "(Validation) Loss: 1080678.8267, MAE: 4097.7510, R2: 0.0886\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1728/5000] | Time: 0.81s\n",
      "(Training) Loss: 1045820.0590\n",
      "(Validation) Loss: 1080486.8825, MAE: 4097.0415, R2: 0.0888\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1729/5000] | Time: 1.04s\n",
      "(Training) Loss: 1056024.7525\n",
      "(Validation) Loss: 1080298.5041, MAE: 4096.7559, R2: 0.0889\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1730/5000] | Time: 0.83s\n",
      "(Training) Loss: 1040466.0317\n",
      "(Validation) Loss: 1080106.4483, MAE: 4096.4526, R2: 0.0891\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1731/5000] | Time: 0.92s\n",
      "(Training) Loss: 1045890.3934\n",
      "(Validation) Loss: 1079913.2038, MAE: 4095.4124, R2: 0.0892\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1732/5000] | Time: 1.01s\n",
      "(Training) Loss: 1040765.9283\n",
      "(Validation) Loss: 1079728.0610, MAE: 4096.2935, R2: 0.0894\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1733/5000] | Time: 1.02s\n",
      "(Training) Loss: 1043188.4359\n",
      "(Validation) Loss: 1079534.0394, MAE: 4095.2200, R2: 0.0896\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1734/5000] | Time: 0.94s\n",
      "(Training) Loss: 1051305.9036\n",
      "(Validation) Loss: 1079360.3149, MAE: 4096.4380, R2: 0.0897\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1735/5000] | Time: 1.03s\n",
      "(Training) Loss: 1042199.2303\n",
      "(Validation) Loss: 1079154.7632, MAE: 4092.9951, R2: 0.0899\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1736/5000] | Time: 1.05s\n",
      "(Training) Loss: 1061269.8027\n",
      "(Validation) Loss: 1078966.8419, MAE: 4092.5437, R2: 0.0900\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1737/5000] | Time: 1.04s\n",
      "(Training) Loss: 1032434.2838\n",
      "(Validation) Loss: 1078770.8800, MAE: 4091.2515, R2: 0.0902\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1738/5000] | Time: 0.99s\n",
      "(Training) Loss: 1071854.6732\n",
      "(Validation) Loss: 1078588.4495, MAE: 4092.5032, R2: 0.0903\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1739/5000] | Time: 0.97s\n",
      "(Training) Loss: 1042091.5577\n",
      "(Validation) Loss: 1078395.4184, MAE: 4091.9238, R2: 0.0905\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1740/5000] | Time: 0.78s\n",
      "(Training) Loss: 1041544.2773\n",
      "(Validation) Loss: 1078205.0286, MAE: 4092.3247, R2: 0.0907\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1741/5000] | Time: 0.78s\n",
      "(Training) Loss: 1054729.3299\n",
      "(Validation) Loss: 1078015.7156, MAE: 4091.1113, R2: 0.0908\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1742/5000] | Time: 0.87s\n",
      "(Training) Loss: 1046063.6777\n",
      "(Validation) Loss: 1077816.0762, MAE: 4088.8701, R2: 0.0910\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1743/5000] | Time: 1.14s\n",
      "(Training) Loss: 1059439.5451\n",
      "(Validation) Loss: 1077663.0857, MAE: 4090.3308, R2: 0.0911\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1744/5000] | Time: 1.18s\n",
      "(Training) Loss: 1038616.9162\n",
      "(Validation) Loss: 1077442.3822, MAE: 4088.8518, R2: 0.0913\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1745/5000] | Time: 0.98s\n",
      "(Training) Loss: 1034714.7684\n",
      "(Validation) Loss: 1077246.2476, MAE: 4087.7029, R2: 0.0915\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1746/5000] | Time: 0.90s\n",
      "(Training) Loss: 1050290.8280\n",
      "(Validation) Loss: 1077118.2375, MAE: 4090.9958, R2: 0.0916\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1747/5000] | Time: 1.07s\n",
      "(Training) Loss: 1039504.8185\n",
      "(Validation) Loss: 1076930.0724, MAE: 4089.5588, R2: 0.0917\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1748/5000] | Time: 1.07s\n",
      "(Training) Loss: 1051188.1612\n",
      "(Validation) Loss: 1076742.0038, MAE: 4087.7229, R2: 0.0919\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1749/5000] | Time: 1.12s\n",
      "(Training) Loss: 1047057.8274\n",
      "(Validation) Loss: 1076550.6946, MAE: 4087.6609, R2: 0.0920\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1750/5000] | Time: 0.85s\n",
      "(Training) Loss: 1052790.7792\n",
      "(Validation) Loss: 1076368.9549, MAE: 4089.3838, R2: 0.0922\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1751/5000] | Time: 0.67s\n",
      "(Training) Loss: 1039244.6650\n",
      "(Validation) Loss: 1076179.8248, MAE: 4091.4387, R2: 0.0924\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1752/5000] | Time: 0.61s\n",
      "(Training) Loss: 1044286.9137\n",
      "(Validation) Loss: 1075985.8946, MAE: 4087.5837, R2: 0.0925\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1753/5000] | Time: 0.86s\n",
      "(Training) Loss: 1046014.9784\n",
      "(Validation) Loss: 1075791.7156, MAE: 4085.4595, R2: 0.0927\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1754/5000] | Time: 0.75s\n",
      "(Training) Loss: 1059908.7589\n",
      "(Validation) Loss: 1075600.2946, MAE: 4083.2449, R2: 0.0928\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1755/5000] | Time: 1.04s\n",
      "(Training) Loss: 1031499.6923\n",
      "(Validation) Loss: 1075404.0381, MAE: 4082.9670, R2: 0.0930\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1756/5000] | Time: 0.84s\n",
      "(Training) Loss: 1040883.0216\n",
      "(Validation) Loss: 1075217.3359, MAE: 4083.2217, R2: 0.0932\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1757/5000] | Time: 0.75s\n",
      "(Training) Loss: 1040887.0711\n",
      "(Validation) Loss: 1075031.0044, MAE: 4083.2603, R2: 0.0933\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1758/5000] | Time: 0.77s\n",
      "(Training) Loss: 1036369.8953\n",
      "(Validation) Loss: 1074841.5086, MAE: 4082.4575, R2: 0.0935\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1759/5000] | Time: 0.88s\n",
      "(Training) Loss: 1027254.6749\n",
      "(Validation) Loss: 1074651.3676, MAE: 4081.8201, R2: 0.0936\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1760/5000] | Time: 0.87s\n",
      "(Training) Loss: 1044585.0311\n",
      "(Validation) Loss: 1074465.1784, MAE: 4080.8130, R2: 0.0938\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1761/5000] | Time: 0.89s\n",
      "(Training) Loss: 1053892.2113\n",
      "(Validation) Loss: 1074273.4679, MAE: 4079.8552, R2: 0.0939\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1762/5000] | Time: 0.91s\n",
      "(Training) Loss: 1045936.1282\n",
      "(Validation) Loss: 1074091.1340, MAE: 4083.5085, R2: 0.0941\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1763/5000] | Time: 0.74s\n",
      "(Training) Loss: 1028416.5993\n",
      "(Validation) Loss: 1073897.0667, MAE: 4081.8286, R2: 0.0943\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1764/5000] | Time: 0.47s\n",
      "(Training) Loss: 1028219.4134\n",
      "(Validation) Loss: 1073720.6552, MAE: 4083.7834, R2: 0.0944\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1765/5000] | Time: 0.98s\n",
      "(Training) Loss: 1037141.6935\n",
      "(Validation) Loss: 1073522.1486, MAE: 4079.4475, R2: 0.0946\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1766/5000] | Time: 1.06s\n",
      "(Training) Loss: 1032788.9746\n",
      "(Validation) Loss: 1073328.7975, MAE: 4076.3428, R2: 0.0947\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1767/5000] | Time: 0.96s\n",
      "(Training) Loss: 1043544.0635\n",
      "(Validation) Loss: 1073136.2387, MAE: 4075.5024, R2: 0.0949\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1768/5000] | Time: 1.01s\n",
      "(Training) Loss: 1040454.7303\n",
      "(Validation) Loss: 1072944.7619, MAE: 4074.0493, R2: 0.0950\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1769/5000] | Time: 0.50s\n",
      "(Training) Loss: 1031505.3947\n",
      "(Validation) Loss: 1072757.2978, MAE: 4074.2163, R2: 0.0952\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1770/5000] | Time: 0.24s\n",
      "(Training) Loss: 1049426.5799\n",
      "(Validation) Loss: 1072572.1041, MAE: 4075.9163, R2: 0.0954\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1771/5000] | Time: 0.22s\n",
      "(Training) Loss: 1030603.4258\n",
      "(Validation) Loss: 1072373.2521, MAE: 4071.9199, R2: 0.0955\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1772/5000] | Time: 0.27s\n",
      "(Training) Loss: 1047956.6091\n",
      "(Validation) Loss: 1072189.1911, MAE: 4071.8474, R2: 0.0957\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1773/5000] | Time: 0.24s\n",
      "(Training) Loss: 1055861.9708\n",
      "(Validation) Loss: 1071999.8933, MAE: 4071.5938, R2: 0.0958\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1774/5000] | Time: 0.25s\n",
      "(Training) Loss: 1034759.1935\n",
      "(Validation) Loss: 1071809.9556, MAE: 4072.6658, R2: 0.0960\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1775/5000] | Time: 0.25s\n",
      "(Training) Loss: 1043326.3832\n",
      "(Validation) Loss: 1071625.5390, MAE: 4073.2505, R2: 0.0961\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1776/5000] | Time: 0.22s\n",
      "(Training) Loss: 1036698.9626\n",
      "(Validation) Loss: 1071433.9352, MAE: 4072.7258, R2: 0.0963\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1777/5000] | Time: 0.24s\n",
      "(Training) Loss: 1025208.8298\n",
      "(Validation) Loss: 1071248.1168, MAE: 4071.0950, R2: 0.0965\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1778/5000] | Time: 0.23s\n",
      "(Training) Loss: 1041293.1631\n",
      "(Validation) Loss: 1071056.5587, MAE: 4070.7615, R2: 0.0966\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1779/5000] | Time: 0.19s\n",
      "(Training) Loss: 1041936.5679\n",
      "(Validation) Loss: 1070864.3708, MAE: 4067.9102, R2: 0.0968\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1780/5000] | Time: 0.21s\n",
      "(Training) Loss: 1029923.7582\n",
      "(Validation) Loss: 1070675.1848, MAE: 4067.9004, R2: 0.0969\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1781/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046218.3617\n",
      "(Validation) Loss: 1070492.0127, MAE: 4070.6089, R2: 0.0971\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1782/5000] | Time: 0.24s\n",
      "(Training) Loss: 1039567.0584\n",
      "(Validation) Loss: 1070298.0267, MAE: 4066.6292, R2: 0.0973\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1783/5000] | Time: 0.23s\n",
      "(Training) Loss: 1038610.4334\n",
      "(Validation) Loss: 1070113.9454, MAE: 4068.5298, R2: 0.0974\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1784/5000] | Time: 0.22s\n",
      "(Training) Loss: 1035638.7849\n",
      "(Validation) Loss: 1069921.1327, MAE: 4065.1250, R2: 0.0976\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1785/5000] | Time: 0.24s\n",
      "(Training) Loss: 1043762.2189\n",
      "(Validation) Loss: 1069728.1676, MAE: 4064.7832, R2: 0.0977\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1786/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023458.3369\n",
      "(Validation) Loss: 1069537.4324, MAE: 4063.3926, R2: 0.0979\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1787/5000] | Time: 0.24s\n",
      "(Training) Loss: 1033523.6555\n",
      "(Validation) Loss: 1069348.7644, MAE: 4061.9163, R2: 0.0980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1788/5000] | Time: 0.24s\n",
      "(Training) Loss: 1029893.1453\n",
      "(Validation) Loss: 1069165.7651, MAE: 4064.0103, R2: 0.0982\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1789/5000] | Time: 0.24s\n",
      "(Training) Loss: 1028620.6187\n",
      "(Validation) Loss: 1068977.5441, MAE: 4064.0420, R2: 0.0984\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1790/5000] | Time: 0.25s\n",
      "(Training) Loss: 1041615.9810\n",
      "(Validation) Loss: 1068799.8324, MAE: 4065.6716, R2: 0.0985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1791/5000] | Time: 0.34s\n",
      "(Training) Loss: 1033448.7887\n",
      "(Validation) Loss: 1068598.0698, MAE: 4060.5493, R2: 0.0987\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1792/5000] | Time: 0.26s\n",
      "(Training) Loss: 1028038.1501\n",
      "(Validation) Loss: 1068409.6051, MAE: 4059.5562, R2: 0.0988\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1793/5000] | Time: 0.25s\n",
      "(Training) Loss: 1022839.4507\n",
      "(Validation) Loss: 1068217.7219, MAE: 4058.6023, R2: 0.0990\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1794/5000] | Time: 0.28s\n",
      "(Training) Loss: 1041575.0558\n",
      "(Validation) Loss: 1068031.9035, MAE: 4058.6926, R2: 0.0991\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1795/5000] | Time: 0.32s\n",
      "(Training) Loss: 1037963.7183\n",
      "(Validation) Loss: 1067846.5422, MAE: 4060.7671, R2: 0.0993\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1796/5000] | Time: 0.29s\n",
      "(Training) Loss: 1043920.1599\n",
      "(Validation) Loss: 1067653.7854, MAE: 4055.8318, R2: 0.0995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1797/5000] | Time: 0.26s\n",
      "(Training) Loss: 1027544.9803\n",
      "(Validation) Loss: 1067468.9371, MAE: 4057.9050, R2: 0.0996\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1798/5000] | Time: 0.25s\n",
      "(Training) Loss: 1033393.7075\n",
      "(Validation) Loss: 1067275.5149, MAE: 4055.4888, R2: 0.0998\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1799/5000] | Time: 0.26s\n",
      "(Training) Loss: 1050028.1074\n",
      "(Validation) Loss: 1067093.0540, MAE: 4056.5720, R2: 0.0999\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1800/5000] | Time: 0.27s\n",
      "(Training) Loss: 1021748.2909\n",
      "(Validation) Loss: 1066897.6762, MAE: 4054.1975, R2: 0.1001\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1801/5000] | Time: 0.26s\n",
      "(Training) Loss: 1046511.5996\n",
      "(Validation) Loss: 1066708.2311, MAE: 4052.4653, R2: 0.1002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1802/5000] | Time: 0.27s\n",
      "(Training) Loss: 1032234.8769\n",
      "(Validation) Loss: 1066533.5873, MAE: 4057.3279, R2: 0.1004\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1803/5000] | Time: 0.27s\n",
      "(Training) Loss: 1050738.1434\n",
      "(Validation) Loss: 1066336.0457, MAE: 4052.8276, R2: 0.1006\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1804/5000] | Time: 0.27s\n",
      "(Training) Loss: 1032217.2291\n",
      "(Validation) Loss: 1066140.5003, MAE: 4050.2090, R2: 0.1007\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1805/5000] | Time: 0.27s\n",
      "(Training) Loss: 1021477.7234\n",
      "(Validation) Loss: 1065951.4971, MAE: 4049.8901, R2: 0.1009\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1806/5000] | Time: 0.29s\n",
      "(Training) Loss: 1021701.1463\n",
      "(Validation) Loss: 1065780.1194, MAE: 4054.5422, R2: 0.1010\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1807/5000] | Time: 0.37s\n",
      "(Training) Loss: 1029336.4410\n",
      "(Validation) Loss: 1065580.9727, MAE: 4047.9094, R2: 0.1012\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1808/5000] | Time: 0.37s\n",
      "(Training) Loss: 1019007.5581\n",
      "(Validation) Loss: 1065387.1898, MAE: 4057.5442, R2: 0.1013\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1809/5000] | Time: 0.27s\n",
      "(Training) Loss: 1040004.9042\n",
      "(Validation) Loss: 1065152.6857, MAE: 4044.6938, R2: 0.1015\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1810/5000] | Time: 0.24s\n",
      "(Training) Loss: 1030200.1015\n",
      "(Validation) Loss: 1065102.5321, MAE: 4056.2334, R2: 0.1016\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1811/5000] | Time: 0.24s\n",
      "(Training) Loss: 1021420.7443\n",
      "(Validation) Loss: 1064933.0337, MAE: 4059.3403, R2: 0.1017\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1812/5000] | Time: 0.28s\n",
      "(Training) Loss: 1023562.5964\n",
      "(Validation) Loss: 1064734.9283, MAE: 4057.1851, R2: 0.1019\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1813/5000] | Time: 0.26s\n",
      "(Training) Loss: 1037925.4232\n",
      "(Validation) Loss: 1064542.5676, MAE: 4051.8562, R2: 0.1020\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1814/5000] | Time: 0.20s\n",
      "(Training) Loss: 1025916.2544\n",
      "(Validation) Loss: 1064347.6419, MAE: 4051.3835, R2: 0.1022\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1815/5000] | Time: 0.20s\n",
      "(Training) Loss: 1028617.1091\n",
      "(Validation) Loss: 1064155.3321, MAE: 4048.8818, R2: 0.1024\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1816/5000] | Time: 0.20s\n",
      "(Training) Loss: 1053611.4048\n",
      "(Validation) Loss: 1063965.9886, MAE: 4048.1143, R2: 0.1025\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1817/5000] | Time: 0.20s\n",
      "(Training) Loss: 1038507.7830\n",
      "(Validation) Loss: 1063775.0248, MAE: 4047.1113, R2: 0.1027\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1818/5000] | Time: 0.23s\n",
      "(Training) Loss: 1026689.6199\n",
      "(Validation) Loss: 1063593.9708, MAE: 4050.5144, R2: 0.1028\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [1819/5000] | Time: 0.25s\n",
      "(Training) Loss: 1041986.8426\n",
      "(Validation) Loss: 1075245.6279, MAE: 4084.6963, R2: 0.0931\n",
      "==========================================================================================\n",
      "Epoch [1820/5000] | Time: 0.21s\n",
      "(Training) Loss: 1053184.6859\n",
      "(Validation) Loss: 1075076.5206, MAE: 4103.2593, R2: 0.0933\n",
      "==========================================================================================\n",
      "Epoch [1821/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046752.2246\n",
      "(Validation) Loss: 1074800.8483, MAE: 4084.0654, R2: 0.0935\n",
      "==========================================================================================\n",
      "Epoch [1822/5000] | Time: 0.22s\n",
      "(Training) Loss: 1036746.6053\n",
      "(Validation) Loss: 1074611.5556, MAE: 4084.5981, R2: 0.0937\n",
      "==========================================================================================\n",
      "Epoch [1823/5000] | Time: 0.21s\n",
      "(Training) Loss: 1056611.3065\n",
      "(Validation) Loss: 1074418.2044, MAE: 4082.2673, R2: 0.0938\n",
      "==========================================================================================\n",
      "Epoch [1824/5000] | Time: 0.29s\n",
      "(Training) Loss: 1038589.4467\n",
      "(Validation) Loss: 1074215.7460, MAE: 4078.7107, R2: 0.0940\n",
      "==========================================================================================\n",
      "Epoch [1825/5000] | Time: 0.23s\n",
      "(Training) Loss: 1029464.3277\n",
      "(Validation) Loss: 1074027.1898, MAE: 4077.7488, R2: 0.0941\n",
      "==========================================================================================\n",
      "Epoch [1826/5000] | Time: 0.23s\n",
      "(Training) Loss: 1039206.6821\n",
      "(Validation) Loss: 1073834.5143, MAE: 4077.2991, R2: 0.0943\n",
      "==========================================================================================\n",
      "Epoch [1827/5000] | Time: 0.28s\n",
      "(Training) Loss: 1038965.5349\n",
      "(Validation) Loss: 1073640.4013, MAE: 4073.9189, R2: 0.0945\n",
      "==========================================================================================\n",
      "Epoch [1828/5000] | Time: 0.32s\n",
      "(Training) Loss: 1030689.7535\n",
      "(Validation) Loss: 1073447.4768, MAE: 4073.5552, R2: 0.0946\n",
      "==========================================================================================\n",
      "Epoch [1829/5000] | Time: 0.30s\n",
      "(Training) Loss: 1028497.3553\n",
      "(Validation) Loss: 1073264.8025, MAE: 4073.8015, R2: 0.0948\n",
      "==========================================================================================\n",
      "Epoch [1830/5000] | Time: 0.33s\n",
      "(Training) Loss: 1038278.1561\n",
      "(Validation) Loss: 1073141.5162, MAE: 4076.3840, R2: 0.0949\n",
      "==========================================================================================\n",
      "Epoch [1831/5000] | Time: 0.27s\n",
      "(Training) Loss: 1057006.8896\n",
      "(Validation) Loss: 1072885.2622, MAE: 4072.3235, R2: 0.0951\n",
      "==========================================================================================\n",
      "Epoch [1832/5000] | Time: 0.33s\n",
      "(Training) Loss: 1038862.2322\n",
      "(Validation) Loss: 1072691.6521, MAE: 4071.6948, R2: 0.0953\n",
      "==========================================================================================\n",
      "Epoch [1833/5000] | Time: 0.31s\n",
      "(Training) Loss: 1054910.8553\n",
      "(Validation) Loss: 1072505.4222, MAE: 4073.0571, R2: 0.0954\n",
      "==========================================================================================\n",
      "Epoch [1834/5000] | Time: 0.36s\n",
      "(Training) Loss: 1041660.9543\n",
      "(Validation) Loss: 1072310.3543, MAE: 4072.0156, R2: 0.0956\n",
      "==========================================================================================\n",
      "Epoch [1835/5000] | Time: 0.33s\n",
      "(Training) Loss: 1048803.8852\n",
      "(Validation) Loss: 1072120.5587, MAE: 4070.1584, R2: 0.0957\n",
      "==========================================================================================\n",
      "Epoch [1836/5000] | Time: 0.29s\n",
      "(Training) Loss: 1039183.9365\n",
      "(Validation) Loss: 1071937.2648, MAE: 4071.4536, R2: 0.0959\n",
      "==========================================================================================\n",
      "Epoch [1837/5000] | Time: 0.30s\n",
      "(Training) Loss: 1052576.5704\n",
      "(Validation) Loss: 1071742.8622, MAE: 4069.8237, R2: 0.0961\n",
      "==========================================================================================\n",
      "Epoch [1838/5000] | Time: 0.28s\n",
      "(Training) Loss: 1038530.4708\n",
      "(Validation) Loss: 1071547.2152, MAE: 4068.7544, R2: 0.0962\n",
      "==========================================================================================\n",
      "Epoch [1839/5000] | Time: 0.31s\n",
      "(Training) Loss: 1035530.5241\n",
      "(Validation) Loss: 1071364.9371, MAE: 4070.7959, R2: 0.0964\n",
      "==========================================================================================\n",
      "Epoch [1840/5000] | Time: 0.29s\n",
      "(Training) Loss: 1035362.7551\n",
      "(Validation) Loss: 1071168.1321, MAE: 4066.6460, R2: 0.0965\n",
      "==========================================================================================\n",
      "Epoch [1841/5000] | Time: 0.30s\n",
      "(Training) Loss: 1023563.7767\n",
      "(Validation) Loss: 1070980.6679, MAE: 4066.8330, R2: 0.0967\n",
      "==========================================================================================\n",
      "Epoch [1842/5000] | Time: 0.27s\n",
      "(Training) Loss: 1040332.4258\n",
      "(Validation) Loss: 1070791.1924, MAE: 4065.1311, R2: 0.0968\n",
      "==========================================================================================\n",
      "Epoch [1843/5000] | Time: 0.28s\n",
      "(Training) Loss: 1026889.8858\n",
      "(Validation) Loss: 1070606.7352, MAE: 4067.1667, R2: 0.0970\n",
      "==========================================================================================\n",
      "Epoch [1844/5000] | Time: 0.33s\n",
      "(Training) Loss: 1024300.4445\n",
      "(Validation) Loss: 1070420.4698, MAE: 4066.7517, R2: 0.0972\n",
      "==========================================================================================\n",
      "Epoch [1845/5000] | Time: 0.33s\n",
      "(Training) Loss: 1022941.5634\n",
      "(Validation) Loss: 1070224.7416, MAE: 4064.3088, R2: 0.0973\n",
      "==========================================================================================\n",
      "Epoch [1846/5000] | Time: 0.29s\n",
      "(Training) Loss: 1047866.5127\n",
      "(Validation) Loss: 1070035.5302, MAE: 4062.9580, R2: 0.0975\n",
      "==========================================================================================\n",
      "Epoch [1847/5000] | Time: 0.32s\n",
      "(Training) Loss: 1045222.1656\n",
      "(Validation) Loss: 1069846.9232, MAE: 4062.1804, R2: 0.0976\n",
      "==========================================================================================\n",
      "Epoch [1848/5000] | Time: 0.30s\n",
      "(Training) Loss: 1022285.6213\n",
      "(Validation) Loss: 1069651.9162, MAE: 4061.8291, R2: 0.0978\n",
      "==========================================================================================\n",
      "Epoch [1849/5000] | Time: 0.29s\n",
      "(Training) Loss: 1029406.4283\n",
      "(Validation) Loss: 1069478.8775, MAE: 4064.9714, R2: 0.0979\n",
      "==========================================================================================\n",
      "Epoch [1850/5000] | Time: 0.35s\n",
      "(Training) Loss: 1046196.6510\n",
      "(Validation) Loss: 1069279.4717, MAE: 4059.6523, R2: 0.0981\n",
      "==========================================================================================\n",
      "Epoch [1851/5000] | Time: 0.31s\n",
      "(Training) Loss: 1038481.5311\n",
      "(Validation) Loss: 1069087.2127, MAE: 4059.1912, R2: 0.0983\n",
      "==========================================================================================\n",
      "Epoch [1852/5000] | Time: 0.31s\n",
      "(Training) Loss: 1065680.8699\n",
      "(Validation) Loss: 1068895.2127, MAE: 4058.2407, R2: 0.0984\n",
      "==========================================================================================\n",
      "Epoch [1853/5000] | Time: 0.25s\n",
      "(Training) Loss: 1059412.9829\n",
      "(Validation) Loss: 1068712.4724, MAE: 4059.0261, R2: 0.0986\n",
      "==========================================================================================\n",
      "Epoch [1854/5000] | Time: 0.30s\n",
      "(Training) Loss: 1033523.0806\n",
      "(Validation) Loss: 1080743.6089, MAE: 4111.2012, R2: 0.0885\n",
      "==========================================================================================\n",
      "Epoch [1855/5000] | Time: 0.33s\n",
      "(Training) Loss: 1043970.9378\n",
      "(Validation) Loss: 1076485.0946, MAE: 4091.0645, R2: 0.0921\n",
      "==========================================================================================\n",
      "Epoch [1856/5000] | Time: 0.28s\n",
      "(Training) Loss: 1044102.6244\n",
      "(Validation) Loss: 1076276.5257, MAE: 4089.0288, R2: 0.0923\n",
      "==========================================================================================\n",
      "Epoch [1857/5000] | Time: 0.31s\n",
      "(Training) Loss: 1046770.2088\n",
      "(Validation) Loss: 1076070.1206, MAE: 4085.9563, R2: 0.0924\n",
      "==========================================================================================\n",
      "Epoch [1858/5000] | Time: 0.26s\n",
      "(Training) Loss: 1066215.8065\n",
      "(Validation) Loss: 1075868.3429, MAE: 4084.3701, R2: 0.0926\n",
      "==========================================================================================\n",
      "Epoch [1859/5000] | Time: 0.36s\n",
      "(Training) Loss: 1036839.2208\n",
      "(Validation) Loss: 1075665.7930, MAE: 4084.4419, R2: 0.0928\n",
      "==========================================================================================\n",
      "Epoch [1860/5000] | Time: 0.33s\n",
      "(Training) Loss: 1042201.1358\n",
      "(Validation) Loss: 1075464.3708, MAE: 4082.2485, R2: 0.0929\n",
      "==========================================================================================\n",
      "Epoch [1861/5000] | Time: 0.36s\n",
      "(Training) Loss: 1055070.3972\n",
      "(Validation) Loss: 1075266.7733, MAE: 4083.1245, R2: 0.0931\n",
      "==========================================================================================\n",
      "Epoch [1862/5000] | Time: 0.28s\n",
      "(Training) Loss: 1032335.8959\n",
      "(Validation) Loss: 1075069.1302, MAE: 4083.0151, R2: 0.0933\n",
      "==========================================================================================\n",
      "Epoch [1863/5000] | Time: 0.29s\n",
      "(Training) Loss: 1048130.4467\n",
      "(Validation) Loss: 1074874.9105, MAE: 4081.6204, R2: 0.0934\n",
      "==========================================================================================\n",
      "Epoch [1864/5000] | Time: 0.34s\n",
      "(Training) Loss: 1062230.8261\n",
      "(Validation) Loss: 1074680.4216, MAE: 4081.4685, R2: 0.0936\n",
      "==========================================================================================\n",
      "Epoch [1865/5000] | Time: 0.25s\n",
      "(Training) Loss: 1031433.8877\n",
      "(Validation) Loss: 1074493.0184, MAE: 4082.2734, R2: 0.0938\n",
      "==========================================================================================\n",
      "Epoch [1866/5000] | Time: 0.35s\n",
      "(Training) Loss: 1030589.7107\n",
      "(Validation) Loss: 1074283.7435, MAE: 4078.8074, R2: 0.0939\n",
      "==========================================================================================\n",
      "Epoch [1867/5000] | Time: 0.29s\n",
      "(Training) Loss: 1046517.8788\n",
      "(Validation) Loss: 1074088.1067, MAE: 4078.0295, R2: 0.0941\n",
      "==========================================================================================\n",
      "Epoch [1868/5000] | Time: 0.31s\n",
      "(Training) Loss: 1028961.1494\n",
      "(Validation) Loss: 1073895.0806, MAE: 4078.3157, R2: 0.0943\n",
      "==========================================================================================\n",
      "Epoch [1869/5000] | Time: 0.27s\n",
      "(Training) Loss: 1050691.4905\n",
      "(Validation) Loss: 1073703.2584, MAE: 4077.5610, R2: 0.0944\n",
      "==========================================================================================\n",
      "Epoch [1870/5000] | Time: 0.31s\n",
      "(Training) Loss: 1039023.0013\n",
      "(Validation) Loss: 1073446.8521, MAE: 4076.6895, R2: 0.0946\n",
      "==========================================================================================\n",
      "Epoch [1871/5000] | Time: 0.31s\n",
      "(Training) Loss: 1052864.2570\n",
      "(Validation) Loss: 1067241.6305, MAE: 4062.9482, R2: 0.0998\n",
      "==========================================================================================\n",
      "Epoch [1872/5000] | Time: 0.34s\n",
      "(Training) Loss: 1037462.0622\n",
      "(Validation) Loss: 1067008.9702, MAE: 4053.1870, R2: 0.1000\n",
      "==========================================================================================\n",
      "Epoch [1873/5000] | Time: 0.30s\n",
      "(Training) Loss: 1033800.5279\n",
      "(Validation) Loss: 1072864.4673, MAE: 4068.9282, R2: 0.0951\n",
      "==========================================================================================\n",
      "Epoch [1874/5000] | Time: 0.33s\n",
      "(Training) Loss: 1029026.6428\n",
      "(Validation) Loss: 1072685.1251, MAE: 4063.7083, R2: 0.0953\n",
      "==========================================================================================\n",
      "Epoch [1875/5000] | Time: 0.29s\n",
      "(Training) Loss: 1045809.7379\n",
      "(Validation) Loss: 1084822.5879, MAE: 4103.1001, R2: 0.0852\n",
      "==========================================================================================\n",
      "Epoch [1876/5000] | Time: 0.31s\n",
      "(Training) Loss: 1040374.4359\n",
      "(Validation) Loss: 1084623.8121, MAE: 4099.2295, R2: 0.0853\n",
      "==========================================================================================\n",
      "Epoch [1877/5000] | Time: 0.26s\n",
      "(Training) Loss: 1049168.1231\n",
      "(Validation) Loss: 1084431.6241, MAE: 4099.6377, R2: 0.0855\n",
      "==========================================================================================\n",
      "Epoch [1878/5000] | Time: 0.27s\n",
      "(Training) Loss: 1037300.3417\n",
      "(Validation) Loss: 1084247.4006, MAE: 4100.6812, R2: 0.0856\n",
      "==========================================================================================\n",
      "Epoch [1879/5000] | Time: 0.30s\n",
      "(Training) Loss: 1035953.2833\n",
      "(Validation) Loss: 1084056.8127, MAE: 4099.6538, R2: 0.0858\n",
      "==========================================================================================\n",
      "Epoch [1880/5000] | Time: 0.29s\n",
      "(Training) Loss: 1045450.5527\n",
      "(Validation) Loss: 1083858.5803, MAE: 4095.6753, R2: 0.0860\n",
      "==========================================================================================\n",
      "Epoch [1881/5000] | Time: 0.35s\n",
      "(Training) Loss: 1050571.0964\n",
      "(Validation) Loss: 1083660.8914, MAE: 4093.1067, R2: 0.0861\n",
      "==========================================================================================\n",
      "Epoch [1882/5000] | Time: 0.30s\n",
      "(Training) Loss: 1043761.5254\n",
      "(Validation) Loss: 1083492.8711, MAE: 4098.8203, R2: 0.0863\n",
      "==========================================================================================\n",
      "Epoch [1883/5000] | Time: 0.34s\n",
      "(Training) Loss: 1037030.4873\n",
      "(Validation) Loss: 1083305.7879, MAE: 4092.8489, R2: 0.0864\n",
      "==========================================================================================\n",
      "Epoch [1884/5000] | Time: 0.30s\n",
      "(Training) Loss: 1067719.3934\n",
      "(Validation) Loss: 1095593.2749, MAE: 4131.4473, R2: 0.0762\n",
      "==========================================================================================\n",
      "Epoch [1885/5000] | Time: 0.28s\n",
      "(Training) Loss: 1053764.5825\n",
      "(Validation) Loss: 1095410.7581, MAE: 4133.8335, R2: 0.0763\n",
      "==========================================================================================\n",
      "Epoch [1886/5000] | Time: 0.33s\n",
      "(Training) Loss: 1067899.0025\n",
      "(Validation) Loss: 1095269.4451, MAE: 4145.3662, R2: 0.0765\n",
      "==========================================================================================\n",
      "Epoch [1887/5000] | Time: 0.28s\n",
      "(Training) Loss: 1060781.1624\n",
      "(Validation) Loss: 1095040.6603, MAE: 4138.2808, R2: 0.0766\n",
      "==========================================================================================\n",
      "Epoch [1888/5000] | Time: 0.31s\n",
      "(Training) Loss: 1074970.2011\n",
      "(Validation) Loss: 1094840.0000, MAE: 4132.8306, R2: 0.0768\n",
      "==========================================================================================\n",
      "Epoch [1889/5000] | Time: 0.30s\n",
      "(Training) Loss: 1065089.7322\n",
      "(Validation) Loss: 1094639.3752, MAE: 4131.8926, R2: 0.0770\n",
      "==========================================================================================\n",
      "Epoch [1890/5000] | Time: 0.26s\n",
      "(Training) Loss: 1051339.4803\n",
      "(Validation) Loss: 1094458.9308, MAE: 4132.2876, R2: 0.0771\n",
      "==========================================================================================\n",
      "Epoch [1891/5000] | Time: 0.28s\n",
      "(Training) Loss: 1072993.0603\n",
      "(Validation) Loss: 1094268.0990, MAE: 4129.8364, R2: 0.0773\n",
      "==========================================================================================\n",
      "Epoch [1892/5000] | Time: 0.27s\n",
      "(Training) Loss: 1046978.3515\n",
      "(Validation) Loss: 1094073.6559, MAE: 4128.8315, R2: 0.0775\n",
      "==========================================================================================\n",
      "Epoch [1893/5000] | Time: 0.30s\n",
      "(Training) Loss: 1061124.9860\n",
      "(Validation) Loss: 1093888.0762, MAE: 4129.5415, R2: 0.0776\n",
      "==========================================================================================\n",
      "Epoch [1894/5000] | Time: 0.27s\n",
      "(Training) Loss: 1054773.6688\n",
      "(Validation) Loss: 1093674.6260, MAE: 4126.5078, R2: 0.0778\n",
      "==========================================================================================\n",
      "Epoch [1895/5000] | Time: 0.27s\n",
      "(Training) Loss: 1058405.9232\n",
      "(Validation) Loss: 1093484.3632, MAE: 4126.0264, R2: 0.0779\n",
      "==========================================================================================\n",
      "Epoch [1896/5000] | Time: 0.31s\n",
      "(Training) Loss: 1089499.6942\n",
      "(Validation) Loss: 1093298.5295, MAE: 4125.9043, R2: 0.0781\n",
      "==========================================================================================\n",
      "Epoch [1897/5000] | Time: 0.32s\n",
      "(Training) Loss: 1054964.5082\n",
      "(Validation) Loss: 1093101.6279, MAE: 4125.1494, R2: 0.0783\n",
      "==========================================================================================\n",
      "Epoch [1898/5000] | Time: 0.30s\n",
      "(Training) Loss: 1053602.2487\n",
      "(Validation) Loss: 1092914.3822, MAE: 4125.4116, R2: 0.0784\n",
      "==========================================================================================\n",
      "Epoch [1899/5000] | Time: 0.32s\n",
      "(Training) Loss: 1061498.7456\n",
      "(Validation) Loss: 1092721.4730, MAE: 4123.6963, R2: 0.0786\n",
      "==========================================================================================\n",
      "Epoch [1900/5000] | Time: 0.30s\n",
      "(Training) Loss: 1049406.9162\n",
      "(Validation) Loss: 1092522.2552, MAE: 4122.9404, R2: 0.0787\n",
      "==========================================================================================\n",
      "Epoch [1901/5000] | Time: 0.33s\n",
      "(Training) Loss: 1055104.2690\n",
      "(Validation) Loss: 1092346.0571, MAE: 4124.6431, R2: 0.0789\n",
      "==========================================================================================\n",
      "Epoch [1902/5000] | Time: 0.27s\n",
      "(Training) Loss: 1053570.6821\n",
      "(Validation) Loss: 1092135.2889, MAE: 4119.9014, R2: 0.0791\n",
      "==========================================================================================\n",
      "Epoch [1903/5000] | Time: 0.26s\n",
      "(Training) Loss: 1068634.7646\n",
      "(Validation) Loss: 1091955.2711, MAE: 4119.5791, R2: 0.0792\n",
      "==========================================================================================\n",
      "Epoch [1904/5000] | Time: 0.30s\n",
      "(Training) Loss: 1045545.9204\n",
      "(Validation) Loss: 1091777.6102, MAE: 4122.6191, R2: 0.0794\n",
      "==========================================================================================\n",
      "Epoch [1905/5000] | Time: 0.33s\n",
      "(Training) Loss: 1046841.3693\n",
      "(Validation) Loss: 1091574.4152, MAE: 4118.9238, R2: 0.0795\n",
      "==========================================================================================\n",
      "Epoch [1906/5000] | Time: 0.25s\n",
      "(Training) Loss: 1077818.1168\n",
      "(Validation) Loss: 1091389.9429, MAE: 4119.2466, R2: 0.0797\n",
      "==========================================================================================\n",
      "Epoch [1907/5000] | Time: 0.25s\n",
      "(Training) Loss: 1055240.9797\n",
      "(Validation) Loss: 1091195.2356, MAE: 4119.4668, R2: 0.0799\n",
      "==========================================================================================\n",
      "Epoch [1908/5000] | Time: 0.26s\n",
      "(Training) Loss: 1057941.3712\n",
      "(Validation) Loss: 1091030.1816, MAE: 4124.7617, R2: 0.0800\n",
      "==========================================================================================\n",
      "Epoch [1909/5000] | Time: 0.28s\n",
      "(Training) Loss: 1053252.5203\n",
      "(Validation) Loss: 1090835.1035, MAE: 4121.0430, R2: 0.0802\n",
      "==========================================================================================\n",
      "Epoch [1910/5000] | Time: 0.21s\n",
      "(Training) Loss: 1045998.5704\n",
      "(Validation) Loss: 1090640.3860, MAE: 4118.0278, R2: 0.0803\n",
      "==========================================================================================\n",
      "Epoch [1911/5000] | Time: 0.22s\n",
      "(Training) Loss: 1057241.7075\n",
      "(Validation) Loss: 1090458.6260, MAE: 4120.0947, R2: 0.0805\n",
      "==========================================================================================\n",
      "Epoch [1912/5000] | Time: 0.26s\n",
      "(Training) Loss: 1068621.0546\n",
      "(Validation) Loss: 1103077.3486, MAE: 4164.3828, R2: 0.0700\n",
      "==========================================================================================\n",
      "Epoch [1913/5000] | Time: 0.27s\n",
      "(Training) Loss: 1072936.8065\n",
      "(Validation) Loss: 1102869.7143, MAE: 4159.3706, R2: 0.0701\n",
      "==========================================================================================\n",
      "Epoch [1914/5000] | Time: 0.23s\n",
      "(Training) Loss: 1061203.3350\n",
      "(Validation) Loss: 1102675.1086, MAE: 4159.2710, R2: 0.0703\n",
      "==========================================================================================\n",
      "Epoch [1915/5000] | Time: 0.28s\n",
      "(Training) Loss: 1063763.6523\n",
      "(Validation) Loss: 1102496.1879, MAE: 4164.3335, R2: 0.0704\n",
      "==========================================================================================\n",
      "Epoch [1916/5000] | Time: 0.23s\n",
      "(Training) Loss: 1065477.4791\n",
      "(Validation) Loss: 1102290.9714, MAE: 4158.1079, R2: 0.0706\n",
      "==========================================================================================\n",
      "Epoch [1917/5000] | Time: 0.26s\n",
      "(Training) Loss: 1069730.8794\n",
      "(Validation) Loss: 1102093.2521, MAE: 4156.5518, R2: 0.0708\n",
      "==========================================================================================\n",
      "Epoch [1918/5000] | Time: 0.27s\n",
      "(Training) Loss: 1076580.0819\n",
      "(Validation) Loss: 1101897.6965, MAE: 4154.9487, R2: 0.0709\n",
      "==========================================================================================\n",
      "Epoch [1919/5000] | Time: 0.26s\n",
      "(Training) Loss: 1087443.0939\n",
      "(Validation) Loss: 1101706.7124, MAE: 4155.0532, R2: 0.0711\n",
      "==========================================================================================\n",
      "Epoch [1920/5000] | Time: 0.24s\n",
      "(Training) Loss: 1068951.4937\n",
      "(Validation) Loss: 1101514.2756, MAE: 4157.2363, R2: 0.0713\n",
      "==========================================================================================\n",
      "Epoch [1921/5000] | Time: 0.21s\n",
      "(Training) Loss: 1069573.3997\n",
      "(Validation) Loss: 1101319.9441, MAE: 4154.9141, R2: 0.0714\n",
      "==========================================================================================\n",
      "Epoch [1922/5000] | Time: 0.23s\n",
      "(Training) Loss: 1075670.5006\n",
      "(Validation) Loss: 1101129.4933, MAE: 4154.5190, R2: 0.0716\n",
      "==========================================================================================\n",
      "Epoch [1923/5000] | Time: 0.25s\n",
      "(Training) Loss: 1063816.0181\n",
      "(Validation) Loss: 1100931.1187, MAE: 4153.6084, R2: 0.0717\n",
      "==========================================================================================\n",
      "Epoch [1924/5000] | Time: 0.23s\n",
      "(Training) Loss: 1078528.0438\n",
      "(Validation) Loss: 1100740.4190, MAE: 4153.8159, R2: 0.0719\n",
      "==========================================================================================\n",
      "Epoch [1925/5000] | Time: 0.23s\n",
      "(Training) Loss: 1068877.4549\n",
      "(Validation) Loss: 1100547.6978, MAE: 4153.0303, R2: 0.0721\n",
      "==========================================================================================\n",
      "Epoch [1926/5000] | Time: 0.22s\n",
      "(Training) Loss: 1064272.4524\n",
      "(Validation) Loss: 1100359.7714, MAE: 4153.7700, R2: 0.0722\n",
      "==========================================================================================\n",
      "Epoch [1927/5000] | Time: 0.27s\n",
      "(Training) Loss: 1103303.1447\n",
      "(Validation) Loss: 1100161.0362, MAE: 4150.3965, R2: 0.0724\n",
      "==========================================================================================\n",
      "Epoch [1928/5000] | Time: 0.21s\n",
      "(Training) Loss: 1060183.9556\n",
      "(Validation) Loss: 1099969.2749, MAE: 4151.0132, R2: 0.0725\n",
      "==========================================================================================\n",
      "Epoch [1929/5000] | Time: 0.27s\n",
      "(Training) Loss: 1068714.2398\n",
      "(Validation) Loss: 1099799.6495, MAE: 4151.2129, R2: 0.0727\n",
      "==========================================================================================\n",
      "Epoch [1930/5000] | Time: 0.26s\n",
      "(Training) Loss: 1067611.3503\n",
      "(Validation) Loss: 1099621.7041, MAE: 4153.3711, R2: 0.0728\n",
      "==========================================================================================\n",
      "Epoch [1931/5000] | Time: 0.25s\n",
      "(Training) Loss: 1060484.0444\n",
      "(Validation) Loss: 1099419.4641, MAE: 4151.6548, R2: 0.0730\n",
      "==========================================================================================\n",
      "Epoch [1932/5000] | Time: 0.23s\n",
      "(Training) Loss: 1056491.9721\n",
      "(Validation) Loss: 1099237.7092, MAE: 4152.5112, R2: 0.0731\n",
      "==========================================================================================\n",
      "Epoch [1933/5000] | Time: 0.32s\n",
      "(Training) Loss: 1065869.9327\n",
      "(Validation) Loss: 1099080.3657, MAE: 4152.8960, R2: 0.0733\n",
      "==========================================================================================\n",
      "Epoch [1934/5000] | Time: 0.27s\n",
      "(Training) Loss: 1068347.4949\n",
      "(Validation) Loss: 1098889.9759, MAE: 4153.5293, R2: 0.0734\n",
      "==========================================================================================\n",
      "Epoch [1935/5000] | Time: 0.22s\n",
      "(Training) Loss: 1070109.2259\n",
      "(Validation) Loss: 1098690.5600, MAE: 4150.3115, R2: 0.0736\n",
      "==========================================================================================\n",
      "Epoch [1936/5000] | Time: 0.21s\n",
      "(Training) Loss: 1056234.9695\n",
      "(Validation) Loss: 1098501.2216, MAE: 4150.4883, R2: 0.0738\n",
      "==========================================================================================\n",
      "Epoch [1937/5000] | Time: 0.27s\n",
      "(Training) Loss: 1056222.2189\n",
      "(Validation) Loss: 1098309.7803, MAE: 4149.8989, R2: 0.0739\n",
      "==========================================================================================\n",
      "Epoch [1938/5000] | Time: 0.23s\n",
      "(Training) Loss: 1056312.2240\n",
      "(Validation) Loss: 1098118.9384, MAE: 4149.3403, R2: 0.0741\n",
      "==========================================================================================\n",
      "Epoch [1939/5000] | Time: 0.22s\n",
      "(Training) Loss: 1059922.7240\n",
      "(Validation) Loss: 1097927.5581, MAE: 4148.1069, R2: 0.0742\n",
      "==========================================================================================\n",
      "Epoch [1940/5000] | Time: 0.24s\n",
      "(Training) Loss: 1063488.6263\n",
      "(Validation) Loss: 1097747.0578, MAE: 4149.4111, R2: 0.0744\n",
      "==========================================================================================\n",
      "Epoch [1941/5000] | Time: 0.25s\n",
      "(Training) Loss: 1059306.3452\n",
      "(Validation) Loss: 1097554.1638, MAE: 4150.0278, R2: 0.0745\n",
      "==========================================================================================\n",
      "Epoch [1942/5000] | Time: 0.27s\n",
      "(Training) Loss: 1073472.4499\n",
      "(Validation) Loss: 1097359.4717, MAE: 4147.5195, R2: 0.0747\n",
      "==========================================================================================\n",
      "Epoch [1943/5000] | Time: 0.27s\n",
      "(Training) Loss: 1063487.9473\n",
      "(Validation) Loss: 1097164.5562, MAE: 4147.5659, R2: 0.0749\n",
      "==========================================================================================\n",
      "Epoch [1944/5000] | Time: 0.30s\n",
      "(Training) Loss: 1053757.5057\n",
      "(Validation) Loss: 1096975.3549, MAE: 4146.2505, R2: 0.0750\n",
      "==========================================================================================\n",
      "Epoch [1945/5000] | Time: 0.28s\n",
      "(Training) Loss: 1064644.3135\n",
      "(Validation) Loss: 1096782.6184, MAE: 4144.6924, R2: 0.0752\n",
      "==========================================================================================\n",
      "Epoch [1946/5000] | Time: 0.26s\n",
      "(Training) Loss: 1053742.3382\n",
      "(Validation) Loss: 1096592.2337, MAE: 4144.8057, R2: 0.0754\n",
      "==========================================================================================\n",
      "Epoch [1947/5000] | Time: 0.22s\n",
      "(Training) Loss: 1088181.7684\n",
      "(Validation) Loss: 1096405.2267, MAE: 4144.4189, R2: 0.0755\n",
      "==========================================================================================\n",
      "Epoch [1948/5000] | Time: 0.24s\n",
      "(Training) Loss: 1067177.0495\n",
      "(Validation) Loss: 1096212.1143, MAE: 4144.2236, R2: 0.0757\n",
      "==========================================================================================\n",
      "Epoch [1949/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046714.1964\n",
      "(Validation) Loss: 1096020.6222, MAE: 4143.1353, R2: 0.0758\n",
      "==========================================================================================\n",
      "Epoch [1950/5000] | Time: 0.25s\n",
      "(Training) Loss: 1068154.6180\n",
      "(Validation) Loss: 1095829.2368, MAE: 4141.0049, R2: 0.0760\n",
      "==========================================================================================\n",
      "Epoch [1951/5000] | Time: 0.28s\n",
      "(Training) Loss: 1063014.1117\n",
      "(Validation) Loss: 1095640.8838, MAE: 4142.0127, R2: 0.0761\n",
      "==========================================================================================\n",
      "Epoch [1952/5000] | Time: 0.27s\n",
      "(Training) Loss: 1062545.7582\n",
      "(Validation) Loss: 1095449.0057, MAE: 4140.6152, R2: 0.0763\n",
      "==========================================================================================\n",
      "Epoch [1953/5000] | Time: 0.23s\n",
      "(Training) Loss: 1046141.5948\n",
      "(Validation) Loss: 1095262.9435, MAE: 4140.4136, R2: 0.0765\n",
      "==========================================================================================\n",
      "Epoch [1954/5000] | Time: 0.24s\n",
      "(Training) Loss: 1074285.7595\n",
      "(Validation) Loss: 1095069.2165, MAE: 4138.3516, R2: 0.0766\n",
      "==========================================================================================\n",
      "Epoch [1955/5000] | Time: 0.25s\n",
      "(Training) Loss: 1070746.2722\n",
      "(Validation) Loss: 1094878.6235, MAE: 4138.3433, R2: 0.0768\n",
      "==========================================================================================\n",
      "Epoch [1956/5000] | Time: 0.25s\n",
      "(Training) Loss: 1057069.7303\n",
      "(Validation) Loss: 1094689.1886, MAE: 4138.9224, R2: 0.0769\n",
      "==========================================================================================\n",
      "Epoch [1957/5000] | Time: 0.23s\n",
      "(Training) Loss: 1070389.9327\n",
      "(Validation) Loss: 1094499.9975, MAE: 4138.6294, R2: 0.0771\n",
      "==========================================================================================\n",
      "Epoch [1958/5000] | Time: 0.29s\n",
      "(Training) Loss: 1058219.9981\n",
      "(Validation) Loss: 1094319.2127, MAE: 4139.6445, R2: 0.0772\n",
      "==========================================================================================\n",
      "Epoch [1959/5000] | Time: 0.29s\n",
      "(Training) Loss: 1079369.4816\n",
      "(Validation) Loss: 1094118.2019, MAE: 4135.5732, R2: 0.0774\n",
      "==========================================================================================\n",
      "Epoch [1960/5000] | Time: 0.27s\n",
      "(Training) Loss: 1067513.0159\n",
      "(Validation) Loss: 1093927.4565, MAE: 4135.2881, R2: 0.0776\n",
      "==========================================================================================\n",
      "Epoch [1961/5000] | Time: 0.27s\n",
      "(Training) Loss: 1054679.2234\n",
      "(Validation) Loss: 1093737.3257, MAE: 4136.8872, R2: 0.0777\n",
      "==========================================================================================\n",
      "Epoch [1962/5000] | Time: 0.27s\n",
      "(Training) Loss: 1049313.2970\n",
      "(Validation) Loss: 1093547.6673, MAE: 4135.4531, R2: 0.0779\n",
      "==========================================================================================\n",
      "Epoch [1963/5000] | Time: 0.29s\n",
      "(Training) Loss: 1063163.9695\n",
      "(Validation) Loss: 1093362.2502, MAE: 4134.4136, R2: 0.0780\n",
      "==========================================================================================\n",
      "Epoch [1964/5000] | Time: 0.24s\n",
      "(Training) Loss: 1062922.8832\n",
      "(Validation) Loss: 1093170.1486, MAE: 4132.7764, R2: 0.0782\n",
      "==========================================================================================\n",
      "Epoch [1965/5000] | Time: 0.25s\n",
      "(Training) Loss: 1059695.2557\n",
      "(Validation) Loss: 1092980.1143, MAE: 4132.0337, R2: 0.0784\n",
      "==========================================================================================\n",
      "Epoch [1966/5000] | Time: 0.26s\n",
      "(Training) Loss: 1068137.9778\n",
      "(Validation) Loss: 1092821.5010, MAE: 4140.0029, R2: 0.0785\n",
      "==========================================================================================\n",
      "Epoch [1967/5000] | Time: 0.28s\n",
      "(Training) Loss: 1043724.6633\n",
      "(Validation) Loss: 1092607.5683, MAE: 4134.4712, R2: 0.0787\n",
      "==========================================================================================\n",
      "Epoch [1968/5000] | Time: 0.23s\n",
      "(Training) Loss: 1046880.0320\n",
      "(Validation) Loss: 1092416.5079, MAE: 4132.1318, R2: 0.0788\n",
      "==========================================================================================\n",
      "Epoch [1969/5000] | Time: 0.22s\n",
      "(Training) Loss: 1057606.1339\n",
      "(Validation) Loss: 1092227.9721, MAE: 4130.8154, R2: 0.0790\n",
      "==========================================================================================\n",
      "Epoch [1970/5000] | Time: 0.23s\n",
      "(Training) Loss: 1071809.0565\n",
      "(Validation) Loss: 1092034.9968, MAE: 4129.8970, R2: 0.0791\n",
      "==========================================================================================\n",
      "Epoch [1971/5000] | Time: 0.28s\n",
      "(Training) Loss: 1072238.1916\n",
      "(Validation) Loss: 1091843.5657, MAE: 4129.0703, R2: 0.0793\n",
      "==========================================================================================\n",
      "Epoch [1972/5000] | Time: 0.23s\n",
      "(Training) Loss: 1065009.9226\n",
      "(Validation) Loss: 1091671.9695, MAE: 4132.6138, R2: 0.0794\n",
      "==========================================================================================\n",
      "Epoch [1973/5000] | Time: 0.26s\n",
      "(Training) Loss: 1057872.9860\n",
      "(Validation) Loss: 1091463.5378, MAE: 4127.5420, R2: 0.0796\n",
      "==========================================================================================\n",
      "Epoch [1974/5000] | Time: 0.28s\n",
      "(Training) Loss: 1052090.4137\n",
      "(Validation) Loss: 1091273.8235, MAE: 4127.9780, R2: 0.0798\n",
      "==========================================================================================\n",
      "Epoch [1975/5000] | Time: 0.31s\n",
      "(Training) Loss: 1066216.6840\n",
      "(Validation) Loss: 1091085.0692, MAE: 4129.4243, R2: 0.0799\n",
      "==========================================================================================\n",
      "Epoch [1976/5000] | Time: 0.30s\n",
      "(Training) Loss: 1062734.7684\n",
      "(Validation) Loss: 1090891.4895, MAE: 4125.1187, R2: 0.0801\n",
      "==========================================================================================\n",
      "Epoch [1977/5000] | Time: 0.29s\n",
      "(Training) Loss: 1044147.2411\n",
      "(Validation) Loss: 1090700.8508, MAE: 4124.3281, R2: 0.0803\n",
      "==========================================================================================\n",
      "Epoch [1978/5000] | Time: 0.28s\n",
      "(Training) Loss: 1054376.5438\n",
      "(Validation) Loss: 1090518.0800, MAE: 4124.9824, R2: 0.0804\n",
      "==========================================================================================\n",
      "Epoch [1979/5000] | Time: 0.26s\n",
      "(Training) Loss: 1043568.7449\n",
      "(Validation) Loss: 1090332.8406, MAE: 4123.9668, R2: 0.0806\n",
      "==========================================================================================\n",
      "Epoch [1980/5000] | Time: 0.28s\n",
      "(Training) Loss: 1063103.2113\n",
      "(Validation) Loss: 1090139.5962, MAE: 4122.4922, R2: 0.0807\n",
      "==========================================================================================\n",
      "Epoch [1981/5000] | Time: 0.29s\n",
      "(Training) Loss: 1045994.8813\n",
      "(Validation) Loss: 1089957.1200, MAE: 4124.8188, R2: 0.0809\n",
      "==========================================================================================\n",
      "Epoch [1982/5000] | Time: 0.27s\n",
      "(Training) Loss: 1059616.9772\n",
      "(Validation) Loss: 1089762.6057, MAE: 4121.4370, R2: 0.0810\n",
      "==========================================================================================\n",
      "Epoch [1983/5000] | Time: 0.27s\n",
      "(Training) Loss: 1051388.7354\n",
      "(Validation) Loss: 1089619.8349, MAE: 4123.5825, R2: 0.0812\n",
      "==========================================================================================\n",
      "Epoch [1984/5000] | Time: 0.31s\n",
      "(Training) Loss: 1050853.0241\n",
      "(Validation) Loss: 1089434.8343, MAE: 4124.5142, R2: 0.0813\n",
      "==========================================================================================\n",
      "Epoch [1985/5000] | Time: 0.25s\n",
      "(Training) Loss: 1065649.5311\n",
      "(Validation) Loss: 1089243.6013, MAE: 4122.8643, R2: 0.0815\n",
      "==========================================================================================\n",
      "Epoch [1986/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046321.4524\n",
      "(Validation) Loss: 1089061.7346, MAE: 4124.3003, R2: 0.0816\n",
      "==========================================================================================\n",
      "Epoch [1987/5000] | Time: 0.28s\n",
      "(Training) Loss: 1061434.1117\n",
      "(Validation) Loss: 1088870.7606, MAE: 4123.8286, R2: 0.0818\n",
      "==========================================================================================\n",
      "Epoch [1988/5000] | Time: 0.27s\n",
      "(Training) Loss: 1052047.5768\n",
      "(Validation) Loss: 1088678.2476, MAE: 4121.5586, R2: 0.0819\n",
      "==========================================================================================\n",
      "Epoch [1989/5000] | Time: 0.30s\n",
      "(Training) Loss: 1046746.2500\n",
      "(Validation) Loss: 1088488.2794, MAE: 4121.4927, R2: 0.0821\n",
      "==========================================================================================\n",
      "Epoch [1990/5000] | Time: 0.32s\n",
      "(Training) Loss: 1067312.2145\n",
      "(Validation) Loss: 1088308.6476, MAE: 4121.5918, R2: 0.0823\n",
      "==========================================================================================\n",
      "Epoch [1991/5000] | Time: 0.34s\n",
      "(Training) Loss: 1053393.6459\n",
      "(Validation) Loss: 1088108.0787, MAE: 4119.2095, R2: 0.0824\n",
      "==========================================================================================\n",
      "Epoch [1992/5000] | Time: 0.32s\n",
      "(Training) Loss: 1054618.0914\n",
      "(Validation) Loss: 1087918.3746, MAE: 4118.5566, R2: 0.0826\n",
      "==========================================================================================\n",
      "Epoch [1993/5000] | Time: 0.27s\n",
      "(Training) Loss: 1062319.4626\n",
      "(Validation) Loss: 1087727.7410, MAE: 4117.5078, R2: 0.0827\n",
      "==========================================================================================\n",
      "Epoch [1994/5000] | Time: 0.28s\n",
      "(Training) Loss: 1067588.1707\n",
      "(Validation) Loss: 1087564.9117, MAE: 4121.8628, R2: 0.0829\n",
      "==========================================================================================\n",
      "Epoch [1995/5000] | Time: 0.27s\n",
      "(Training) Loss: 1065099.5603\n",
      "(Validation) Loss: 1087351.5073, MAE: 4116.5879, R2: 0.0830\n",
      "==========================================================================================\n",
      "Epoch [1996/5000] | Time: 0.26s\n",
      "(Training) Loss: 1064029.1168\n",
      "(Validation) Loss: 1087160.0660, MAE: 4116.1030, R2: 0.0832\n",
      "==========================================================================================\n",
      "Epoch [1997/5000] | Time: 0.24s\n",
      "(Training) Loss: 1062481.0933\n",
      "(Validation) Loss: 1086967.3397, MAE: 4113.8540, R2: 0.0834\n",
      "==========================================================================================\n",
      "Epoch [1998/5000] | Time: 0.23s\n",
      "(Training) Loss: 1057239.3940\n",
      "(Validation) Loss: 1086781.9124, MAE: 4114.6582, R2: 0.0835\n",
      "==========================================================================================\n",
      "Epoch [1999/5000] | Time: 0.23s\n",
      "(Training) Loss: 1050075.5025\n",
      "(Validation) Loss: 1086590.5473, MAE: 4112.5503, R2: 0.0837\n",
      "==========================================================================================\n",
      "Epoch [2000/5000] | Time: 0.26s\n",
      "(Training) Loss: 1040678.9810\n",
      "(Validation) Loss: 1086403.2152, MAE: 4112.7358, R2: 0.0838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch2000.pth\n",
      "==========================================================================================\n",
      "Epoch [2001/5000] | Time: 0.31s\n",
      "(Training) Loss: 1047548.1041\n",
      "(Validation) Loss: 1086221.5010, MAE: 4113.9199, R2: 0.0840\n",
      "==========================================================================================\n",
      "Epoch [2002/5000] | Time: 0.29s\n",
      "(Training) Loss: 1076514.6104\n",
      "(Validation) Loss: 1086029.5517, MAE: 4112.0522, R2: 0.0841\n",
      "==========================================================================================\n",
      "Epoch [2003/5000] | Time: 0.32s\n",
      "(Training) Loss: 1054481.2621\n",
      "(Validation) Loss: 1085839.4565, MAE: 4112.1802, R2: 0.0843\n",
      "==========================================================================================\n",
      "Epoch [2004/5000] | Time: 0.36s\n",
      "(Training) Loss: 1057840.7843\n",
      "(Validation) Loss: 1085656.0813, MAE: 4113.1631, R2: 0.0845\n",
      "==========================================================================================\n",
      "Epoch [2005/5000] | Time: 0.29s\n",
      "(Training) Loss: 1049493.9860\n",
      "(Validation) Loss: 1085462.5016, MAE: 4110.5098, R2: 0.0846\n",
      "==========================================================================================\n",
      "Epoch [2006/5000] | Time: 0.30s\n",
      "(Training) Loss: 1044038.1834\n",
      "(Validation) Loss: 1085273.2140, MAE: 4109.3149, R2: 0.0848\n",
      "==========================================================================================\n",
      "Epoch [2007/5000] | Time: 0.29s\n",
      "(Training) Loss: 1053494.5070\n",
      "(Validation) Loss: 1085083.4235, MAE: 4108.4297, R2: 0.0849\n",
      "==========================================================================================\n",
      "Epoch [2008/5000] | Time: 0.28s\n",
      "(Training) Loss: 1039069.3004\n",
      "(Validation) Loss: 1084896.9651, MAE: 4107.4170, R2: 0.0851\n",
      "==========================================================================================\n",
      "Epoch [2009/5000] | Time: 0.27s\n",
      "(Training) Loss: 1046649.9968\n",
      "(Validation) Loss: 1084720.0457, MAE: 4112.0352, R2: 0.0852\n",
      "==========================================================================================\n",
      "Epoch [2010/5000] | Time: 0.30s\n",
      "(Training) Loss: 1045747.0076\n",
      "(Validation) Loss: 1084530.7632, MAE: 4110.0088, R2: 0.0854\n",
      "==========================================================================================\n",
      "Epoch [2011/5000] | Time: 0.28s\n",
      "(Training) Loss: 1044922.9010\n",
      "(Validation) Loss: 1084336.2946, MAE: 4105.8057, R2: 0.0856\n",
      "==========================================================================================\n",
      "Epoch [2012/5000] | Time: 0.32s\n",
      "(Training) Loss: 1052375.9594\n",
      "(Validation) Loss: 1084149.5771, MAE: 4105.4492, R2: 0.0857\n",
      "==========================================================================================\n",
      "Epoch [2013/5000] | Time: 0.32s\n",
      "(Training) Loss: 1041081.9987\n",
      "(Validation) Loss: 1083958.3797, MAE: 4104.3120, R2: 0.0859\n",
      "==========================================================================================\n",
      "Epoch [2014/5000] | Time: 0.27s\n",
      "(Training) Loss: 1046699.8084\n",
      "(Validation) Loss: 1083776.3098, MAE: 4105.4189, R2: 0.0860\n",
      "==========================================================================================\n",
      "Epoch [2015/5000] | Time: 0.37s\n",
      "(Training) Loss: 1040959.6301\n",
      "(Validation) Loss: 1083587.1289, MAE: 4103.1685, R2: 0.0862\n",
      "==========================================================================================\n",
      "Epoch [2016/5000] | Time: 0.31s\n",
      "(Training) Loss: 1044739.8642\n",
      "(Validation) Loss: 1083399.5022, MAE: 4103.2832, R2: 0.0863\n",
      "==========================================================================================\n",
      "Epoch [2017/5000] | Time: 0.23s\n",
      "(Training) Loss: 1047441.2272\n",
      "(Validation) Loss: 1083211.4692, MAE: 4102.6499, R2: 0.0865\n",
      "==========================================================================================\n",
      "Epoch [2018/5000] | Time: 0.23s\n",
      "(Training) Loss: 1049563.4664\n",
      "(Validation) Loss: 1083022.0394, MAE: 4101.1021, R2: 0.0867\n",
      "==========================================================================================\n",
      "Epoch [2019/5000] | Time: 0.21s\n",
      "(Training) Loss: 1059893.4632\n",
      "(Validation) Loss: 1082842.9156, MAE: 4101.6860, R2: 0.0868\n",
      "==========================================================================================\n",
      "Epoch [2020/5000] | Time: 0.19s\n",
      "(Training) Loss: 1056141.7297\n",
      "(Validation) Loss: 1082654.7708, MAE: 4103.5620, R2: 0.0870\n",
      "==========================================================================================\n",
      "Epoch [2021/5000] | Time: 0.20s\n",
      "(Training) Loss: 1054012.6440\n",
      "(Validation) Loss: 1082474.2705, MAE: 4102.0703, R2: 0.0871\n",
      "==========================================================================================\n",
      "Epoch [2022/5000] | Time: 0.20s\n",
      "(Training) Loss: 1035961.6805\n",
      "(Validation) Loss: 1082334.7911, MAE: 4105.2407, R2: 0.0872\n",
      "==========================================================================================\n",
      "Epoch [2023/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046568.1523\n",
      "(Validation) Loss: 1082140.9422, MAE: 4102.3115, R2: 0.0874\n",
      "==========================================================================================\n",
      "Epoch [2024/5000] | Time: 0.21s\n",
      "(Training) Loss: 1050515.9201\n",
      "(Validation) Loss: 1081978.0216, MAE: 4110.8989, R2: 0.0875\n",
      "==========================================================================================\n",
      "Epoch [2025/5000] | Time: 0.25s\n",
      "(Training) Loss: 1043481.8242\n",
      "(Validation) Loss: 1081769.5289, MAE: 4101.5034, R2: 0.0877\n",
      "==========================================================================================\n",
      "Epoch [2026/5000] | Time: 0.22s\n",
      "(Training) Loss: 1054454.1840\n",
      "(Validation) Loss: 1081582.6133, MAE: 4101.8052, R2: 0.0879\n",
      "==========================================================================================\n",
      "Epoch [2027/5000] | Time: 0.21s\n",
      "(Training) Loss: 1038419.6390\n",
      "(Validation) Loss: 1081394.0927, MAE: 4101.7090, R2: 0.0880\n",
      "==========================================================================================\n",
      "Epoch [2028/5000] | Time: 0.21s\n",
      "(Training) Loss: 1049268.7830\n",
      "(Validation) Loss: 1081200.8838, MAE: 4098.1885, R2: 0.0882\n",
      "==========================================================================================\n",
      "Epoch [2029/5000] | Time: 0.28s\n",
      "(Training) Loss: 1051582.1973\n",
      "(Validation) Loss: 1081015.7460, MAE: 4098.6636, R2: 0.0883\n",
      "==========================================================================================\n",
      "Epoch [2030/5000] | Time: 0.22s\n",
      "(Training) Loss: 1038798.5787\n",
      "(Validation) Loss: 1080829.3943, MAE: 4098.1655, R2: 0.0885\n",
      "==========================================================================================\n",
      "Epoch [2031/5000] | Time: 0.22s\n",
      "(Training) Loss: 1041534.1523\n",
      "(Validation) Loss: 1087395.1543, MAE: 4126.4839, R2: 0.0830\n",
      "==========================================================================================\n",
      "Epoch [2032/5000] | Time: 0.21s\n",
      "(Training) Loss: 1042880.5444\n",
      "(Validation) Loss: 1087207.3956, MAE: 4123.6768, R2: 0.0832\n",
      "==========================================================================================\n",
      "Epoch [2033/5000] | Time: 0.21s\n",
      "(Training) Loss: 1054908.5102\n",
      "(Validation) Loss: 1087016.4521, MAE: 4121.3101, R2: 0.0833\n",
      "==========================================================================================\n",
      "Epoch [2034/5000] | Time: 0.23s\n",
      "(Training) Loss: 1050616.4181\n",
      "(Validation) Loss: 1086838.3644, MAE: 4121.8745, R2: 0.0835\n",
      "==========================================================================================\n",
      "Epoch [2035/5000] | Time: 0.25s\n",
      "(Training) Loss: 1056087.4321\n",
      "(Validation) Loss: 1086651.1086, MAE: 4121.2153, R2: 0.0836\n",
      "==========================================================================================\n",
      "Epoch [2036/5000] | Time: 0.22s\n",
      "(Training) Loss: 1053687.0565\n",
      "(Validation) Loss: 1086465.7422, MAE: 4121.4507, R2: 0.0838\n",
      "==========================================================================================\n",
      "Epoch [2037/5000] | Time: 0.35s\n",
      "(Training) Loss: 1072949.8997\n",
      "(Validation) Loss: 1086277.0844, MAE: 4120.4033, R2: 0.0839\n",
      "==========================================================================================\n",
      "Epoch [2038/5000] | Time: 0.69s\n",
      "(Training) Loss: 1050351.6970\n",
      "(Validation) Loss: 1086085.1454, MAE: 4120.3882, R2: 0.0841\n",
      "==========================================================================================\n",
      "Epoch [2039/5000] | Time: 0.32s\n",
      "(Training) Loss: 1066598.1060\n",
      "(Validation) Loss: 1085895.9187, MAE: 4117.1782, R2: 0.0843\n",
      "==========================================================================================\n",
      "Epoch [2040/5000] | Time: 0.68s\n",
      "(Training) Loss: 1039725.5904\n",
      "(Validation) Loss: 1085708.1803, MAE: 4116.1685, R2: 0.0844\n",
      "==========================================================================================\n",
      "Epoch [2041/5000] | Time: 0.78s\n",
      "(Training) Loss: 1041763.0082\n",
      "(Validation) Loss: 1085527.0857, MAE: 4116.9800, R2: 0.0846\n",
      "==========================================================================================\n",
      "Epoch [2042/5000] | Time: 0.72s\n",
      "(Training) Loss: 1051698.6136\n",
      "(Validation) Loss: 1085347.3829, MAE: 4116.7256, R2: 0.0847\n",
      "==========================================================================================\n",
      "Epoch [2043/5000] | Time: 0.87s\n",
      "(Training) Loss: 1053382.8065\n",
      "(Validation) Loss: 1085169.3359, MAE: 4117.5312, R2: 0.0849\n",
      "==========================================================================================\n",
      "Epoch [2044/5000] | Time: 0.76s\n",
      "(Training) Loss: 1074892.4454\n",
      "(Validation) Loss: 1084972.0229, MAE: 4115.6128, R2: 0.0850\n",
      "==========================================================================================\n",
      "Epoch [2045/5000] | Time: 0.71s\n",
      "(Training) Loss: 1067021.4987\n",
      "(Validation) Loss: 1084788.8863, MAE: 4114.7681, R2: 0.0852\n",
      "==========================================================================================\n",
      "Epoch [2046/5000] | Time: 0.86s\n",
      "(Training) Loss: 1045959.3433\n",
      "(Validation) Loss: 1084595.6317, MAE: 4113.0503, R2: 0.0853\n",
      "==========================================================================================\n",
      "Epoch [2047/5000] | Time: 0.81s\n",
      "(Training) Loss: 1050661.9334\n",
      "(Validation) Loss: 1084412.2921, MAE: 4113.3818, R2: 0.0855\n",
      "==========================================================================================\n",
      "Epoch [2048/5000] | Time: 0.73s\n",
      "(Training) Loss: 1050098.7284\n",
      "(Validation) Loss: 1084226.3416, MAE: 4112.3496, R2: 0.0856\n",
      "==========================================================================================\n",
      "Epoch [2049/5000] | Time: 0.74s\n",
      "(Training) Loss: 1036944.0235\n",
      "(Validation) Loss: 1084039.1314, MAE: 4110.6245, R2: 0.0858\n",
      "==========================================================================================\n",
      "Epoch [2050/5000] | Time: 0.96s\n",
      "(Training) Loss: 1042442.4543\n",
      "(Validation) Loss: 1083864.5537, MAE: 4112.6777, R2: 0.0860\n",
      "==========================================================================================\n",
      "Epoch [2051/5000] | Time: 0.82s\n",
      "(Training) Loss: 1037120.5308\n",
      "(Validation) Loss: 1083678.1410, MAE: 4113.2910, R2: 0.0861\n",
      "==========================================================================================\n",
      "Epoch [2052/5000] | Time: 0.90s\n",
      "(Training) Loss: 1042107.7449\n",
      "(Validation) Loss: 1083503.4768, MAE: 4113.6011, R2: 0.0863\n",
      "==========================================================================================\n",
      "Epoch [2053/5000] | Time: 0.78s\n",
      "(Training) Loss: 1042002.8712\n",
      "(Validation) Loss: 1083309.3029, MAE: 4110.8823, R2: 0.0864\n",
      "==========================================================================================\n",
      "Epoch [2054/5000] | Time: 0.76s\n",
      "(Training) Loss: 1051843.3141\n",
      "(Validation) Loss: 1083122.0825, MAE: 4109.3262, R2: 0.0866\n",
      "==========================================================================================\n",
      "Epoch [2055/5000] | Time: 0.59s\n",
      "(Training) Loss: 1057296.5742\n",
      "(Validation) Loss: 1082936.4419, MAE: 4108.4092, R2: 0.0867\n",
      "==========================================================================================\n",
      "Epoch [2056/5000] | Time: 0.27s\n",
      "(Training) Loss: 1044456.0279\n",
      "(Validation) Loss: 1082747.4032, MAE: 4105.9414, R2: 0.0869\n",
      "==========================================================================================\n",
      "Epoch [2057/5000] | Time: 0.26s\n",
      "(Training) Loss: 1036139.4645\n",
      "(Validation) Loss: 1082561.0260, MAE: 4105.2134, R2: 0.0870\n",
      "==========================================================================================\n",
      "Epoch [2058/5000] | Time: 0.24s\n",
      "(Training) Loss: 1050055.2792\n",
      "(Validation) Loss: 1082376.7822, MAE: 4103.6260, R2: 0.0872\n",
      "==========================================================================================\n",
      "Epoch [2059/5000] | Time: 0.23s\n",
      "(Training) Loss: 1037999.9499\n",
      "(Validation) Loss: 1082196.0584, MAE: 4105.9985, R2: 0.0873\n",
      "==========================================================================================\n",
      "Epoch [2060/5000] | Time: 0.24s\n",
      "(Training) Loss: 1045188.2418\n",
      "(Validation) Loss: 1082010.0368, MAE: 4104.6035, R2: 0.0875\n",
      "==========================================================================================\n",
      "Epoch [2061/5000] | Time: 0.71s\n",
      "(Training) Loss: 1066174.2297\n",
      "(Validation) Loss: 1081827.0933, MAE: 4103.8677, R2: 0.0876\n",
      "==========================================================================================\n",
      "Epoch [2062/5000] | Time: 0.51s\n",
      "(Training) Loss: 1064515.9201\n",
      "(Validation) Loss: 1081636.8254, MAE: 4102.6182, R2: 0.0878\n",
      "==========================================================================================\n",
      "Epoch [2063/5000] | Time: 0.58s\n",
      "(Training) Loss: 1059194.1434\n",
      "(Validation) Loss: 1081453.4654, MAE: 4102.4976, R2: 0.0880\n",
      "==========================================================================================\n",
      "Epoch [2064/5000] | Time: 0.74s\n",
      "(Training) Loss: 1048178.3490\n",
      "(Validation) Loss: 1081262.4508, MAE: 4100.7300, R2: 0.0881\n",
      "==========================================================================================\n",
      "Epoch [2065/5000] | Time: 0.88s\n",
      "(Training) Loss: 1043521.8280\n",
      "(Validation) Loss: 1081088.6502, MAE: 4103.1152, R2: 0.0883\n",
      "==========================================================================================\n",
      "Epoch [2066/5000] | Time: 0.34s\n",
      "(Training) Loss: 1045884.7874\n",
      "(Validation) Loss: 1080896.6959, MAE: 4100.5703, R2: 0.0884\n",
      "==========================================================================================\n",
      "Epoch [2067/5000] | Time: 0.28s\n",
      "(Training) Loss: 1048940.6802\n",
      "(Validation) Loss: 1080717.7854, MAE: 4101.9263, R2: 0.0886\n",
      "==========================================================================================\n",
      "Epoch [2068/5000] | Time: 0.28s\n",
      "(Training) Loss: 1043896.6827\n",
      "(Validation) Loss: 1080532.4444, MAE: 4100.5088, R2: 0.0887\n",
      "==========================================================================================\n",
      "Epoch [2069/5000] | Time: 0.28s\n",
      "(Training) Loss: 1041058.4892\n",
      "(Validation) Loss: 1080342.0800, MAE: 4098.9297, R2: 0.0889\n",
      "==========================================================================================\n",
      "Epoch [2070/5000] | Time: 0.31s\n",
      "(Training) Loss: 1041584.6364\n",
      "(Validation) Loss: 1080155.9314, MAE: 4097.0156, R2: 0.0890\n",
      "==========================================================================================\n",
      "Epoch [2071/5000] | Time: 0.31s\n",
      "(Training) Loss: 1059817.4810\n",
      "(Validation) Loss: 1079974.3492, MAE: 4097.5967, R2: 0.0892\n",
      "==========================================================================================\n",
      "Epoch [2072/5000] | Time: 0.30s\n",
      "(Training) Loss: 1032129.3069\n",
      "(Validation) Loss: 1079792.2895, MAE: 4100.2183, R2: 0.0893\n",
      "==========================================================================================\n",
      "Epoch [2073/5000] | Time: 0.31s\n",
      "(Training) Loss: 1042142.2043\n",
      "(Validation) Loss: 1079605.7498, MAE: 4095.2378, R2: 0.0895\n",
      "==========================================================================================\n",
      "Epoch [2074/5000] | Time: 0.26s\n",
      "(Training) Loss: 1032925.0336\n",
      "(Validation) Loss: 1079434.3822, MAE: 4100.0693, R2: 0.0896\n",
      "==========================================================================================\n",
      "Epoch [2075/5000] | Time: 0.24s\n",
      "(Training) Loss: 1037904.4467\n",
      "(Validation) Loss: 1079236.9625, MAE: 4095.2747, R2: 0.0898\n",
      "==========================================================================================\n",
      "Epoch [2076/5000] | Time: 0.25s\n",
      "(Training) Loss: 1061684.4784\n",
      "(Validation) Loss: 1079054.4356, MAE: 4094.9524, R2: 0.0900\n",
      "==========================================================================================\n",
      "Epoch [2077/5000] | Time: 0.28s\n",
      "(Training) Loss: 1034811.3553\n",
      "(Validation) Loss: 1078866.5956, MAE: 4092.6187, R2: 0.0901\n",
      "==========================================================================================\n",
      "Epoch [2078/5000] | Time: 0.29s\n",
      "(Training) Loss: 1056058.6970\n",
      "(Validation) Loss: 1078688.6959, MAE: 4093.8982, R2: 0.0903\n",
      "==========================================================================================\n",
      "Epoch [2079/5000] | Time: 0.27s\n",
      "(Training) Loss: 1042301.1155\n",
      "(Validation) Loss: 1078509.9378, MAE: 4097.2383, R2: 0.0904\n",
      "==========================================================================================\n",
      "Epoch [2080/5000] | Time: 0.34s\n",
      "(Training) Loss: 1045839.2982\n",
      "(Validation) Loss: 1078333.2368, MAE: 4097.4277, R2: 0.0906\n",
      "==========================================================================================\n",
      "Epoch [2081/5000] | Time: 0.34s\n",
      "(Training) Loss: 1032014.4681\n",
      "(Validation) Loss: 1078129.9200, MAE: 4090.6558, R2: 0.0907\n",
      "==========================================================================================\n",
      "Epoch [2082/5000] | Time: 0.29s\n",
      "(Training) Loss: 1044369.1992\n",
      "(Validation) Loss: 1077959.3651, MAE: 4094.3342, R2: 0.0909\n",
      "==========================================================================================\n",
      "Epoch [2083/5000] | Time: 0.27s\n",
      "(Training) Loss: 1055003.3921\n",
      "(Validation) Loss: 1077764.4089, MAE: 4089.3994, R2: 0.0910\n",
      "==========================================================================================\n",
      "Epoch [2084/5000] | Time: 0.26s\n",
      "(Training) Loss: 1041301.8826\n",
      "(Validation) Loss: 1077578.2857, MAE: 4087.6863, R2: 0.0912\n",
      "==========================================================================================\n",
      "Epoch [2085/5000] | Time: 0.24s\n",
      "(Training) Loss: 1033851.4036\n",
      "(Validation) Loss: 1077394.0825, MAE: 4087.4841, R2: 0.0913\n",
      "==========================================================================================\n",
      "Epoch [2086/5000] | Time: 0.26s\n",
      "(Training) Loss: 1033164.2865\n",
      "(Validation) Loss: 1077218.1181, MAE: 4087.0215, R2: 0.0915\n",
      "==========================================================================================\n",
      "Epoch [2087/5000] | Time: 0.26s\n",
      "(Training) Loss: 1044205.3261\n",
      "(Validation) Loss: 1077028.1752, MAE: 4085.7915, R2: 0.0916\n",
      "==========================================================================================\n",
      "Epoch [2088/5000] | Time: 0.26s\n",
      "(Training) Loss: 1036181.7516\n",
      "(Validation) Loss: 1076846.6083, MAE: 4084.0410, R2: 0.0918\n",
      "==========================================================================================\n",
      "Epoch [2089/5000] | Time: 0.27s\n",
      "(Training) Loss: 1033209.1402\n",
      "(Validation) Loss: 1076662.1308, MAE: 4084.4094, R2: 0.0920\n",
      "==========================================================================================\n",
      "Epoch [2090/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046884.1053\n",
      "(Validation) Loss: 1076482.3568, MAE: 4085.3994, R2: 0.0921\n",
      "==========================================================================================\n",
      "Epoch [2091/5000] | Time: 0.25s\n",
      "(Training) Loss: 1042025.6358\n",
      "(Validation) Loss: 1076302.9384, MAE: 4084.5208, R2: 0.0923\n",
      "==========================================================================================\n",
      "Epoch [2092/5000] | Time: 0.23s\n",
      "(Training) Loss: 1042570.5615\n",
      "(Validation) Loss: 1076115.5911, MAE: 4083.3210, R2: 0.0924\n",
      "==========================================================================================\n",
      "Epoch [2093/5000] | Time: 0.27s\n",
      "(Training) Loss: 1039010.0393\n",
      "(Validation) Loss: 1075928.6502, MAE: 4082.2229, R2: 0.0926\n",
      "==========================================================================================\n",
      "Epoch [2094/5000] | Time: 0.27s\n",
      "(Training) Loss: 1050483.1466\n",
      "(Validation) Loss: 1075746.0521, MAE: 4080.8813, R2: 0.0927\n",
      "==========================================================================================\n",
      "Epoch [2095/5000] | Time: 0.24s\n",
      "(Training) Loss: 1056499.0654\n",
      "(Validation) Loss: 1075566.4152, MAE: 4082.8933, R2: 0.0929\n",
      "==========================================================================================\n",
      "Epoch [2096/5000] | Time: 0.25s\n",
      "(Training) Loss: 1040195.9981\n",
      "(Validation) Loss: 1075384.3251, MAE: 4082.4622, R2: 0.0930\n",
      "==========================================================================================\n",
      "Epoch [2097/5000] | Time: 0.27s\n",
      "(Training) Loss: 1037127.8579\n",
      "(Validation) Loss: 1075199.3549, MAE: 4082.7017, R2: 0.0932\n",
      "==========================================================================================\n",
      "Epoch [2098/5000] | Time: 0.25s\n",
      "(Training) Loss: 1036239.8109\n",
      "(Validation) Loss: 1075010.4076, MAE: 4079.5488, R2: 0.0933\n",
      "==========================================================================================\n",
      "Epoch [2099/5000] | Time: 0.25s\n",
      "(Training) Loss: 1052295.5114\n",
      "(Validation) Loss: 1074828.3581, MAE: 4078.0393, R2: 0.0935\n",
      "==========================================================================================\n",
      "Epoch [2100/5000] | Time: 0.24s\n",
      "(Training) Loss: 1060730.5863\n",
      "(Validation) Loss: 1074642.4533, MAE: 4077.5093, R2: 0.0936\n",
      "==========================================================================================\n",
      "Epoch [2101/5000] | Time: 0.24s\n",
      "(Training) Loss: 1027941.2467\n",
      "(Validation) Loss: 1074457.5746, MAE: 4076.5791, R2: 0.0938\n",
      "==========================================================================================\n",
      "Epoch [2102/5000] | Time: 0.22s\n",
      "(Training) Loss: 1056325.8712\n",
      "(Validation) Loss: 1074273.4578, MAE: 4074.6226, R2: 0.0939\n",
      "==========================================================================================\n",
      "Epoch [2103/5000] | Time: 0.22s\n",
      "(Training) Loss: 1035642.8401\n",
      "(Validation) Loss: 1074088.7619, MAE: 4074.2937, R2: 0.0941\n",
      "==========================================================================================\n",
      "Epoch [2104/5000] | Time: 0.21s\n",
      "(Training) Loss: 1037859.0247\n",
      "(Validation) Loss: 1073908.2463, MAE: 4074.1218, R2: 0.0942\n",
      "==========================================================================================\n",
      "Epoch [2105/5000] | Time: 0.19s\n",
      "(Training) Loss: 1042064.0381\n",
      "(Validation) Loss: 1073726.5981, MAE: 4074.0049, R2: 0.0944\n",
      "==========================================================================================\n",
      "Epoch [2106/5000] | Time: 0.20s\n",
      "(Training) Loss: 1038972.6808\n",
      "(Validation) Loss: 1073537.9606, MAE: 4072.8267, R2: 0.0946\n",
      "==========================================================================================\n",
      "Epoch [2107/5000] | Time: 0.24s\n",
      "(Training) Loss: 1054457.6713\n",
      "(Validation) Loss: 1073369.9556, MAE: 4076.0730, R2: 0.0947\n",
      "==========================================================================================\n",
      "Epoch [2108/5000] | Time: 0.21s\n",
      "(Training) Loss: 1044376.8959\n",
      "(Validation) Loss: 1073179.6165, MAE: 4074.2051, R2: 0.0949\n",
      "==========================================================================================\n",
      "Epoch [2109/5000] | Time: 0.19s\n",
      "(Training) Loss: 1026755.7197\n",
      "(Validation) Loss: 1072995.1390, MAE: 4072.2771, R2: 0.0950\n",
      "==========================================================================================\n",
      "Epoch [2110/5000] | Time: 0.19s\n",
      "(Training) Loss: 1042826.9778\n",
      "(Validation) Loss: 1072810.2502, MAE: 4070.9893, R2: 0.0952\n",
      "==========================================================================================\n",
      "Epoch [2111/5000] | Time: 0.19s\n",
      "(Training) Loss: 1025888.8406\n",
      "(Validation) Loss: 1072626.5549, MAE: 4070.3469, R2: 0.0953\n",
      "==========================================================================================\n",
      "Epoch [2112/5000] | Time: 0.19s\n",
      "(Training) Loss: 1037899.6618\n",
      "(Validation) Loss: 1072461.8057, MAE: 4073.7290, R2: 0.0955\n",
      "==========================================================================================\n",
      "Epoch [2113/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046108.4086\n",
      "(Validation) Loss: 1072265.5543, MAE: 4069.1155, R2: 0.0956\n",
      "==========================================================================================\n",
      "Epoch [2114/5000] | Time: 0.21s\n",
      "(Training) Loss: 1028050.1482\n",
      "(Validation) Loss: 1072077.8463, MAE: 4067.8682, R2: 0.0958\n",
      "==========================================================================================\n",
      "Epoch [2115/5000] | Time: 0.20s\n",
      "(Training) Loss: 1047107.2500\n",
      "(Validation) Loss: 1071901.6940, MAE: 4067.8079, R2: 0.0959\n",
      "==========================================================================================\n",
      "Epoch [2116/5000] | Time: 0.21s\n",
      "(Training) Loss: 1064279.1992\n",
      "(Validation) Loss: 1071713.0565, MAE: 4066.1460, R2: 0.0961\n",
      "==========================================================================================\n",
      "Epoch [2117/5000] | Time: 0.19s\n",
      "(Training) Loss: 1039339.2170\n",
      "(Validation) Loss: 1071529.1581, MAE: 4067.1201, R2: 0.0962\n",
      "==========================================================================================\n",
      "Epoch [2118/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023901.1330\n",
      "(Validation) Loss: 1071349.0032, MAE: 4067.5049, R2: 0.0964\n",
      "==========================================================================================\n",
      "Epoch [2119/5000] | Time: 0.23s\n",
      "(Training) Loss: 1055773.7259\n",
      "(Validation) Loss: 1071165.2267, MAE: 4065.6819, R2: 0.0965\n",
      "==========================================================================================\n",
      "Epoch [2120/5000] | Time: 0.22s\n",
      "(Training) Loss: 1046717.5933\n",
      "(Validation) Loss: 1070985.4679, MAE: 4067.3274, R2: 0.0967\n",
      "==========================================================================================\n",
      "Epoch [2121/5000] | Time: 0.23s\n",
      "(Training) Loss: 1035153.8230\n",
      "(Validation) Loss: 1070803.7994, MAE: 4065.1577, R2: 0.0968\n",
      "==========================================================================================\n",
      "Epoch [2122/5000] | Time: 0.21s\n",
      "(Training) Loss: 1062410.9277\n",
      "(Validation) Loss: 1070623.6241, MAE: 4068.5293, R2: 0.0970\n",
      "==========================================================================================\n",
      "Epoch [2123/5000] | Time: 0.24s\n",
      "(Training) Loss: 1029021.7849\n",
      "(Validation) Loss: 1070435.4438, MAE: 4063.6123, R2: 0.0971\n",
      "==========================================================================================\n",
      "Epoch [2124/5000] | Time: 0.23s\n",
      "(Training) Loss: 1031872.9404\n",
      "(Validation) Loss: 1070253.4298, MAE: 4063.7314, R2: 0.0973\n",
      "==========================================================================================\n",
      "Epoch [2125/5000] | Time: 0.20s\n",
      "(Training) Loss: 1037306.3198\n",
      "(Validation) Loss: 1070137.7524, MAE: 4065.2705, R2: 0.0974\n",
      "==========================================================================================\n",
      "Epoch [2126/5000] | Time: 0.20s\n",
      "(Training) Loss: 1025397.2535\n",
      "(Validation) Loss: 1069956.1752, MAE: 4065.6150, R2: 0.0975\n",
      "==========================================================================================\n",
      "Epoch [2127/5000] | Time: 0.20s\n",
      "(Training) Loss: 1039629.9175\n",
      "(Validation) Loss: 1069773.3841, MAE: 4063.9844, R2: 0.0977\n",
      "==========================================================================================\n",
      "Epoch [2128/5000] | Time: 0.25s\n",
      "(Training) Loss: 1046076.3445\n",
      "(Validation) Loss: 1069596.1651, MAE: 4066.0359, R2: 0.0978\n",
      "==========================================================================================\n",
      "Epoch [2129/5000] | Time: 0.23s\n",
      "(Training) Loss: 1031255.3014\n",
      "(Validation) Loss: 1069409.1124, MAE: 4063.5410, R2: 0.0980\n",
      "==========================================================================================\n",
      "Epoch [2130/5000] | Time: 0.25s\n",
      "(Training) Loss: 1031031.6060\n",
      "(Validation) Loss: 1069232.1676, MAE: 4063.4089, R2: 0.0981\n",
      "==========================================================================================\n",
      "Epoch [2131/5000] | Time: 0.22s\n",
      "(Training) Loss: 1037082.8966\n",
      "(Validation) Loss: 1069143.2889, MAE: 4070.0918, R2: 0.0982\n",
      "==========================================================================================\n",
      "Epoch [2132/5000] | Time: 0.20s\n",
      "(Training) Loss: 1038707.7716\n",
      "(Validation) Loss: 1068890.2705, MAE: 4068.1265, R2: 0.0984\n",
      "==========================================================================================\n",
      "Epoch [2133/5000] | Time: 0.24s\n",
      "(Training) Loss: 1067009.5622\n",
      "(Validation) Loss: 1068685.2063, MAE: 4061.6555, R2: 0.0986\n",
      "==========================================================================================\n",
      "Epoch [2134/5000] | Time: 0.24s\n",
      "(Training) Loss: 1036096.4594\n",
      "(Validation) Loss: 1068494.3746, MAE: 4060.2039, R2: 0.0988\n",
      "==========================================================================================\n",
      "Epoch [2135/5000] | Time: 0.22s\n",
      "(Training) Loss: 1029496.4315\n",
      "(Validation) Loss: 1068321.3765, MAE: 4061.1868, R2: 0.0989\n",
      "==========================================================================================\n",
      "Epoch [2136/5000] | Time: 0.21s\n",
      "(Training) Loss: 1028994.4283\n",
      "(Validation) Loss: 1068131.2305, MAE: 4058.7407, R2: 0.0991\n",
      "==========================================================================================\n",
      "Epoch [2137/5000] | Time: 0.20s\n",
      "(Training) Loss: 1043583.2652\n",
      "(Validation) Loss: 1067953.4222, MAE: 4058.2271, R2: 0.0992\n",
      "==========================================================================================\n",
      "Epoch [2138/5000] | Time: 0.25s\n",
      "(Training) Loss: 1032949.7665\n",
      "(Validation) Loss: 1067771.7994, MAE: 4059.7166, R2: 0.0994\n",
      "==========================================================================================\n",
      "Epoch [2139/5000] | Time: 0.21s\n",
      "(Training) Loss: 1044906.0876\n",
      "(Validation) Loss: 1067590.2222, MAE: 4057.5833, R2: 0.0995\n",
      "==========================================================================================\n",
      "Epoch [2140/5000] | Time: 0.20s\n",
      "(Training) Loss: 1053297.2843\n",
      "(Validation) Loss: 1067408.8127, MAE: 4058.0796, R2: 0.0997\n",
      "==========================================================================================\n",
      "Epoch [2141/5000] | Time: 0.20s\n",
      "(Training) Loss: 1022710.0286\n",
      "(Validation) Loss: 1067223.6698, MAE: 4056.1304, R2: 0.0998\n",
      "==========================================================================================\n",
      "Epoch [2142/5000] | Time: 0.22s\n",
      "(Training) Loss: 1026461.4810\n",
      "(Validation) Loss: 1067040.0305, MAE: 4055.6858, R2: 0.1000\n",
      "==========================================================================================\n",
      "Epoch [2143/5000] | Time: 0.24s\n",
      "(Training) Loss: 1041924.1177\n",
      "(Validation) Loss: 1066880.1422, MAE: 4061.2566, R2: 0.1001\n",
      "==========================================================================================\n",
      "Epoch [2144/5000] | Time: 0.20s\n",
      "(Training) Loss: 1028658.6206\n",
      "(Validation) Loss: 1066674.9156, MAE: 4053.2642, R2: 0.1003\n",
      "==========================================================================================\n",
      "Epoch [2145/5000] | Time: 0.23s\n",
      "(Training) Loss: 1026420.7373\n",
      "(Validation) Loss: 1066495.8781, MAE: 4052.5542, R2: 0.1004\n",
      "==========================================================================================\n",
      "Epoch [2146/5000] | Time: 0.21s\n",
      "(Training) Loss: 1030674.1574\n",
      "(Validation) Loss: 1066318.3340, MAE: 4054.3518, R2: 0.1006\n",
      "==========================================================================================\n",
      "Epoch [2147/5000] | Time: 0.21s\n",
      "(Training) Loss: 1021613.6954\n",
      "(Validation) Loss: 1066130.8444, MAE: 4051.7083, R2: 0.1007\n",
      "==========================================================================================\n",
      "Epoch [2148/5000] | Time: 0.23s\n",
      "(Training) Loss: 1027023.7354\n",
      "(Validation) Loss: 1065950.9841, MAE: 4050.8025, R2: 0.1009\n",
      "==========================================================================================\n",
      "Epoch [2149/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023505.7367\n",
      "(Validation) Loss: 1065772.3530, MAE: 4050.8894, R2: 0.1010\n",
      "==========================================================================================\n",
      "Epoch [2150/5000] | Time: 0.23s\n",
      "(Training) Loss: 1040080.4581\n",
      "(Validation) Loss: 1065589.9276, MAE: 4049.4924, R2: 0.1012\n",
      "==========================================================================================\n",
      "Epoch [2151/5000] | Time: 0.24s\n",
      "(Training) Loss: 1033410.4112\n",
      "(Validation) Loss: 1065412.4851, MAE: 4050.2988, R2: 0.1013\n",
      "==========================================================================================\n",
      "Epoch [2152/5000] | Time: 0.26s\n",
      "(Training) Loss: 1044013.2881\n",
      "(Validation) Loss: 1065246.2476, MAE: 4052.7664, R2: 0.1015\n",
      "==========================================================================================\n",
      "Epoch [2153/5000] | Time: 0.20s\n",
      "(Training) Loss: 1039010.9797\n",
      "(Validation) Loss: 1065046.6235, MAE: 4049.9199, R2: 0.1016\n",
      "==========================================================================================\n",
      "Epoch [2154/5000] | Time: 0.22s\n",
      "(Training) Loss: 1025169.7951\n",
      "(Validation) Loss: 1064865.3003, MAE: 4048.4915, R2: 0.1018\n",
      "==========================================================================================\n",
      "Epoch [2155/5000] | Time: 0.21s\n",
      "(Training) Loss: 1022195.6339\n",
      "(Validation) Loss: 1064678.6997, MAE: 4046.1133, R2: 0.1019\n",
      "==========================================================================================\n",
      "Epoch [2156/5000] | Time: 0.20s\n",
      "(Training) Loss: 1034121.8756\n",
      "(Validation) Loss: 1064497.6660, MAE: 4045.6536, R2: 0.1021\n",
      "==========================================================================================\n",
      "Epoch [2157/5000] | Time: 0.19s\n",
      "(Training) Loss: 1027204.6180\n",
      "(Validation) Loss: 1064320.2489, MAE: 4046.2053, R2: 0.1022\n",
      "==========================================================================================\n",
      "Epoch [2158/5000] | Time: 0.23s\n",
      "(Training) Loss: 1028450.7992\n",
      "(Validation) Loss: 1064139.9975, MAE: 4046.9558, R2: 0.1024\n",
      "==========================================================================================\n",
      "Epoch [2159/5000] | Time: 0.23s\n",
      "(Training) Loss: 1024153.9835\n",
      "(Validation) Loss: 1063956.4190, MAE: 4044.6423, R2: 0.1025\n",
      "==========================================================================================\n",
      "Epoch [2160/5000] | Time: 0.22s\n",
      "(Training) Loss: 1044598.3338\n",
      "(Validation) Loss: 1063777.4070, MAE: 4043.4036, R2: 0.1027\n",
      "==========================================================================================\n",
      "Epoch [2161/5000] | Time: 0.24s\n",
      "(Training) Loss: 1024950.4695\n",
      "(Validation) Loss: 1063534.8724, MAE: 4048.4363, R2: 0.1029\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2162/5000] | Time: 0.21s\n",
      "(Training) Loss: 1016549.8165\n",
      "(Validation) Loss: 1063298.2044, MAE: 4035.7480, R2: 0.1031\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2163/5000] | Time: 0.23s\n",
      "(Training) Loss: 1022115.3598\n",
      "(Validation) Loss: 1063117.5924, MAE: 4033.9727, R2: 0.1032\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2164/5000] | Time: 0.22s\n",
      "(Training) Loss: 1034692.4289\n",
      "(Validation) Loss: 1062938.9410, MAE: 4033.1289, R2: 0.1034\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2165/5000] | Time: 0.20s\n",
      "(Training) Loss: 1020063.2468\n",
      "(Validation) Loss: 1062759.0451, MAE: 4032.1682, R2: 0.1035\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2166/5000] | Time: 0.20s\n",
      "(Training) Loss: 1025945.5076\n",
      "(Validation) Loss: 1062581.4146, MAE: 4031.9849, R2: 0.1037\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2167/5000] | Time: 0.20s\n",
      "(Training) Loss: 1025967.1751\n",
      "(Validation) Loss: 1062399.3651, MAE: 4031.1160, R2: 0.1038\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2168/5000] | Time: 0.21s\n",
      "(Training) Loss: 1034185.8858\n",
      "(Validation) Loss: 1062269.0743, MAE: 4034.6455, R2: 0.1039\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2169/5000] | Time: 0.24s\n",
      "(Training) Loss: 1027909.9937\n",
      "(Validation) Loss: 1062092.3327, MAE: 4035.4504, R2: 0.1041\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2170/5000] | Time: 0.21s\n",
      "(Training) Loss: 1023576.1707\n",
      "(Validation) Loss: 1061903.9695, MAE: 4033.0315, R2: 0.1043\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2171/5000] | Time: 0.20s\n",
      "(Training) Loss: 1046451.2208\n",
      "(Validation) Loss: 1061722.3111, MAE: 4032.4263, R2: 0.1044\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2172/5000] | Time: 0.20s\n",
      "(Training) Loss: 1027935.5482\n",
      "(Validation) Loss: 1061538.0165, MAE: 4029.9253, R2: 0.1046\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2173/5000] | Time: 0.20s\n",
      "(Training) Loss: 1027018.7430\n",
      "(Validation) Loss: 1061364.9168, MAE: 4032.2402, R2: 0.1047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2174/5000] | Time: 0.20s\n",
      "(Training) Loss: 1019549.2563\n",
      "(Validation) Loss: 1061173.8006, MAE: 4029.6196, R2: 0.1049\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2175/5000] | Time: 0.20s\n",
      "(Training) Loss: 1027026.7646\n",
      "(Validation) Loss: 1061001.4730, MAE: 4029.3735, R2: 0.1050\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2176/5000] | Time: 0.22s\n",
      "(Training) Loss: 1043328.6504\n",
      "(Validation) Loss: 1060749.6127, MAE: 4026.7676, R2: 0.1052\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2177/5000] | Time: 0.19s\n",
      "(Training) Loss: 1026332.7227\n",
      "(Validation) Loss: 1060550.5321, MAE: 4021.1758, R2: 0.1054\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2178/5000] | Time: 0.20s\n",
      "(Training) Loss: 1017374.5631\n",
      "(Validation) Loss: 1060421.1302, MAE: 4030.3257, R2: 0.1055\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2179/5000] | Time: 0.22s\n",
      "(Training) Loss: 1023362.7405\n",
      "(Validation) Loss: 1060230.7403, MAE: 4024.2227, R2: 0.1056\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2180/5000] | Time: 0.22s\n",
      "(Training) Loss: 1042672.5362\n",
      "(Validation) Loss: 1060028.9930, MAE: 4023.1204, R2: 0.1058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2181/5000] | Time: 0.21s\n",
      "(Training) Loss: 1028004.6675\n",
      "(Validation) Loss: 1059873.3816, MAE: 4024.2971, R2: 0.1059\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2182/5000] | Time: 0.25s\n",
      "(Training) Loss: 1052907.7900\n",
      "(Validation) Loss: 1059683.0578, MAE: 4020.4856, R2: 0.1061\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2183/5000] | Time: 0.21s\n",
      "(Training) Loss: 1033246.2893\n",
      "(Validation) Loss: 1059501.9632, MAE: 4020.1206, R2: 0.1063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2184/5000] | Time: 0.20s\n",
      "(Training) Loss: 1036956.9239\n",
      "(Validation) Loss: 1059322.5448, MAE: 4019.8894, R2: 0.1064\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2185/5000] | Time: 0.21s\n",
      "(Training) Loss: 1034362.7214\n",
      "(Validation) Loss: 1059176.1575, MAE: 4023.9802, R2: 0.1065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2186/5000] | Time: 0.20s\n",
      "(Training) Loss: 1020160.9937\n",
      "(Validation) Loss: 1059011.9721, MAE: 4023.7949, R2: 0.1067\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2187/5000] | Time: 0.20s\n",
      "(Training) Loss: 1015771.7040\n",
      "(Validation) Loss: 1058830.4457, MAE: 4023.2957, R2: 0.1068\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2188/5000] | Time: 0.22s\n",
      "(Training) Loss: 1024282.7805\n",
      "(Validation) Loss: 1058648.7467, MAE: 4020.9358, R2: 0.1070\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2189/5000] | Time: 0.22s\n",
      "(Training) Loss: 1030676.3580\n",
      "(Validation) Loss: 1058464.6756, MAE: 4019.7932, R2: 0.1071\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2190/5000] | Time: 0.25s\n",
      "(Training) Loss: 1017071.0044\n",
      "(Validation) Loss: 1058283.2406, MAE: 4019.4968, R2: 0.1073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2191/5000] | Time: 0.22s\n",
      "(Training) Loss: 1020225.7059\n",
      "(Validation) Loss: 1058100.5105, MAE: 4018.3889, R2: 0.1074\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2192/5000] | Time: 0.22s\n",
      "(Training) Loss: 1023917.2995\n",
      "(Validation) Loss: 1057928.1778, MAE: 4018.6035, R2: 0.1076\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2193/5000] | Time: 0.22s\n",
      "(Training) Loss: 1016500.6713\n",
      "(Validation) Loss: 1057750.7302, MAE: 4020.2422, R2: 0.1077\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2194/5000] | Time: 0.25s\n",
      "(Training) Loss: 1024313.5038\n",
      "(Validation) Loss: 1057565.4959, MAE: 4017.0239, R2: 0.1079\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2195/5000] | Time: 0.23s\n",
      "(Training) Loss: 1037344.3706\n",
      "(Validation) Loss: 1057382.7048, MAE: 4014.8228, R2: 0.1080\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2196/5000] | Time: 0.31s\n",
      "(Training) Loss: 1018783.0844\n",
      "(Validation) Loss: 1057209.8844, MAE: 4017.0156, R2: 0.1082\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2197/5000] | Time: 0.22s\n",
      "(Training) Loss: 1027907.5539\n",
      "(Validation) Loss: 1057022.9435, MAE: 4015.0049, R2: 0.1083\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2198/5000] | Time: 0.20s\n",
      "(Training) Loss: 1019705.2697\n",
      "(Validation) Loss: 1056841.5543, MAE: 4013.6089, R2: 0.1085\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2199/5000] | Time: 0.21s\n",
      "(Training) Loss: 1020700.5070\n",
      "(Validation) Loss: 1056665.4832, MAE: 4014.4050, R2: 0.1086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2200/5000] | Time: 0.23s\n",
      "(Training) Loss: 1021121.2462\n",
      "(Validation) Loss: 1056488.1473, MAE: 4015.4429, R2: 0.1088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2201/5000] | Time: 0.23s\n",
      "(Training) Loss: 1020219.1662\n",
      "(Validation) Loss: 1056301.3283, MAE: 4013.4775, R2: 0.1089\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2202/5000] | Time: 0.21s\n",
      "(Training) Loss: 1032085.1980\n",
      "(Validation) Loss: 1056132.8965, MAE: 4014.6716, R2: 0.1091\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2203/5000] | Time: 0.22s\n",
      "(Training) Loss: 1022771.8769\n",
      "(Validation) Loss: 1055943.7359, MAE: 4012.1353, R2: 0.1092\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2204/5000] | Time: 0.24s\n",
      "(Training) Loss: 1017876.6840\n",
      "(Validation) Loss: 1055759.5987, MAE: 4011.4546, R2: 0.1094\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2205/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023036.8204\n",
      "(Validation) Loss: 1055586.6311, MAE: 4012.7593, R2: 0.1095\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2206/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012821.9952\n",
      "(Validation) Loss: 1055404.5867, MAE: 4010.2346, R2: 0.1097\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2207/5000] | Time: 0.23s\n",
      "(Training) Loss: 1018319.7081\n",
      "(Validation) Loss: 1055223.4210, MAE: 4009.2322, R2: 0.1098\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2208/5000] | Time: 0.24s\n",
      "(Training) Loss: 1049368.7887\n",
      "(Validation) Loss: 1055093.7346, MAE: 4014.0220, R2: 0.1099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2209/5000] | Time: 0.24s\n",
      "(Training) Loss: 1020851.0527\n",
      "(Validation) Loss: 1054858.3263, MAE: 4007.8416, R2: 0.1101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2210/5000] | Time: 0.20s\n",
      "(Training) Loss: 1057692.0596\n",
      "(Validation) Loss: 1054689.3765, MAE: 4009.1492, R2: 0.1103\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2211/5000] | Time: 0.22s\n",
      "(Training) Loss: 1017049.8794\n",
      "(Validation) Loss: 1054492.5867, MAE: 4006.1758, R2: 0.1104\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2212/5000] | Time: 0.22s\n",
      "(Training) Loss: 1040725.6402\n",
      "(Validation) Loss: 1054312.4317, MAE: 4004.9399, R2: 0.1106\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2213/5000] | Time: 0.22s\n",
      "(Training) Loss: 1021644.2030\n",
      "(Validation) Loss: 1049208.6806, MAE: 3997.7793, R2: 0.1148\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2214/5000] | Time: 0.24s\n",
      "(Training) Loss: 1021399.6028\n",
      "(Validation) Loss: 1051585.5898, MAE: 4001.7197, R2: 0.1128\n",
      "==========================================================================================\n",
      "Epoch [2215/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006991.3207\n",
      "(Validation) Loss: 1051398.4914, MAE: 3999.5515, R2: 0.1130\n",
      "==========================================================================================\n",
      "Epoch [2216/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010707.5159\n",
      "(Validation) Loss: 1051230.0394, MAE: 3997.7302, R2: 0.1131\n",
      "==========================================================================================\n",
      "Epoch [2217/5000] | Time: 0.22s\n",
      "(Training) Loss: 1018353.9410\n",
      "(Validation) Loss: 1051063.0552, MAE: 3997.6829, R2: 0.1133\n",
      "==========================================================================================\n",
      "Epoch [2218/5000] | Time: 0.23s\n",
      "(Training) Loss: 1035023.2329\n",
      "(Validation) Loss: 1050894.1511, MAE: 3996.7131, R2: 0.1134\n",
      "==========================================================================================\n",
      "Epoch [2219/5000] | Time: 0.28s\n",
      "(Training) Loss: 1009967.9397\n",
      "(Validation) Loss: 1050723.0984, MAE: 3995.8735, R2: 0.1136\n",
      "==========================================================================================\n",
      "Epoch [2220/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014753.2421\n",
      "(Validation) Loss: 1050554.8089, MAE: 3993.2517, R2: 0.1137\n",
      "==========================================================================================\n",
      "Epoch [2221/5000] | Time: 0.22s\n",
      "(Training) Loss: 1052744.3480\n",
      "(Validation) Loss: 1050382.0902, MAE: 3992.4102, R2: 0.1139\n",
      "==========================================================================================\n",
      "Epoch [2222/5000] | Time: 0.25s\n",
      "(Training) Loss: 1013887.0984\n",
      "(Validation) Loss: 1050210.0724, MAE: 3991.5349, R2: 0.1140\n",
      "==========================================================================================\n",
      "Epoch [2223/5000] | Time: 0.25s\n",
      "(Training) Loss: 1047980.9797\n",
      "(Validation) Loss: 1050038.0902, MAE: 3989.6311, R2: 0.1141\n",
      "==========================================================================================\n",
      "Epoch [2224/5000] | Time: 0.25s\n",
      "(Training) Loss: 1006129.6878\n",
      "(Validation) Loss: 1049868.1803, MAE: 3990.9207, R2: 0.1143\n",
      "==========================================================================================\n",
      "Epoch [2225/5000] | Time: 0.26s\n",
      "(Training) Loss: 1018471.6104\n",
      "(Validation) Loss: 1049699.9010, MAE: 3988.9844, R2: 0.1144\n",
      "==========================================================================================\n",
      "Epoch [2226/5000] | Time: 0.22s\n",
      "(Training) Loss: 1018827.1859\n",
      "(Validation) Loss: 1049539.7841, MAE: 3997.5588, R2: 0.1146\n",
      "==========================================================================================\n",
      "Epoch [2227/5000] | Time: 0.22s\n",
      "(Training) Loss: 1018939.4740\n",
      "(Validation) Loss: 1049343.9187, MAE: 3990.3096, R2: 0.1147\n",
      "==========================================================================================\n",
      "Epoch [2228/5000] | Time: 0.25s\n",
      "(Training) Loss: 1015222.2570\n",
      "(Validation) Loss: 1049231.4260, MAE: 3999.3157, R2: 0.1148\n",
      "==========================================================================================\n",
      "Epoch [2229/5000] | Time: 0.22s\n",
      "(Training) Loss: 1025879.3617\n",
      "(Validation) Loss: 1049001.3308, MAE: 3987.1509, R2: 0.1150\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2230/5000] | Time: 0.24s\n",
      "(Training) Loss: 1033017.1110\n",
      "(Validation) Loss: 1048865.5035, MAE: 3989.0701, R2: 0.1151\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2231/5000] | Time: 0.24s\n",
      "(Training) Loss: 1030254.2944\n",
      "(Validation) Loss: 1048690.2248, MAE: 3985.6885, R2: 0.1153\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2232/5000] | Time: 0.27s\n",
      "(Training) Loss: 1018143.9467\n",
      "(Validation) Loss: 1048525.2114, MAE: 3986.7234, R2: 0.1154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2233/5000] | Time: 0.23s\n",
      "(Training) Loss: 1030078.5901\n",
      "(Validation) Loss: 1048352.9498, MAE: 3984.0886, R2: 0.1155\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2234/5000] | Time: 0.22s\n",
      "(Training) Loss: 1014195.0266\n",
      "(Validation) Loss: 1048183.0705, MAE: 3984.5315, R2: 0.1157\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2235/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007693.6523\n",
      "(Validation) Loss: 1048013.2368, MAE: 3983.1060, R2: 0.1158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2236/5000] | Time: 0.26s\n",
      "(Training) Loss: 1020471.3877\n",
      "(Validation) Loss: 1041871.8984, MAE: 3966.3435, R2: 0.1209\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2237/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009096.6478\n",
      "(Validation) Loss: 1048834.6159, MAE: 3997.7263, R2: 0.1151\n",
      "==========================================================================================\n",
      "Epoch [2238/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012619.4524\n",
      "(Validation) Loss: 1043326.7657, MAE: 3967.6978, R2: 0.1197\n",
      "==========================================================================================\n",
      "Epoch [2239/5000] | Time: 0.22s\n",
      "(Training) Loss: 1038611.5761\n",
      "(Validation) Loss: 1043142.5473, MAE: 3966.8647, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [2240/5000] | Time: 0.23s\n",
      "(Training) Loss: 1002749.7938\n",
      "(Validation) Loss: 1042964.7797, MAE: 3968.0996, R2: 0.1200\n",
      "==========================================================================================\n",
      "Epoch [2241/5000] | Time: 0.22s\n",
      "(Training) Loss: 1025008.0444\n",
      "(Validation) Loss: 1042791.6343, MAE: 3968.0337, R2: 0.1202\n",
      "==========================================================================================\n",
      "Epoch [2242/5000] | Time: 0.27s\n",
      "(Training) Loss: 1013035.3629\n",
      "(Validation) Loss: 1042600.8381, MAE: 3964.7676, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [2243/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010459.8471\n",
      "(Validation) Loss: 1042426.8902, MAE: 3964.4451, R2: 0.1205\n",
      "==========================================================================================\n",
      "Epoch [2244/5000] | Time: 0.23s\n",
      "(Training) Loss: 1022468.2310\n",
      "(Validation) Loss: 1042252.4292, MAE: 3963.8711, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [2245/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005324.7563\n",
      "(Validation) Loss: 1042072.7111, MAE: 3962.8020, R2: 0.1208\n",
      "==========================================================================================\n",
      "Epoch [2246/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014307.9886\n",
      "(Validation) Loss: 1041922.9917, MAE: 3969.3149, R2: 0.1209\n",
      "==========================================================================================\n",
      "Epoch [2247/5000] | Time: 0.25s\n",
      "(Training) Loss: 1031797.7881\n",
      "(Validation) Loss: 1041745.0057, MAE: 3967.7781, R2: 0.1211\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2248/5000] | Time: 0.25s\n",
      "(Training) Loss: 1013816.8382\n",
      "(Validation) Loss: 1041589.9124, MAE: 3973.7380, R2: 0.1212\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2249/5000] | Time: 0.23s\n",
      "(Training) Loss: 1029200.9365\n",
      "(Validation) Loss: 1041384.1524, MAE: 3963.0845, R2: 0.1214\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2250/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008312.4937\n",
      "(Validation) Loss: 1041206.0343, MAE: 3961.2314, R2: 0.1215\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2251/5000] | Time: 0.27s\n",
      "(Training) Loss: 1000619.4791\n",
      "(Validation) Loss: 1041044.2311, MAE: 3962.2507, R2: 0.1216\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2252/5000] | Time: 0.25s\n",
      "(Training) Loss: 996874.1735\n",
      "(Validation) Loss: 1040868.5308, MAE: 3960.5200, R2: 0.1218\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2253/5000] | Time: 0.26s\n",
      "(Training) Loss: 1007108.9429\n",
      "(Validation) Loss: 1040700.8965, MAE: 3962.1016, R2: 0.1219\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2254/5000] | Time: 0.27s\n",
      "(Training) Loss: 1045107.7411\n",
      "(Validation) Loss: 1040527.1263, MAE: 3961.1621, R2: 0.1221\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2255/5000] | Time: 0.27s\n",
      "(Training) Loss: 1006861.8731\n",
      "(Validation) Loss: 1044174.6032, MAE: 3974.5000, R2: 0.1192\n",
      "==========================================================================================\n",
      "Epoch [2256/5000] | Time: 0.27s\n",
      "(Training) Loss: 1014775.9391\n",
      "(Validation) Loss: 1040188.2971, MAE: 3962.3196, R2: 0.1223\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2257/5000] | Time: 0.29s\n",
      "(Training) Loss: 996611.2766\n",
      "(Validation) Loss: 1040002.0368, MAE: 3961.0596, R2: 0.1225\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2258/5000] | Time: 0.27s\n",
      "(Training) Loss: 1014809.2037\n",
      "(Validation) Loss: 1039875.5860, MAE: 3967.9771, R2: 0.1226\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2259/5000] | Time: 0.28s\n",
      "(Training) Loss: 1015270.2881\n",
      "(Validation) Loss: 1054096.3505, MAE: 4008.9644, R2: 0.1108\n",
      "==========================================================================================\n",
      "Epoch [2260/5000] | Time: 0.24s\n",
      "(Training) Loss: 1028026.7088\n",
      "(Validation) Loss: 1053904.3505, MAE: 4002.0198, R2: 0.1109\n",
      "==========================================================================================\n",
      "Epoch [2261/5000] | Time: 0.26s\n",
      "(Training) Loss: 1030756.6954\n",
      "(Validation) Loss: 1053731.6927, MAE: 4003.6736, R2: 0.1111\n",
      "==========================================================================================\n",
      "Epoch [2262/5000] | Time: 0.29s\n",
      "(Training) Loss: 1018279.1104\n",
      "(Validation) Loss: 1053555.6825, MAE: 4002.0178, R2: 0.1112\n",
      "==========================================================================================\n",
      "Epoch [2263/5000] | Time: 0.32s\n",
      "(Training) Loss: 1046095.5514\n",
      "(Validation) Loss: 1053420.1346, MAE: 4004.0518, R2: 0.1113\n",
      "==========================================================================================\n",
      "Epoch [2264/5000] | Time: 0.30s\n",
      "(Training) Loss: 1033403.8591\n",
      "(Validation) Loss: 1053244.1905, MAE: 4002.8982, R2: 0.1115\n",
      "==========================================================================================\n",
      "Epoch [2265/5000] | Time: 0.26s\n",
      "(Training) Loss: 1007552.0335\n",
      "(Validation) Loss: 1053068.6679, MAE: 4003.8159, R2: 0.1116\n",
      "==========================================================================================\n",
      "Epoch [2266/5000] | Time: 0.25s\n",
      "(Training) Loss: 1027631.7621\n",
      "(Validation) Loss: 1052900.4800, MAE: 4003.4521, R2: 0.1118\n",
      "==========================================================================================\n",
      "Epoch [2267/5000] | Time: 0.28s\n",
      "(Training) Loss: 1014519.1758\n",
      "(Validation) Loss: 1052700.6730, MAE: 4007.0032, R2: 0.1119\n",
      "==========================================================================================\n",
      "Epoch [2268/5000] | Time: 0.26s\n",
      "(Training) Loss: 1021854.0089\n",
      "(Validation) Loss: 1052513.7371, MAE: 4002.0469, R2: 0.1121\n",
      "==========================================================================================\n",
      "Epoch [2269/5000] | Time: 0.29s\n",
      "(Training) Loss: 1029113.6720\n",
      "(Validation) Loss: 1047526.9537, MAE: 3985.7092, R2: 0.1162\n",
      "==========================================================================================\n",
      "Epoch [2270/5000] | Time: 0.28s\n",
      "(Training) Loss: 1025107.0514\n",
      "(Validation) Loss: 1047367.5479, MAE: 3981.7092, R2: 0.1164\n",
      "==========================================================================================\n",
      "Epoch [2271/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019579.9822\n",
      "(Validation) Loss: 1047235.8603, MAE: 3986.8804, R2: 0.1165\n",
      "==========================================================================================\n",
      "Epoch [2272/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010431.0996\n",
      "(Validation) Loss: 1047055.2686, MAE: 3984.0906, R2: 0.1166\n",
      "==========================================================================================\n",
      "Epoch [2273/5000] | Time: 0.23s\n",
      "(Training) Loss: 1015194.8706\n",
      "(Validation) Loss: 1046893.9327, MAE: 3984.5129, R2: 0.1168\n",
      "==========================================================================================\n",
      "Epoch [2274/5000] | Time: 0.22s\n",
      "(Training) Loss: 1025603.1218\n",
      "(Validation) Loss: 1046712.3962, MAE: 3980.5835, R2: 0.1169\n",
      "==========================================================================================\n",
      "Epoch [2275/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010357.1929\n",
      "(Validation) Loss: 1046543.7511, MAE: 3980.0950, R2: 0.1171\n",
      "==========================================================================================\n",
      "Epoch [2276/5000] | Time: 0.22s\n",
      "(Training) Loss: 1017917.1079\n",
      "(Validation) Loss: 1046376.7365, MAE: 3980.6831, R2: 0.1172\n",
      "==========================================================================================\n",
      "Epoch [2277/5000] | Time: 0.22s\n",
      "(Training) Loss: 1003236.3008\n",
      "(Validation) Loss: 1046236.2159, MAE: 3981.4153, R2: 0.1173\n",
      "==========================================================================================\n",
      "Epoch [2278/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008954.1085\n",
      "(Validation) Loss: 1046039.8425, MAE: 3979.1545, R2: 0.1175\n",
      "==========================================================================================\n",
      "Epoch [2279/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009055.2481\n",
      "(Validation) Loss: 1045886.6489, MAE: 3983.6267, R2: 0.1176\n",
      "==========================================================================================\n",
      "Epoch [2280/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012981.7881\n",
      "(Validation) Loss: 1045697.1835, MAE: 3976.0151, R2: 0.1178\n",
      "==========================================================================================\n",
      "Epoch [2281/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002833.0955\n",
      "(Validation) Loss: 1045528.9346, MAE: 3975.5881, R2: 0.1179\n",
      "==========================================================================================\n",
      "Epoch [2282/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007653.2893\n",
      "(Validation) Loss: 1045363.1340, MAE: 3975.4680, R2: 0.1180\n",
      "==========================================================================================\n",
      "Epoch [2283/5000] | Time: 0.29s\n",
      "(Training) Loss: 1012506.3407\n",
      "(Validation) Loss: 1045251.5200, MAE: 3979.1155, R2: 0.1181\n",
      "==========================================================================================\n",
      "Epoch [2284/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007594.9892\n",
      "(Validation) Loss: 1045041.1429, MAE: 3980.1343, R2: 0.1183\n",
      "==========================================================================================\n",
      "Epoch [2285/5000] | Time: 0.23s\n",
      "(Training) Loss: 1020052.3319\n",
      "(Validation) Loss: 1044870.5727, MAE: 3978.5442, R2: 0.1184\n",
      "==========================================================================================\n",
      "Epoch [2286/5000] | Time: 0.25s\n",
      "(Training) Loss: 1007884.8147\n",
      "(Validation) Loss: 1044700.2921, MAE: 3977.7378, R2: 0.1186\n",
      "==========================================================================================\n",
      "Epoch [2287/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010145.3192\n",
      "(Validation) Loss: 1044528.0711, MAE: 3975.6060, R2: 0.1187\n",
      "==========================================================================================\n",
      "Epoch [2288/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010740.9854\n",
      "(Validation) Loss: 1044422.6438, MAE: 3976.9756, R2: 0.1188\n",
      "==========================================================================================\n",
      "Epoch [2289/5000] | Time: 0.22s\n",
      "(Training) Loss: 1006817.8344\n",
      "(Validation) Loss: 1044185.7727, MAE: 3971.7683, R2: 0.1190\n",
      "==========================================================================================\n",
      "Epoch [2290/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004511.2678\n",
      "(Validation) Loss: 1044032.5689, MAE: 3974.7317, R2: 0.1191\n",
      "==========================================================================================\n",
      "Epoch [2291/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014332.7912\n",
      "(Validation) Loss: 1043863.0756, MAE: 3973.5701, R2: 0.1193\n",
      "==========================================================================================\n",
      "Epoch [2292/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009107.0263\n",
      "(Validation) Loss: 1043685.9581, MAE: 3972.7766, R2: 0.1194\n",
      "==========================================================================================\n",
      "Epoch [2293/5000] | Time: 0.25s\n",
      "(Training) Loss: 1007564.1507\n",
      "(Validation) Loss: 1043521.6863, MAE: 3971.5115, R2: 0.1196\n",
      "==========================================================================================\n",
      "Epoch [2294/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007089.6079\n",
      "(Validation) Loss: 1043365.9835, MAE: 3974.2661, R2: 0.1197\n",
      "==========================================================================================\n",
      "Epoch [2295/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019380.3515\n",
      "(Validation) Loss: 1043173.1606, MAE: 3966.5239, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [2296/5000] | Time: 0.23s\n",
      "(Training) Loss: 1006837.2690\n",
      "(Validation) Loss: 1043004.9575, MAE: 3966.4915, R2: 0.1200\n",
      "==========================================================================================\n",
      "Epoch [2297/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010105.9905\n",
      "(Validation) Loss: 1042839.4159, MAE: 3966.2927, R2: 0.1201\n",
      "==========================================================================================\n",
      "Epoch [2298/5000] | Time: 0.23s\n",
      "(Training) Loss: 1002092.2995\n",
      "(Validation) Loss: 1042668.2870, MAE: 3965.0632, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [2299/5000] | Time: 0.23s\n",
      "(Training) Loss: 1019322.1897\n",
      "(Validation) Loss: 1042497.6863, MAE: 3963.7546, R2: 0.1204\n",
      "==========================================================================================\n",
      "Epoch [2300/5000] | Time: 0.22s\n",
      "(Training) Loss: 997848.1783\n",
      "(Validation) Loss: 1042329.4121, MAE: 3964.5137, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [2301/5000] | Time: 0.21s\n",
      "(Training) Loss: 1009354.1802\n",
      "(Validation) Loss: 1042167.7562, MAE: 3963.2058, R2: 0.1207\n",
      "==========================================================================================\n",
      "Epoch [2302/5000] | Time: 0.25s\n",
      "(Training) Loss: 1004842.3426\n",
      "(Validation) Loss: 1041999.6089, MAE: 3963.2292, R2: 0.1208\n",
      "==========================================================================================\n",
      "Epoch [2303/5000] | Time: 0.24s\n",
      "(Training) Loss: 1009033.2195\n",
      "(Validation) Loss: 1041830.7860, MAE: 3961.8369, R2: 0.1210\n",
      "==========================================================================================\n",
      "Epoch [2304/5000] | Time: 0.23s\n",
      "(Training) Loss: 1011585.2722\n",
      "(Validation) Loss: 1041660.5105, MAE: 3961.1013, R2: 0.1211\n",
      "==========================================================================================\n",
      "Epoch [2305/5000] | Time: 0.22s\n",
      "(Training) Loss: 1017259.1269\n",
      "(Validation) Loss: 1041497.3714, MAE: 3961.7451, R2: 0.1213\n",
      "==========================================================================================\n",
      "Epoch [2306/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010836.3414\n",
      "(Validation) Loss: 1041324.0990, MAE: 3960.6426, R2: 0.1214\n",
      "==========================================================================================\n",
      "Epoch [2307/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007885.8020\n",
      "(Validation) Loss: 1041158.9435, MAE: 3960.5750, R2: 0.1215\n",
      "==========================================================================================\n",
      "Epoch [2308/5000] | Time: 0.23s\n",
      "(Training) Loss: 1003663.6180\n",
      "(Validation) Loss: 1040989.6330, MAE: 3959.3076, R2: 0.1217\n",
      "==========================================================================================\n",
      "Epoch [2309/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000634.1669\n",
      "(Validation) Loss: 1040817.8286, MAE: 3957.9399, R2: 0.1218\n",
      "==========================================================================================\n",
      "Epoch [2310/5000] | Time: 0.23s\n",
      "(Training) Loss: 1032181.2259\n",
      "(Validation) Loss: 1040657.1886, MAE: 3958.8147, R2: 0.1220\n",
      "==========================================================================================\n",
      "Epoch [2311/5000] | Time: 0.25s\n",
      "(Training) Loss: 1013895.6662\n",
      "(Validation) Loss: 1040486.6743, MAE: 3959.3318, R2: 0.1221\n",
      "==========================================================================================\n",
      "Epoch [2312/5000] | Time: 0.24s\n",
      "(Training) Loss: 1032846.9429\n",
      "(Validation) Loss: 1040322.5143, MAE: 3958.0229, R2: 0.1222\n",
      "==========================================================================================\n",
      "Epoch [2313/5000] | Time: 0.24s\n",
      "(Training) Loss: 1003774.6412\n",
      "(Validation) Loss: 1040158.9587, MAE: 3960.5859, R2: 0.1224\n",
      "==========================================================================================\n",
      "Epoch [2314/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001188.0343\n",
      "(Validation) Loss: 1040030.1359, MAE: 3959.3818, R2: 0.1225\n",
      "==========================================================================================\n",
      "Epoch [2315/5000] | Time: 0.21s\n",
      "(Training) Loss: 1011029.0755\n",
      "(Validation) Loss: 1039866.4686, MAE: 3960.4797, R2: 0.1226\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2316/5000] | Time: 0.22s\n",
      "(Training) Loss: 1020369.2855\n",
      "(Validation) Loss: 1039696.0711, MAE: 3958.7830, R2: 0.1228\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2317/5000] | Time: 0.25s\n",
      "(Training) Loss: 1008616.2088\n",
      "(Validation) Loss: 1039528.8838, MAE: 3958.9927, R2: 0.1229\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2318/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005202.2570\n",
      "(Validation) Loss: 1039375.3092, MAE: 3963.8940, R2: 0.1230\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2319/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004363.4848\n",
      "(Validation) Loss: 1039195.4946, MAE: 3958.3577, R2: 0.1232\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2320/5000] | Time: 0.23s\n",
      "(Training) Loss: 1006110.2011\n",
      "(Validation) Loss: 1039029.5975, MAE: 3958.1677, R2: 0.1233\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2321/5000] | Time: 0.21s\n",
      "(Training) Loss: 1022553.2056\n",
      "(Validation) Loss: 1038862.4152, MAE: 3956.4602, R2: 0.1234\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2322/5000] | Time: 0.25s\n",
      "(Training) Loss: 1013460.7081\n",
      "(Validation) Loss: 1038687.0603, MAE: 3954.4607, R2: 0.1236\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2323/5000] | Time: 0.25s\n",
      "(Training) Loss: 993577.8275\n",
      "(Validation) Loss: 1038524.1244, MAE: 3955.4946, R2: 0.1237\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2324/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004831.1459\n",
      "(Validation) Loss: 1038358.2273, MAE: 3954.9041, R2: 0.1239\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2325/5000] | Time: 0.24s\n",
      "(Training) Loss: 1000878.5051\n",
      "(Validation) Loss: 1038196.1092, MAE: 3955.0229, R2: 0.1240\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2326/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010075.1250\n",
      "(Validation) Loss: 1038024.7010, MAE: 3954.2092, R2: 0.1241\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2327/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014475.6307\n",
      "(Validation) Loss: 1037856.0762, MAE: 3952.4460, R2: 0.1243\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2328/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001133.7030\n",
      "(Validation) Loss: 1037692.6578, MAE: 3954.5256, R2: 0.1244\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2329/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000768.6313\n",
      "(Validation) Loss: 1037522.0114, MAE: 3951.6099, R2: 0.1246\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2330/5000] | Time: 0.24s\n",
      "(Training) Loss: 1014390.6269\n",
      "(Validation) Loss: 1037353.8844, MAE: 3950.8950, R2: 0.1247\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2331/5000] | Time: 0.23s\n",
      "(Training) Loss: 998185.4632\n",
      "(Validation) Loss: 1037186.6108, MAE: 3949.8782, R2: 0.1248\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2332/5000] | Time: 0.24s\n",
      "(Training) Loss: 1009364.0812\n",
      "(Validation) Loss: 1037022.5625, MAE: 3950.4102, R2: 0.1250\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2333/5000] | Time: 0.21s\n",
      "(Training) Loss: 997802.8128\n",
      "(Validation) Loss: 1036862.9638, MAE: 3951.3247, R2: 0.1251\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2334/5000] | Time: 0.21s\n",
      "(Training) Loss: 998380.4004\n",
      "(Validation) Loss: 1036754.4737, MAE: 3953.5532, R2: 0.1252\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2335/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002103.7570\n",
      "(Validation) Loss: 1036530.9105, MAE: 3951.0063, R2: 0.1254\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2336/5000] | Time: 0.20s\n",
      "(Training) Loss: 991747.8398\n",
      "(Validation) Loss: 1036353.9200, MAE: 3948.0088, R2: 0.1255\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2337/5000] | Time: 0.22s\n",
      "(Training) Loss: 1021914.6789\n",
      "(Validation) Loss: 1036187.0273, MAE: 3946.1614, R2: 0.1257\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2338/5000] | Time: 0.22s\n",
      "(Training) Loss: 996521.4702\n",
      "(Validation) Loss: 1036021.2521, MAE: 3948.0811, R2: 0.1258\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2339/5000] | Time: 0.22s\n",
      "(Training) Loss: 1014710.2494\n",
      "(Validation) Loss: 1035851.9568, MAE: 3945.9707, R2: 0.1260\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2340/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019519.5952\n",
      "(Validation) Loss: 1035684.1854, MAE: 3945.5688, R2: 0.1261\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2341/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014212.0070\n",
      "(Validation) Loss: 1035516.7746, MAE: 3945.3521, R2: 0.1262\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2342/5000] | Time: 0.24s\n",
      "(Training) Loss: 995577.1694\n",
      "(Validation) Loss: 1035361.5594, MAE: 3947.4080, R2: 0.1264\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2343/5000] | Time: 0.20s\n",
      "(Training) Loss: 1009615.7024\n",
      "(Validation) Loss: 1035212.2463, MAE: 3951.7239, R2: 0.1265\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2344/5000] | Time: 0.20s\n",
      "(Training) Loss: 1002390.8319\n",
      "(Validation) Loss: 1035027.6622, MAE: 3945.8311, R2: 0.1266\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2345/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004219.4473\n",
      "(Validation) Loss: 1034851.3930, MAE: 3942.7410, R2: 0.1268\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2346/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019586.1015\n",
      "(Validation) Loss: 1034682.9003, MAE: 3941.7488, R2: 0.1269\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2347/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004750.1459\n",
      "(Validation) Loss: 1034526.0800, MAE: 3943.0972, R2: 0.1271\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2348/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002097.2881\n",
      "(Validation) Loss: 1034353.0514, MAE: 3941.2126, R2: 0.1272\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2349/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008752.8909\n",
      "(Validation) Loss: 1034179.5200, MAE: 3938.4136, R2: 0.1274\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2350/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004593.8357\n",
      "(Validation) Loss: 1034014.6641, MAE: 3939.3237, R2: 0.1275\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2351/5000] | Time: 0.21s\n",
      "(Training) Loss: 998288.0197\n",
      "(Validation) Loss: 1033852.0483, MAE: 3940.3435, R2: 0.1276\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2352/5000] | Time: 0.27s\n",
      "(Training) Loss: 1006483.3610\n",
      "(Validation) Loss: 1033717.5568, MAE: 3943.0759, R2: 0.1277\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2353/5000] | Time: 0.21s\n",
      "(Training) Loss: 1018917.7500\n",
      "(Validation) Loss: 1033530.4686, MAE: 3942.4341, R2: 0.1279\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2354/5000] | Time: 0.19s\n",
      "(Training) Loss: 1026611.3249\n",
      "(Validation) Loss: 1033351.9746, MAE: 3938.4854, R2: 0.1280\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2355/5000] | Time: 0.27s\n",
      "(Training) Loss: 1008844.0013\n",
      "(Validation) Loss: 1033175.1111, MAE: 3935.7305, R2: 0.1282\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2356/5000] | Time: 0.24s\n",
      "(Training) Loss: 1009238.2690\n",
      "(Validation) Loss: 1033010.9359, MAE: 3935.6799, R2: 0.1283\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2357/5000] | Time: 0.24s\n",
      "(Training) Loss: 1000301.1003\n",
      "(Validation) Loss: 1032852.2362, MAE: 3937.9829, R2: 0.1285\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2358/5000] | Time: 0.22s\n",
      "(Training) Loss: 1032465.3122\n",
      "(Validation) Loss: 1032673.7625, MAE: 3933.4978, R2: 0.1286\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2359/5000] | Time: 0.22s\n",
      "(Training) Loss: 995733.2443\n",
      "(Validation) Loss: 1032505.8540, MAE: 3933.1011, R2: 0.1287\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2360/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007747.6688\n",
      "(Validation) Loss: 1032339.6267, MAE: 3933.0007, R2: 0.1289\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2361/5000] | Time: 0.20s\n",
      "(Training) Loss: 996261.3985\n",
      "(Validation) Loss: 1032176.2743, MAE: 3932.6311, R2: 0.1290\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2362/5000] | Time: 0.21s\n",
      "(Training) Loss: 1010676.7437\n",
      "(Validation) Loss: 1032024.8229, MAE: 3934.5825, R2: 0.1291\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2363/5000] | Time: 0.23s\n",
      "(Training) Loss: 996431.3071\n",
      "(Validation) Loss: 1031911.1314, MAE: 3936.5137, R2: 0.1292\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2364/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002775.6123\n",
      "(Validation) Loss: 1031745.7067, MAE: 3935.9714, R2: 0.1294\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2365/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001110.7259\n",
      "(Validation) Loss: 1031583.4210, MAE: 3936.1245, R2: 0.1295\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2366/5000] | Time: 0.23s\n",
      "(Training) Loss: 991569.8490\n",
      "(Validation) Loss: 1031417.5543, MAE: 3936.6775, R2: 0.1297\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2367/5000] | Time: 0.24s\n",
      "(Training) Loss: 995598.7912\n",
      "(Validation) Loss: 1031249.6152, MAE: 3935.7832, R2: 0.1298\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2368/5000] | Time: 0.23s\n",
      "(Training) Loss: 1007622.3947\n",
      "(Validation) Loss: 1031076.2006, MAE: 3932.3323, R2: 0.1299\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2369/5000] | Time: 0.20s\n",
      "(Training) Loss: 1013674.7081\n",
      "(Validation) Loss: 1030911.5378, MAE: 3933.3562, R2: 0.1301\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2370/5000] | Time: 0.20s\n",
      "(Training) Loss: 999486.5723\n",
      "(Validation) Loss: 1030746.1638, MAE: 3932.8723, R2: 0.1302\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2371/5000] | Time: 0.19s\n",
      "(Training) Loss: 1001662.1926\n",
      "(Validation) Loss: 1030581.9022, MAE: 3932.4980, R2: 0.1303\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2372/5000] | Time: 0.21s\n",
      "(Training) Loss: 992165.1453\n",
      "(Validation) Loss: 1030423.2940, MAE: 3933.8306, R2: 0.1305\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2373/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011929.8896\n",
      "(Validation) Loss: 1030254.2730, MAE: 3933.3474, R2: 0.1306\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2374/5000] | Time: 0.19s\n",
      "(Training) Loss: 1001211.7722\n",
      "(Validation) Loss: 1030080.8990, MAE: 3931.0525, R2: 0.1308\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2375/5000] | Time: 0.19s\n",
      "(Training) Loss: 1023576.7843\n",
      "(Validation) Loss: 1029913.5340, MAE: 3929.1572, R2: 0.1309\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2376/5000] | Time: 0.19s\n",
      "(Training) Loss: 993874.3503\n",
      "(Validation) Loss: 1029743.4717, MAE: 3928.7400, R2: 0.1310\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2377/5000] | Time: 0.23s\n",
      "(Training) Loss: 997154.1358\n",
      "(Validation) Loss: 1029580.8914, MAE: 3929.2336, R2: 0.1312\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2378/5000] | Time: 0.23s\n",
      "(Training) Loss: 1013093.3230\n",
      "(Validation) Loss: 1029417.8692, MAE: 3928.6621, R2: 0.1313\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2379/5000] | Time: 0.19s\n",
      "(Training) Loss: 1004935.8978\n",
      "(Validation) Loss: 1029250.0775, MAE: 3927.9204, R2: 0.1315\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2380/5000] | Time: 0.19s\n",
      "(Training) Loss: 1002163.7234\n",
      "(Validation) Loss: 1029083.6876, MAE: 3926.7632, R2: 0.1316\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2381/5000] | Time: 0.19s\n",
      "(Training) Loss: 992587.1028\n",
      "(Validation) Loss: 1028920.4978, MAE: 3927.9131, R2: 0.1317\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2382/5000] | Time: 0.20s\n",
      "(Training) Loss: 991670.3074\n",
      "(Validation) Loss: 1028785.7422, MAE: 3936.5933, R2: 0.1318\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2383/5000] | Time: 0.22s\n",
      "(Training) Loss: 994229.9036\n",
      "(Validation) Loss: 1028586.8952, MAE: 3923.7959, R2: 0.1320\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2384/5000] | Time: 0.21s\n",
      "(Training) Loss: 1006816.1244\n",
      "(Validation) Loss: 1028423.0197, MAE: 3924.9426, R2: 0.1321\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2385/5000] | Time: 0.20s\n",
      "(Training) Loss: 999608.2430\n",
      "(Validation) Loss: 1028256.0863, MAE: 3925.8433, R2: 0.1323\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2386/5000] | Time: 0.20s\n",
      "(Training) Loss: 1007260.5286\n",
      "(Validation) Loss: 1028089.9251, MAE: 3923.0583, R2: 0.1324\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2387/5000] | Time: 0.19s\n",
      "(Training) Loss: 1026495.4657\n",
      "(Validation) Loss: 1027926.5016, MAE: 3923.5437, R2: 0.1326\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2388/5000] | Time: 0.20s\n",
      "(Training) Loss: 989208.8242\n",
      "(Validation) Loss: 1027767.3651, MAE: 3925.9253, R2: 0.1327\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2389/5000] | Time: 0.19s\n",
      "(Training) Loss: 998374.9334\n",
      "(Validation) Loss: 1027597.8057, MAE: 3928.0881, R2: 0.1328\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2390/5000] | Time: 0.22s\n",
      "(Training) Loss: 996969.0057\n",
      "(Validation) Loss: 1027424.0356, MAE: 3921.5303, R2: 0.1330\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2391/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000088.3090\n",
      "(Validation) Loss: 1027261.3079, MAE: 3922.0137, R2: 0.1331\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2392/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007206.8706\n",
      "(Validation) Loss: 1027095.5429, MAE: 3920.3533, R2: 0.1333\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2393/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010346.6802\n",
      "(Validation) Loss: 1026931.9314, MAE: 3919.6384, R2: 0.1334\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2394/5000] | Time: 0.24s\n",
      "(Training) Loss: 983303.3073\n",
      "(Validation) Loss: 1026773.3333, MAE: 3922.7517, R2: 0.1335\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2395/5000] | Time: 0.20s\n",
      "(Training) Loss: 1007379.8871\n",
      "(Validation) Loss: 1026606.0394, MAE: 3921.6042, R2: 0.1337\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2396/5000] | Time: 0.18s\n",
      "(Training) Loss: 1026506.3049\n",
      "(Validation) Loss: 1026433.1378, MAE: 3917.9207, R2: 0.1338\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2397/5000] | Time: 0.19s\n",
      "(Training) Loss: 1013714.5381\n",
      "(Validation) Loss: 1026265.6660, MAE: 3917.0603, R2: 0.1339\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2398/5000] | Time: 0.20s\n",
      "(Training) Loss: 1010929.8731\n",
      "(Validation) Loss: 1026099.3625, MAE: 3917.2708, R2: 0.1341\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2399/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004776.3629\n",
      "(Validation) Loss: 1025963.2610, MAE: 3925.2473, R2: 0.1342\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2400/5000] | Time: 0.23s\n",
      "(Training) Loss: 986749.8598\n",
      "(Validation) Loss: 1025762.3416, MAE: 3915.1245, R2: 0.1344\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2401/5000] | Time: 0.22s\n",
      "(Training) Loss: 986374.0355\n",
      "(Validation) Loss: 1025601.2140, MAE: 3915.4048, R2: 0.1345\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2402/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009259.8550\n",
      "(Validation) Loss: 1025439.1060, MAE: 3914.4785, R2: 0.1346\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2403/5000] | Time: 0.20s\n",
      "(Training) Loss: 1017826.0076\n",
      "(Validation) Loss: 1025273.0463, MAE: 3913.6511, R2: 0.1348\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2404/5000] | Time: 0.21s\n",
      "(Training) Loss: 981794.7956\n",
      "(Validation) Loss: 1025142.2883, MAE: 3925.2305, R2: 0.1349\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2405/5000] | Time: 0.23s\n",
      "(Training) Loss: 1003746.3737\n",
      "(Validation) Loss: 1024945.8895, MAE: 3915.3464, R2: 0.1350\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2406/5000] | Time: 0.20s\n",
      "(Training) Loss: 989644.0920\n",
      "(Validation) Loss: 1024775.3956, MAE: 3912.0081, R2: 0.1352\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2407/5000] | Time: 0.23s\n",
      "(Training) Loss: 992717.8176\n",
      "(Validation) Loss: 1024612.6832, MAE: 3912.0559, R2: 0.1353\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2408/5000] | Time: 0.20s\n",
      "(Training) Loss: 995293.3236\n",
      "(Validation) Loss: 1024453.3333, MAE: 3912.4460, R2: 0.1355\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2409/5000] | Time: 0.20s\n",
      "(Training) Loss: 985109.9975\n",
      "(Validation) Loss: 1024286.8978, MAE: 3911.0149, R2: 0.1356\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2410/5000] | Time: 0.21s\n",
      "(Training) Loss: 996245.7843\n",
      "(Validation) Loss: 1024125.9937, MAE: 3911.4436, R2: 0.1357\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2411/5000] | Time: 0.23s\n",
      "(Training) Loss: 991492.3071\n",
      "(Validation) Loss: 1023980.3683, MAE: 3911.7927, R2: 0.1359\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2412/5000] | Time: 0.23s\n",
      "(Training) Loss: 983443.7110\n",
      "(Validation) Loss: 1023797.0387, MAE: 3909.8862, R2: 0.1360\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2413/5000] | Time: 0.24s\n",
      "(Training) Loss: 999864.7373\n",
      "(Validation) Loss: 1023640.1016, MAE: 3909.9429, R2: 0.1361\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2414/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001739.5489\n",
      "(Validation) Loss: 1023494.3441, MAE: 3912.3691, R2: 0.1363\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2415/5000] | Time: 0.23s\n",
      "(Training) Loss: 997274.8363\n",
      "(Validation) Loss: 1023303.0451, MAE: 3907.0210, R2: 0.1364\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2416/5000] | Time: 0.20s\n",
      "(Training) Loss: 999058.4905\n",
      "(Validation) Loss: 1023087.1162, MAE: 3904.7656, R2: 0.1366\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2417/5000] | Time: 0.21s\n",
      "(Training) Loss: 997057.4632\n",
      "(Validation) Loss: 1022975.3092, MAE: 3906.3982, R2: 0.1367\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2418/5000] | Time: 0.21s\n",
      "(Training) Loss: 996163.6231\n",
      "(Validation) Loss: 1022805.1251, MAE: 3904.4119, R2: 0.1368\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2419/5000] | Time: 0.22s\n",
      "(Training) Loss: 987803.7253\n",
      "(Validation) Loss: 1022645.3384, MAE: 3904.5525, R2: 0.1370\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2420/5000] | Time: 0.20s\n",
      "(Training) Loss: 1000003.9759\n",
      "(Validation) Loss: 1022477.9581, MAE: 3903.5286, R2: 0.1371\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2421/5000] | Time: 0.20s\n",
      "(Training) Loss: 995391.1110\n",
      "(Validation) Loss: 1022315.2813, MAE: 3903.4390, R2: 0.1372\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2422/5000] | Time: 0.22s\n",
      "(Training) Loss: 983380.5489\n",
      "(Validation) Loss: 1022153.3359, MAE: 3905.2451, R2: 0.1374\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2423/5000] | Time: 0.20s\n",
      "(Training) Loss: 994468.8255\n",
      "(Validation) Loss: 1021989.1352, MAE: 3903.3752, R2: 0.1375\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2424/5000] | Time: 0.22s\n",
      "(Training) Loss: 985649.7792\n",
      "(Validation) Loss: 1021820.0737, MAE: 3900.7837, R2: 0.1377\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2425/5000] | Time: 0.23s\n",
      "(Training) Loss: 982396.7538\n",
      "(Validation) Loss: 1021663.4006, MAE: 3903.3623, R2: 0.1378\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2426/5000] | Time: 0.21s\n",
      "(Training) Loss: 997172.4131\n",
      "(Validation) Loss: 1021507.9517, MAE: 3906.5098, R2: 0.1379\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2427/5000] | Time: 0.19s\n",
      "(Training) Loss: 994689.2868\n",
      "(Validation) Loss: 1021333.6940, MAE: 3901.4961, R2: 0.1381\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2428/5000] | Time: 0.24s\n",
      "(Training) Loss: 977910.1133\n",
      "(Validation) Loss: 1021169.6102, MAE: 3899.6589, R2: 0.1382\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2429/5000] | Time: 0.23s\n",
      "(Training) Loss: 999606.6009\n",
      "(Validation) Loss: 1021083.9619, MAE: 3904.0918, R2: 0.1383\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2430/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005441.2989\n",
      "(Validation) Loss: 1020921.1530, MAE: 3904.3108, R2: 0.1384\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2431/5000] | Time: 0.27s\n",
      "(Training) Loss: 993764.0755\n",
      "(Validation) Loss: 1020757.4248, MAE: 3906.5125, R2: 0.1385\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2432/5000] | Time: 0.26s\n",
      "(Training) Loss: 979149.1504\n",
      "(Validation) Loss: 1020588.1549, MAE: 3903.5718, R2: 0.1387\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2433/5000] | Time: 0.23s\n",
      "(Training) Loss: 992061.5114\n",
      "(Validation) Loss: 1020435.0883, MAE: 3905.7104, R2: 0.1388\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2434/5000] | Time: 0.25s\n",
      "(Training) Loss: 991246.4616\n",
      "(Validation) Loss: 1020259.7740, MAE: 3901.1174, R2: 0.1389\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2435/5000] | Time: 0.23s\n",
      "(Training) Loss: 978881.1361\n",
      "(Validation) Loss: 1020100.2667, MAE: 3902.4585, R2: 0.1391\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2436/5000] | Time: 0.24s\n",
      "(Training) Loss: 979878.0441\n",
      "(Validation) Loss: 1019952.1067, MAE: 3905.0349, R2: 0.1392\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2437/5000] | Time: 0.21s\n",
      "(Training) Loss: 980926.1459\n",
      "(Validation) Loss: 1019772.6781, MAE: 3900.3604, R2: 0.1394\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2438/5000] | Time: 0.20s\n",
      "(Training) Loss: 986522.3192\n",
      "(Validation) Loss: 1019608.2184, MAE: 3898.1604, R2: 0.1395\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2439/5000] | Time: 0.19s\n",
      "(Training) Loss: 993949.9626\n",
      "(Validation) Loss: 1019443.9619, MAE: 3898.1353, R2: 0.1396\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2440/5000] | Time: 0.19s\n",
      "(Training) Loss: 985074.5381\n",
      "(Validation) Loss: 1019284.4038, MAE: 3898.1438, R2: 0.1398\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2441/5000] | Time: 0.19s\n",
      "(Training) Loss: 979515.1269\n",
      "(Validation) Loss: 1019118.3644, MAE: 3897.3215, R2: 0.1399\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2442/5000] | Time: 0.22s\n",
      "(Training) Loss: 996749.9794\n",
      "(Validation) Loss: 1018953.2698, MAE: 3896.3152, R2: 0.1400\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2443/5000] | Time: 0.22s\n",
      "(Training) Loss: 990690.0330\n",
      "(Validation) Loss: 1018793.5594, MAE: 3896.4390, R2: 0.1402\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2444/5000] | Time: 0.19s\n",
      "(Training) Loss: 994989.3338\n",
      "(Validation) Loss: 1018564.3987, MAE: 3896.6746, R2: 0.1404\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2445/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002751.5076\n",
      "(Validation) Loss: 1018387.9924, MAE: 3892.6328, R2: 0.1405\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2446/5000] | Time: 0.21s\n",
      "(Training) Loss: 1000689.4816\n",
      "(Validation) Loss: 1018213.4857, MAE: 3888.1301, R2: 0.1407\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2447/5000] | Time: 0.20s\n",
      "(Training) Loss: 980732.3953\n",
      "(Validation) Loss: 1018055.2279, MAE: 3889.2598, R2: 0.1408\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2448/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012668.3185\n",
      "(Validation) Loss: 1017894.7251, MAE: 3890.4407, R2: 0.1409\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2449/5000] | Time: 0.23s\n",
      "(Training) Loss: 978538.2551\n",
      "(Validation) Loss: 1017721.7879, MAE: 3886.8386, R2: 0.1411\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2450/5000] | Time: 0.22s\n",
      "(Training) Loss: 985863.1720\n",
      "(Validation) Loss: 1017565.8971, MAE: 3888.8311, R2: 0.1412\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2451/5000] | Time: 0.23s\n",
      "(Training) Loss: 990464.1180\n",
      "(Validation) Loss: 1017393.7016, MAE: 3884.9844, R2: 0.1413\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2452/5000] | Time: 0.23s\n",
      "(Training) Loss: 978163.5470\n",
      "(Validation) Loss: 1017231.4565, MAE: 3885.4504, R2: 0.1415\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2453/5000] | Time: 0.20s\n",
      "(Training) Loss: 981631.2925\n",
      "(Validation) Loss: 1017067.9568, MAE: 3885.2969, R2: 0.1416\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2454/5000] | Time: 0.23s\n",
      "(Training) Loss: 986451.4251\n",
      "(Validation) Loss: 1016906.5397, MAE: 3883.6096, R2: 0.1417\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2455/5000] | Time: 0.23s\n",
      "(Training) Loss: 982936.1364\n",
      "(Validation) Loss: 1016743.2381, MAE: 3881.9558, R2: 0.1419\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2456/5000] | Time: 0.22s\n",
      "(Training) Loss: 973875.2267\n",
      "(Validation) Loss: 1016578.8241, MAE: 3881.8584, R2: 0.1420\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2457/5000] | Time: 0.23s\n",
      "(Training) Loss: 999348.5723\n",
      "(Validation) Loss: 1016429.1810, MAE: 3884.0159, R2: 0.1421\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2458/5000] | Time: 0.22s\n",
      "(Training) Loss: 987733.9575\n",
      "(Validation) Loss: 1016257.2698, MAE: 3881.3601, R2: 0.1423\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2459/5000] | Time: 0.24s\n",
      "(Training) Loss: 977613.9315\n",
      "(Validation) Loss: 1016093.8565, MAE: 3881.1899, R2: 0.1424\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2460/5000] | Time: 0.21s\n",
      "(Training) Loss: 1000191.5133\n",
      "(Validation) Loss: 1015932.3530, MAE: 3880.9546, R2: 0.1426\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2461/5000] | Time: 0.25s\n",
      "(Training) Loss: 992411.1650\n",
      "(Validation) Loss: 1015764.6984, MAE: 3880.0774, R2: 0.1427\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2462/5000] | Time: 0.26s\n",
      "(Training) Loss: 996615.8693\n",
      "(Validation) Loss: 1015599.5581, MAE: 3878.7773, R2: 0.1428\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2463/5000] | Time: 0.20s\n",
      "(Training) Loss: 976867.2310\n",
      "(Validation) Loss: 1015439.3448, MAE: 3878.6809, R2: 0.1430\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2464/5000] | Time: 0.21s\n",
      "(Training) Loss: 999449.3477\n",
      "(Validation) Loss: 1015278.9943, MAE: 3880.2366, R2: 0.1431\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2465/5000] | Time: 0.23s\n",
      "(Training) Loss: 986952.7240\n",
      "(Validation) Loss: 1015113.3917, MAE: 3878.2234, R2: 0.1432\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2466/5000] | Time: 0.22s\n",
      "(Training) Loss: 982399.7551\n",
      "(Validation) Loss: 1014943.9746, MAE: 3876.2949, R2: 0.1434\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2467/5000] | Time: 0.41s\n",
      "(Training) Loss: 974087.9584\n",
      "(Validation) Loss: 1014781.4248, MAE: 3875.9009, R2: 0.1435\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2468/5000] | Time: 0.24s\n",
      "(Training) Loss: 978545.0838\n",
      "(Validation) Loss: 1014627.9060, MAE: 3878.3982, R2: 0.1436\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2469/5000] | Time: 0.22s\n",
      "(Training) Loss: 996209.0673\n",
      "(Validation) Loss: 1014461.5162, MAE: 3876.2092, R2: 0.1438\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2470/5000] | Time: 0.21s\n",
      "(Training) Loss: 981263.1022\n",
      "(Validation) Loss: 1014295.7257, MAE: 3875.4104, R2: 0.1439\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2471/5000] | Time: 0.20s\n",
      "(Training) Loss: 977227.1815\n",
      "(Validation) Loss: 1014134.8724, MAE: 3875.3555, R2: 0.1441\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2472/5000] | Time: 0.20s\n",
      "(Training) Loss: 983555.1015\n",
      "(Validation) Loss: 1013967.1822, MAE: 3872.6028, R2: 0.1442\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2473/5000] | Time: 0.19s\n",
      "(Training) Loss: 998388.0774\n",
      "(Validation) Loss: 1013806.6997, MAE: 3872.7593, R2: 0.1443\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2474/5000] | Time: 0.20s\n",
      "(Training) Loss: 982356.7462\n",
      "(Validation) Loss: 1013644.5613, MAE: 3873.0422, R2: 0.1445\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2475/5000] | Time: 0.31s\n",
      "(Training) Loss: 975404.4841\n",
      "(Validation) Loss: 1013482.9410, MAE: 3872.8225, R2: 0.1446\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2476/5000] | Time: 0.26s\n",
      "(Training) Loss: 988884.0254\n",
      "(Validation) Loss: 1013315.1137, MAE: 3869.6360, R2: 0.1447\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2477/5000] | Time: 0.19s\n",
      "(Training) Loss: 971933.1377\n",
      "(Validation) Loss: 1013155.1644, MAE: 3870.0537, R2: 0.1449\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2478/5000] | Time: 0.20s\n",
      "(Training) Loss: 977401.0298\n",
      "(Validation) Loss: 1013003.9822, MAE: 3871.6658, R2: 0.1450\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2479/5000] | Time: 0.19s\n",
      "(Training) Loss: 984925.7291\n",
      "(Validation) Loss: 1012828.0737, MAE: 3868.3901, R2: 0.1451\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2480/5000] | Time: 0.21s\n",
      "(Training) Loss: 973018.4013\n",
      "(Validation) Loss: 1012616.4114, MAE: 3864.4880, R2: 0.1453\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2481/5000] | Time: 0.20s\n",
      "(Training) Loss: 986126.5489\n",
      "(Validation) Loss: 1012478.2324, MAE: 3871.0737, R2: 0.1454\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2482/5000] | Time: 0.23s\n",
      "(Training) Loss: 984582.3198\n",
      "(Validation) Loss: 1012341.5975, MAE: 3867.4343, R2: 0.1456\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2483/5000] | Time: 0.20s\n",
      "(Training) Loss: 976889.6263\n",
      "(Validation) Loss: 1012203.0070, MAE: 3871.0183, R2: 0.1457\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2484/5000] | Time: 0.20s\n",
      "(Training) Loss: 972594.5984\n",
      "(Validation) Loss: 1012029.0997, MAE: 3869.7747, R2: 0.1458\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2485/5000] | Time: 0.24s\n",
      "(Training) Loss: 982426.9429\n",
      "(Validation) Loss: 1011823.7613, MAE: 3866.8232, R2: 0.1460\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2486/5000] | Time: 0.39s\n",
      "(Training) Loss: 979907.5216\n",
      "(Validation) Loss: 1011656.1016, MAE: 3863.2124, R2: 0.1461\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2487/5000] | Time: 0.21s\n",
      "(Training) Loss: 992101.5203\n",
      "(Validation) Loss: 1011501.9124, MAE: 3865.6350, R2: 0.1463\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2488/5000] | Time: 0.19s\n",
      "(Training) Loss: 981588.7602\n",
      "(Validation) Loss: 1011333.0692, MAE: 3865.0996, R2: 0.1464\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2489/5000] | Time: 0.53s\n",
      "(Training) Loss: 984469.7227\n",
      "(Validation) Loss: 1011164.2971, MAE: 3862.4153, R2: 0.1465\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2490/5000] | Time: 0.29s\n",
      "(Training) Loss: 987377.0222\n",
      "(Validation) Loss: 1010993.4883, MAE: 3859.4346, R2: 0.1467\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2491/5000] | Time: 0.33s\n",
      "(Training) Loss: 984891.4734\n",
      "(Validation) Loss: 1010846.7149, MAE: 3863.4539, R2: 0.1468\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2492/5000] | Time: 0.79s\n",
      "(Training) Loss: 970403.9746\n",
      "(Validation) Loss: 1010671.9492, MAE: 3859.6716, R2: 0.1469\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2493/5000] | Time: 0.88s\n",
      "(Training) Loss: 972685.9029\n",
      "(Validation) Loss: 1010506.3060, MAE: 3857.5952, R2: 0.1471\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2494/5000] | Time: 1.03s\n",
      "(Training) Loss: 983800.6510\n",
      "(Validation) Loss: 1010319.4921, MAE: 3857.1470, R2: 0.1472\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2495/5000] | Time: 1.06s\n",
      "(Training) Loss: 981485.2265\n",
      "(Validation) Loss: 1010146.9816, MAE: 3852.7803, R2: 0.1474\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2496/5000] | Time: 0.96s\n",
      "(Training) Loss: 987539.2652\n",
      "(Validation) Loss: 1010132.0483, MAE: 3857.7729, R2: 0.1474\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2497/5000] | Time: 0.88s\n",
      "(Training) Loss: 982907.9911\n",
      "(Validation) Loss: 1009824.7517, MAE: 3852.3904, R2: 0.1477\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2498/5000] | Time: 1.18s\n",
      "(Training) Loss: 998110.2329\n",
      "(Validation) Loss: 1009691.3219, MAE: 3854.0371, R2: 0.1478\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2499/5000] | Time: 1.04s\n",
      "(Training) Loss: 983813.4797\n",
      "(Validation) Loss: 1009530.3162, MAE: 3854.3491, R2: 0.1479\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2500/5000] | Time: 0.83s\n",
      "(Training) Loss: 984439.4023\n",
      "(Validation) Loss: 1009368.3454, MAE: 3853.6638, R2: 0.1480\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch2500.pth\n",
      "==========================================================================================\n",
      "Epoch [2501/5000] | Time: 0.89s\n",
      "(Training) Loss: 968954.1923\n",
      "(Validation) Loss: 1009213.0590, MAE: 3857.4880, R2: 0.1482\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2502/5000] | Time: 1.11s\n",
      "(Training) Loss: 984171.8522\n",
      "(Validation) Loss: 1009050.9105, MAE: 3853.0276, R2: 0.1483\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2503/5000] | Time: 0.80s\n",
      "(Training) Loss: 968691.5476\n",
      "(Validation) Loss: 1008878.9943, MAE: 3851.2312, R2: 0.1484\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2504/5000] | Time: 0.87s\n",
      "(Training) Loss: 973498.1472\n",
      "(Validation) Loss: 1008721.6356, MAE: 3850.6165, R2: 0.1486\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2505/5000] | Time: 0.82s\n",
      "(Training) Loss: 979329.3858\n",
      "(Validation) Loss: 1008557.3892, MAE: 3849.3308, R2: 0.1487\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2506/5000] | Time: 0.80s\n",
      "(Training) Loss: 990135.1948\n",
      "(Validation) Loss: 1008394.6463, MAE: 3848.2126, R2: 0.1488\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2507/5000] | Time: 0.80s\n",
      "(Training) Loss: 975054.0254\n",
      "(Validation) Loss: 1008236.9067, MAE: 3850.1343, R2: 0.1490\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2508/5000] | Time: 0.78s\n",
      "(Training) Loss: 994165.7963\n",
      "(Validation) Loss: 1008068.4902, MAE: 3850.6934, R2: 0.1491\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2509/5000] | Time: 0.67s\n",
      "(Training) Loss: 969562.7418\n",
      "(Validation) Loss: 1007919.7663, MAE: 3853.7080, R2: 0.1492\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2510/5000] | Time: 0.75s\n",
      "(Training) Loss: 971697.0546\n",
      "(Validation) Loss: 1007744.2844, MAE: 3853.2800, R2: 0.1494\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2511/5000] | Time: 1.03s\n",
      "(Training) Loss: 980093.1808\n",
      "(Validation) Loss: 1007567.9238, MAE: 3848.8457, R2: 0.1495\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2512/5000] | Time: 0.98s\n",
      "(Training) Loss: 974878.2931\n",
      "(Validation) Loss: 1007403.7486, MAE: 3846.9673, R2: 0.1497\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2513/5000] | Time: 0.83s\n",
      "(Training) Loss: 974417.5822\n",
      "(Validation) Loss: 1007239.1060, MAE: 3845.1277, R2: 0.1498\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2514/5000] | Time: 0.79s\n",
      "(Training) Loss: 978651.8566\n",
      "(Validation) Loss: 1007066.6159, MAE: 3841.7070, R2: 0.1500\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2515/5000] | Time: 0.77s\n",
      "(Training) Loss: 972582.1694\n",
      "(Validation) Loss: 1006904.8990, MAE: 3840.7537, R2: 0.1501\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2516/5000] | Time: 0.92s\n",
      "(Training) Loss: 975987.5901\n",
      "(Validation) Loss: 1006766.3238, MAE: 3844.7842, R2: 0.1502\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2517/5000] | Time: 0.36s\n",
      "(Training) Loss: 976887.6529\n",
      "(Validation) Loss: 1006582.9841, MAE: 3840.1299, R2: 0.1504\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2518/5000] | Time: 0.35s\n",
      "(Training) Loss: 974203.3280\n",
      "(Validation) Loss: 1006420.5816, MAE: 3839.3110, R2: 0.1505\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2519/5000] | Time: 0.62s\n",
      "(Training) Loss: 963661.5349\n",
      "(Validation) Loss: 1006258.8648, MAE: 3838.6355, R2: 0.1506\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2520/5000] | Time: 0.94s\n",
      "(Training) Loss: 979877.5971\n",
      "(Validation) Loss: 1006134.1765, MAE: 3840.6541, R2: 0.1507\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2521/5000] | Time: 1.00s\n",
      "(Training) Loss: 965664.4156\n",
      "(Validation) Loss: 1005974.2781, MAE: 3841.1946, R2: 0.1509\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2522/5000] | Time: 0.99s\n",
      "(Training) Loss: 979558.2766\n",
      "(Validation) Loss: 1005825.8032, MAE: 3846.0718, R2: 0.1510\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2523/5000] | Time: 0.77s\n",
      "(Training) Loss: 970041.9695\n",
      "(Validation) Loss: 1005651.7892, MAE: 3841.2507, R2: 0.1511\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2524/5000] | Time: 0.38s\n",
      "(Training) Loss: 982825.8610\n",
      "(Validation) Loss: 1005488.4978, MAE: 3840.0574, R2: 0.1513\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2525/5000] | Time: 0.28s\n",
      "(Training) Loss: 967668.2747\n",
      "(Validation) Loss: 1005344.6197, MAE: 3843.0500, R2: 0.1514\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2526/5000] | Time: 0.34s\n",
      "(Training) Loss: 984445.0197\n",
      "(Validation) Loss: 1005175.6292, MAE: 3840.7537, R2: 0.1515\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2527/5000] | Time: 0.35s\n",
      "(Training) Loss: 979237.3737\n",
      "(Validation) Loss: 1005002.0775, MAE: 3837.4790, R2: 0.1517\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2528/5000] | Time: 0.34s\n",
      "(Training) Loss: 987835.1313\n",
      "(Validation) Loss: 1004851.8044, MAE: 3840.8723, R2: 0.1518\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2529/5000] | Time: 0.29s\n",
      "(Training) Loss: 975431.5736\n",
      "(Validation) Loss: 1004684.2006, MAE: 3840.0308, R2: 0.1519\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2530/5000] | Time: 0.31s\n",
      "(Training) Loss: 985103.2659\n",
      "(Validation) Loss: 1012314.9054, MAE: 3866.9702, R2: 0.1456\n",
      "==========================================================================================\n",
      "Epoch [2531/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005376.9864\n",
      "(Validation) Loss: 1012156.0584, MAE: 3866.6926, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [2532/5000] | Time: 0.24s\n",
      "(Training) Loss: 980120.4416\n",
      "(Validation) Loss: 1011994.5194, MAE: 3865.4104, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [2533/5000] | Time: 0.33s\n",
      "(Training) Loss: 998151.4467\n",
      "(Validation) Loss: 1011836.1143, MAE: 3865.7622, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [2534/5000] | Time: 0.29s\n",
      "(Training) Loss: 993271.7716\n",
      "(Validation) Loss: 1011673.8946, MAE: 3863.8164, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [2535/5000] | Time: 0.27s\n",
      "(Training) Loss: 976537.9105\n",
      "(Validation) Loss: 1011512.4216, MAE: 3864.3337, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [2536/5000] | Time: 0.23s\n",
      "(Training) Loss: 972425.4645\n",
      "(Validation) Loss: 1011345.6965, MAE: 3863.8521, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [2537/5000] | Time: 0.27s\n",
      "(Training) Loss: 973132.8858\n",
      "(Validation) Loss: 1011189.4451, MAE: 3861.6362, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [2538/5000] | Time: 0.35s\n",
      "(Training) Loss: 972603.7075\n",
      "(Validation) Loss: 1011038.6743, MAE: 3864.6204, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [2539/5000] | Time: 0.31s\n",
      "(Training) Loss: 993352.3553\n",
      "(Validation) Loss: 1010879.5784, MAE: 3862.6790, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [2540/5000] | Time: 0.33s\n",
      "(Training) Loss: 978491.9924\n",
      "(Validation) Loss: 1010706.8597, MAE: 3860.1226, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [2541/5000] | Time: 0.37s\n",
      "(Training) Loss: 972999.3388\n",
      "(Validation) Loss: 1004479.9543, MAE: 3845.2996, R2: 0.1521\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2542/5000] | Time: 0.31s\n",
      "(Training) Loss: 988315.1770\n",
      "(Validation) Loss: 1012165.0438, MAE: 3881.5569, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [2543/5000] | Time: 0.24s\n",
      "(Training) Loss: 1000103.3579\n",
      "(Validation) Loss: 1011986.9714, MAE: 3868.3782, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [2544/5000] | Time: 0.21s\n",
      "(Training) Loss: 1001148.0939\n",
      "(Validation) Loss: 1011828.0483, MAE: 3867.0266, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [2545/5000] | Time: 0.24s\n",
      "(Training) Loss: 986656.6339\n",
      "(Validation) Loss: 1011669.7651, MAE: 3865.8574, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [2546/5000] | Time: 0.26s\n",
      "(Training) Loss: 993900.4695\n",
      "(Validation) Loss: 1011521.0463, MAE: 3866.3372, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [2547/5000] | Time: 0.25s\n",
      "(Training) Loss: 970365.2881\n",
      "(Validation) Loss: 1011375.1721, MAE: 3868.5603, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [2548/5000] | Time: 0.27s\n",
      "(Training) Loss: 983770.3477\n",
      "(Validation) Loss: 1011212.5765, MAE: 3864.4639, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [2549/5000] | Time: 0.32s\n",
      "(Training) Loss: 989212.4112\n",
      "(Validation) Loss: 1011055.9289, MAE: 3863.0596, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [2550/5000] | Time: 0.30s\n",
      "(Training) Loss: 996342.6643\n",
      "(Validation) Loss: 1010904.2997, MAE: 3863.7188, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [2551/5000] | Time: 0.26s\n",
      "(Training) Loss: 973978.3071\n",
      "(Validation) Loss: 1010750.7911, MAE: 3863.2534, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [2552/5000] | Time: 0.26s\n",
      "(Training) Loss: 976957.8585\n",
      "(Validation) Loss: 1010611.9010, MAE: 3865.2393, R2: 0.1470\n",
      "==========================================================================================\n",
      "Epoch [2553/5000] | Time: 0.24s\n",
      "(Training) Loss: 969160.0430\n",
      "(Validation) Loss: 1010453.7651, MAE: 3864.4155, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [2554/5000] | Time: 0.22s\n",
      "(Training) Loss: 975399.1815\n",
      "(Validation) Loss: 1010294.6641, MAE: 3861.0352, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [2555/5000] | Time: 0.19s\n",
      "(Training) Loss: 990064.4949\n",
      "(Validation) Loss: 1010137.4883, MAE: 3860.2473, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [2556/5000] | Time: 0.23s\n",
      "(Training) Loss: 981046.6345\n",
      "(Validation) Loss: 1009979.1492, MAE: 3858.0891, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [2557/5000] | Time: 0.21s\n",
      "(Training) Loss: 986863.1701\n",
      "(Validation) Loss: 1009824.7771, MAE: 3857.9207, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [2558/5000] | Time: 0.24s\n",
      "(Training) Loss: 976473.0130\n",
      "(Validation) Loss: 1009672.8889, MAE: 3857.4155, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [2559/5000] | Time: 0.27s\n",
      "(Training) Loss: 973742.7265\n",
      "(Validation) Loss: 1009523.6825, MAE: 3857.8215, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [2560/5000] | Time: 0.27s\n",
      "(Training) Loss: 982884.5984\n",
      "(Validation) Loss: 1009389.4502, MAE: 3861.5469, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [2561/5000] | Time: 0.34s\n",
      "(Training) Loss: 983960.4334\n",
      "(Validation) Loss: 1009223.6597, MAE: 3860.3149, R2: 0.1482\n",
      "==========================================================================================\n",
      "Epoch [2562/5000] | Time: 0.25s\n",
      "(Training) Loss: 976100.5647\n",
      "(Validation) Loss: 1009045.0032, MAE: 3857.0710, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [2563/5000] | Time: 0.28s\n",
      "(Training) Loss: 975977.7589\n",
      "(Validation) Loss: 1008885.3537, MAE: 3852.9285, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [2564/5000] | Time: 0.21s\n",
      "(Training) Loss: 978913.3027\n",
      "(Validation) Loss: 1008726.3390, MAE: 3851.7195, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [2565/5000] | Time: 0.21s\n",
      "(Training) Loss: 971442.6599\n",
      "(Validation) Loss: 1008568.7924, MAE: 3850.8254, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [2566/5000] | Time: 0.24s\n",
      "(Training) Loss: 988870.1758\n",
      "(Validation) Loss: 1008458.3517, MAE: 3854.3909, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [2567/5000] | Time: 0.25s\n",
      "(Training) Loss: 971447.3407\n",
      "(Validation) Loss: 1008271.3346, MAE: 3850.6362, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [2568/5000] | Time: 0.21s\n",
      "(Training) Loss: 967520.3506\n",
      "(Validation) Loss: 1008145.2444, MAE: 3851.4570, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [2569/5000] | Time: 0.20s\n",
      "(Training) Loss: 974127.9562\n",
      "(Validation) Loss: 1007998.8571, MAE: 3851.4089, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [2570/5000] | Time: 0.20s\n",
      "(Training) Loss: 984623.9518\n",
      "(Validation) Loss: 1007846.6489, MAE: 3851.2937, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [2571/5000] | Time: 0.20s\n",
      "(Training) Loss: 970264.2119\n",
      "(Validation) Loss: 1007696.6248, MAE: 3851.6287, R2: 0.1494\n",
      "==========================================================================================\n",
      "Epoch [2572/5000] | Time: 0.20s\n",
      "(Training) Loss: 988144.4860\n",
      "(Validation) Loss: 1007535.7156, MAE: 3848.8162, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [2573/5000] | Time: 0.19s\n",
      "(Training) Loss: 970379.9765\n",
      "(Validation) Loss: 1007383.6190, MAE: 3849.4888, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [2574/5000] | Time: 0.19s\n",
      "(Training) Loss: 980552.2849\n",
      "(Validation) Loss: 1007233.5238, MAE: 3848.3259, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [2575/5000] | Time: 0.22s\n",
      "(Training) Loss: 971881.6599\n",
      "(Validation) Loss: 1007085.5060, MAE: 3848.8140, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [2576/5000] | Time: 0.21s\n",
      "(Training) Loss: 977318.1117\n",
      "(Validation) Loss: 1006930.2400, MAE: 3848.1350, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [2577/5000] | Time: 0.27s\n",
      "(Training) Loss: 967101.3115\n",
      "(Validation) Loss: 1006771.6317, MAE: 3846.0950, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [2578/5000] | Time: 0.29s\n",
      "(Training) Loss: 965563.6288\n",
      "(Validation) Loss: 1006628.0889, MAE: 3847.9485, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [2579/5000] | Time: 0.23s\n",
      "(Training) Loss: 989371.1637\n",
      "(Validation) Loss: 1006500.6019, MAE: 3852.1309, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [2580/5000] | Time: 0.24s\n",
      "(Training) Loss: 965850.2792\n",
      "(Validation) Loss: 1006320.7975, MAE: 3846.3096, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [2581/5000] | Time: 0.32s\n",
      "(Training) Loss: 980241.3065\n",
      "(Validation) Loss: 1006168.2184, MAE: 3845.7144, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [2582/5000] | Time: 0.29s\n",
      "(Training) Loss: 965227.5909\n",
      "(Validation) Loss: 1006011.9213, MAE: 3843.9685, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [2583/5000] | Time: 0.42s\n",
      "(Training) Loss: 1001697.6263\n",
      "(Validation) Loss: 1005862.6286, MAE: 3842.8872, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [2584/5000] | Time: 0.37s\n",
      "(Training) Loss: 967880.3344\n",
      "(Validation) Loss: 1005712.2438, MAE: 3844.7102, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [2585/5000] | Time: 0.31s\n",
      "(Training) Loss: 969024.6701\n",
      "(Validation) Loss: 1005557.7244, MAE: 3842.7837, R2: 0.1512\n",
      "==========================================================================================\n",
      "Epoch [2586/5000] | Time: 0.26s\n",
      "(Training) Loss: 993141.7570\n",
      "(Validation) Loss: 1005402.4076, MAE: 3841.5647, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [2587/5000] | Time: 0.24s\n",
      "(Training) Loss: 991417.1199\n",
      "(Validation) Loss: 1005248.9041, MAE: 3841.1426, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [2588/5000] | Time: 0.32s\n",
      "(Training) Loss: 972110.1897\n",
      "(Validation) Loss: 1005101.8362, MAE: 3841.9937, R2: 0.1516\n",
      "==========================================================================================\n",
      "Epoch [2589/5000] | Time: 0.28s\n",
      "(Training) Loss: 962516.6270\n",
      "(Validation) Loss: 1004941.7956, MAE: 3840.0942, R2: 0.1517\n",
      "==========================================================================================\n",
      "Epoch [2590/5000] | Time: 0.23s\n",
      "(Training) Loss: 980244.9803\n",
      "(Validation) Loss: 1004793.3613, MAE: 3840.0615, R2: 0.1518\n",
      "==========================================================================================\n",
      "Epoch [2591/5000] | Time: 0.20s\n",
      "(Training) Loss: 969151.6472\n",
      "(Validation) Loss: 1004641.4832, MAE: 3839.5183, R2: 0.1520\n",
      "==========================================================================================\n",
      "Epoch [2592/5000] | Time: 0.21s\n",
      "(Training) Loss: 968626.6916\n",
      "(Validation) Loss: 1004492.4648, MAE: 3841.1082, R2: 0.1521\n",
      "==========================================================================================\n",
      "Epoch [2593/5000] | Time: 0.24s\n",
      "(Training) Loss: 961919.5706\n",
      "(Validation) Loss: 1004342.3492, MAE: 3839.9229, R2: 0.1522\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2594/5000] | Time: 0.21s\n",
      "(Training) Loss: 972491.5114\n",
      "(Validation) Loss: 1004190.5625, MAE: 3838.2107, R2: 0.1523\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2595/5000] | Time: 0.21s\n",
      "(Training) Loss: 981063.7538\n",
      "(Validation) Loss: 1004033.7778, MAE: 3837.5906, R2: 0.1525\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2596/5000] | Time: 0.32s\n",
      "(Training) Loss: 971968.3877\n",
      "(Validation) Loss: 1003919.9390, MAE: 3840.0088, R2: 0.1526\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2597/5000] | Time: 0.20s\n",
      "(Training) Loss: 972688.5933\n",
      "(Validation) Loss: 1003786.0419, MAE: 3842.3428, R2: 0.1527\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2598/5000] | Time: 0.31s\n",
      "(Training) Loss: 970521.8693\n",
      "(Validation) Loss: 1003632.0356, MAE: 3840.8191, R2: 0.1528\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2599/5000] | Time: 0.21s\n",
      "(Training) Loss: 974490.2690\n",
      "(Validation) Loss: 1003428.1600, MAE: 3836.5010, R2: 0.1530\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2600/5000] | Time: 0.21s\n",
      "(Training) Loss: 965943.0311\n",
      "(Validation) Loss: 1003281.3917, MAE: 3836.3728, R2: 0.1531\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2601/5000] | Time: 0.23s\n",
      "(Training) Loss: 981127.0019\n",
      "(Validation) Loss: 1003147.1695, MAE: 3840.4761, R2: 0.1532\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2602/5000] | Time: 0.23s\n",
      "(Training) Loss: 971011.2208\n",
      "(Validation) Loss: 1002982.8114, MAE: 3837.7917, R2: 0.1534\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2603/5000] | Time: 0.27s\n",
      "(Training) Loss: 980772.6193\n",
      "(Validation) Loss: 1002873.0768, MAE: 3837.8818, R2: 0.1534\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2604/5000] | Time: 0.21s\n",
      "(Training) Loss: 977878.9575\n",
      "(Validation) Loss: 1002725.3283, MAE: 3837.4824, R2: 0.1536\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2605/5000] | Time: 0.20s\n",
      "(Training) Loss: 967341.0977\n",
      "(Validation) Loss: 1002570.1029, MAE: 3837.6477, R2: 0.1537\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2606/5000] | Time: 0.20s\n",
      "(Training) Loss: 965265.1999\n",
      "(Validation) Loss: 1002411.4946, MAE: 3835.7683, R2: 0.1538\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2607/5000] | Time: 0.27s\n",
      "(Training) Loss: 991892.3046\n",
      "(Validation) Loss: 1002266.7073, MAE: 3836.6958, R2: 0.1539\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2608/5000] | Time: 0.25s\n",
      "(Training) Loss: 978528.5603\n",
      "(Validation) Loss: 1002111.7257, MAE: 3836.0952, R2: 0.1541\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2609/5000] | Time: 0.36s\n",
      "(Training) Loss: 965159.6980\n",
      "(Validation) Loss: 1001961.9403, MAE: 3835.5930, R2: 0.1542\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2610/5000] | Time: 0.28s\n",
      "(Training) Loss: 987019.8585\n",
      "(Validation) Loss: 1001806.9790, MAE: 3833.8523, R2: 0.1543\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2611/5000] | Time: 0.34s\n",
      "(Training) Loss: 971819.5996\n",
      "(Validation) Loss: 1001653.2165, MAE: 3833.5750, R2: 0.1545\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2612/5000] | Time: 0.33s\n",
      "(Training) Loss: 967221.2576\n",
      "(Validation) Loss: 1001507.6673, MAE: 3833.9331, R2: 0.1546\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2613/5000] | Time: 0.27s\n",
      "(Training) Loss: 980024.7424\n",
      "(Validation) Loss: 1001348.4800, MAE: 3831.2017, R2: 0.1547\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2614/5000] | Time: 0.24s\n",
      "(Training) Loss: 961816.7716\n",
      "(Validation) Loss: 1001197.3130, MAE: 3831.0530, R2: 0.1548\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2615/5000] | Time: 0.25s\n",
      "(Training) Loss: 973662.1174\n",
      "(Validation) Loss: 1001054.5016, MAE: 3833.5876, R2: 0.1550\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2616/5000] | Time: 0.22s\n",
      "(Training) Loss: 979842.1910\n",
      "(Validation) Loss: 1000897.8083, MAE: 3831.2209, R2: 0.1551\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2617/5000] | Time: 0.22s\n",
      "(Training) Loss: 963668.4283\n",
      "(Validation) Loss: 1000746.5295, MAE: 3831.9746, R2: 0.1552\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2618/5000] | Time: 0.23s\n",
      "(Training) Loss: 981650.3931\n",
      "(Validation) Loss: 1000596.6019, MAE: 3830.8982, R2: 0.1553\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2619/5000] | Time: 0.24s\n",
      "(Training) Loss: 971804.3233\n",
      "(Validation) Loss: 1000459.5149, MAE: 3833.8982, R2: 0.1555\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2620/5000] | Time: 0.28s\n",
      "(Training) Loss: 992736.9315\n",
      "(Validation) Loss: 1000287.2635, MAE: 3828.8228, R2: 0.1556\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2621/5000] | Time: 0.25s\n",
      "(Training) Loss: 959923.7056\n",
      "(Validation) Loss: 1000146.1587, MAE: 3830.1257, R2: 0.1557\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2622/5000] | Time: 0.37s\n",
      "(Training) Loss: 968749.2272\n",
      "(Validation) Loss: 999986.6514, MAE: 3828.0242, R2: 0.1558\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2623/5000] | Time: 0.27s\n",
      "(Training) Loss: 971525.4055\n",
      "(Validation) Loss: 999836.7340, MAE: 3826.9958, R2: 0.1560\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2624/5000] | Time: 0.25s\n",
      "(Training) Loss: 996924.2075\n",
      "(Validation) Loss: 1015870.4660, MAE: 3891.5527, R2: 0.1426\n",
      "==========================================================================================\n",
      "Epoch [2625/5000] | Time: 0.22s\n",
      "(Training) Loss: 979774.6187\n",
      "(Validation) Loss: 1015685.3994, MAE: 3885.8118, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [2626/5000] | Time: 0.21s\n",
      "(Training) Loss: 984982.3515\n",
      "(Validation) Loss: 1015535.1873, MAE: 3882.9822, R2: 0.1429\n",
      "==========================================================================================\n",
      "Epoch [2627/5000] | Time: 0.20s\n",
      "(Training) Loss: 987489.3902\n",
      "(Validation) Loss: 1015379.2356, MAE: 3883.3025, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [2628/5000] | Time: 0.21s\n",
      "(Training) Loss: 990747.8274\n",
      "(Validation) Loss: 1015226.1283, MAE: 3884.8098, R2: 0.1431\n",
      "==========================================================================================\n",
      "Epoch [2629/5000] | Time: 0.23s\n",
      "(Training) Loss: 981761.9353\n",
      "(Validation) Loss: 1015070.7403, MAE: 3882.0632, R2: 0.1433\n",
      "==========================================================================================\n",
      "Epoch [2630/5000] | Time: 0.22s\n",
      "(Training) Loss: 997746.7849\n",
      "(Validation) Loss: 1014923.7537, MAE: 3884.8699, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [2631/5000] | Time: 0.22s\n",
      "(Training) Loss: 986327.2310\n",
      "(Validation) Loss: 1014749.2724, MAE: 3879.8792, R2: 0.1435\n",
      "==========================================================================================\n",
      "Epoch [2632/5000] | Time: 0.21s\n",
      "(Training) Loss: 990704.9137\n",
      "(Validation) Loss: 1014594.2654, MAE: 3879.0635, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [2633/5000] | Time: 0.35s\n",
      "(Training) Loss: 980656.4613\n",
      "(Validation) Loss: 1014437.3740, MAE: 3879.6248, R2: 0.1438\n",
      "==========================================================================================\n",
      "Epoch [2634/5000] | Time: 0.27s\n",
      "(Training) Loss: 985346.6758\n",
      "(Validation) Loss: 1014283.2152, MAE: 3877.9746, R2: 0.1439\n",
      "==========================================================================================\n",
      "Epoch [2635/5000] | Time: 0.25s\n",
      "(Training) Loss: 979513.2487\n",
      "(Validation) Loss: 1014128.9194, MAE: 3877.8616, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [2636/5000] | Time: 0.21s\n",
      "(Training) Loss: 1008052.0368\n",
      "(Validation) Loss: 1013971.2711, MAE: 3876.6926, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [2637/5000] | Time: 0.31s\n",
      "(Training) Loss: 978792.9074\n",
      "(Validation) Loss: 1013817.8590, MAE: 3878.3118, R2: 0.1443\n",
      "==========================================================================================\n",
      "Epoch [2638/5000] | Time: 0.30s\n",
      "(Training) Loss: 992328.2773\n",
      "(Validation) Loss: 1013662.5270, MAE: 3878.0115, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [2639/5000] | Time: 0.31s\n",
      "(Training) Loss: 975107.4086\n",
      "(Validation) Loss: 1006602.4483, MAE: 3858.0063, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [2640/5000] | Time: 0.31s\n",
      "(Training) Loss: 974431.7887\n",
      "(Validation) Loss: 1006438.7657, MAE: 3857.1609, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [2641/5000] | Time: 0.25s\n",
      "(Training) Loss: 968965.1155\n",
      "(Validation) Loss: 1006395.4337, MAE: 3860.6172, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [2642/5000] | Time: 0.26s\n",
      "(Training) Loss: 982090.7449\n",
      "(Validation) Loss: 1006155.6165, MAE: 3865.5652, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [2643/5000] | Time: 0.26s\n",
      "(Training) Loss: 978782.2830\n",
      "(Validation) Loss: 1005948.5613, MAE: 3850.6714, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [2644/5000] | Time: 0.26s\n",
      "(Training) Loss: 965106.9051\n",
      "(Validation) Loss: 1005788.2362, MAE: 3849.8279, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [2645/5000] | Time: 0.26s\n",
      "(Training) Loss: 987756.5742\n",
      "(Validation) Loss: 1005635.5810, MAE: 3851.1907, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [2646/5000] | Time: 0.28s\n",
      "(Training) Loss: 989538.1586\n",
      "(Validation) Loss: 1005471.4870, MAE: 3847.8433, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [2647/5000] | Time: 0.26s\n",
      "(Training) Loss: 982702.3484\n",
      "(Validation) Loss: 1005313.7422, MAE: 3846.6448, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [2648/5000] | Time: 0.24s\n",
      "(Training) Loss: 978319.3204\n",
      "(Validation) Loss: 1005151.8578, MAE: 3845.7432, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [2649/5000] | Time: 0.25s\n",
      "(Training) Loss: 983901.6992\n",
      "(Validation) Loss: 1005003.0781, MAE: 3847.5276, R2: 0.1517\n",
      "==========================================================================================\n",
      "Epoch [2650/5000] | Time: 0.25s\n",
      "(Training) Loss: 1001835.9791\n",
      "(Validation) Loss: 1004848.5181, MAE: 3846.9734, R2: 0.1518\n",
      "==========================================================================================\n",
      "Epoch [2651/5000] | Time: 0.34s\n",
      "(Training) Loss: 971527.9600\n",
      "(Validation) Loss: 1004687.8375, MAE: 3847.3464, R2: 0.1519\n",
      "==========================================================================================\n",
      "Epoch [2652/5000] | Time: 0.20s\n",
      "(Training) Loss: 967813.0717\n",
      "(Validation) Loss: 1004529.0971, MAE: 3845.5908, R2: 0.1521\n",
      "==========================================================================================\n",
      "Epoch [2653/5000] | Time: 0.24s\n",
      "(Training) Loss: 982165.3185\n",
      "(Validation) Loss: 1004377.3156, MAE: 3845.6394, R2: 0.1522\n",
      "==========================================================================================\n",
      "Epoch [2654/5000] | Time: 0.21s\n",
      "(Training) Loss: 986541.4118\n",
      "(Validation) Loss: 1004212.5410, MAE: 3843.1882, R2: 0.1523\n",
      "==========================================================================================\n",
      "Epoch [2655/5000] | Time: 0.24s\n",
      "(Training) Loss: 962459.4374\n",
      "(Validation) Loss: 1004053.2876, MAE: 3842.7148, R2: 0.1525\n",
      "==========================================================================================\n",
      "Epoch [2656/5000] | Time: 0.25s\n",
      "(Training) Loss: 983767.9657\n",
      "(Validation) Loss: 1003906.7683, MAE: 3844.2515, R2: 0.1526\n",
      "==========================================================================================\n",
      "Epoch [2657/5000] | Time: 0.35s\n",
      "(Training) Loss: 964365.0311\n",
      "(Validation) Loss: 1003812.8203, MAE: 3842.8044, R2: 0.1527\n",
      "==========================================================================================\n",
      "Epoch [2658/5000] | Time: 0.23s\n",
      "(Training) Loss: 983554.4162\n",
      "(Validation) Loss: 1003588.3175, MAE: 3841.2568, R2: 0.1528\n",
      "==========================================================================================\n",
      "Epoch [2659/5000] | Time: 0.21s\n",
      "(Training) Loss: 979422.7335\n",
      "(Validation) Loss: 1003437.0895, MAE: 3842.1680, R2: 0.1530\n",
      "==========================================================================================\n",
      "Epoch [2660/5000] | Time: 0.21s\n",
      "(Training) Loss: 969943.0279\n",
      "(Validation) Loss: 1003277.4044, MAE: 3840.9902, R2: 0.1531\n",
      "==========================================================================================\n",
      "Epoch [2661/5000] | Time: 0.21s\n",
      "(Training) Loss: 974022.4099\n",
      "(Validation) Loss: 1003119.6749, MAE: 3839.9373, R2: 0.1532\n",
      "==========================================================================================\n",
      "Epoch [2662/5000] | Time: 0.21s\n",
      "(Training) Loss: 979411.7544\n",
      "(Validation) Loss: 1002968.4368, MAE: 3840.2939, R2: 0.1534\n",
      "==========================================================================================\n",
      "Epoch [2663/5000] | Time: 0.21s\n",
      "(Training) Loss: 974615.9061\n",
      "(Validation) Loss: 1002810.0775, MAE: 3838.3528, R2: 0.1535\n",
      "==========================================================================================\n",
      "Epoch [2664/5000] | Time: 0.21s\n",
      "(Training) Loss: 970237.2475\n",
      "(Validation) Loss: 1002652.6425, MAE: 3838.4512, R2: 0.1536\n",
      "==========================================================================================\n",
      "Epoch [2665/5000] | Time: 0.25s\n",
      "(Training) Loss: 977291.0419\n",
      "(Validation) Loss: 1002507.0375, MAE: 3840.9395, R2: 0.1537\n",
      "==========================================================================================\n",
      "Epoch [2666/5000] | Time: 0.22s\n",
      "(Training) Loss: 960021.3735\n",
      "(Validation) Loss: 1002343.9695, MAE: 3836.8333, R2: 0.1539\n",
      "==========================================================================================\n",
      "Epoch [2667/5000] | Time: 0.28s\n",
      "(Training) Loss: 965140.3737\n",
      "(Validation) Loss: 1002197.9073, MAE: 3837.5896, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [2668/5000] | Time: 0.34s\n",
      "(Training) Loss: 985459.1732\n",
      "(Validation) Loss: 1002045.4603, MAE: 3837.2407, R2: 0.1541\n",
      "==========================================================================================\n",
      "Epoch [2669/5000] | Time: 0.24s\n",
      "(Training) Loss: 985615.3915\n",
      "(Validation) Loss: 1001877.9835, MAE: 3834.9629, R2: 0.1543\n",
      "==========================================================================================\n",
      "Epoch [2670/5000] | Time: 0.35s\n",
      "(Training) Loss: 968879.4150\n",
      "(Validation) Loss: 1001730.2806, MAE: 3837.7361, R2: 0.1544\n",
      "==========================================================================================\n",
      "Epoch [2671/5000] | Time: 0.34s\n",
      "(Training) Loss: 960132.9099\n",
      "(Validation) Loss: 1001573.4349, MAE: 3836.2058, R2: 0.1545\n",
      "==========================================================================================\n",
      "Epoch [2672/5000] | Time: 0.33s\n",
      "(Training) Loss: 974093.1583\n",
      "(Validation) Loss: 1001500.5917, MAE: 3840.5083, R2: 0.1546\n",
      "==========================================================================================\n",
      "Epoch [2673/5000] | Time: 0.27s\n",
      "(Training) Loss: 960498.4572\n",
      "(Validation) Loss: 1001343.7308, MAE: 3839.0593, R2: 0.1547\n",
      "==========================================================================================\n",
      "Epoch [2674/5000] | Time: 0.31s\n",
      "(Training) Loss: 985374.0952\n",
      "(Validation) Loss: 1013814.6641, MAE: 3878.6206, R2: 0.1443\n",
      "==========================================================================================\n",
      "Epoch [2675/5000] | Time: 0.36s\n",
      "(Training) Loss: 1002389.4632\n",
      "(Validation) Loss: 1030223.3956, MAE: 3935.1980, R2: 0.1306\n",
      "==========================================================================================\n",
      "Epoch [2676/5000] | Time: 0.32s\n",
      "(Training) Loss: 1002787.6612\n",
      "(Validation) Loss: 1030047.2279, MAE: 3932.8406, R2: 0.1308\n",
      "==========================================================================================\n",
      "Epoch [2677/5000] | Time: 0.24s\n",
      "(Training) Loss: 1010562.2544\n",
      "(Validation) Loss: 1046799.0908, MAE: 3988.7512, R2: 0.1168\n",
      "==========================================================================================\n",
      "Epoch [2678/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002809.6786\n",
      "(Validation) Loss: 1050544.6248, MAE: 4005.4336, R2: 0.1137\n",
      "==========================================================================================\n",
      "Epoch [2679/5000] | Time: 0.25s\n",
      "(Training) Loss: 1009846.1529\n",
      "(Validation) Loss: 1050344.8889, MAE: 4000.8713, R2: 0.1139\n",
      "==========================================================================================\n",
      "Epoch [2680/5000] | Time: 0.33s\n",
      "(Training) Loss: 1025311.6301\n",
      "(Validation) Loss: 1050161.6152, MAE: 4000.6460, R2: 0.1140\n",
      "==========================================================================================\n",
      "Epoch [2681/5000] | Time: 0.29s\n",
      "(Training) Loss: 1022534.5381\n",
      "(Validation) Loss: 1049978.1283, MAE: 3999.8701, R2: 0.1142\n",
      "==========================================================================================\n",
      "Epoch [2682/5000] | Time: 0.23s\n",
      "(Training) Loss: 1016354.7088\n",
      "(Validation) Loss: 1049798.1105, MAE: 3999.1980, R2: 0.1143\n",
      "==========================================================================================\n",
      "Epoch [2683/5000] | Time: 0.24s\n",
      "(Training) Loss: 1020200.8185\n",
      "(Validation) Loss: 1049624.1625, MAE: 4000.5732, R2: 0.1145\n",
      "==========================================================================================\n",
      "Epoch [2684/5000] | Time: 0.23s\n",
      "(Training) Loss: 1012259.2665\n",
      "(Validation) Loss: 1049446.8775, MAE: 3999.6953, R2: 0.1146\n",
      "==========================================================================================\n",
      "Epoch [2685/5000] | Time: 0.27s\n",
      "(Training) Loss: 1023847.9930\n",
      "(Validation) Loss: 1049282.4737, MAE: 4002.8914, R2: 0.1148\n",
      "==========================================================================================\n",
      "Epoch [2686/5000] | Time: 0.22s\n",
      "(Training) Loss: 1016644.8255\n",
      "(Validation) Loss: 1040639.7968, MAE: 3972.4729, R2: 0.1220\n",
      "==========================================================================================\n",
      "Epoch [2687/5000] | Time: 0.27s\n",
      "(Training) Loss: 1016558.7627\n",
      "(Validation) Loss: 1040461.1708, MAE: 3971.4580, R2: 0.1221\n",
      "==========================================================================================\n",
      "Epoch [2688/5000] | Time: 0.22s\n",
      "(Training) Loss: 1002651.6961\n",
      "(Validation) Loss: 1040279.8832, MAE: 3969.3540, R2: 0.1223\n",
      "==========================================================================================\n",
      "Epoch [2689/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000080.3166\n",
      "(Validation) Loss: 1040109.4705, MAE: 3969.7495, R2: 0.1224\n",
      "==========================================================================================\n",
      "Epoch [2690/5000] | Time: 0.31s\n",
      "(Training) Loss: 1012875.4385\n",
      "(Validation) Loss: 1039933.6229, MAE: 3967.4058, R2: 0.1226\n",
      "==========================================================================================\n",
      "Epoch [2691/5000] | Time: 0.24s\n",
      "(Training) Loss: 998713.4873\n",
      "(Validation) Loss: 1039758.2578, MAE: 3967.8474, R2: 0.1227\n",
      "==========================================================================================\n",
      "Epoch [2692/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019450.5444\n",
      "(Validation) Loss: 1039592.7060, MAE: 3968.7063, R2: 0.1228\n",
      "==========================================================================================\n",
      "Epoch [2693/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010317.3319\n",
      "(Validation) Loss: 1039423.5937, MAE: 3968.8730, R2: 0.1230\n",
      "==========================================================================================\n",
      "Epoch [2694/5000] | Time: 0.23s\n",
      "(Training) Loss: 999687.9023\n",
      "(Validation) Loss: 1039241.3105, MAE: 3965.8384, R2: 0.1231\n",
      "==========================================================================================\n",
      "Epoch [2695/5000] | Time: 0.28s\n",
      "(Training) Loss: 1031938.2398\n",
      "(Validation) Loss: 1039072.4724, MAE: 3967.8162, R2: 0.1233\n",
      "==========================================================================================\n",
      "Epoch [2696/5000] | Time: 0.26s\n",
      "(Training) Loss: 1013484.2386\n",
      "(Validation) Loss: 1038894.2679, MAE: 3965.5823, R2: 0.1234\n",
      "==========================================================================================\n",
      "Epoch [2697/5000] | Time: 0.27s\n",
      "(Training) Loss: 1001701.6701\n",
      "(Validation) Loss: 1038717.4451, MAE: 3963.9214, R2: 0.1236\n",
      "==========================================================================================\n",
      "Epoch [2698/5000] | Time: 0.29s\n",
      "(Training) Loss: 1023107.2544\n",
      "(Validation) Loss: 1038546.8292, MAE: 3962.9807, R2: 0.1237\n",
      "==========================================================================================\n",
      "Epoch [2699/5000] | Time: 0.33s\n",
      "(Training) Loss: 996865.5647\n",
      "(Validation) Loss: 1038375.5581, MAE: 3963.1646, R2: 0.1239\n",
      "==========================================================================================\n",
      "Epoch [2700/5000] | Time: 0.30s\n",
      "(Training) Loss: 1031142.6574\n",
      "(Validation) Loss: 1038208.0660, MAE: 3962.7629, R2: 0.1240\n",
      "==========================================================================================\n",
      "Epoch [2701/5000] | Time: 0.27s\n",
      "(Training) Loss: 1014628.9321\n",
      "(Validation) Loss: 1038043.1340, MAE: 3966.0422, R2: 0.1241\n",
      "==========================================================================================\n",
      "Epoch [2702/5000] | Time: 0.22s\n",
      "(Training) Loss: 998419.6472\n",
      "(Validation) Loss: 1037861.3029, MAE: 3960.7307, R2: 0.1243\n",
      "==========================================================================================\n",
      "Epoch [2703/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001569.8338\n",
      "(Validation) Loss: 1037701.4756, MAE: 3964.1553, R2: 0.1244\n",
      "==========================================================================================\n",
      "Epoch [2704/5000] | Time: 0.30s\n",
      "(Training) Loss: 996961.3445\n",
      "(Validation) Loss: 1037524.2667, MAE: 3960.2925, R2: 0.1246\n",
      "==========================================================================================\n",
      "Epoch [2705/5000] | Time: 0.25s\n",
      "(Training) Loss: 994590.7072\n",
      "(Validation) Loss: 1037358.9537, MAE: 3960.5071, R2: 0.1247\n",
      "==========================================================================================\n",
      "Epoch [2706/5000] | Time: 0.23s\n",
      "(Training) Loss: 1017048.4753\n",
      "(Validation) Loss: 1037195.1187, MAE: 3960.9163, R2: 0.1248\n",
      "==========================================================================================\n",
      "Epoch [2707/5000] | Time: 0.25s\n",
      "(Training) Loss: 1002372.5812\n",
      "(Validation) Loss: 1037013.4248, MAE: 3957.7390, R2: 0.1250\n",
      "==========================================================================================\n",
      "Epoch [2708/5000] | Time: 0.25s\n",
      "(Training) Loss: 1020909.6973\n",
      "(Validation) Loss: 1036852.3886, MAE: 3959.4907, R2: 0.1251\n",
      "==========================================================================================\n",
      "Epoch [2709/5000] | Time: 0.25s\n",
      "(Training) Loss: 1017863.7462\n",
      "(Validation) Loss: 1036675.3625, MAE: 3956.3330, R2: 0.1253\n",
      "==========================================================================================\n",
      "Epoch [2710/5000] | Time: 0.23s\n",
      "(Training) Loss: 997568.4331\n",
      "(Validation) Loss: 1036540.8762, MAE: 3967.4675, R2: 0.1254\n",
      "==========================================================================================\n",
      "Epoch [2711/5000] | Time: 0.24s\n",
      "(Training) Loss: 1026378.7976\n",
      "(Validation) Loss: 1036339.8959, MAE: 3956.3823, R2: 0.1255\n",
      "==========================================================================================\n",
      "Epoch [2712/5000] | Time: 0.26s\n",
      "(Training) Loss: 1024618.3832\n",
      "(Validation) Loss: 1036166.5727, MAE: 3954.7820, R2: 0.1257\n",
      "==========================================================================================\n",
      "Epoch [2713/5000] | Time: 0.26s\n",
      "(Training) Loss: 1010497.8395\n",
      "(Validation) Loss: 1036011.3524, MAE: 3960.0310, R2: 0.1258\n",
      "==========================================================================================\n",
      "Epoch [2714/5000] | Time: 0.27s\n",
      "(Training) Loss: 1009794.6643\n",
      "(Validation) Loss: 1035833.5390, MAE: 3956.7271, R2: 0.1260\n",
      "==========================================================================================\n",
      "Epoch [2715/5000] | Time: 0.56s\n",
      "(Training) Loss: 1010890.3591\n",
      "(Validation) Loss: 1035662.1765, MAE: 3954.7498, R2: 0.1261\n",
      "==========================================================================================\n",
      "Epoch [2716/5000] | Time: 0.28s\n",
      "(Training) Loss: 1005752.6691\n",
      "(Validation) Loss: 1035492.9981, MAE: 3953.6460, R2: 0.1263\n",
      "==========================================================================================\n",
      "Epoch [2717/5000] | Time: 0.32s\n",
      "(Training) Loss: 1000952.0964\n",
      "(Validation) Loss: 1035324.3886, MAE: 3952.7644, R2: 0.1264\n",
      "==========================================================================================\n",
      "Epoch [2718/5000] | Time: 0.31s\n",
      "(Training) Loss: 1004268.6326\n",
      "(Validation) Loss: 1035156.1600, MAE: 3951.3096, R2: 0.1265\n",
      "==========================================================================================\n",
      "Epoch [2719/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009746.5552\n",
      "(Validation) Loss: 1034986.2502, MAE: 3950.6521, R2: 0.1267\n",
      "==========================================================================================\n",
      "Epoch [2720/5000] | Time: 0.21s\n",
      "(Training) Loss: 1005764.7868\n",
      "(Validation) Loss: 1034823.3194, MAE: 3951.3416, R2: 0.1268\n",
      "==========================================================================================\n",
      "Epoch [2721/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012083.4416\n",
      "(Validation) Loss: 1034655.2787, MAE: 3950.5867, R2: 0.1270\n",
      "==========================================================================================\n",
      "Epoch [2722/5000] | Time: 0.21s\n",
      "(Training) Loss: 999832.4645\n",
      "(Validation) Loss: 1034484.0330, MAE: 3949.2930, R2: 0.1271\n",
      "==========================================================================================\n",
      "Epoch [2723/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010888.2963\n",
      "(Validation) Loss: 1034328.6451, MAE: 3957.2866, R2: 0.1272\n",
      "==========================================================================================\n",
      "Epoch [2724/5000] | Time: 0.36s\n",
      "(Training) Loss: 1020764.2202\n",
      "(Validation) Loss: 1034153.1835, MAE: 3952.1699, R2: 0.1274\n",
      "==========================================================================================\n",
      "Epoch [2725/5000] | Time: 0.24s\n",
      "(Training) Loss: 1007397.4454\n",
      "(Validation) Loss: 1033988.9371, MAE: 3954.9500, R2: 0.1275\n",
      "==========================================================================================\n",
      "Epoch [2726/5000] | Time: 0.23s\n",
      "(Training) Loss: 995813.2602\n",
      "(Validation) Loss: 1033810.7733, MAE: 3948.8904, R2: 0.1277\n",
      "==========================================================================================\n",
      "Epoch [2727/5000] | Time: 0.23s\n",
      "(Training) Loss: 996548.3813\n",
      "(Validation) Loss: 1033640.3098, MAE: 3946.7581, R2: 0.1278\n",
      "==========================================================================================\n",
      "Epoch [2728/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003307.7037\n",
      "(Validation) Loss: 1033475.2000, MAE: 3946.2556, R2: 0.1279\n",
      "==========================================================================================\n",
      "Epoch [2729/5000] | Time: 0.22s\n",
      "(Training) Loss: 1016255.9543\n",
      "(Validation) Loss: 1033314.8597, MAE: 3946.9214, R2: 0.1281\n",
      "==========================================================================================\n",
      "Epoch [2730/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012966.0305\n",
      "(Validation) Loss: 1033150.4102, MAE: 3947.6958, R2: 0.1282\n",
      "==========================================================================================\n",
      "Epoch [2731/5000] | Time: 0.26s\n",
      "(Training) Loss: 991820.2490\n",
      "(Validation) Loss: 1032985.5746, MAE: 3949.1228, R2: 0.1283\n",
      "==========================================================================================\n",
      "Epoch [2732/5000] | Time: 0.30s\n",
      "(Training) Loss: 1002332.8204\n",
      "(Validation) Loss: 1032818.7987, MAE: 3947.2085, R2: 0.1285\n",
      "==========================================================================================\n",
      "Epoch [2733/5000] | Time: 0.27s\n",
      "(Training) Loss: 1007149.4454\n",
      "(Validation) Loss: 1032643.5759, MAE: 3943.5334, R2: 0.1286\n",
      "==========================================================================================\n",
      "Epoch [2734/5000] | Time: 0.29s\n",
      "(Training) Loss: 995659.1878\n",
      "(Validation) Loss: 1032480.8279, MAE: 3945.2488, R2: 0.1288\n",
      "==========================================================================================\n",
      "Epoch [2735/5000] | Time: 0.24s\n",
      "(Training) Loss: 988498.9657\n",
      "(Validation) Loss: 1032310.9994, MAE: 3942.4849, R2: 0.1289\n",
      "==========================================================================================\n",
      "Epoch [2736/5000] | Time: 0.21s\n",
      "(Training) Loss: 1023720.7633\n",
      "(Validation) Loss: 1032155.6470, MAE: 3944.4790, R2: 0.1290\n",
      "==========================================================================================\n",
      "Epoch [2737/5000] | Time: 0.23s\n",
      "(Training) Loss: 991253.2008\n",
      "(Validation) Loss: 1031974.2933, MAE: 3940.6863, R2: 0.1292\n",
      "==========================================================================================\n",
      "Epoch [2738/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004403.1536\n",
      "(Validation) Loss: 1031814.7657, MAE: 3941.2612, R2: 0.1293\n",
      "==========================================================================================\n",
      "Epoch [2739/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008646.1523\n",
      "(Validation) Loss: 1031647.3194, MAE: 3940.2483, R2: 0.1295\n",
      "==========================================================================================\n",
      "Epoch [2740/5000] | Time: 0.24s\n",
      "(Training) Loss: 1001543.8027\n",
      "(Validation) Loss: 1031476.6984, MAE: 3939.1533, R2: 0.1296\n",
      "==========================================================================================\n",
      "Epoch [2741/5000] | Time: 0.24s\n",
      "(Training) Loss: 999758.8820\n",
      "(Validation) Loss: 1031313.2698, MAE: 3938.0425, R2: 0.1297\n",
      "==========================================================================================\n",
      "Epoch [2742/5000] | Time: 0.24s\n",
      "(Training) Loss: 990106.5473\n",
      "(Validation) Loss: 1031146.5905, MAE: 3937.6533, R2: 0.1299\n",
      "==========================================================================================\n",
      "Epoch [2743/5000] | Time: 0.26s\n",
      "(Training) Loss: 993359.6060\n",
      "(Validation) Loss: 1030978.8851, MAE: 3936.4849, R2: 0.1300\n",
      "==========================================================================================\n",
      "Epoch [2744/5000] | Time: 0.24s\n",
      "(Training) Loss: 1016050.7805\n",
      "(Validation) Loss: 1030818.5143, MAE: 3937.4766, R2: 0.1301\n",
      "==========================================================================================\n",
      "Epoch [2745/5000] | Time: 0.29s\n",
      "(Training) Loss: 997951.9848\n",
      "(Validation) Loss: 1030654.9892, MAE: 3939.2039, R2: 0.1303\n",
      "==========================================================================================\n",
      "Epoch [2746/5000] | Time: 0.35s\n",
      "(Training) Loss: 996604.8598\n",
      "(Validation) Loss: 1030488.8025, MAE: 3938.3096, R2: 0.1304\n",
      "==========================================================================================\n",
      "Epoch [2747/5000] | Time: 0.31s\n",
      "(Training) Loss: 996253.1954\n",
      "(Validation) Loss: 1030318.2578, MAE: 3935.3125, R2: 0.1306\n",
      "==========================================================================================\n",
      "Epoch [2748/5000] | Time: 0.28s\n",
      "(Training) Loss: 992433.1539\n",
      "(Validation) Loss: 1030180.7390, MAE: 3944.1248, R2: 0.1307\n",
      "==========================================================================================\n",
      "Epoch [2749/5000] | Time: 0.30s\n",
      "(Training) Loss: 1010126.4074\n",
      "(Validation) Loss: 1033204.3175, MAE: 3948.5474, R2: 0.1282\n",
      "==========================================================================================\n",
      "Epoch [2750/5000] | Time: 0.31s\n",
      "(Training) Loss: 994422.6383\n",
      "(Validation) Loss: 1029821.5213, MAE: 3933.7810, R2: 0.1310\n",
      "==========================================================================================\n",
      "Epoch [2751/5000] | Time: 0.25s\n",
      "(Training) Loss: 990384.5584\n",
      "(Validation) Loss: 1029657.3257, MAE: 3934.4546, R2: 0.1311\n",
      "==========================================================================================\n",
      "Epoch [2752/5000] | Time: 0.26s\n",
      "(Training) Loss: 993558.6942\n",
      "(Validation) Loss: 1029488.8330, MAE: 3932.2307, R2: 0.1313\n",
      "==========================================================================================\n",
      "Epoch [2753/5000] | Time: 0.27s\n",
      "(Training) Loss: 989311.0933\n",
      "(Validation) Loss: 1029332.9524, MAE: 3933.4895, R2: 0.1314\n",
      "==========================================================================================\n",
      "Epoch [2754/5000] | Time: 0.29s\n",
      "(Training) Loss: 985463.2657\n",
      "(Validation) Loss: 1029157.2419, MAE: 3929.9268, R2: 0.1315\n",
      "==========================================================================================\n",
      "Epoch [2755/5000] | Time: 0.27s\n",
      "(Training) Loss: 1005561.4055\n",
      "(Validation) Loss: 1029134.3137, MAE: 3942.7412, R2: 0.1315\n",
      "==========================================================================================\n",
      "Epoch [2756/5000] | Time: 0.28s\n",
      "(Training) Loss: 1004028.2157\n",
      "(Validation) Loss: 1028968.1473, MAE: 3942.7861, R2: 0.1317\n",
      "==========================================================================================\n",
      "Epoch [2757/5000] | Time: 0.28s\n",
      "(Training) Loss: 987323.3807\n",
      "(Validation) Loss: 1028797.8971, MAE: 3941.8562, R2: 0.1318\n",
      "==========================================================================================\n",
      "Epoch [2758/5000] | Time: 0.34s\n",
      "(Training) Loss: 1003201.3598\n",
      "(Validation) Loss: 1028623.3854, MAE: 3937.8572, R2: 0.1320\n",
      "==========================================================================================\n",
      "Epoch [2759/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016899.5971\n",
      "(Validation) Loss: 1028450.5651, MAE: 3935.0393, R2: 0.1321\n",
      "==========================================================================================\n",
      "Epoch [2760/5000] | Time: 0.27s\n",
      "(Training) Loss: 991875.7316\n",
      "(Validation) Loss: 1028291.0984, MAE: 3938.1670, R2: 0.1323\n",
      "==========================================================================================\n",
      "Epoch [2761/5000] | Time: 0.31s\n",
      "(Training) Loss: 996095.5476\n",
      "(Validation) Loss: 1028127.8425, MAE: 3937.0330, R2: 0.1324\n",
      "==========================================================================================\n",
      "Epoch [2762/5000] | Time: 0.32s\n",
      "(Training) Loss: 997691.0590\n",
      "(Validation) Loss: 1027961.8133, MAE: 3937.4788, R2: 0.1325\n",
      "==========================================================================================\n",
      "Epoch [2763/5000] | Time: 0.26s\n",
      "(Training) Loss: 989060.4023\n",
      "(Validation) Loss: 1027786.6463, MAE: 3932.3455, R2: 0.1327\n",
      "==========================================================================================\n",
      "Epoch [2764/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005652.5552\n",
      "(Validation) Loss: 1027620.0381, MAE: 3932.2134, R2: 0.1328\n",
      "==========================================================================================\n",
      "Epoch [2765/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000560.1701\n",
      "(Validation) Loss: 1027462.3137, MAE: 3933.7593, R2: 0.1329\n",
      "==========================================================================================\n",
      "Epoch [2766/5000] | Time: 0.23s\n",
      "(Training) Loss: 997480.3249\n",
      "(Validation) Loss: 1027294.9384, MAE: 3933.5247, R2: 0.1331\n",
      "==========================================================================================\n",
      "Epoch [2767/5000] | Time: 0.28s\n",
      "(Training) Loss: 990151.6034\n",
      "(Validation) Loss: 1027122.3111, MAE: 3930.3433, R2: 0.1332\n",
      "==========================================================================================\n",
      "Epoch [2768/5000] | Time: 0.31s\n",
      "(Training) Loss: 1005556.4645\n",
      "(Validation) Loss: 1026957.1302, MAE: 3929.2524, R2: 0.1334\n",
      "==========================================================================================\n",
      "Epoch [2769/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001463.3084\n",
      "(Validation) Loss: 1026793.7117, MAE: 3930.9502, R2: 0.1335\n",
      "==========================================================================================\n",
      "Epoch [2770/5000] | Time: 0.28s\n",
      "(Training) Loss: 990668.5596\n",
      "(Validation) Loss: 1026620.8356, MAE: 3928.4385, R2: 0.1336\n",
      "==========================================================================================\n",
      "Epoch [2771/5000] | Time: 0.29s\n",
      "(Training) Loss: 989710.8636\n",
      "(Validation) Loss: 1026464.2083, MAE: 3930.0032, R2: 0.1338\n",
      "==========================================================================================\n",
      "Epoch [2772/5000] | Time: 0.28s\n",
      "(Training) Loss: 996482.4734\n",
      "(Validation) Loss: 1026304.3098, MAE: 3930.5815, R2: 0.1339\n",
      "==========================================================================================\n",
      "Epoch [2773/5000] | Time: 0.30s\n",
      "(Training) Loss: 1013221.0051\n",
      "(Validation) Loss: 1026129.5187, MAE: 3927.2388, R2: 0.1341\n",
      "==========================================================================================\n",
      "Epoch [2774/5000] | Time: 0.35s\n",
      "(Training) Loss: 987961.0622\n",
      "(Validation) Loss: 1025965.4349, MAE: 3928.2803, R2: 0.1342\n",
      "==========================================================================================\n",
      "Epoch [2775/5000] | Time: 0.25s\n",
      "(Training) Loss: 992165.3319\n",
      "(Validation) Loss: 1025693.3333, MAE: 3923.9331, R2: 0.1344\n",
      "==========================================================================================\n",
      "Epoch [2776/5000] | Time: 0.27s\n",
      "(Training) Loss: 986120.1364\n",
      "(Validation) Loss: 1025524.2819, MAE: 3920.0579, R2: 0.1346\n",
      "==========================================================================================\n",
      "Epoch [2777/5000] | Time: 0.26s\n",
      "(Training) Loss: 983074.8504\n",
      "(Validation) Loss: 1025366.5879, MAE: 3923.6013, R2: 0.1347\n",
      "==========================================================================================\n",
      "Epoch [2778/5000] | Time: 0.28s\n",
      "(Training) Loss: 998122.5977\n",
      "(Validation) Loss: 1025247.4870, MAE: 3922.3108, R2: 0.1348\n",
      "==========================================================================================\n",
      "Epoch [2779/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002933.4010\n",
      "(Validation) Loss: 1025138.3721, MAE: 3924.2197, R2: 0.1349\n",
      "==========================================================================================\n",
      "Epoch [2780/5000] | Time: 0.22s\n",
      "(Training) Loss: 991934.5622\n",
      "(Validation) Loss: 1024972.3479, MAE: 3923.9512, R2: 0.1350\n",
      "==========================================================================================\n",
      "Epoch [2781/5000] | Time: 0.22s\n",
      "(Training) Loss: 1006207.2392\n",
      "(Validation) Loss: 1024809.4070, MAE: 3923.5864, R2: 0.1352\n",
      "==========================================================================================\n",
      "Epoch [2782/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016511.9683\n",
      "(Validation) Loss: 1024639.9137, MAE: 3922.0647, R2: 0.1353\n",
      "==========================================================================================\n",
      "Epoch [2783/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001992.9448\n",
      "(Validation) Loss: 1024472.9194, MAE: 3920.8569, R2: 0.1354\n",
      "==========================================================================================\n",
      "Epoch [2784/5000] | Time: 0.29s\n",
      "(Training) Loss: 1009387.5863\n",
      "(Validation) Loss: 1024307.4286, MAE: 3921.5527, R2: 0.1356\n",
      "==========================================================================================\n",
      "Epoch [2785/5000] | Time: 0.29s\n",
      "(Training) Loss: 986816.0479\n",
      "(Validation) Loss: 1024141.7854, MAE: 3921.1755, R2: 0.1357\n",
      "==========================================================================================\n",
      "Epoch [2786/5000] | Time: 0.28s\n",
      "(Training) Loss: 999769.4048\n",
      "(Validation) Loss: 1023976.6502, MAE: 3919.5764, R2: 0.1358\n",
      "==========================================================================================\n",
      "Epoch [2787/5000] | Time: 0.35s\n",
      "(Training) Loss: 994026.4391\n",
      "(Validation) Loss: 1023813.4502, MAE: 3919.9409, R2: 0.1360\n",
      "==========================================================================================\n",
      "Epoch [2788/5000] | Time: 0.32s\n",
      "(Training) Loss: 996420.1180\n",
      "(Validation) Loss: 1023647.3346, MAE: 3919.5593, R2: 0.1361\n",
      "==========================================================================================\n",
      "Epoch [2789/5000] | Time: 0.35s\n",
      "(Training) Loss: 990014.4277\n",
      "(Validation) Loss: 1023477.0083, MAE: 3917.4089, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [2790/5000] | Time: 0.30s\n",
      "(Training) Loss: 985318.0305\n",
      "(Validation) Loss: 1023312.3860, MAE: 3916.5149, R2: 0.1364\n",
      "==========================================================================================\n",
      "Epoch [2791/5000] | Time: 0.31s\n",
      "(Training) Loss: 996424.2056\n",
      "(Validation) Loss: 1023149.6533, MAE: 3916.7324, R2: 0.1365\n",
      "==========================================================================================\n",
      "Epoch [2792/5000] | Time: 0.35s\n",
      "(Training) Loss: 1010230.7652\n",
      "(Validation) Loss: 1022988.3683, MAE: 3916.1133, R2: 0.1367\n",
      "==========================================================================================\n",
      "Epoch [2793/5000] | Time: 0.26s\n",
      "(Training) Loss: 1002328.4968\n",
      "(Validation) Loss: 1022827.4946, MAE: 3916.8132, R2: 0.1368\n",
      "==========================================================================================\n",
      "Epoch [2794/5000] | Time: 0.26s\n",
      "(Training) Loss: 993248.2030\n",
      "(Validation) Loss: 1022659.2000, MAE: 3916.5857, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [2795/5000] | Time: 0.28s\n",
      "(Training) Loss: 991646.7602\n",
      "(Validation) Loss: 1022488.2337, MAE: 3915.7920, R2: 0.1371\n",
      "==========================================================================================\n",
      "Epoch [2796/5000] | Time: 0.25s\n",
      "(Training) Loss: 987974.4308\n",
      "(Validation) Loss: 1022326.8470, MAE: 3914.5908, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [2797/5000] | Time: 0.29s\n",
      "(Training) Loss: 994877.7113\n",
      "(Validation) Loss: 1022161.4375, MAE: 3914.0508, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [2798/5000] | Time: 0.25s\n",
      "(Training) Loss: 1003974.9524\n",
      "(Validation) Loss: 1021994.3975, MAE: 3911.7632, R2: 0.1375\n",
      "==========================================================================================\n",
      "Epoch [2799/5000] | Time: 0.31s\n",
      "(Training) Loss: 981450.4312\n",
      "(Validation) Loss: 1021833.4578, MAE: 3913.0359, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [2800/5000] | Time: 0.31s\n",
      "(Training) Loss: 982242.3940\n",
      "(Validation) Loss: 1021669.2927, MAE: 3912.3184, R2: 0.1378\n",
      "==========================================================================================\n",
      "Epoch [2801/5000] | Time: 0.29s\n",
      "(Training) Loss: 993478.4346\n",
      "(Validation) Loss: 1021533.8768, MAE: 3917.7048, R2: 0.1379\n",
      "==========================================================================================\n",
      "Epoch [2802/5000] | Time: 0.25s\n",
      "(Training) Loss: 991957.8953\n",
      "(Validation) Loss: 1021346.1740, MAE: 3913.3936, R2: 0.1380\n",
      "==========================================================================================\n",
      "Epoch [2803/5000] | Time: 0.39s\n",
      "(Training) Loss: 989109.4074\n",
      "(Validation) Loss: 1021200.2133, MAE: 3916.5454, R2: 0.1382\n",
      "==========================================================================================\n",
      "Epoch [2804/5000] | Time: 0.51s\n",
      "(Training) Loss: 984583.4010\n",
      "(Validation) Loss: 1021014.5473, MAE: 3910.5430, R2: 0.1383\n",
      "==========================================================================================\n",
      "Epoch [2805/5000] | Time: 0.30s\n",
      "(Training) Loss: 1013114.1129\n",
      "(Validation) Loss: 1020843.8197, MAE: 3909.9775, R2: 0.1385\n",
      "==========================================================================================\n",
      "Epoch [2806/5000] | Time: 0.26s\n",
      "(Training) Loss: 991008.3166\n",
      "(Validation) Loss: 1020684.6629, MAE: 3909.5791, R2: 0.1386\n",
      "==========================================================================================\n",
      "Epoch [2807/5000] | Time: 0.23s\n",
      "(Training) Loss: 987201.3864\n",
      "(Validation) Loss: 1020521.0921, MAE: 3908.5422, R2: 0.1387\n",
      "==========================================================================================\n",
      "Epoch [2808/5000] | Time: 0.24s\n",
      "(Training) Loss: 997296.1193\n",
      "(Validation) Loss: 1020357.3283, MAE: 3909.4023, R2: 0.1389\n",
      "==========================================================================================\n",
      "Epoch [2809/5000] | Time: 0.25s\n",
      "(Training) Loss: 998522.9816\n",
      "(Validation) Loss: 1020190.8978, MAE: 3907.8201, R2: 0.1390\n",
      "==========================================================================================\n",
      "Epoch [2810/5000] | Time: 0.35s\n",
      "(Training) Loss: 1021735.5070\n",
      "(Validation) Loss: 1020022.1410, MAE: 3905.7646, R2: 0.1391\n",
      "==========================================================================================\n",
      "Epoch [2811/5000] | Time: 0.25s\n",
      "(Training) Loss: 1009574.8185\n",
      "(Validation) Loss: 1019853.9886, MAE: 3904.0266, R2: 0.1393\n",
      "==========================================================================================\n",
      "Epoch [2812/5000] | Time: 0.28s\n",
      "(Training) Loss: 989593.0162\n",
      "(Validation) Loss: 1019695.8324, MAE: 3905.5437, R2: 0.1394\n",
      "==========================================================================================\n",
      "Epoch [2813/5000] | Time: 0.28s\n",
      "(Training) Loss: 1000157.5698\n",
      "(Validation) Loss: 1019524.6070, MAE: 3903.8918, R2: 0.1396\n",
      "==========================================================================================\n",
      "Epoch [2814/5000] | Time: 0.29s\n",
      "(Training) Loss: 987214.0571\n",
      "(Validation) Loss: 1019359.4819, MAE: 3902.5461, R2: 0.1397\n",
      "==========================================================================================\n",
      "Epoch [2815/5000] | Time: 0.28s\n",
      "(Training) Loss: 980595.7519\n",
      "(Validation) Loss: 1019198.6286, MAE: 3903.6267, R2: 0.1398\n",
      "==========================================================================================\n",
      "Epoch [2816/5000] | Time: 0.37s\n",
      "(Training) Loss: 985042.4327\n",
      "(Validation) Loss: 1019042.9054, MAE: 3906.2593, R2: 0.1400\n",
      "==========================================================================================\n",
      "Epoch [2817/5000] | Time: 0.36s\n",
      "(Training) Loss: 979530.6136\n",
      "(Validation) Loss: 1018872.3454, MAE: 3902.1838, R2: 0.1401\n",
      "==========================================================================================\n",
      "Epoch [2818/5000] | Time: 0.32s\n",
      "(Training) Loss: 980279.5926\n",
      "(Validation) Loss: 1018716.3479, MAE: 3904.5056, R2: 0.1402\n",
      "==========================================================================================\n",
      "Epoch [2819/5000] | Time: 0.61s\n",
      "(Training) Loss: 979782.7538\n",
      "(Validation) Loss: 1018552.9549, MAE: 3902.8765, R2: 0.1404\n",
      "==========================================================================================\n",
      "Epoch [2820/5000] | Time: 0.96s\n",
      "(Training) Loss: 986419.9930\n",
      "(Validation) Loss: 1018287.2483, MAE: 3896.9431, R2: 0.1406\n",
      "==========================================================================================\n",
      "Epoch [2821/5000] | Time: 0.97s\n",
      "(Training) Loss: 988614.2614\n",
      "(Validation) Loss: 1018124.6629, MAE: 3897.5076, R2: 0.1407\n",
      "==========================================================================================\n",
      "Epoch [2822/5000] | Time: 0.89s\n",
      "(Training) Loss: 1007685.1904\n",
      "(Validation) Loss: 1017952.8635, MAE: 3892.4143, R2: 0.1409\n",
      "==========================================================================================\n",
      "Epoch [2823/5000] | Time: 0.78s\n",
      "(Training) Loss: 988455.8547\n",
      "(Validation) Loss: 1017712.2590, MAE: 3887.2432, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [2824/5000] | Time: 0.96s\n",
      "(Training) Loss: 975489.3839\n",
      "(Validation) Loss: 1017731.4032, MAE: 3898.2061, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [2825/5000] | Time: 0.98s\n",
      "(Training) Loss: 976846.0292\n",
      "(Validation) Loss: 1017567.1060, MAE: 3897.2483, R2: 0.1412\n",
      "==========================================================================================\n",
      "Epoch [2826/5000] | Time: 1.03s\n",
      "(Training) Loss: 985417.5114\n",
      "(Validation) Loss: 1017407.7714, MAE: 3897.2915, R2: 0.1413\n",
      "==========================================================================================\n",
      "Epoch [2827/5000] | Time: 0.88s\n",
      "(Training) Loss: 987018.3788\n",
      "(Validation) Loss: 1017244.5105, MAE: 3897.3691, R2: 0.1415\n",
      "==========================================================================================\n",
      "Epoch [2828/5000] | Time: 0.84s\n",
      "(Training) Loss: 991570.1662\n",
      "(Validation) Loss: 1017079.6749, MAE: 3895.6826, R2: 0.1416\n",
      "==========================================================================================\n",
      "Epoch [2829/5000] | Time: 0.83s\n",
      "(Training) Loss: 974743.8204\n",
      "(Validation) Loss: 1016915.7181, MAE: 3895.1628, R2: 0.1417\n",
      "==========================================================================================\n",
      "Epoch [2830/5000] | Time: 0.47s\n",
      "(Training) Loss: 997813.6935\n",
      "(Validation) Loss: 1016753.3206, MAE: 3894.5918, R2: 0.1419\n",
      "==========================================================================================\n",
      "Epoch [2831/5000] | Time: 0.33s\n",
      "(Training) Loss: 981658.4797\n",
      "(Validation) Loss: 1016583.3448, MAE: 3892.8655, R2: 0.1420\n",
      "==========================================================================================\n",
      "Epoch [2832/5000] | Time: 0.31s\n",
      "(Training) Loss: 976313.2589\n",
      "(Validation) Loss: 1016425.7524, MAE: 3893.5627, R2: 0.1421\n",
      "==========================================================================================\n",
      "Epoch [2833/5000] | Time: 0.28s\n",
      "(Training) Loss: 981506.9702\n",
      "(Validation) Loss: 1016265.9302, MAE: 3893.6504, R2: 0.1423\n",
      "==========================================================================================\n",
      "Epoch [2834/5000] | Time: 0.88s\n",
      "(Training) Loss: 977980.6263\n",
      "(Validation) Loss: 1016103.9390, MAE: 3893.7957, R2: 0.1424\n",
      "==========================================================================================\n",
      "Epoch [2835/5000] | Time: 0.77s\n",
      "(Training) Loss: 985042.0457\n",
      "(Validation) Loss: 1015935.9797, MAE: 3891.4155, R2: 0.1425\n",
      "==========================================================================================\n",
      "Epoch [2836/5000] | Time: 0.90s\n",
      "(Training) Loss: 987216.9016\n",
      "(Validation) Loss: 1015776.1219, MAE: 3891.8845, R2: 0.1427\n",
      "==========================================================================================\n",
      "Epoch [2837/5000] | Time: 0.82s\n",
      "(Training) Loss: 983675.7703\n",
      "(Validation) Loss: 1015618.1689, MAE: 3892.4734, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [2838/5000] | Time: 0.38s\n",
      "(Training) Loss: 980778.8198\n",
      "(Validation) Loss: 1015447.2686, MAE: 3891.1299, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [2839/5000] | Time: 0.33s\n",
      "(Training) Loss: 978178.4410\n",
      "(Validation) Loss: 1015293.3130, MAE: 3892.6597, R2: 0.1431\n",
      "==========================================================================================\n",
      "Epoch [2840/5000] | Time: 0.34s\n",
      "(Training) Loss: 986152.9296\n",
      "(Validation) Loss: 1015120.3657, MAE: 3888.8965, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [2841/5000] | Time: 0.27s\n",
      "(Training) Loss: 979660.8858\n",
      "(Validation) Loss: 1014958.2273, MAE: 3889.6226, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [2842/5000] | Time: 0.27s\n",
      "(Training) Loss: 1010719.9270\n",
      "(Validation) Loss: 1014793.9048, MAE: 3888.1128, R2: 0.1435\n",
      "==========================================================================================\n",
      "Epoch [2843/5000] | Time: 0.25s\n",
      "(Training) Loss: 991600.1536\n",
      "(Validation) Loss: 1014627.5251, MAE: 3887.8594, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [2844/5000] | Time: 0.25s\n",
      "(Training) Loss: 981617.8553\n",
      "(Validation) Loss: 1014463.4006, MAE: 3887.7759, R2: 0.1438\n",
      "==========================================================================================\n",
      "Epoch [2845/5000] | Time: 0.29s\n",
      "(Training) Loss: 994112.0165\n",
      "(Validation) Loss: 1014297.2902, MAE: 3885.5874, R2: 0.1439\n",
      "==========================================================================================\n",
      "Epoch [2846/5000] | Time: 0.25s\n",
      "(Training) Loss: 996069.8709\n",
      "(Validation) Loss: 1014140.5308, MAE: 3886.4155, R2: 0.1440\n",
      "==========================================================================================\n",
      "Epoch [2847/5000] | Time: 0.30s\n",
      "(Training) Loss: 992155.7640\n",
      "(Validation) Loss: 1013971.0832, MAE: 3884.8955, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [2848/5000] | Time: 0.31s\n",
      "(Training) Loss: 988332.6405\n",
      "(Validation) Loss: 1013809.1429, MAE: 3884.9358, R2: 0.1443\n",
      "==========================================================================================\n",
      "Epoch [2849/5000] | Time: 0.26s\n",
      "(Training) Loss: 989744.1954\n",
      "(Validation) Loss: 1013644.3429, MAE: 3884.0000, R2: 0.1445\n",
      "==========================================================================================\n",
      "Epoch [2850/5000] | Time: 0.26s\n",
      "(Training) Loss: 988065.4569\n",
      "(Validation) Loss: 1008665.4730, MAE: 3866.8635, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [2851/5000] | Time: 0.29s\n",
      "(Training) Loss: 980637.5470\n",
      "(Validation) Loss: 1008489.1987, MAE: 3865.2498, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [2852/5000] | Time: 0.33s\n",
      "(Training) Loss: 965784.6557\n",
      "(Validation) Loss: 1008309.4959, MAE: 3861.7612, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [2853/5000] | Time: 0.29s\n",
      "(Training) Loss: 969026.9987\n",
      "(Validation) Loss: 1008158.6540, MAE: 3867.2163, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [2854/5000] | Time: 0.30s\n",
      "(Training) Loss: 979332.2621\n",
      "(Validation) Loss: 1007982.6844, MAE: 3863.5769, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [2855/5000] | Time: 0.30s\n",
      "(Training) Loss: 965166.1193\n",
      "(Validation) Loss: 1007815.7816, MAE: 3863.6082, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [2856/5000] | Time: 0.26s\n",
      "(Training) Loss: 991242.4708\n",
      "(Validation) Loss: 1007642.8394, MAE: 3859.9238, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [2857/5000] | Time: 0.27s\n",
      "(Training) Loss: 971902.7272\n",
      "(Validation) Loss: 1007475.1543, MAE: 3860.4695, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [2858/5000] | Time: 0.31s\n",
      "(Training) Loss: 974587.5577\n",
      "(Validation) Loss: 1007312.3149, MAE: 3860.2463, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [2859/5000] | Time: 0.25s\n",
      "(Training) Loss: 966971.9829\n",
      "(Validation) Loss: 1007152.1524, MAE: 3861.9426, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [2860/5000] | Time: 0.38s\n",
      "(Training) Loss: 978553.4664\n",
      "(Validation) Loss: 1006979.7892, MAE: 3858.4023, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [2861/5000] | Time: 0.39s\n",
      "(Training) Loss: 971724.6263\n",
      "(Validation) Loss: 1006808.2337, MAE: 3856.8308, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [2862/5000] | Time: 0.26s\n",
      "(Training) Loss: 986828.5761\n",
      "(Validation) Loss: 1006652.6375, MAE: 3860.0317, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [2863/5000] | Time: 0.26s\n",
      "(Training) Loss: 978493.9175\n",
      "(Validation) Loss: 1006476.3632, MAE: 3855.4380, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [2864/5000] | Time: 0.28s\n",
      "(Training) Loss: 985434.4334\n",
      "(Validation) Loss: 1006311.8629, MAE: 3856.2908, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [2865/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001434.0819\n",
      "(Validation) Loss: 1006146.6006, MAE: 3855.2444, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [2866/5000] | Time: 0.26s\n",
      "(Training) Loss: 973363.9848\n",
      "(Validation) Loss: 1005978.1435, MAE: 3854.8276, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [2867/5000] | Time: 0.24s\n",
      "(Training) Loss: 965835.5514\n",
      "(Validation) Loss: 998188.8813, MAE: 3831.7063, R2: 0.1573\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2868/5000] | Time: 0.27s\n",
      "(Training) Loss: 964501.7589\n",
      "(Validation) Loss: 998026.8902, MAE: 3828.3550, R2: 0.1575\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2869/5000] | Time: 0.45s\n",
      "(Training) Loss: 956905.4521\n",
      "(Validation) Loss: 997872.9854, MAE: 3828.2854, R2: 0.1576\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2870/5000] | Time: 0.34s\n",
      "(Training) Loss: 964326.5787\n",
      "(Validation) Loss: 997710.9689, MAE: 3827.5081, R2: 0.1577\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2871/5000] | Time: 0.25s\n",
      "(Training) Loss: 966875.8509\n",
      "(Validation) Loss: 997551.0502, MAE: 3826.0029, R2: 0.1579\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2872/5000] | Time: 0.31s\n",
      "(Training) Loss: 956152.3026\n",
      "(Validation) Loss: 997401.5086, MAE: 3827.1038, R2: 0.1580\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2873/5000] | Time: 0.27s\n",
      "(Training) Loss: 982835.0324\n",
      "(Validation) Loss: 997240.1473, MAE: 3825.3088, R2: 0.1581\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2874/5000] | Time: 0.34s\n",
      "(Training) Loss: 976965.7081\n",
      "(Validation) Loss: 997075.4489, MAE: 3823.9802, R2: 0.1583\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2875/5000] | Time: 0.26s\n",
      "(Training) Loss: 980464.5926\n",
      "(Validation) Loss: 996916.7340, MAE: 3823.4194, R2: 0.1584\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2876/5000] | Time: 0.29s\n",
      "(Training) Loss: 959231.6808\n",
      "(Validation) Loss: 996770.5905, MAE: 3825.7502, R2: 0.1585\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2877/5000] | Time: 0.28s\n",
      "(Training) Loss: 981548.8940\n",
      "(Validation) Loss: 996596.8813, MAE: 3820.6406, R2: 0.1587\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2878/5000] | Time: 0.26s\n",
      "(Training) Loss: 972455.9524\n",
      "(Validation) Loss: 996433.6152, MAE: 3819.7227, R2: 0.1588\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2879/5000] | Time: 0.29s\n",
      "(Training) Loss: 968421.8680\n",
      "(Validation) Loss: 996279.4717, MAE: 3821.0103, R2: 0.1589\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2880/5000] | Time: 0.33s\n",
      "(Training) Loss: 955729.6701\n",
      "(Validation) Loss: 996117.9784, MAE: 3819.4331, R2: 0.1591\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2881/5000] | Time: 0.25s\n",
      "(Training) Loss: 960133.0057\n",
      "(Validation) Loss: 995960.8686, MAE: 3818.9172, R2: 0.1592\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2882/5000] | Time: 0.26s\n",
      "(Training) Loss: 961027.6466\n",
      "(Validation) Loss: 995800.1219, MAE: 3817.2869, R2: 0.1593\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2883/5000] | Time: 0.26s\n",
      "(Training) Loss: 964159.0457\n",
      "(Validation) Loss: 995642.5194, MAE: 3818.1558, R2: 0.1595\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2884/5000] | Time: 0.31s\n",
      "(Training) Loss: 960775.2049\n",
      "(Validation) Loss: 995413.6381, MAE: 3814.5955, R2: 0.1597\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2885/5000] | Time: 0.29s\n",
      "(Training) Loss: 955891.0225\n",
      "(Validation) Loss: 995258.5346, MAE: 3814.9504, R2: 0.1598\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2886/5000] | Time: 0.42s\n",
      "(Training) Loss: 964096.6028\n",
      "(Validation) Loss: 995091.4794, MAE: 3811.4780, R2: 0.1599\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2887/5000] | Time: 0.28s\n",
      "(Training) Loss: 960660.0717\n",
      "(Validation) Loss: 994934.2324, MAE: 3810.5615, R2: 0.1601\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2888/5000] | Time: 0.26s\n",
      "(Training) Loss: 955877.8087\n",
      "(Validation) Loss: 994769.5797, MAE: 3808.9355, R2: 0.1602\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2889/5000] | Time: 0.26s\n",
      "(Training) Loss: 977742.7989\n",
      "(Validation) Loss: 994610.6768, MAE: 3807.8247, R2: 0.1603\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2890/5000] | Time: 0.26s\n",
      "(Training) Loss: 960371.0742\n",
      "(Validation) Loss: 994456.2133, MAE: 3809.0525, R2: 0.1605\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2891/5000] | Time: 0.26s\n",
      "(Training) Loss: 955607.4743\n",
      "(Validation) Loss: 994297.2952, MAE: 3808.7493, R2: 0.1606\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2892/5000] | Time: 0.28s\n",
      "(Training) Loss: 967706.0089\n",
      "(Validation) Loss: 994137.8692, MAE: 3807.4526, R2: 0.1607\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2893/5000] | Time: 0.30s\n",
      "(Training) Loss: 956681.9892\n",
      "(Validation) Loss: 993976.6349, MAE: 3806.2847, R2: 0.1609\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2894/5000] | Time: 0.26s\n",
      "(Training) Loss: 955113.1313\n",
      "(Validation) Loss: 993818.8749, MAE: 3806.4229, R2: 0.1610\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2895/5000] | Time: 0.33s\n",
      "(Training) Loss: 953582.5485\n",
      "(Validation) Loss: 993677.8971, MAE: 3809.8000, R2: 0.1611\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2896/5000] | Time: 0.28s\n",
      "(Training) Loss: 962856.1916\n",
      "(Validation) Loss: 993524.5156, MAE: 3807.1033, R2: 0.1612\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2897/5000] | Time: 0.28s\n",
      "(Training) Loss: 955999.3801\n",
      "(Validation) Loss: 993349.5314, MAE: 3805.2686, R2: 0.1614\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2898/5000] | Time: 0.29s\n",
      "(Training) Loss: 975462.4283\n",
      "(Validation) Loss: 993186.0317, MAE: 3803.9863, R2: 0.1615\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2899/5000] | Time: 0.26s\n",
      "(Training) Loss: 963284.7443\n",
      "(Validation) Loss: 993031.1975, MAE: 3804.9324, R2: 0.1616\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2900/5000] | Time: 0.30s\n",
      "(Training) Loss: 980643.1567\n",
      "(Validation) Loss: 992864.1117, MAE: 3801.8074, R2: 0.1618\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2901/5000] | Time: 0.29s\n",
      "(Training) Loss: 964487.9137\n",
      "(Validation) Loss: 992709.7143, MAE: 3802.3096, R2: 0.1619\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2902/5000] | Time: 0.30s\n",
      "(Training) Loss: 951270.8125\n",
      "(Validation) Loss: 992540.3835, MAE: 3799.6216, R2: 0.1621\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2903/5000] | Time: 0.32s\n",
      "(Training) Loss: 975349.9949\n",
      "(Validation) Loss: 992387.3727, MAE: 3799.5212, R2: 0.1622\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2904/5000] | Time: 0.27s\n",
      "(Training) Loss: 1000682.9232\n",
      "(Validation) Loss: 992241.8184, MAE: 3802.9409, R2: 0.1623\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2905/5000] | Time: 0.27s\n",
      "(Training) Loss: 975908.2373\n",
      "(Validation) Loss: 992064.2844, MAE: 3798.8191, R2: 0.1625\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2906/5000] | Time: 0.28s\n",
      "(Training) Loss: 968657.8452\n",
      "(Validation) Loss: 991904.5943, MAE: 3798.7661, R2: 0.1626\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2907/5000] | Time: 0.30s\n",
      "(Training) Loss: 962175.4898\n",
      "(Validation) Loss: 991745.4679, MAE: 3797.9993, R2: 0.1627\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2908/5000] | Time: 0.27s\n",
      "(Training) Loss: 971525.4956\n",
      "(Validation) Loss: 991588.6222, MAE: 3798.3022, R2: 0.1628\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2909/5000] | Time: 0.26s\n",
      "(Training) Loss: 953663.4388\n",
      "(Validation) Loss: 991427.6470, MAE: 3797.4897, R2: 0.1630\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2910/5000] | Time: 0.25s\n",
      "(Training) Loss: 973136.8807\n",
      "(Validation) Loss: 991276.9067, MAE: 3798.0452, R2: 0.1631\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2911/5000] | Time: 0.27s\n",
      "(Training) Loss: 950406.5995\n",
      "(Validation) Loss: 991107.3676, MAE: 3794.3845, R2: 0.1632\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2912/5000] | Time: 0.27s\n",
      "(Training) Loss: 960161.4797\n",
      "(Validation) Loss: 990955.8756, MAE: 3795.3677, R2: 0.1634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2913/5000] | Time: 0.24s\n",
      "(Training) Loss: 955400.7912\n",
      "(Validation) Loss: 990816.9803, MAE: 3796.2949, R2: 0.1635\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2914/5000] | Time: 0.23s\n",
      "(Training) Loss: 953219.1485\n",
      "(Validation) Loss: 990695.1314, MAE: 3808.8298, R2: 0.1636\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2915/5000] | Time: 0.28s\n",
      "(Training) Loss: 950194.5363\n",
      "(Validation) Loss: 999327.1517, MAE: 3829.4060, R2: 0.1564\n",
      "==========================================================================================\n",
      "Epoch [2916/5000] | Time: 0.25s\n",
      "(Training) Loss: 984748.8204\n",
      "(Validation) Loss: 999169.0057, MAE: 3827.4268, R2: 0.1565\n",
      "==========================================================================================\n",
      "Epoch [2917/5000] | Time: 0.26s\n",
      "(Training) Loss: 976739.7963\n",
      "(Validation) Loss: 999004.7695, MAE: 3825.4663, R2: 0.1567\n",
      "==========================================================================================\n",
      "Epoch [2918/5000] | Time: 0.27s\n",
      "(Training) Loss: 973926.4810\n",
      "(Validation) Loss: 998844.0584, MAE: 3823.7031, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [2919/5000] | Time: 0.25s\n",
      "(Training) Loss: 997841.2253\n",
      "(Validation) Loss: 998683.8095, MAE: 3822.8750, R2: 0.1569\n",
      "==========================================================================================\n",
      "Epoch [2920/5000] | Time: 0.22s\n",
      "(Training) Loss: 962264.9575\n",
      "(Validation) Loss: 998525.1505, MAE: 3822.7397, R2: 0.1571\n",
      "==========================================================================================\n",
      "Epoch [2921/5000] | Time: 0.26s\n",
      "(Training) Loss: 972459.6180\n",
      "(Validation) Loss: 998367.5022, MAE: 3822.0176, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [2922/5000] | Time: 0.25s\n",
      "(Training) Loss: 979811.4645\n",
      "(Validation) Loss: 1003147.7638, MAE: 3839.2412, R2: 0.1532\n",
      "==========================================================================================\n",
      "Epoch [2923/5000] | Time: 0.24s\n",
      "(Training) Loss: 958155.6424\n",
      "(Validation) Loss: 998048.3454, MAE: 3820.6362, R2: 0.1575\n",
      "==========================================================================================\n",
      "Epoch [2924/5000] | Time: 0.27s\n",
      "(Training) Loss: 970883.0152\n",
      "(Validation) Loss: 997889.8540, MAE: 3819.4956, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [2925/5000] | Time: 0.27s\n",
      "(Training) Loss: 992547.7881\n",
      "(Validation) Loss: 997737.8946, MAE: 3820.4314, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [2926/5000] | Time: 0.26s\n",
      "(Training) Loss: 975589.0102\n",
      "(Validation) Loss: 997576.0762, MAE: 3819.4431, R2: 0.1579\n",
      "==========================================================================================\n",
      "Epoch [2927/5000] | Time: 0.29s\n",
      "(Training) Loss: 984467.5343\n",
      "(Validation) Loss: 997417.1733, MAE: 3818.3406, R2: 0.1580\n",
      "==========================================================================================\n",
      "Epoch [2928/5000] | Time: 0.25s\n",
      "(Training) Loss: 979842.8109\n",
      "(Validation) Loss: 997264.4063, MAE: 3819.6575, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [2929/5000] | Time: 0.24s\n",
      "(Training) Loss: 958045.3671\n",
      "(Validation) Loss: 997132.7543, MAE: 3827.7747, R2: 0.1582\n",
      "==========================================================================================\n",
      "Epoch [2930/5000] | Time: 0.25s\n",
      "(Training) Loss: 967055.3249\n",
      "(Validation) Loss: 996942.4457, MAE: 3816.6685, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [2931/5000] | Time: 0.28s\n",
      "(Training) Loss: 970375.3706\n",
      "(Validation) Loss: 996805.7244, MAE: 3821.4785, R2: 0.1585\n",
      "==========================================================================================\n",
      "Epoch [2932/5000] | Time: 0.26s\n",
      "(Training) Loss: 957038.4492\n",
      "(Validation) Loss: 996625.0565, MAE: 3815.6489, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [2933/5000] | Time: 0.27s\n",
      "(Training) Loss: 956466.4925\n",
      "(Validation) Loss: 996469.1098, MAE: 3814.9023, R2: 0.1588\n",
      "==========================================================================================\n",
      "Epoch [2934/5000] | Time: 0.28s\n",
      "(Training) Loss: 969066.5609\n",
      "(Validation) Loss: 996317.0133, MAE: 3814.9407, R2: 0.1589\n",
      "==========================================================================================\n",
      "Epoch [2935/5000] | Time: 0.25s\n",
      "(Training) Loss: 967384.9759\n",
      "(Validation) Loss: 996162.3111, MAE: 3815.5391, R2: 0.1590\n",
      "==========================================================================================\n",
      "Epoch [2936/5000] | Time: 0.30s\n",
      "(Training) Loss: 981638.1415\n",
      "(Validation) Loss: 995999.9746, MAE: 3813.8818, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [2937/5000] | Time: 0.30s\n",
      "(Training) Loss: 977103.5095\n",
      "(Validation) Loss: 995843.8705, MAE: 3813.3191, R2: 0.1593\n",
      "==========================================================================================\n",
      "Epoch [2938/5000] | Time: 0.27s\n",
      "(Training) Loss: 971620.3261\n",
      "(Validation) Loss: 995681.7727, MAE: 3811.7588, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [2939/5000] | Time: 0.29s\n",
      "(Training) Loss: 978981.5508\n",
      "(Validation) Loss: 995527.9898, MAE: 3812.2026, R2: 0.1596\n",
      "==========================================================================================\n",
      "Epoch [2940/5000] | Time: 0.25s\n",
      "(Training) Loss: 972534.9873\n",
      "(Validation) Loss: 995368.9498, MAE: 3811.8088, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [2941/5000] | Time: 0.29s\n",
      "(Training) Loss: 963998.8306\n",
      "(Validation) Loss: 995211.7130, MAE: 3811.6985, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [2942/5000] | Time: 0.27s\n",
      "(Training) Loss: 954991.0917\n",
      "(Validation) Loss: 995056.2743, MAE: 3811.4524, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [2943/5000] | Time: 0.29s\n",
      "(Training) Loss: 972171.8458\n",
      "(Validation) Loss: 994900.7137, MAE: 3810.4578, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [2944/5000] | Time: 0.25s\n",
      "(Training) Loss: 954832.1279\n",
      "(Validation) Loss: 994758.0851, MAE: 3809.8069, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [2945/5000] | Time: 0.29s\n",
      "(Training) Loss: 956004.5990\n",
      "(Validation) Loss: 994585.2597, MAE: 3808.7026, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [2946/5000] | Time: 0.31s\n",
      "(Training) Loss: 975859.3756\n",
      "(Validation) Loss: 994428.9930, MAE: 3807.5706, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [2947/5000] | Time: 0.29s\n",
      "(Training) Loss: 963729.6034\n",
      "(Validation) Loss: 994278.9943, MAE: 3809.3066, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [2948/5000] | Time: 0.26s\n",
      "(Training) Loss: 969934.3287\n",
      "(Validation) Loss: 994120.4063, MAE: 3807.9844, R2: 0.1607\n",
      "==========================================================================================\n",
      "Epoch [2949/5000] | Time: 0.26s\n",
      "(Training) Loss: 969512.5914\n",
      "(Validation) Loss: 993960.7721, MAE: 3807.3013, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [2950/5000] | Time: 0.26s\n",
      "(Training) Loss: 967021.3553\n",
      "(Validation) Loss: 993802.4737, MAE: 3805.8232, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [2951/5000] | Time: 0.23s\n",
      "(Training) Loss: 972263.3445\n",
      "(Validation) Loss: 993646.6489, MAE: 3805.8499, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [2952/5000] | Time: 0.25s\n",
      "(Training) Loss: 966977.3909\n",
      "(Validation) Loss: 993491.8298, MAE: 3805.3657, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [2953/5000] | Time: 0.25s\n",
      "(Training) Loss: 956019.7925\n",
      "(Validation) Loss: 993329.1225, MAE: 3804.0933, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [2954/5000] | Time: 0.26s\n",
      "(Training) Loss: 978291.2605\n",
      "(Validation) Loss: 993181.6330, MAE: 3805.5225, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [2955/5000] | Time: 0.26s\n",
      "(Training) Loss: 951514.7758\n",
      "(Validation) Loss: 993018.4381, MAE: 3803.7178, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [2956/5000] | Time: 0.24s\n",
      "(Training) Loss: 965538.7373\n",
      "(Validation) Loss: 992865.5137, MAE: 3802.6748, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [2957/5000] | Time: 0.21s\n",
      "(Training) Loss: 972624.5641\n",
      "(Validation) Loss: 992707.6114, MAE: 3801.6694, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [2958/5000] | Time: 0.20s\n",
      "(Training) Loss: 965982.3744\n",
      "(Validation) Loss: 992547.8705, MAE: 3800.6829, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [2959/5000] | Time: 0.26s\n",
      "(Training) Loss: 957348.0635\n",
      "(Validation) Loss: 992396.0178, MAE: 3802.1023, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [2960/5000] | Time: 0.22s\n",
      "(Training) Loss: 971336.3725\n",
      "(Validation) Loss: 992245.7702, MAE: 3801.9702, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [2961/5000] | Time: 0.32s\n",
      "(Training) Loss: 981431.3128\n",
      "(Validation) Loss: 992079.4616, MAE: 3800.4343, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [2962/5000] | Time: 0.34s\n",
      "(Training) Loss: 958938.0533\n",
      "(Validation) Loss: 991923.7283, MAE: 3800.3538, R2: 0.1626\n",
      "==========================================================================================\n",
      "Epoch [2963/5000] | Time: 0.34s\n",
      "(Training) Loss: 971585.9975\n",
      "(Validation) Loss: 991768.1067, MAE: 3799.3901, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [2964/5000] | Time: 0.33s\n",
      "(Training) Loss: 983515.0400\n",
      "(Validation) Loss: 991610.3721, MAE: 3799.0398, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [2965/5000] | Time: 0.28s\n",
      "(Training) Loss: 960005.0362\n",
      "(Validation) Loss: 991466.5143, MAE: 3803.2815, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [2966/5000] | Time: 0.29s\n",
      "(Training) Loss: 960054.1726\n",
      "(Validation) Loss: 991315.1390, MAE: 3798.1248, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [2967/5000] | Time: 0.29s\n",
      "(Training) Loss: 971937.2360\n",
      "(Validation) Loss: 991161.1175, MAE: 3798.5701, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [2968/5000] | Time: 0.30s\n",
      "(Training) Loss: 957319.0159\n",
      "(Validation) Loss: 991000.9956, MAE: 3797.4961, R2: 0.1633\n",
      "==========================================================================================\n",
      "Epoch [2969/5000] | Time: 0.31s\n",
      "(Training) Loss: 952183.9045\n",
      "(Validation) Loss: 990844.9981, MAE: 3796.0413, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [2970/5000] | Time: 0.30s\n",
      "(Training) Loss: 962935.9340\n",
      "(Validation) Loss: 990690.7429, MAE: 3796.4817, R2: 0.1636\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2971/5000] | Time: 0.32s\n",
      "(Training) Loss: 981727.7056\n",
      "(Validation) Loss: 990537.6965, MAE: 3795.3127, R2: 0.1637\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2972/5000] | Time: 0.33s\n",
      "(Training) Loss: 955455.0799\n",
      "(Validation) Loss: 990373.5771, MAE: 3793.9800, R2: 0.1639\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2973/5000] | Time: 0.28s\n",
      "(Training) Loss: 956394.7963\n",
      "(Validation) Loss: 990229.0235, MAE: 3796.7949, R2: 0.1640\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2974/5000] | Time: 0.30s\n",
      "(Training) Loss: 956061.5235\n",
      "(Validation) Loss: 990148.6019, MAE: 3799.8210, R2: 0.1640\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2975/5000] | Time: 0.33s\n",
      "(Training) Loss: 955440.4816\n",
      "(Validation) Loss: 989913.6559, MAE: 3794.5034, R2: 0.1642\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2976/5000] | Time: 0.30s\n",
      "(Training) Loss: 958973.3407\n",
      "(Validation) Loss: 989749.8210, MAE: 3791.9272, R2: 0.1644\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2977/5000] | Time: 0.35s\n",
      "(Training) Loss: 965359.6485\n",
      "(Validation) Loss: 989600.3454, MAE: 3792.5151, R2: 0.1645\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2978/5000] | Time: 0.34s\n",
      "(Training) Loss: 974021.2348\n",
      "(Validation) Loss: 989441.6305, MAE: 3791.3323, R2: 0.1646\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2979/5000] | Time: 0.31s\n",
      "(Training) Loss: 951500.6072\n",
      "(Validation) Loss: 989287.6241, MAE: 3792.5986, R2: 0.1648\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2980/5000] | Time: 0.32s\n",
      "(Training) Loss: 956357.9803\n",
      "(Validation) Loss: 989128.9905, MAE: 3789.5032, R2: 0.1649\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2981/5000] | Time: 0.35s\n",
      "(Training) Loss: 993610.9207\n",
      "(Validation) Loss: 988973.1048, MAE: 3789.4299, R2: 0.1650\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2982/5000] | Time: 0.38s\n",
      "(Training) Loss: 965821.6117\n",
      "(Validation) Loss: 988815.0959, MAE: 3788.8069, R2: 0.1652\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2983/5000] | Time: 0.41s\n",
      "(Training) Loss: 959830.9454\n",
      "(Validation) Loss: 988674.1232, MAE: 3791.5718, R2: 0.1653\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2984/5000] | Time: 0.37s\n",
      "(Training) Loss: 988211.0082\n",
      "(Validation) Loss: 988502.8470, MAE: 3788.0410, R2: 0.1654\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2985/5000] | Time: 0.35s\n",
      "(Training) Loss: 968593.7551\n",
      "(Validation) Loss: 988348.2667, MAE: 3787.7778, R2: 0.1655\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2986/5000] | Time: 0.42s\n",
      "(Training) Loss: 950521.2322\n",
      "(Validation) Loss: 988196.4546, MAE: 3789.5845, R2: 0.1657\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2987/5000] | Time: 0.33s\n",
      "(Training) Loss: 959128.1352\n",
      "(Validation) Loss: 988037.3892, MAE: 3787.9404, R2: 0.1658\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2988/5000] | Time: 0.33s\n",
      "(Training) Loss: 949415.3217\n",
      "(Validation) Loss: 987887.5987, MAE: 3786.7290, R2: 0.1659\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2989/5000] | Time: 0.34s\n",
      "(Training) Loss: 962422.0070\n",
      "(Validation) Loss: 987725.9784, MAE: 3785.0347, R2: 0.1661\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2990/5000] | Time: 0.37s\n",
      "(Training) Loss: 955494.7424\n",
      "(Validation) Loss: 987573.9530, MAE: 3784.6902, R2: 0.1662\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2991/5000] | Time: 0.29s\n",
      "(Training) Loss: 967626.3382\n",
      "(Validation) Loss: 987415.2330, MAE: 3783.6091, R2: 0.1663\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2992/5000] | Time: 0.35s\n",
      "(Training) Loss: 950648.0958\n",
      "(Validation) Loss: 987263.2584, MAE: 3783.8247, R2: 0.1665\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2993/5000] | Time: 0.40s\n",
      "(Training) Loss: 961160.9131\n",
      "(Validation) Loss: 987101.3130, MAE: 3781.3845, R2: 0.1666\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2994/5000] | Time: 0.39s\n",
      "(Training) Loss: 955095.6339\n",
      "(Validation) Loss: 986955.6622, MAE: 3783.1809, R2: 0.1667\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2995/5000] | Time: 0.27s\n",
      "(Training) Loss: 952241.4848\n",
      "(Validation) Loss: 986795.6165, MAE: 3780.8396, R2: 0.1668\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2996/5000] | Time: 0.28s\n",
      "(Training) Loss: 958991.0793\n",
      "(Validation) Loss: 986643.5454, MAE: 3781.1829, R2: 0.1670\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2997/5000] | Time: 0.30s\n",
      "(Training) Loss: 954160.5644\n",
      "(Validation) Loss: 986494.2273, MAE: 3782.6299, R2: 0.1671\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2998/5000] | Time: 0.36s\n",
      "(Training) Loss: 971800.6662\n",
      "(Validation) Loss: 986328.3251, MAE: 3779.2852, R2: 0.1672\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [2999/5000] | Time: 0.29s\n",
      "(Training) Loss: 971064.1935\n",
      "(Validation) Loss: 986174.7302, MAE: 3780.1431, R2: 0.1674\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3000/5000] | Time: 0.29s\n",
      "(Training) Loss: 954452.3572\n",
      "(Validation) Loss: 986017.4476, MAE: 3778.7502, R2: 0.1675\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch3000.pth\n",
      "==========================================================================================\n",
      "Epoch [3001/5000] | Time: 0.29s\n",
      "(Training) Loss: 962411.4166\n",
      "(Validation) Loss: 985872.7771, MAE: 3781.9368, R2: 0.1676\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3002/5000] | Time: 0.31s\n",
      "(Training) Loss: 957111.0235\n",
      "(Validation) Loss: 985713.1378, MAE: 3779.5645, R2: 0.1677\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3003/5000] | Time: 0.26s\n",
      "(Training) Loss: 976223.3756\n",
      "(Validation) Loss: 985548.3124, MAE: 3776.0000, R2: 0.1679\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3004/5000] | Time: 0.30s\n",
      "(Training) Loss: 963511.5362\n",
      "(Validation) Loss: 985427.0679, MAE: 3785.7075, R2: 0.1680\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3005/5000] | Time: 0.28s\n",
      "(Training) Loss: 965133.1967\n",
      "(Validation) Loss: 985240.7670, MAE: 3776.5024, R2: 0.1681\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3006/5000] | Time: 0.28s\n",
      "(Training) Loss: 962135.2849\n",
      "(Validation) Loss: 985081.9098, MAE: 3774.1853, R2: 0.1683\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3007/5000] | Time: 0.33s\n",
      "(Training) Loss: 950293.3712\n",
      "(Validation) Loss: 984926.8825, MAE: 3774.0139, R2: 0.1684\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3008/5000] | Time: 0.37s\n",
      "(Training) Loss: 952050.7119\n",
      "(Validation) Loss: 984786.0368, MAE: 3776.3127, R2: 0.1685\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3009/5000] | Time: 0.22s\n",
      "(Training) Loss: 963651.5552\n",
      "(Validation) Loss: 984633.3054, MAE: 3776.8677, R2: 0.1686\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3010/5000] | Time: 0.21s\n",
      "(Training) Loss: 945348.1071\n",
      "(Validation) Loss: 984470.8216, MAE: 3775.0422, R2: 0.1688\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3011/5000] | Time: 0.25s\n",
      "(Training) Loss: 961787.5895\n",
      "(Validation) Loss: 984313.2902, MAE: 3773.2686, R2: 0.1689\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3012/5000] | Time: 0.21s\n",
      "(Training) Loss: 948203.9727\n",
      "(Validation) Loss: 984155.6470, MAE: 3771.5730, R2: 0.1690\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3013/5000] | Time: 0.19s\n",
      "(Training) Loss: 959147.0584\n",
      "(Validation) Loss: 984006.3949, MAE: 3772.4124, R2: 0.1692\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3014/5000] | Time: 0.23s\n",
      "(Training) Loss: 943477.5220\n",
      "(Validation) Loss: 983846.0800, MAE: 3770.3364, R2: 0.1693\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3015/5000] | Time: 0.23s\n",
      "(Training) Loss: 963918.6421\n",
      "(Validation) Loss: 983701.9124, MAE: 3770.7810, R2: 0.1694\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3016/5000] | Time: 0.23s\n",
      "(Training) Loss: 948934.7938\n",
      "(Validation) Loss: 983552.8889, MAE: 3768.7346, R2: 0.1695\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3017/5000] | Time: 0.22s\n",
      "(Training) Loss: 952868.8173\n",
      "(Validation) Loss: 983409.7321, MAE: 3771.2727, R2: 0.1697\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3018/5000] | Time: 0.25s\n",
      "(Training) Loss: 959982.0955\n",
      "(Validation) Loss: 983248.6959, MAE: 3768.3826, R2: 0.1698\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3019/5000] | Time: 0.28s\n",
      "(Training) Loss: 952004.0863\n",
      "(Validation) Loss: 983104.0863, MAE: 3771.8369, R2: 0.1699\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3020/5000] | Time: 0.34s\n",
      "(Training) Loss: 962262.1478\n",
      "(Validation) Loss: 982938.2705, MAE: 3768.5474, R2: 0.1701\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3021/5000] | Time: 0.35s\n",
      "(Training) Loss: 958103.8744\n",
      "(Validation) Loss: 982786.6159, MAE: 3768.6313, R2: 0.1702\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3022/5000] | Time: 0.32s\n",
      "(Training) Loss: 972141.4803\n",
      "(Validation) Loss: 982638.2629, MAE: 3769.5786, R2: 0.1703\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3023/5000] | Time: 0.35s\n",
      "(Training) Loss: 945620.0857\n",
      "(Validation) Loss: 982474.2298, MAE: 3767.6599, R2: 0.1704\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3024/5000] | Time: 0.32s\n",
      "(Training) Loss: 958828.5666\n",
      "(Validation) Loss: 982321.3359, MAE: 3766.9775, R2: 0.1706\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3025/5000] | Time: 0.30s\n",
      "(Training) Loss: 956773.0178\n",
      "(Validation) Loss: 982171.0121, MAE: 3767.5720, R2: 0.1707\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3026/5000] | Time: 0.28s\n",
      "(Training) Loss: 945686.9854\n",
      "(Validation) Loss: 982015.9848, MAE: 3768.0232, R2: 0.1708\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3027/5000] | Time: 0.28s\n",
      "(Training) Loss: 962083.3046\n",
      "(Validation) Loss: 981868.2159, MAE: 3767.9504, R2: 0.1709\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3028/5000] | Time: 0.27s\n",
      "(Training) Loss: 962870.1174\n",
      "(Validation) Loss: 981703.8476, MAE: 3764.6292, R2: 0.1711\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3029/5000] | Time: 0.27s\n",
      "(Training) Loss: 943242.0923\n",
      "(Validation) Loss: 981562.4432, MAE: 3766.0039, R2: 0.1712\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3030/5000] | Time: 0.29s\n",
      "(Training) Loss: 960568.2792\n",
      "(Validation) Loss: 981392.7213, MAE: 3763.7175, R2: 0.1713\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3031/5000] | Time: 0.32s\n",
      "(Training) Loss: 946342.4137\n",
      "(Validation) Loss: 981246.5575, MAE: 3764.1343, R2: 0.1715\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3032/5000] | Time: 0.27s\n",
      "(Training) Loss: 941334.4091\n",
      "(Validation) Loss: 981084.8051, MAE: 3762.0056, R2: 0.1716\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3033/5000] | Time: 0.33s\n",
      "(Training) Loss: 966173.5393\n",
      "(Validation) Loss: 980933.3232, MAE: 3761.1799, R2: 0.1717\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3034/5000] | Time: 0.35s\n",
      "(Training) Loss: 942846.4128\n",
      "(Validation) Loss: 980779.5606, MAE: 3762.0496, R2: 0.1719\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3035/5000] | Time: 0.35s\n",
      "(Training) Loss: 958011.2659\n",
      "(Validation) Loss: 980627.1848, MAE: 3760.4124, R2: 0.1720\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3036/5000] | Time: 0.38s\n",
      "(Training) Loss: 952601.9784\n",
      "(Validation) Loss: 980456.0711, MAE: 3762.0381, R2: 0.1721\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3037/5000] | Time: 0.34s\n",
      "(Training) Loss: 976594.0717\n",
      "(Validation) Loss: 983462.3594, MAE: 3775.6550, R2: 0.1696\n",
      "==========================================================================================\n",
      "Epoch [3038/5000] | Time: 0.33s\n",
      "(Training) Loss: 957673.9848\n",
      "(Validation) Loss: 983287.9797, MAE: 3774.8665, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3039/5000] | Time: 0.33s\n",
      "(Training) Loss: 950794.8173\n",
      "(Validation) Loss: 983126.5067, MAE: 3774.1733, R2: 0.1699\n",
      "==========================================================================================\n",
      "Epoch [3040/5000] | Time: 0.35s\n",
      "(Training) Loss: 949249.3115\n",
      "(Validation) Loss: 982961.2292, MAE: 3773.1101, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3041/5000] | Time: 0.47s\n",
      "(Training) Loss: 949959.5514\n",
      "(Validation) Loss: 982804.8152, MAE: 3773.4272, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [3042/5000] | Time: 0.32s\n",
      "(Training) Loss: 957903.7018\n",
      "(Validation) Loss: 982646.1511, MAE: 3773.0669, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [3043/5000] | Time: 0.25s\n",
      "(Training) Loss: 970536.9549\n",
      "(Validation) Loss: 991661.2216, MAE: 3807.5359, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [3044/5000] | Time: 0.27s\n",
      "(Training) Loss: 973827.2728\n",
      "(Validation) Loss: 991504.3962, MAE: 3806.2180, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [3045/5000] | Time: 0.41s\n",
      "(Training) Loss: 961474.6206\n",
      "(Validation) Loss: 991335.5124, MAE: 3803.8115, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [3046/5000] | Time: 0.29s\n",
      "(Training) Loss: 957523.3826\n",
      "(Validation) Loss: 991175.3702, MAE: 3803.6780, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [3047/5000] | Time: 0.28s\n",
      "(Training) Loss: 959259.9778\n",
      "(Validation) Loss: 988524.0635, MAE: 3793.1907, R2: 0.1654\n",
      "==========================================================================================\n",
      "Epoch [3048/5000] | Time: 0.25s\n",
      "(Training) Loss: 952462.6288\n",
      "(Validation) Loss: 988288.5283, MAE: 3792.2275, R2: 0.1656\n",
      "==========================================================================================\n",
      "Epoch [3049/5000] | Time: 0.27s\n",
      "(Training) Loss: 959540.6206\n",
      "(Validation) Loss: 988113.2089, MAE: 3788.4587, R2: 0.1657\n",
      "==========================================================================================\n",
      "Epoch [3050/5000] | Time: 0.29s\n",
      "(Training) Loss: 947527.8315\n",
      "(Validation) Loss: 987953.7524, MAE: 3788.9207, R2: 0.1659\n",
      "==========================================================================================\n",
      "Epoch [3051/5000] | Time: 0.40s\n",
      "(Training) Loss: 948255.1263\n",
      "(Validation) Loss: 987785.7067, MAE: 3787.8086, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3052/5000] | Time: 0.32s\n",
      "(Training) Loss: 946874.0254\n",
      "(Validation) Loss: 987715.8552, MAE: 3795.2988, R2: 0.1661\n",
      "==========================================================================================\n",
      "Epoch [3053/5000] | Time: 0.30s\n",
      "(Training) Loss: 949202.8871\n",
      "(Validation) Loss: 987538.5448, MAE: 3789.3679, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3054/5000] | Time: 0.29s\n",
      "(Training) Loss: 949410.8804\n",
      "(Validation) Loss: 987386.6514, MAE: 3791.5044, R2: 0.1663\n",
      "==========================================================================================\n",
      "Epoch [3055/5000] | Time: 0.25s\n",
      "(Training) Loss: 969941.9911\n",
      "(Validation) Loss: 987217.0819, MAE: 3788.1609, R2: 0.1665\n",
      "==========================================================================================\n",
      "Epoch [3056/5000] | Time: 0.29s\n",
      "(Training) Loss: 946465.7138\n",
      "(Validation) Loss: 987056.8483, MAE: 3788.7114, R2: 0.1666\n",
      "==========================================================================================\n",
      "Epoch [3057/5000] | Time: 0.31s\n",
      "(Training) Loss: 954131.0324\n",
      "(Validation) Loss: 986893.1403, MAE: 3787.2869, R2: 0.1668\n",
      "==========================================================================================\n",
      "Epoch [3058/5000] | Time: 0.27s\n",
      "(Training) Loss: 960489.3579\n",
      "(Validation) Loss: 986733.6432, MAE: 3787.3582, R2: 0.1669\n",
      "==========================================================================================\n",
      "Epoch [3059/5000] | Time: 0.32s\n",
      "(Training) Loss: 952842.9975\n",
      "(Validation) Loss: 986572.4241, MAE: 3786.9597, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3060/5000] | Time: 0.30s\n",
      "(Training) Loss: 957795.7481\n",
      "(Validation) Loss: 986412.7848, MAE: 3787.6558, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3061/5000] | Time: 0.32s\n",
      "(Training) Loss: 970634.3192\n",
      "(Validation) Loss: 986374.1867, MAE: 3793.8035, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3062/5000] | Time: 0.29s\n",
      "(Training) Loss: 948652.6754\n",
      "(Validation) Loss: 986212.3581, MAE: 3794.8877, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3063/5000] | Time: 0.28s\n",
      "(Training) Loss: 960810.5374\n",
      "(Validation) Loss: 986051.4743, MAE: 3794.0247, R2: 0.1675\n",
      "==========================================================================================\n",
      "Epoch [3064/5000] | Time: 0.29s\n",
      "(Training) Loss: 947978.2684\n",
      "(Validation) Loss: 985894.4813, MAE: 3794.3613, R2: 0.1676\n",
      "==========================================================================================\n",
      "Epoch [3065/5000] | Time: 0.28s\n",
      "(Training) Loss: 958545.6574\n",
      "(Validation) Loss: 985731.6470, MAE: 3792.2085, R2: 0.1677\n",
      "==========================================================================================\n",
      "Epoch [3066/5000] | Time: 0.40s\n",
      "(Training) Loss: 956976.6332\n",
      "(Validation) Loss: 985568.5181, MAE: 3790.8792, R2: 0.1679\n",
      "==========================================================================================\n",
      "Epoch [3067/5000] | Time: 0.42s\n",
      "(Training) Loss: 964958.8947\n",
      "(Validation) Loss: 985419.5556, MAE: 3792.3848, R2: 0.1680\n",
      "==========================================================================================\n",
      "Epoch [3068/5000] | Time: 0.45s\n",
      "(Training) Loss: 955201.5730\n",
      "(Validation) Loss: 985248.6298, MAE: 3789.1536, R2: 0.1681\n",
      "==========================================================================================\n",
      "Epoch [3069/5000] | Time: 0.30s\n",
      "(Training) Loss: 958874.1161\n",
      "(Validation) Loss: 985090.7479, MAE: 3788.6423, R2: 0.1683\n",
      "==========================================================================================\n",
      "Epoch [3070/5000] | Time: 0.30s\n",
      "(Training) Loss: 983225.6326\n",
      "(Validation) Loss: 984931.8349, MAE: 3788.1536, R2: 0.1684\n",
      "==========================================================================================\n",
      "Epoch [3071/5000] | Time: 0.27s\n",
      "(Training) Loss: 945170.2414\n",
      "(Validation) Loss: 984779.5556, MAE: 3792.5657, R2: 0.1685\n",
      "==========================================================================================\n",
      "Epoch [3072/5000] | Time: 0.29s\n",
      "(Training) Loss: 965196.3629\n",
      "(Validation) Loss: 984610.3619, MAE: 3787.4119, R2: 0.1687\n",
      "==========================================================================================\n",
      "Epoch [3073/5000] | Time: 0.27s\n",
      "(Training) Loss: 946035.5907\n",
      "(Validation) Loss: 984451.2254, MAE: 3787.0039, R2: 0.1688\n",
      "==========================================================================================\n",
      "Epoch [3074/5000] | Time: 0.26s\n",
      "(Training) Loss: 956864.3769\n",
      "(Validation) Loss: 984292.9117, MAE: 3785.7244, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [3075/5000] | Time: 0.36s\n",
      "(Training) Loss: 966625.5495\n",
      "(Validation) Loss: 984134.1968, MAE: 3785.3550, R2: 0.1691\n",
      "==========================================================================================\n",
      "Epoch [3076/5000] | Time: 0.35s\n",
      "(Training) Loss: 956580.9952\n",
      "(Validation) Loss: 983973.2470, MAE: 3784.9426, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [3077/5000] | Time: 0.29s\n",
      "(Training) Loss: 970817.2690\n",
      "(Validation) Loss: 983816.5029, MAE: 3785.6018, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [3078/5000] | Time: 0.28s\n",
      "(Training) Loss: 965028.7938\n",
      "(Validation) Loss: 983654.9435, MAE: 3785.1892, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [3079/5000] | Time: 0.45s\n",
      "(Training) Loss: 945205.8287\n",
      "(Validation) Loss: 983498.1994, MAE: 3785.4182, R2: 0.1696\n",
      "==========================================================================================\n",
      "Epoch [3080/5000] | Time: 0.37s\n",
      "(Training) Loss: 956498.6072\n",
      "(Validation) Loss: 983338.1435, MAE: 3784.4468, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [3081/5000] | Time: 0.41s\n",
      "(Training) Loss: 945092.5463\n",
      "(Validation) Loss: 983168.0610, MAE: 3784.5264, R2: 0.1699\n",
      "==========================================================================================\n",
      "Epoch [3082/5000] | Time: 0.31s\n",
      "(Training) Loss: 951721.8464\n",
      "(Validation) Loss: 983029.0438, MAE: 3784.9121, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3083/5000] | Time: 0.27s\n",
      "(Training) Loss: 970257.0692\n",
      "(Validation) Loss: 1001438.7962, MAE: 3845.3511, R2: 0.1546\n",
      "==========================================================================================\n",
      "Epoch [3084/5000] | Time: 0.25s\n",
      "(Training) Loss: 961557.2557\n",
      "(Validation) Loss: 1001266.1486, MAE: 3847.1899, R2: 0.1548\n",
      "==========================================================================================\n",
      "Epoch [3085/5000] | Time: 0.28s\n",
      "(Training) Loss: 962886.6101\n",
      "(Validation) Loss: 1001098.2197, MAE: 3844.2737, R2: 0.1549\n",
      "==========================================================================================\n",
      "Epoch [3086/5000] | Time: 0.26s\n",
      "(Training) Loss: 984835.0838\n",
      "(Validation) Loss: 1000923.6571, MAE: 3842.0435, R2: 0.1551\n",
      "==========================================================================================\n",
      "Epoch [3087/5000] | Time: 0.29s\n",
      "(Training) Loss: 961521.0933\n",
      "(Validation) Loss: 1000757.5670, MAE: 3840.4534, R2: 0.1552\n",
      "==========================================================================================\n",
      "Epoch [3088/5000] | Time: 0.39s\n",
      "(Training) Loss: 972751.7170\n",
      "(Validation) Loss: 1000614.9689, MAE: 3846.4072, R2: 0.1553\n",
      "==========================================================================================\n",
      "Epoch [3089/5000] | Time: 0.41s\n",
      "(Training) Loss: 982466.0495\n",
      "(Validation) Loss: 1000437.9225, MAE: 3841.3755, R2: 0.1555\n",
      "==========================================================================================\n",
      "Epoch [3090/5000] | Time: 0.22s\n",
      "(Training) Loss: 970949.0330\n",
      "(Validation) Loss: 1000264.8686, MAE: 3838.5088, R2: 0.1556\n",
      "==========================================================================================\n",
      "Epoch [3091/5000] | Time: 0.24s\n",
      "(Training) Loss: 964019.3039\n",
      "(Validation) Loss: 1000120.2794, MAE: 3843.4250, R2: 0.1557\n",
      "==========================================================================================\n",
      "Epoch [3092/5000] | Time: 0.22s\n",
      "(Training) Loss: 967235.2595\n",
      "(Validation) Loss: 999943.0146, MAE: 3838.3818, R2: 0.1559\n",
      "==========================================================================================\n",
      "Epoch [3093/5000] | Time: 0.20s\n",
      "(Training) Loss: 969554.0895\n",
      "(Validation) Loss: 999786.8800, MAE: 3840.5117, R2: 0.1560\n",
      "==========================================================================================\n",
      "Epoch [3094/5000] | Time: 0.20s\n",
      "(Training) Loss: 970312.0635\n",
      "(Validation) Loss: 999620.4241, MAE: 3843.5125, R2: 0.1561\n",
      "==========================================================================================\n",
      "Epoch [3095/5000] | Time: 0.20s\n",
      "(Training) Loss: 973402.4708\n",
      "(Validation) Loss: 999459.8400, MAE: 3839.9619, R2: 0.1563\n",
      "==========================================================================================\n",
      "Epoch [3096/5000] | Time: 0.37s\n",
      "(Training) Loss: 958475.3379\n",
      "(Validation) Loss: 999288.7314, MAE: 3837.2546, R2: 0.1564\n",
      "==========================================================================================\n",
      "Epoch [3097/5000] | Time: 0.41s\n",
      "(Training) Loss: 970988.7805\n",
      "(Validation) Loss: 999127.5378, MAE: 3836.5083, R2: 0.1566\n",
      "==========================================================================================\n",
      "Epoch [3098/5000] | Time: 0.26s\n",
      "(Training) Loss: 964301.2563\n",
      "(Validation) Loss: 998966.4051, MAE: 3836.1995, R2: 0.1567\n",
      "==========================================================================================\n",
      "Epoch [3099/5000] | Time: 0.29s\n",
      "(Training) Loss: 980099.6015\n",
      "(Validation) Loss: 998808.9854, MAE: 3836.4182, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [3100/5000] | Time: 0.32s\n",
      "(Training) Loss: 961476.0996\n",
      "(Validation) Loss: 995658.5600, MAE: 3826.9829, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [3101/5000] | Time: 0.35s\n",
      "(Training) Loss: 964253.1139\n",
      "(Validation) Loss: 995496.2083, MAE: 3824.1160, R2: 0.1596\n",
      "==========================================================================================\n",
      "Epoch [3102/5000] | Time: 0.47s\n",
      "(Training) Loss: 961250.8572\n",
      "(Validation) Loss: 995341.1200, MAE: 3823.9517, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [3103/5000] | Time: 0.24s\n",
      "(Training) Loss: 980253.0679\n",
      "(Validation) Loss: 995185.3663, MAE: 3822.8691, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [3104/5000] | Time: 0.30s\n",
      "(Training) Loss: 959612.5577\n",
      "(Validation) Loss: 995031.0908, MAE: 3824.8425, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [3105/5000] | Time: 0.39s\n",
      "(Training) Loss: 996747.6294\n",
      "(Validation) Loss: 994867.8146, MAE: 3821.6467, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [3106/5000] | Time: 0.22s\n",
      "(Training) Loss: 964769.2614\n",
      "(Validation) Loss: 994704.3098, MAE: 3820.1013, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [3107/5000] | Time: 0.24s\n",
      "(Training) Loss: 977002.4949\n",
      "(Validation) Loss: 994549.4806, MAE: 3820.6133, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [3108/5000] | Time: 0.22s\n",
      "(Training) Loss: 970358.2608\n",
      "(Validation) Loss: 994388.4597, MAE: 3818.8477, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [3109/5000] | Time: 0.24s\n",
      "(Training) Loss: 957914.2595\n",
      "(Validation) Loss: 994231.6241, MAE: 3818.6584, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [3110/5000] | Time: 0.22s\n",
      "(Training) Loss: 970454.7253\n",
      "(Validation) Loss: 994078.0140, MAE: 3819.7476, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [3111/5000] | Time: 0.21s\n",
      "(Training) Loss: 977441.8680\n",
      "(Validation) Loss: 993924.3378, MAE: 3819.1934, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [3112/5000] | Time: 0.23s\n",
      "(Training) Loss: 961582.1954\n",
      "(Validation) Loss: 993774.7251, MAE: 3817.1328, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [3113/5000] | Time: 0.23s\n",
      "(Training) Loss: 961316.0038\n",
      "(Validation) Loss: 993602.4076, MAE: 3816.6184, R2: 0.1612\n",
      "==========================================================================================\n",
      "Epoch [3114/5000] | Time: 0.26s\n",
      "(Training) Loss: 955642.6846\n",
      "(Validation) Loss: 993447.7206, MAE: 3816.8206, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [3115/5000] | Time: 0.24s\n",
      "(Training) Loss: 967630.5165\n",
      "(Validation) Loss: 993286.8013, MAE: 3813.9182, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [3116/5000] | Time: 0.23s\n",
      "(Training) Loss: 964931.4765\n",
      "(Validation) Loss: 993139.9771, MAE: 3816.6067, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [3117/5000] | Time: 0.34s\n",
      "(Training) Loss: 961550.4714\n",
      "(Validation) Loss: 992974.8419, MAE: 3813.1731, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [3118/5000] | Time: 0.25s\n",
      "(Training) Loss: 952164.3609\n",
      "(Validation) Loss: 992821.4451, MAE: 3814.6108, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [3119/5000] | Time: 0.25s\n",
      "(Training) Loss: 963101.2703\n",
      "(Validation) Loss: 992671.8730, MAE: 3814.3577, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [3120/5000] | Time: 0.21s\n",
      "(Training) Loss: 973370.6631\n",
      "(Validation) Loss: 992504.5689, MAE: 3812.3962, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [3121/5000] | Time: 0.20s\n",
      "(Training) Loss: 981240.4327\n",
      "(Validation) Loss: 992349.9225, MAE: 3811.9023, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [3122/5000] | Time: 0.31s\n",
      "(Training) Loss: 979316.0203\n",
      "(Validation) Loss: 992194.1689, MAE: 3812.2793, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [3123/5000] | Time: 0.26s\n",
      "(Training) Loss: 951331.5077\n",
      "(Validation) Loss: 992036.8254, MAE: 3811.6399, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [3124/5000] | Time: 0.31s\n",
      "(Training) Loss: 965625.2912\n",
      "(Validation) Loss: 991883.7587, MAE: 3810.7844, R2: 0.1626\n",
      "==========================================================================================\n",
      "Epoch [3125/5000] | Time: 0.19s\n",
      "(Training) Loss: 972144.7462\n",
      "(Validation) Loss: 991734.7098, MAE: 3814.2417, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [3126/5000] | Time: 0.19s\n",
      "(Training) Loss: 992273.7043\n",
      "(Validation) Loss: 991562.1333, MAE: 3808.6521, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [3127/5000] | Time: 0.20s\n",
      "(Training) Loss: 970003.4860\n",
      "(Validation) Loss: 989281.3663, MAE: 3801.4182, R2: 0.1648\n",
      "==========================================================================================\n",
      "Epoch [3128/5000] | Time: 0.29s\n",
      "(Training) Loss: 961275.5679\n",
      "(Validation) Loss: 989127.6140, MAE: 3799.3315, R2: 0.1649\n",
      "==========================================================================================\n",
      "Epoch [3129/5000] | Time: 0.29s\n",
      "(Training) Loss: 947841.3773\n",
      "(Validation) Loss: 988975.6546, MAE: 3799.9568, R2: 0.1650\n",
      "==========================================================================================\n",
      "Epoch [3130/5000] | Time: 0.21s\n",
      "(Training) Loss: 962542.1129\n",
      "(Validation) Loss: 988823.8425, MAE: 3799.2708, R2: 0.1651\n",
      "==========================================================================================\n",
      "Epoch [3131/5000] | Time: 0.21s\n",
      "(Training) Loss: 947634.0409\n",
      "(Validation) Loss: 988714.0724, MAE: 3802.0879, R2: 0.1652\n",
      "==========================================================================================\n",
      "Epoch [3132/5000] | Time: 0.19s\n",
      "(Training) Loss: 950721.0374\n",
      "(Validation) Loss: 988548.8508, MAE: 3806.1709, R2: 0.1654\n",
      "==========================================================================================\n",
      "Epoch [3133/5000] | Time: 0.23s\n",
      "(Training) Loss: 954588.1034\n",
      "(Validation) Loss: 988366.4863, MAE: 3796.6511, R2: 0.1655\n",
      "==========================================================================================\n",
      "Epoch [3134/5000] | Time: 0.22s\n",
      "(Training) Loss: 953076.9283\n",
      "(Validation) Loss: 988232.4267, MAE: 3800.9473, R2: 0.1656\n",
      "==========================================================================================\n",
      "Epoch [3135/5000] | Time: 0.21s\n",
      "(Training) Loss: 951873.9594\n",
      "(Validation) Loss: 988065.9454, MAE: 3795.7710, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [3136/5000] | Time: 0.21s\n",
      "(Training) Loss: 956665.5533\n",
      "(Validation) Loss: 987911.8171, MAE: 3794.8315, R2: 0.1659\n",
      "==========================================================================================\n",
      "Epoch [3137/5000] | Time: 0.21s\n",
      "(Training) Loss: 971701.5939\n",
      "(Validation) Loss: 987759.2279, MAE: 3793.6045, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3138/5000] | Time: 0.21s\n",
      "(Training) Loss: 953888.2576\n",
      "(Validation) Loss: 987605.7854, MAE: 3793.0867, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3139/5000] | Time: 0.26s\n",
      "(Training) Loss: 963402.9594\n",
      "(Validation) Loss: 987455.8324, MAE: 3793.3069, R2: 0.1663\n",
      "==========================================================================================\n",
      "Epoch [3140/5000] | Time: 0.23s\n",
      "(Training) Loss: 958347.9346\n",
      "(Validation) Loss: 987318.6590, MAE: 3797.3203, R2: 0.1664\n",
      "==========================================================================================\n",
      "Epoch [3141/5000] | Time: 0.19s\n",
      "(Training) Loss: 967786.5152\n",
      "(Validation) Loss: 987153.9860, MAE: 3794.6799, R2: 0.1665\n",
      "==========================================================================================\n",
      "Epoch [3142/5000] | Time: 0.19s\n",
      "(Training) Loss: 955100.5209\n",
      "(Validation) Loss: 986994.1181, MAE: 3791.5178, R2: 0.1667\n",
      "==========================================================================================\n",
      "Epoch [3143/5000] | Time: 0.20s\n",
      "(Training) Loss: 958857.6561\n",
      "(Validation) Loss: 986843.7587, MAE: 3790.5818, R2: 0.1668\n",
      "==========================================================================================\n",
      "Epoch [3144/5000] | Time: 0.23s\n",
      "(Training) Loss: 948238.2573\n",
      "(Validation) Loss: 986689.5797, MAE: 3789.7312, R2: 0.1669\n",
      "==========================================================================================\n",
      "Epoch [3145/5000] | Time: 0.21s\n",
      "(Training) Loss: 951236.7088\n",
      "(Validation) Loss: 986540.9219, MAE: 3789.5420, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3146/5000] | Time: 0.26s\n",
      "(Training) Loss: 952453.6789\n",
      "(Validation) Loss: 986385.2648, MAE: 3788.3669, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3147/5000] | Time: 0.27s\n",
      "(Training) Loss: 957945.8325\n",
      "(Validation) Loss: 986243.6825, MAE: 3791.9309, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3148/5000] | Time: 0.40s\n",
      "(Training) Loss: 949199.4886\n",
      "(Validation) Loss: 986095.3803, MAE: 3792.3877, R2: 0.1674\n",
      "==========================================================================================\n",
      "Epoch [3149/5000] | Time: 0.22s\n",
      "(Training) Loss: 964587.3503\n",
      "(Validation) Loss: 985943.1924, MAE: 3792.2915, R2: 0.1675\n",
      "==========================================================================================\n",
      "Epoch [3150/5000] | Time: 0.19s\n",
      "(Training) Loss: 962510.6840\n",
      "(Validation) Loss: 985782.9486, MAE: 3791.0620, R2: 0.1677\n",
      "==========================================================================================\n",
      "Epoch [3151/5000] | Time: 0.22s\n",
      "(Training) Loss: 955523.3058\n",
      "(Validation) Loss: 985628.0229, MAE: 3789.7104, R2: 0.1678\n",
      "==========================================================================================\n",
      "Epoch [3152/5000] | Time: 0.22s\n",
      "(Training) Loss: 965784.9911\n",
      "(Validation) Loss: 985474.0114, MAE: 3788.1091, R2: 0.1679\n",
      "==========================================================================================\n",
      "Epoch [3153/5000] | Time: 0.26s\n",
      "(Training) Loss: 961030.3832\n",
      "(Validation) Loss: 985328.5435, MAE: 3788.7883, R2: 0.1681\n",
      "==========================================================================================\n",
      "Epoch [3154/5000] | Time: 0.31s\n",
      "(Training) Loss: 960372.8211\n",
      "(Validation) Loss: 985169.1530, MAE: 3786.8816, R2: 0.1682\n",
      "==========================================================================================\n",
      "Epoch [3155/5000] | Time: 0.25s\n",
      "(Training) Loss: 950456.2506\n",
      "(Validation) Loss: 985014.9638, MAE: 3786.2969, R2: 0.1683\n",
      "==========================================================================================\n",
      "Epoch [3156/5000] | Time: 0.18s\n",
      "(Training) Loss: 963432.2138\n",
      "(Validation) Loss: 984866.8089, MAE: 3785.8201, R2: 0.1684\n",
      "==========================================================================================\n",
      "Epoch [3157/5000] | Time: 0.20s\n",
      "(Training) Loss: 945028.2689\n",
      "(Validation) Loss: 984727.1010, MAE: 3788.2800, R2: 0.1686\n",
      "==========================================================================================\n",
      "Epoch [3158/5000] | Time: 0.19s\n",
      "(Training) Loss: 952950.5232\n",
      "(Validation) Loss: 984562.1587, MAE: 3785.0063, R2: 0.1687\n",
      "==========================================================================================\n",
      "Epoch [3159/5000] | Time: 0.24s\n",
      "(Training) Loss: 969246.2614\n",
      "(Validation) Loss: 984415.6038, MAE: 3784.3608, R2: 0.1688\n",
      "==========================================================================================\n",
      "Epoch [3160/5000] | Time: 0.22s\n",
      "(Training) Loss: 967991.8065\n",
      "(Validation) Loss: 984272.7771, MAE: 3789.0234, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [3161/5000] | Time: 0.22s\n",
      "(Training) Loss: 958446.0343\n",
      "(Validation) Loss: 984102.4102, MAE: 3782.5347, R2: 0.1691\n",
      "==========================================================================================\n",
      "Epoch [3162/5000] | Time: 0.23s\n",
      "(Training) Loss: 962077.7741\n",
      "(Validation) Loss: 983949.3841, MAE: 3780.7080, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [3163/5000] | Time: 0.22s\n",
      "(Training) Loss: 965766.1022\n",
      "(Validation) Loss: 983804.5257, MAE: 3782.7676, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [3164/5000] | Time: 0.19s\n",
      "(Training) Loss: 948779.3572\n",
      "(Validation) Loss: 983639.5987, MAE: 3778.9946, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [3165/5000] | Time: 0.24s\n",
      "(Training) Loss: 954012.2836\n",
      "(Validation) Loss: 983491.0476, MAE: 3778.3062, R2: 0.1696\n",
      "==========================================================================================\n",
      "Epoch [3166/5000] | Time: 0.24s\n",
      "(Training) Loss: 951689.4645\n",
      "(Validation) Loss: 983338.8394, MAE: 3777.6812, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [3167/5000] | Time: 0.20s\n",
      "(Training) Loss: 987247.2741\n",
      "(Validation) Loss: 983191.7714, MAE: 3778.4031, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3168/5000] | Time: 0.22s\n",
      "(Training) Loss: 949078.9962\n",
      "(Validation) Loss: 983034.2756, MAE: 3776.7837, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3169/5000] | Time: 0.23s\n",
      "(Training) Loss: 967293.4727\n",
      "(Validation) Loss: 982884.0635, MAE: 3777.4246, R2: 0.1701\n",
      "==========================================================================================\n",
      "Epoch [3170/5000] | Time: 0.22s\n",
      "(Training) Loss: 971325.1720\n",
      "(Validation) Loss: 982741.1200, MAE: 3780.2598, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [3171/5000] | Time: 0.21s\n",
      "(Training) Loss: 956840.8864\n",
      "(Validation) Loss: 982580.5206, MAE: 3776.6016, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [3172/5000] | Time: 0.20s\n",
      "(Training) Loss: 943285.0763\n",
      "(Validation) Loss: 982345.6610, MAE: 3772.3352, R2: 0.1705\n",
      "==========================================================================================\n",
      "Epoch [3173/5000] | Time: 0.24s\n",
      "(Training) Loss: 956336.8077\n",
      "(Validation) Loss: 982189.2216, MAE: 3769.8142, R2: 0.1707\n",
      "==========================================================================================\n",
      "Epoch [3174/5000] | Time: 0.20s\n",
      "(Training) Loss: 965721.9048\n",
      "(Validation) Loss: 982038.9029, MAE: 3769.3640, R2: 0.1708\n",
      "==========================================================================================\n",
      "Epoch [3175/5000] | Time: 0.21s\n",
      "(Training) Loss: 960900.2348\n",
      "(Validation) Loss: 981880.7060, MAE: 3766.8879, R2: 0.1709\n",
      "==========================================================================================\n",
      "Epoch [3176/5000] | Time: 0.23s\n",
      "(Training) Loss: 954586.9619\n",
      "(Validation) Loss: 981744.7365, MAE: 3772.2610, R2: 0.1711\n",
      "==========================================================================================\n",
      "Epoch [3177/5000] | Time: 0.21s\n",
      "(Training) Loss: 942825.1669\n",
      "(Validation) Loss: 981586.0622, MAE: 3768.8613, R2: 0.1712\n",
      "==========================================================================================\n",
      "Epoch [3178/5000] | Time: 0.25s\n",
      "(Training) Loss: 955737.9080\n",
      "(Validation) Loss: 981428.2159, MAE: 3765.2031, R2: 0.1713\n",
      "==========================================================================================\n",
      "Epoch [3179/5000] | Time: 0.22s\n",
      "(Training) Loss: 944126.9283\n",
      "(Validation) Loss: 981291.6876, MAE: 3769.9480, R2: 0.1714\n",
      "==========================================================================================\n",
      "Epoch [3180/5000] | Time: 0.20s\n",
      "(Training) Loss: 942189.3125\n",
      "(Validation) Loss: 981134.0648, MAE: 3764.9248, R2: 0.1716\n",
      "==========================================================================================\n",
      "Epoch [3181/5000] | Time: 0.22s\n",
      "(Training) Loss: 953887.7621\n",
      "(Validation) Loss: 980984.0000, MAE: 3765.5115, R2: 0.1717\n",
      "==========================================================================================\n",
      "Epoch [3182/5000] | Time: 0.21s\n",
      "(Training) Loss: 965973.8173\n",
      "(Validation) Loss: 980844.5359, MAE: 3772.0374, R2: 0.1718\n",
      "==========================================================================================\n",
      "Epoch [3183/5000] | Time: 0.24s\n",
      "(Training) Loss: 944262.3775\n",
      "(Validation) Loss: 980681.9302, MAE: 3766.2361, R2: 0.1719\n",
      "==========================================================================================\n",
      "Epoch [3184/5000] | Time: 0.23s\n",
      "(Training) Loss: 952806.9327\n",
      "(Validation) Loss: 980527.3448, MAE: 3764.2485, R2: 0.1721\n",
      "==========================================================================================\n",
      "Epoch [3185/5000] | Time: 0.21s\n",
      "(Training) Loss: 942313.4937\n",
      "(Validation) Loss: 980378.8394, MAE: 3763.7847, R2: 0.1722\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3186/5000] | Time: 0.20s\n",
      "(Training) Loss: 952740.1821\n",
      "(Validation) Loss: 980238.9892, MAE: 3765.5146, R2: 0.1723\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3187/5000] | Time: 0.29s\n",
      "(Training) Loss: 956481.7589\n",
      "(Validation) Loss: 980092.7492, MAE: 3766.5654, R2: 0.1724\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3188/5000] | Time: 0.20s\n",
      "(Training) Loss: 957265.1948\n",
      "(Validation) Loss: 979921.3054, MAE: 3761.1204, R2: 0.1726\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3189/5000] | Time: 0.20s\n",
      "(Training) Loss: 964898.8966\n",
      "(Validation) Loss: 979772.7390, MAE: 3759.5928, R2: 0.1727\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3190/5000] | Time: 0.20s\n",
      "(Training) Loss: 943878.3325\n",
      "(Validation) Loss: 979623.7460, MAE: 3760.4792, R2: 0.1728\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3191/5000] | Time: 0.20s\n",
      "(Training) Loss: 945460.0876\n",
      "(Validation) Loss: 979481.3054, MAE: 3760.3000, R2: 0.1729\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3192/5000] | Time: 0.22s\n",
      "(Training) Loss: 940704.8499\n",
      "(Validation) Loss: 979322.9613, MAE: 3758.8591, R2: 0.1731\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [3193/5000] | Time: 0.33s\n",
      "(Training) Loss: 954477.4981\n",
      "(Validation) Loss: 998355.3727, MAE: 3824.0479, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [3194/5000] | Time: 0.26s\n",
      "(Training) Loss: 968752.9981\n",
      "(Validation) Loss: 998187.5962, MAE: 3821.2515, R2: 0.1573\n",
      "==========================================================================================\n",
      "Epoch [3195/5000] | Time: 0.24s\n",
      "(Training) Loss: 959796.5698\n",
      "(Validation) Loss: 998032.3657, MAE: 3821.6333, R2: 0.1575\n",
      "==========================================================================================\n",
      "Epoch [3196/5000] | Time: 0.19s\n",
      "(Training) Loss: 962150.7671\n",
      "(Validation) Loss: 997884.0889, MAE: 3822.2996, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [3197/5000] | Time: 0.24s\n",
      "(Training) Loss: 974932.4194\n",
      "(Validation) Loss: 997813.1556, MAE: 3826.5986, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [3198/5000] | Time: 0.23s\n",
      "(Training) Loss: 966839.9264\n",
      "(Validation) Loss: 997667.0375, MAE: 3831.3403, R2: 0.1578\n",
      "==========================================================================================\n",
      "Epoch [3199/5000] | Time: 0.22s\n",
      "(Training) Loss: 966597.3274\n",
      "(Validation) Loss: 997497.5187, MAE: 3825.8506, R2: 0.1579\n",
      "==========================================================================================\n",
      "Epoch [3200/5000] | Time: 0.26s\n",
      "(Training) Loss: 978046.6193\n",
      "(Validation) Loss: 997338.9054, MAE: 3824.4109, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [3201/5000] | Time: 0.21s\n",
      "(Training) Loss: 969455.7766\n",
      "(Validation) Loss: 997180.9778, MAE: 3823.6355, R2: 0.1582\n",
      "==========================================================================================\n",
      "Epoch [3202/5000] | Time: 0.21s\n",
      "(Training) Loss: 959776.6129\n",
      "(Validation) Loss: 997023.0908, MAE: 3823.5874, R2: 0.1583\n",
      "==========================================================================================\n",
      "Epoch [3203/5000] | Time: 0.29s\n",
      "(Training) Loss: 976530.6453\n",
      "(Validation) Loss: 996867.5911, MAE: 3821.9631, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [3204/5000] | Time: 0.22s\n",
      "(Training) Loss: 978034.4105\n",
      "(Validation) Loss: 996725.2673, MAE: 3824.3545, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [3205/5000] | Time: 0.20s\n",
      "(Training) Loss: 978936.9369\n",
      "(Validation) Loss: 996567.0349, MAE: 3826.0496, R2: 0.1587\n",
      "==========================================================================================\n",
      "Epoch [3206/5000] | Time: 0.23s\n",
      "(Training) Loss: 980178.8052\n",
      "(Validation) Loss: 996406.8927, MAE: 3823.0203, R2: 0.1588\n",
      "==========================================================================================\n",
      "Epoch [3207/5000] | Time: 0.22s\n",
      "(Training) Loss: 969497.0812\n",
      "(Validation) Loss: 996248.4521, MAE: 3823.0686, R2: 0.1590\n",
      "==========================================================================================\n",
      "Epoch [3208/5000] | Time: 0.26s\n",
      "(Training) Loss: 980501.5806\n",
      "(Validation) Loss: 996086.6743, MAE: 3819.6880, R2: 0.1591\n",
      "==========================================================================================\n",
      "Epoch [3209/5000] | Time: 0.26s\n",
      "(Training) Loss: 976153.1897\n",
      "(Validation) Loss: 995930.0317, MAE: 3819.2739, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [3210/5000] | Time: 0.26s\n",
      "(Training) Loss: 978341.5019\n",
      "(Validation) Loss: 995774.4102, MAE: 3819.0002, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [3211/5000] | Time: 0.21s\n",
      "(Training) Loss: 965321.0292\n",
      "(Validation) Loss: 995627.2914, MAE: 3819.7949, R2: 0.1595\n",
      "==========================================================================================\n",
      "Epoch [3212/5000] | Time: 0.35s\n",
      "(Training) Loss: 957733.6942\n",
      "(Validation) Loss: 989335.4108, MAE: 3812.1018, R2: 0.1647\n",
      "==========================================================================================\n",
      "Epoch [3213/5000] | Time: 0.22s\n",
      "(Training) Loss: 976427.9816\n",
      "(Validation) Loss: 995211.5810, MAE: 3825.8101, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [3214/5000] | Time: 0.20s\n",
      "(Training) Loss: 957819.2846\n",
      "(Validation) Loss: 995031.8070, MAE: 3819.7212, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [3215/5000] | Time: 0.24s\n",
      "(Training) Loss: 958677.0971\n",
      "(Validation) Loss: 994876.8356, MAE: 3819.6416, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [3216/5000] | Time: 0.24s\n",
      "(Training) Loss: 961976.8547\n",
      "(Validation) Loss: 994712.6451, MAE: 3818.1248, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [3217/5000] | Time: 0.22s\n",
      "(Training) Loss: 972560.3985\n",
      "(Validation) Loss: 994546.2959, MAE: 3814.8623, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [3218/5000] | Time: 0.23s\n",
      "(Training) Loss: 972470.4451\n",
      "(Validation) Loss: 994394.1435, MAE: 3814.6841, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [3219/5000] | Time: 0.20s\n",
      "(Training) Loss: 957269.5577\n",
      "(Validation) Loss: 994241.2698, MAE: 3818.8223, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [3220/5000] | Time: 0.20s\n",
      "(Training) Loss: 967472.4181\n",
      "(Validation) Loss: 994076.9321, MAE: 3813.4590, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [3221/5000] | Time: 0.22s\n",
      "(Training) Loss: 958672.4258\n",
      "(Validation) Loss: 993920.2337, MAE: 3813.8667, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [3222/5000] | Time: 0.21s\n",
      "(Training) Loss: 956646.6516\n",
      "(Validation) Loss: 993762.6921, MAE: 3812.2524, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [3223/5000] | Time: 0.23s\n",
      "(Training) Loss: 995300.1510\n",
      "(Validation) Loss: 993609.3460, MAE: 3812.4399, R2: 0.1612\n",
      "==========================================================================================\n",
      "Epoch [3224/5000] | Time: 0.29s\n",
      "(Training) Loss: 963427.2798\n",
      "(Validation) Loss: 993684.8711, MAE: 3814.6150, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [3225/5000] | Time: 0.23s\n",
      "(Training) Loss: 970183.3534\n",
      "(Validation) Loss: 993296.3556, MAE: 3810.6924, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [3226/5000] | Time: 0.26s\n",
      "(Training) Loss: 953381.7237\n",
      "(Validation) Loss: 993141.2571, MAE: 3811.4143, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [3227/5000] | Time: 0.22s\n",
      "(Training) Loss: 959078.6231\n",
      "(Validation) Loss: 992984.4114, MAE: 3809.3625, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [3228/5000] | Time: 0.23s\n",
      "(Training) Loss: 980445.2878\n",
      "(Validation) Loss: 992829.1352, MAE: 3809.9207, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [3229/5000] | Time: 0.20s\n",
      "(Training) Loss: 972159.3369\n",
      "(Validation) Loss: 992674.8597, MAE: 3809.6597, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [3230/5000] | Time: 0.23s\n",
      "(Training) Loss: 957195.0006\n",
      "(Validation) Loss: 992516.0330, MAE: 3807.2126, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [3231/5000] | Time: 0.24s\n",
      "(Training) Loss: 963212.5647\n",
      "(Validation) Loss: 992370.3517, MAE: 3809.2866, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [3232/5000] | Time: 0.25s\n",
      "(Training) Loss: 980014.7043\n",
      "(Validation) Loss: 992207.0400, MAE: 3805.9407, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [3233/5000] | Time: 0.25s\n",
      "(Training) Loss: 959319.8913\n",
      "(Validation) Loss: 992048.7873, MAE: 3804.8372, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [3234/5000] | Time: 0.28s\n",
      "(Training) Loss: 966347.5279\n",
      "(Validation) Loss: 991906.5702, MAE: 3808.5254, R2: 0.1626\n",
      "==========================================================================================\n",
      "Epoch [3235/5000] | Time: 0.27s\n",
      "(Training) Loss: 960120.5635\n",
      "(Validation) Loss: 991745.6102, MAE: 3806.0696, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [3236/5000] | Time: 0.21s\n",
      "(Training) Loss: 963251.3223\n",
      "(Validation) Loss: 991588.5206, MAE: 3803.6028, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [3237/5000] | Time: 0.25s\n",
      "(Training) Loss: 962935.4124\n",
      "(Validation) Loss: 991435.7435, MAE: 3803.8540, R2: 0.1630\n",
      "==========================================================================================\n",
      "Epoch [3238/5000] | Time: 0.31s\n",
      "(Training) Loss: 963522.1865\n",
      "(Validation) Loss: 991283.0476, MAE: 3803.3406, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [3239/5000] | Time: 0.27s\n",
      "(Training) Loss: 964457.1098\n",
      "(Validation) Loss: 991130.5448, MAE: 3803.0796, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [3240/5000] | Time: 0.26s\n",
      "(Training) Loss: 963587.5444\n",
      "(Validation) Loss: 990971.2711, MAE: 3800.5740, R2: 0.1634\n",
      "==========================================================================================\n",
      "Epoch [3241/5000] | Time: 0.26s\n",
      "(Training) Loss: 960286.5152\n",
      "(Validation) Loss: 990823.3956, MAE: 3807.6902, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [3242/5000] | Time: 0.22s\n",
      "(Training) Loss: 978603.7024\n",
      "(Validation) Loss: 990669.2317, MAE: 3804.0679, R2: 0.1636\n",
      "==========================================================================================\n",
      "Epoch [3243/5000] | Time: 0.26s\n",
      "(Training) Loss: 960706.3585\n",
      "(Validation) Loss: 990515.0375, MAE: 3802.8374, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [3244/5000] | Time: 0.25s\n",
      "(Training) Loss: 955416.4181\n",
      "(Validation) Loss: 990362.5956, MAE: 3802.5061, R2: 0.1639\n",
      "==========================================================================================\n",
      "Epoch [3245/5000] | Time: 0.24s\n",
      "(Training) Loss: 959492.7513\n",
      "(Validation) Loss: 990211.7740, MAE: 3802.4150, R2: 0.1640\n",
      "==========================================================================================\n",
      "Epoch [3246/5000] | Time: 0.26s\n",
      "(Training) Loss: 953885.0577\n",
      "(Validation) Loss: 990053.9581, MAE: 3800.5410, R2: 0.1641\n",
      "==========================================================================================\n",
      "Epoch [3247/5000] | Time: 0.25s\n",
      "(Training) Loss: 968097.7678\n",
      "(Validation) Loss: 989900.9676, MAE: 3798.8374, R2: 0.1643\n",
      "==========================================================================================\n",
      "Epoch [3248/5000] | Time: 0.26s\n",
      "(Training) Loss: 964835.4803\n",
      "(Validation) Loss: 989749.1556, MAE: 3799.4609, R2: 0.1644\n",
      "==========================================================================================\n",
      "Epoch [3249/5000] | Time: 0.33s\n",
      "(Training) Loss: 966114.8541\n",
      "(Validation) Loss: 989591.3244, MAE: 3797.2380, R2: 0.1645\n",
      "==========================================================================================\n",
      "Epoch [3250/5000] | Time: 0.30s\n",
      "(Training) Loss: 960967.7348\n",
      "(Validation) Loss: 989441.3206, MAE: 3798.3054, R2: 0.1646\n",
      "==========================================================================================\n",
      "Epoch [3251/5000] | Time: 0.29s\n",
      "(Training) Loss: 950233.7998\n",
      "(Validation) Loss: 989284.4698, MAE: 3796.6296, R2: 0.1648\n",
      "==========================================================================================\n",
      "Epoch [3252/5000] | Time: 0.24s\n",
      "(Training) Loss: 976183.1973\n",
      "(Validation) Loss: 989135.0756, MAE: 3796.8201, R2: 0.1649\n",
      "==========================================================================================\n",
      "Epoch [3253/5000] | Time: 0.28s\n",
      "(Training) Loss: 993591.3718\n",
      "(Validation) Loss: 988976.4876, MAE: 3795.5679, R2: 0.1650\n",
      "==========================================================================================\n",
      "Epoch [3254/5000] | Time: 0.27s\n",
      "(Training) Loss: 973680.9086\n",
      "(Validation) Loss: 988828.6121, MAE: 3796.1743, R2: 0.1651\n",
      "==========================================================================================\n",
      "Epoch [3255/5000] | Time: 0.24s\n",
      "(Training) Loss: 962164.4378\n",
      "(Validation) Loss: 988670.1867, MAE: 3794.7432, R2: 0.1653\n",
      "==========================================================================================\n",
      "Epoch [3256/5000] | Time: 0.24s\n",
      "(Training) Loss: 953505.1199\n",
      "(Validation) Loss: 988515.5048, MAE: 3794.6096, R2: 0.1654\n",
      "==========================================================================================\n",
      "Epoch [3257/5000] | Time: 0.26s\n",
      "(Training) Loss: 948652.4794\n",
      "(Validation) Loss: 988359.1162, MAE: 3791.6016, R2: 0.1655\n",
      "==========================================================================================\n",
      "Epoch [3258/5000] | Time: 0.33s\n",
      "(Training) Loss: 955303.9968\n",
      "(Validation) Loss: 988219.6622, MAE: 3795.5676, R2: 0.1657\n",
      "==========================================================================================\n",
      "Epoch [3259/5000] | Time: 0.21s\n",
      "(Training) Loss: 951786.6453\n",
      "(Validation) Loss: 988086.9130, MAE: 3797.6851, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [3260/5000] | Time: 0.25s\n",
      "(Training) Loss: 964308.2792\n",
      "(Validation) Loss: 987916.9727, MAE: 3795.0496, R2: 0.1659\n",
      "==========================================================================================\n",
      "Epoch [3261/5000] | Time: 0.19s\n",
      "(Training) Loss: 952861.6701\n",
      "(Validation) Loss: 987760.2286, MAE: 3793.4141, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3262/5000] | Time: 0.20s\n",
      "(Training) Loss: 967209.1872\n",
      "(Validation) Loss: 987604.1752, MAE: 3790.4531, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3263/5000] | Time: 0.26s\n",
      "(Training) Loss: 971655.0901\n",
      "(Validation) Loss: 987454.7454, MAE: 3790.4739, R2: 0.1663\n",
      "==========================================================================================\n",
      "Epoch [3264/5000] | Time: 0.30s\n",
      "(Training) Loss: 954524.8274\n",
      "(Validation) Loss: 987299.7943, MAE: 3790.0105, R2: 0.1664\n",
      "==========================================================================================\n",
      "Epoch [3265/5000] | Time: 0.29s\n",
      "(Training) Loss: 953174.1662\n",
      "(Validation) Loss: 987145.1581, MAE: 3788.2737, R2: 0.1665\n",
      "==========================================================================================\n",
      "Epoch [3266/5000] | Time: 0.27s\n",
      "(Training) Loss: 958038.2018\n",
      "(Validation) Loss: 986997.5010, MAE: 3789.5891, R2: 0.1667\n",
      "==========================================================================================\n",
      "Epoch [3267/5000] | Time: 0.22s\n",
      "(Training) Loss: 958606.8046\n",
      "(Validation) Loss: 986842.5854, MAE: 3790.6267, R2: 0.1668\n",
      "==========================================================================================\n",
      "Epoch [3268/5000] | Time: 0.28s\n",
      "(Training) Loss: 962766.4683\n",
      "(Validation) Loss: 986709.3079, MAE: 3793.8899, R2: 0.1669\n",
      "==========================================================================================\n",
      "Epoch [3269/5000] | Time: 0.29s\n",
      "(Training) Loss: 953149.9613\n",
      "(Validation) Loss: 986564.0787, MAE: 3793.8701, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3270/5000] | Time: 0.19s\n",
      "(Training) Loss: 949473.7367\n",
      "(Validation) Loss: 986388.4343, MAE: 3789.1606, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3271/5000] | Time: 0.18s\n",
      "(Training) Loss: 952005.7306\n",
      "(Validation) Loss: 986240.5079, MAE: 3787.5625, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3272/5000] | Time: 0.18s\n",
      "(Training) Loss: 951916.2398\n",
      "(Validation) Loss: 986094.6844, MAE: 3788.4473, R2: 0.1674\n",
      "==========================================================================================\n",
      "Epoch [3273/5000] | Time: 0.21s\n",
      "(Training) Loss: 952269.5990\n",
      "(Validation) Loss: 985938.6362, MAE: 3788.2952, R2: 0.1676\n",
      "==========================================================================================\n",
      "Epoch [3274/5000] | Time: 0.19s\n",
      "(Training) Loss: 963629.2481\n",
      "(Validation) Loss: 985795.4337, MAE: 3787.7893, R2: 0.1677\n",
      "==========================================================================================\n",
      "Epoch [3275/5000] | Time: 0.20s\n",
      "(Training) Loss: 969961.6180\n",
      "(Validation) Loss: 985640.6654, MAE: 3787.3918, R2: 0.1678\n",
      "==========================================================================================\n",
      "Epoch [3276/5000] | Time: 0.22s\n",
      "(Training) Loss: 953127.4549\n",
      "(Validation) Loss: 986644.9575, MAE: 3797.5933, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3277/5000] | Time: 0.24s\n",
      "(Training) Loss: 957209.2214\n",
      "(Validation) Loss: 986492.1295, MAE: 3795.1785, R2: 0.1671\n",
      "==========================================================================================\n",
      "Epoch [3278/5000] | Time: 0.27s\n",
      "(Training) Loss: 970153.6897\n",
      "(Validation) Loss: 986348.8711, MAE: 3792.3096, R2: 0.1672\n",
      "==========================================================================================\n",
      "Epoch [3279/5000] | Time: 0.20s\n",
      "(Training) Loss: 952959.5723\n",
      "(Validation) Loss: 986204.0635, MAE: 3791.2678, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3280/5000] | Time: 0.25s\n",
      "(Training) Loss: 950043.4543\n",
      "(Validation) Loss: 986058.7225, MAE: 3791.7678, R2: 0.1675\n",
      "==========================================================================================\n",
      "Epoch [3281/5000] | Time: 0.23s\n",
      "(Training) Loss: 954059.1618\n",
      "(Validation) Loss: 985905.3105, MAE: 3788.9475, R2: 0.1676\n",
      "==========================================================================================\n",
      "Epoch [3282/5000] | Time: 0.30s\n",
      "(Training) Loss: 953752.3503\n",
      "(Validation) Loss: 985795.1441, MAE: 3796.9619, R2: 0.1677\n",
      "==========================================================================================\n",
      "Epoch [3283/5000] | Time: 0.28s\n",
      "(Training) Loss: 956728.5266\n",
      "(Validation) Loss: 985608.6298, MAE: 3786.4778, R2: 0.1678\n",
      "==========================================================================================\n",
      "Epoch [3284/5000] | Time: 0.33s\n",
      "(Training) Loss: 961948.4162\n",
      "(Validation) Loss: 985471.8375, MAE: 3788.9919, R2: 0.1679\n",
      "==========================================================================================\n",
      "Epoch [3285/5000] | Time: 0.36s\n",
      "(Training) Loss: 948711.4803\n",
      "(Validation) Loss: 985315.3625, MAE: 3785.0220, R2: 0.1681\n",
      "==========================================================================================\n",
      "Epoch [3286/5000] | Time: 0.34s\n",
      "(Training) Loss: 947787.7925\n",
      "(Validation) Loss: 985172.1295, MAE: 3784.9600, R2: 0.1682\n",
      "==========================================================================================\n",
      "Epoch [3287/5000] | Time: 0.30s\n",
      "(Training) Loss: 948843.3801\n",
      "(Validation) Loss: 985022.7505, MAE: 3782.8911, R2: 0.1683\n",
      "==========================================================================================\n",
      "Epoch [3288/5000] | Time: 0.28s\n",
      "(Training) Loss: 955182.7722\n",
      "(Validation) Loss: 984891.5048, MAE: 3784.9082, R2: 0.1684\n",
      "==========================================================================================\n",
      "Epoch [3289/5000] | Time: 0.29s\n",
      "(Training) Loss: 947998.2418\n",
      "(Validation) Loss: 984732.2260, MAE: 3782.3069, R2: 0.1686\n",
      "==========================================================================================\n",
      "Epoch [3290/5000] | Time: 0.29s\n",
      "(Training) Loss: 973249.2430\n",
      "(Validation) Loss: 984593.8438, MAE: 3783.7439, R2: 0.1687\n",
      "==========================================================================================\n",
      "Epoch [3291/5000] | Time: 0.25s\n",
      "(Training) Loss: 957454.8464\n",
      "(Validation) Loss: 984475.3829, MAE: 3787.3110, R2: 0.1688\n",
      "==========================================================================================\n",
      "Epoch [3292/5000] | Time: 0.36s\n",
      "(Training) Loss: 943488.5869\n",
      "(Validation) Loss: 984305.2038, MAE: 3784.5168, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [3293/5000] | Time: 0.35s\n",
      "(Training) Loss: 972540.3953\n",
      "(Validation) Loss: 984160.3403, MAE: 3783.9600, R2: 0.1690\n",
      "==========================================================================================\n",
      "Epoch [3294/5000] | Time: 0.32s\n",
      "(Training) Loss: 973314.9797\n",
      "(Validation) Loss: 984000.3810, MAE: 3779.4790, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [3295/5000] | Time: 0.26s\n",
      "(Training) Loss: 955287.8934\n",
      "(Validation) Loss: 983852.1448, MAE: 3779.2705, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [3296/5000] | Time: 0.24s\n",
      "(Training) Loss: 965485.9924\n",
      "(Validation) Loss: 983709.0895, MAE: 3779.4761, R2: 0.1694\n",
      "==========================================================================================\n",
      "Epoch [3297/5000] | Time: 0.28s\n",
      "(Training) Loss: 947240.2614\n",
      "(Validation) Loss: 983564.2514, MAE: 3779.3870, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [3298/5000] | Time: 0.28s\n",
      "(Training) Loss: 942638.7125\n",
      "(Validation) Loss: 983415.6648, MAE: 3779.0342, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [3299/5000] | Time: 0.23s\n",
      "(Training) Loss: 954180.0157\n",
      "(Validation) Loss: 983267.2152, MAE: 3775.2305, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3300/5000] | Time: 0.26s\n",
      "(Training) Loss: 949478.5171\n",
      "(Validation) Loss: 983129.9556, MAE: 3777.8733, R2: 0.1699\n",
      "==========================================================================================\n",
      "Epoch [3301/5000] | Time: 0.30s\n",
      "(Training) Loss: 952583.0907\n",
      "(Validation) Loss: 982982.9537, MAE: 3776.0562, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3302/5000] | Time: 0.28s\n",
      "(Training) Loss: 959906.3947\n",
      "(Validation) Loss: 982837.4603, MAE: 3776.7104, R2: 0.1701\n",
      "==========================================================================================\n",
      "Epoch [3303/5000] | Time: 0.27s\n",
      "(Training) Loss: 953740.5990\n",
      "(Validation) Loss: 982697.8337, MAE: 3777.5286, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [3304/5000] | Time: 0.27s\n",
      "(Training) Loss: 967564.4416\n",
      "(Validation) Loss: 982545.5695, MAE: 3775.9473, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [3305/5000] | Time: 0.25s\n",
      "(Training) Loss: 959178.4232\n",
      "(Validation) Loss: 982395.8146, MAE: 3773.9463, R2: 0.1705\n",
      "==========================================================================================\n",
      "Epoch [3306/5000] | Time: 0.23s\n",
      "(Training) Loss: 958286.6041\n",
      "(Validation) Loss: 982259.5048, MAE: 3775.0242, R2: 0.1706\n",
      "==========================================================================================\n",
      "Epoch [3307/5000] | Time: 0.23s\n",
      "(Training) Loss: 956138.7513\n",
      "(Validation) Loss: 982105.6660, MAE: 3774.5803, R2: 0.1707\n",
      "==========================================================================================\n",
      "Epoch [3308/5000] | Time: 0.23s\n",
      "(Training) Loss: 960860.0044\n",
      "(Validation) Loss: 988084.6578, MAE: 3795.1841, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [3309/5000] | Time: 0.24s\n",
      "(Training) Loss: 965348.1713\n",
      "(Validation) Loss: 987914.5651, MAE: 3791.3032, R2: 0.1659\n",
      "==========================================================================================\n",
      "Epoch [3310/5000] | Time: 0.20s\n",
      "(Training) Loss: 963123.2849\n",
      "(Validation) Loss: 987760.2286, MAE: 3791.1843, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3311/5000] | Time: 0.20s\n",
      "(Training) Loss: 962969.5964\n",
      "(Validation) Loss: 987608.9752, MAE: 3792.3806, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3312/5000] | Time: 0.19s\n",
      "(Training) Loss: 958729.0397\n",
      "(Validation) Loss: 987448.4013, MAE: 3790.3977, R2: 0.1663\n",
      "==========================================================================================\n",
      "Epoch [3313/5000] | Time: 0.25s\n",
      "(Training) Loss: 965322.2519\n",
      "(Validation) Loss: 987311.3397, MAE: 3797.3193, R2: 0.1664\n",
      "==========================================================================================\n",
      "Epoch [3314/5000] | Time: 0.24s\n",
      "(Training) Loss: 950565.4746\n",
      "(Validation) Loss: 992775.9187, MAE: 3813.8147, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [3315/5000] | Time: 0.24s\n",
      "(Training) Loss: 964412.0736\n",
      "(Validation) Loss: 992597.9937, MAE: 3809.9548, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [3316/5000] | Time: 0.22s\n",
      "(Training) Loss: 957224.1637\n",
      "(Validation) Loss: 992435.2914, MAE: 3810.5479, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [3317/5000] | Time: 0.26s\n",
      "(Training) Loss: 976713.0381\n",
      "(Validation) Loss: 992270.3797, MAE: 3808.0225, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [3318/5000] | Time: 0.32s\n",
      "(Training) Loss: 961128.8014\n",
      "(Validation) Loss: 992110.6184, MAE: 3808.1133, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [3319/5000] | Time: 0.29s\n",
      "(Training) Loss: 957419.3807\n",
      "(Validation) Loss: 991947.6673, MAE: 3807.5208, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [3320/5000] | Time: 0.25s\n",
      "(Training) Loss: 967200.3972\n",
      "(Validation) Loss: 991791.0044, MAE: 3808.2607, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [3321/5000] | Time: 0.25s\n",
      "(Training) Loss: 954834.4365\n",
      "(Validation) Loss: 991634.5244, MAE: 3807.2800, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [3322/5000] | Time: 0.25s\n",
      "(Training) Loss: 991141.9067\n",
      "(Validation) Loss: 991471.9746, MAE: 3805.8735, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [3323/5000] | Time: 0.23s\n",
      "(Training) Loss: 955156.2379\n",
      "(Validation) Loss: 991311.8933, MAE: 3805.8755, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [3324/5000] | Time: 0.27s\n",
      "(Training) Loss: 969216.9105\n",
      "(Validation) Loss: 991160.1676, MAE: 3805.9207, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [3325/5000] | Time: 0.23s\n",
      "(Training) Loss: 969629.6421\n",
      "(Validation) Loss: 990997.2114, MAE: 3803.3723, R2: 0.1633\n",
      "==========================================================================================\n",
      "Epoch [3326/5000] | Time: 0.23s\n",
      "(Training) Loss: 975759.7132\n",
      "(Validation) Loss: 990845.6584, MAE: 3803.4058, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [3327/5000] | Time: 0.24s\n",
      "(Training) Loss: 960009.6396\n",
      "(Validation) Loss: 990685.5162, MAE: 3802.6765, R2: 0.1636\n",
      "==========================================================================================\n",
      "Epoch [3328/5000] | Time: 0.27s\n",
      "(Training) Loss: 963447.8668\n",
      "(Validation) Loss: 990530.4178, MAE: 3802.1511, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [3329/5000] | Time: 0.23s\n",
      "(Training) Loss: 951454.0558\n",
      "(Validation) Loss: 990370.8292, MAE: 3801.0469, R2: 0.1639\n",
      "==========================================================================================\n",
      "Epoch [3330/5000] | Time: 0.25s\n",
      "(Training) Loss: 961095.8439\n",
      "(Validation) Loss: 990218.4838, MAE: 3801.0178, R2: 0.1640\n",
      "==========================================================================================\n",
      "Epoch [3331/5000] | Time: 0.25s\n",
      "(Training) Loss: 951707.5644\n",
      "(Validation) Loss: 990064.6095, MAE: 3800.8184, R2: 0.1641\n",
      "==========================================================================================\n",
      "Epoch [3332/5000] | Time: 0.24s\n",
      "(Training) Loss: 964301.3033\n",
      "(Validation) Loss: 989911.2178, MAE: 3800.8064, R2: 0.1642\n",
      "==========================================================================================\n",
      "Epoch [3333/5000] | Time: 0.25s\n",
      "(Training) Loss: 962325.8566\n",
      "(Validation) Loss: 989757.1200, MAE: 3800.1787, R2: 0.1644\n",
      "==========================================================================================\n",
      "Epoch [3334/5000] | Time: 0.26s\n",
      "(Training) Loss: 960141.4093\n",
      "(Validation) Loss: 989598.4356, MAE: 3798.5613, R2: 0.1645\n",
      "==========================================================================================\n",
      "Epoch [3335/5000] | Time: 0.29s\n",
      "(Training) Loss: 958778.5533\n",
      "(Validation) Loss: 989449.2190, MAE: 3799.0256, R2: 0.1646\n",
      "==========================================================================================\n",
      "Epoch [3336/5000] | Time: 0.23s\n",
      "(Training) Loss: 965977.6739\n",
      "(Validation) Loss: 989292.9422, MAE: 3798.4314, R2: 0.1648\n",
      "==========================================================================================\n",
      "Epoch [3337/5000] | Time: 0.28s\n",
      "(Training) Loss: 951755.1386\n",
      "(Validation) Loss: 989137.5797, MAE: 3799.0383, R2: 0.1649\n",
      "==========================================================================================\n",
      "Epoch [3338/5000] | Time: 0.23s\n",
      "(Training) Loss: 965021.3230\n",
      "(Validation) Loss: 988986.4229, MAE: 3796.9768, R2: 0.1650\n",
      "==========================================================================================\n",
      "Epoch [3339/5000] | Time: 0.27s\n",
      "(Training) Loss: 963283.9277\n",
      "(Validation) Loss: 988832.4927, MAE: 3796.9958, R2: 0.1651\n",
      "==========================================================================================\n",
      "Epoch [3340/5000] | Time: 0.26s\n",
      "(Training) Loss: 961281.5489\n",
      "(Validation) Loss: 988683.4489, MAE: 3797.6477, R2: 0.1653\n",
      "==========================================================================================\n",
      "Epoch [3341/5000] | Time: 0.27s\n",
      "(Training) Loss: 975143.8604\n",
      "(Validation) Loss: 988598.8317, MAE: 3799.9309, R2: 0.1653\n",
      "==========================================================================================\n",
      "Epoch [3342/5000] | Time: 0.25s\n",
      "(Training) Loss: 954814.8572\n",
      "(Validation) Loss: 988447.7257, MAE: 3801.0337, R2: 0.1655\n",
      "==========================================================================================\n",
      "Epoch [3343/5000] | Time: 0.30s\n",
      "(Training) Loss: 961762.9829\n",
      "(Validation) Loss: 988291.8400, MAE: 3798.8179, R2: 0.1656\n",
      "==========================================================================================\n",
      "Epoch [3344/5000] | Time: 0.28s\n",
      "(Training) Loss: 961126.1079\n",
      "(Validation) Loss: 988141.0489, MAE: 3799.9019, R2: 0.1657\n",
      "==========================================================================================\n",
      "Epoch [3345/5000] | Time: 0.26s\n",
      "(Training) Loss: 948680.4756\n",
      "(Validation) Loss: 987987.8197, MAE: 3798.7639, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [3346/5000] | Time: 0.25s\n",
      "(Training) Loss: 955208.0381\n",
      "(Validation) Loss: 987829.5568, MAE: 3796.9199, R2: 0.1660\n",
      "==========================================================================================\n",
      "Epoch [3347/5000] | Time: 0.24s\n",
      "(Training) Loss: 968734.5723\n",
      "(Validation) Loss: 987690.2806, MAE: 3806.6343, R2: 0.1661\n",
      "==========================================================================================\n",
      "Epoch [3348/5000] | Time: 0.27s\n",
      "(Training) Loss: 985426.9419\n",
      "(Validation) Loss: 987524.9117, MAE: 3798.0557, R2: 0.1662\n",
      "==========================================================================================\n",
      "Epoch [3349/5000] | Time: 0.26s\n",
      "(Training) Loss: 952872.2335\n",
      "(Validation) Loss: 987373.6178, MAE: 3798.4114, R2: 0.1664\n",
      "==========================================================================================\n",
      "Epoch [3350/5000] | Time: 0.25s\n",
      "(Training) Loss: 964269.0025\n",
      "(Validation) Loss: 987222.2578, MAE: 3798.2190, R2: 0.1665\n",
      "==========================================================================================\n",
      "Epoch [3351/5000] | Time: 0.33s\n",
      "(Training) Loss: 955981.4727\n",
      "(Validation) Loss: 987061.8870, MAE: 3794.9189, R2: 0.1666\n",
      "==========================================================================================\n",
      "Epoch [3352/5000] | Time: 0.29s\n",
      "(Training) Loss: 953480.1681\n",
      "(Validation) Loss: 986908.2413, MAE: 3793.9666, R2: 0.1667\n",
      "==========================================================================================\n",
      "Epoch [3353/5000] | Time: 0.24s\n",
      "(Training) Loss: 972983.2893\n",
      "(Validation) Loss: 986760.0813, MAE: 3795.1987, R2: 0.1669\n",
      "==========================================================================================\n",
      "Epoch [3354/5000] | Time: 0.29s\n",
      "(Training) Loss: 960619.3515\n",
      "(Validation) Loss: 986608.4876, MAE: 3794.6489, R2: 0.1670\n",
      "==========================================================================================\n",
      "Epoch [3355/5000] | Time: 0.31s\n",
      "(Training) Loss: 963798.5044\n",
      "(Validation) Loss: 986448.5384, MAE: 3793.0891, R2: 0.1671\n",
      "==========================================================================================\n",
      "Epoch [3356/5000] | Time: 0.28s\n",
      "(Training) Loss: 958847.0381\n",
      "(Validation) Loss: 986294.1867, MAE: 3792.3577, R2: 0.1673\n",
      "==========================================================================================\n",
      "Epoch [3357/5000] | Time: 0.27s\n",
      "(Training) Loss: 956802.9905\n",
      "(Validation) Loss: 986137.3917, MAE: 3790.4829, R2: 0.1674\n",
      "==========================================================================================\n",
      "Epoch [3358/5000] | Time: 0.27s\n",
      "(Training) Loss: 956112.3991\n",
      "(Validation) Loss: 985986.2044, MAE: 3790.2200, R2: 0.1675\n",
      "==========================================================================================\n",
      "Epoch [3359/5000] | Time: 0.25s\n",
      "(Training) Loss: 978716.3813\n",
      "(Validation) Loss: 985836.8762, MAE: 3790.3911, R2: 0.1676\n",
      "==========================================================================================\n",
      "Epoch [3360/5000] | Time: 0.23s\n",
      "(Training) Loss: 949068.7655\n",
      "(Validation) Loss: 985681.8997, MAE: 3789.9822, R2: 0.1678\n",
      "==========================================================================================\n",
      "Epoch [3361/5000] | Time: 0.27s\n",
      "(Training) Loss: 953332.1161\n",
      "(Validation) Loss: 985532.3378, MAE: 3790.5920, R2: 0.1679\n",
      "==========================================================================================\n",
      "Epoch [3362/5000] | Time: 0.21s\n",
      "(Training) Loss: 984272.4594\n",
      "(Validation) Loss: 985374.8063, MAE: 3787.7202, R2: 0.1680\n",
      "==========================================================================================\n",
      "Epoch [3363/5000] | Time: 0.22s\n",
      "(Training) Loss: 957944.6463\n",
      "(Validation) Loss: 985220.4495, MAE: 3787.2336, R2: 0.1681\n",
      "==========================================================================================\n",
      "Epoch [3364/5000] | Time: 0.22s\n",
      "(Training) Loss: 962912.3160\n",
      "(Validation) Loss: 985070.7911, MAE: 3787.3137, R2: 0.1683\n",
      "==========================================================================================\n",
      "Epoch [3365/5000] | Time: 0.20s\n",
      "(Training) Loss: 956649.3280\n",
      "(Validation) Loss: 984914.0470, MAE: 3785.9353, R2: 0.1684\n",
      "==========================================================================================\n",
      "Epoch [3366/5000] | Time: 0.21s\n",
      "(Training) Loss: 957076.6304\n",
      "(Validation) Loss: 984761.7117, MAE: 3785.3074, R2: 0.1685\n",
      "==========================================================================================\n",
      "Epoch [3367/5000] | Time: 0.23s\n",
      "(Training) Loss: 957427.4607\n",
      "(Validation) Loss: 984609.3613, MAE: 3784.7314, R2: 0.1687\n",
      "==========================================================================================\n",
      "Epoch [3368/5000] | Time: 0.21s\n",
      "(Training) Loss: 963634.0412\n",
      "(Validation) Loss: 984458.9308, MAE: 3785.1160, R2: 0.1688\n",
      "==========================================================================================\n",
      "Epoch [3369/5000] | Time: 0.20s\n",
      "(Training) Loss: 953284.3756\n",
      "(Validation) Loss: 984307.8654, MAE: 3784.9983, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [3370/5000] | Time: 0.22s\n",
      "(Training) Loss: 950247.3883\n",
      "(Validation) Loss: 984152.1676, MAE: 3785.1501, R2: 0.1690\n",
      "==========================================================================================\n",
      "Epoch [3371/5000] | Time: 0.30s\n",
      "(Training) Loss: 950141.2747\n",
      "(Validation) Loss: 984002.8241, MAE: 3783.5476, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [3372/5000] | Time: 0.29s\n",
      "(Training) Loss: 944219.2919\n",
      "(Validation) Loss: 983860.9117, MAE: 3785.3564, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [3373/5000] | Time: 0.27s\n",
      "(Training) Loss: 997510.3496\n",
      "(Validation) Loss: 983722.2146, MAE: 3787.0500, R2: 0.1694\n",
      "==========================================================================================\n",
      "Epoch [3374/5000] | Time: 0.24s\n",
      "(Training) Loss: 952616.8369\n",
      "(Validation) Loss: 983544.4978, MAE: 3782.0139, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [3375/5000] | Time: 0.29s\n",
      "(Training) Loss: 950823.3978\n",
      "(Validation) Loss: 983417.0260, MAE: 3787.4717, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [3376/5000] | Time: 0.25s\n",
      "(Training) Loss: 965387.4213\n",
      "(Validation) Loss: 983238.6997, MAE: 3780.6555, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3377/5000] | Time: 0.21s\n",
      "(Training) Loss: 957737.6003\n",
      "(Validation) Loss: 983268.6375, MAE: 3792.7366, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [3378/5000] | Time: 0.22s\n",
      "(Training) Loss: 951764.5451\n",
      "(Validation) Loss: 982968.6197, MAE: 3787.7009, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [3379/5000] | Time: 0.24s\n",
      "(Training) Loss: 948027.6853\n",
      "(Validation) Loss: 982787.7790, MAE: 3780.3953, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [3380/5000] | Time: 0.24s\n",
      "(Training) Loss: 949321.6034\n",
      "(Validation) Loss: 982635.7283, MAE: 3779.9055, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [3381/5000] | Time: 0.26s\n",
      "(Training) Loss: 955047.0311\n",
      "(Validation) Loss: 982488.4216, MAE: 3782.0579, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [3382/5000] | Time: 0.23s\n",
      "(Training) Loss: 970323.9588\n",
      "(Validation) Loss: 1023544.8178, MAE: 3916.1255, R2: 0.1362\n",
      "==========================================================================================\n",
      "Epoch [3383/5000] | Time: 0.21s\n",
      "(Training) Loss: 987835.8921\n",
      "(Validation) Loss: 1023377.0514, MAE: 3913.6826, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [3384/5000] | Time: 0.27s\n",
      "(Training) Loss: 1002439.6256\n",
      "(Validation) Loss: 1023213.3994, MAE: 3914.2615, R2: 0.1365\n",
      "==========================================================================================\n",
      "Epoch [3385/5000] | Time: 0.31s\n",
      "(Training) Loss: 997628.8211\n",
      "(Validation) Loss: 1023041.3359, MAE: 3911.9546, R2: 0.1366\n",
      "==========================================================================================\n",
      "Epoch [3386/5000] | Time: 0.27s\n",
      "(Training) Loss: 986761.4708\n",
      "(Validation) Loss: 1022880.5638, MAE: 3912.3223, R2: 0.1368\n",
      "==========================================================================================\n",
      "Epoch [3387/5000] | Time: 0.25s\n",
      "(Training) Loss: 979376.5262\n",
      "(Validation) Loss: 1022717.7803, MAE: 3913.5234, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [3388/5000] | Time: 0.28s\n",
      "(Training) Loss: 991285.0641\n",
      "(Validation) Loss: 1022555.6063, MAE: 3911.4785, R2: 0.1370\n",
      "==========================================================================================\n",
      "Epoch [3389/5000] | Time: 0.28s\n",
      "(Training) Loss: 980668.2668\n",
      "(Validation) Loss: 1022406.8165, MAE: 3914.8962, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [3390/5000] | Time: 0.28s\n",
      "(Training) Loss: 1012980.6948\n",
      "(Validation) Loss: 1022228.5917, MAE: 3909.9644, R2: 0.1373\n",
      "==========================================================================================\n",
      "Epoch [3391/5000] | Time: 0.31s\n",
      "(Training) Loss: 982806.6187\n",
      "(Validation) Loss: 1022065.7117, MAE: 3909.5234, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [3392/5000] | Time: 0.29s\n",
      "(Training) Loss: 979249.5955\n",
      "(Validation) Loss: 1021910.0546, MAE: 3910.3784, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [3393/5000] | Time: 0.23s\n",
      "(Training) Loss: 994347.0374\n",
      "(Validation) Loss: 1021753.5390, MAE: 3912.0442, R2: 0.1377\n",
      "==========================================================================================\n",
      "Epoch [3394/5000] | Time: 0.27s\n",
      "(Training) Loss: 978734.2333\n",
      "(Validation) Loss: 1021576.8533, MAE: 3908.2017, R2: 0.1378\n",
      "==========================================================================================\n",
      "Epoch [3395/5000] | Time: 0.31s\n",
      "(Training) Loss: 984745.9289\n",
      "(Validation) Loss: 1021422.7302, MAE: 3907.7996, R2: 0.1380\n",
      "==========================================================================================\n",
      "Epoch [3396/5000] | Time: 0.29s\n",
      "(Training) Loss: 999681.5895\n",
      "(Validation) Loss: 1021257.9911, MAE: 3906.6521, R2: 0.1381\n",
      "==========================================================================================\n",
      "Epoch [3397/5000] | Time: 0.29s\n",
      "(Training) Loss: 981645.4353\n",
      "(Validation) Loss: 1021089.0971, MAE: 3904.4504, R2: 0.1383\n",
      "==========================================================================================\n",
      "Epoch [3398/5000] | Time: 0.33s\n",
      "(Training) Loss: 989493.2906\n",
      "(Validation) Loss: 1020934.6540, MAE: 3905.1587, R2: 0.1384\n",
      "==========================================================================================\n",
      "Epoch [3399/5000] | Time: 0.34s\n",
      "(Training) Loss: 999735.3794\n",
      "(Validation) Loss: 1020768.3098, MAE: 3903.3220, R2: 0.1385\n",
      "==========================================================================================\n",
      "Epoch [3400/5000] | Time: 0.32s\n",
      "(Training) Loss: 1002668.3712\n",
      "(Validation) Loss: 1020611.6165, MAE: 3904.3120, R2: 0.1387\n",
      "==========================================================================================\n",
      "Epoch [3401/5000] | Time: 0.27s\n",
      "(Training) Loss: 985359.7145\n",
      "(Validation) Loss: 1020445.2419, MAE: 3902.8887, R2: 0.1388\n",
      "==========================================================================================\n",
      "Epoch [3402/5000] | Time: 0.33s\n",
      "(Training) Loss: 998578.5850\n",
      "(Validation) Loss: 1020292.9575, MAE: 3903.6099, R2: 0.1389\n",
      "==========================================================================================\n",
      "Epoch [3403/5000] | Time: 0.38s\n",
      "(Training) Loss: 983359.3039\n",
      "(Validation) Loss: 1020131.5606, MAE: 3903.4263, R2: 0.1391\n",
      "==========================================================================================\n",
      "Epoch [3404/5000] | Time: 0.37s\n",
      "(Training) Loss: 980259.6688\n",
      "(Validation) Loss: 1019965.8159, MAE: 3901.4521, R2: 0.1392\n",
      "==========================================================================================\n",
      "Epoch [3405/5000] | Time: 0.31s\n",
      "(Training) Loss: 993190.0089\n",
      "(Validation) Loss: 1019802.8495, MAE: 3899.7053, R2: 0.1393\n",
      "==========================================================================================\n",
      "Epoch [3406/5000] | Time: 0.28s\n",
      "(Training) Loss: 979292.4559\n",
      "(Validation) Loss: 1019641.8692, MAE: 3899.7170, R2: 0.1395\n",
      "==========================================================================================\n",
      "Epoch [3407/5000] | Time: 0.25s\n",
      "(Training) Loss: 995870.9727\n",
      "(Validation) Loss: 1019490.6362, MAE: 3901.2061, R2: 0.1396\n",
      "==========================================================================================\n",
      "Epoch [3408/5000] | Time: 0.25s\n",
      "(Training) Loss: 981436.8978\n",
      "(Validation) Loss: 1019321.1378, MAE: 3898.5193, R2: 0.1397\n",
      "==========================================================================================\n",
      "Epoch [3409/5000] | Time: 0.22s\n",
      "(Training) Loss: 983803.1967\n",
      "(Validation) Loss: 1019170.1333, MAE: 3900.6318, R2: 0.1399\n",
      "==========================================================================================\n",
      "Epoch [3410/5000] | Time: 0.23s\n",
      "(Training) Loss: 976584.9010\n",
      "(Validation) Loss: 1019002.2502, MAE: 3897.7336, R2: 0.1400\n",
      "==========================================================================================\n",
      "Epoch [3411/5000] | Time: 0.20s\n",
      "(Training) Loss: 984061.5641\n",
      "(Validation) Loss: 1018847.8222, MAE: 3898.2432, R2: 0.1401\n",
      "==========================================================================================\n",
      "Epoch [3412/5000] | Time: 0.23s\n",
      "(Training) Loss: 982563.0301\n",
      "(Validation) Loss: 1018700.8254, MAE: 3900.9810, R2: 0.1402\n",
      "==========================================================================================\n",
      "Epoch [3413/5000] | Time: 0.22s\n",
      "(Training) Loss: 979793.8585\n",
      "(Validation) Loss: 1018529.0362, MAE: 3898.6914, R2: 0.1404\n",
      "==========================================================================================\n",
      "Epoch [3414/5000] | Time: 0.28s\n",
      "(Training) Loss: 994095.2659\n",
      "(Validation) Loss: 1018371.3270, MAE: 3895.7092, R2: 0.1405\n",
      "==========================================================================================\n",
      "Epoch [3415/5000] | Time: 0.27s\n",
      "(Training) Loss: 989614.8020\n",
      "(Validation) Loss: 1018209.0260, MAE: 3894.8132, R2: 0.1407\n",
      "==========================================================================================\n",
      "Epoch [3416/5000] | Time: 0.28s\n",
      "(Training) Loss: 989540.2157\n",
      "(Validation) Loss: 1018052.7187, MAE: 3895.3899, R2: 0.1408\n",
      "==========================================================================================\n",
      "Epoch [3417/5000] | Time: 0.30s\n",
      "(Training) Loss: 988084.0470\n",
      "(Validation) Loss: 1017889.2140, MAE: 3893.9331, R2: 0.1409\n",
      "==========================================================================================\n",
      "Epoch [3418/5000] | Time: 0.33s\n",
      "(Training) Loss: 994154.4721\n",
      "(Validation) Loss: 1017728.7263, MAE: 3893.0117, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [3419/5000] | Time: 0.31s\n",
      "(Training) Loss: 981236.8890\n",
      "(Validation) Loss: 1017565.9022, MAE: 3891.7815, R2: 0.1412\n",
      "==========================================================================================\n",
      "Epoch [3420/5000] | Time: 0.31s\n",
      "(Training) Loss: 996784.4378\n",
      "(Validation) Loss: 1017409.2343, MAE: 3891.5095, R2: 0.1413\n",
      "==========================================================================================\n",
      "Epoch [3421/5000] | Time: 0.34s\n",
      "(Training) Loss: 1010407.4873\n",
      "(Validation) Loss: 1017250.7987, MAE: 3892.0056, R2: 0.1415\n",
      "==========================================================================================\n",
      "Epoch [3422/5000] | Time: 0.34s\n",
      "(Training) Loss: 993859.5895\n",
      "(Validation) Loss: 1017092.0076, MAE: 3891.9651, R2: 0.1416\n",
      "==========================================================================================\n",
      "Epoch [3423/5000] | Time: 0.31s\n",
      "(Training) Loss: 996077.8458\n",
      "(Validation) Loss: 1016937.7829, MAE: 3892.4443, R2: 0.1417\n",
      "==========================================================================================\n",
      "Epoch [3424/5000] | Time: 0.30s\n",
      "(Training) Loss: 994689.7449\n",
      "(Validation) Loss: 1016778.0063, MAE: 3891.9514, R2: 0.1418\n",
      "==========================================================================================\n",
      "Epoch [3425/5000] | Time: 0.28s\n",
      "(Training) Loss: 987178.7563\n",
      "(Validation) Loss: 1016610.5549, MAE: 3889.3149, R2: 0.1420\n",
      "==========================================================================================\n",
      "Epoch [3426/5000] | Time: 0.25s\n",
      "(Training) Loss: 992367.5635\n",
      "(Validation) Loss: 1016453.1860, MAE: 3888.3245, R2: 0.1421\n",
      "==========================================================================================\n",
      "Epoch [3427/5000] | Time: 0.25s\n",
      "(Training) Loss: 984108.9340\n",
      "(Validation) Loss: 1016295.7917, MAE: 3889.4819, R2: 0.1423\n",
      "==========================================================================================\n",
      "Epoch [3428/5000] | Time: 0.28s\n",
      "(Training) Loss: 982555.8839\n",
      "(Validation) Loss: 1016133.7956, MAE: 3887.6118, R2: 0.1424\n",
      "==========================================================================================\n",
      "Epoch [3429/5000] | Time: 0.36s\n",
      "(Training) Loss: 1002992.6999\n",
      "(Validation) Loss: 1015974.8876, MAE: 3886.6489, R2: 0.1425\n",
      "==========================================================================================\n",
      "Epoch [3430/5000] | Time: 0.29s\n",
      "(Training) Loss: 994070.9949\n",
      "(Validation) Loss: 1015820.7340, MAE: 3887.5215, R2: 0.1426\n",
      "==========================================================================================\n",
      "Epoch [3431/5000] | Time: 0.28s\n",
      "(Training) Loss: 996057.7513\n",
      "(Validation) Loss: 1015664.4724, MAE: 3887.8413, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [3432/5000] | Time: 0.35s\n",
      "(Training) Loss: 994978.1770\n",
      "(Validation) Loss: 1015496.9397, MAE: 3885.2578, R2: 0.1429\n",
      "==========================================================================================\n",
      "Epoch [3433/5000] | Time: 0.31s\n",
      "(Training) Loss: 990017.6453\n",
      "(Validation) Loss: 1015338.7479, MAE: 3884.6504, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [3434/5000] | Time: 0.29s\n",
      "(Training) Loss: 981945.2538\n",
      "(Validation) Loss: 1015181.8971, MAE: 3883.8149, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [3435/5000] | Time: 0.32s\n",
      "(Training) Loss: 993375.8852\n",
      "(Validation) Loss: 1015025.5492, MAE: 3885.0732, R2: 0.1433\n",
      "==========================================================================================\n",
      "Epoch [3436/5000] | Time: 0.26s\n",
      "(Training) Loss: 980431.7595\n",
      "(Validation) Loss: 1014864.6654, MAE: 3882.6177, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [3437/5000] | Time: 0.30s\n",
      "(Training) Loss: 982446.4378\n",
      "(Validation) Loss: 1014717.1606, MAE: 3885.9912, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [3438/5000] | Time: 0.30s\n",
      "(Training) Loss: 1006447.8604\n",
      "(Validation) Loss: 1014551.4311, MAE: 3882.0781, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [3439/5000] | Time: 0.35s\n",
      "(Training) Loss: 980590.4841\n",
      "(Validation) Loss: 1014394.1283, MAE: 3881.0051, R2: 0.1438\n",
      "==========================================================================================\n",
      "Epoch [3440/5000] | Time: 0.29s\n",
      "(Training) Loss: 971663.0649\n",
      "(Validation) Loss: 1014246.5371, MAE: 3883.2041, R2: 0.1440\n",
      "==========================================================================================\n",
      "Epoch [3441/5000] | Time: 0.32s\n",
      "(Training) Loss: 980920.2551\n",
      "(Validation) Loss: 1014085.0794, MAE: 3881.8645, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [3442/5000] | Time: 0.31s\n",
      "(Training) Loss: 975238.2893\n",
      "(Validation) Loss: 1013930.6159, MAE: 3881.2854, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [3443/5000] | Time: 0.29s\n",
      "(Training) Loss: 982174.4753\n",
      "(Validation) Loss: 1013767.0095, MAE: 3879.0342, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [3444/5000] | Time: 0.29s\n",
      "(Training) Loss: 986030.3306\n",
      "(Validation) Loss: 1013611.3575, MAE: 3879.2180, R2: 0.1445\n",
      "==========================================================================================\n",
      "Epoch [3445/5000] | Time: 0.34s\n",
      "(Training) Loss: 972693.1174\n",
      "(Validation) Loss: 1013461.6686, MAE: 3880.1226, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [3446/5000] | Time: 0.38s\n",
      "(Training) Loss: 983974.7138\n",
      "(Validation) Loss: 1013299.0070, MAE: 3878.0510, R2: 0.1447\n",
      "==========================================================================================\n",
      "Epoch [3447/5000] | Time: 0.40s\n",
      "(Training) Loss: 985523.7030\n",
      "(Validation) Loss: 1013142.4457, MAE: 3878.5813, R2: 0.1449\n",
      "==========================================================================================\n",
      "Epoch [3448/5000] | Time: 0.42s\n",
      "(Training) Loss: 1028512.7126\n",
      "(Validation) Loss: 1012988.9727, MAE: 3878.7366, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [3449/5000] | Time: 0.35s\n",
      "(Training) Loss: 981984.6053\n",
      "(Validation) Loss: 1012835.2305, MAE: 3880.1277, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [3450/5000] | Time: 0.39s\n",
      "(Training) Loss: 970487.6418\n",
      "(Validation) Loss: 1012666.1384, MAE: 3877.8152, R2: 0.1453\n",
      "==========================================================================================\n",
      "Epoch [3451/5000] | Time: 0.39s\n",
      "(Training) Loss: 995708.7735\n",
      "(Validation) Loss: 1012510.0800, MAE: 3875.4548, R2: 0.1454\n",
      "==========================================================================================\n",
      "Epoch [3452/5000] | Time: 0.38s\n",
      "(Training) Loss: 983602.6580\n",
      "(Validation) Loss: 1012352.4165, MAE: 3875.8572, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [3453/5000] | Time: 0.39s\n",
      "(Training) Loss: 980817.9721\n",
      "(Validation) Loss: 1012194.3822, MAE: 3873.4312, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [3454/5000] | Time: 0.41s\n",
      "(Training) Loss: 988626.3763\n",
      "(Validation) Loss: 1012044.6324, MAE: 3875.3438, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [3455/5000] | Time: 0.35s\n",
      "(Training) Loss: 975237.1599\n",
      "(Validation) Loss: 1011881.7879, MAE: 3874.5017, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [3456/5000] | Time: 0.42s\n",
      "(Training) Loss: 970092.7051\n",
      "(Validation) Loss: 1011725.4146, MAE: 3873.9502, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [3457/5000] | Time: 0.36s\n",
      "(Training) Loss: 978195.1409\n",
      "(Validation) Loss: 1011576.4876, MAE: 3873.5784, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [3458/5000] | Time: 0.41s\n",
      "(Training) Loss: 980111.3801\n",
      "(Validation) Loss: 1011423.1060, MAE: 3873.9849, R2: 0.1463\n",
      "==========================================================================================\n",
      "Epoch [3459/5000] | Time: 0.36s\n",
      "(Training) Loss: 980225.5799\n",
      "(Validation) Loss: 1011259.3270, MAE: 3871.6343, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [3460/5000] | Time: 0.36s\n",
      "(Training) Loss: 989008.4169\n",
      "(Validation) Loss: 1011107.5505, MAE: 3872.8977, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [3461/5000] | Time: 0.35s\n",
      "(Training) Loss: 992778.3674\n",
      "(Validation) Loss: 1010946.4279, MAE: 3869.9736, R2: 0.1467\n",
      "==========================================================================================\n",
      "Epoch [3462/5000] | Time: 0.29s\n",
      "(Training) Loss: 978479.5539\n",
      "(Validation) Loss: 1010791.6597, MAE: 3871.1926, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [3463/5000] | Time: 0.33s\n",
      "(Training) Loss: 981155.8541\n",
      "(Validation) Loss: 1010632.7568, MAE: 3870.1694, R2: 0.1470\n",
      "==========================================================================================\n",
      "Epoch [3464/5000] | Time: 0.38s\n",
      "(Training) Loss: 996384.4841\n",
      "(Validation) Loss: 1010477.9429, MAE: 3869.9468, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [3465/5000] | Time: 0.45s\n",
      "(Training) Loss: 982801.3464\n",
      "(Validation) Loss: 1010318.8622, MAE: 3869.6152, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [3466/5000] | Time: 0.34s\n",
      "(Training) Loss: 972407.1047\n",
      "(Validation) Loss: 1010163.6876, MAE: 3868.6187, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [3467/5000] | Time: 0.32s\n",
      "(Training) Loss: 967904.1025\n",
      "(Validation) Loss: 1010005.9378, MAE: 3866.4031, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [3468/5000] | Time: 0.30s\n",
      "(Training) Loss: 975644.1770\n",
      "(Validation) Loss: 1009853.5162, MAE: 3865.6201, R2: 0.1476\n",
      "==========================================================================================\n",
      "Epoch [3469/5000] | Time: 0.40s\n",
      "(Training) Loss: 975142.7189\n",
      "(Validation) Loss: 1009690.3771, MAE: 3864.1836, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [3470/5000] | Time: 0.48s\n",
      "(Training) Loss: 967455.5676\n",
      "(Validation) Loss: 1009538.1333, MAE: 3863.8225, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [3471/5000] | Time: 0.47s\n",
      "(Training) Loss: 977473.1536\n",
      "(Validation) Loss: 1009387.2254, MAE: 3864.0183, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [3472/5000] | Time: 0.36s\n",
      "(Training) Loss: 970461.9841\n",
      "(Validation) Loss: 1009231.9390, MAE: 3863.9290, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [3473/5000] | Time: 0.27s\n",
      "(Training) Loss: 975031.4048\n",
      "(Validation) Loss: 1009041.5492, MAE: 3867.5483, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [3474/5000] | Time: 0.27s\n",
      "(Training) Loss: 988094.9061\n",
      "(Validation) Loss: 1008828.5308, MAE: 3857.3015, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [3475/5000] | Time: 0.30s\n",
      "(Training) Loss: 980600.5343\n",
      "(Validation) Loss: 1008689.5289, MAE: 3860.4968, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [3476/5000] | Time: 0.26s\n",
      "(Training) Loss: 995696.0441\n",
      "(Validation) Loss: 1008539.9263, MAE: 3861.9463, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [3477/5000] | Time: 0.23s\n",
      "(Training) Loss: 993643.0733\n",
      "(Validation) Loss: 1008410.3314, MAE: 3867.5244, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [3478/5000] | Time: 0.23s\n",
      "(Training) Loss: 974986.0996\n",
      "(Validation) Loss: 1008204.9168, MAE: 3855.6335, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [3479/5000] | Time: 0.26s\n",
      "(Training) Loss: 994487.4302\n",
      "(Validation) Loss: 1008046.1511, MAE: 3854.4629, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [3480/5000] | Time: 0.21s\n",
      "(Training) Loss: 969608.7138\n",
      "(Validation) Loss: 1007890.3060, MAE: 3853.5127, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [3481/5000] | Time: 0.21s\n",
      "(Training) Loss: 992952.5165\n",
      "(Validation) Loss: 1007738.7683, MAE: 3854.1582, R2: 0.1494\n",
      "==========================================================================================\n",
      "Epoch [3482/5000] | Time: 0.23s\n",
      "(Training) Loss: 986937.8065\n",
      "(Validation) Loss: 1007577.9302, MAE: 3852.3982, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [3483/5000] | Time: 0.21s\n",
      "(Training) Loss: 968329.9927\n",
      "(Validation) Loss: 1007423.3905, MAE: 3852.4214, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [3484/5000] | Time: 0.34s\n",
      "(Training) Loss: 971144.9029\n",
      "(Validation) Loss: 1007298.6210, MAE: 3859.8606, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [3485/5000] | Time: 0.32s\n",
      "(Training) Loss: 968178.2881\n",
      "(Validation) Loss: 1007122.6311, MAE: 3853.5532, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [3486/5000] | Time: 0.25s\n",
      "(Training) Loss: 983850.0470\n",
      "(Validation) Loss: 1006957.1302, MAE: 3849.0361, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [3487/5000] | Time: 0.25s\n",
      "(Training) Loss: 971207.8043\n",
      "(Validation) Loss: 1006801.0311, MAE: 3849.9385, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [3488/5000] | Time: 0.22s\n",
      "(Training) Loss: 966554.6390\n",
      "(Validation) Loss: 1006644.1041, MAE: 3848.1265, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [3489/5000] | Time: 0.24s\n",
      "(Training) Loss: 976928.5857\n",
      "(Validation) Loss: 1006497.6305, MAE: 3849.1396, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [3490/5000] | Time: 0.22s\n",
      "(Training) Loss: 972272.6491\n",
      "(Validation) Loss: 1006430.5371, MAE: 3854.4902, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [3491/5000] | Time: 0.25s\n",
      "(Training) Loss: 981223.8331\n",
      "(Validation) Loss: 1006279.7003, MAE: 3855.0562, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [3492/5000] | Time: 0.25s\n",
      "(Training) Loss: 980334.7627\n",
      "(Validation) Loss: 1006123.7181, MAE: 3854.3079, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [3493/5000] | Time: 0.29s\n",
      "(Training) Loss: 984899.3579\n",
      "(Validation) Loss: 1005961.7625, MAE: 3852.3721, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [3494/5000] | Time: 0.24s\n",
      "(Training) Loss: 968892.9873\n",
      "(Validation) Loss: 1005806.4102, MAE: 3850.9778, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [3495/5000] | Time: 0.26s\n",
      "(Training) Loss: 986311.7081\n",
      "(Validation) Loss: 1005650.4737, MAE: 3850.7703, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [3496/5000] | Time: 0.26s\n",
      "(Training) Loss: 970871.7335\n",
      "(Validation) Loss: 1005497.1225, MAE: 3852.1313, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [3497/5000] | Time: 0.24s\n",
      "(Training) Loss: 981655.2348\n",
      "(Validation) Loss: 1005343.0502, MAE: 3850.2896, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [3498/5000] | Time: 0.29s\n",
      "(Training) Loss: 987963.2354\n",
      "(Validation) Loss: 1005197.2876, MAE: 3853.6069, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [3499/5000] | Time: 0.22s\n",
      "(Training) Loss: 978539.9467\n",
      "(Validation) Loss: 1005031.1975, MAE: 3851.1123, R2: 0.1516\n",
      "==========================================================================================\n",
      "Epoch [3500/5000] | Time: 0.20s\n",
      "(Training) Loss: 976061.7722\n",
      "(Validation) Loss: 1004876.4394, MAE: 3851.3965, R2: 0.1518\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch3500.pth\n",
      "==========================================================================================\n",
      "Epoch [3501/5000] | Time: 0.24s\n",
      "(Training) Loss: 967989.8204\n",
      "(Validation) Loss: 1004720.8533, MAE: 3849.6772, R2: 0.1519\n",
      "==========================================================================================\n",
      "Epoch [3502/5000] | Time: 0.24s\n",
      "(Training) Loss: 985254.8680\n",
      "(Validation) Loss: 1004563.9568, MAE: 3848.3354, R2: 0.1520\n",
      "==========================================================================================\n",
      "Epoch [3503/5000] | Time: 0.23s\n",
      "(Training) Loss: 972290.8334\n",
      "(Validation) Loss: 1004406.0292, MAE: 3847.5720, R2: 0.1522\n",
      "==========================================================================================\n",
      "Epoch [3504/5000] | Time: 0.32s\n",
      "(Training) Loss: 983413.3579\n",
      "(Validation) Loss: 1004256.4470, MAE: 3848.8845, R2: 0.1523\n",
      "==========================================================================================\n",
      "Epoch [3505/5000] | Time: 0.31s\n",
      "(Training) Loss: 964532.9353\n",
      "(Validation) Loss: 1004096.4216, MAE: 3846.2937, R2: 0.1524\n",
      "==========================================================================================\n",
      "Epoch [3506/5000] | Time: 0.26s\n",
      "(Training) Loss: 962688.8144\n",
      "(Validation) Loss: 1003953.4781, MAE: 3849.6755, R2: 0.1525\n",
      "==========================================================================================\n",
      "Epoch [3507/5000] | Time: 0.26s\n",
      "(Training) Loss: 974787.5546\n",
      "(Validation) Loss: 1003797.8768, MAE: 3849.6069, R2: 0.1527\n",
      "==========================================================================================\n",
      "Epoch [3508/5000] | Time: 0.26s\n",
      "(Training) Loss: 987021.4232\n",
      "(Validation) Loss: 1025359.4108, MAE: 3935.9585, R2: 0.1347\n",
      "==========================================================================================\n",
      "Epoch [3509/5000] | Time: 0.30s\n",
      "(Training) Loss: 997651.5872\n",
      "(Validation) Loss: 1025108.6629, MAE: 3917.9062, R2: 0.1349\n",
      "==========================================================================================\n",
      "Epoch [3510/5000] | Time: 0.30s\n",
      "(Training) Loss: 985187.1732\n",
      "(Validation) Loss: 1024968.0610, MAE: 3922.5051, R2: 0.1350\n",
      "==========================================================================================\n",
      "Epoch [3511/5000] | Time: 0.32s\n",
      "(Training) Loss: 992403.7418\n",
      "(Validation) Loss: 1024780.0076, MAE: 3916.1609, R2: 0.1352\n",
      "==========================================================================================\n",
      "Epoch [3512/5000] | Time: 0.27s\n",
      "(Training) Loss: 980968.7787\n",
      "(Validation) Loss: 1024615.1467, MAE: 3915.2769, R2: 0.1353\n",
      "==========================================================================================\n",
      "Epoch [3513/5000] | Time: 0.32s\n",
      "(Training) Loss: 1004139.9632\n",
      "(Validation) Loss: 1046589.3486, MAE: 3987.4133, R2: 0.1170\n",
      "==========================================================================================\n",
      "Epoch [3514/5000] | Time: 0.28s\n",
      "(Training) Loss: 1015424.1885\n",
      "(Validation) Loss: 1046493.1606, MAE: 4003.7651, R2: 0.1171\n",
      "==========================================================================================\n",
      "Epoch [3515/5000] | Time: 0.30s\n",
      "(Training) Loss: 1012810.9055\n",
      "(Validation) Loss: 1046256.6806, MAE: 3986.7507, R2: 0.1173\n",
      "==========================================================================================\n",
      "Epoch [3516/5000] | Time: 0.23s\n",
      "(Training) Loss: 1037628.1599\n",
      "(Validation) Loss: 1046085.9479, MAE: 3986.5225, R2: 0.1174\n",
      "==========================================================================================\n",
      "Epoch [3517/5000] | Time: 0.26s\n",
      "(Training) Loss: 1029278.5730\n",
      "(Validation) Loss: 1045918.0140, MAE: 3985.1841, R2: 0.1176\n",
      "==========================================================================================\n",
      "Epoch [3518/5000] | Time: 0.32s\n",
      "(Training) Loss: 1031754.5013\n",
      "(Validation) Loss: 1045761.2190, MAE: 3988.7856, R2: 0.1177\n",
      "==========================================================================================\n",
      "Epoch [3519/5000] | Time: 0.29s\n",
      "(Training) Loss: 1025854.5393\n",
      "(Validation) Loss: 1045574.7149, MAE: 3982.6060, R2: 0.1179\n",
      "==========================================================================================\n",
      "Epoch [3520/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006301.6916\n",
      "(Validation) Loss: 1045407.8984, MAE: 3982.4365, R2: 0.1180\n",
      "==========================================================================================\n",
      "Epoch [3521/5000] | Time: 0.29s\n",
      "(Training) Loss: 1006023.6377\n",
      "(Validation) Loss: 1064117.7397, MAE: 4064.4517, R2: 0.1024\n",
      "==========================================================================================\n",
      "Epoch [3522/5000] | Time: 0.29s\n",
      "(Training) Loss: 1036789.7614\n",
      "(Validation) Loss: 1052557.4197, MAE: 4011.4177, R2: 0.1120\n",
      "==========================================================================================\n",
      "Epoch [3523/5000] | Time: 0.32s\n",
      "(Training) Loss: 1027401.7018\n",
      "(Validation) Loss: 1052383.8781, MAE: 4009.1562, R2: 0.1122\n",
      "==========================================================================================\n",
      "Epoch [3524/5000] | Time: 0.34s\n",
      "(Training) Loss: 1027536.5476\n",
      "(Validation) Loss: 1052220.0381, MAE: 4008.6155, R2: 0.1123\n",
      "==========================================================================================\n",
      "Epoch [3525/5000] | Time: 0.32s\n",
      "(Training) Loss: 1016584.6677\n",
      "(Validation) Loss: 1052050.9613, MAE: 4007.2146, R2: 0.1125\n",
      "==========================================================================================\n",
      "Epoch [3526/5000] | Time: 0.30s\n",
      "(Training) Loss: 1017644.8039\n",
      "(Validation) Loss: 1051891.6978, MAE: 4008.1279, R2: 0.1126\n",
      "==========================================================================================\n",
      "Epoch [3527/5000] | Time: 0.27s\n",
      "(Training) Loss: 1029344.3312\n",
      "(Validation) Loss: 1051725.7143, MAE: 4006.8445, R2: 0.1127\n",
      "==========================================================================================\n",
      "Epoch [3528/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008563.2766\n",
      "(Validation) Loss: 1051567.1010, MAE: 4006.2778, R2: 0.1129\n",
      "==========================================================================================\n",
      "Epoch [3529/5000] | Time: 0.27s\n",
      "(Training) Loss: 1005627.8650\n",
      "(Validation) Loss: 1051399.0451, MAE: 4005.4883, R2: 0.1130\n",
      "==========================================================================================\n",
      "Epoch [3530/5000] | Time: 0.41s\n",
      "(Training) Loss: 1027399.4448\n",
      "(Validation) Loss: 1051247.4565, MAE: 4007.5405, R2: 0.1131\n",
      "==========================================================================================\n",
      "Epoch [3531/5000] | Time: 0.29s\n",
      "(Training) Loss: 1015536.0647\n",
      "(Validation) Loss: 1051078.8876, MAE: 4005.7039, R2: 0.1133\n",
      "==========================================================================================\n",
      "Epoch [3532/5000] | Time: 0.28s\n",
      "(Training) Loss: 1013815.9442\n",
      "(Validation) Loss: 1050914.1130, MAE: 4004.4006, R2: 0.1134\n",
      "==========================================================================================\n",
      "Epoch [3533/5000] | Time: 0.27s\n",
      "(Training) Loss: 1010160.9404\n",
      "(Validation) Loss: 1050753.6203, MAE: 4004.0032, R2: 0.1135\n",
      "==========================================================================================\n",
      "Epoch [3534/5000] | Time: 0.30s\n",
      "(Training) Loss: 1026186.9594\n",
      "(Validation) Loss: 1050589.7397, MAE: 4002.7886, R2: 0.1137\n",
      "==========================================================================================\n",
      "Epoch [3535/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016714.8414\n",
      "(Validation) Loss: 1050427.3727, MAE: 4002.4216, R2: 0.1138\n",
      "==========================================================================================\n",
      "Epoch [3536/5000] | Time: 0.29s\n",
      "(Training) Loss: 1024656.0203\n",
      "(Validation) Loss: 1050265.2952, MAE: 4001.6646, R2: 0.1139\n",
      "==========================================================================================\n",
      "Epoch [3537/5000] | Time: 0.27s\n",
      "(Training) Loss: 1032821.4543\n",
      "(Validation) Loss: 1050103.2279, MAE: 4001.1003, R2: 0.1141\n",
      "==========================================================================================\n",
      "Epoch [3538/5000] | Time: 0.26s\n",
      "(Training) Loss: 1022392.8433\n",
      "(Validation) Loss: 1049942.7657, MAE: 4000.9778, R2: 0.1142\n",
      "==========================================================================================\n",
      "Epoch [3539/5000] | Time: 0.29s\n",
      "(Training) Loss: 1019831.1332\n",
      "(Validation) Loss: 1049774.5067, MAE: 3999.5657, R2: 0.1144\n",
      "==========================================================================================\n",
      "Epoch [3540/5000] | Time: 0.26s\n",
      "(Training) Loss: 1010224.5857\n",
      "(Validation) Loss: 1049611.0883, MAE: 3997.9792, R2: 0.1145\n",
      "==========================================================================================\n",
      "Epoch [3541/5000] | Time: 0.42s\n",
      "(Training) Loss: 1043637.4575\n",
      "(Validation) Loss: 1049455.5835, MAE: 3999.4407, R2: 0.1146\n",
      "==========================================================================================\n",
      "Epoch [3542/5000] | Time: 0.26s\n",
      "(Training) Loss: 1014710.9702\n",
      "(Validation) Loss: 1049291.7232, MAE: 3997.6296, R2: 0.1148\n",
      "==========================================================================================\n",
      "Epoch [3543/5000] | Time: 0.28s\n",
      "(Training) Loss: 1005335.9622\n",
      "(Validation) Loss: 1049129.3917, MAE: 3997.5605, R2: 0.1149\n",
      "==========================================================================================\n",
      "Epoch [3544/5000] | Time: 0.33s\n",
      "(Training) Loss: 1020629.1523\n",
      "(Validation) Loss: 1048970.3162, MAE: 3996.4133, R2: 0.1150\n",
      "==========================================================================================\n",
      "Epoch [3545/5000] | Time: 0.35s\n",
      "(Training) Loss: 1038907.2322\n",
      "(Validation) Loss: 1048807.6292, MAE: 3995.7305, R2: 0.1152\n",
      "==========================================================================================\n",
      "Epoch [3546/5000] | Time: 0.33s\n",
      "(Training) Loss: 1024882.8439\n",
      "(Validation) Loss: 1048641.9606, MAE: 3994.0208, R2: 0.1153\n",
      "==========================================================================================\n",
      "Epoch [3547/5000] | Time: 0.24s\n",
      "(Training) Loss: 1015325.8794\n",
      "(Validation) Loss: 1048487.5733, MAE: 3995.9683, R2: 0.1154\n",
      "==========================================================================================\n",
      "Epoch [3548/5000] | Time: 0.24s\n",
      "(Training) Loss: 1011195.7532\n",
      "(Validation) Loss: 1048321.3206, MAE: 3993.8872, R2: 0.1156\n",
      "==========================================================================================\n",
      "Epoch [3549/5000] | Time: 0.25s\n",
      "(Training) Loss: 1022510.9181\n",
      "(Validation) Loss: 1048162.2197, MAE: 3993.5024, R2: 0.1157\n",
      "==========================================================================================\n",
      "Epoch [3550/5000] | Time: 0.23s\n",
      "(Training) Loss: 1026324.3363\n",
      "(Validation) Loss: 1048015.2025, MAE: 3998.7576, R2: 0.1158\n",
      "==========================================================================================\n",
      "Epoch [3551/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023662.6098\n",
      "(Validation) Loss: 1047849.8083, MAE: 3995.2476, R2: 0.1160\n",
      "==========================================================================================\n",
      "Epoch [3552/5000] | Time: 0.27s\n",
      "(Training) Loss: 1002031.6928\n",
      "(Validation) Loss: 1047705.7016, MAE: 3993.5508, R2: 0.1161\n",
      "==========================================================================================\n",
      "Epoch [3553/5000] | Time: 0.24s\n",
      "(Training) Loss: 1001841.3134\n",
      "(Validation) Loss: 1047543.2940, MAE: 3991.5679, R2: 0.1162\n",
      "==========================================================================================\n",
      "Epoch [3554/5000] | Time: 0.27s\n",
      "(Training) Loss: 1027390.7735\n",
      "(Validation) Loss: 1047387.7892, MAE: 3991.8608, R2: 0.1163\n",
      "==========================================================================================\n",
      "Epoch [3555/5000] | Time: 0.26s\n",
      "(Training) Loss: 1010474.1244\n",
      "(Validation) Loss: 1047239.4768, MAE: 3995.7888, R2: 0.1165\n",
      "==========================================================================================\n",
      "Epoch [3556/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014516.9010\n",
      "(Validation) Loss: 1047072.5029, MAE: 3992.5667, R2: 0.1166\n",
      "==========================================================================================\n",
      "Epoch [3557/5000] | Time: 0.23s\n",
      "(Training) Loss: 1013693.3642\n",
      "(Validation) Loss: 1046913.7981, MAE: 3992.1218, R2: 0.1167\n",
      "==========================================================================================\n",
      "Epoch [3558/5000] | Time: 0.29s\n",
      "(Training) Loss: 1026473.1161\n",
      "(Validation) Loss: 1046748.9168, MAE: 3990.2869, R2: 0.1169\n",
      "==========================================================================================\n",
      "Epoch [3559/5000] | Time: 0.27s\n",
      "(Training) Loss: 1003621.6123\n",
      "(Validation) Loss: 1046587.2610, MAE: 3989.5342, R2: 0.1170\n",
      "==========================================================================================\n",
      "Epoch [3560/5000] | Time: 0.27s\n",
      "(Training) Loss: 1030332.8363\n",
      "(Validation) Loss: 1046445.3181, MAE: 3992.3069, R2: 0.1171\n",
      "==========================================================================================\n",
      "Epoch [3561/5000] | Time: 0.37s\n",
      "(Training) Loss: 1038056.1447\n",
      "(Validation) Loss: 1046268.2057, MAE: 3988.2661, R2: 0.1173\n",
      "==========================================================================================\n",
      "Epoch [3562/5000] | Time: 0.32s\n",
      "(Training) Loss: 1012031.6352\n",
      "(Validation) Loss: 1046102.8876, MAE: 3987.6006, R2: 0.1174\n",
      "==========================================================================================\n",
      "Epoch [3563/5000] | Time: 0.38s\n",
      "(Training) Loss: 1019259.7703\n",
      "(Validation) Loss: 1045958.0241, MAE: 3991.0828, R2: 0.1175\n",
      "==========================================================================================\n",
      "Epoch [3564/5000] | Time: 0.30s\n",
      "(Training) Loss: 1020130.9327\n",
      "(Validation) Loss: 1045787.5708, MAE: 3987.7725, R2: 0.1177\n",
      "==========================================================================================\n",
      "Epoch [3565/5000] | Time: 0.30s\n",
      "(Training) Loss: 1020448.5958\n",
      "(Validation) Loss: 1045623.0756, MAE: 3985.7759, R2: 0.1178\n",
      "==========================================================================================\n",
      "Epoch [3566/5000] | Time: 0.31s\n",
      "(Training) Loss: 1023903.8528\n",
      "(Validation) Loss: 1045469.0387, MAE: 3987.1763, R2: 0.1179\n",
      "==========================================================================================\n",
      "Epoch [3567/5000] | Time: 0.31s\n",
      "(Training) Loss: 1017549.5685\n",
      "(Validation) Loss: 1045308.9930, MAE: 3986.8582, R2: 0.1181\n",
      "==========================================================================================\n",
      "Epoch [3568/5000] | Time: 0.28s\n",
      "(Training) Loss: 1005830.6415\n",
      "(Validation) Loss: 1045143.2330, MAE: 3984.7593, R2: 0.1182\n",
      "==========================================================================================\n",
      "Epoch [3569/5000] | Time: 0.30s\n",
      "(Training) Loss: 1021197.5533\n",
      "(Validation) Loss: 1044987.8705, MAE: 3984.3894, R2: 0.1183\n",
      "==========================================================================================\n",
      "Epoch [3570/5000] | Time: 0.27s\n",
      "(Training) Loss: 1017995.1891\n",
      "(Validation) Loss: 1044824.2895, MAE: 3982.5886, R2: 0.1185\n",
      "==========================================================================================\n",
      "Epoch [3571/5000] | Time: 0.32s\n",
      "(Training) Loss: 1003087.2652\n",
      "(Validation) Loss: 1044691.8451, MAE: 3989.6279, R2: 0.1186\n",
      "==========================================================================================\n",
      "Epoch [3572/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008511.8534\n",
      "(Validation) Loss: 1044509.8667, MAE: 3982.4629, R2: 0.1187\n",
      "==========================================================================================\n",
      "Epoch [3573/5000] | Time: 0.28s\n",
      "(Training) Loss: 1010172.9518\n",
      "(Validation) Loss: 1044346.4483, MAE: 3980.9631, R2: 0.1189\n",
      "==========================================================================================\n",
      "Epoch [3574/5000] | Time: 0.25s\n",
      "(Training) Loss: 1008256.7951\n",
      "(Validation) Loss: 1044188.7340, MAE: 3980.7524, R2: 0.1190\n",
      "==========================================================================================\n",
      "Epoch [3575/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002865.8325\n",
      "(Validation) Loss: 1044027.8044, MAE: 3979.4263, R2: 0.1191\n",
      "==========================================================================================\n",
      "Epoch [3576/5000] | Time: 0.24s\n",
      "(Training) Loss: 1038720.9467\n",
      "(Validation) Loss: 1043882.9308, MAE: 3982.7578, R2: 0.1193\n",
      "==========================================================================================\n",
      "Epoch [3577/5000] | Time: 0.25s\n",
      "(Training) Loss: 1044269.5057\n",
      "(Validation) Loss: 1043719.3041, MAE: 3982.3298, R2: 0.1194\n",
      "==========================================================================================\n",
      "Epoch [3578/5000] | Time: 0.21s\n",
      "(Training) Loss: 1014197.4150\n",
      "(Validation) Loss: 1043547.5251, MAE: 3979.1523, R2: 0.1195\n",
      "==========================================================================================\n",
      "Epoch [3579/5000] | Time: 0.21s\n",
      "(Training) Loss: 997948.6713\n",
      "(Validation) Loss: 1043387.3168, MAE: 3977.4670, R2: 0.1197\n",
      "==========================================================================================\n",
      "Epoch [3580/5000] | Time: 0.22s\n",
      "(Training) Loss: 1010987.0622\n",
      "(Validation) Loss: 1043235.7689, MAE: 3978.1616, R2: 0.1198\n",
      "==========================================================================================\n",
      "Epoch [3581/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011017.1624\n",
      "(Validation) Loss: 1043071.6089, MAE: 3976.0139, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [3582/5000] | Time: 0.25s\n",
      "(Training) Loss: 1026097.2246\n",
      "(Validation) Loss: 1042915.7435, MAE: 3976.3479, R2: 0.1201\n",
      "==========================================================================================\n",
      "Epoch [3583/5000] | Time: 0.24s\n",
      "(Training) Loss: 1014439.7538\n",
      "(Validation) Loss: 1042754.6159, MAE: 3975.2737, R2: 0.1202\n",
      "==========================================================================================\n",
      "Epoch [3584/5000] | Time: 0.26s\n",
      "(Training) Loss: 1011519.2227\n",
      "(Validation) Loss: 1042594.3314, MAE: 3974.6619, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [3585/5000] | Time: 0.25s\n",
      "(Training) Loss: 1029054.5685\n",
      "(Validation) Loss: 1042449.8997, MAE: 3977.0479, R2: 0.1205\n",
      "==========================================================================================\n",
      "Epoch [3586/5000] | Time: 0.27s\n",
      "(Training) Loss: 1023879.4987\n",
      "(Validation) Loss: 1042287.3498, MAE: 3976.8816, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [3587/5000] | Time: 0.27s\n",
      "(Training) Loss: 1001057.0412\n",
      "(Validation) Loss: 1042118.9994, MAE: 3974.4944, R2: 0.1207\n",
      "==========================================================================================\n",
      "Epoch [3588/5000] | Time: 0.27s\n",
      "(Training) Loss: 998633.2046\n",
      "(Validation) Loss: 1041964.4495, MAE: 3974.3584, R2: 0.1209\n",
      "==========================================================================================\n",
      "Epoch [3589/5000] | Time: 0.29s\n",
      "(Training) Loss: 996550.3646\n",
      "(Validation) Loss: 1041801.1835, MAE: 3971.0361, R2: 0.1210\n",
      "==========================================================================================\n",
      "Epoch [3590/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003327.0660\n",
      "(Validation) Loss: 1041646.3238, MAE: 3970.6584, R2: 0.1211\n",
      "==========================================================================================\n",
      "Epoch [3591/5000] | Time: 0.29s\n",
      "(Training) Loss: 1015375.9835\n",
      "(Validation) Loss: 1041490.7886, MAE: 3970.8655, R2: 0.1213\n",
      "==========================================================================================\n",
      "Epoch [3592/5000] | Time: 0.33s\n",
      "(Training) Loss: 1007285.7532\n",
      "(Validation) Loss: 1041332.3225, MAE: 3971.1667, R2: 0.1214\n",
      "==========================================================================================\n",
      "Epoch [3593/5000] | Time: 0.30s\n",
      "(Training) Loss: 1027147.2671\n",
      "(Validation) Loss: 1041178.2095, MAE: 3971.0500, R2: 0.1215\n",
      "==========================================================================================\n",
      "Epoch [3594/5000] | Time: 0.22s\n",
      "(Training) Loss: 1005782.6174\n",
      "(Validation) Loss: 1041017.0971, MAE: 3970.5942, R2: 0.1217\n",
      "==========================================================================================\n",
      "Epoch [3595/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007926.1812\n",
      "(Validation) Loss: 1040855.2990, MAE: 3967.9443, R2: 0.1218\n",
      "==========================================================================================\n",
      "Epoch [3596/5000] | Time: 0.21s\n",
      "(Training) Loss: 1005301.6294\n",
      "(Validation) Loss: 1040700.8762, MAE: 3969.2283, R2: 0.1219\n",
      "==========================================================================================\n",
      "Epoch [3597/5000] | Time: 0.21s\n",
      "(Training) Loss: 1009752.6110\n",
      "(Validation) Loss: 1040538.8444, MAE: 3967.4490, R2: 0.1221\n",
      "==========================================================================================\n",
      "Epoch [3598/5000] | Time: 0.21s\n",
      "(Training) Loss: 1012496.3439\n",
      "(Validation) Loss: 1040382.2832, MAE: 3966.2166, R2: 0.1222\n",
      "==========================================================================================\n",
      "Epoch [3599/5000] | Time: 0.29s\n",
      "(Training) Loss: 1014874.7906\n",
      "(Validation) Loss: 1040226.3721, MAE: 3966.9463, R2: 0.1223\n",
      "==========================================================================================\n",
      "Epoch [3600/5000] | Time: 0.29s\n",
      "(Training) Loss: 998035.9086\n",
      "(Validation) Loss: 1040068.8457, MAE: 3967.1733, R2: 0.1224\n",
      "==========================================================================================\n",
      "Epoch [3601/5000] | Time: 0.22s\n",
      "(Training) Loss: 1027806.3782\n",
      "(Validation) Loss: 1039908.8711, MAE: 3965.0303, R2: 0.1226\n",
      "==========================================================================================\n",
      "Epoch [3602/5000] | Time: 0.27s\n",
      "(Training) Loss: 1009677.4949\n",
      "(Validation) Loss: 1039754.1841, MAE: 3966.8005, R2: 0.1227\n",
      "==========================================================================================\n",
      "Epoch [3603/5000] | Time: 0.31s\n",
      "(Training) Loss: 1017541.4340\n",
      "(Validation) Loss: 1039590.7911, MAE: 3965.0239, R2: 0.1228\n",
      "==========================================================================================\n",
      "Epoch [3604/5000] | Time: 0.24s\n",
      "(Training) Loss: 1007819.0628\n",
      "(Validation) Loss: 1039433.8590, MAE: 3964.7419, R2: 0.1230\n",
      "==========================================================================================\n",
      "Epoch [3605/5000] | Time: 0.21s\n",
      "(Training) Loss: 1003356.3261\n",
      "(Validation) Loss: 1039275.5048, MAE: 3964.3274, R2: 0.1231\n",
      "==========================================================================================\n",
      "Epoch [3606/5000] | Time: 0.34s\n",
      "(Training) Loss: 993261.8194\n",
      "(Validation) Loss: 1036299.3727, MAE: 3951.9976, R2: 0.1256\n",
      "==========================================================================================\n",
      "Epoch [3607/5000] | Time: 0.26s\n",
      "(Training) Loss: 1014373.8287\n",
      "(Validation) Loss: 1036065.9708, MAE: 3946.0923, R2: 0.1258\n",
      "==========================================================================================\n",
      "Epoch [3608/5000] | Time: 0.23s\n",
      "(Training) Loss: 992952.6602\n",
      "(Validation) Loss: 1035904.8940, MAE: 3945.1882, R2: 0.1259\n",
      "==========================================================================================\n",
      "Epoch [3609/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000932.7640\n",
      "(Validation) Loss: 1035775.4159, MAE: 3949.0493, R2: 0.1260\n",
      "==========================================================================================\n",
      "Epoch [3610/5000] | Time: 0.30s\n",
      "(Training) Loss: 994546.0485\n",
      "(Validation) Loss: 1035681.0210, MAE: 3953.3213, R2: 0.1261\n",
      "==========================================================================================\n",
      "Epoch [3611/5000] | Time: 0.23s\n",
      "(Training) Loss: 994901.1003\n",
      "(Validation) Loss: 1035519.9187, MAE: 3949.9421, R2: 0.1262\n",
      "==========================================================================================\n",
      "Epoch [3612/5000] | Time: 0.20s\n",
      "(Training) Loss: 1027496.7608\n",
      "(Validation) Loss: 1054940.9727, MAE: 4037.6895, R2: 0.1100\n",
      "==========================================================================================\n",
      "Epoch [3613/5000] | Time: 0.20s\n",
      "(Training) Loss: 1016383.5977\n",
      "(Validation) Loss: 1049162.0165, MAE: 4013.3687, R2: 0.1149\n",
      "==========================================================================================\n",
      "Epoch [3614/5000] | Time: 0.21s\n",
      "(Training) Loss: 1013227.3280\n",
      "(Validation) Loss: 1048978.1130, MAE: 4006.3555, R2: 0.1150\n",
      "==========================================================================================\n",
      "Epoch [3615/5000] | Time: 0.28s\n",
      "(Training) Loss: 1033603.2786\n",
      "(Validation) Loss: 1048814.5879, MAE: 4004.6440, R2: 0.1152\n",
      "==========================================================================================\n",
      "Epoch [3616/5000] | Time: 0.21s\n",
      "(Training) Loss: 1003531.0368\n",
      "(Validation) Loss: 1037127.7359, MAE: 3961.9897, R2: 0.1249\n",
      "==========================================================================================\n",
      "Epoch [3617/5000] | Time: 0.22s\n",
      "(Training) Loss: 1018619.6288\n",
      "(Validation) Loss: 1036911.0857, MAE: 3960.2378, R2: 0.1251\n",
      "==========================================================================================\n",
      "Epoch [3618/5000] | Time: 0.27s\n",
      "(Training) Loss: 1001152.7652\n",
      "(Validation) Loss: 1036724.7848, MAE: 3955.0447, R2: 0.1252\n",
      "==========================================================================================\n",
      "Epoch [3619/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004636.1218\n",
      "(Validation) Loss: 1036542.0749, MAE: 3948.6479, R2: 0.1254\n",
      "==========================================================================================\n",
      "Epoch [3620/5000] | Time: 0.22s\n",
      "(Training) Loss: 1006281.8528\n",
      "(Validation) Loss: 1036383.0095, MAE: 3948.3696, R2: 0.1255\n",
      "==========================================================================================\n",
      "Epoch [3621/5000] | Time: 0.21s\n",
      "(Training) Loss: 1008793.4201\n",
      "(Validation) Loss: 1036235.4184, MAE: 3951.3264, R2: 0.1256\n",
      "==========================================================================================\n",
      "Epoch [3622/5000] | Time: 0.23s\n",
      "(Training) Loss: 1005303.2411\n",
      "(Validation) Loss: 1036084.6476, MAE: 3953.1694, R2: 0.1258\n",
      "==========================================================================================\n",
      "Epoch [3623/5000] | Time: 0.21s\n",
      "(Training) Loss: 1032695.5787\n",
      "(Validation) Loss: 1035900.6476, MAE: 3945.4377, R2: 0.1259\n",
      "==========================================================================================\n",
      "Epoch [3624/5000] | Time: 0.21s\n",
      "(Training) Loss: 1011307.9074\n",
      "(Validation) Loss: 1035789.5517, MAE: 3955.2756, R2: 0.1260\n",
      "==========================================================================================\n",
      "Epoch [3625/5000] | Time: 0.25s\n",
      "(Training) Loss: 995798.3109\n",
      "(Validation) Loss: 1035589.5111, MAE: 3947.0488, R2: 0.1262\n",
      "==========================================================================================\n",
      "Epoch [3626/5000] | Time: 0.35s\n",
      "(Training) Loss: 1035101.2107\n",
      "(Validation) Loss: 1035424.7467, MAE: 3943.1682, R2: 0.1263\n",
      "==========================================================================================\n",
      "Epoch [3627/5000] | Time: 0.28s\n",
      "(Training) Loss: 999826.4613\n",
      "(Validation) Loss: 1035260.7086, MAE: 3942.0906, R2: 0.1265\n",
      "==========================================================================================\n",
      "Epoch [3628/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005602.4492\n",
      "(Validation) Loss: 1035106.8952, MAE: 3942.4758, R2: 0.1266\n",
      "==========================================================================================\n",
      "Epoch [3629/5000] | Time: 0.31s\n",
      "(Training) Loss: 1000737.4721\n",
      "(Validation) Loss: 1034957.7397, MAE: 3944.2869, R2: 0.1267\n",
      "==========================================================================================\n",
      "Epoch [3630/5000] | Time: 0.33s\n",
      "(Training) Loss: 998901.0063\n",
      "(Validation) Loss: 1034863.7562, MAE: 3946.4644, R2: 0.1268\n",
      "==========================================================================================\n",
      "Epoch [3631/5000] | Time: 0.31s\n",
      "(Training) Loss: 994628.3560\n",
      "(Validation) Loss: 1034717.2876, MAE: 3949.2100, R2: 0.1269\n",
      "==========================================================================================\n",
      "Epoch [3632/5000] | Time: 0.25s\n",
      "(Training) Loss: 1010569.9264\n",
      "(Validation) Loss: 1034555.9365, MAE: 3946.9463, R2: 0.1270\n",
      "==========================================================================================\n",
      "Epoch [3633/5000] | Time: 0.27s\n",
      "(Training) Loss: 1008714.7126\n",
      "(Validation) Loss: 1034395.0375, MAE: 3945.4988, R2: 0.1272\n",
      "==========================================================================================\n",
      "Epoch [3634/5000] | Time: 0.21s\n",
      "(Training) Loss: 992918.6624\n",
      "(Validation) Loss: 1034229.7651, MAE: 3943.2231, R2: 0.1273\n",
      "==========================================================================================\n",
      "Epoch [3635/5000] | Time: 0.25s\n",
      "(Training) Loss: 1002945.2824\n",
      "(Validation) Loss: 1034080.9752, MAE: 3944.5024, R2: 0.1274\n",
      "==========================================================================================\n",
      "Epoch [3636/5000] | Time: 0.23s\n",
      "(Training) Loss: 1014986.6405\n",
      "(Validation) Loss: 1033919.9949, MAE: 3943.1902, R2: 0.1276\n",
      "==========================================================================================\n",
      "Epoch [3637/5000] | Time: 0.24s\n",
      "(Training) Loss: 995588.6383\n",
      "(Validation) Loss: 1033765.1911, MAE: 3944.0801, R2: 0.1277\n",
      "==========================================================================================\n",
      "Epoch [3638/5000] | Time: 0.28s\n",
      "(Training) Loss: 996850.8236\n",
      "(Validation) Loss: 1033609.1886, MAE: 3942.7781, R2: 0.1278\n",
      "==========================================================================================\n",
      "Epoch [3639/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001036.5482\n",
      "(Validation) Loss: 1033451.9771, MAE: 3943.0405, R2: 0.1280\n",
      "==========================================================================================\n",
      "Epoch [3640/5000] | Time: 0.22s\n",
      "(Training) Loss: 996957.5425\n",
      "(Validation) Loss: 1033291.3321, MAE: 3941.4443, R2: 0.1281\n",
      "==========================================================================================\n",
      "Epoch [3641/5000] | Time: 0.26s\n",
      "(Training) Loss: 1012391.5501\n",
      "(Validation) Loss: 1033138.5752, MAE: 3941.5400, R2: 0.1282\n",
      "==========================================================================================\n",
      "Epoch [3642/5000] | Time: 0.29s\n",
      "(Training) Loss: 1004652.7132\n",
      "(Validation) Loss: 1032973.6432, MAE: 3939.7371, R2: 0.1284\n",
      "==========================================================================================\n",
      "Epoch [3643/5000] | Time: 0.21s\n",
      "(Training) Loss: 990070.7744\n",
      "(Validation) Loss: 1032816.5384, MAE: 3938.9956, R2: 0.1285\n",
      "==========================================================================================\n",
      "Epoch [3644/5000] | Time: 0.24s\n",
      "(Training) Loss: 993864.4962\n",
      "(Validation) Loss: 1032660.4902, MAE: 3939.0076, R2: 0.1286\n",
      "==========================================================================================\n",
      "Epoch [3645/5000] | Time: 0.23s\n",
      "(Training) Loss: 1017002.3680\n",
      "(Validation) Loss: 1032503.4108, MAE: 3937.5032, R2: 0.1287\n",
      "==========================================================================================\n",
      "Epoch [3646/5000] | Time: 0.23s\n",
      "(Training) Loss: 1009557.8528\n",
      "(Validation) Loss: 1032353.8489, MAE: 3940.0918, R2: 0.1289\n",
      "==========================================================================================\n",
      "Epoch [3647/5000] | Time: 0.21s\n",
      "(Training) Loss: 1000079.7303\n",
      "(Validation) Loss: 1032189.2470, MAE: 3937.9102, R2: 0.1290\n",
      "==========================================================================================\n",
      "Epoch [3648/5000] | Time: 0.20s\n",
      "(Training) Loss: 1004963.6593\n",
      "(Validation) Loss: 1032062.1765, MAE: 3945.6699, R2: 0.1291\n",
      "==========================================================================================\n",
      "Epoch [3649/5000] | Time: 0.21s\n",
      "(Training) Loss: 1002413.3636\n",
      "(Validation) Loss: 1031880.5994, MAE: 3938.2175, R2: 0.1293\n",
      "==========================================================================================\n",
      "Epoch [3650/5000] | Time: 0.26s\n",
      "(Training) Loss: 995872.3369\n",
      "(Validation) Loss: 1031730.7327, MAE: 3938.5837, R2: 0.1294\n",
      "==========================================================================================\n",
      "Epoch [3651/5000] | Time: 0.24s\n",
      "(Training) Loss: 992546.3668\n",
      "(Validation) Loss: 1031556.6121, MAE: 3933.7512, R2: 0.1295\n",
      "==========================================================================================\n",
      "Epoch [3652/5000] | Time: 0.26s\n",
      "(Training) Loss: 1009628.6085\n",
      "(Validation) Loss: 1031405.1657, MAE: 3934.3735, R2: 0.1297\n",
      "==========================================================================================\n",
      "Epoch [3653/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010391.9105\n",
      "(Validation) Loss: 1031245.2114, MAE: 3934.1816, R2: 0.1298\n",
      "==========================================================================================\n",
      "Epoch [3654/5000] | Time: 0.29s\n",
      "(Training) Loss: 991063.1117\n",
      "(Validation) Loss: 1031087.9644, MAE: 3932.9045, R2: 0.1299\n",
      "==========================================================================================\n",
      "Epoch [3655/5000] | Time: 0.24s\n",
      "(Training) Loss: 997950.7373\n",
      "(Validation) Loss: 1030932.1803, MAE: 3931.9888, R2: 0.1301\n",
      "==========================================================================================\n",
      "Epoch [3656/5000] | Time: 0.24s\n",
      "(Training) Loss: 1001860.5279\n",
      "(Validation) Loss: 1030771.5200, MAE: 3930.9236, R2: 0.1302\n",
      "==========================================================================================\n",
      "Epoch [3657/5000] | Time: 0.27s\n",
      "(Training) Loss: 1003489.5114\n",
      "(Validation) Loss: 1030631.1517, MAE: 3934.9722, R2: 0.1303\n",
      "==========================================================================================\n",
      "Epoch [3658/5000] | Time: 0.25s\n",
      "(Training) Loss: 1006890.0235\n",
      "(Validation) Loss: 1030460.6984, MAE: 3930.8965, R2: 0.1305\n",
      "==========================================================================================\n",
      "Epoch [3659/5000] | Time: 0.25s\n",
      "(Training) Loss: 987908.5457\n",
      "(Validation) Loss: 1030296.6806, MAE: 3929.3359, R2: 0.1306\n",
      "==========================================================================================\n",
      "Epoch [3660/5000] | Time: 0.22s\n",
      "(Training) Loss: 986604.8192\n",
      "(Validation) Loss: 1030173.2673, MAE: 3939.4968, R2: 0.1307\n",
      "==========================================================================================\n",
      "Epoch [3661/5000] | Time: 0.26s\n",
      "(Training) Loss: 999000.3043\n",
      "(Validation) Loss: 1029951.2432, MAE: 3928.3760, R2: 0.1309\n",
      "==========================================================================================\n",
      "Epoch [3662/5000] | Time: 0.26s\n",
      "(Training) Loss: 998656.6656\n",
      "(Validation) Loss: 1029806.5219, MAE: 3928.3157, R2: 0.1310\n",
      "==========================================================================================\n",
      "Epoch [3663/5000] | Time: 0.27s\n",
      "(Training) Loss: 985686.9866\n",
      "(Validation) Loss: 1029635.3524, MAE: 3928.0120, R2: 0.1311\n",
      "==========================================================================================\n",
      "Epoch [3664/5000] | Time: 0.22s\n",
      "(Training) Loss: 995395.7157\n",
      "(Validation) Loss: 1029479.2635, MAE: 3926.6848, R2: 0.1313\n",
      "==========================================================================================\n",
      "Epoch [3665/5000] | Time: 0.21s\n",
      "(Training) Loss: 995492.4315\n",
      "(Validation) Loss: 1029319.4311, MAE: 3925.7112, R2: 0.1314\n",
      "==========================================================================================\n",
      "Epoch [3666/5000] | Time: 0.22s\n",
      "(Training) Loss: 994001.7779\n",
      "(Validation) Loss: 1029173.6076, MAE: 3927.1448, R2: 0.1315\n",
      "==========================================================================================\n",
      "Epoch [3667/5000] | Time: 0.22s\n",
      "(Training) Loss: 997285.5435\n",
      "(Validation) Loss: 1029009.3156, MAE: 3924.8096, R2: 0.1317\n",
      "==========================================================================================\n",
      "Epoch [3668/5000] | Time: 0.21s\n",
      "(Training) Loss: 984545.8703\n",
      "(Validation) Loss: 1028844.2667, MAE: 3921.4968, R2: 0.1318\n",
      "==========================================================================================\n",
      "Epoch [3669/5000] | Time: 0.21s\n",
      "(Training) Loss: 1006146.9112\n",
      "(Validation) Loss: 1028680.7010, MAE: 3919.0596, R2: 0.1319\n",
      "==========================================================================================\n",
      "Epoch [3670/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011953.4619\n",
      "(Validation) Loss: 1028617.7524, MAE: 3925.0149, R2: 0.1320\n",
      "==========================================================================================\n",
      "Epoch [3671/5000] | Time: 0.22s\n",
      "(Training) Loss: 985140.8745\n",
      "(Validation) Loss: 1028462.2070, MAE: 3925.6492, R2: 0.1321\n",
      "==========================================================================================\n",
      "Epoch [3672/5000] | Time: 0.21s\n",
      "(Training) Loss: 1004080.8147\n",
      "(Validation) Loss: 1028298.5956, MAE: 3922.9438, R2: 0.1323\n",
      "==========================================================================================\n",
      "Epoch [3673/5000] | Time: 0.24s\n",
      "(Training) Loss: 989197.8407\n",
      "(Validation) Loss: 1028140.7390, MAE: 3921.3855, R2: 0.1324\n",
      "==========================================================================================\n",
      "Epoch [3674/5000] | Time: 0.23s\n",
      "(Training) Loss: 1028931.5596\n",
      "(Validation) Loss: 1027985.3917, MAE: 3920.9119, R2: 0.1325\n",
      "==========================================================================================\n",
      "Epoch [3675/5000] | Time: 0.22s\n",
      "(Training) Loss: 1020122.0194\n",
      "(Validation) Loss: 1027825.4629, MAE: 3920.4390, R2: 0.1326\n",
      "==========================================================================================\n",
      "Epoch [3676/5000] | Time: 0.22s\n",
      "(Training) Loss: 988415.5406\n",
      "(Validation) Loss: 1027670.8114, MAE: 3920.9143, R2: 0.1328\n",
      "==========================================================================================\n",
      "Epoch [3677/5000] | Time: 0.23s\n",
      "(Training) Loss: 999314.0692\n",
      "(Validation) Loss: 1027512.7060, MAE: 3919.8044, R2: 0.1329\n",
      "==========================================================================================\n",
      "Epoch [3678/5000] | Time: 0.26s\n",
      "(Training) Loss: 995858.8959\n",
      "(Validation) Loss: 1027354.8749, MAE: 3918.8149, R2: 0.1330\n",
      "==========================================================================================\n",
      "Epoch [3679/5000] | Time: 0.23s\n",
      "(Training) Loss: 1011150.2170\n",
      "(Validation) Loss: 1027200.7975, MAE: 3918.0710, R2: 0.1332\n",
      "==========================================================================================\n",
      "Epoch [3680/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000527.1377\n",
      "(Validation) Loss: 1027047.7816, MAE: 3918.9966, R2: 0.1333\n",
      "==========================================================================================\n",
      "Epoch [3681/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001692.4486\n",
      "(Validation) Loss: 1026888.6197, MAE: 3917.5730, R2: 0.1334\n",
      "==========================================================================================\n",
      "Epoch [3682/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004512.1168\n",
      "(Validation) Loss: 1026726.9790, MAE: 3916.1133, R2: 0.1336\n",
      "==========================================================================================\n",
      "Epoch [3683/5000] | Time: 0.24s\n",
      "(Training) Loss: 987695.7183\n",
      "(Validation) Loss: 1026571.7435, MAE: 3915.5032, R2: 0.1337\n",
      "==========================================================================================\n",
      "Epoch [3684/5000] | Time: 0.23s\n",
      "(Training) Loss: 1022728.1967\n",
      "(Validation) Loss: 1026417.6660, MAE: 3914.7996, R2: 0.1338\n",
      "==========================================================================================\n",
      "Epoch [3685/5000] | Time: 0.23s\n",
      "(Training) Loss: 1010017.2754\n",
      "(Validation) Loss: 1026258.6159, MAE: 3914.7517, R2: 0.1340\n",
      "==========================================================================================\n",
      "Epoch [3686/5000] | Time: 0.21s\n",
      "(Training) Loss: 994447.2792\n",
      "(Validation) Loss: 1026102.7708, MAE: 3914.7170, R2: 0.1341\n",
      "==========================================================================================\n",
      "Epoch [3687/5000] | Time: 0.22s\n",
      "(Training) Loss: 985783.9004\n",
      "(Validation) Loss: 1025953.0768, MAE: 3914.6904, R2: 0.1342\n",
      "==========================================================================================\n",
      "Epoch [3688/5000] | Time: 0.24s\n",
      "(Training) Loss: 983711.3347\n",
      "(Validation) Loss: 1025788.7898, MAE: 3912.6523, R2: 0.1343\n",
      "==========================================================================================\n",
      "Epoch [3689/5000] | Time: 0.28s\n",
      "(Training) Loss: 988940.2240\n",
      "(Validation) Loss: 1025639.6851, MAE: 3913.6223, R2: 0.1345\n",
      "==========================================================================================\n",
      "Epoch [3690/5000] | Time: 0.27s\n",
      "(Training) Loss: 983375.9651\n",
      "(Validation) Loss: 1025481.3460, MAE: 3911.8479, R2: 0.1346\n",
      "==========================================================================================\n",
      "Epoch [3691/5000] | Time: 0.25s\n",
      "(Training) Loss: 989754.0961\n",
      "(Validation) Loss: 1025327.1111, MAE: 3911.2112, R2: 0.1347\n",
      "==========================================================================================\n",
      "Epoch [3692/5000] | Time: 0.29s\n",
      "(Training) Loss: 985085.1180\n",
      "(Validation) Loss: 1025172.4241, MAE: 3911.0952, R2: 0.1349\n",
      "==========================================================================================\n",
      "Epoch [3693/5000] | Time: 0.32s\n",
      "(Training) Loss: 998880.5197\n",
      "(Validation) Loss: 1025056.6654, MAE: 3916.8132, R2: 0.1350\n",
      "==========================================================================================\n",
      "Epoch [3694/5000] | Time: 0.33s\n",
      "(Training) Loss: 985543.3458\n",
      "(Validation) Loss: 1024859.1644, MAE: 3909.8120, R2: 0.1351\n",
      "==========================================================================================\n",
      "Epoch [3695/5000] | Time: 0.32s\n",
      "(Training) Loss: 991937.9613\n",
      "(Validation) Loss: 1024708.7797, MAE: 3909.7290, R2: 0.1352\n",
      "==========================================================================================\n",
      "Epoch [3696/5000] | Time: 0.32s\n",
      "(Training) Loss: 1000502.1701\n",
      "(Validation) Loss: 1024554.7937, MAE: 3909.2371, R2: 0.1354\n",
      "==========================================================================================\n",
      "Epoch [3697/5000] | Time: 0.31s\n",
      "(Training) Loss: 985232.7741\n",
      "(Validation) Loss: 1024398.2984, MAE: 3909.0422, R2: 0.1355\n",
      "==========================================================================================\n",
      "Epoch [3698/5000] | Time: 0.32s\n",
      "(Training) Loss: 984587.1545\n",
      "(Validation) Loss: 1024247.5327, MAE: 3909.3704, R2: 0.1356\n",
      "==========================================================================================\n",
      "Epoch [3699/5000] | Time: 0.34s\n",
      "(Training) Loss: 991369.9137\n",
      "(Validation) Loss: 1024093.3130, MAE: 3908.4697, R2: 0.1358\n",
      "==========================================================================================\n",
      "Epoch [3700/5000] | Time: 0.28s\n",
      "(Training) Loss: 984677.4879\n",
      "(Validation) Loss: 1023931.6673, MAE: 3906.2773, R2: 0.1359\n",
      "==========================================================================================\n",
      "Epoch [3701/5000] | Time: 0.28s\n",
      "(Training) Loss: 985533.5451\n",
      "(Validation) Loss: 1023778.1537, MAE: 3906.1436, R2: 0.1360\n",
      "==========================================================================================\n",
      "Epoch [3702/5000] | Time: 0.26s\n",
      "(Training) Loss: 993674.3261\n",
      "(Validation) Loss: 1023626.7835, MAE: 3905.5466, R2: 0.1361\n",
      "==========================================================================================\n",
      "Epoch [3703/5000] | Time: 0.33s\n",
      "(Training) Loss: 991780.7297\n",
      "(Validation) Loss: 1023470.0952, MAE: 3904.9758, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [3704/5000] | Time: 0.31s\n",
      "(Training) Loss: 991033.3852\n",
      "(Validation) Loss: 1023325.5365, MAE: 3907.3042, R2: 0.1364\n",
      "==========================================================================================\n",
      "Epoch [3705/5000] | Time: 0.29s\n",
      "(Training) Loss: 997528.5666\n",
      "(Validation) Loss: 1023168.7975, MAE: 3907.2886, R2: 0.1365\n",
      "==========================================================================================\n",
      "Epoch [3706/5000] | Time: 0.31s\n",
      "(Training) Loss: 993464.8471\n",
      "(Validation) Loss: 1023000.1422, MAE: 3902.8582, R2: 0.1367\n",
      "==========================================================================================\n",
      "Epoch [3707/5000] | Time: 0.27s\n",
      "(Training) Loss: 995665.9816\n",
      "(Validation) Loss: 1022840.1676, MAE: 3901.8464, R2: 0.1368\n",
      "==========================================================================================\n",
      "Epoch [3708/5000] | Time: 0.31s\n",
      "(Training) Loss: 998827.1764\n",
      "(Validation) Loss: 1022689.8083, MAE: 3901.5339, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [3709/5000] | Time: 0.29s\n",
      "(Training) Loss: 999752.3623\n",
      "(Validation) Loss: 1022532.8711, MAE: 3901.7058, R2: 0.1371\n",
      "==========================================================================================\n",
      "Epoch [3710/5000] | Time: 0.30s\n",
      "(Training) Loss: 996562.0235\n",
      "(Validation) Loss: 1022374.9892, MAE: 3900.4746, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [3711/5000] | Time: 0.28s\n",
      "(Training) Loss: 1000274.9070\n",
      "(Validation) Loss: 1022222.6387, MAE: 3900.2883, R2: 0.1373\n",
      "==========================================================================================\n",
      "Epoch [3712/5000] | Time: 0.30s\n",
      "(Training) Loss: 988887.9273\n",
      "(Validation) Loss: 1022067.7029, MAE: 3901.6248, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [3713/5000] | Time: 0.30s\n",
      "(Training) Loss: 985442.9784\n",
      "(Validation) Loss: 1021860.2413, MAE: 3896.6963, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [3714/5000] | Time: 0.29s\n",
      "(Training) Loss: 1003098.5190\n",
      "(Validation) Loss: 1045058.4940, MAE: 3975.7095, R2: 0.1183\n",
      "==========================================================================================\n",
      "Epoch [3715/5000] | Time: 0.31s\n",
      "(Training) Loss: 1015166.5006\n",
      "(Validation) Loss: 1044895.3752, MAE: 3975.2039, R2: 0.1184\n",
      "==========================================================================================\n",
      "Epoch [3716/5000] | Time: 0.28s\n",
      "(Training) Loss: 1007873.9124\n",
      "(Validation) Loss: 1044753.3562, MAE: 3978.9873, R2: 0.1185\n",
      "==========================================================================================\n",
      "Epoch [3717/5000] | Time: 0.28s\n",
      "(Training) Loss: 1011270.1745\n",
      "(Validation) Loss: 1044592.4775, MAE: 3979.3196, R2: 0.1187\n",
      "==========================================================================================\n",
      "Epoch [3718/5000] | Time: 0.28s\n",
      "(Training) Loss: 1012829.9385\n",
      "(Validation) Loss: 1044423.2889, MAE: 3976.6177, R2: 0.1188\n",
      "==========================================================================================\n",
      "Epoch [3719/5000] | Time: 0.30s\n",
      "(Training) Loss: 1008567.7716\n",
      "(Validation) Loss: 1044257.6254, MAE: 3974.9839, R2: 0.1190\n",
      "==========================================================================================\n",
      "Epoch [3720/5000] | Time: 0.23s\n",
      "(Training) Loss: 1011216.2811\n",
      "(Validation) Loss: 1044086.5778, MAE: 3972.0945, R2: 0.1191\n",
      "==========================================================================================\n",
      "Epoch [3721/5000] | Time: 0.32s\n",
      "(Training) Loss: 1012395.1808\n",
      "(Validation) Loss: 1043931.4946, MAE: 3973.3247, R2: 0.1192\n",
      "==========================================================================================\n",
      "Epoch [3722/5000] | Time: 0.29s\n",
      "(Training) Loss: 1000204.9300\n",
      "(Validation) Loss: 1043769.1479, MAE: 3973.1948, R2: 0.1194\n",
      "==========================================================================================\n",
      "Epoch [3723/5000] | Time: 0.22s\n",
      "(Training) Loss: 1000804.3706\n",
      "(Validation) Loss: 1043606.4051, MAE: 3971.7727, R2: 0.1195\n",
      "==========================================================================================\n",
      "Epoch [3724/5000] | Time: 0.22s\n",
      "(Training) Loss: 999092.8590\n",
      "(Validation) Loss: 1043457.7168, MAE: 3973.2495, R2: 0.1196\n",
      "==========================================================================================\n",
      "Epoch [3725/5000] | Time: 0.21s\n",
      "(Training) Loss: 1014532.5393\n",
      "(Validation) Loss: 1043290.3822, MAE: 3970.4517, R2: 0.1198\n",
      "==========================================================================================\n",
      "Epoch [3726/5000] | Time: 0.20s\n",
      "(Training) Loss: 1020940.4924\n",
      "(Validation) Loss: 1043135.6241, MAE: 3972.2620, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [3727/5000] | Time: 0.19s\n",
      "(Training) Loss: 1012958.0273\n",
      "(Validation) Loss: 1042964.6781, MAE: 3969.1089, R2: 0.1200\n",
      "==========================================================================================\n",
      "Epoch [3728/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002595.8496\n",
      "(Validation) Loss: 1042806.8063, MAE: 3968.8330, R2: 0.1202\n",
      "==========================================================================================\n",
      "Epoch [3729/5000] | Time: 0.22s\n",
      "(Training) Loss: 999120.5674\n",
      "(Validation) Loss: 1042642.1994, MAE: 3967.4321, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [3730/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007627.8883\n",
      "(Validation) Loss: 1042479.2635, MAE: 3966.9309, R2: 0.1204\n",
      "==========================================================================================\n",
      "Epoch [3731/5000] | Time: 0.21s\n",
      "(Training) Loss: 1008951.2786\n",
      "(Validation) Loss: 1042324.0279, MAE: 3967.2322, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [3732/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009445.6371\n",
      "(Validation) Loss: 1042172.0178, MAE: 3967.9785, R2: 0.1207\n",
      "==========================================================================================\n",
      "Epoch [3733/5000] | Time: 0.26s\n",
      "(Training) Loss: 1001361.8642\n",
      "(Validation) Loss: 1042005.3029, MAE: 3966.2581, R2: 0.1208\n",
      "==========================================================================================\n",
      "Epoch [3734/5000] | Time: 0.25s\n",
      "(Training) Loss: 996751.4304\n",
      "(Validation) Loss: 1041859.5657, MAE: 3967.2974, R2: 0.1210\n",
      "==========================================================================================\n",
      "Epoch [3735/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007533.8509\n",
      "(Validation) Loss: 1046646.1105, MAE: 3984.5288, R2: 0.1170\n",
      "==========================================================================================\n",
      "Epoch [3736/5000] | Time: 0.24s\n",
      "(Training) Loss: 1023496.0428\n",
      "(Validation) Loss: 1046465.0717, MAE: 3982.7761, R2: 0.1171\n",
      "==========================================================================================\n",
      "Epoch [3737/5000] | Time: 0.21s\n",
      "(Training) Loss: 1023073.2931\n",
      "(Validation) Loss: 1046296.1473, MAE: 3983.6609, R2: 0.1173\n",
      "==========================================================================================\n",
      "Epoch [3738/5000] | Time: 0.22s\n",
      "(Training) Loss: 1019761.2227\n",
      "(Validation) Loss: 1046120.5232, MAE: 3981.4758, R2: 0.1174\n",
      "==========================================================================================\n",
      "Epoch [3739/5000] | Time: 0.22s\n",
      "(Training) Loss: 1014877.9067\n",
      "(Validation) Loss: 1045946.4635, MAE: 3978.9373, R2: 0.1175\n",
      "==========================================================================================\n",
      "Epoch [3740/5000] | Time: 0.25s\n",
      "(Training) Loss: 1011163.0298\n",
      "(Validation) Loss: 1045794.2705, MAE: 3983.2229, R2: 0.1177\n",
      "==========================================================================================\n",
      "Epoch [3741/5000] | Time: 0.26s\n",
      "(Training) Loss: 1017143.2449\n",
      "(Validation) Loss: 1045614.8775, MAE: 3978.8564, R2: 0.1178\n",
      "==========================================================================================\n",
      "Epoch [3742/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023617.7011\n",
      "(Validation) Loss: 1045450.7225, MAE: 3978.0339, R2: 0.1180\n",
      "==========================================================================================\n",
      "Epoch [3743/5000] | Time: 0.25s\n",
      "(Training) Loss: 1004987.2608\n",
      "(Validation) Loss: 1045277.5010, MAE: 3976.5801, R2: 0.1181\n",
      "==========================================================================================\n",
      "Epoch [3744/5000] | Time: 0.23s\n",
      "(Training) Loss: 1027779.0044\n",
      "(Validation) Loss: 1045139.3829, MAE: 3982.2727, R2: 0.1182\n",
      "==========================================================================================\n",
      "Epoch [3745/5000] | Time: 0.34s\n",
      "(Training) Loss: 1017582.8299\n",
      "(Validation) Loss: 1044962.0775, MAE: 3979.2134, R2: 0.1184\n",
      "==========================================================================================\n",
      "Epoch [3746/5000] | Time: 0.21s\n",
      "(Training) Loss: 1031225.5828\n",
      "(Validation) Loss: 1044784.9651, MAE: 3976.7356, R2: 0.1185\n",
      "==========================================================================================\n",
      "Epoch [3747/5000] | Time: 0.23s\n",
      "(Training) Loss: 1024454.6339\n",
      "(Validation) Loss: 1044612.8051, MAE: 3973.1111, R2: 0.1187\n",
      "==========================================================================================\n",
      "Epoch [3748/5000] | Time: 0.28s\n",
      "(Training) Loss: 1026485.4949\n",
      "(Validation) Loss: 1044449.1225, MAE: 3973.4653, R2: 0.1188\n",
      "==========================================================================================\n",
      "Epoch [3749/5000] | Time: 0.25s\n",
      "(Training) Loss: 1029817.8058\n",
      "(Validation) Loss: 1044279.8425, MAE: 3971.9988, R2: 0.1189\n",
      "==========================================================================================\n",
      "Epoch [3750/5000] | Time: 0.21s\n",
      "(Training) Loss: 1010179.8198\n",
      "(Validation) Loss: 1044114.7886, MAE: 3972.9524, R2: 0.1191\n",
      "==========================================================================================\n",
      "Epoch [3751/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016814.9898\n",
      "(Validation) Loss: 1043950.8978, MAE: 3971.1250, R2: 0.1192\n",
      "==========================================================================================\n",
      "Epoch [3752/5000] | Time: 0.27s\n",
      "(Training) Loss: 1043392.0647\n",
      "(Validation) Loss: 1043807.6343, MAE: 3976.0261, R2: 0.1193\n",
      "==========================================================================================\n",
      "Epoch [3753/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007040.4829\n",
      "(Validation) Loss: 1043644.7594, MAE: 3975.3416, R2: 0.1195\n",
      "==========================================================================================\n",
      "Epoch [3754/5000] | Time: 0.23s\n",
      "(Training) Loss: 1036078.7157\n",
      "(Validation) Loss: 1043476.3429, MAE: 3972.7085, R2: 0.1196\n",
      "==========================================================================================\n",
      "Epoch [3755/5000] | Time: 0.27s\n",
      "(Training) Loss: 1019642.1675\n",
      "(Validation) Loss: 1043314.5244, MAE: 3972.9780, R2: 0.1197\n",
      "==========================================================================================\n",
      "Epoch [3756/5000] | Time: 0.20s\n",
      "(Training) Loss: 1001407.8947\n",
      "(Validation) Loss: 1043143.8425, MAE: 3971.7126, R2: 0.1199\n",
      "==========================================================================================\n",
      "Epoch [3757/5000] | Time: 0.25s\n",
      "(Training) Loss: 1007623.1231\n",
      "(Validation) Loss: 1042980.7797, MAE: 3969.0483, R2: 0.1200\n",
      "==========================================================================================\n",
      "Epoch [3758/5000] | Time: 0.28s\n",
      "(Training) Loss: 1006343.0190\n",
      "(Validation) Loss: 1042825.4375, MAE: 3969.9263, R2: 0.1201\n",
      "==========================================================================================\n",
      "Epoch [3759/5000] | Time: 0.26s\n",
      "(Training) Loss: 1027586.1003\n",
      "(Validation) Loss: 1042658.9003, MAE: 3968.4702, R2: 0.1203\n",
      "==========================================================================================\n",
      "Epoch [3760/5000] | Time: 0.21s\n",
      "(Training) Loss: 1002025.9721\n",
      "(Validation) Loss: 1042490.3822, MAE: 3966.8403, R2: 0.1204\n",
      "==========================================================================================\n",
      "Epoch [3761/5000] | Time: 0.23s\n",
      "(Training) Loss: 997600.1662\n",
      "(Validation) Loss: 1042328.4673, MAE: 3966.4580, R2: 0.1206\n",
      "==========================================================================================\n",
      "Epoch [3762/5000] | Time: 0.28s\n",
      "(Training) Loss: 1024692.7893\n",
      "(Validation) Loss: 1042171.8349, MAE: 3966.0271, R2: 0.1207\n",
      "==========================================================================================\n",
      "Epoch [3763/5000] | Time: 0.22s\n",
      "(Training) Loss: 1008637.9530\n",
      "(Validation) Loss: 1042010.5498, MAE: 3966.7488, R2: 0.1208\n",
      "==========================================================================================\n",
      "Epoch [3764/5000] | Time: 0.26s\n",
      "(Training) Loss: 1013692.3522\n",
      "(Validation) Loss: 1041844.2108, MAE: 3964.0845, R2: 0.1210\n",
      "==========================================================================================\n",
      "Epoch [3765/5000] | Time: 0.23s\n",
      "(Training) Loss: 1015239.1237\n",
      "(Validation) Loss: 1041684.4241, MAE: 3965.7512, R2: 0.1211\n",
      "==========================================================================================\n",
      "Epoch [3766/5000] | Time: 0.22s\n",
      "(Training) Loss: 1015371.2525\n",
      "(Validation) Loss: 1041549.4705, MAE: 3970.4482, R2: 0.1212\n",
      "==========================================================================================\n",
      "Epoch [3767/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012592.2227\n",
      "(Validation) Loss: 1041366.4102, MAE: 3965.1206, R2: 0.1214\n",
      "==========================================================================================\n",
      "Epoch [3768/5000] | Time: 0.22s\n",
      "(Training) Loss: 1017730.2868\n",
      "(Validation) Loss: 1041201.2241, MAE: 3963.3718, R2: 0.1215\n",
      "==========================================================================================\n",
      "Epoch [3769/5000] | Time: 0.23s\n",
      "(Training) Loss: 996678.1307\n",
      "(Validation) Loss: 1041034.4533, MAE: 3961.8530, R2: 0.1216\n",
      "==========================================================================================\n",
      "Epoch [3770/5000] | Time: 0.25s\n",
      "(Training) Loss: 998591.1929\n",
      "(Validation) Loss: 1040878.0038, MAE: 3962.5845, R2: 0.1218\n",
      "==========================================================================================\n",
      "Epoch [3771/5000] | Time: 0.22s\n",
      "(Training) Loss: 1009278.9194\n",
      "(Validation) Loss: 1040720.8584, MAE: 3964.3491, R2: 0.1219\n",
      "==========================================================================================\n",
      "Epoch [3772/5000] | Time: 0.23s\n",
      "(Training) Loss: 1030445.9454\n",
      "(Validation) Loss: 1040555.6267, MAE: 3961.2498, R2: 0.1220\n",
      "==========================================================================================\n",
      "Epoch [3773/5000] | Time: 0.35s\n",
      "(Training) Loss: 997788.7005\n",
      "(Validation) Loss: 1040395.8857, MAE: 3961.9260, R2: 0.1222\n",
      "==========================================================================================\n",
      "Epoch [3774/5000] | Time: 0.30s\n",
      "(Training) Loss: 1007900.8680\n",
      "(Validation) Loss: 1040238.4711, MAE: 3961.0784, R2: 0.1223\n",
      "==========================================================================================\n",
      "Epoch [3775/5000] | Time: 0.35s\n",
      "(Training) Loss: 1008957.0552\n",
      "(Validation) Loss: 1040074.8648, MAE: 3960.5781, R2: 0.1224\n",
      "==========================================================================================\n",
      "Epoch [3776/5000] | Time: 0.22s\n",
      "(Training) Loss: 1028809.0311\n",
      "(Validation) Loss: 1039913.6000, MAE: 3960.0559, R2: 0.1226\n",
      "==========================================================================================\n",
      "Epoch [3777/5000] | Time: 0.23s\n",
      "(Training) Loss: 1026569.9613\n",
      "(Validation) Loss: 1039742.2070, MAE: 3957.0500, R2: 0.1227\n",
      "==========================================================================================\n",
      "Epoch [3778/5000] | Time: 0.27s\n",
      "(Training) Loss: 1013126.0755\n",
      "(Validation) Loss: 1039589.4400, MAE: 3959.7195, R2: 0.1228\n",
      "==========================================================================================\n",
      "Epoch [3779/5000] | Time: 0.21s\n",
      "(Training) Loss: 1006983.1409\n",
      "(Validation) Loss: 1039428.0229, MAE: 3958.3264, R2: 0.1230\n",
      "==========================================================================================\n",
      "Epoch [3780/5000] | Time: 0.22s\n",
      "(Training) Loss: 1004371.9867\n",
      "(Validation) Loss: 1039268.3429, MAE: 3958.4983, R2: 0.1231\n",
      "==========================================================================================\n",
      "Epoch [3781/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011764.4467\n",
      "(Validation) Loss: 1039102.3492, MAE: 3957.0540, R2: 0.1232\n",
      "==========================================================================================\n",
      "Epoch [3782/5000] | Time: 0.24s\n",
      "(Training) Loss: 1002372.6929\n",
      "(Validation) Loss: 1038938.2349, MAE: 3955.7170, R2: 0.1234\n",
      "==========================================================================================\n",
      "Epoch [3783/5000] | Time: 0.23s\n",
      "(Training) Loss: 1000373.2982\n",
      "(Validation) Loss: 1038776.8483, MAE: 3954.9419, R2: 0.1235\n",
      "==========================================================================================\n",
      "Epoch [3784/5000] | Time: 0.24s\n",
      "(Training) Loss: 998803.3544\n",
      "(Validation) Loss: 1038616.7365, MAE: 3955.9036, R2: 0.1237\n",
      "==========================================================================================\n",
      "Epoch [3785/5000] | Time: 0.24s\n",
      "(Training) Loss: 1014122.6536\n",
      "(Validation) Loss: 1038456.2235, MAE: 3953.3137, R2: 0.1238\n",
      "==========================================================================================\n",
      "Epoch [3786/5000] | Time: 0.24s\n",
      "(Training) Loss: 1007889.1637\n",
      "(Validation) Loss: 1038292.4343, MAE: 3952.8899, R2: 0.1239\n",
      "==========================================================================================\n",
      "Epoch [3787/5000] | Time: 0.26s\n",
      "(Training) Loss: 1008916.0596\n",
      "(Validation) Loss: 1038143.4514, MAE: 3956.3074, R2: 0.1240\n",
      "==========================================================================================\n",
      "Epoch [3788/5000] | Time: 0.23s\n",
      "(Training) Loss: 1009800.7468\n",
      "(Validation) Loss: 1037979.8298, MAE: 3955.5022, R2: 0.1242\n",
      "==========================================================================================\n",
      "Epoch [3789/5000] | Time: 0.27s\n",
      "(Training) Loss: 1015074.9930\n",
      "(Validation) Loss: 1037808.3149, MAE: 3950.3369, R2: 0.1243\n",
      "==========================================================================================\n",
      "Epoch [3790/5000] | Time: 0.37s\n",
      "(Training) Loss: 1012242.8953\n",
      "(Validation) Loss: 1037648.0406, MAE: 3950.9580, R2: 0.1245\n",
      "==========================================================================================\n",
      "Epoch [3791/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006815.8046\n",
      "(Validation) Loss: 1037485.0743, MAE: 3950.1541, R2: 0.1246\n",
      "==========================================================================================\n",
      "Epoch [3792/5000] | Time: 0.21s\n",
      "(Training) Loss: 995649.9778\n",
      "(Validation) Loss: 1037328.3556, MAE: 3951.0298, R2: 0.1247\n",
      "==========================================================================================\n",
      "Epoch [3793/5000] | Time: 0.21s\n",
      "(Training) Loss: 1014412.3566\n",
      "(Validation) Loss: 1037170.9511, MAE: 3950.1880, R2: 0.1249\n",
      "==========================================================================================\n",
      "Epoch [3794/5000] | Time: 0.26s\n",
      "(Training) Loss: 998628.3014\n",
      "(Validation) Loss: 1037013.6940, MAE: 3950.5168, R2: 0.1250\n",
      "==========================================================================================\n",
      "Epoch [3795/5000] | Time: 0.26s\n",
      "(Training) Loss: 1002966.6142\n",
      "(Validation) Loss: 1036846.3543, MAE: 3948.6821, R2: 0.1251\n",
      "==========================================================================================\n",
      "Epoch [3796/5000] | Time: 0.25s\n",
      "(Training) Loss: 1009026.8788\n",
      "(Validation) Loss: 1036689.9454, MAE: 3948.8196, R2: 0.1253\n",
      "==========================================================================================\n",
      "Epoch [3797/5000] | Time: 0.26s\n",
      "(Training) Loss: 1017085.4162\n",
      "(Validation) Loss: 1036523.2559, MAE: 3947.5779, R2: 0.1254\n",
      "==========================================================================================\n",
      "Epoch [3798/5000] | Time: 0.23s\n",
      "(Training) Loss: 1019055.1142\n",
      "(Validation) Loss: 1036361.9708, MAE: 3946.4231, R2: 0.1255\n",
      "==========================================================================================\n",
      "Epoch [3799/5000] | Time: 0.27s\n",
      "(Training) Loss: 1034945.6681\n",
      "(Validation) Loss: 1036201.3308, MAE: 3947.0930, R2: 0.1257\n",
      "==========================================================================================\n",
      "Epoch [3800/5000] | Time: 0.22s\n",
      "(Training) Loss: 996687.7437\n",
      "(Validation) Loss: 1036038.1765, MAE: 3945.0847, R2: 0.1258\n",
      "==========================================================================================\n",
      "Epoch [3801/5000] | Time: 0.22s\n",
      "(Training) Loss: 1012868.8915\n",
      "(Validation) Loss: 1035879.6546, MAE: 3945.2974, R2: 0.1259\n",
      "==========================================================================================\n",
      "Epoch [3802/5000] | Time: 0.22s\n",
      "(Training) Loss: 998929.3896\n",
      "(Validation) Loss: 1035714.8800, MAE: 3944.3713, R2: 0.1261\n",
      "==========================================================================================\n",
      "Epoch [3803/5000] | Time: 0.22s\n",
      "(Training) Loss: 1013588.5419\n",
      "(Validation) Loss: 1035561.6102, MAE: 3945.2529, R2: 0.1262\n",
      "==========================================================================================\n",
      "Epoch [3804/5000] | Time: 0.22s\n",
      "(Training) Loss: 1005573.0761\n",
      "(Validation) Loss: 1035398.6590, MAE: 3942.8066, R2: 0.1263\n",
      "==========================================================================================\n",
      "Epoch [3805/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001023.6440\n",
      "(Validation) Loss: 1035248.3048, MAE: 3946.4956, R2: 0.1265\n",
      "==========================================================================================\n",
      "Epoch [3806/5000] | Time: 0.24s\n",
      "(Training) Loss: 990276.1315\n",
      "(Validation) Loss: 1035078.4965, MAE: 3943.0876, R2: 0.1266\n",
      "==========================================================================================\n",
      "Epoch [3807/5000] | Time: 0.28s\n",
      "(Training) Loss: 998630.3058\n",
      "(Validation) Loss: 1034917.5517, MAE: 3941.2717, R2: 0.1267\n",
      "==========================================================================================\n",
      "Epoch [3808/5000] | Time: 0.34s\n",
      "(Training) Loss: 991481.8149\n",
      "(Validation) Loss: 1034755.4235, MAE: 3940.3191, R2: 0.1269\n",
      "==========================================================================================\n",
      "Epoch [3809/5000] | Time: 0.22s\n",
      "(Training) Loss: 1013694.0825\n",
      "(Validation) Loss: 1034604.6425, MAE: 3941.6392, R2: 0.1270\n",
      "==========================================================================================\n",
      "Epoch [3810/5000] | Time: 0.21s\n",
      "(Training) Loss: 1003243.6542\n",
      "(Validation) Loss: 1034436.4851, MAE: 3938.8887, R2: 0.1271\n",
      "==========================================================================================\n",
      "Epoch [3811/5000] | Time: 0.21s\n",
      "(Training) Loss: 991377.1079\n",
      "(Validation) Loss: 1034297.1632, MAE: 3942.8572, R2: 0.1273\n",
      "==========================================================================================\n",
      "Epoch [3812/5000] | Time: 0.24s\n",
      "(Training) Loss: 995550.9435\n",
      "(Validation) Loss: 1034128.6908, MAE: 3940.9294, R2: 0.1274\n",
      "==========================================================================================\n",
      "Epoch [3813/5000] | Time: 0.19s\n",
      "(Training) Loss: 1015297.6161\n",
      "(Validation) Loss: 1033961.2698, MAE: 3939.2896, R2: 0.1275\n",
      "==========================================================================================\n",
      "Epoch [3814/5000] | Time: 0.19s\n",
      "(Training) Loss: 1012828.2091\n",
      "(Validation) Loss: 1033802.1130, MAE: 3937.2209, R2: 0.1277\n",
      "==========================================================================================\n",
      "Epoch [3815/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011467.1256\n",
      "(Validation) Loss: 1033639.3346, MAE: 3937.3447, R2: 0.1278\n",
      "==========================================================================================\n",
      "Epoch [3816/5000] | Time: 0.21s\n",
      "(Training) Loss: 998004.5780\n",
      "(Validation) Loss: 1033479.7613, MAE: 3937.1155, R2: 0.1279\n",
      "==========================================================================================\n",
      "Epoch [3817/5000] | Time: 0.23s\n",
      "(Training) Loss: 990995.8249\n",
      "(Validation) Loss: 1033316.9067, MAE: 3935.9475, R2: 0.1281\n",
      "==========================================================================================\n",
      "Epoch [3818/5000] | Time: 0.24s\n",
      "(Training) Loss: 1004104.6878\n",
      "(Validation) Loss: 1033162.7733, MAE: 3936.3374, R2: 0.1282\n",
      "==========================================================================================\n",
      "Epoch [3819/5000] | Time: 0.24s\n",
      "(Training) Loss: 993815.0336\n",
      "(Validation) Loss: 1033003.3829, MAE: 3936.5117, R2: 0.1283\n",
      "==========================================================================================\n",
      "Epoch [3820/5000] | Time: 0.25s\n",
      "(Training) Loss: 992956.6897\n",
      "(Validation) Loss: 1032855.7460, MAE: 3938.0964, R2: 0.1285\n",
      "==========================================================================================\n",
      "Epoch [3821/5000] | Time: 0.25s\n",
      "(Training) Loss: 1016104.7183\n",
      "(Validation) Loss: 1032686.7352, MAE: 3935.8252, R2: 0.1286\n",
      "==========================================================================================\n",
      "Epoch [3822/5000] | Time: 0.22s\n",
      "(Training) Loss: 995176.8921\n",
      "(Validation) Loss: 1032518.8825, MAE: 3933.5039, R2: 0.1287\n",
      "==========================================================================================\n",
      "Epoch [3823/5000] | Time: 0.21s\n",
      "(Training) Loss: 1008172.6555\n",
      "(Validation) Loss: 1032359.0400, MAE: 3932.4285, R2: 0.1289\n",
      "==========================================================================================\n",
      "Epoch [3824/5000] | Time: 0.20s\n",
      "(Training) Loss: 1000997.9461\n",
      "(Validation) Loss: 1032210.8698, MAE: 3935.1895, R2: 0.1290\n",
      "==========================================================================================\n",
      "Epoch [3825/5000] | Time: 0.22s\n",
      "(Training) Loss: 1005394.4613\n",
      "(Validation) Loss: 1032047.5073, MAE: 3937.8848, R2: 0.1291\n",
      "==========================================================================================\n",
      "Epoch [3826/5000] | Time: 0.24s\n",
      "(Training) Loss: 1021823.0552\n",
      "(Validation) Loss: 1031878.7098, MAE: 3931.1636, R2: 0.1293\n",
      "==========================================================================================\n",
      "Epoch [3827/5000] | Time: 0.24s\n",
      "(Training) Loss: 1005843.6745\n",
      "(Validation) Loss: 1031731.1746, MAE: 3934.7195, R2: 0.1294\n",
      "==========================================================================================\n",
      "Epoch [3828/5000] | Time: 0.22s\n",
      "(Training) Loss: 990880.1374\n",
      "(Validation) Loss: 1031555.8756, MAE: 3929.6001, R2: 0.1295\n",
      "==========================================================================================\n",
      "Epoch [3829/5000] | Time: 0.21s\n",
      "(Training) Loss: 987364.0209\n",
      "(Validation) Loss: 1031397.2622, MAE: 3930.0356, R2: 0.1297\n",
      "==========================================================================================\n",
      "Epoch [3830/5000] | Time: 0.22s\n",
      "(Training) Loss: 1007687.9505\n",
      "(Validation) Loss: 1031262.3949, MAE: 3934.9602, R2: 0.1298\n",
      "==========================================================================================\n",
      "Epoch [3831/5000] | Time: 0.20s\n",
      "(Training) Loss: 1017453.5273\n",
      "(Validation) Loss: 1031077.2927, MAE: 3927.8289, R2: 0.1299\n",
      "==========================================================================================\n",
      "Epoch [3832/5000] | Time: 0.22s\n",
      "(Training) Loss: 991771.4695\n",
      "(Validation) Loss: 1030930.4889, MAE: 3931.7297, R2: 0.1301\n",
      "==========================================================================================\n",
      "Epoch [3833/5000] | Time: 0.22s\n",
      "(Training) Loss: 989184.8360\n",
      "(Validation) Loss: 1030767.1568, MAE: 3930.0049, R2: 0.1302\n",
      "==========================================================================================\n",
      "Epoch [3834/5000] | Time: 0.22s\n",
      "(Training) Loss: 986350.6263\n",
      "(Validation) Loss: 1023605.3130, MAE: 3958.8887, R2: 0.1362\n",
      "==========================================================================================\n",
      "Epoch [3835/5000] | Time: 0.23s\n",
      "(Training) Loss: 987192.8096\n",
      "(Validation) Loss: 1023404.2565, MAE: 3925.1523, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [3836/5000] | Time: 0.22s\n",
      "(Training) Loss: 986569.8306\n",
      "(Validation) Loss: 1023294.2171, MAE: 3930.3540, R2: 0.1364\n",
      "==========================================================================================\n",
      "Epoch [3837/5000] | Time: 0.23s\n",
      "(Training) Loss: 982062.1123\n",
      "(Validation) Loss: 1023093.8768, MAE: 3918.0156, R2: 0.1366\n",
      "==========================================================================================\n",
      "Epoch [3838/5000] | Time: 0.24s\n",
      "(Training) Loss: 983203.7735\n",
      "(Validation) Loss: 1022916.1448, MAE: 3910.9443, R2: 0.1367\n",
      "==========================================================================================\n",
      "Epoch [3839/5000] | Time: 0.27s\n",
      "(Training) Loss: 1003217.9499\n",
      "(Validation) Loss: 1022771.3676, MAE: 3913.6716, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [3840/5000] | Time: 0.22s\n",
      "(Training) Loss: 1011769.7868\n",
      "(Validation) Loss: 1022614.7810, MAE: 3912.3550, R2: 0.1370\n",
      "==========================================================================================\n",
      "Epoch [3841/5000] | Time: 0.23s\n",
      "(Training) Loss: 993287.0159\n",
      "(Validation) Loss: 1022486.9740, MAE: 3916.1106, R2: 0.1371\n",
      "==========================================================================================\n",
      "Epoch [3842/5000] | Time: 0.23s\n",
      "(Training) Loss: 987549.8388\n",
      "(Validation) Loss: 1022308.8762, MAE: 3908.5500, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [3843/5000] | Time: 0.22s\n",
      "(Training) Loss: 986110.5482\n",
      "(Validation) Loss: 1022135.7613, MAE: 3904.4675, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [3844/5000] | Time: 0.22s\n",
      "(Training) Loss: 983125.6453\n",
      "(Validation) Loss: 1021997.1200, MAE: 3907.6003, R2: 0.1375\n",
      "==========================================================================================\n",
      "Epoch [3845/5000] | Time: 0.23s\n",
      "(Training) Loss: 1015903.4105\n",
      "(Validation) Loss: 1021841.1733, MAE: 3905.2908, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [3846/5000] | Time: 0.25s\n",
      "(Training) Loss: 991563.3179\n",
      "(Validation) Loss: 1021694.5219, MAE: 3906.8223, R2: 0.1378\n",
      "==========================================================================================\n",
      "Epoch [3847/5000] | Time: 0.23s\n",
      "(Training) Loss: 981476.2881\n",
      "(Validation) Loss: 1021528.1879, MAE: 3904.4521, R2: 0.1379\n",
      "==========================================================================================\n",
      "Epoch [3848/5000] | Time: 0.22s\n",
      "(Training) Loss: 998030.0006\n",
      "(Validation) Loss: 1021359.9390, MAE: 3900.7527, R2: 0.1380\n",
      "==========================================================================================\n",
      "Epoch [3849/5000] | Time: 0.23s\n",
      "(Training) Loss: 982013.5108\n",
      "(Validation) Loss: 1021229.6838, MAE: 3905.0647, R2: 0.1381\n",
      "==========================================================================================\n",
      "Epoch [3850/5000] | Time: 0.22s\n",
      "(Training) Loss: 992114.7887\n",
      "(Validation) Loss: 1021051.9568, MAE: 3899.4854, R2: 0.1383\n",
      "==========================================================================================\n",
      "Epoch [3851/5000] | Time: 0.21s\n",
      "(Training) Loss: 989525.1091\n",
      "(Validation) Loss: 1020898.7276, MAE: 3899.3069, R2: 0.1384\n",
      "==========================================================================================\n",
      "Epoch [3852/5000] | Time: 0.23s\n",
      "(Training) Loss: 993408.1523\n",
      "(Validation) Loss: 1020744.7975, MAE: 3898.6165, R2: 0.1385\n",
      "==========================================================================================\n",
      "Epoch [3853/5000] | Time: 0.25s\n",
      "(Training) Loss: 985398.4372\n",
      "(Validation) Loss: 1020592.0711, MAE: 3898.6926, R2: 0.1387\n",
      "==========================================================================================\n",
      "Epoch [3854/5000] | Time: 0.22s\n",
      "(Training) Loss: 991034.1840\n",
      "(Validation) Loss: 1020434.0470, MAE: 3896.7861, R2: 0.1388\n",
      "==========================================================================================\n",
      "Epoch [3855/5000] | Time: 0.23s\n",
      "(Training) Loss: 981981.2919\n",
      "(Validation) Loss: 1020300.4851, MAE: 3899.4993, R2: 0.1389\n",
      "==========================================================================================\n",
      "Epoch [3856/5000] | Time: 0.24s\n",
      "(Training) Loss: 983339.1466\n",
      "(Validation) Loss: 1020127.6851, MAE: 3895.9800, R2: 0.1391\n",
      "==========================================================================================\n",
      "Epoch [3857/5000] | Time: 0.24s\n",
      "(Training) Loss: 982295.6359\n",
      "(Validation) Loss: 1019975.3651, MAE: 3895.7529, R2: 0.1392\n",
      "==========================================================================================\n",
      "Epoch [3858/5000] | Time: 0.23s\n",
      "(Training) Loss: 1023504.0241\n",
      "(Validation) Loss: 1019813.7549, MAE: 3893.3142, R2: 0.1393\n",
      "==========================================================================================\n",
      "Epoch [3859/5000] | Time: 0.22s\n",
      "(Training) Loss: 1003203.5152\n",
      "(Validation) Loss: 1019659.3829, MAE: 3894.3342, R2: 0.1395\n",
      "==========================================================================================\n",
      "Epoch [3860/5000] | Time: 0.23s\n",
      "(Training) Loss: 977220.6545\n",
      "(Validation) Loss: 1019511.8578, MAE: 3895.4163, R2: 0.1396\n",
      "==========================================================================================\n",
      "Epoch [3861/5000] | Time: 0.23s\n",
      "(Training) Loss: 990104.1891\n",
      "(Validation) Loss: 1019370.3314, MAE: 3896.0955, R2: 0.1397\n",
      "==========================================================================================\n",
      "Epoch [3862/5000] | Time: 0.22s\n",
      "(Training) Loss: 985012.9201\n",
      "(Validation) Loss: 1019231.3803, MAE: 3899.8528, R2: 0.1398\n",
      "==========================================================================================\n",
      "Epoch [3863/5000] | Time: 0.23s\n",
      "(Training) Loss: 999710.2728\n",
      "(Validation) Loss: 1019119.5937, MAE: 3897.7534, R2: 0.1399\n",
      "==========================================================================================\n",
      "Epoch [3864/5000] | Time: 0.22s\n",
      "(Training) Loss: 997276.7354\n",
      "(Validation) Loss: 1018958.0952, MAE: 3895.2244, R2: 0.1400\n",
      "==========================================================================================\n",
      "Epoch [3865/5000] | Time: 0.27s\n",
      "(Training) Loss: 985869.7075\n",
      "(Validation) Loss: 1018801.9606, MAE: 3894.6599, R2: 0.1402\n",
      "==========================================================================================\n",
      "Epoch [3866/5000] | Time: 0.39s\n",
      "(Training) Loss: 983918.7291\n",
      "(Validation) Loss: 1018650.5498, MAE: 3895.3342, R2: 0.1403\n",
      "==========================================================================================\n",
      "Epoch [3867/5000] | Time: 0.21s\n",
      "(Training) Loss: 980184.0558\n",
      "(Validation) Loss: 1018495.1416, MAE: 3894.3647, R2: 0.1404\n",
      "==========================================================================================\n",
      "Epoch [3868/5000] | Time: 0.25s\n",
      "(Training) Loss: 990554.4213\n",
      "(Validation) Loss: 1018340.7594, MAE: 3893.2751, R2: 0.1405\n",
      "==========================================================================================\n",
      "Epoch [3869/5000] | Time: 0.24s\n",
      "(Training) Loss: 985084.3268\n",
      "(Validation) Loss: 1018191.9492, MAE: 3893.5720, R2: 0.1407\n",
      "==========================================================================================\n",
      "Epoch [3870/5000] | Time: 0.23s\n",
      "(Training) Loss: 979635.0628\n",
      "(Validation) Loss: 1018029.7092, MAE: 3891.1521, R2: 0.1408\n",
      "==========================================================================================\n",
      "Epoch [3871/5000] | Time: 0.25s\n",
      "(Training) Loss: 1014582.6732\n",
      "(Validation) Loss: 1017883.7333, MAE: 3892.5645, R2: 0.1409\n",
      "==========================================================================================\n",
      "Epoch [3872/5000] | Time: 0.30s\n",
      "(Training) Loss: 991869.6485\n",
      "(Validation) Loss: 1017722.8800, MAE: 3891.8286, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [3873/5000] | Time: 0.30s\n",
      "(Training) Loss: 995023.8274\n",
      "(Validation) Loss: 1017564.5816, MAE: 3890.2893, R2: 0.1412\n",
      "==========================================================================================\n",
      "Epoch [3874/5000] | Time: 0.23s\n",
      "(Training) Loss: 978901.8001\n",
      "(Validation) Loss: 1017413.0083, MAE: 3889.9578, R2: 0.1413\n",
      "==========================================================================================\n",
      "Epoch [3875/5000] | Time: 0.21s\n",
      "(Training) Loss: 981598.9994\n",
      "(Validation) Loss: 1017260.7187, MAE: 3889.1621, R2: 0.1414\n",
      "==========================================================================================\n",
      "Epoch [3876/5000] | Time: 0.22s\n",
      "(Training) Loss: 976106.8855\n",
      "(Validation) Loss: 1017111.0806, MAE: 3890.8550, R2: 0.1416\n",
      "==========================================================================================\n",
      "Epoch [3877/5000] | Time: 0.22s\n",
      "(Training) Loss: 1001720.5032\n",
      "(Validation) Loss: 1016952.6502, MAE: 3887.8054, R2: 0.1417\n",
      "==========================================================================================\n",
      "Epoch [3878/5000] | Time: 0.21s\n",
      "(Training) Loss: 997180.3135\n",
      "(Validation) Loss: 1016802.4889, MAE: 3888.4937, R2: 0.1418\n",
      "==========================================================================================\n",
      "Epoch [3879/5000] | Time: 0.19s\n",
      "(Training) Loss: 978069.6294\n",
      "(Validation) Loss: 1016657.2241, MAE: 3889.4761, R2: 0.1420\n",
      "==========================================================================================\n",
      "Epoch [3880/5000] | Time: 0.20s\n",
      "(Training) Loss: 1003968.3122\n",
      "(Validation) Loss: 1016487.7714, MAE: 3886.0151, R2: 0.1421\n",
      "==========================================================================================\n",
      "Epoch [3881/5000] | Time: 0.21s\n",
      "(Training) Loss: 1007400.7627\n",
      "(Validation) Loss: 1016364.2260, MAE: 3891.7505, R2: 0.1422\n",
      "==========================================================================================\n",
      "Epoch [3882/5000] | Time: 0.20s\n",
      "(Training) Loss: 998927.8928\n",
      "(Validation) Loss: 1016173.9581, MAE: 3884.0161, R2: 0.1424\n",
      "==========================================================================================\n",
      "Epoch [3883/5000] | Time: 0.22s\n",
      "(Training) Loss: 979650.1466\n",
      "(Validation) Loss: 1016026.7683, MAE: 3885.1279, R2: 0.1425\n",
      "==========================================================================================\n",
      "Epoch [3884/5000] | Time: 0.20s\n",
      "(Training) Loss: 981915.7773\n",
      "(Validation) Loss: 1015871.5733, MAE: 3883.9675, R2: 0.1426\n",
      "==========================================================================================\n",
      "Epoch [3885/5000] | Time: 0.21s\n",
      "(Training) Loss: 991050.2957\n",
      "(Validation) Loss: 1015719.9797, MAE: 3884.1646, R2: 0.1427\n",
      "==========================================================================================\n",
      "Epoch [3886/5000] | Time: 0.21s\n",
      "(Training) Loss: 978741.6789\n",
      "(Validation) Loss: 1015621.2317, MAE: 3889.0002, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [3887/5000] | Time: 0.22s\n",
      "(Training) Loss: 989794.7418\n",
      "(Validation) Loss: 1015408.3556, MAE: 3881.4934, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [3888/5000] | Time: 0.29s\n",
      "(Training) Loss: 987492.2500\n",
      "(Validation) Loss: 1015261.7448, MAE: 3882.4946, R2: 0.1431\n",
      "==========================================================================================\n",
      "Epoch [3889/5000] | Time: 0.27s\n",
      "(Training) Loss: 983570.0406\n",
      "(Validation) Loss: 1015107.2965, MAE: 3881.8826, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [3890/5000] | Time: 0.23s\n",
      "(Training) Loss: 977439.0019\n",
      "(Validation) Loss: 1014941.7752, MAE: 3878.2134, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [3891/5000] | Time: 0.20s\n",
      "(Training) Loss: 995068.1624\n",
      "(Validation) Loss: 1014793.2902, MAE: 3878.0811, R2: 0.1435\n",
      "==========================================================================================\n",
      "Epoch [3892/5000] | Time: 0.25s\n",
      "(Training) Loss: 976266.4435\n",
      "(Validation) Loss: 1014644.9422, MAE: 3879.0625, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [3893/5000] | Time: 0.23s\n",
      "(Training) Loss: 994535.0184\n",
      "(Validation) Loss: 1014596.0686, MAE: 3886.6228, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [3894/5000] | Time: 0.24s\n",
      "(Training) Loss: 978140.8499\n",
      "(Validation) Loss: 1014349.6381, MAE: 3882.1694, R2: 0.1439\n",
      "==========================================================================================\n",
      "Epoch [3895/5000] | Time: 0.27s\n",
      "(Training) Loss: 973656.4016\n",
      "(Validation) Loss: 1014141.9632, MAE: 3876.0400, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [3896/5000] | Time: 0.29s\n",
      "(Training) Loss: 990098.6225\n",
      "(Validation) Loss: 1013986.4432, MAE: 3874.0112, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [3897/5000] | Time: 0.25s\n",
      "(Training) Loss: 994061.9232\n",
      "(Validation) Loss: 1013822.9486, MAE: 3872.6213, R2: 0.1443\n",
      "==========================================================================================\n",
      "Epoch [3898/5000] | Time: 0.28s\n",
      "(Training) Loss: 985274.1459\n",
      "(Validation) Loss: 1013715.8705, MAE: 3875.7947, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [3899/5000] | Time: 0.29s\n",
      "(Training) Loss: 970658.1258\n",
      "(Validation) Loss: 1013595.2711, MAE: 3876.3931, R2: 0.1445\n",
      "==========================================================================================\n",
      "Epoch [3900/5000] | Time: 0.31s\n",
      "(Training) Loss: 970299.2765\n",
      "(Validation) Loss: 1013443.6978, MAE: 3875.9155, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [3901/5000] | Time: 0.27s\n",
      "(Training) Loss: 996117.8299\n",
      "(Validation) Loss: 1013292.0584, MAE: 3875.3289, R2: 0.1448\n",
      "==========================================================================================\n",
      "Epoch [3902/5000] | Time: 0.28s\n",
      "(Training) Loss: 983064.6453\n",
      "(Validation) Loss: 1013138.4025, MAE: 3875.7600, R2: 0.1449\n",
      "==========================================================================================\n",
      "Epoch [3903/5000] | Time: 0.26s\n",
      "(Training) Loss: 1003853.5812\n",
      "(Validation) Loss: 1012983.8222, MAE: 3874.4302, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [3904/5000] | Time: 0.30s\n",
      "(Training) Loss: 981319.3369\n",
      "(Validation) Loss: 1012826.9410, MAE: 3873.6797, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [3905/5000] | Time: 0.25s\n",
      "(Training) Loss: 976821.0082\n",
      "(Validation) Loss: 1012672.2844, MAE: 3872.5859, R2: 0.1453\n",
      "==========================================================================================\n",
      "Epoch [3906/5000] | Time: 0.27s\n",
      "(Training) Loss: 985564.4518\n",
      "(Validation) Loss: 1012522.0876, MAE: 3873.6304, R2: 0.1454\n",
      "==========================================================================================\n",
      "Epoch [3907/5000] | Time: 0.31s\n",
      "(Training) Loss: 992799.3217\n",
      "(Validation) Loss: 1012369.6660, MAE: 3873.3162, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [3908/5000] | Time: 0.30s\n",
      "(Training) Loss: 985639.3274\n",
      "(Validation) Loss: 1012213.6381, MAE: 3872.5850, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [3909/5000] | Time: 0.29s\n",
      "(Training) Loss: 978846.0013\n",
      "(Validation) Loss: 1012059.4641, MAE: 3871.7798, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [3910/5000] | Time: 0.29s\n",
      "(Training) Loss: 979767.0190\n",
      "(Validation) Loss: 1011902.6743, MAE: 3870.8115, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [3911/5000] | Time: 0.38s\n",
      "(Training) Loss: 995634.1129\n",
      "(Validation) Loss: 1011764.1651, MAE: 3872.9268, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [3912/5000] | Time: 0.27s\n",
      "(Training) Loss: 1002554.3775\n",
      "(Validation) Loss: 1011596.5156, MAE: 3869.9221, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [3913/5000] | Time: 0.34s\n",
      "(Training) Loss: 992973.7081\n",
      "(Validation) Loss: 1011442.7733, MAE: 3869.1875, R2: 0.1463\n",
      "==========================================================================================\n",
      "Epoch [3914/5000] | Time: 0.26s\n",
      "(Training) Loss: 1005634.7506\n",
      "(Validation) Loss: 1011289.2597, MAE: 3868.9563, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [3915/5000] | Time: 0.27s\n",
      "(Training) Loss: 983396.7468\n",
      "(Validation) Loss: 1011134.8724, MAE: 3868.5347, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [3916/5000] | Time: 0.24s\n",
      "(Training) Loss: 988721.0343\n",
      "(Validation) Loss: 1010977.3359, MAE: 3867.2053, R2: 0.1467\n",
      "==========================================================================================\n",
      "Epoch [3917/5000] | Time: 0.38s\n",
      "(Training) Loss: 980605.5850\n",
      "(Validation) Loss: 1010822.6997, MAE: 3866.5320, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [3918/5000] | Time: 0.31s\n",
      "(Training) Loss: 984513.3274\n",
      "(Validation) Loss: 1010670.9790, MAE: 3866.1572, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [3919/5000] | Time: 0.27s\n",
      "(Training) Loss: 982810.1009\n",
      "(Validation) Loss: 1010515.8959, MAE: 3865.5435, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [3920/5000] | Time: 0.30s\n",
      "(Training) Loss: 977122.4061\n",
      "(Validation) Loss: 1010362.8698, MAE: 3865.1177, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [3921/5000] | Time: 0.31s\n",
      "(Training) Loss: 964303.2849\n",
      "(Validation) Loss: 1002644.9422, MAE: 3846.7793, R2: 0.1536\n",
      "==========================================================================================\n",
      "Epoch [3922/5000] | Time: 0.29s\n",
      "(Training) Loss: 990461.8687\n",
      "(Validation) Loss: 1002500.5359, MAE: 3843.5701, R2: 0.1538\n",
      "==========================================================================================\n",
      "Epoch [3923/5000] | Time: 0.28s\n",
      "(Training) Loss: 975448.0622\n",
      "(Validation) Loss: 1002340.2971, MAE: 3839.9717, R2: 0.1539\n",
      "==========================================================================================\n",
      "Epoch [3924/5000] | Time: 0.24s\n",
      "(Training) Loss: 970353.0812\n",
      "(Validation) Loss: 1002199.1568, MAE: 3841.5229, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [3925/5000] | Time: 0.27s\n",
      "(Training) Loss: 992165.2094\n",
      "(Validation) Loss: 1002057.4629, MAE: 3840.6584, R2: 0.1541\n",
      "==========================================================================================\n",
      "Epoch [3926/5000] | Time: 0.25s\n",
      "(Training) Loss: 984818.8915\n",
      "(Validation) Loss: 1001901.0387, MAE: 3839.4609, R2: 0.1543\n",
      "==========================================================================================\n",
      "Epoch [3927/5000] | Time: 0.28s\n",
      "(Training) Loss: 973456.2253\n",
      "(Validation) Loss: 1001751.5733, MAE: 3840.2168, R2: 0.1544\n",
      "==========================================================================================\n",
      "Epoch [3928/5000] | Time: 0.24s\n",
      "(Training) Loss: 987277.6954\n",
      "(Validation) Loss: 1001602.9105, MAE: 3837.6323, R2: 0.1545\n",
      "==========================================================================================\n",
      "Epoch [3929/5000] | Time: 0.24s\n",
      "(Training) Loss: 996674.1003\n",
      "(Validation) Loss: 1001456.5130, MAE: 3837.6101, R2: 0.1546\n",
      "==========================================================================================\n",
      "Epoch [3930/5000] | Time: 0.26s\n",
      "(Training) Loss: 973135.6599\n",
      "(Validation) Loss: 1001313.0006, MAE: 3842.3101, R2: 0.1547\n",
      "==========================================================================================\n",
      "Epoch [3931/5000] | Time: 0.30s\n",
      "(Training) Loss: 990387.8959\n",
      "(Validation) Loss: 1001156.9473, MAE: 3837.7825, R2: 0.1549\n",
      "==========================================================================================\n",
      "Epoch [3932/5000] | Time: 0.27s\n",
      "(Training) Loss: 965491.7481\n",
      "(Validation) Loss: 1001010.7276, MAE: 3836.0479, R2: 0.1550\n",
      "==========================================================================================\n",
      "Epoch [3933/5000] | Time: 0.32s\n",
      "(Training) Loss: 988541.5266\n",
      "(Validation) Loss: 1000859.1086, MAE: 3834.7185, R2: 0.1551\n",
      "==========================================================================================\n",
      "Epoch [3934/5000] | Time: 0.29s\n",
      "(Training) Loss: 963078.5749\n",
      "(Validation) Loss: 1000712.2946, MAE: 3833.9993, R2: 0.1552\n",
      "==========================================================================================\n",
      "Epoch [3935/5000] | Time: 0.26s\n",
      "(Training) Loss: 979710.5571\n",
      "(Validation) Loss: 1000576.1727, MAE: 3835.8184, R2: 0.1554\n",
      "==========================================================================================\n",
      "Epoch [3936/5000] | Time: 0.25s\n",
      "(Training) Loss: 960916.0711\n",
      "(Validation) Loss: 1000417.7879, MAE: 3834.8743, R2: 0.1555\n",
      "==========================================================================================\n",
      "Epoch [3937/5000] | Time: 0.32s\n",
      "(Training) Loss: 971869.7747\n",
      "(Validation) Loss: 1000270.4254, MAE: 3834.1001, R2: 0.1556\n",
      "==========================================================================================\n",
      "Epoch [3938/5000] | Time: 0.32s\n",
      "(Training) Loss: 982165.7367\n",
      "(Validation) Loss: 1000124.2413, MAE: 3834.2280, R2: 0.1557\n",
      "==========================================================================================\n",
      "Epoch [3939/5000] | Time: 0.24s\n",
      "(Training) Loss: 959994.9803\n",
      "(Validation) Loss: 999973.2165, MAE: 3833.0056, R2: 0.1559\n",
      "==========================================================================================\n",
      "Epoch [3940/5000] | Time: 0.23s\n",
      "(Training) Loss: 967626.0952\n",
      "(Validation) Loss: 999825.7930, MAE: 3832.0657, R2: 0.1560\n",
      "==========================================================================================\n",
      "Epoch [3941/5000] | Time: 0.28s\n",
      "(Training) Loss: 977254.7170\n",
      "(Validation) Loss: 999678.1816, MAE: 3830.4543, R2: 0.1561\n",
      "==========================================================================================\n",
      "Epoch [3942/5000] | Time: 0.27s\n",
      "(Training) Loss: 999554.7275\n",
      "(Validation) Loss: 999531.0019, MAE: 3831.1099, R2: 0.1562\n",
      "==========================================================================================\n",
      "Epoch [3943/5000] | Time: 0.26s\n",
      "(Training) Loss: 968496.6510\n",
      "(Validation) Loss: 999386.9359, MAE: 3832.2031, R2: 0.1563\n",
      "==========================================================================================\n",
      "Epoch [3944/5000] | Time: 0.28s\n",
      "(Training) Loss: 963687.8940\n",
      "(Validation) Loss: 999230.0444, MAE: 3829.8062, R2: 0.1565\n",
      "==========================================================================================\n",
      "Epoch [3945/5000] | Time: 0.28s\n",
      "(Training) Loss: 963453.5444\n",
      "(Validation) Loss: 999093.8870, MAE: 3831.7502, R2: 0.1566\n",
      "==========================================================================================\n",
      "Epoch [3946/5000] | Time: 0.32s\n",
      "(Training) Loss: 962457.7674\n",
      "(Validation) Loss: 998939.3676, MAE: 3828.8264, R2: 0.1567\n",
      "==========================================================================================\n",
      "Epoch [3947/5000] | Time: 0.33s\n",
      "(Training) Loss: 987710.1891\n",
      "(Validation) Loss: 998802.4889, MAE: 3829.9607, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [3948/5000] | Time: 0.38s\n",
      "(Training) Loss: 957893.7843\n",
      "(Validation) Loss: 998645.6533, MAE: 3828.4204, R2: 0.1570\n",
      "==========================================================================================\n",
      "Epoch [3949/5000] | Time: 0.32s\n",
      "(Training) Loss: 977170.6015\n",
      "(Validation) Loss: 998498.3721, MAE: 3826.8438, R2: 0.1571\n",
      "==========================================================================================\n",
      "Epoch [3950/5000] | Time: 0.27s\n",
      "(Training) Loss: 979711.7919\n",
      "(Validation) Loss: 998350.2527, MAE: 3826.0845, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [3951/5000] | Time: 0.24s\n",
      "(Training) Loss: 968763.7792\n",
      "(Validation) Loss: 998204.5613, MAE: 3826.4607, R2: 0.1573\n",
      "==========================================================================================\n",
      "Epoch [3952/5000] | Time: 0.26s\n",
      "(Training) Loss: 976940.4841\n",
      "(Validation) Loss: 998052.1143, MAE: 3824.2666, R2: 0.1575\n",
      "==========================================================================================\n",
      "Epoch [3953/5000] | Time: 0.24s\n",
      "(Training) Loss: 972039.7221\n",
      "(Validation) Loss: 997907.5098, MAE: 3825.0891, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [3954/5000] | Time: 0.24s\n",
      "(Training) Loss: 985263.9137\n",
      "(Validation) Loss: 997759.9441, MAE: 3824.1169, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [3955/5000] | Time: 0.27s\n",
      "(Training) Loss: 962064.1694\n",
      "(Validation) Loss: 997636.3429, MAE: 3830.6416, R2: 0.1578\n",
      "==========================================================================================\n",
      "Epoch [3956/5000] | Time: 0.33s\n",
      "(Training) Loss: 964797.8458\n",
      "(Validation) Loss: 997464.8838, MAE: 3823.9937, R2: 0.1579\n",
      "==========================================================================================\n",
      "Epoch [3957/5000] | Time: 0.29s\n",
      "(Training) Loss: 967470.4791\n",
      "(Validation) Loss: 997319.7003, MAE: 3823.1931, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [3958/5000] | Time: 0.33s\n",
      "(Training) Loss: 992508.4245\n",
      "(Validation) Loss: 997166.1460, MAE: 3821.0400, R2: 0.1582\n",
      "==========================================================================================\n",
      "Epoch [3959/5000] | Time: 0.32s\n",
      "(Training) Loss: 955506.8849\n",
      "(Validation) Loss: 997013.7397, MAE: 3820.1438, R2: 0.1583\n",
      "==========================================================================================\n",
      "Epoch [3960/5000] | Time: 0.27s\n",
      "(Training) Loss: 957670.8864\n",
      "(Validation) Loss: 996870.6438, MAE: 3820.0183, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [3961/5000] | Time: 0.26s\n",
      "(Training) Loss: 979983.2519\n",
      "(Validation) Loss: 996722.8902, MAE: 3818.9888, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [3962/5000] | Time: 0.25s\n",
      "(Training) Loss: 956136.7202\n",
      "(Validation) Loss: 996583.8984, MAE: 3821.0635, R2: 0.1587\n",
      "==========================================================================================\n",
      "Epoch [3963/5000] | Time: 0.25s\n",
      "(Training) Loss: 974790.5051\n",
      "(Validation) Loss: 996434.3162, MAE: 3819.2937, R2: 0.1588\n",
      "==========================================================================================\n",
      "Epoch [3964/5000] | Time: 0.26s\n",
      "(Training) Loss: 973312.9023\n",
      "(Validation) Loss: 996280.3251, MAE: 3817.3074, R2: 0.1589\n",
      "==========================================================================================\n",
      "Epoch [3965/5000] | Time: 0.32s\n",
      "(Training) Loss: 962492.4848\n",
      "(Validation) Loss: 996141.3181, MAE: 3819.8572, R2: 0.1591\n",
      "==========================================================================================\n",
      "Epoch [3966/5000] | Time: 0.30s\n",
      "(Training) Loss: 970708.8477\n",
      "(Validation) Loss: 995985.5340, MAE: 3816.0732, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [3967/5000] | Time: 0.28s\n",
      "(Training) Loss: 966001.8680\n",
      "(Validation) Loss: 995862.7708, MAE: 3820.4009, R2: 0.1593\n",
      "==========================================================================================\n",
      "Epoch [3968/5000] | Time: 0.28s\n",
      "(Training) Loss: 976637.9600\n",
      "(Validation) Loss: 995695.5022, MAE: 3815.9209, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [3969/5000] | Time: 0.27s\n",
      "(Training) Loss: 982954.1720\n",
      "(Validation) Loss: 995549.8159, MAE: 3816.0254, R2: 0.1595\n",
      "==========================================================================================\n",
      "Epoch [3970/5000] | Time: 0.26s\n",
      "(Training) Loss: 975626.7982\n",
      "(Validation) Loss: 995392.8279, MAE: 3813.2803, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [3971/5000] | Time: 0.25s\n",
      "(Training) Loss: 970481.1567\n",
      "(Validation) Loss: 995249.3054, MAE: 3814.9070, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [3972/5000] | Time: 0.28s\n",
      "(Training) Loss: 963170.0964\n",
      "(Validation) Loss: 995097.6762, MAE: 3813.1567, R2: 0.1599\n",
      "==========================================================================================\n",
      "Epoch [3973/5000] | Time: 0.31s\n",
      "(Training) Loss: 979659.1865\n",
      "(Validation) Loss: 994958.3035, MAE: 3814.5144, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [3974/5000] | Time: 0.32s\n",
      "(Training) Loss: 972055.7773\n",
      "(Validation) Loss: 994805.7651, MAE: 3813.3835, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [3975/5000] | Time: 0.29s\n",
      "(Training) Loss: 969062.5184\n",
      "(Validation) Loss: 994661.1708, MAE: 3813.3159, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [3976/5000] | Time: 0.27s\n",
      "(Training) Loss: 976071.8230\n",
      "(Validation) Loss: 994512.1981, MAE: 3812.0508, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [3977/5000] | Time: 0.28s\n",
      "(Training) Loss: 961440.2563\n",
      "(Validation) Loss: 994356.6425, MAE: 3810.1428, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [3978/5000] | Time: 0.30s\n",
      "(Training) Loss: 963292.0076\n",
      "(Validation) Loss: 994212.3378, MAE: 3809.8127, R2: 0.1607\n",
      "==========================================================================================\n",
      "Epoch [3979/5000] | Time: 0.30s\n",
      "(Training) Loss: 971625.5838\n",
      "(Validation) Loss: 994074.2959, MAE: 3812.0144, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [3980/5000] | Time: 0.26s\n",
      "(Training) Loss: 978697.3852\n",
      "(Validation) Loss: 993915.7181, MAE: 3808.8035, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [3981/5000] | Time: 0.28s\n",
      "(Training) Loss: 969039.4175\n",
      "(Validation) Loss: 993780.3784, MAE: 3811.6677, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [3982/5000] | Time: 0.28s\n",
      "(Training) Loss: 954086.4940\n",
      "(Validation) Loss: 993626.4889, MAE: 3810.0620, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [3983/5000] | Time: 0.27s\n",
      "(Training) Loss: 954280.4588\n",
      "(Validation) Loss: 993481.7422, MAE: 3809.6526, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [3984/5000] | Time: 0.28s\n",
      "(Training) Loss: 951902.0370\n",
      "(Validation) Loss: 993332.6984, MAE: 3807.7393, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [3985/5000] | Time: 0.31s\n",
      "(Training) Loss: 973263.1865\n",
      "(Validation) Loss: 993186.6768, MAE: 3806.7188, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [3986/5000] | Time: 0.26s\n",
      "(Training) Loss: 954276.4610\n",
      "(Validation) Loss: 993035.8298, MAE: 3806.2915, R2: 0.1616\n",
      "==========================================================================================\n",
      "Epoch [3987/5000] | Time: 0.25s\n",
      "(Training) Loss: 964144.8008\n",
      "(Validation) Loss: 992888.7111, MAE: 3805.2983, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [3988/5000] | Time: 0.22s\n",
      "(Training) Loss: 968827.3528\n",
      "(Validation) Loss: 992744.6857, MAE: 3805.8486, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [3989/5000] | Time: 0.24s\n",
      "(Training) Loss: 956215.7088\n",
      "(Validation) Loss: 992598.0241, MAE: 3805.2175, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [3990/5000] | Time: 0.23s\n",
      "(Training) Loss: 976191.3807\n",
      "(Validation) Loss: 992455.6648, MAE: 3805.1289, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [3991/5000] | Time: 0.25s\n",
      "(Training) Loss: 964725.3985\n",
      "(Validation) Loss: 992307.8248, MAE: 3804.8088, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [3992/5000] | Time: 0.26s\n",
      "(Training) Loss: 971579.9505\n",
      "(Validation) Loss: 992150.1867, MAE: 3800.5493, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [3993/5000] | Time: 0.28s\n",
      "(Training) Loss: 984071.9695\n",
      "(Validation) Loss: 992008.5790, MAE: 3802.8193, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [3994/5000] | Time: 0.26s\n",
      "(Training) Loss: 962543.7316\n",
      "(Validation) Loss: 991853.0743, MAE: 3800.1873, R2: 0.1626\n",
      "==========================================================================================\n",
      "Epoch [3995/5000] | Time: 0.28s\n",
      "(Training) Loss: 964013.1053\n",
      "(Validation) Loss: 991712.6705, MAE: 3801.6780, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [3996/5000] | Time: 0.27s\n",
      "(Training) Loss: 955671.3566\n",
      "(Validation) Loss: 991568.5943, MAE: 3800.7896, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [3997/5000] | Time: 0.32s\n",
      "(Training) Loss: 952838.3484\n",
      "(Validation) Loss: 991414.2273, MAE: 3798.7861, R2: 0.1630\n",
      "==========================================================================================\n",
      "Epoch [3998/5000] | Time: 0.29s\n",
      "(Training) Loss: 974520.5419\n",
      "(Validation) Loss: 991279.4921, MAE: 3801.3877, R2: 0.1631\n",
      "==========================================================================================\n",
      "Epoch [3999/5000] | Time: 0.29s\n",
      "(Training) Loss: 962957.6079\n",
      "(Validation) Loss: 991128.2133, MAE: 3799.7266, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [4000/5000] | Time: 0.30s\n",
      "(Training) Loss: 954546.5057\n",
      "(Validation) Loss: 990976.0914, MAE: 3798.6663, R2: 0.1634\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch4000.pth\n",
      "==========================================================================================\n",
      "Epoch [4001/5000] | Time: 0.31s\n",
      "(Training) Loss: 958936.6263\n",
      "(Validation) Loss: 990827.9263, MAE: 3797.0366, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [4002/5000] | Time: 0.33s\n",
      "(Training) Loss: 963485.8931\n",
      "(Validation) Loss: 990685.6076, MAE: 3798.1768, R2: 0.1636\n",
      "==========================================================================================\n",
      "Epoch [4003/5000] | Time: 0.32s\n",
      "(Training) Loss: 955868.0019\n",
      "(Validation) Loss: 990532.4190, MAE: 3794.4590, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [4004/5000] | Time: 0.33s\n",
      "(Training) Loss: 950785.4941\n",
      "(Validation) Loss: 990388.8406, MAE: 3794.7139, R2: 0.1638\n",
      "==========================================================================================\n",
      "Epoch [4005/5000] | Time: 0.31s\n",
      "(Training) Loss: 953569.0793\n",
      "(Validation) Loss: 990250.8648, MAE: 3797.4258, R2: 0.1640\n",
      "==========================================================================================\n",
      "Epoch [4006/5000] | Time: 0.28s\n",
      "(Training) Loss: 952726.8668\n",
      "(Validation) Loss: 990094.7200, MAE: 3793.6606, R2: 0.1641\n",
      "==========================================================================================\n",
      "Epoch [4007/5000] | Time: 0.28s\n",
      "(Training) Loss: 949824.4910\n",
      "(Validation) Loss: 989951.5429, MAE: 3793.9863, R2: 0.1642\n",
      "==========================================================================================\n",
      "Epoch [4008/5000] | Time: 0.28s\n",
      "(Training) Loss: 954972.7005\n",
      "(Validation) Loss: 989804.6019, MAE: 3792.5229, R2: 0.1643\n",
      "==========================================================================================\n",
      "Epoch [4009/5000] | Time: 0.32s\n",
      "(Training) Loss: 968124.6212\n",
      "(Validation) Loss: 989665.7829, MAE: 3793.9038, R2: 0.1644\n",
      "==========================================================================================\n",
      "Epoch [4010/5000] | Time: 0.30s\n",
      "(Training) Loss: 957554.3287\n",
      "(Validation) Loss: 989511.3752, MAE: 3791.2327, R2: 0.1646\n",
      "==========================================================================================\n",
      "Epoch [4011/5000] | Time: 0.27s\n",
      "(Training) Loss: 967308.9569\n",
      "(Validation) Loss: 989366.9943, MAE: 3792.2673, R2: 0.1647\n",
      "==========================================================================================\n",
      "Epoch [4012/5000] | Time: 0.31s\n",
      "(Training) Loss: 981294.3515\n",
      "(Validation) Loss: 989219.7943, MAE: 3790.9150, R2: 0.1648\n",
      "==========================================================================================\n",
      "Epoch [4013/5000] | Time: 0.30s\n",
      "(Training) Loss: 957372.6992\n",
      "(Validation) Loss: 989068.6933, MAE: 3790.1726, R2: 0.1649\n",
      "==========================================================================================\n",
      "Epoch [4014/5000] | Time: 0.34s\n",
      "(Training) Loss: 977355.4734\n",
      "(Validation) Loss: 988929.1683, MAE: 3791.1841, R2: 0.1651\n",
      "==========================================================================================\n",
      "Epoch [4015/5000] | Time: 0.32s\n",
      "(Training) Loss: 986091.3909\n",
      "(Validation) Loss: 988784.8889, MAE: 3791.8584, R2: 0.1652\n",
      "==========================================================================================\n",
      "Epoch [4016/5000] | Time: 0.30s\n",
      "(Training) Loss: 981314.7855\n",
      "(Validation) Loss: 988584.7771, MAE: 3787.2512, R2: 0.1654\n",
      "==========================================================================================\n",
      "Epoch [4017/5000] | Time: 0.30s\n",
      "(Training) Loss: 965809.0025\n",
      "(Validation) Loss: 988441.4832, MAE: 3790.8254, R2: 0.1655\n",
      "==========================================================================================\n",
      "Epoch [4018/5000] | Time: 0.29s\n",
      "(Training) Loss: 952067.2462\n",
      "(Validation) Loss: 988337.3460, MAE: 3789.7043, R2: 0.1656\n",
      "==========================================================================================\n",
      "Epoch [4019/5000] | Time: 0.30s\n",
      "(Training) Loss: 956337.9045\n",
      "(Validation) Loss: 988187.6165, MAE: 3787.3447, R2: 0.1657\n",
      "==========================================================================================\n",
      "Epoch [4020/5000] | Time: 0.30s\n",
      "(Training) Loss: 951786.8236\n",
      "(Validation) Loss: 988064.9600, MAE: 3799.5845, R2: 0.1658\n",
      "==========================================================================================\n",
      "Epoch [4021/5000] | Time: 0.29s\n",
      "(Training) Loss: 975031.2893\n",
      "(Validation) Loss: 995345.1378, MAE: 3822.3242, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [4022/5000] | Time: 0.28s\n",
      "(Training) Loss: 970833.2219\n",
      "(Validation) Loss: 995221.0235, MAE: 3825.5959, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [4023/5000] | Time: 0.27s\n",
      "(Training) Loss: 959341.5774\n",
      "(Validation) Loss: 995016.6400, MAE: 3813.9087, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [4024/5000] | Time: 0.25s\n",
      "(Training) Loss: 980156.4898\n",
      "(Validation) Loss: 994867.4438, MAE: 3812.9822, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [4025/5000] | Time: 0.29s\n",
      "(Training) Loss: 958005.6072\n",
      "(Validation) Loss: 994700.1194, MAE: 3809.5320, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [4026/5000] | Time: 0.26s\n",
      "(Training) Loss: 975948.7887\n",
      "(Validation) Loss: 994551.5429, MAE: 3810.5088, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [4027/5000] | Time: 0.26s\n",
      "(Training) Loss: 973147.8718\n",
      "(Validation) Loss: 994407.9746, MAE: 3811.9919, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [4028/5000] | Time: 0.27s\n",
      "(Training) Loss: 976752.2544\n",
      "(Validation) Loss: 994244.0889, MAE: 3809.5125, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [4029/5000] | Time: 0.26s\n",
      "(Training) Loss: 972601.8642\n",
      "(Validation) Loss: 994090.6870, MAE: 3808.2422, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [4030/5000] | Time: 0.27s\n",
      "(Training) Loss: 976866.2760\n",
      "(Validation) Loss: 993938.3517, MAE: 3808.1597, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [4031/5000] | Time: 0.25s\n",
      "(Training) Loss: 965744.6910\n",
      "(Validation) Loss: 993786.4889, MAE: 3809.8447, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [4032/5000] | Time: 0.29s\n",
      "(Training) Loss: 971725.4150\n",
      "(Validation) Loss: 993633.8286, MAE: 3808.8455, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [4033/5000] | Time: 0.28s\n",
      "(Training) Loss: 970925.2005\n",
      "(Validation) Loss: 993476.1397, MAE: 3806.8733, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [4034/5000] | Time: 0.27s\n",
      "(Training) Loss: 964592.1104\n",
      "(Validation) Loss: 993323.2051, MAE: 3806.5964, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [4035/5000] | Time: 0.27s\n",
      "(Training) Loss: 964437.0723\n",
      "(Validation) Loss: 993178.1587, MAE: 3806.4866, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [4036/5000] | Time: 0.28s\n",
      "(Training) Loss: 962608.4689\n",
      "(Validation) Loss: 993018.9867, MAE: 3804.6609, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [4037/5000] | Time: 0.27s\n",
      "(Training) Loss: 955072.7836\n",
      "(Validation) Loss: 992872.3302, MAE: 3804.9214, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [4038/5000] | Time: 0.24s\n",
      "(Training) Loss: 968436.1612\n",
      "(Validation) Loss: 992717.3943, MAE: 3803.3174, R2: 0.1619\n",
      "==========================================================================================\n",
      "Epoch [4039/5000] | Time: 0.25s\n",
      "(Training) Loss: 954934.2779\n",
      "(Validation) Loss: 992575.1619, MAE: 3805.1436, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [4040/5000] | Time: 0.21s\n",
      "(Training) Loss: 968450.4207\n",
      "(Validation) Loss: 992413.2267, MAE: 3802.0369, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [4041/5000] | Time: 0.23s\n",
      "(Training) Loss: 961832.7963\n",
      "(Validation) Loss: 992263.8781, MAE: 3802.4126, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [4042/5000] | Time: 0.21s\n",
      "(Training) Loss: 976178.4124\n",
      "(Validation) Loss: 992110.4559, MAE: 3800.3955, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [4043/5000] | Time: 0.22s\n",
      "(Training) Loss: 951317.0479\n",
      "(Validation) Loss: 991959.2381, MAE: 3802.2483, R2: 0.1625\n",
      "==========================================================================================\n",
      "Epoch [4044/5000] | Time: 0.26s\n",
      "(Training) Loss: 955382.9385\n",
      "(Validation) Loss: 991817.2394, MAE: 3801.5549, R2: 0.1627\n",
      "==========================================================================================\n",
      "Epoch [4045/5000] | Time: 0.21s\n",
      "(Training) Loss: 962399.4369\n",
      "(Validation) Loss: 991671.1365, MAE: 3802.8792, R2: 0.1628\n",
      "==========================================================================================\n",
      "Epoch [4046/5000] | Time: 0.24s\n",
      "(Training) Loss: 985275.2738\n",
      "(Validation) Loss: 991517.5162, MAE: 3800.6621, R2: 0.1629\n",
      "==========================================================================================\n",
      "Epoch [4047/5000] | Time: 0.25s\n",
      "(Training) Loss: 984466.5197\n",
      "(Validation) Loss: 991368.2083, MAE: 3801.4966, R2: 0.1630\n",
      "==========================================================================================\n",
      "Epoch [4048/5000] | Time: 0.22s\n",
      "(Training) Loss: 957441.0451\n",
      "(Validation) Loss: 991206.2425, MAE: 3797.6416, R2: 0.1632\n",
      "==========================================================================================\n",
      "Epoch [4049/5000] | Time: 0.27s\n",
      "(Training) Loss: 961618.0571\n",
      "(Validation) Loss: 991056.4521, MAE: 3800.2793, R2: 0.1633\n",
      "==========================================================================================\n",
      "Epoch [4050/5000] | Time: 0.25s\n",
      "(Training) Loss: 959082.8020\n",
      "(Validation) Loss: 990905.2597, MAE: 3796.5857, R2: 0.1634\n",
      "==========================================================================================\n",
      "Epoch [4051/5000] | Time: 0.26s\n",
      "(Training) Loss: 952014.9661\n",
      "(Validation) Loss: 990765.2470, MAE: 3798.9348, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [4052/5000] | Time: 0.22s\n",
      "(Training) Loss: 972249.2741\n",
      "(Validation) Loss: 990604.4597, MAE: 3795.2556, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [4053/5000] | Time: 0.23s\n",
      "(Training) Loss: 973128.3661\n",
      "(Validation) Loss: 1013230.5016, MAE: 3913.4727, R2: 0.1448\n",
      "==========================================================================================\n",
      "Epoch [4054/5000] | Time: 0.23s\n",
      "(Training) Loss: 985822.8896\n",
      "(Validation) Loss: 1013028.0025, MAE: 3887.7878, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [4055/5000] | Time: 0.27s\n",
      "(Training) Loss: 977768.8426\n",
      "(Validation) Loss: 1012865.0667, MAE: 3881.8774, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [4056/5000] | Time: 0.30s\n",
      "(Training) Loss: 983234.6796\n",
      "(Validation) Loss: 1012705.0159, MAE: 3877.3428, R2: 0.1452\n",
      "==========================================================================================\n",
      "Epoch [4057/5000] | Time: 0.22s\n",
      "(Training) Loss: 982458.5584\n",
      "(Validation) Loss: 1012544.7111, MAE: 3876.9832, R2: 0.1454\n",
      "==========================================================================================\n",
      "Epoch [4058/5000] | Time: 0.25s\n",
      "(Training) Loss: 975586.1434\n",
      "(Validation) Loss: 1012388.4495, MAE: 3876.0837, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [4059/5000] | Time: 0.27s\n",
      "(Training) Loss: 976195.0355\n",
      "(Validation) Loss: 1012236.0737, MAE: 3876.1777, R2: 0.1456\n",
      "==========================================================================================\n",
      "Epoch [4060/5000] | Time: 0.25s\n",
      "(Training) Loss: 977243.2684\n",
      "(Validation) Loss: 1012072.8076, MAE: 3874.7996, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [4061/5000] | Time: 0.27s\n",
      "(Training) Loss: 990168.6136\n",
      "(Validation) Loss: 1011930.2806, MAE: 3876.7983, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [4062/5000] | Time: 0.24s\n",
      "(Training) Loss: 984089.6396\n",
      "(Validation) Loss: 1011763.5810, MAE: 3874.6362, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [4063/5000] | Time: 0.28s\n",
      "(Training) Loss: 980454.9013\n",
      "(Validation) Loss: 1011606.8775, MAE: 3873.0959, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [4064/5000] | Time: 0.26s\n",
      "(Training) Loss: 987978.9810\n",
      "(Validation) Loss: 1011450.6108, MAE: 3872.7769, R2: 0.1463\n",
      "==========================================================================================\n",
      "Epoch [4065/5000] | Time: 0.28s\n",
      "(Training) Loss: 971518.5799\n",
      "(Validation) Loss: 1011295.4159, MAE: 3874.3982, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [4066/5000] | Time: 0.29s\n",
      "(Training) Loss: 985276.9594\n",
      "(Validation) Loss: 1011139.6063, MAE: 3870.6890, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [4067/5000] | Time: 0.25s\n",
      "(Training) Loss: 973478.9353\n",
      "(Validation) Loss: 1010985.0463, MAE: 3871.4014, R2: 0.1467\n",
      "==========================================================================================\n",
      "Epoch [4068/5000] | Time: 0.27s\n",
      "(Training) Loss: 987210.3020\n",
      "(Validation) Loss: 1010830.4356, MAE: 3871.5452, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [4069/5000] | Time: 0.25s\n",
      "(Training) Loss: 967878.3257\n",
      "(Validation) Loss: 1010675.0070, MAE: 3872.9185, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [4070/5000] | Time: 0.26s\n",
      "(Training) Loss: 994739.7576\n",
      "(Validation) Loss: 1010517.9835, MAE: 3868.6038, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [4071/5000] | Time: 0.27s\n",
      "(Training) Loss: 976891.1110\n",
      "(Validation) Loss: 1010373.8413, MAE: 3870.9324, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [4072/5000] | Time: 0.26s\n",
      "(Training) Loss: 984576.9296\n",
      "(Validation) Loss: 1010207.2381, MAE: 3868.1140, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [4073/5000] | Time: 0.27s\n",
      "(Training) Loss: 996213.1739\n",
      "(Validation) Loss: 1010050.1435, MAE: 3867.3032, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4074/5000] | Time: 0.26s\n",
      "(Training) Loss: 977956.2824\n",
      "(Validation) Loss: 1009898.8495, MAE: 3866.9475, R2: 0.1476\n",
      "==========================================================================================\n",
      "Epoch [4075/5000] | Time: 0.29s\n",
      "(Training) Loss: 969944.9410\n",
      "(Validation) Loss: 1009741.3232, MAE: 3866.4299, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4076/5000] | Time: 0.25s\n",
      "(Training) Loss: 986697.3249\n",
      "(Validation) Loss: 1009606.3289, MAE: 3870.1641, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [4077/5000] | Time: 0.25s\n",
      "(Training) Loss: 987918.9629\n",
      "(Validation) Loss: 1009432.6095, MAE: 3866.7878, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4078/5000] | Time: 0.26s\n",
      "(Training) Loss: 980183.8921\n",
      "(Validation) Loss: 1009276.3378, MAE: 3863.4626, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4079/5000] | Time: 0.30s\n",
      "(Training) Loss: 979860.9530\n",
      "(Validation) Loss: 1009124.0533, MAE: 3863.4578, R2: 0.1482\n",
      "==========================================================================================\n",
      "Epoch [4080/5000] | Time: 0.28s\n",
      "(Training) Loss: 966713.9960\n",
      "(Validation) Loss: 1008974.0089, MAE: 3864.8423, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4081/5000] | Time: 0.27s\n",
      "(Training) Loss: 988266.5286\n",
      "(Validation) Loss: 1008817.0006, MAE: 3863.4390, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4082/5000] | Time: 0.24s\n",
      "(Training) Loss: 974179.3255\n",
      "(Validation) Loss: 1008661.1657, MAE: 3861.7568, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4083/5000] | Time: 0.25s\n",
      "(Training) Loss: 994729.9162\n",
      "(Validation) Loss: 1008511.0654, MAE: 3862.5476, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4084/5000] | Time: 0.27s\n",
      "(Training) Loss: 977122.0501\n",
      "(Validation) Loss: 1008355.5606, MAE: 3861.6875, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4085/5000] | Time: 0.29s\n",
      "(Training) Loss: 978379.4207\n",
      "(Validation) Loss: 1008199.0146, MAE: 3860.7429, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [4086/5000] | Time: 0.30s\n",
      "(Training) Loss: 977100.6228\n",
      "(Validation) Loss: 1008054.2730, MAE: 3862.4639, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4087/5000] | Time: 0.26s\n",
      "(Training) Loss: 985803.6707\n",
      "(Validation) Loss: 1007894.9079, MAE: 3859.1653, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4088/5000] | Time: 0.30s\n",
      "(Training) Loss: 980304.4651\n",
      "(Validation) Loss: 1007743.3092, MAE: 3859.9468, R2: 0.1494\n",
      "==========================================================================================\n",
      "Epoch [4089/5000] | Time: 0.27s\n",
      "(Training) Loss: 976023.7839\n",
      "(Validation) Loss: 1007589.1352, MAE: 3858.8274, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4090/5000] | Time: 0.31s\n",
      "(Training) Loss: 978536.4264\n",
      "(Validation) Loss: 1007439.0806, MAE: 3859.1572, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [4091/5000] | Time: 0.26s\n",
      "(Training) Loss: 972926.0463\n",
      "(Validation) Loss: 1007279.8527, MAE: 3857.8323, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [4092/5000] | Time: 0.26s\n",
      "(Training) Loss: 970044.3115\n",
      "(Validation) Loss: 1007131.8197, MAE: 3856.9399, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [4093/5000] | Time: 0.23s\n",
      "(Training) Loss: 993766.5286\n",
      "(Validation) Loss: 1006979.1289, MAE: 3860.2561, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4094/5000] | Time: 0.25s\n",
      "(Training) Loss: 967952.4540\n",
      "(Validation) Loss: 1006822.6438, MAE: 3855.0574, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4095/5000] | Time: 0.25s\n",
      "(Training) Loss: 985060.7392\n",
      "(Validation) Loss: 1006671.7613, MAE: 3855.6836, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [4096/5000] | Time: 0.25s\n",
      "(Training) Loss: 965515.3715\n",
      "(Validation) Loss: 1006517.0337, MAE: 3855.8132, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [4097/5000] | Time: 0.25s\n",
      "(Training) Loss: 969912.7370\n",
      "(Validation) Loss: 1006363.4946, MAE: 3854.4832, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [4098/5000] | Time: 0.27s\n",
      "(Training) Loss: 981606.2703\n",
      "(Validation) Loss: 1006214.1511, MAE: 3855.2461, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [4099/5000] | Time: 0.24s\n",
      "(Training) Loss: 979527.8204\n",
      "(Validation) Loss: 1006060.0381, MAE: 3853.5498, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [4100/5000] | Time: 0.27s\n",
      "(Training) Loss: 994746.9220\n",
      "(Validation) Loss: 1005902.6743, MAE: 3854.7283, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [4101/5000] | Time: 0.25s\n",
      "(Training) Loss: 977756.1643\n",
      "(Validation) Loss: 1005751.1721, MAE: 3853.2473, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [4102/5000] | Time: 0.27s\n",
      "(Training) Loss: 968392.3598\n",
      "(Validation) Loss: 1005594.9613, MAE: 3851.1843, R2: 0.1512\n",
      "==========================================================================================\n",
      "Epoch [4103/5000] | Time: 0.25s\n",
      "(Training) Loss: 966024.1402\n",
      "(Validation) Loss: 1005441.5086, MAE: 3850.2629, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [4104/5000] | Time: 0.27s\n",
      "(Training) Loss: 968580.9784\n",
      "(Validation) Loss: 1005291.6876, MAE: 3850.1704, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [4105/5000] | Time: 0.25s\n",
      "(Training) Loss: 999909.5127\n",
      "(Validation) Loss: 1005141.0641, MAE: 3851.0073, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [4106/5000] | Time: 0.27s\n",
      "(Training) Loss: 974734.3147\n",
      "(Validation) Loss: 1004990.2070, MAE: 3850.9026, R2: 0.1517\n",
      "==========================================================================================\n",
      "Epoch [4107/5000] | Time: 0.29s\n",
      "(Training) Loss: 964063.6831\n",
      "(Validation) Loss: 1004829.3029, MAE: 3849.9563, R2: 0.1518\n",
      "==========================================================================================\n",
      "Epoch [4108/5000] | Time: 0.27s\n",
      "(Training) Loss: 968768.9600\n",
      "(Validation) Loss: 1004681.7930, MAE: 3850.2207, R2: 0.1519\n",
      "==========================================================================================\n",
      "Epoch [4109/5000] | Time: 0.27s\n",
      "(Training) Loss: 971929.5895\n",
      "(Validation) Loss: 1004529.0514, MAE: 3848.9871, R2: 0.1521\n",
      "==========================================================================================\n",
      "Epoch [4110/5000] | Time: 0.24s\n",
      "(Training) Loss: 969026.0717\n",
      "(Validation) Loss: 1004376.2794, MAE: 3847.2927, R2: 0.1522\n",
      "==========================================================================================\n",
      "Epoch [4111/5000] | Time: 0.23s\n",
      "(Training) Loss: 969352.2094\n",
      "(Validation) Loss: 1004222.8775, MAE: 3846.8835, R2: 0.1523\n",
      "==========================================================================================\n",
      "Epoch [4112/5000] | Time: 0.26s\n",
      "(Training) Loss: 964172.6009\n",
      "(Validation) Loss: 1004075.9771, MAE: 3846.8354, R2: 0.1524\n",
      "==========================================================================================\n",
      "Epoch [4113/5000] | Time: 0.24s\n",
      "(Training) Loss: 975210.9651\n",
      "(Validation) Loss: 1003922.5448, MAE: 3846.3701, R2: 0.1526\n",
      "==========================================================================================\n",
      "Epoch [4114/5000] | Time: 0.22s\n",
      "(Training) Loss: 968240.8883\n",
      "(Validation) Loss: 1003771.2965, MAE: 3847.1494, R2: 0.1527\n",
      "==========================================================================================\n",
      "Epoch [4115/5000] | Time: 0.20s\n",
      "(Training) Loss: 980835.6485\n",
      "(Validation) Loss: 1003619.3981, MAE: 3849.9482, R2: 0.1528\n",
      "==========================================================================================\n",
      "Epoch [4116/5000] | Time: 0.23s\n",
      "(Training) Loss: 970961.5850\n",
      "(Validation) Loss: 1003473.4019, MAE: 3848.8020, R2: 0.1529\n",
      "==========================================================================================\n",
      "Epoch [4117/5000] | Time: 0.21s\n",
      "(Training) Loss: 961635.4067\n",
      "(Validation) Loss: 1003326.1765, MAE: 3848.3337, R2: 0.1531\n",
      "==========================================================================================\n",
      "Epoch [4118/5000] | Time: 0.25s\n",
      "(Training) Loss: 969043.7824\n",
      "(Validation) Loss: 1003170.5549, MAE: 3846.8147, R2: 0.1532\n",
      "==========================================================================================\n",
      "Epoch [4119/5000] | Time: 0.23s\n",
      "(Training) Loss: 978619.3852\n",
      "(Validation) Loss: 1003010.3517, MAE: 3843.8232, R2: 0.1533\n",
      "==========================================================================================\n",
      "Epoch [4120/5000] | Time: 0.21s\n",
      "(Training) Loss: 981111.1631\n",
      "(Validation) Loss: 1002861.0235, MAE: 3844.6968, R2: 0.1534\n",
      "==========================================================================================\n",
      "Epoch [4121/5000] | Time: 0.23s\n",
      "(Training) Loss: 963914.4359\n",
      "(Validation) Loss: 1002704.9498, MAE: 3842.2463, R2: 0.1536\n",
      "==========================================================================================\n",
      "Epoch [4122/5000] | Time: 0.22s\n",
      "(Training) Loss: 972506.5926\n",
      "(Validation) Loss: 1002563.9568, MAE: 3845.3596, R2: 0.1537\n",
      "==========================================================================================\n",
      "Epoch [4123/5000] | Time: 0.21s\n",
      "(Training) Loss: 977120.6681\n",
      "(Validation) Loss: 1002402.4584, MAE: 3842.3435, R2: 0.1538\n",
      "==========================================================================================\n",
      "Epoch [4124/5000] | Time: 0.29s\n",
      "(Training) Loss: 980199.0899\n",
      "(Validation) Loss: 1002250.1638, MAE: 3841.7234, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [4125/5000] | Time: 0.31s\n",
      "(Training) Loss: 968779.4023\n",
      "(Validation) Loss: 1002008.2286, MAE: 3834.0000, R2: 0.1542\n",
      "==========================================================================================\n",
      "Epoch [4126/5000] | Time: 0.27s\n",
      "(Training) Loss: 979877.8915\n",
      "(Validation) Loss: 1001850.8089, MAE: 3836.2683, R2: 0.1543\n",
      "==========================================================================================\n",
      "Epoch [4127/5000] | Time: 0.23s\n",
      "(Training) Loss: 973473.0952\n",
      "(Validation) Loss: 1010483.5251, MAE: 3862.4644, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [4128/5000] | Time: 0.27s\n",
      "(Training) Loss: 979436.2678\n",
      "(Validation) Loss: 1010357.3181, MAE: 3866.2979, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [4129/5000] | Time: 0.23s\n",
      "(Training) Loss: 970164.8426\n",
      "(Validation) Loss: 1010182.2578, MAE: 3862.7598, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [4130/5000] | Time: 0.27s\n",
      "(Training) Loss: 985010.2284\n",
      "(Validation) Loss: 1010029.5568, MAE: 3865.3269, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4131/5000] | Time: 0.28s\n",
      "(Training) Loss: 989487.2525\n",
      "(Validation) Loss: 1009907.4794, MAE: 3871.4187, R2: 0.1476\n",
      "==========================================================================================\n",
      "Epoch [4132/5000] | Time: 0.21s\n",
      "(Training) Loss: 993526.2018\n",
      "(Validation) Loss: 1009711.9390, MAE: 3864.3022, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4133/5000] | Time: 0.25s\n",
      "(Training) Loss: 984501.6840\n",
      "(Validation) Loss: 1009549.4044, MAE: 3863.7185, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [4134/5000] | Time: 0.23s\n",
      "(Training) Loss: 979747.4385\n",
      "(Validation) Loss: 1009392.6552, MAE: 3864.0361, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4135/5000] | Time: 0.28s\n",
      "(Training) Loss: 976921.9638\n",
      "(Validation) Loss: 1009223.0603, MAE: 3860.0193, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4136/5000] | Time: 0.22s\n",
      "(Training) Loss: 975199.4099\n",
      "(Validation) Loss: 1009069.6432, MAE: 3860.9832, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [4137/5000] | Time: 0.25s\n",
      "(Training) Loss: 980258.0882\n",
      "(Validation) Loss: 1008902.3390, MAE: 3857.3882, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4138/5000] | Time: 0.22s\n",
      "(Training) Loss: 985154.9594\n",
      "(Validation) Loss: 1008744.8229, MAE: 3857.4524, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4139/5000] | Time: 0.24s\n",
      "(Training) Loss: 966363.6408\n",
      "(Validation) Loss: 1008586.1689, MAE: 3857.4609, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4140/5000] | Time: 0.21s\n",
      "(Training) Loss: 1000103.9645\n",
      "(Validation) Loss: 1008510.2629, MAE: 3864.0022, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4141/5000] | Time: 0.21s\n",
      "(Training) Loss: 974721.4150\n",
      "(Validation) Loss: 1008268.7746, MAE: 3856.3381, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4142/5000] | Time: 0.24s\n",
      "(Training) Loss: 989252.9124\n",
      "(Validation) Loss: 1008117.7346, MAE: 3858.0410, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4143/5000] | Time: 0.21s\n",
      "(Training) Loss: 991145.4473\n",
      "(Validation) Loss: 1007954.1994, MAE: 3855.0732, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4144/5000] | Time: 0.25s\n",
      "(Training) Loss: 967962.0419\n",
      "(Validation) Loss: 1007800.3657, MAE: 3856.1423, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4145/5000] | Time: 0.23s\n",
      "(Training) Loss: 985740.4277\n",
      "(Validation) Loss: 1007641.8692, MAE: 3854.0256, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4146/5000] | Time: 0.24s\n",
      "(Training) Loss: 966951.5878\n",
      "(Validation) Loss: 1013513.4984, MAE: 3873.9844, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [4147/5000] | Time: 0.30s\n",
      "(Training) Loss: 995552.1421\n",
      "(Validation) Loss: 1013356.5308, MAE: 3873.7378, R2: 0.1447\n",
      "==========================================================================================\n",
      "Epoch [4148/5000] | Time: 0.21s\n",
      "(Training) Loss: 984427.1631\n",
      "(Validation) Loss: 1013199.7054, MAE: 3876.8862, R2: 0.1448\n",
      "==========================================================================================\n",
      "Epoch [4149/5000] | Time: 0.33s\n",
      "(Training) Loss: 987707.4188\n",
      "(Validation) Loss: 1013037.0641, MAE: 3873.2290, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [4150/5000] | Time: 0.23s\n",
      "(Training) Loss: 983703.5571\n",
      "(Validation) Loss: 1012881.9657, MAE: 3871.6968, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [4151/5000] | Time: 0.24s\n",
      "(Training) Loss: 988983.0200\n",
      "(Validation) Loss: 1012719.2432, MAE: 3870.4841, R2: 0.1452\n",
      "==========================================================================================\n",
      "Epoch [4152/5000] | Time: 0.23s\n",
      "(Training) Loss: 980263.3287\n",
      "(Validation) Loss: 1012564.5054, MAE: 3872.4626, R2: 0.1454\n",
      "==========================================================================================\n",
      "Epoch [4153/5000] | Time: 0.27s\n",
      "(Training) Loss: 976657.6168\n",
      "(Validation) Loss: 1012408.3098, MAE: 3869.3989, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [4154/5000] | Time: 0.22s\n",
      "(Training) Loss: 996887.9702\n",
      "(Validation) Loss: 1012247.5022, MAE: 3867.4390, R2: 0.1456\n",
      "==========================================================================================\n",
      "Epoch [4155/5000] | Time: 0.27s\n",
      "(Training) Loss: 985416.0993\n",
      "(Validation) Loss: 1012091.6775, MAE: 3869.0234, R2: 0.1458\n",
      "==========================================================================================\n",
      "Epoch [4156/5000] | Time: 0.34s\n",
      "(Training) Loss: 996590.6104\n",
      "(Validation) Loss: 1011929.2292, MAE: 3866.7368, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [4157/5000] | Time: 0.25s\n",
      "(Training) Loss: 970353.5376\n",
      "(Validation) Loss: 1011771.0375, MAE: 3866.8591, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [4158/5000] | Time: 0.28s\n",
      "(Training) Loss: 973312.8896\n",
      "(Validation) Loss: 1011638.0292, MAE: 3868.5012, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [4159/5000] | Time: 0.31s\n",
      "(Training) Loss: 997567.9055\n",
      "(Validation) Loss: 1011462.7708, MAE: 3866.6272, R2: 0.1463\n",
      "==========================================================================================\n",
      "Epoch [4160/5000] | Time: 0.24s\n",
      "(Training) Loss: 982844.6616\n",
      "(Validation) Loss: 1011300.6273, MAE: 3864.6809, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [4161/5000] | Time: 0.29s\n",
      "(Training) Loss: 982586.8610\n",
      "(Validation) Loss: 1011148.6121, MAE: 3867.0479, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [4162/5000] | Time: 0.24s\n",
      "(Training) Loss: 980682.0397\n",
      "(Validation) Loss: 1010991.1771, MAE: 3866.1606, R2: 0.1467\n",
      "==========================================================================================\n",
      "Epoch [4163/5000] | Time: 0.26s\n",
      "(Training) Loss: 997808.8395\n",
      "(Validation) Loss: 1010836.3835, MAE: 3865.7805, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [4164/5000] | Time: 0.25s\n",
      "(Training) Loss: 984549.9454\n",
      "(Validation) Loss: 1010756.6781, MAE: 3874.7275, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [4165/5000] | Time: 0.31s\n",
      "(Training) Loss: 993764.5305\n",
      "(Validation) Loss: 1010518.8114, MAE: 3865.7412, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [4166/5000] | Time: 0.28s\n",
      "(Training) Loss: 970024.3813\n",
      "(Validation) Loss: 1010356.3886, MAE: 3864.1975, R2: 0.1472\n",
      "==========================================================================================\n",
      "Epoch [4167/5000] | Time: 0.26s\n",
      "(Training) Loss: 994007.8128\n",
      "(Validation) Loss: 1010205.1251, MAE: 3864.8074, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [4168/5000] | Time: 0.27s\n",
      "(Training) Loss: 988734.4048\n",
      "(Validation) Loss: 1010044.8406, MAE: 3864.2136, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4169/5000] | Time: 0.31s\n",
      "(Training) Loss: 1001667.3071\n",
      "(Validation) Loss: 1009920.6451, MAE: 3870.4155, R2: 0.1476\n",
      "==========================================================================================\n",
      "Epoch [4170/5000] | Time: 0.30s\n",
      "(Training) Loss: 988064.4530\n",
      "(Validation) Loss: 1009728.7263, MAE: 3863.4260, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4171/5000] | Time: 0.29s\n",
      "(Training) Loss: 983588.9854\n",
      "(Validation) Loss: 1009570.6870, MAE: 3861.3381, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [4172/5000] | Time: 0.29s\n",
      "(Training) Loss: 969031.5533\n",
      "(Validation) Loss: 1009412.2870, MAE: 3860.7622, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4173/5000] | Time: 0.25s\n",
      "(Training) Loss: 983713.8027\n",
      "(Validation) Loss: 1009263.9594, MAE: 3861.5571, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4174/5000] | Time: 0.22s\n",
      "(Training) Loss: 974074.9499\n",
      "(Validation) Loss: 1009104.1575, MAE: 3861.2788, R2: 0.1482\n",
      "==========================================================================================\n",
      "Epoch [4175/5000] | Time: 0.22s\n",
      "(Training) Loss: 976285.8204\n",
      "(Validation) Loss: 1008947.8654, MAE: 3859.5435, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4176/5000] | Time: 0.21s\n",
      "(Training) Loss: 973133.6212\n",
      "(Validation) Loss: 1008802.1587, MAE: 3863.9626, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4177/5000] | Time: 0.20s\n",
      "(Training) Loss: 1026307.2614\n",
      "(Validation) Loss: 1008650.6210, MAE: 3861.6418, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4178/5000] | Time: 0.28s\n",
      "(Training) Loss: 974986.7608\n",
      "(Validation) Loss: 1008476.8508, MAE: 3859.3196, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [4179/5000] | Time: 0.23s\n",
      "(Training) Loss: 975995.8572\n",
      "(Validation) Loss: 1008351.2990, MAE: 3863.5505, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4180/5000] | Time: 0.23s\n",
      "(Training) Loss: 1006620.0463\n",
      "(Validation) Loss: 1008174.3390, MAE: 3859.4055, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [4181/5000] | Time: 0.22s\n",
      "(Training) Loss: 972181.5635\n",
      "(Validation) Loss: 1008014.8876, MAE: 3857.5823, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4182/5000] | Time: 0.29s\n",
      "(Training) Loss: 970982.2792\n",
      "(Validation) Loss: 1007861.4044, MAE: 3857.2451, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4183/5000] | Time: 0.26s\n",
      "(Training) Loss: 1000792.3464\n",
      "(Validation) Loss: 1007714.0470, MAE: 3860.7053, R2: 0.1494\n",
      "==========================================================================================\n",
      "Epoch [4184/5000] | Time: 0.24s\n",
      "(Training) Loss: 983344.5971\n",
      "(Validation) Loss: 1007553.0311, MAE: 3857.2456, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4185/5000] | Time: 0.26s\n",
      "(Training) Loss: 969069.3039\n",
      "(Validation) Loss: 1007403.2254, MAE: 3858.1309, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [4186/5000] | Time: 0.26s\n",
      "(Training) Loss: 971114.6694\n",
      "(Validation) Loss: 1007272.5790, MAE: 3862.2920, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [4187/5000] | Time: 0.33s\n",
      "(Training) Loss: 965072.9047\n",
      "(Validation) Loss: 1007176.6349, MAE: 3861.5854, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [4188/5000] | Time: 0.36s\n",
      "(Training) Loss: 967512.5155\n",
      "(Validation) Loss: 1007022.8317, MAE: 3861.0728, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4189/5000] | Time: 0.38s\n",
      "(Training) Loss: 993911.7494\n",
      "(Validation) Loss: 1006885.9378, MAE: 3863.4854, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4190/5000] | Time: 0.35s\n",
      "(Training) Loss: 968205.3674\n",
      "(Validation) Loss: 1006707.6165, MAE: 3859.0251, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [4191/5000] | Time: 0.32s\n",
      "(Training) Loss: 979608.3572\n",
      "(Validation) Loss: 1006559.4057, MAE: 3861.4099, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [4192/5000] | Time: 0.28s\n",
      "(Training) Loss: 964456.2542\n",
      "(Validation) Loss: 1006405.7448, MAE: 3861.8066, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [4193/5000] | Time: 0.28s\n",
      "(Training) Loss: 974225.8672\n",
      "(Validation) Loss: 1006247.3041, MAE: 3857.4221, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [4194/5000] | Time: 0.28s\n",
      "(Training) Loss: 978662.7811\n",
      "(Validation) Loss: 1006091.5657, MAE: 3858.7009, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [4195/5000] | Time: 0.25s\n",
      "(Training) Loss: 971387.4975\n",
      "(Validation) Loss: 1005936.1524, MAE: 3856.8447, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [4196/5000] | Time: 0.28s\n",
      "(Training) Loss: 969618.6631\n",
      "(Validation) Loss: 1005784.1575, MAE: 3856.5378, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [4197/5000] | Time: 0.31s\n",
      "(Training) Loss: 996409.7367\n",
      "(Validation) Loss: 1005702.6743, MAE: 3863.7537, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [4198/5000] | Time: 0.30s\n",
      "(Training) Loss: 974394.1129\n",
      "(Validation) Loss: 1005465.6254, MAE: 3853.8499, R2: 0.1513\n",
      "==========================================================================================\n",
      "Epoch [4199/5000] | Time: 0.30s\n",
      "(Training) Loss: 972796.8642\n",
      "(Validation) Loss: 1005305.4781, MAE: 3853.9983, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [4200/5000] | Time: 0.24s\n",
      "(Training) Loss: 973005.7170\n",
      "(Validation) Loss: 1005160.3708, MAE: 3854.1577, R2: 0.1515\n",
      "==========================================================================================\n",
      "Epoch [4201/5000] | Time: 0.27s\n",
      "(Training) Loss: 989531.1485\n",
      "(Validation) Loss: 1005008.1117, MAE: 3853.9832, R2: 0.1517\n",
      "==========================================================================================\n",
      "Epoch [4202/5000] | Time: 0.26s\n",
      "(Training) Loss: 980625.7170\n",
      "(Validation) Loss: 1004850.5803, MAE: 3854.5232, R2: 0.1518\n",
      "==========================================================================================\n",
      "Epoch [4203/5000] | Time: 0.32s\n",
      "(Training) Loss: 981424.1003\n",
      "(Validation) Loss: 1004700.3429, MAE: 3854.0728, R2: 0.1519\n",
      "==========================================================================================\n",
      "Epoch [4204/5000] | Time: 0.26s\n",
      "(Training) Loss: 970584.5990\n",
      "(Validation) Loss: 1004533.3384, MAE: 3853.2812, R2: 0.1521\n",
      "==========================================================================================\n",
      "Epoch [4205/5000] | Time: 0.26s\n",
      "(Training) Loss: 975157.3687\n",
      "(Validation) Loss: 1004376.1524, MAE: 3849.3259, R2: 0.1522\n",
      "==========================================================================================\n",
      "Epoch [4206/5000] | Time: 0.28s\n",
      "(Training) Loss: 969605.2126\n",
      "(Validation) Loss: 1004222.3340, MAE: 3850.7212, R2: 0.1523\n",
      "==========================================================================================\n",
      "Epoch [4207/5000] | Time: 0.27s\n",
      "(Training) Loss: 982373.4185\n",
      "(Validation) Loss: 1004069.3029, MAE: 3849.7664, R2: 0.1524\n",
      "==========================================================================================\n",
      "Epoch [4208/5000] | Time: 0.26s\n",
      "(Training) Loss: 974492.5964\n",
      "(Validation) Loss: 1003909.3333, MAE: 3847.1714, R2: 0.1526\n",
      "==========================================================================================\n",
      "Epoch [4209/5000] | Time: 0.30s\n",
      "(Training) Loss: 983918.2402\n",
      "(Validation) Loss: 1003754.8546, MAE: 3845.9729, R2: 0.1527\n",
      "==========================================================================================\n",
      "Epoch [4210/5000] | Time: 0.29s\n",
      "(Training) Loss: 1009631.0844\n",
      "(Validation) Loss: 1003599.3194, MAE: 3846.3179, R2: 0.1528\n",
      "==========================================================================================\n",
      "Epoch [4211/5000] | Time: 0.32s\n",
      "(Training) Loss: 970532.2773\n",
      "(Validation) Loss: 1003449.5492, MAE: 3848.6741, R2: 0.1530\n",
      "==========================================================================================\n",
      "Epoch [4212/5000] | Time: 0.31s\n",
      "(Training) Loss: 967130.1536\n",
      "(Validation) Loss: 1003289.3206, MAE: 3846.3940, R2: 0.1531\n",
      "==========================================================================================\n",
      "Epoch [4213/5000] | Time: 0.26s\n",
      "(Training) Loss: 972723.3610\n",
      "(Validation) Loss: 1003132.9422, MAE: 3845.4727, R2: 0.1532\n",
      "==========================================================================================\n",
      "Epoch [4214/5000] | Time: 0.26s\n",
      "(Training) Loss: 967355.5133\n",
      "(Validation) Loss: 1002980.0990, MAE: 3847.0476, R2: 0.1533\n",
      "==========================================================================================\n",
      "Epoch [4215/5000] | Time: 0.30s\n",
      "(Training) Loss: 967140.6079\n",
      "(Validation) Loss: 1002841.4222, MAE: 3843.1746, R2: 0.1535\n",
      "==========================================================================================\n",
      "Epoch [4216/5000] | Time: 0.28s\n",
      "(Training) Loss: 972809.8674\n",
      "(Validation) Loss: 1002682.0368, MAE: 3845.4548, R2: 0.1536\n",
      "==========================================================================================\n",
      "Epoch [4217/5000] | Time: 0.25s\n",
      "(Training) Loss: 980528.7874\n",
      "(Validation) Loss: 1002512.2337, MAE: 3842.8713, R2: 0.1537\n",
      "==========================================================================================\n",
      "Epoch [4218/5000] | Time: 0.34s\n",
      "(Training) Loss: 971402.2805\n",
      "(Validation) Loss: 1002362.0267, MAE: 3844.0024, R2: 0.1539\n",
      "==========================================================================================\n",
      "Epoch [4219/5000] | Time: 0.27s\n",
      "(Training) Loss: 976179.0336\n",
      "(Validation) Loss: 1002206.7657, MAE: 3845.4182, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [4220/5000] | Time: 0.32s\n",
      "(Training) Loss: 977843.2138\n",
      "(Validation) Loss: 1002054.4610, MAE: 3843.7910, R2: 0.1541\n",
      "==========================================================================================\n",
      "Epoch [4221/5000] | Time: 0.32s\n",
      "(Training) Loss: 964224.3154\n",
      "(Validation) Loss: 1001897.8489, MAE: 3842.5264, R2: 0.1543\n",
      "==========================================================================================\n",
      "Epoch [4222/5000] | Time: 0.27s\n",
      "(Training) Loss: 976161.9822\n",
      "(Validation) Loss: 1001745.0210, MAE: 3842.1682, R2: 0.1544\n",
      "==========================================================================================\n",
      "Epoch [4223/5000] | Time: 0.28s\n",
      "(Training) Loss: 973281.0539\n",
      "(Validation) Loss: 1001587.6013, MAE: 3841.3447, R2: 0.1545\n",
      "==========================================================================================\n",
      "Epoch [4224/5000] | Time: 0.27s\n",
      "(Training) Loss: 1006802.8395\n",
      "(Validation) Loss: 1001443.7283, MAE: 3843.7375, R2: 0.1546\n",
      "==========================================================================================\n",
      "Epoch [4225/5000] | Time: 0.26s\n",
      "(Training) Loss: 968260.8445\n",
      "(Validation) Loss: 1001270.5270, MAE: 3838.5571, R2: 0.1548\n",
      "==========================================================================================\n",
      "Epoch [4226/5000] | Time: 0.30s\n",
      "(Training) Loss: 989592.0971\n",
      "(Validation) Loss: 1001113.6610, MAE: 3837.2107, R2: 0.1549\n",
      "==========================================================================================\n",
      "Epoch [4227/5000] | Time: 0.28s\n",
      "(Training) Loss: 967630.7760\n",
      "(Validation) Loss: 1000954.3670, MAE: 3837.0447, R2: 0.1550\n",
      "==========================================================================================\n",
      "Epoch [4228/5000] | Time: 0.24s\n",
      "(Training) Loss: 991583.1383\n",
      "(Validation) Loss: 1000829.7041, MAE: 3837.1812, R2: 0.1551\n",
      "==========================================================================================\n",
      "Epoch [4229/5000] | Time: 0.27s\n",
      "(Training) Loss: 978979.2392\n",
      "(Validation) Loss: 1000653.2825, MAE: 3837.3079, R2: 0.1553\n",
      "==========================================================================================\n",
      "Epoch [4230/5000] | Time: 0.27s\n",
      "(Training) Loss: 972393.5888\n",
      "(Validation) Loss: 1015601.0159, MAE: 3900.9294, R2: 0.1428\n",
      "==========================================================================================\n",
      "Epoch [4231/5000] | Time: 0.28s\n",
      "(Training) Loss: 974359.3433\n",
      "(Validation) Loss: 1015452.6171, MAE: 3895.0083, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [4232/5000] | Time: 0.23s\n",
      "(Training) Loss: 986658.3655\n",
      "(Validation) Loss: 1015197.9479, MAE: 3887.1396, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [4233/5000] | Time: 0.24s\n",
      "(Training) Loss: 992130.1516\n",
      "(Validation) Loss: 1015077.4857, MAE: 3887.3247, R2: 0.1433\n",
      "==========================================================================================\n",
      "Epoch [4234/5000] | Time: 0.22s\n",
      "(Training) Loss: 977605.0584\n",
      "(Validation) Loss: 1014866.1486, MAE: 3883.4468, R2: 0.1435\n",
      "==========================================================================================\n",
      "Epoch [4235/5000] | Time: 0.24s\n",
      "(Training) Loss: 982005.3477\n",
      "(Validation) Loss: 1014700.8914, MAE: 3878.8901, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [4236/5000] | Time: 0.25s\n",
      "(Training) Loss: 985637.5254\n",
      "(Validation) Loss: 1014546.7175, MAE: 3877.8259, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [4237/5000] | Time: 0.23s\n",
      "(Training) Loss: 994915.0558\n",
      "(Validation) Loss: 1014394.3771, MAE: 3877.2322, R2: 0.1438\n",
      "==========================================================================================\n",
      "Epoch [4238/5000] | Time: 0.24s\n",
      "(Training) Loss: 993154.2297\n",
      "(Validation) Loss: 1014239.3295, MAE: 3876.5955, R2: 0.1440\n",
      "==========================================================================================\n",
      "Epoch [4239/5000] | Time: 0.26s\n",
      "(Training) Loss: 975085.4353\n",
      "(Validation) Loss: 1014077.5975, MAE: 3874.7209, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [4240/5000] | Time: 0.21s\n",
      "(Training) Loss: 984943.3436\n",
      "(Validation) Loss: 1013942.4356, MAE: 3878.9756, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [4241/5000] | Time: 0.22s\n",
      "(Training) Loss: 983398.6812\n",
      "(Validation) Loss: 1013776.5587, MAE: 3876.7317, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [4242/5000] | Time: 0.24s\n",
      "(Training) Loss: 988742.4099\n",
      "(Validation) Loss: 1013676.3937, MAE: 3879.6028, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [4243/5000] | Time: 0.24s\n",
      "(Training) Loss: 977045.0844\n",
      "(Validation) Loss: 1013521.6406, MAE: 3878.7349, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [4244/5000] | Time: 0.27s\n",
      "(Training) Loss: 986658.5812\n",
      "(Validation) Loss: 1013378.2959, MAE: 3880.4417, R2: 0.1447\n",
      "==========================================================================================\n",
      "Epoch [4245/5000] | Time: 0.29s\n",
      "(Training) Loss: 1001989.1041\n",
      "(Validation) Loss: 1013215.5175, MAE: 3877.9023, R2: 0.1448\n",
      "==========================================================================================\n",
      "Epoch [4246/5000] | Time: 0.26s\n",
      "(Training) Loss: 971956.6758\n",
      "(Validation) Loss: 1013053.9327, MAE: 3876.2295, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [4247/5000] | Time: 0.29s\n",
      "(Training) Loss: 979916.4074\n",
      "(Validation) Loss: 1012896.2235, MAE: 3874.4885, R2: 0.1451\n",
      "==========================================================================================\n",
      "Epoch [4248/5000] | Time: 0.28s\n",
      "(Training) Loss: 997363.9226\n",
      "(Validation) Loss: 1012743.0603, MAE: 3874.6692, R2: 0.1452\n",
      "==========================================================================================\n",
      "Epoch [4249/5000] | Time: 0.28s\n",
      "(Training) Loss: 1001623.6193\n",
      "(Validation) Loss: 1012601.9302, MAE: 3877.5420, R2: 0.1453\n",
      "==========================================================================================\n",
      "Epoch [4250/5000] | Time: 0.27s\n",
      "(Training) Loss: 998108.2113\n",
      "(Validation) Loss: 1012434.3416, MAE: 3873.7244, R2: 0.1455\n",
      "==========================================================================================\n",
      "Epoch [4251/5000] | Time: 0.24s\n",
      "(Training) Loss: 985662.1942\n",
      "(Validation) Loss: 1012279.3397, MAE: 3873.7493, R2: 0.1456\n",
      "==========================================================================================\n",
      "Epoch [4252/5000] | Time: 0.28s\n",
      "(Training) Loss: 990736.4397\n",
      "(Validation) Loss: 1012124.4597, MAE: 3872.8745, R2: 0.1457\n",
      "==========================================================================================\n",
      "Epoch [4253/5000] | Time: 0.31s\n",
      "(Training) Loss: 994496.6180\n",
      "(Validation) Loss: 1011977.4679, MAE: 3873.8477, R2: 0.1459\n",
      "==========================================================================================\n",
      "Epoch [4254/5000] | Time: 0.28s\n",
      "(Training) Loss: 974114.2265\n",
      "(Validation) Loss: 1011826.4483, MAE: 3874.8306, R2: 0.1460\n",
      "==========================================================================================\n",
      "Epoch [4255/5000] | Time: 0.26s\n",
      "(Training) Loss: 969670.1050\n",
      "(Validation) Loss: 1011663.1162, MAE: 3870.8416, R2: 0.1461\n",
      "==========================================================================================\n",
      "Epoch [4256/5000] | Time: 0.32s\n",
      "(Training) Loss: 1002903.7525\n",
      "(Validation) Loss: 1011517.7295, MAE: 3871.8274, R2: 0.1462\n",
      "==========================================================================================\n",
      "Epoch [4257/5000] | Time: 0.29s\n",
      "(Training) Loss: 999592.0571\n",
      "(Validation) Loss: 1011360.2895, MAE: 3872.0461, R2: 0.1464\n",
      "==========================================================================================\n",
      "Epoch [4258/5000] | Time: 0.27s\n",
      "(Training) Loss: 997058.0984\n",
      "(Validation) Loss: 1011209.3867, MAE: 3872.2463, R2: 0.1465\n",
      "==========================================================================================\n",
      "Epoch [4259/5000] | Time: 0.30s\n",
      "(Training) Loss: 977971.4651\n",
      "(Validation) Loss: 1011048.5638, MAE: 3870.4492, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [4260/5000] | Time: 0.27s\n",
      "(Training) Loss: 996585.7627\n",
      "(Validation) Loss: 1010892.5562, MAE: 3868.9517, R2: 0.1468\n",
      "==========================================================================================\n",
      "Epoch [4261/5000] | Time: 0.29s\n",
      "(Training) Loss: 986864.6434\n",
      "(Validation) Loss: 1010737.7879, MAE: 3869.0930, R2: 0.1469\n",
      "==========================================================================================\n",
      "Epoch [4262/5000] | Time: 0.30s\n",
      "(Training) Loss: 970797.7167\n",
      "(Validation) Loss: 1010597.7702, MAE: 3871.4038, R2: 0.1470\n",
      "==========================================================================================\n",
      "Epoch [4263/5000] | Time: 0.30s\n",
      "(Training) Loss: 982393.2069\n",
      "(Validation) Loss: 1010434.3365, MAE: 3867.6997, R2: 0.1471\n",
      "==========================================================================================\n",
      "Epoch [4264/5000] | Time: 0.27s\n",
      "(Training) Loss: 987392.2532\n",
      "(Validation) Loss: 1010292.5054, MAE: 3869.1650, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [4265/5000] | Time: 0.27s\n",
      "(Training) Loss: 973020.9575\n",
      "(Validation) Loss: 1010135.5581, MAE: 3868.5864, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [4266/5000] | Time: 0.32s\n",
      "(Training) Loss: 976147.9810\n",
      "(Validation) Loss: 1009974.3695, MAE: 3865.5984, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4267/5000] | Time: 0.32s\n",
      "(Training) Loss: 984126.0774\n",
      "(Validation) Loss: 1009816.0457, MAE: 3864.1558, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4268/5000] | Time: 0.33s\n",
      "(Training) Loss: 979352.9315\n",
      "(Validation) Loss: 1009676.7390, MAE: 3866.0334, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [4269/5000] | Time: 0.27s\n",
      "(Training) Loss: 1007181.4340\n",
      "(Validation) Loss: 1009532.3429, MAE: 3867.7063, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [4270/5000] | Time: 0.30s\n",
      "(Training) Loss: 990797.6681\n",
      "(Validation) Loss: 1009359.9238, MAE: 3863.3542, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4271/5000] | Time: 0.28s\n",
      "(Training) Loss: 991751.6129\n",
      "(Validation) Loss: 1009236.0990, MAE: 3867.5393, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4272/5000] | Time: 0.30s\n",
      "(Training) Loss: 972911.3388\n",
      "(Validation) Loss: 1009063.7562, MAE: 3866.6101, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [4273/5000] | Time: 0.28s\n",
      "(Training) Loss: 971879.3008\n",
      "(Validation) Loss: 1008912.8533, MAE: 3864.4717, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4274/5000] | Time: 0.27s\n",
      "(Training) Loss: 990445.6789\n",
      "(Validation) Loss: 1008749.6178, MAE: 3861.0952, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4275/5000] | Time: 0.28s\n",
      "(Training) Loss: 965844.2199\n",
      "(Validation) Loss: 1008604.4444, MAE: 3863.0139, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4276/5000] | Time: 0.30s\n",
      "(Training) Loss: 966903.4905\n",
      "(Validation) Loss: 1008457.2292, MAE: 3864.2197, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [4277/5000] | Time: 0.29s\n",
      "(Training) Loss: 980367.3642\n",
      "(Validation) Loss: 1008296.8533, MAE: 3860.9341, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4278/5000] | Time: 0.29s\n",
      "(Training) Loss: 973989.7234\n",
      "(Validation) Loss: 1008140.3429, MAE: 3859.2412, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4279/5000] | Time: 0.32s\n",
      "(Training) Loss: 983597.3154\n",
      "(Validation) Loss: 1008004.6121, MAE: 3862.6907, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4280/5000] | Time: 0.32s\n",
      "(Training) Loss: 978413.5368\n",
      "(Validation) Loss: 1007838.4914, MAE: 3859.0247, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4281/5000] | Time: 0.30s\n",
      "(Training) Loss: 971557.7253\n",
      "(Validation) Loss: 1007803.9416, MAE: 3870.8267, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4282/5000] | Time: 0.28s\n",
      "(Training) Loss: 970744.6301\n",
      "(Validation) Loss: 1007639.4260, MAE: 3866.5144, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4283/5000] | Time: 0.30s\n",
      "(Training) Loss: 972184.0044\n",
      "(Validation) Loss: 1007496.0610, MAE: 3870.1184, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [4284/5000] | Time: 0.32s\n",
      "(Training) Loss: 965618.3588\n",
      "(Validation) Loss: 1007362.8495, MAE: 3872.2393, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [4285/5000] | Time: 0.31s\n",
      "(Training) Loss: 969316.7310\n",
      "(Validation) Loss: 1007184.7111, MAE: 3864.7371, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [4286/5000] | Time: 0.34s\n",
      "(Training) Loss: 977455.3579\n",
      "(Validation) Loss: 1007045.1098, MAE: 3867.5457, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4287/5000] | Time: 0.29s\n",
      "(Training) Loss: 984080.2119\n",
      "(Validation) Loss: 1006889.1683, MAE: 3871.2725, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4288/5000] | Time: 0.30s\n",
      "(Training) Loss: 965671.6758\n",
      "(Validation) Loss: 1006728.9143, MAE: 3868.9094, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [4289/5000] | Time: 0.34s\n",
      "(Training) Loss: 998671.8261\n",
      "(Validation) Loss: 1006579.6063, MAE: 3866.3149, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [4290/5000] | Time: 0.31s\n",
      "(Training) Loss: 1001154.0958\n",
      "(Validation) Loss: 1006430.4610, MAE: 3865.2126, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [4291/5000] | Time: 0.35s\n",
      "(Training) Loss: 964437.2644\n",
      "(Validation) Loss: 1028938.2349, MAE: 3953.2920, R2: 0.1317\n",
      "==========================================================================================\n",
      "Epoch [4292/5000] | Time: 0.33s\n",
      "(Training) Loss: 1031357.1834\n",
      "(Validation) Loss: 1033547.1949, MAE: 3952.6174, R2: 0.1279\n",
      "==========================================================================================\n",
      "Epoch [4293/5000] | Time: 0.28s\n",
      "(Training) Loss: 996148.3598\n",
      "(Validation) Loss: 1033363.2356, MAE: 3949.0710, R2: 0.1280\n",
      "==========================================================================================\n",
      "Epoch [4294/5000] | Time: 0.36s\n",
      "(Training) Loss: 1010248.4258\n",
      "(Validation) Loss: 1033222.8825, MAE: 3954.7168, R2: 0.1281\n",
      "==========================================================================================\n",
      "Epoch [4295/5000] | Time: 0.34s\n",
      "(Training) Loss: 1013572.9784\n",
      "(Validation) Loss: 1033054.4203, MAE: 3952.5063, R2: 0.1283\n",
      "==========================================================================================\n",
      "Epoch [4296/5000] | Time: 0.31s\n",
      "(Training) Loss: 996762.6282\n",
      "(Validation) Loss: 1032876.8254, MAE: 3947.1165, R2: 0.1284\n",
      "==========================================================================================\n",
      "Epoch [4297/5000] | Time: 0.28s\n",
      "(Training) Loss: 997320.7322\n",
      "(Validation) Loss: 1032722.6768, MAE: 3948.5605, R2: 0.1286\n",
      "==========================================================================================\n",
      "Epoch [4298/5000] | Time: 0.30s\n",
      "(Training) Loss: 1002721.7500\n",
      "(Validation) Loss: 1032560.2946, MAE: 3947.1165, R2: 0.1287\n",
      "==========================================================================================\n",
      "Epoch [4299/5000] | Time: 0.34s\n",
      "(Training) Loss: 998356.9067\n",
      "(Validation) Loss: 1032399.4921, MAE: 3946.3423, R2: 0.1288\n",
      "==========================================================================================\n",
      "Epoch [4300/5000] | Time: 0.30s\n",
      "(Training) Loss: 1013324.1869\n",
      "(Validation) Loss: 1032230.9537, MAE: 3942.4861, R2: 0.1290\n",
      "==========================================================================================\n",
      "Epoch [4301/5000] | Time: 0.31s\n",
      "(Training) Loss: 1002676.7291\n",
      "(Validation) Loss: 1032071.4210, MAE: 3941.7761, R2: 0.1291\n",
      "==========================================================================================\n",
      "Epoch [4302/5000] | Time: 0.29s\n",
      "(Training) Loss: 999122.5463\n",
      "(Validation) Loss: 1031916.1448, MAE: 3942.8530, R2: 0.1292\n",
      "==========================================================================================\n",
      "Epoch [4303/5000] | Time: 0.32s\n",
      "(Training) Loss: 1003977.4105\n",
      "(Validation) Loss: 1031765.3283, MAE: 3942.8025, R2: 0.1294\n",
      "==========================================================================================\n",
      "Epoch [4304/5000] | Time: 0.30s\n",
      "(Training) Loss: 1009157.5590\n",
      "(Validation) Loss: 1031599.4870, MAE: 3941.6553, R2: 0.1295\n",
      "==========================================================================================\n",
      "Epoch [4305/5000] | Time: 0.33s\n",
      "(Training) Loss: 995890.4607\n",
      "(Validation) Loss: 1031451.4641, MAE: 3944.0327, R2: 0.1296\n",
      "==========================================================================================\n",
      "Epoch [4306/5000] | Time: 0.31s\n",
      "(Training) Loss: 1011295.6681\n",
      "(Validation) Loss: 1031287.6648, MAE: 3940.8101, R2: 0.1298\n",
      "==========================================================================================\n",
      "Epoch [4307/5000] | Time: 0.28s\n",
      "(Training) Loss: 1007550.3166\n",
      "(Validation) Loss: 1031129.3613, MAE: 3939.6968, R2: 0.1299\n",
      "==========================================================================================\n",
      "Epoch [4308/5000] | Time: 0.32s\n",
      "(Training) Loss: 993732.8331\n",
      "(Validation) Loss: 1030973.1403, MAE: 3939.8169, R2: 0.1300\n",
      "==========================================================================================\n",
      "Epoch [4309/5000] | Time: 0.32s\n",
      "(Training) Loss: 1009415.2636\n",
      "(Validation) Loss: 1030841.9606, MAE: 3944.8259, R2: 0.1301\n",
      "==========================================================================================\n",
      "Epoch [4310/5000] | Time: 0.31s\n",
      "(Training) Loss: 989204.0425\n",
      "(Validation) Loss: 1030660.2667, MAE: 3938.4304, R2: 0.1303\n",
      "==========================================================================================\n",
      "Epoch [4311/5000] | Time: 0.35s\n",
      "(Training) Loss: 986248.5031\n",
      "(Validation) Loss: 1030589.7448, MAE: 3950.2158, R2: 0.1303\n",
      "==========================================================================================\n",
      "Epoch [4312/5000] | Time: 0.33s\n",
      "(Training) Loss: 1017731.8617\n",
      "(Validation) Loss: 1030351.0248, MAE: 3937.0144, R2: 0.1305\n",
      "==========================================================================================\n",
      "Epoch [4313/5000] | Time: 0.30s\n",
      "(Training) Loss: 1001109.6028\n",
      "(Validation) Loss: 1030198.7352, MAE: 3937.0098, R2: 0.1307\n",
      "==========================================================================================\n",
      "Epoch [4314/5000] | Time: 0.29s\n",
      "(Training) Loss: 1004656.0666\n",
      "(Validation) Loss: 1030041.3410, MAE: 3936.5242, R2: 0.1308\n",
      "==========================================================================================\n",
      "Epoch [4315/5000] | Time: 0.28s\n",
      "(Training) Loss: 1008857.2589\n",
      "(Validation) Loss: 1029881.7575, MAE: 3934.3882, R2: 0.1309\n",
      "==========================================================================================\n",
      "Epoch [4316/5000] | Time: 0.33s\n",
      "(Training) Loss: 1009852.4937\n",
      "(Validation) Loss: 1029723.1390, MAE: 3933.6726, R2: 0.1311\n",
      "==========================================================================================\n",
      "Epoch [4317/5000] | Time: 0.38s\n",
      "(Training) Loss: 1001857.1980\n",
      "(Validation) Loss: 1029569.8387, MAE: 3933.7566, R2: 0.1312\n",
      "==========================================================================================\n",
      "Epoch [4318/5000] | Time: 0.33s\n",
      "(Training) Loss: 1002409.5825\n",
      "(Validation) Loss: 1029471.4006, MAE: 3944.3259, R2: 0.1313\n",
      "==========================================================================================\n",
      "Epoch [4319/5000] | Time: 0.48s\n",
      "(Training) Loss: 992817.0666\n",
      "(Validation) Loss: 1029270.8114, MAE: 3934.7476, R2: 0.1314\n",
      "==========================================================================================\n",
      "Epoch [4320/5000] | Time: 0.31s\n",
      "(Training) Loss: 984789.8417\n",
      "(Validation) Loss: 1029101.1251, MAE: 3931.9124, R2: 0.1316\n",
      "==========================================================================================\n",
      "Epoch [4321/5000] | Time: 0.28s\n",
      "(Training) Loss: 994702.3985\n",
      "(Validation) Loss: 1028950.0698, MAE: 3931.9009, R2: 0.1317\n",
      "==========================================================================================\n",
      "Epoch [4322/5000] | Time: 0.36s\n",
      "(Training) Loss: 989821.7132\n",
      "(Validation) Loss: 1028793.6051, MAE: 3930.2593, R2: 0.1318\n",
      "==========================================================================================\n",
      "Epoch [4323/5000] | Time: 0.30s\n",
      "(Training) Loss: 1000480.5330\n",
      "(Validation) Loss: 1028641.0819, MAE: 3929.2449, R2: 0.1320\n",
      "==========================================================================================\n",
      "Epoch [4324/5000] | Time: 0.20s\n",
      "(Training) Loss: 1003265.2836\n",
      "(Validation) Loss: 1028491.9365, MAE: 3931.3784, R2: 0.1321\n",
      "==========================================================================================\n",
      "Epoch [4325/5000] | Time: 0.23s\n",
      "(Training) Loss: 1004949.7868\n",
      "(Validation) Loss: 1028333.9733, MAE: 3928.6240, R2: 0.1322\n",
      "==========================================================================================\n",
      "Epoch [4326/5000] | Time: 0.24s\n",
      "(Training) Loss: 1000120.8128\n",
      "(Validation) Loss: 1028178.0825, MAE: 3928.1248, R2: 0.1324\n",
      "==========================================================================================\n",
      "Epoch [4327/5000] | Time: 0.26s\n",
      "(Training) Loss: 1027847.7722\n",
      "(Validation) Loss: 1028024.3454, MAE: 3928.1470, R2: 0.1325\n",
      "==========================================================================================\n",
      "Epoch [4328/5000] | Time: 0.26s\n",
      "(Training) Loss: 1007169.6218\n",
      "(Validation) Loss: 1027866.4533, MAE: 3928.1362, R2: 0.1326\n",
      "==========================================================================================\n",
      "Epoch [4329/5000] | Time: 0.26s\n",
      "(Training) Loss: 986207.6466\n",
      "(Validation) Loss: 1027723.1187, MAE: 3931.1672, R2: 0.1327\n",
      "==========================================================================================\n",
      "Epoch [4330/5000] | Time: 0.28s\n",
      "(Training) Loss: 993385.8864\n",
      "(Validation) Loss: 1027555.4997, MAE: 3927.4812, R2: 0.1329\n",
      "==========================================================================================\n",
      "Epoch [4331/5000] | Time: 0.31s\n",
      "(Training) Loss: 991246.6789\n",
      "(Validation) Loss: 1027406.0952, MAE: 3926.2336, R2: 0.1330\n",
      "==========================================================================================\n",
      "Epoch [4332/5000] | Time: 0.27s\n",
      "(Training) Loss: 988452.6079\n",
      "(Validation) Loss: 1027250.5244, MAE: 3925.1416, R2: 0.1331\n",
      "==========================================================================================\n",
      "Epoch [4333/5000] | Time: 0.22s\n",
      "(Training) Loss: 991010.0723\n",
      "(Validation) Loss: 1027122.4076, MAE: 3930.8538, R2: 0.1332\n",
      "==========================================================================================\n",
      "Epoch [4334/5000] | Time: 0.25s\n",
      "(Training) Loss: 991068.6231\n",
      "(Validation) Loss: 1026948.3022, MAE: 3926.0549, R2: 0.1334\n",
      "==========================================================================================\n",
      "Epoch [4335/5000] | Time: 0.28s\n",
      "(Training) Loss: 993522.6675\n",
      "(Validation) Loss: 1026802.5498, MAE: 3926.7104, R2: 0.1335\n",
      "==========================================================================================\n",
      "Epoch [4336/5000] | Time: 0.23s\n",
      "(Training) Loss: 1002250.4365\n",
      "(Validation) Loss: 1026636.5663, MAE: 3923.6492, R2: 0.1336\n",
      "==========================================================================================\n",
      "Epoch [4337/5000] | Time: 0.24s\n",
      "(Training) Loss: 986367.1662\n",
      "(Validation) Loss: 1026482.2400, MAE: 3921.4717, R2: 0.1338\n",
      "==========================================================================================\n",
      "Epoch [4338/5000] | Time: 0.23s\n",
      "(Training) Loss: 1001788.1171\n",
      "(Validation) Loss: 1026333.0794, MAE: 3925.8020, R2: 0.1339\n",
      "==========================================================================================\n",
      "Epoch [4339/5000] | Time: 0.26s\n",
      "(Training) Loss: 1000815.0431\n",
      "(Validation) Loss: 1026309.6940, MAE: 3931.4675, R2: 0.1339\n",
      "==========================================================================================\n",
      "Epoch [4340/5000] | Time: 0.27s\n",
      "(Training) Loss: 999576.7341\n",
      "(Validation) Loss: 1026241.0362, MAE: 3931.7646, R2: 0.1340\n",
      "==========================================================================================\n",
      "Epoch [4341/5000] | Time: 0.26s\n",
      "(Training) Loss: 991793.6206\n",
      "(Validation) Loss: 1026083.3727, MAE: 3930.0786, R2: 0.1341\n",
      "==========================================================================================\n",
      "Epoch [4342/5000] | Time: 0.27s\n",
      "(Training) Loss: 983851.2855\n",
      "(Validation) Loss: 1025931.4286, MAE: 3932.5295, R2: 0.1342\n",
      "==========================================================================================\n",
      "Epoch [4343/5000] | Time: 0.23s\n",
      "(Training) Loss: 1002429.5603\n",
      "(Validation) Loss: 1025777.9708, MAE: 3929.4546, R2: 0.1343\n",
      "==========================================================================================\n",
      "Epoch [4344/5000] | Time: 0.23s\n",
      "(Training) Loss: 999635.9435\n",
      "(Validation) Loss: 1025624.4825, MAE: 3928.8982, R2: 0.1345\n",
      "==========================================================================================\n",
      "Epoch [4345/5000] | Time: 0.27s\n",
      "(Training) Loss: 1005692.1739\n",
      "(Validation) Loss: 1025473.6152, MAE: 3931.9771, R2: 0.1346\n",
      "==========================================================================================\n",
      "Epoch [4346/5000] | Time: 0.24s\n",
      "(Training) Loss: 982069.5239\n",
      "(Validation) Loss: 1025314.3213, MAE: 3932.0161, R2: 0.1347\n",
      "==========================================================================================\n",
      "Epoch [4347/5000] | Time: 0.26s\n",
      "(Training) Loss: 996969.5628\n",
      "(Validation) Loss: 1025171.0781, MAE: 3931.3677, R2: 0.1348\n",
      "==========================================================================================\n",
      "Epoch [4348/5000] | Time: 0.24s\n",
      "(Training) Loss: 996822.0108\n",
      "(Validation) Loss: 1025011.7283, MAE: 3928.5920, R2: 0.1350\n",
      "==========================================================================================\n",
      "Epoch [4349/5000] | Time: 0.32s\n",
      "(Training) Loss: 994368.1117\n",
      "(Validation) Loss: 1024855.7917, MAE: 3926.7317, R2: 0.1351\n",
      "==========================================================================================\n",
      "Epoch [4350/5000] | Time: 0.29s\n",
      "(Training) Loss: 993625.9937\n",
      "(Validation) Loss: 1024704.5333, MAE: 3927.0859, R2: 0.1352\n",
      "==========================================================================================\n",
      "Epoch [4351/5000] | Time: 0.27s\n",
      "(Training) Loss: 1017170.6878\n",
      "(Validation) Loss: 1024548.4648, MAE: 3927.0505, R2: 0.1354\n",
      "==========================================================================================\n",
      "Epoch [4352/5000] | Time: 0.31s\n",
      "(Training) Loss: 1004272.2728\n",
      "(Validation) Loss: 1024396.0076, MAE: 3927.0698, R2: 0.1355\n",
      "==========================================================================================\n",
      "Epoch [4353/5000] | Time: 0.34s\n",
      "(Training) Loss: 991008.1244\n",
      "(Validation) Loss: 1024236.3530, MAE: 3923.8125, R2: 0.1356\n",
      "==========================================================================================\n",
      "Epoch [4354/5000] | Time: 0.30s\n",
      "(Training) Loss: 993829.5609\n",
      "(Validation) Loss: 1024083.8248, MAE: 3923.8857, R2: 0.1358\n",
      "==========================================================================================\n",
      "Epoch [4355/5000] | Time: 0.31s\n",
      "(Training) Loss: 1002393.2259\n",
      "(Validation) Loss: 1023943.8171, MAE: 3926.2026, R2: 0.1359\n",
      "==========================================================================================\n",
      "Epoch [4356/5000] | Time: 0.32s\n",
      "(Training) Loss: 982074.5879\n",
      "(Validation) Loss: 1023778.0317, MAE: 3923.7568, R2: 0.1360\n",
      "==========================================================================================\n",
      "Epoch [4357/5000] | Time: 0.27s\n",
      "(Training) Loss: 993568.8959\n",
      "(Validation) Loss: 1023647.6698, MAE: 3927.6978, R2: 0.1361\n",
      "==========================================================================================\n",
      "Epoch [4358/5000] | Time: 0.26s\n",
      "(Training) Loss: 993011.2360\n",
      "(Validation) Loss: 1023478.2883, MAE: 3924.1323, R2: 0.1363\n",
      "==========================================================================================\n",
      "Epoch [4359/5000] | Time: 0.26s\n",
      "(Training) Loss: 1006790.7976\n",
      "(Validation) Loss: 1023328.2032, MAE: 3923.4978, R2: 0.1364\n",
      "==========================================================================================\n",
      "Epoch [4360/5000] | Time: 0.31s\n",
      "(Training) Loss: 992601.0711\n",
      "(Validation) Loss: 1023168.6400, MAE: 3921.6521, R2: 0.1365\n",
      "==========================================================================================\n",
      "Epoch [4361/5000] | Time: 0.34s\n",
      "(Training) Loss: 998834.9277\n",
      "(Validation) Loss: 1023015.3041, MAE: 3921.2397, R2: 0.1366\n",
      "==========================================================================================\n",
      "Epoch [4362/5000] | Time: 0.31s\n",
      "(Training) Loss: 999675.0279\n",
      "(Validation) Loss: 1022864.8483, MAE: 3921.4780, R2: 0.1368\n",
      "==========================================================================================\n",
      "Epoch [4363/5000] | Time: 0.30s\n",
      "(Training) Loss: 1016005.3744\n",
      "(Validation) Loss: 1022709.8311, MAE: 3920.6279, R2: 0.1369\n",
      "==========================================================================================\n",
      "Epoch [4364/5000] | Time: 0.28s\n",
      "(Training) Loss: 989990.2018\n",
      "(Validation) Loss: 1022556.8152, MAE: 3920.1636, R2: 0.1370\n",
      "==========================================================================================\n",
      "Epoch [4365/5000] | Time: 0.31s\n",
      "(Training) Loss: 992136.4937\n",
      "(Validation) Loss: 1022400.1067, MAE: 3918.7075, R2: 0.1372\n",
      "==========================================================================================\n",
      "Epoch [4366/5000] | Time: 0.31s\n",
      "(Training) Loss: 992110.4841\n",
      "(Validation) Loss: 1022262.1410, MAE: 3920.7898, R2: 0.1373\n",
      "==========================================================================================\n",
      "Epoch [4367/5000] | Time: 0.29s\n",
      "(Training) Loss: 982909.0761\n",
      "(Validation) Loss: 1022095.4362, MAE: 3917.3142, R2: 0.1374\n",
      "==========================================================================================\n",
      "Epoch [4368/5000] | Time: 0.28s\n",
      "(Training) Loss: 999115.5266\n",
      "(Validation) Loss: 1021948.2362, MAE: 3917.5342, R2: 0.1375\n",
      "==========================================================================================\n",
      "Epoch [4369/5000] | Time: 0.30s\n",
      "(Training) Loss: 990999.1358\n",
      "(Validation) Loss: 1021816.7670, MAE: 3923.6553, R2: 0.1376\n",
      "==========================================================================================\n",
      "Epoch [4370/5000] | Time: 0.32s\n",
      "(Training) Loss: 980189.1374\n",
      "(Validation) Loss: 1021644.6984, MAE: 3917.4536, R2: 0.1378\n",
      "==========================================================================================\n",
      "Epoch [4371/5000] | Time: 0.31s\n",
      "(Training) Loss: 999066.6770\n",
      "(Validation) Loss: 1021487.9543, MAE: 3915.2678, R2: 0.1379\n",
      "==========================================================================================\n",
      "Epoch [4372/5000] | Time: 0.30s\n",
      "(Training) Loss: 985474.2183\n",
      "(Validation) Loss: 1021342.4762, MAE: 3916.6431, R2: 0.1380\n",
      "==========================================================================================\n",
      "Epoch [4373/5000] | Time: 0.36s\n",
      "(Training) Loss: 999155.9784\n",
      "(Validation) Loss: 1021186.0419, MAE: 3914.3555, R2: 0.1382\n",
      "==========================================================================================\n",
      "Epoch [4374/5000] | Time: 0.31s\n",
      "(Training) Loss: 998614.3982\n",
      "(Validation) Loss: 1021040.3403, MAE: 3916.3823, R2: 0.1383\n",
      "==========================================================================================\n",
      "Epoch [4375/5000] | Time: 0.29s\n",
      "(Training) Loss: 984612.8655\n",
      "(Validation) Loss: 1020878.5727, MAE: 3912.4277, R2: 0.1384\n",
      "==========================================================================================\n",
      "Epoch [4376/5000] | Time: 0.28s\n",
      "(Training) Loss: 995677.5552\n",
      "(Validation) Loss: 1020733.8768, MAE: 3916.4839, R2: 0.1385\n",
      "==========================================================================================\n",
      "Epoch [4377/5000] | Time: 0.28s\n",
      "(Training) Loss: 992327.5140\n",
      "(Validation) Loss: 1020575.1010, MAE: 3913.4482, R2: 0.1387\n",
      "==========================================================================================\n",
      "Epoch [4378/5000] | Time: 0.34s\n",
      "(Training) Loss: 992705.1358\n",
      "(Validation) Loss: 1020423.9390, MAE: 3912.8269, R2: 0.1388\n",
      "==========================================================================================\n",
      "Epoch [4379/5000] | Time: 0.33s\n",
      "(Training) Loss: 978320.1326\n",
      "(Validation) Loss: 1020277.8260, MAE: 3914.0962, R2: 0.1389\n",
      "==========================================================================================\n",
      "Epoch [4380/5000] | Time: 0.31s\n",
      "(Training) Loss: 986201.4569\n",
      "(Validation) Loss: 1020119.0908, MAE: 3911.3733, R2: 0.1391\n",
      "==========================================================================================\n",
      "Epoch [4381/5000] | Time: 0.30s\n",
      "(Training) Loss: 1002132.7297\n",
      "(Validation) Loss: 1019968.7517, MAE: 3911.7671, R2: 0.1392\n",
      "==========================================================================================\n",
      "Epoch [4382/5000] | Time: 0.28s\n",
      "(Training) Loss: 986657.1574\n",
      "(Validation) Loss: 1019810.4178, MAE: 3910.0388, R2: 0.1393\n",
      "==========================================================================================\n",
      "Epoch [4383/5000] | Time: 0.29s\n",
      "(Training) Loss: 992418.4423\n",
      "(Validation) Loss: 1019661.3486, MAE: 3909.0161, R2: 0.1394\n",
      "==========================================================================================\n",
      "Epoch [4384/5000] | Time: 0.31s\n",
      "(Training) Loss: 1013382.7462\n",
      "(Validation) Loss: 1019509.6127, MAE: 3908.7036, R2: 0.1396\n",
      "==========================================================================================\n",
      "Epoch [4385/5000] | Time: 0.27s\n",
      "(Training) Loss: 990938.0105\n",
      "(Validation) Loss: 1019360.9549, MAE: 3912.0806, R2: 0.1397\n",
      "==========================================================================================\n",
      "Epoch [4386/5000] | Time: 0.28s\n",
      "(Training) Loss: 980195.8185\n",
      "(Validation) Loss: 1019203.5098, MAE: 3907.1809, R2: 0.1398\n",
      "==========================================================================================\n",
      "Epoch [4387/5000] | Time: 0.30s\n",
      "(Training) Loss: 1000641.4683\n",
      "(Validation) Loss: 1019050.6006, MAE: 3906.1482, R2: 0.1400\n",
      "==========================================================================================\n",
      "Epoch [4388/5000] | Time: 0.28s\n",
      "(Training) Loss: 983002.2024\n",
      "(Validation) Loss: 1018895.7003, MAE: 3906.0159, R2: 0.1401\n",
      "==========================================================================================\n",
      "Epoch [4389/5000] | Time: 0.28s\n",
      "(Training) Loss: 985155.2043\n",
      "(Validation) Loss: 1018755.4337, MAE: 3906.8337, R2: 0.1402\n",
      "==========================================================================================\n",
      "Epoch [4390/5000] | Time: 0.29s\n",
      "(Training) Loss: 1000687.2287\n",
      "(Validation) Loss: 1018599.0298, MAE: 3905.3689, R2: 0.1403\n",
      "==========================================================================================\n",
      "Epoch [4391/5000] | Time: 0.31s\n",
      "(Training) Loss: 990200.5165\n",
      "(Validation) Loss: 1018448.7010, MAE: 3906.9321, R2: 0.1405\n",
      "==========================================================================================\n",
      "Epoch [4392/5000] | Time: 0.29s\n",
      "(Training) Loss: 984572.7878\n",
      "(Validation) Loss: 1018302.3594, MAE: 3907.1404, R2: 0.1406\n",
      "==========================================================================================\n",
      "Epoch [4393/5000] | Time: 0.28s\n",
      "(Training) Loss: 979851.6345\n",
      "(Validation) Loss: 1018139.4692, MAE: 3902.6858, R2: 0.1407\n",
      "==========================================================================================\n",
      "Epoch [4394/5000] | Time: 0.30s\n",
      "(Training) Loss: 998469.1669\n",
      "(Validation) Loss: 1017988.2210, MAE: 3902.7085, R2: 0.1408\n",
      "==========================================================================================\n",
      "Epoch [4395/5000] | Time: 0.33s\n",
      "(Training) Loss: 990155.5635\n",
      "(Validation) Loss: 1017837.0794, MAE: 3901.8752, R2: 0.1410\n",
      "==========================================================================================\n",
      "Epoch [4396/5000] | Time: 0.31s\n",
      "(Training) Loss: 989030.2912\n",
      "(Validation) Loss: 1017683.6470, MAE: 3900.9185, R2: 0.1411\n",
      "==========================================================================================\n",
      "Epoch [4397/5000] | Time: 0.29s\n",
      "(Training) Loss: 993061.9664\n",
      "(Validation) Loss: 1017541.0489, MAE: 3903.6907, R2: 0.1412\n",
      "==========================================================================================\n",
      "Epoch [4398/5000] | Time: 0.29s\n",
      "(Training) Loss: 976049.0292\n",
      "(Validation) Loss: 1017386.9308, MAE: 3901.4580, R2: 0.1413\n",
      "==========================================================================================\n",
      "Epoch [4399/5000] | Time: 0.32s\n",
      "(Training) Loss: 1003200.4530\n",
      "(Validation) Loss: 1017231.6190, MAE: 3901.1587, R2: 0.1415\n",
      "==========================================================================================\n",
      "Epoch [4400/5000] | Time: 0.28s\n",
      "(Training) Loss: 1002688.2094\n",
      "(Validation) Loss: 1017076.9016, MAE: 3900.1162, R2: 0.1416\n",
      "==========================================================================================\n",
      "Epoch [4401/5000] | Time: 0.28s\n",
      "(Training) Loss: 976719.7141\n",
      "(Validation) Loss: 1016926.5676, MAE: 3899.4866, R2: 0.1417\n",
      "==========================================================================================\n",
      "Epoch [4402/5000] | Time: 0.29s\n",
      "(Training) Loss: 980413.3065\n",
      "(Validation) Loss: 1016773.0590, MAE: 3902.5564, R2: 0.1418\n",
      "==========================================================================================\n",
      "Epoch [4403/5000] | Time: 0.28s\n",
      "(Training) Loss: 977222.4454\n",
      "(Validation) Loss: 1016625.0717, MAE: 3899.0125, R2: 0.1420\n",
      "==========================================================================================\n",
      "Epoch [4404/5000] | Time: 0.27s\n",
      "(Training) Loss: 990318.6339\n",
      "(Validation) Loss: 1016475.5251, MAE: 3898.7334, R2: 0.1421\n",
      "==========================================================================================\n",
      "Epoch [4405/5000] | Time: 0.27s\n",
      "(Training) Loss: 979833.4740\n",
      "(Validation) Loss: 1016315.1390, MAE: 3895.4951, R2: 0.1422\n",
      "==========================================================================================\n",
      "Epoch [4406/5000] | Time: 0.24s\n",
      "(Training) Loss: 973392.7013\n",
      "(Validation) Loss: 1016184.7873, MAE: 3903.3994, R2: 0.1423\n",
      "==========================================================================================\n",
      "Epoch [4407/5000] | Time: 0.27s\n",
      "(Training) Loss: 993782.2982\n",
      "(Validation) Loss: 1016025.1530, MAE: 3897.9705, R2: 0.1425\n",
      "==========================================================================================\n",
      "Epoch [4408/5000] | Time: 0.29s\n",
      "(Training) Loss: 1010195.7506\n",
      "(Validation) Loss: 1015870.0597, MAE: 3895.9861, R2: 0.1426\n",
      "==========================================================================================\n",
      "Epoch [4409/5000] | Time: 0.30s\n",
      "(Training) Loss: 996666.6085\n",
      "(Validation) Loss: 1015712.0813, MAE: 3895.7610, R2: 0.1427\n",
      "==========================================================================================\n",
      "Epoch [4410/5000] | Time: 0.43s\n",
      "(Training) Loss: 983101.7728\n",
      "(Validation) Loss: 1015564.1448, MAE: 3895.9453, R2: 0.1429\n",
      "==========================================================================================\n",
      "Epoch [4411/5000] | Time: 0.31s\n",
      "(Training) Loss: 980742.9089\n",
      "(Validation) Loss: 1015426.0368, MAE: 3898.0781, R2: 0.1430\n",
      "==========================================================================================\n",
      "Epoch [4412/5000] | Time: 0.36s\n",
      "(Training) Loss: 984957.3655\n",
      "(Validation) Loss: 1015265.4273, MAE: 3895.0532, R2: 0.1431\n",
      "==========================================================================================\n",
      "Epoch [4413/5000] | Time: 0.34s\n",
      "(Training) Loss: 982315.1440\n",
      "(Validation) Loss: 1015108.5206, MAE: 3896.1487, R2: 0.1432\n",
      "==========================================================================================\n",
      "Epoch [4414/5000] | Time: 0.31s\n",
      "(Training) Loss: 974531.3924\n",
      "(Validation) Loss: 1014957.0895, MAE: 3892.4707, R2: 0.1434\n",
      "==========================================================================================\n",
      "Epoch [4415/5000] | Time: 0.32s\n",
      "(Training) Loss: 1001329.2062\n",
      "(Validation) Loss: 1014676.3175, MAE: 3884.9143, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [4416/5000] | Time: 0.28s\n",
      "(Training) Loss: 973240.7989\n",
      "(Validation) Loss: 1014653.8362, MAE: 3891.8301, R2: 0.1436\n",
      "==========================================================================================\n",
      "Epoch [4417/5000] | Time: 0.34s\n",
      "(Training) Loss: 983747.6548\n",
      "(Validation) Loss: 1014509.3994, MAE: 3893.7410, R2: 0.1437\n",
      "==========================================================================================\n",
      "Epoch [4418/5000] | Time: 0.28s\n",
      "(Training) Loss: 972851.2703\n",
      "(Validation) Loss: 1014351.1619, MAE: 3891.4670, R2: 0.1439\n",
      "==========================================================================================\n",
      "Epoch [4419/5000] | Time: 0.29s\n",
      "(Training) Loss: 983175.9619\n",
      "(Validation) Loss: 1014220.7644, MAE: 3893.1689, R2: 0.1440\n",
      "==========================================================================================\n",
      "Epoch [4420/5000] | Time: 0.29s\n",
      "(Training) Loss: 974634.8972\n",
      "(Validation) Loss: 1014058.7835, MAE: 3889.6152, R2: 0.1441\n",
      "==========================================================================================\n",
      "Epoch [4421/5000] | Time: 0.30s\n",
      "(Training) Loss: 986966.8287\n",
      "(Validation) Loss: 1013907.6013, MAE: 3888.0295, R2: 0.1442\n",
      "==========================================================================================\n",
      "Epoch [4422/5000] | Time: 0.33s\n",
      "(Training) Loss: 970783.0785\n",
      "(Validation) Loss: 1013749.8921, MAE: 3886.6365, R2: 0.1444\n",
      "==========================================================================================\n",
      "Epoch [4423/5000] | Time: 0.31s\n",
      "(Training) Loss: 979436.2836\n",
      "(Validation) Loss: 1013604.8559, MAE: 3888.6841, R2: 0.1445\n",
      "==========================================================================================\n",
      "Epoch [4424/5000] | Time: 0.32s\n",
      "(Training) Loss: 978994.9327\n",
      "(Validation) Loss: 1013445.5416, MAE: 3883.9622, R2: 0.1446\n",
      "==========================================================================================\n",
      "Epoch [4425/5000] | Time: 0.31s\n",
      "(Training) Loss: 978776.2671\n",
      "(Validation) Loss: 1013297.4070, MAE: 3886.1882, R2: 0.1447\n",
      "==========================================================================================\n",
      "Epoch [4426/5000] | Time: 0.30s\n",
      "(Training) Loss: 978120.2195\n",
      "(Validation) Loss: 1013157.3283, MAE: 3888.3962, R2: 0.1449\n",
      "==========================================================================================\n",
      "Epoch [4427/5000] | Time: 0.34s\n",
      "(Training) Loss: 989342.4283\n",
      "(Validation) Loss: 1012991.8781, MAE: 3881.7688, R2: 0.1450\n",
      "==========================================================================================\n",
      "Epoch [4428/5000] | Time: 0.28s\n",
      "(Training) Loss: 985088.0362\n",
      "(Validation) Loss: 1010250.5498, MAE: 3878.1223, R2: 0.1473\n",
      "==========================================================================================\n",
      "Epoch [4429/5000] | Time: 0.29s\n",
      "(Training) Loss: 972829.0964\n",
      "(Validation) Loss: 1010097.9606, MAE: 3875.0098, R2: 0.1474\n",
      "==========================================================================================\n",
      "Epoch [4430/5000] | Time: 0.28s\n",
      "(Training) Loss: 972194.1155\n",
      "(Validation) Loss: 1009950.0190, MAE: 3871.5278, R2: 0.1475\n",
      "==========================================================================================\n",
      "Epoch [4431/5000] | Time: 0.30s\n",
      "(Training) Loss: 972650.6485\n",
      "(Validation) Loss: 1009809.6406, MAE: 3872.1519, R2: 0.1477\n",
      "==========================================================================================\n",
      "Epoch [4432/5000] | Time: 0.30s\n",
      "(Training) Loss: 978775.5279\n",
      "(Validation) Loss: 1009669.8514, MAE: 3874.0042, R2: 0.1478\n",
      "==========================================================================================\n",
      "Epoch [4433/5000] | Time: 0.32s\n",
      "(Training) Loss: 985395.2379\n",
      "(Validation) Loss: 1009514.2603, MAE: 3871.7075, R2: 0.1479\n",
      "==========================================================================================\n",
      "Epoch [4434/5000] | Time: 0.34s\n",
      "(Training) Loss: 974251.7490\n",
      "(Validation) Loss: 1009364.5206, MAE: 3870.8372, R2: 0.1480\n",
      "==========================================================================================\n",
      "Epoch [4435/5000] | Time: 0.31s\n",
      "(Training) Loss: 992704.2157\n",
      "(Validation) Loss: 1009231.7308, MAE: 3872.4602, R2: 0.1481\n",
      "==========================================================================================\n",
      "Epoch [4436/5000] | Time: 0.33s\n",
      "(Training) Loss: 984773.6409\n",
      "(Validation) Loss: 1009074.6870, MAE: 3868.8120, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [4437/5000] | Time: 0.29s\n",
      "(Training) Loss: 986386.1675\n",
      "(Validation) Loss: 1008921.7473, MAE: 3867.0754, R2: 0.1484\n",
      "==========================================================================================\n",
      "Epoch [4438/5000] | Time: 0.29s\n",
      "(Training) Loss: 977354.0812\n",
      "(Validation) Loss: 1008782.3797, MAE: 3868.9104, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4439/5000] | Time: 0.33s\n",
      "(Training) Loss: 969007.3823\n",
      "(Validation) Loss: 1008632.0813, MAE: 3868.5715, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4440/5000] | Time: 0.33s\n",
      "(Training) Loss: 988085.7030\n",
      "(Validation) Loss: 1008487.1517, MAE: 3870.5093, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [4441/5000] | Time: 0.33s\n",
      "(Training) Loss: 976896.9588\n",
      "(Validation) Loss: 1008339.4540, MAE: 3867.6721, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4442/5000] | Time: 0.38s\n",
      "(Training) Loss: 980988.8407\n",
      "(Validation) Loss: 1008076.5816, MAE: 3859.6870, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4443/5000] | Time: 0.37s\n",
      "(Training) Loss: 972477.5533\n",
      "(Validation) Loss: 1007922.0267, MAE: 3858.3699, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4444/5000] | Time: 0.34s\n",
      "(Training) Loss: 967107.8426\n",
      "(Validation) Loss: 1007780.3937, MAE: 3857.3350, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4445/5000] | Time: 0.32s\n",
      "(Training) Loss: 977614.0761\n",
      "(Validation) Loss: 1007643.3676, MAE: 3858.6121, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4446/5000] | Time: 0.32s\n",
      "(Training) Loss: 978661.0349\n",
      "(Validation) Loss: 1007586.5448, MAE: 3875.1489, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4447/5000] | Time: 0.31s\n",
      "(Training) Loss: 983697.3287\n",
      "(Validation) Loss: 1011022.7556, MAE: 3870.4819, R2: 0.1466\n",
      "==========================================================================================\n",
      "Epoch [4448/5000] | Time: 0.31s\n",
      "(Training) Loss: 980714.4397\n",
      "(Validation) Loss: 1008686.6032, MAE: 3860.4622, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4449/5000] | Time: 0.33s\n",
      "(Training) Loss: 979632.8801\n",
      "(Validation) Loss: 1008543.1924, MAE: 3863.6658, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4450/5000] | Time: 0.34s\n",
      "(Training) Loss: 984988.9848\n",
      "(Validation) Loss: 1008379.5556, MAE: 3858.4802, R2: 0.1489\n",
      "==========================================================================================\n",
      "Epoch [4451/5000] | Time: 0.33s\n",
      "(Training) Loss: 969926.6637\n",
      "(Validation) Loss: 1008218.1181, MAE: 3855.4553, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [4452/5000] | Time: 0.34s\n",
      "(Training) Loss: 967035.5146\n",
      "(Validation) Loss: 1008078.9435, MAE: 3857.0723, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4453/5000] | Time: 0.29s\n",
      "(Training) Loss: 971589.9765\n",
      "(Validation) Loss: 1007927.2686, MAE: 3856.7441, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4454/5000] | Time: 0.35s\n",
      "(Training) Loss: 983081.3376\n",
      "(Validation) Loss: 1007909.8006, MAE: 3866.2576, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4455/5000] | Time: 0.29s\n",
      "(Training) Loss: 970131.9511\n",
      "(Validation) Loss: 1007791.2838, MAE: 3868.1216, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4456/5000] | Time: 0.33s\n",
      "(Training) Loss: 991808.0698\n",
      "(Validation) Loss: 1007610.0775, MAE: 3864.1182, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4457/5000] | Time: 0.33s\n",
      "(Training) Loss: 968943.6402\n",
      "(Validation) Loss: 1007456.2641, MAE: 3862.8718, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [4458/5000] | Time: 0.35s\n",
      "(Training) Loss: 997902.1371\n",
      "(Validation) Loss: 1007301.5213, MAE: 3861.4409, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [4459/5000] | Time: 0.36s\n",
      "(Training) Loss: 998413.4016\n",
      "(Validation) Loss: 1007158.2222, MAE: 3863.8108, R2: 0.1499\n",
      "==========================================================================================\n",
      "Epoch [4460/5000] | Time: 0.36s\n",
      "(Training) Loss: 976397.2170\n",
      "(Validation) Loss: 1007009.9657, MAE: 3864.0200, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4461/5000] | Time: 0.32s\n",
      "(Training) Loss: 1010893.1846\n",
      "(Validation) Loss: 1006857.3460, MAE: 3861.9536, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4462/5000] | Time: 0.28s\n",
      "(Training) Loss: 976528.8598\n",
      "(Validation) Loss: 1006709.4654, MAE: 3861.2463, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [4463/5000] | Time: 0.29s\n",
      "(Training) Loss: 979528.2690\n",
      "(Validation) Loss: 1006566.4051, MAE: 3862.8101, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [4464/5000] | Time: 0.36s\n",
      "(Training) Loss: 964588.8870\n",
      "(Validation) Loss: 1006410.0165, MAE: 3859.3140, R2: 0.1505\n",
      "==========================================================================================\n",
      "Epoch [4465/5000] | Time: 0.33s\n",
      "(Training) Loss: 982253.1516\n",
      "(Validation) Loss: 1006295.3803, MAE: 3861.7195, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [4466/5000] | Time: 0.33s\n",
      "(Training) Loss: 972524.0324\n",
      "(Validation) Loss: 1006115.6267, MAE: 3859.6807, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [4467/5000] | Time: 0.33s\n",
      "(Training) Loss: 971637.8020\n",
      "(Validation) Loss: 1005971.4794, MAE: 3858.6804, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [4468/5000] | Time: 0.27s\n",
      "(Training) Loss: 967942.4791\n",
      "(Validation) Loss: 1005820.7594, MAE: 3857.9155, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [4469/5000] | Time: 0.30s\n",
      "(Training) Loss: 966177.1815\n",
      "(Validation) Loss: 1005667.8400, MAE: 3854.5923, R2: 0.1511\n",
      "==========================================================================================\n",
      "Epoch [4470/5000] | Time: 0.31s\n",
      "(Training) Loss: 970351.0102\n",
      "(Validation) Loss: 1005524.4546, MAE: 3855.1013, R2: 0.1512\n",
      "==========================================================================================\n",
      "Epoch [4471/5000] | Time: 0.35s\n",
      "(Training) Loss: 973928.1904\n",
      "(Validation) Loss: 1005298.9206, MAE: 3858.5273, R2: 0.1514\n",
      "==========================================================================================\n",
      "Epoch [4472/5000] | Time: 0.31s\n",
      "(Training) Loss: 995624.6929\n",
      "(Validation) Loss: 1009168.3251, MAE: 3877.2354, R2: 0.1482\n",
      "==========================================================================================\n",
      "Epoch [4473/5000] | Time: 0.32s\n",
      "(Training) Loss: 986553.5159\n",
      "(Validation) Loss: 1009004.2006, MAE: 3872.4568, R2: 0.1483\n",
      "==========================================================================================\n",
      "Epoch [4474/5000] | Time: 0.31s\n",
      "(Training) Loss: 968521.5466\n",
      "(Validation) Loss: 1008848.8940, MAE: 3873.1204, R2: 0.1485\n",
      "==========================================================================================\n",
      "Epoch [4475/5000] | Time: 0.30s\n",
      "(Training) Loss: 968535.8372\n",
      "(Validation) Loss: 1008698.0622, MAE: 3872.9927, R2: 0.1486\n",
      "==========================================================================================\n",
      "Epoch [4476/5000] | Time: 0.28s\n",
      "(Training) Loss: 977978.3331\n",
      "(Validation) Loss: 1008546.1740, MAE: 3871.1025, R2: 0.1487\n",
      "==========================================================================================\n",
      "Epoch [4477/5000] | Time: 0.31s\n",
      "(Training) Loss: 968090.1199\n",
      "(Validation) Loss: 1008396.3479, MAE: 3872.8831, R2: 0.1488\n",
      "==========================================================================================\n",
      "Epoch [4478/5000] | Time: 0.34s\n",
      "(Training) Loss: 966268.5331\n",
      "(Validation) Loss: 1008243.9568, MAE: 3870.6741, R2: 0.1490\n",
      "==========================================================================================\n",
      "Epoch [4479/5000] | Time: 0.30s\n",
      "(Training) Loss: 987893.8135\n",
      "(Validation) Loss: 1008094.3644, MAE: 3868.3108, R2: 0.1491\n",
      "==========================================================================================\n",
      "Epoch [4480/5000] | Time: 0.32s\n",
      "(Training) Loss: 974276.1637\n",
      "(Validation) Loss: 1007947.9517, MAE: 3869.7200, R2: 0.1492\n",
      "==========================================================================================\n",
      "Epoch [4481/5000] | Time: 0.31s\n",
      "(Training) Loss: 985166.1777\n",
      "(Validation) Loss: 1007793.6356, MAE: 3867.7830, R2: 0.1493\n",
      "==========================================================================================\n",
      "Epoch [4482/5000] | Time: 0.31s\n",
      "(Training) Loss: 983012.5819\n",
      "(Validation) Loss: 1007646.9841, MAE: 3867.7195, R2: 0.1495\n",
      "==========================================================================================\n",
      "Epoch [4483/5000] | Time: 0.29s\n",
      "(Training) Loss: 972529.1694\n",
      "(Validation) Loss: 1007499.6521, MAE: 3868.0310, R2: 0.1496\n",
      "==========================================================================================\n",
      "Epoch [4484/5000] | Time: 0.29s\n",
      "(Training) Loss: 980053.0349\n",
      "(Validation) Loss: 1007351.1263, MAE: 3867.5889, R2: 0.1497\n",
      "==========================================================================================\n",
      "Epoch [4485/5000] | Time: 0.29s\n",
      "(Training) Loss: 976933.5121\n",
      "(Validation) Loss: 1007201.2597, MAE: 3866.7620, R2: 0.1498\n",
      "==========================================================================================\n",
      "Epoch [4486/5000] | Time: 0.31s\n",
      "(Training) Loss: 971844.3991\n",
      "(Validation) Loss: 1007045.9429, MAE: 3864.8994, R2: 0.1500\n",
      "==========================================================================================\n",
      "Epoch [4487/5000] | Time: 0.30s\n",
      "(Training) Loss: 978074.8128\n",
      "(Validation) Loss: 1006896.4622, MAE: 3864.0161, R2: 0.1501\n",
      "==========================================================================================\n",
      "Epoch [4488/5000] | Time: 0.34s\n",
      "(Training) Loss: 982582.6301\n",
      "(Validation) Loss: 1006755.6165, MAE: 3864.7888, R2: 0.1502\n",
      "==========================================================================================\n",
      "Epoch [4489/5000] | Time: 0.32s\n",
      "(Training) Loss: 984811.3103\n",
      "(Validation) Loss: 1006606.2883, MAE: 3864.3220, R2: 0.1503\n",
      "==========================================================================================\n",
      "Epoch [4490/5000] | Time: 0.31s\n",
      "(Training) Loss: 982224.6586\n",
      "(Validation) Loss: 1006455.8578, MAE: 3863.9331, R2: 0.1504\n",
      "==========================================================================================\n",
      "Epoch [4491/5000] | Time: 0.33s\n",
      "(Training) Loss: 984795.2919\n",
      "(Validation) Loss: 1006235.5962, MAE: 3857.3975, R2: 0.1506\n",
      "==========================================================================================\n",
      "Epoch [4492/5000] | Time: 0.31s\n",
      "(Training) Loss: 975967.8312\n",
      "(Validation) Loss: 1006143.6698, MAE: 3866.0388, R2: 0.1507\n",
      "==========================================================================================\n",
      "Epoch [4493/5000] | Time: 0.32s\n",
      "(Training) Loss: 988482.0692\n",
      "(Validation) Loss: 1005891.1898, MAE: 3855.8555, R2: 0.1509\n",
      "==========================================================================================\n",
      "Epoch [4494/5000] | Time: 0.30s\n",
      "(Training) Loss: 973906.8261\n",
      "(Validation) Loss: 1005762.9917, MAE: 3857.2385, R2: 0.1510\n",
      "==========================================================================================\n",
      "Epoch [4495/5000] | Time: 0.30s\n",
      "(Training) Loss: 974869.5216\n",
      "(Validation) Loss: 998807.5429, MAE: 3849.6113, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [4496/5000] | Time: 0.31s\n",
      "(Training) Loss: 961304.9645\n",
      "(Validation) Loss: 998631.1010, MAE: 3836.1184, R2: 0.1570\n",
      "==========================================================================================\n",
      "Epoch [4497/5000] | Time: 0.31s\n",
      "(Training) Loss: 968367.3065\n",
      "(Validation) Loss: 998487.1314, MAE: 3834.4004, R2: 0.1571\n",
      "==========================================================================================\n",
      "Epoch [4498/5000] | Time: 0.36s\n",
      "(Training) Loss: 962700.3484\n",
      "(Validation) Loss: 998342.1714, MAE: 3833.4453, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [4499/5000] | Time: 0.35s\n",
      "(Training) Loss: 964960.2868\n",
      "(Validation) Loss: 998199.7206, MAE: 3832.4944, R2: 0.1573\n",
      "==========================================================================================\n",
      "Epoch [4500/5000] | Time: 0.35s\n",
      "(Training) Loss: 970573.3201\n",
      "(Validation) Loss: 998079.6648, MAE: 3836.2434, R2: 0.1574\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch4500.pth\n",
      "==========================================================================================\n",
      "Epoch [4501/5000] | Time: 0.32s\n",
      "(Training) Loss: 975235.3769\n",
      "(Validation) Loss: 997915.5657, MAE: 3831.4812, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [4502/5000] | Time: 0.27s\n",
      "(Training) Loss: 981840.0660\n",
      "(Validation) Loss: 997778.2908, MAE: 3832.7534, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [4503/5000] | Time: 0.34s\n",
      "(Training) Loss: 955849.7568\n",
      "(Validation) Loss: 997636.8305, MAE: 3832.1914, R2: 0.1578\n",
      "==========================================================================================\n",
      "Epoch [4504/5000] | Time: 0.30s\n",
      "(Training) Loss: 961190.8115\n",
      "(Validation) Loss: 997489.2292, MAE: 3829.3459, R2: 0.1579\n",
      "==========================================================================================\n",
      "Epoch [4505/5000] | Time: 0.32s\n",
      "(Training) Loss: 964117.5082\n",
      "(Validation) Loss: 997355.7333, MAE: 3830.8911, R2: 0.1580\n",
      "==========================================================================================\n",
      "Epoch [4506/5000] | Time: 0.32s\n",
      "(Training) Loss: 974434.6555\n",
      "(Validation) Loss: 997217.4578, MAE: 3831.0955, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [4507/5000] | Time: 0.32s\n",
      "(Training) Loss: 967241.1983\n",
      "(Validation) Loss: 997067.9416, MAE: 3830.4072, R2: 0.1583\n",
      "==========================================================================================\n",
      "Epoch [4508/5000] | Time: 0.34s\n",
      "(Training) Loss: 968812.7982\n",
      "(Validation) Loss: 996930.0876, MAE: 3832.9353, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [4509/5000] | Time: 0.36s\n",
      "(Training) Loss: 978026.4486\n",
      "(Validation) Loss: 996780.3479, MAE: 3827.1162, R2: 0.1585\n",
      "==========================================================================================\n",
      "Epoch [4510/5000] | Time: 0.36s\n",
      "(Training) Loss: 970834.4454\n",
      "(Validation) Loss: 996639.7917, MAE: 3827.9119, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [4511/5000] | Time: 0.32s\n",
      "(Training) Loss: 969563.3687\n",
      "(Validation) Loss: 996497.8337, MAE: 3828.3660, R2: 0.1587\n",
      "==========================================================================================\n",
      "Epoch [4512/5000] | Time: 0.38s\n",
      "(Training) Loss: 969533.8166\n",
      "(Validation) Loss: 996354.0114, MAE: 3826.8672, R2: 0.1589\n",
      "==========================================================================================\n",
      "Epoch [4513/5000] | Time: 0.32s\n",
      "(Training) Loss: 966821.9372\n",
      "(Validation) Loss: 996214.9384, MAE: 3827.5012, R2: 0.1590\n",
      "==========================================================================================\n",
      "Epoch [4514/5000] | Time: 0.28s\n",
      "(Training) Loss: 979071.3119\n",
      "(Validation) Loss: 996076.4597, MAE: 3826.9321, R2: 0.1591\n",
      "==========================================================================================\n",
      "Epoch [4515/5000] | Time: 0.27s\n",
      "(Training) Loss: 980133.1745\n",
      "(Validation) Loss: 995923.2813, MAE: 3824.6938, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [4516/5000] | Time: 0.22s\n",
      "(Training) Loss: 953937.0866\n",
      "(Validation) Loss: 995781.2267, MAE: 3824.9495, R2: 0.1593\n",
      "==========================================================================================\n",
      "Epoch [4517/5000] | Time: 0.24s\n",
      "(Training) Loss: 963659.4099\n",
      "(Validation) Loss: 995649.7524, MAE: 3825.8406, R2: 0.1595\n",
      "==========================================================================================\n",
      "Epoch [4518/5000] | Time: 0.24s\n",
      "(Training) Loss: 958792.3306\n",
      "(Validation) Loss: 995507.5759, MAE: 3826.3721, R2: 0.1596\n",
      "==========================================================================================\n",
      "Epoch [4519/5000] | Time: 0.22s\n",
      "(Training) Loss: 967487.1916\n",
      "(Validation) Loss: 995357.0387, MAE: 3821.5769, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [4520/5000] | Time: 0.28s\n",
      "(Training) Loss: 960797.7157\n",
      "(Validation) Loss: 995212.8863, MAE: 3820.2209, R2: 0.1598\n",
      "==========================================================================================\n",
      "Epoch [4521/5000] | Time: 0.28s\n",
      "(Training) Loss: 993470.8940\n",
      "(Validation) Loss: 995071.2686, MAE: 3818.3372, R2: 0.1599\n",
      "==========================================================================================\n",
      "Epoch [4522/5000] | Time: 0.28s\n",
      "(Training) Loss: 962086.4467\n",
      "(Validation) Loss: 994929.0971, MAE: 3820.0308, R2: 0.1601\n",
      "==========================================================================================\n",
      "Epoch [4523/5000] | Time: 0.25s\n",
      "(Training) Loss: 965668.4854\n",
      "(Validation) Loss: 994789.2825, MAE: 3819.6367, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [4524/5000] | Time: 0.29s\n",
      "(Training) Loss: 976581.0470\n",
      "(Validation) Loss: 994642.7276, MAE: 3819.4951, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [4525/5000] | Time: 0.32s\n",
      "(Training) Loss: 966122.7551\n",
      "(Validation) Loss: 994506.9867, MAE: 3818.9558, R2: 0.1604\n",
      "==========================================================================================\n",
      "Epoch [4526/5000] | Time: 0.29s\n",
      "(Training) Loss: 984095.5089\n",
      "(Validation) Loss: 994355.1289, MAE: 3815.5603, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [4527/5000] | Time: 0.29s\n",
      "(Training) Loss: 962276.4499\n",
      "(Validation) Loss: 994218.9410, MAE: 3817.7090, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [4528/5000] | Time: 0.31s\n",
      "(Training) Loss: 969572.1383\n",
      "(Validation) Loss: 994154.6667, MAE: 3829.4387, R2: 0.1607\n",
      "==========================================================================================\n",
      "Epoch [4529/5000] | Time: 0.28s\n",
      "(Training) Loss: 965921.0863\n",
      "(Validation) Loss: 993943.7206, MAE: 3819.6658, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [4530/5000] | Time: 0.25s\n",
      "(Training) Loss: 972937.0057\n",
      "(Validation) Loss: 993794.8444, MAE: 3815.7358, R2: 0.1610\n",
      "==========================================================================================\n",
      "Epoch [4531/5000] | Time: 0.27s\n",
      "(Training) Loss: 975754.1428\n",
      "(Validation) Loss: 993642.9511, MAE: 3813.0017, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [4532/5000] | Time: 0.24s\n",
      "(Training) Loss: 954115.9461\n",
      "(Validation) Loss: 993508.3733, MAE: 3814.3406, R2: 0.1612\n",
      "==========================================================================================\n",
      "Epoch [4533/5000] | Time: 0.24s\n",
      "(Training) Loss: 968316.7043\n",
      "(Validation) Loss: 993361.2343, MAE: 3811.9609, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [4534/5000] | Time: 0.29s\n",
      "(Training) Loss: 983177.5260\n",
      "(Validation) Loss: 993225.7270, MAE: 3814.8364, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [4535/5000] | Time: 0.29s\n",
      "(Training) Loss: 966234.8071\n",
      "(Validation) Loss: 993080.0102, MAE: 3812.3323, R2: 0.1616\n",
      "==========================================================================================\n",
      "Epoch [4536/5000] | Time: 0.30s\n",
      "(Training) Loss: 991835.7094\n",
      "(Validation) Loss: 992939.9822, MAE: 3812.0156, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [4537/5000] | Time: 0.30s\n",
      "(Training) Loss: 983346.8566\n",
      "(Validation) Loss: 992799.3244, MAE: 3812.1614, R2: 0.1618\n",
      "==========================================================================================\n",
      "Epoch [4538/5000] | Time: 0.37s\n",
      "(Training) Loss: 956515.5685\n",
      "(Validation) Loss: 992653.0946, MAE: 3811.2041, R2: 0.1620\n",
      "==========================================================================================\n",
      "Epoch [4539/5000] | Time: 0.37s\n",
      "(Training) Loss: 984081.3388\n",
      "(Validation) Loss: 992516.5867, MAE: 3810.6150, R2: 0.1621\n",
      "==========================================================================================\n",
      "Epoch [4540/5000] | Time: 0.31s\n",
      "(Training) Loss: 958405.0673\n",
      "(Validation) Loss: 992385.2902, MAE: 3815.5688, R2: 0.1622\n",
      "==========================================================================================\n",
      "Epoch [4541/5000] | Time: 0.31s\n",
      "(Training) Loss: 976757.5539\n",
      "(Validation) Loss: 992231.5124, MAE: 3810.8159, R2: 0.1623\n",
      "==========================================================================================\n",
      "Epoch [4542/5000] | Time: 0.27s\n",
      "(Training) Loss: 953777.6850\n",
      "(Validation) Loss: 992088.2032, MAE: 3809.8257, R2: 0.1624\n",
      "==========================================================================================\n",
      "Epoch [4543/5000] | Time: 0.30s\n",
      "(Training) Loss: 966159.5761\n",
      "(Validation) Loss: 1002609.9251, MAE: 3850.6387, R2: 0.1537\n",
      "==========================================================================================\n",
      "Epoch [4544/5000] | Time: 0.33s\n",
      "(Training) Loss: 960366.1798\n",
      "(Validation) Loss: 1002449.1479, MAE: 3847.2952, R2: 0.1538\n",
      "==========================================================================================\n",
      "Epoch [4545/5000] | Time: 0.30s\n",
      "(Training) Loss: 964438.2157\n",
      "(Validation) Loss: 1002304.7213, MAE: 3849.3838, R2: 0.1539\n",
      "==========================================================================================\n",
      "Epoch [4546/5000] | Time: 0.34s\n",
      "(Training) Loss: 972644.1326\n",
      "(Validation) Loss: 1002156.8254, MAE: 3849.5085, R2: 0.1540\n",
      "==========================================================================================\n",
      "Epoch [4547/5000] | Time: 0.32s\n",
      "(Training) Loss: 974061.5964\n",
      "(Validation) Loss: 999611.3321, MAE: 3836.8108, R2: 0.1562\n",
      "==========================================================================================\n",
      "Epoch [4548/5000] | Time: 0.33s\n",
      "(Training) Loss: 971851.7646\n",
      "(Validation) Loss: 999477.4806, MAE: 3838.0413, R2: 0.1563\n",
      "==========================================================================================\n",
      "Epoch [4549/5000] | Time: 0.32s\n",
      "(Training) Loss: 978592.3999\n",
      "(Validation) Loss: 999348.5308, MAE: 3846.0962, R2: 0.1564\n",
      "==========================================================================================\n",
      "Epoch [4550/5000] | Time: 0.28s\n",
      "(Training) Loss: 973047.6098\n",
      "(Validation) Loss: 999185.8743, MAE: 3839.3423, R2: 0.1565\n",
      "==========================================================================================\n",
      "Epoch [4551/5000] | Time: 0.32s\n",
      "(Training) Loss: 980720.7690\n",
      "(Validation) Loss: 999023.4921, MAE: 3834.9368, R2: 0.1566\n",
      "==========================================================================================\n",
      "Epoch [4552/5000] | Time: 0.28s\n",
      "(Training) Loss: 978823.0876\n",
      "(Validation) Loss: 998880.9448, MAE: 3835.6006, R2: 0.1568\n",
      "==========================================================================================\n",
      "Epoch [4553/5000] | Time: 0.28s\n",
      "(Training) Loss: 961323.4746\n",
      "(Validation) Loss: 998731.6317, MAE: 3833.6809, R2: 0.1569\n",
      "==========================================================================================\n",
      "Epoch [4554/5000] | Time: 0.31s\n",
      "(Training) Loss: 968390.2773\n",
      "(Validation) Loss: 998595.2863, MAE: 3835.3105, R2: 0.1570\n",
      "==========================================================================================\n",
      "Epoch [4555/5000] | Time: 0.38s\n",
      "(Training) Loss: 970460.5092\n",
      "(Validation) Loss: 998448.9905, MAE: 3833.8518, R2: 0.1571\n",
      "==========================================================================================\n",
      "Epoch [4556/5000] | Time: 0.33s\n",
      "(Training) Loss: 958073.8595\n",
      "(Validation) Loss: 998305.2190, MAE: 3834.9172, R2: 0.1572\n",
      "==========================================================================================\n",
      "Epoch [4557/5000] | Time: 0.29s\n",
      "(Training) Loss: 980184.0819\n",
      "(Validation) Loss: 998158.1359, MAE: 3832.3704, R2: 0.1574\n",
      "==========================================================================================\n",
      "Epoch [4558/5000] | Time: 0.28s\n",
      "(Training) Loss: 981968.1567\n",
      "(Validation) Loss: 998006.7098, MAE: 3828.8354, R2: 0.1575\n",
      "==========================================================================================\n",
      "Epoch [4559/5000] | Time: 0.28s\n",
      "(Training) Loss: 958493.1187\n",
      "(Validation) Loss: 997892.1600, MAE: 3838.2043, R2: 0.1576\n",
      "==========================================================================================\n",
      "Epoch [4560/5000] | Time: 0.33s\n",
      "(Training) Loss: 987551.8046\n",
      "(Validation) Loss: 997727.1060, MAE: 3830.5952, R2: 0.1577\n",
      "==========================================================================================\n",
      "Epoch [4561/5000] | Time: 0.33s\n",
      "(Training) Loss: 963332.7069\n",
      "(Validation) Loss: 997580.0533, MAE: 3829.5293, R2: 0.1578\n",
      "==========================================================================================\n",
      "Epoch [4562/5000] | Time: 0.33s\n",
      "(Training) Loss: 956225.7724\n",
      "(Validation) Loss: 997447.1060, MAE: 3830.3931, R2: 0.1580\n",
      "==========================================================================================\n",
      "Epoch [4563/5000] | Time: 0.34s\n",
      "(Training) Loss: 959351.4607\n",
      "(Validation) Loss: 997290.2248, MAE: 3828.4028, R2: 0.1581\n",
      "==========================================================================================\n",
      "Epoch [4564/5000] | Time: 0.29s\n",
      "(Training) Loss: 983640.9321\n",
      "(Validation) Loss: 997149.7295, MAE: 3827.4927, R2: 0.1582\n",
      "==========================================================================================\n",
      "Epoch [4565/5000] | Time: 0.31s\n",
      "(Training) Loss: 974991.4416\n",
      "(Validation) Loss: 997011.0527, MAE: 3828.4580, R2: 0.1583\n",
      "==========================================================================================\n",
      "Epoch [4566/5000] | Time: 0.29s\n",
      "(Training) Loss: 957130.0847\n",
      "(Validation) Loss: 996885.5619, MAE: 3832.8601, R2: 0.1584\n",
      "==========================================================================================\n",
      "Epoch [4567/5000] | Time: 0.28s\n",
      "(Training) Loss: 969030.2912\n",
      "(Validation) Loss: 996723.3829, MAE: 3826.7964, R2: 0.1586\n",
      "==========================================================================================\n",
      "Epoch [4568/5000] | Time: 0.30s\n",
      "(Training) Loss: 968916.0038\n",
      "(Validation) Loss: 996582.8978, MAE: 3827.3892, R2: 0.1587\n",
      "==========================================================================================\n",
      "Epoch [4569/5000] | Time: 0.33s\n",
      "(Training) Loss: 959872.1294\n",
      "(Validation) Loss: 996438.6083, MAE: 3826.9944, R2: 0.1588\n",
      "==========================================================================================\n",
      "Epoch [4570/5000] | Time: 0.26s\n",
      "(Training) Loss: 955463.6929\n",
      "(Validation) Loss: 996299.9975, MAE: 3827.2007, R2: 0.1589\n",
      "==========================================================================================\n",
      "Epoch [4571/5000] | Time: 0.33s\n",
      "(Training) Loss: 960275.9816\n",
      "(Validation) Loss: 996165.2317, MAE: 3827.8608, R2: 0.1590\n",
      "==========================================================================================\n",
      "Epoch [4572/5000] | Time: 0.31s\n",
      "(Training) Loss: 979070.6256\n",
      "(Validation) Loss: 996012.9473, MAE: 3823.8921, R2: 0.1592\n",
      "==========================================================================================\n",
      "Epoch [4573/5000] | Time: 0.35s\n",
      "(Training) Loss: 970021.8439\n",
      "(Validation) Loss: 995864.3606, MAE: 3822.5134, R2: 0.1593\n",
      "==========================================================================================\n",
      "Epoch [4574/5000] | Time: 0.28s\n",
      "(Training) Loss: 996445.6129\n",
      "(Validation) Loss: 995719.1162, MAE: 3820.3665, R2: 0.1594\n",
      "==========================================================================================\n",
      "Epoch [4575/5000] | Time: 0.30s\n",
      "(Training) Loss: 963395.1878\n",
      "(Validation) Loss: 995578.2654, MAE: 3822.4534, R2: 0.1595\n",
      "==========================================================================================\n",
      "Epoch [4576/5000] | Time: 0.28s\n",
      "(Training) Loss: 986441.8344\n",
      "(Validation) Loss: 995430.3238, MAE: 3818.9849, R2: 0.1596\n",
      "==========================================================================================\n",
      "Epoch [4577/5000] | Time: 0.32s\n",
      "(Training) Loss: 986658.3173\n",
      "(Validation) Loss: 995299.2965, MAE: 3822.9993, R2: 0.1597\n",
      "==========================================================================================\n",
      "Epoch [4578/5000] | Time: 0.31s\n",
      "(Training) Loss: 962411.7773\n",
      "(Validation) Loss: 995147.3879, MAE: 3820.4194, R2: 0.1599\n",
      "==========================================================================================\n",
      "Epoch [4579/5000] | Time: 0.36s\n",
      "(Training) Loss: 970644.8312\n",
      "(Validation) Loss: 995001.0565, MAE: 3817.6794, R2: 0.1600\n",
      "==========================================================================================\n",
      "Epoch [4580/5000] | Time: 0.34s\n",
      "(Training) Loss: 954288.5590\n",
      "(Validation) Loss: 1006114.5295, MAE: 3880.9666, R2: 0.1508\n",
      "==========================================================================================\n",
      "Epoch [4581/5000] | Time: 0.34s\n",
      "(Training) Loss: 953780.9126\n",
      "(Validation) Loss: 994714.7276, MAE: 3816.4119, R2: 0.1602\n",
      "==========================================================================================\n",
      "Epoch [4582/5000] | Time: 0.29s\n",
      "(Training) Loss: 973938.2766\n",
      "(Validation) Loss: 994578.7276, MAE: 3815.7759, R2: 0.1603\n",
      "==========================================================================================\n",
      "Epoch [4583/5000] | Time: 0.28s\n",
      "(Training) Loss: 979587.1263\n",
      "(Validation) Loss: 994431.1721, MAE: 3814.7583, R2: 0.1605\n",
      "==========================================================================================\n",
      "Epoch [4584/5000] | Time: 0.30s\n",
      "(Training) Loss: 953992.8468\n",
      "(Validation) Loss: 994300.5867, MAE: 3816.9182, R2: 0.1606\n",
      "==========================================================================================\n",
      "Epoch [4585/5000] | Time: 0.30s\n",
      "(Training) Loss: 965588.5102\n",
      "(Validation) Loss: 994154.8749, MAE: 3815.1985, R2: 0.1607\n",
      "==========================================================================================\n",
      "Epoch [4586/5000] | Time: 0.28s\n",
      "(Training) Loss: 966096.3445\n",
      "(Validation) Loss: 994042.2654, MAE: 3822.6384, R2: 0.1608\n",
      "==========================================================================================\n",
      "Epoch [4587/5000] | Time: 0.28s\n",
      "(Training) Loss: 979148.7011\n",
      "(Validation) Loss: 993872.5435, MAE: 3815.2041, R2: 0.1609\n",
      "==========================================================================================\n",
      "Epoch [4588/5000] | Time: 0.32s\n",
      "(Training) Loss: 956491.8014\n",
      "(Validation) Loss: 993729.7981, MAE: 3815.4231, R2: 0.1611\n",
      "==========================================================================================\n",
      "Epoch [4589/5000] | Time: 0.30s\n",
      "(Training) Loss: 961816.1977\n",
      "(Validation) Loss: 993582.5524, MAE: 3813.1003, R2: 0.1612\n",
      "==========================================================================================\n",
      "Epoch [4590/5000] | Time: 0.30s\n",
      "(Training) Loss: 952330.3488\n",
      "(Validation) Loss: 993450.0724, MAE: 3814.8416, R2: 0.1613\n",
      "==========================================================================================\n",
      "Epoch [4591/5000] | Time: 0.34s\n",
      "(Training) Loss: 976157.2544\n",
      "(Validation) Loss: 993303.0552, MAE: 3811.9548, R2: 0.1614\n",
      "==========================================================================================\n",
      "Epoch [4592/5000] | Time: 0.29s\n",
      "(Training) Loss: 968106.9841\n",
      "(Validation) Loss: 993157.0133, MAE: 3811.2949, R2: 0.1615\n",
      "==========================================================================================\n",
      "Epoch [4593/5000] | Time: 0.29s\n",
      "(Training) Loss: 971725.7138\n",
      "(Validation) Loss: 993010.5651, MAE: 3809.3799, R2: 0.1617\n",
      "==========================================================================================\n",
      "Epoch [4594/5000] | Time: 0.29s\n",
      "(Training) Loss: 968307.9632\n",
      "(Validation) Loss: 990987.5708, MAE: 3801.6587, R2: 0.1633\n",
      "==========================================================================================\n",
      "Epoch [4595/5000] | Time: 0.30s\n",
      "(Training) Loss: 968390.5679\n",
      "(Validation) Loss: 990828.0229, MAE: 3796.3809, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [4596/5000] | Time: 0.31s\n",
      "(Training) Loss: 972442.8255\n",
      "(Validation) Loss: 990780.8356, MAE: 3801.6082, R2: 0.1635\n",
      "==========================================================================================\n",
      "Epoch [4597/5000] | Time: 0.31s\n",
      "(Training) Loss: 949293.0913\n",
      "(Validation) Loss: 990649.7422, MAE: 3803.1140, R2: 0.1636\n",
      "==========================================================================================\n",
      "Epoch [4598/5000] | Time: 0.31s\n",
      "(Training) Loss: 991171.3325\n",
      "(Validation) Loss: 990505.1733, MAE: 3800.0811, R2: 0.1637\n",
      "==========================================================================================\n",
      "Epoch [4599/5000] | Time: 0.30s\n",
      "(Training) Loss: 988830.3661\n",
      "(Validation) Loss: 990364.6984, MAE: 3800.3486, R2: 0.1639\n",
      "==========================================================================================\n",
      "Epoch [4600/5000] | Time: 0.31s\n",
      "(Training) Loss: 954319.1396\n",
      "(Validation) Loss: 982967.9086, MAE: 3778.8191, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [4601/5000] | Time: 0.29s\n",
      "(Training) Loss: 975328.0086\n",
      "(Validation) Loss: 982753.9454, MAE: 3773.1860, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [4602/5000] | Time: 0.29s\n",
      "(Training) Loss: 979982.9074\n",
      "(Validation) Loss: 982625.4171, MAE: 3772.4006, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [4603/5000] | Time: 0.29s\n",
      "(Training) Loss: 944811.0891\n",
      "(Validation) Loss: 982522.1333, MAE: 3774.2498, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [4604/5000] | Time: 0.28s\n",
      "(Training) Loss: 966535.7113\n",
      "(Validation) Loss: 982375.0603, MAE: 3770.9905, R2: 0.1705\n",
      "==========================================================================================\n",
      "Epoch [4605/5000] | Time: 0.30s\n",
      "(Training) Loss: 957548.2354\n",
      "(Validation) Loss: 982242.9206, MAE: 3769.8953, R2: 0.1706\n",
      "==========================================================================================\n",
      "Epoch [4606/5000] | Time: 0.29s\n",
      "(Training) Loss: 962474.0936\n",
      "(Validation) Loss: 982146.3517, MAE: 3775.4473, R2: 0.1707\n",
      "==========================================================================================\n",
      "Epoch [4607/5000] | Time: 0.31s\n",
      "(Training) Loss: 971591.3813\n",
      "(Validation) Loss: 981989.7295, MAE: 3769.8130, R2: 0.1708\n",
      "==========================================================================================\n",
      "Epoch [4608/5000] | Time: 0.35s\n",
      "(Training) Loss: 954487.6678\n",
      "(Validation) Loss: 984352.8635, MAE: 3777.4136, R2: 0.1689\n",
      "==========================================================================================\n",
      "Epoch [4609/5000] | Time: 0.27s\n",
      "(Training) Loss: 970585.1840\n",
      "(Validation) Loss: 984213.9530, MAE: 3779.5708, R2: 0.1690\n",
      "==========================================================================================\n",
      "Epoch [4610/5000] | Time: 0.29s\n",
      "(Training) Loss: 957111.7544\n",
      "(Validation) Loss: 984057.5187, MAE: 3774.4673, R2: 0.1691\n",
      "==========================================================================================\n",
      "Epoch [4611/5000] | Time: 0.30s\n",
      "(Training) Loss: 965558.5006\n",
      "(Validation) Loss: 983927.8730, MAE: 3777.1704, R2: 0.1692\n",
      "==========================================================================================\n",
      "Epoch [4612/5000] | Time: 0.29s\n",
      "(Training) Loss: 943472.5353\n",
      "(Validation) Loss: 983815.0705, MAE: 3781.7197, R2: 0.1693\n",
      "==========================================================================================\n",
      "Epoch [4613/5000] | Time: 0.28s\n",
      "(Training) Loss: 973144.9429\n",
      "(Validation) Loss: 983648.8381, MAE: 3776.8044, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [4614/5000] | Time: 0.32s\n",
      "(Training) Loss: 947034.1104\n",
      "(Validation) Loss: 983558.9587, MAE: 3784.7727, R2: 0.1695\n",
      "==========================================================================================\n",
      "Epoch [4615/5000] | Time: 0.30s\n",
      "(Training) Loss: 974174.4055\n",
      "(Validation) Loss: 983417.8286, MAE: 3778.1016, R2: 0.1697\n",
      "==========================================================================================\n",
      "Epoch [4616/5000] | Time: 0.32s\n",
      "(Training) Loss: 977273.7931\n",
      "(Validation) Loss: 983237.3435, MAE: 3775.5791, R2: 0.1698\n",
      "==========================================================================================\n",
      "Epoch [4617/5000] | Time: 0.30s\n",
      "(Training) Loss: 959678.8674\n",
      "(Validation) Loss: 983123.6470, MAE: 3781.0447, R2: 0.1699\n",
      "==========================================================================================\n",
      "Epoch [4618/5000] | Time: 0.28s\n",
      "(Training) Loss: 956712.1783\n",
      "(Validation) Loss: 982953.2140, MAE: 3773.5730, R2: 0.1700\n",
      "==========================================================================================\n",
      "Epoch [4619/5000] | Time: 0.31s\n",
      "(Training) Loss: 958458.8915\n",
      "(Validation) Loss: 982811.7232, MAE: 3770.8767, R2: 0.1702\n",
      "==========================================================================================\n",
      "Epoch [4620/5000] | Time: 0.28s\n",
      "(Training) Loss: 983375.3890\n",
      "(Validation) Loss: 982668.9676, MAE: 3769.6621, R2: 0.1703\n",
      "==========================================================================================\n",
      "Epoch [4621/5000] | Time: 0.31s\n",
      "(Training) Loss: 942895.2648\n",
      "(Validation) Loss: 982528.2337, MAE: 3768.1082, R2: 0.1704\n",
      "==========================================================================================\n",
      "Epoch [4622/5000] | Time: 0.25s\n",
      "(Training) Loss: 956373.7665\n",
      "(Validation) Loss: 982436.7898, MAE: 3774.8499, R2: 0.1705\n",
      "==========================================================================================\n",
      "Epoch [4623/5000] | Time: 0.30s\n",
      "(Training) Loss: 951136.1732\n",
      "(Validation) Loss: 982264.1473, MAE: 3770.8132, R2: 0.1706\n",
      "==========================================================================================\n",
      "Epoch [4624/5000] | Time: 0.32s\n",
      "(Training) Loss: 945502.2373\n",
      "(Validation) Loss: 982123.6825, MAE: 3768.5737, R2: 0.1707\n",
      "==========================================================================================\n",
      "Epoch [4625/5000] | Time: 0.32s\n",
      "(Training) Loss: 942338.2397\n",
      "(Validation) Loss: 981987.0222, MAE: 3769.0515, R2: 0.1708\n",
      "==========================================================================================\n",
      "Epoch [4626/5000] | Time: 0.32s\n",
      "(Training) Loss: 947390.9055\n",
      "(Validation) Loss: 981876.4749, MAE: 3771.3093, R2: 0.1709\n",
      "==========================================================================================\n",
      "Epoch [4627/5000] | Time: 0.31s\n",
      "(Training) Loss: 960235.7563\n",
      "(Validation) Loss: 981718.4559, MAE: 3766.1399, R2: 0.1711\n",
      "==========================================================================================\n",
      "Epoch [4628/5000] | Time: 0.28s\n",
      "(Training) Loss: 942070.0766\n",
      "(Validation) Loss: 981581.2876, MAE: 3767.0442, R2: 0.1712\n",
      "==========================================================================================\n",
      "Epoch [4629/5000] | Time: 0.28s\n",
      "(Training) Loss: 959629.1701\n",
      "(Validation) Loss: 981442.5346, MAE: 3765.4578, R2: 0.1713\n",
      "==========================================================================================\n",
      "Epoch [4630/5000] | Time: 0.31s\n",
      "(Training) Loss: 944436.7855\n",
      "(Validation) Loss: 981305.9708, MAE: 3765.7893, R2: 0.1714\n",
      "==========================================================================================\n",
      "Epoch [4631/5000] | Time: 0.31s\n",
      "(Training) Loss: 941984.8314\n",
      "(Validation) Loss: 981177.2343, MAE: 3765.6414, R2: 0.1715\n",
      "==========================================================================================\n",
      "Epoch [4632/5000] | Time: 0.30s\n",
      "(Training) Loss: 945679.3433\n",
      "(Validation) Loss: 981041.7778, MAE: 3765.3354, R2: 0.1716\n",
      "==========================================================================================\n",
      "Epoch [4633/5000] | Time: 0.27s\n",
      "(Training) Loss: 970703.1231\n",
      "(Validation) Loss: 980895.1365, MAE: 3763.8340, R2: 0.1718\n",
      "==========================================================================================\n",
      "Epoch [4634/5000] | Time: 0.30s\n",
      "(Training) Loss: 966849.2640\n",
      "(Validation) Loss: 980754.9714, MAE: 3760.8701, R2: 0.1719\n",
      "==========================================================================================\n",
      "Epoch [4635/5000] | Time: 0.32s\n",
      "(Training) Loss: 956154.1846\n",
      "(Validation) Loss: 980618.7022, MAE: 3761.1206, R2: 0.1720\n",
      "==========================================================================================\n",
      "Epoch [4636/5000] | Time: 0.31s\n",
      "(Training) Loss: 957414.7069\n",
      "(Validation) Loss: 980481.4171, MAE: 3760.3318, R2: 0.1721\n",
      "==========================================================================================\n",
      "Epoch [4637/5000] | Time: 0.29s\n",
      "(Training) Loss: 943493.5504\n",
      "(Validation) Loss: 980347.9111, MAE: 3760.7571, R2: 0.1722\n",
      "==========================================================================================\n",
      "Epoch [4638/5000] | Time: 0.30s\n",
      "(Training) Loss: 959418.0590\n",
      "(Validation) Loss: 980223.6698, MAE: 3763.2834, R2: 0.1723\n",
      "==========================================================================================\n",
      "Epoch [4639/5000] | Time: 0.30s\n",
      "(Training) Loss: 945056.9239\n",
      "(Validation) Loss: 980085.3130, MAE: 3764.3406, R2: 0.1724\n",
      "==========================================================================================\n",
      "Epoch [4640/5000] | Time: 0.32s\n",
      "(Training) Loss: 976567.9638\n",
      "(Validation) Loss: 979947.2305, MAE: 3760.9556, R2: 0.1725\n",
      "==========================================================================================\n",
      "Epoch [4641/5000] | Time: 0.30s\n",
      "(Training) Loss: 948691.8680\n",
      "(Validation) Loss: 979803.6927, MAE: 3761.3362, R2: 0.1727\n",
      "==========================================================================================\n",
      "Epoch [4642/5000] | Time: 0.28s\n",
      "(Training) Loss: 953711.9892\n",
      "(Validation) Loss: 979673.6406, MAE: 3759.1394, R2: 0.1728\n",
      "==========================================================================================\n",
      "Epoch [4643/5000] | Time: 0.29s\n",
      "(Training) Loss: 948880.1472\n",
      "(Validation) Loss: 979538.8495, MAE: 3759.9163, R2: 0.1729\n",
      "==========================================================================================\n",
      "Epoch [4644/5000] | Time: 0.29s\n",
      "(Training) Loss: 951010.8173\n",
      "(Validation) Loss: 979407.1263, MAE: 3760.0879, R2: 0.1730\n",
      "==========================================================================================\n",
      "Epoch [4645/5000] | Time: 0.35s\n",
      "(Training) Loss: 948184.3128\n",
      "(Validation) Loss: 979258.0724, MAE: 3757.0371, R2: 0.1731\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4646/5000] | Time: 0.36s\n",
      "(Training) Loss: 963711.6015\n",
      "(Validation) Loss: 979130.7073, MAE: 3758.4817, R2: 0.1732\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4647/5000] | Time: 0.31s\n",
      "(Training) Loss: 940912.3677\n",
      "(Validation) Loss: 978996.7695, MAE: 3758.6975, R2: 0.1733\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4648/5000] | Time: 0.28s\n",
      "(Training) Loss: 947872.3439\n",
      "(Validation) Loss: 978866.4432, MAE: 3757.6409, R2: 0.1735\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4649/5000] | Time: 0.28s\n",
      "(Training) Loss: 951996.7284\n",
      "(Validation) Loss: 978729.8438, MAE: 3758.5400, R2: 0.1736\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4650/5000] | Time: 0.28s\n",
      "(Training) Loss: 950373.6853\n",
      "(Validation) Loss: 978577.0463, MAE: 3753.7422, R2: 0.1737\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4651/5000] | Time: 0.28s\n",
      "(Training) Loss: 955445.4213\n",
      "(Validation) Loss: 978476.5206, MAE: 3759.4653, R2: 0.1738\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4652/5000] | Time: 0.27s\n",
      "(Training) Loss: 937742.1595\n",
      "(Validation) Loss: 978309.2165, MAE: 3755.5381, R2: 0.1739\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4653/5000] | Time: 0.30s\n",
      "(Training) Loss: 963257.8376\n",
      "(Validation) Loss: 978175.6038, MAE: 3754.5361, R2: 0.1740\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4654/5000] | Time: 0.28s\n",
      "(Training) Loss: 954883.8680\n",
      "(Validation) Loss: 978034.5905, MAE: 3752.0461, R2: 0.1741\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4655/5000] | Time: 0.30s\n",
      "(Training) Loss: 969271.8585\n",
      "(Validation) Loss: 977944.1829, MAE: 3765.1023, R2: 0.1742\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4656/5000] | Time: 0.30s\n",
      "(Training) Loss: 940203.1996\n",
      "(Validation) Loss: 977765.8971, MAE: 3752.0208, R2: 0.1744\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4657/5000] | Time: 0.28s\n",
      "(Training) Loss: 950647.4143\n",
      "(Validation) Loss: 977635.6927, MAE: 3752.8333, R2: 0.1745\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4658/5000] | Time: 0.30s\n",
      "(Training) Loss: 952432.7874\n",
      "(Validation) Loss: 968577.5543, MAE: 3722.3120, R2: 0.1820\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4659/5000] | Time: 0.28s\n",
      "(Training) Loss: 929621.0842\n",
      "(Validation) Loss: 968508.9930, MAE: 3726.3672, R2: 0.1821\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4660/5000] | Time: 0.29s\n",
      "(Training) Loss: 947863.2551\n",
      "(Validation) Loss: 968383.4159, MAE: 3730.5652, R2: 0.1822\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4661/5000] | Time: 0.30s\n",
      "(Training) Loss: 936837.5343\n",
      "(Validation) Loss: 968217.3003, MAE: 3724.8352, R2: 0.1823\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4662/5000] | Time: 0.30s\n",
      "(Training) Loss: 936751.0470\n",
      "(Validation) Loss: 968084.8152, MAE: 3726.0864, R2: 0.1824\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4663/5000] | Time: 0.27s\n",
      "(Training) Loss: 941504.6789\n",
      "(Validation) Loss: 967938.7327, MAE: 3723.3010, R2: 0.1826\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4664/5000] | Time: 0.27s\n",
      "(Training) Loss: 930537.4454\n",
      "(Validation) Loss: 967803.9314, MAE: 3724.8149, R2: 0.1827\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4665/5000] | Time: 0.27s\n",
      "(Training) Loss: 928016.6696\n",
      "(Validation) Loss: 967707.8654, MAE: 3733.4165, R2: 0.1827\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4666/5000] | Time: 0.27s\n",
      "(Training) Loss: 951122.3115\n",
      "(Validation) Loss: 967547.7283, MAE: 3728.4438, R2: 0.1829\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4667/5000] | Time: 0.24s\n",
      "(Training) Loss: 945514.5584\n",
      "(Validation) Loss: 967386.2146, MAE: 3722.3940, R2: 0.1830\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4668/5000] | Time: 0.29s\n",
      "(Training) Loss: 938567.7602\n",
      "(Validation) Loss: 967248.5994, MAE: 3721.6555, R2: 0.1831\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4669/5000] | Time: 0.31s\n",
      "(Training) Loss: 937740.7532\n",
      "(Validation) Loss: 967115.1187, MAE: 3722.3252, R2: 0.1832\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4670/5000] | Time: 0.33s\n",
      "(Training) Loss: 943404.7221\n",
      "(Validation) Loss: 966967.4108, MAE: 3720.4280, R2: 0.1834\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4671/5000] | Time: 0.32s\n",
      "(Training) Loss: 937635.7170\n",
      "(Validation) Loss: 966829.9225, MAE: 3721.3542, R2: 0.1835\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4672/5000] | Time: 0.27s\n",
      "(Training) Loss: 952096.6079\n",
      "(Validation) Loss: 966696.7010, MAE: 3719.7942, R2: 0.1836\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4673/5000] | Time: 0.29s\n",
      "(Training) Loss: 931007.3598\n",
      "(Validation) Loss: 966558.5727, MAE: 3719.7778, R2: 0.1837\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4674/5000] | Time: 0.30s\n",
      "(Training) Loss: 950715.7246\n",
      "(Validation) Loss: 966423.9289, MAE: 3720.5083, R2: 0.1838\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4675/5000] | Time: 0.32s\n",
      "(Training) Loss: 939779.1840\n",
      "(Validation) Loss: 966285.0235, MAE: 3720.8899, R2: 0.1839\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4676/5000] | Time: 0.30s\n",
      "(Training) Loss: 940172.6237\n",
      "(Validation) Loss: 966144.4775, MAE: 3721.3931, R2: 0.1841\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4677/5000] | Time: 0.30s\n",
      "(Training) Loss: 932595.2062\n",
      "(Validation) Loss: 966015.4514, MAE: 3723.8350, R2: 0.1842\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4678/5000] | Time: 0.29s\n",
      "(Training) Loss: 936044.5406\n",
      "(Validation) Loss: 965867.1441, MAE: 3717.0361, R2: 0.1843\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4679/5000] | Time: 0.27s\n",
      "(Training) Loss: 935769.1643\n",
      "(Validation) Loss: 965727.6698, MAE: 3716.0212, R2: 0.1844\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4680/5000] | Time: 0.27s\n",
      "(Training) Loss: 927538.2119\n",
      "(Validation) Loss: 965595.1238, MAE: 3715.8521, R2: 0.1845\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4681/5000] | Time: 0.32s\n",
      "(Training) Loss: 930646.1662\n",
      "(Validation) Loss: 965471.6495, MAE: 3718.7048, R2: 0.1846\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4682/5000] | Time: 0.26s\n",
      "(Training) Loss: 937965.8718\n",
      "(Validation) Loss: 965318.6641, MAE: 3713.8005, R2: 0.1847\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4683/5000] | Time: 0.27s\n",
      "(Training) Loss: 947672.6022\n",
      "(Validation) Loss: 965205.6990, MAE: 3719.6807, R2: 0.1848\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4684/5000] | Time: 0.28s\n",
      "(Training) Loss: 935778.8173\n",
      "(Validation) Loss: 965048.6044, MAE: 3714.1870, R2: 0.1850\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4685/5000] | Time: 0.27s\n",
      "(Training) Loss: 944882.2659\n",
      "(Validation) Loss: 964908.3987, MAE: 3713.4749, R2: 0.1851\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4686/5000] | Time: 0.28s\n",
      "(Training) Loss: 933095.3972\n",
      "(Validation) Loss: 964768.6552, MAE: 3712.1934, R2: 0.1852\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4687/5000] | Time: 0.29s\n",
      "(Training) Loss: 939091.6872\n",
      "(Validation) Loss: 964634.7124, MAE: 3712.1514, R2: 0.1853\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4688/5000] | Time: 0.28s\n",
      "(Training) Loss: 946240.3242\n",
      "(Validation) Loss: 964499.1390, MAE: 3713.7642, R2: 0.1854\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4689/5000] | Time: 0.29s\n",
      "(Training) Loss: 940217.9594\n",
      "(Validation) Loss: 964353.9810, MAE: 3710.8687, R2: 0.1855\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4690/5000] | Time: 0.27s\n",
      "(Training) Loss: 945247.1142\n",
      "(Validation) Loss: 964220.7441, MAE: 3716.3354, R2: 0.1857\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4691/5000] | Time: 0.26s\n",
      "(Training) Loss: 956661.5565\n",
      "(Validation) Loss: 964078.4559, MAE: 3709.8870, R2: 0.1858\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4692/5000] | Time: 0.28s\n",
      "(Training) Loss: 950890.4055\n",
      "(Validation) Loss: 963948.9727, MAE: 3709.9099, R2: 0.1859\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4693/5000] | Time: 0.28s\n",
      "(Training) Loss: 940152.6377\n",
      "(Validation) Loss: 963809.4984, MAE: 3709.6733, R2: 0.1860\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4694/5000] | Time: 0.27s\n",
      "(Training) Loss: 935061.3135\n",
      "(Validation) Loss: 963664.8533, MAE: 3707.1848, R2: 0.1861\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4695/5000] | Time: 0.26s\n",
      "(Training) Loss: 948092.3230\n",
      "(Validation) Loss: 963534.5981, MAE: 3709.1257, R2: 0.1862\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4696/5000] | Time: 0.27s\n",
      "(Training) Loss: 928135.2938\n",
      "(Validation) Loss: 963388.9727, MAE: 3705.9929, R2: 0.1863\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4697/5000] | Time: 0.29s\n",
      "(Training) Loss: 931055.0489\n",
      "(Validation) Loss: 963255.5530, MAE: 3705.5032, R2: 0.1865\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4698/5000] | Time: 0.32s\n",
      "(Training) Loss: 941614.6529\n",
      "(Validation) Loss: 963117.2470, MAE: 3708.5403, R2: 0.1866\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4699/5000] | Time: 0.30s\n",
      "(Training) Loss: 942139.4235\n",
      "(Validation) Loss: 962991.6190, MAE: 3708.9585, R2: 0.1867\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4700/5000] | Time: 0.30s\n",
      "(Training) Loss: 923678.6908\n",
      "(Validation) Loss: 962846.4813, MAE: 3705.6321, R2: 0.1868\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4701/5000] | Time: 0.28s\n",
      "(Training) Loss: 932920.6415\n",
      "(Validation) Loss: 962715.9365, MAE: 3706.3618, R2: 0.1869\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4702/5000] | Time: 0.26s\n",
      "(Training) Loss: 952211.2570\n",
      "(Validation) Loss: 962586.8648, MAE: 3707.0022, R2: 0.1870\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4703/5000] | Time: 0.27s\n",
      "(Training) Loss: 937271.8331\n",
      "(Validation) Loss: 962452.0229, MAE: 3706.1997, R2: 0.1871\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4704/5000] | Time: 0.31s\n",
      "(Training) Loss: 949130.8940\n",
      "(Validation) Loss: 962300.6476, MAE: 3702.8923, R2: 0.1873\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4705/5000] | Time: 0.30s\n",
      "(Training) Loss: 947837.7868\n",
      "(Validation) Loss: 962163.8806, MAE: 3702.7217, R2: 0.1874\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4706/5000] | Time: 0.27s\n",
      "(Training) Loss: 944947.2735\n",
      "(Validation) Loss: 961962.6108, MAE: 3697.7258, R2: 0.1875\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4707/5000] | Time: 0.30s\n",
      "(Training) Loss: 930783.4074\n",
      "(Validation) Loss: 961858.9308, MAE: 3702.0498, R2: 0.1876\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4708/5000] | Time: 0.31s\n",
      "(Training) Loss: 945957.0914\n",
      "(Validation) Loss: 961735.7867, MAE: 3702.6079, R2: 0.1877\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4709/5000] | Time: 0.33s\n",
      "(Training) Loss: 930211.4569\n",
      "(Validation) Loss: 961607.2635, MAE: 3704.3340, R2: 0.1878\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4710/5000] | Time: 0.28s\n",
      "(Training) Loss: 944457.1447\n",
      "(Validation) Loss: 961421.3841, MAE: 3699.4321, R2: 0.1880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4711/5000] | Time: 0.31s\n",
      "(Training) Loss: 932194.4023\n",
      "(Validation) Loss: 961362.7886, MAE: 3702.8584, R2: 0.1880\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4712/5000] | Time: 0.28s\n",
      "(Training) Loss: 936444.1234\n",
      "(Validation) Loss: 954613.5060, MAE: 3678.4221, R2: 0.1937\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4713/5000] | Time: 0.33s\n",
      "(Training) Loss: 932361.1942\n",
      "(Validation) Loss: 954485.3079, MAE: 3679.7739, R2: 0.1938\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4714/5000] | Time: 0.26s\n",
      "(Training) Loss: 924244.6796\n",
      "(Validation) Loss: 950009.7930, MAE: 3672.8989, R2: 0.1975\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4715/5000] | Time: 0.28s\n",
      "(Training) Loss: 928338.3261\n",
      "(Validation) Loss: 949872.0000, MAE: 3675.0203, R2: 0.1976\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4716/5000] | Time: 0.26s\n",
      "(Training) Loss: 928526.2602\n",
      "(Validation) Loss: 949722.5752, MAE: 3672.4714, R2: 0.1977\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4717/5000] | Time: 0.29s\n",
      "(Training) Loss: 928011.8395\n",
      "(Validation) Loss: 949581.5975, MAE: 3670.3777, R2: 0.1979\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4718/5000] | Time: 0.28s\n",
      "(Training) Loss: 921479.1225\n",
      "(Validation) Loss: 949443.0679, MAE: 3668.1948, R2: 0.1980\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4719/5000] | Time: 0.28s\n",
      "(Training) Loss: 932440.1497\n",
      "(Validation) Loss: 949306.8190, MAE: 3666.4958, R2: 0.1981\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4720/5000] | Time: 0.26s\n",
      "(Training) Loss: 915299.6910\n",
      "(Validation) Loss: 949174.8571, MAE: 3667.5786, R2: 0.1982\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4721/5000] | Time: 0.27s\n",
      "(Training) Loss: 936846.4898\n",
      "(Validation) Loss: 949043.1949, MAE: 3667.5034, R2: 0.1983\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4722/5000] | Time: 0.26s\n",
      "(Training) Loss: 925384.8464\n",
      "(Validation) Loss: 948908.0533, MAE: 3666.0603, R2: 0.1984\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4723/5000] | Time: 0.31s\n",
      "(Training) Loss: 949713.7240\n",
      "(Validation) Loss: 948773.9581, MAE: 3665.0181, R2: 0.1985\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4724/5000] | Time: 0.28s\n",
      "(Training) Loss: 937245.5006\n",
      "(Validation) Loss: 948644.7898, MAE: 3667.2070, R2: 0.1986\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4725/5000] | Time: 0.29s\n",
      "(Training) Loss: 931942.8731\n",
      "(Validation) Loss: 948506.4127, MAE: 3664.0623, R2: 0.1988\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4726/5000] | Time: 0.29s\n",
      "(Training) Loss: 914241.6180\n",
      "(Validation) Loss: 948384.2083, MAE: 3667.1667, R2: 0.1989\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4727/5000] | Time: 0.29s\n",
      "(Training) Loss: 921318.4549\n",
      "(Validation) Loss: 948248.5689, MAE: 3664.3140, R2: 0.1990\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4728/5000] | Time: 0.29s\n",
      "(Training) Loss: 931498.8141\n",
      "(Validation) Loss: 948126.1562, MAE: 3668.9082, R2: 0.1991\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4729/5000] | Time: 0.26s\n",
      "(Training) Loss: 931971.7253\n",
      "(Validation) Loss: 947985.8844, MAE: 3664.1238, R2: 0.1992\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4730/5000] | Time: 0.27s\n",
      "(Training) Loss: 920793.8687\n",
      "(Validation) Loss: 947856.2743, MAE: 3665.0786, R2: 0.1993\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4731/5000] | Time: 0.28s\n",
      "(Training) Loss: 931568.4734\n",
      "(Validation) Loss: 947718.6844, MAE: 3661.4216, R2: 0.1994\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4732/5000] | Time: 0.27s\n",
      "(Training) Loss: 917901.8845\n",
      "(Validation) Loss: 947589.9683, MAE: 3662.2610, R2: 0.1995\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4733/5000] | Time: 0.30s\n",
      "(Training) Loss: 933040.1307\n",
      "(Validation) Loss: 947462.6895, MAE: 3662.8477, R2: 0.1996\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4734/5000] | Time: 0.29s\n",
      "(Training) Loss: 910774.2621\n",
      "(Validation) Loss: 947328.1524, MAE: 3661.6609, R2: 0.1997\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4735/5000] | Time: 0.28s\n",
      "(Training) Loss: 913899.6282\n",
      "(Validation) Loss: 947198.6032, MAE: 3662.9373, R2: 0.1998\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4736/5000] | Time: 0.29s\n",
      "(Training) Loss: 921830.4181\n",
      "(Validation) Loss: 947064.8990, MAE: 3660.8560, R2: 0.2000\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4737/5000] | Time: 0.27s\n",
      "(Training) Loss: 923829.7284\n",
      "(Validation) Loss: 946928.4419, MAE: 3659.1821, R2: 0.2001\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4738/5000] | Time: 0.29s\n",
      "(Training) Loss: 936815.8052\n",
      "(Validation) Loss: 946802.8444, MAE: 3659.9167, R2: 0.2002\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4739/5000] | Time: 0.29s\n",
      "(Training) Loss: 914847.9765\n",
      "(Validation) Loss: 946665.7473, MAE: 3659.3604, R2: 0.2003\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4740/5000] | Time: 0.29s\n",
      "(Training) Loss: 928742.9036\n",
      "(Validation) Loss: 941667.7994, MAE: 3647.1816, R2: 0.2045\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4741/5000] | Time: 0.28s\n",
      "(Training) Loss: 907494.1935\n",
      "(Validation) Loss: 941546.1943, MAE: 3648.0845, R2: 0.2046\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4742/5000] | Time: 0.27s\n",
      "(Training) Loss: 917983.4181\n",
      "(Validation) Loss: 941405.7194, MAE: 3641.5908, R2: 0.2047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4743/5000] | Time: 0.28s\n",
      "(Training) Loss: 909959.4765\n",
      "(Validation) Loss: 941315.3981, MAE: 3642.3689, R2: 0.2047\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4744/5000] | Time: 0.29s\n",
      "(Training) Loss: 926341.0463\n",
      "(Validation) Loss: 941140.2870, MAE: 3640.9324, R2: 0.2049\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4745/5000] | Time: 0.26s\n",
      "(Training) Loss: 918140.4397\n",
      "(Validation) Loss: 940992.1321, MAE: 3650.6489, R2: 0.2050\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4746/5000] | Time: 0.28s\n",
      "(Training) Loss: 908625.3249\n",
      "(Validation) Loss: 940788.0279, MAE: 3641.0342, R2: 0.2052\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4747/5000] | Time: 0.26s\n",
      "(Training) Loss: 916404.6783\n",
      "(Validation) Loss: 940660.4444, MAE: 3640.3713, R2: 0.2053\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4748/5000] | Time: 0.28s\n",
      "(Training) Loss: 926778.7310\n",
      "(Validation) Loss: 940531.6622, MAE: 3633.8982, R2: 0.2054\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4749/5000] | Time: 0.29s\n",
      "(Training) Loss: 912935.9086\n",
      "(Validation) Loss: 940390.9181, MAE: 3630.5020, R2: 0.2055\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4750/5000] | Time: 0.27s\n",
      "(Training) Loss: 927182.4175\n",
      "(Validation) Loss: 940272.7467, MAE: 3631.5112, R2: 0.2056\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4751/5000] | Time: 0.26s\n",
      "(Training) Loss: 915362.3782\n",
      "(Validation) Loss: 940138.7073, MAE: 3630.5415, R2: 0.2057\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4752/5000] | Time: 0.27s\n",
      "(Training) Loss: 911009.8058\n",
      "(Validation) Loss: 940083.0273, MAE: 3639.0310, R2: 0.2058\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4753/5000] | Time: 0.27s\n",
      "(Training) Loss: 941161.5463\n",
      "(Validation) Loss: 939955.8502, MAE: 3636.1201, R2: 0.2059\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4754/5000] | Time: 0.26s\n",
      "(Training) Loss: 910764.6580\n",
      "(Validation) Loss: 939825.5441, MAE: 3634.9792, R2: 0.2060\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4755/5000] | Time: 0.28s\n",
      "(Training) Loss: 914912.4664\n",
      "(Validation) Loss: 939700.0990, MAE: 3634.1396, R2: 0.2061\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4756/5000] | Time: 0.27s\n",
      "(Training) Loss: 913840.8445\n",
      "(Validation) Loss: 939574.5168, MAE: 3635.3894, R2: 0.2062\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4757/5000] | Time: 0.30s\n",
      "(Training) Loss: 917424.2138\n",
      "(Validation) Loss: 939447.6800, MAE: 3633.6514, R2: 0.2063\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4758/5000] | Time: 0.27s\n",
      "(Training) Loss: 916315.8687\n",
      "(Validation) Loss: 939323.3371, MAE: 3632.9189, R2: 0.2064\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4759/5000] | Time: 0.25s\n",
      "(Training) Loss: 921592.2081\n",
      "(Validation) Loss: 939194.4279, MAE: 3633.0771, R2: 0.2065\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4760/5000] | Time: 0.27s\n",
      "(Training) Loss: 906549.9499\n",
      "(Validation) Loss: 939073.6000, MAE: 3632.9146, R2: 0.2066\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4761/5000] | Time: 0.28s\n",
      "(Training) Loss: 920239.5114\n",
      "(Validation) Loss: 938938.4584, MAE: 3631.0708, R2: 0.2067\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4762/5000] | Time: 0.26s\n",
      "(Training) Loss: 907962.3775\n",
      "(Validation) Loss: 938809.3562, MAE: 3630.6899, R2: 0.2068\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4763/5000] | Time: 0.25s\n",
      "(Training) Loss: 905067.3699\n",
      "(Validation) Loss: 938687.4565, MAE: 3629.7952, R2: 0.2069\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4764/5000] | Time: 0.27s\n",
      "(Training) Loss: 902597.4316\n",
      "(Validation) Loss: 938570.5143, MAE: 3631.5896, R2: 0.2070\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4765/5000] | Time: 0.29s\n",
      "(Training) Loss: 910615.6992\n",
      "(Validation) Loss: 938435.5556, MAE: 3630.5161, R2: 0.2072\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4766/5000] | Time: 0.27s\n",
      "(Training) Loss: 921305.8268\n",
      "(Validation) Loss: 938309.3689, MAE: 3630.1606, R2: 0.2073\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4767/5000] | Time: 0.30s\n",
      "(Training) Loss: 909892.4721\n",
      "(Validation) Loss: 938180.3683, MAE: 3628.3406, R2: 0.2074\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4768/5000] | Time: 0.33s\n",
      "(Training) Loss: 913000.0266\n",
      "(Validation) Loss: 938054.0648, MAE: 3628.0129, R2: 0.2075\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4769/5000] | Time: 0.28s\n",
      "(Training) Loss: 911703.3122\n",
      "(Validation) Loss: 937927.3549, MAE: 3626.9375, R2: 0.2076\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4770/5000] | Time: 0.30s\n",
      "(Training) Loss: 903931.3106\n",
      "(Validation) Loss: 937803.5860, MAE: 3628.5208, R2: 0.2077\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4771/5000] | Time: 0.30s\n",
      "(Training) Loss: 900316.3227\n",
      "(Validation) Loss: 937681.4222, MAE: 3629.8254, R2: 0.2078\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4772/5000] | Time: 0.30s\n",
      "(Training) Loss: 908116.3956\n",
      "(Validation) Loss: 937564.8051, MAE: 3630.8130, R2: 0.2079\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4773/5000] | Time: 0.28s\n",
      "(Training) Loss: 935355.0362\n",
      "(Validation) Loss: 937437.1556, MAE: 3629.4473, R2: 0.2080\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4774/5000] | Time: 0.27s\n",
      "(Training) Loss: 923085.1548\n",
      "(Validation) Loss: 937308.4546, MAE: 3629.4304, R2: 0.2081\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4775/5000] | Time: 0.28s\n",
      "(Training) Loss: 913787.5603\n",
      "(Validation) Loss: 937177.4019, MAE: 3627.6892, R2: 0.2082\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4776/5000] | Time: 0.27s\n",
      "(Training) Loss: 905139.0330\n",
      "(Validation) Loss: 937053.5619, MAE: 3627.7207, R2: 0.2083\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4777/5000] | Time: 0.26s\n",
      "(Training) Loss: 919017.4708\n",
      "(Validation) Loss: 936928.1016, MAE: 3628.6765, R2: 0.2084\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4778/5000] | Time: 0.28s\n",
      "(Training) Loss: 915272.2836\n",
      "(Validation) Loss: 936806.6540, MAE: 3628.1536, R2: 0.2085\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4779/5000] | Time: 0.28s\n",
      "(Training) Loss: 908796.9645\n",
      "(Validation) Loss: 936681.0159, MAE: 3627.5315, R2: 0.2086\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4780/5000] | Time: 0.28s\n",
      "(Training) Loss: 923487.4473\n",
      "(Validation) Loss: 936544.3302, MAE: 3625.6382, R2: 0.2087\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4781/5000] | Time: 0.30s\n",
      "(Training) Loss: 914588.5444\n",
      "(Validation) Loss: 936418.8546, MAE: 3625.5696, R2: 0.2088\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4782/5000] | Time: 0.28s\n",
      "(Training) Loss: 906686.1758\n",
      "(Validation) Loss: 936312.6806, MAE: 3631.1807, R2: 0.2089\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4783/5000] | Time: 0.28s\n",
      "(Training) Loss: 911707.9283\n",
      "(Validation) Loss: 936160.7568, MAE: 3623.0637, R2: 0.2090\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4784/5000] | Time: 0.25s\n",
      "(Training) Loss: 906031.3407\n",
      "(Validation) Loss: 936027.8806, MAE: 3621.9165, R2: 0.2092\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4785/5000] | Time: 0.26s\n",
      "(Training) Loss: 928027.7494\n",
      "(Validation) Loss: 935902.5117, MAE: 3620.8386, R2: 0.2093\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4786/5000] | Time: 0.28s\n",
      "(Training) Loss: 921739.0895\n",
      "(Validation) Loss: 935779.7740, MAE: 3622.6724, R2: 0.2094\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4787/5000] | Time: 0.24s\n",
      "(Training) Loss: 925115.9918\n",
      "(Validation) Loss: 935647.1314, MAE: 3621.3501, R2: 0.2095\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4788/5000] | Time: 0.27s\n",
      "(Training) Loss: 910874.2145\n",
      "(Validation) Loss: 935520.4216, MAE: 3619.0298, R2: 0.2096\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4789/5000] | Time: 0.30s\n",
      "(Training) Loss: 923757.9353\n",
      "(Validation) Loss: 935395.5454, MAE: 3622.7769, R2: 0.2097\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4790/5000] | Time: 0.25s\n",
      "(Training) Loss: 909485.3972\n",
      "(Validation) Loss: 935267.3422, MAE: 3618.3455, R2: 0.2098\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4791/5000] | Time: 0.28s\n",
      "(Training) Loss: 907231.9746\n",
      "(Validation) Loss: 935142.6692, MAE: 3619.0085, R2: 0.2099\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4792/5000] | Time: 0.28s\n",
      "(Training) Loss: 900913.2678\n",
      "(Validation) Loss: 935016.6044, MAE: 3618.7258, R2: 0.2100\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4793/5000] | Time: 0.28s\n",
      "(Training) Loss: 903561.2030\n",
      "(Validation) Loss: 934891.4794, MAE: 3617.4155, R2: 0.2101\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4794/5000] | Time: 0.27s\n",
      "(Training) Loss: 905201.1371\n",
      "(Validation) Loss: 934770.6260, MAE: 3620.2737, R2: 0.2102\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4795/5000] | Time: 0.27s\n",
      "(Training) Loss: 914490.1497\n",
      "(Validation) Loss: 934643.6978, MAE: 3619.6460, R2: 0.2103\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4796/5000] | Time: 0.31s\n",
      "(Training) Loss: 920982.4029\n",
      "(Validation) Loss: 934521.8133, MAE: 3623.7170, R2: 0.2104\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4797/5000] | Time: 0.29s\n",
      "(Training) Loss: 920912.8794\n",
      "(Validation) Loss: 934384.4978, MAE: 3616.3635, R2: 0.2105\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4798/5000] | Time: 0.27s\n",
      "(Training) Loss: 916075.4607\n",
      "(Validation) Loss: 934271.7206, MAE: 3618.2581, R2: 0.2106\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4799/5000] | Time: 0.27s\n",
      "(Training) Loss: 916264.8109\n",
      "(Validation) Loss: 934138.2197, MAE: 3617.1748, R2: 0.2107\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4800/5000] | Time: 0.27s\n",
      "(Training) Loss: 897863.2219\n",
      "(Validation) Loss: 934003.9517, MAE: 3614.7527, R2: 0.2108\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4801/5000] | Time: 0.29s\n",
      "(Training) Loss: 904793.8869\n",
      "(Validation) Loss: 933886.7657, MAE: 3616.0393, R2: 0.2109\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4802/5000] | Time: 0.27s\n",
      "(Training) Loss: 899351.0352\n",
      "(Validation) Loss: 933757.1505, MAE: 3614.5347, R2: 0.2111\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4803/5000] | Time: 0.27s\n",
      "(Training) Loss: 908847.4442\n",
      "(Validation) Loss: 933633.6711, MAE: 3615.0317, R2: 0.2112\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4804/5000] | Time: 0.23s\n",
      "(Training) Loss: 902998.4537\n",
      "(Validation) Loss: 933509.3333, MAE: 3615.7622, R2: 0.2113\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4805/5000] | Time: 0.26s\n",
      "(Training) Loss: 906984.9093\n",
      "(Validation) Loss: 933400.7111, MAE: 3618.4373, R2: 0.2113\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4806/5000] | Time: 0.25s\n",
      "(Training) Loss: 905584.0755\n",
      "(Validation) Loss: 933273.5340, MAE: 3620.8110, R2: 0.2115\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4807/5000] | Time: 0.24s\n",
      "(Training) Loss: 911147.3115\n",
      "(Validation) Loss: 933128.7568, MAE: 3612.9429, R2: 0.2116\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4808/5000] | Time: 0.24s\n",
      "(Training) Loss: 914721.9753\n",
      "(Validation) Loss: 933004.6324, MAE: 3614.1519, R2: 0.2117\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4809/5000] | Time: 0.28s\n",
      "(Training) Loss: 900783.3610\n",
      "(Validation) Loss: 932877.1606, MAE: 3613.1025, R2: 0.2118\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4810/5000] | Time: 0.26s\n",
      "(Training) Loss: 908896.4791\n",
      "(Validation) Loss: 932756.1295, MAE: 3614.8284, R2: 0.2119\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4811/5000] | Time: 0.23s\n",
      "(Training) Loss: 911035.9848\n",
      "(Validation) Loss: 932631.7613, MAE: 3615.3032, R2: 0.2120\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4812/5000] | Time: 0.25s\n",
      "(Training) Loss: 904568.1504\n",
      "(Validation) Loss: 932507.2356, MAE: 3613.8247, R2: 0.2121\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4813/5000] | Time: 0.26s\n",
      "(Training) Loss: 912475.7557\n",
      "(Validation) Loss: 932376.1676, MAE: 3612.4482, R2: 0.2122\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4814/5000] | Time: 0.27s\n",
      "(Training) Loss: 934589.9342\n",
      "(Validation) Loss: 932244.6832, MAE: 3610.8118, R2: 0.2123\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4815/5000] | Time: 0.26s\n",
      "(Training) Loss: 903276.4162\n",
      "(Validation) Loss: 934584.6248, MAE: 3617.2412, R2: 0.2105\n",
      "==========================================================================================\n",
      "Epoch [4816/5000] | Time: 0.27s\n",
      "(Training) Loss: 909100.9864\n",
      "(Validation) Loss: 931989.9378, MAE: 3608.5088, R2: 0.2125\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4817/5000] | Time: 0.25s\n",
      "(Training) Loss: 916586.8991\n",
      "(Validation) Loss: 931867.4844, MAE: 3608.3818, R2: 0.2126\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4818/5000] | Time: 0.27s\n",
      "(Training) Loss: 907853.2671\n",
      "(Validation) Loss: 931739.7130, MAE: 3607.9980, R2: 0.2127\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4819/5000] | Time: 0.25s\n",
      "(Training) Loss: 899435.2966\n",
      "(Validation) Loss: 931617.1124, MAE: 3608.1934, R2: 0.2128\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4820/5000] | Time: 0.25s\n",
      "(Training) Loss: 910800.7582\n",
      "(Validation) Loss: 931494.4051, MAE: 3608.3792, R2: 0.2129\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4821/5000] | Time: 0.28s\n",
      "(Training) Loss: 916843.7722\n",
      "(Validation) Loss: 933057.9098, MAE: 3612.9734, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [4822/5000] | Time: 0.27s\n",
      "(Training) Loss: 901274.4486\n",
      "(Validation) Loss: 932913.5594, MAE: 3612.1423, R2: 0.2118\n",
      "==========================================================================================\n",
      "Epoch [4823/5000] | Time: 0.34s\n",
      "(Training) Loss: 914948.6954\n",
      "(Validation) Loss: 947182.1460, MAE: 3662.1638, R2: 0.1999\n",
      "==========================================================================================\n",
      "Epoch [4824/5000] | Time: 0.27s\n",
      "(Training) Loss: 916522.8591\n",
      "(Validation) Loss: 947100.9930, MAE: 3662.9622, R2: 0.1999\n",
      "==========================================================================================\n",
      "Epoch [4825/5000] | Time: 0.30s\n",
      "(Training) Loss: 917315.1345\n",
      "(Validation) Loss: 946960.2387, MAE: 3660.1223, R2: 0.2000\n",
      "==========================================================================================\n",
      "Epoch [4826/5000] | Time: 0.27s\n",
      "(Training) Loss: 915024.2779\n",
      "(Validation) Loss: 946825.3003, MAE: 3661.1360, R2: 0.2002\n",
      "==========================================================================================\n",
      "Epoch [4827/5000] | Time: 0.29s\n",
      "(Training) Loss: 912476.0102\n",
      "(Validation) Loss: 946689.6102, MAE: 3660.1318, R2: 0.2003\n",
      "==========================================================================================\n",
      "Epoch [4828/5000] | Time: 0.31s\n",
      "(Training) Loss: 928827.2411\n",
      "(Validation) Loss: 946556.8356, MAE: 3659.3289, R2: 0.2004\n",
      "==========================================================================================\n",
      "Epoch [4829/5000] | Time: 0.25s\n",
      "(Training) Loss: 933085.6539\n",
      "(Validation) Loss: 946417.0159, MAE: 3659.5403, R2: 0.2005\n",
      "==========================================================================================\n",
      "Epoch [4830/5000] | Time: 0.29s\n",
      "(Training) Loss: 946278.4549\n",
      "(Validation) Loss: 946285.2724, MAE: 3660.2441, R2: 0.2006\n",
      "==========================================================================================\n",
      "Epoch [4831/5000] | Time: 0.27s\n",
      "(Training) Loss: 928790.8718\n",
      "(Validation) Loss: 946149.6635, MAE: 3660.4094, R2: 0.2007\n",
      "==========================================================================================\n",
      "Epoch [4832/5000] | Time: 0.27s\n",
      "(Training) Loss: 909819.0628\n",
      "(Validation) Loss: 946013.8057, MAE: 3660.5723, R2: 0.2008\n",
      "==========================================================================================\n",
      "Epoch [4833/5000] | Time: 0.27s\n",
      "(Training) Loss: 947751.0857\n",
      "(Validation) Loss: 945879.9644, MAE: 3659.1240, R2: 0.2009\n",
      "==========================================================================================\n",
      "Epoch [4834/5000] | Time: 0.27s\n",
      "(Training) Loss: 922183.5831\n",
      "(Validation) Loss: 945746.1740, MAE: 3659.7710, R2: 0.2011\n",
      "==========================================================================================\n",
      "Epoch [4835/5000] | Time: 0.26s\n",
      "(Training) Loss: 969889.7081\n",
      "(Validation) Loss: 945616.9092, MAE: 3661.2244, R2: 0.2012\n",
      "==========================================================================================\n",
      "Epoch [4836/5000] | Time: 0.27s\n",
      "(Training) Loss: 921681.1126\n",
      "(Validation) Loss: 945471.8222, MAE: 3657.7380, R2: 0.2013\n",
      "==========================================================================================\n",
      "Epoch [4837/5000] | Time: 0.27s\n",
      "(Training) Loss: 932195.8236\n",
      "(Validation) Loss: 945341.2876, MAE: 3658.6726, R2: 0.2014\n",
      "==========================================================================================\n",
      "Epoch [4838/5000] | Time: 0.29s\n",
      "(Training) Loss: 919744.1872\n",
      "(Validation) Loss: 945212.7949, MAE: 3658.3909, R2: 0.2015\n",
      "==========================================================================================\n",
      "Epoch [4839/5000] | Time: 0.33s\n",
      "(Training) Loss: 916510.8845\n",
      "(Validation) Loss: 945082.3873, MAE: 3659.4619, R2: 0.2016\n",
      "==========================================================================================\n",
      "Epoch [4840/5000] | Time: 0.31s\n",
      "(Training) Loss: 921244.4981\n",
      "(Validation) Loss: 944941.9987, MAE: 3654.6353, R2: 0.2017\n",
      "==========================================================================================\n",
      "Epoch [4841/5000] | Time: 0.32s\n",
      "(Training) Loss: 909133.0076\n",
      "(Validation) Loss: 944811.2457, MAE: 3654.5676, R2: 0.2018\n",
      "==========================================================================================\n",
      "Epoch [4842/5000] | Time: 0.32s\n",
      "(Training) Loss: 906725.8625\n",
      "(Validation) Loss: 944682.8952, MAE: 3654.3901, R2: 0.2019\n",
      "==========================================================================================\n",
      "Epoch [4843/5000] | Time: 0.28s\n",
      "(Training) Loss: 920616.7671\n",
      "(Validation) Loss: 944552.2743, MAE: 3655.2073, R2: 0.2021\n",
      "==========================================================================================\n",
      "Epoch [4844/5000] | Time: 0.30s\n",
      "(Training) Loss: 931062.3192\n",
      "(Validation) Loss: 944424.3403, MAE: 3656.0747, R2: 0.2022\n",
      "==========================================================================================\n",
      "Epoch [4845/5000] | Time: 0.30s\n",
      "(Training) Loss: 919270.7195\n",
      "(Validation) Loss: 944291.1238, MAE: 3654.9082, R2: 0.2023\n",
      "==========================================================================================\n",
      "Epoch [4846/5000] | Time: 0.30s\n",
      "(Training) Loss: 935830.7912\n",
      "(Validation) Loss: 944162.3060, MAE: 3656.0347, R2: 0.2024\n",
      "==========================================================================================\n",
      "Epoch [4847/5000] | Time: 0.28s\n",
      "(Training) Loss: 917561.4695\n",
      "(Validation) Loss: 944025.3003, MAE: 3653.4207, R2: 0.2025\n",
      "==========================================================================================\n",
      "Epoch [4848/5000] | Time: 0.27s\n",
      "(Training) Loss: 907873.0197\n",
      "(Validation) Loss: 943901.6076, MAE: 3656.6218, R2: 0.2026\n",
      "==========================================================================================\n",
      "Epoch [4849/5000] | Time: 0.26s\n",
      "(Training) Loss: 937498.5216\n",
      "(Validation) Loss: 943765.3283, MAE: 3652.8340, R2: 0.2027\n",
      "==========================================================================================\n",
      "Epoch [4850/5000] | Time: 0.26s\n",
      "(Training) Loss: 907924.2195\n",
      "(Validation) Loss: 943631.4311, MAE: 3653.4236, R2: 0.2028\n",
      "==========================================================================================\n",
      "Epoch [4851/5000] | Time: 0.25s\n",
      "(Training) Loss: 921761.6834\n",
      "(Validation) Loss: 943507.0527, MAE: 3654.5156, R2: 0.2029\n",
      "==========================================================================================\n",
      "Epoch [4852/5000] | Time: 0.30s\n",
      "(Training) Loss: 910304.7094\n",
      "(Validation) Loss: 943367.1263, MAE: 3651.7878, R2: 0.2030\n",
      "==========================================================================================\n",
      "Epoch [4853/5000] | Time: 0.24s\n",
      "(Training) Loss: 907309.6523\n",
      "(Validation) Loss: 943235.6216, MAE: 3650.5955, R2: 0.2031\n",
      "==========================================================================================\n",
      "Epoch [4854/5000] | Time: 0.28s\n",
      "(Training) Loss: 935346.0533\n",
      "(Validation) Loss: 943111.3346, MAE: 3651.0627, R2: 0.2033\n",
      "==========================================================================================\n",
      "Epoch [4855/5000] | Time: 0.31s\n",
      "(Training) Loss: 928985.9426\n",
      "(Validation) Loss: 942977.3714, MAE: 3650.4453, R2: 0.2034\n",
      "==========================================================================================\n",
      "Epoch [4856/5000] | Time: 0.23s\n",
      "(Training) Loss: 905469.9116\n",
      "(Validation) Loss: 942842.0267, MAE: 3649.5659, R2: 0.2035\n",
      "==========================================================================================\n",
      "Epoch [4857/5000] | Time: 0.22s\n",
      "(Training) Loss: 919214.7795\n",
      "(Validation) Loss: 942719.9390, MAE: 3649.5215, R2: 0.2036\n",
      "==========================================================================================\n",
      "Epoch [4858/5000] | Time: 0.24s\n",
      "(Training) Loss: 908957.4778\n",
      "(Validation) Loss: 942585.0921, MAE: 3648.2307, R2: 0.2037\n",
      "==========================================================================================\n",
      "Epoch [4859/5000] | Time: 0.25s\n",
      "(Training) Loss: 932309.0178\n",
      "(Validation) Loss: 942468.1448, MAE: 3651.3823, R2: 0.2038\n",
      "==========================================================================================\n",
      "Epoch [4860/5000] | Time: 0.30s\n",
      "(Training) Loss: 919307.8699\n",
      "(Validation) Loss: 942363.9568, MAE: 3655.8813, R2: 0.2039\n",
      "==========================================================================================\n",
      "Epoch [4861/5000] | Time: 0.27s\n",
      "(Training) Loss: 914769.1034\n",
      "(Validation) Loss: 942189.5263, MAE: 3647.6108, R2: 0.2040\n",
      "==========================================================================================\n",
      "Epoch [4862/5000] | Time: 0.23s\n",
      "(Training) Loss: 913765.3452\n",
      "(Validation) Loss: 942063.3752, MAE: 3647.9475, R2: 0.2041\n",
      "==========================================================================================\n",
      "Epoch [4863/5000] | Time: 0.28s\n",
      "(Training) Loss: 908665.4686\n",
      "(Validation) Loss: 941931.4438, MAE: 3646.9248, R2: 0.2042\n",
      "==========================================================================================\n",
      "Epoch [4864/5000] | Time: 0.30s\n",
      "(Training) Loss: 920011.5063\n",
      "(Validation) Loss: 941804.7390, MAE: 3646.1482, R2: 0.2043\n",
      "==========================================================================================\n",
      "Epoch [4865/5000] | Time: 0.28s\n",
      "(Training) Loss: 931619.5273\n",
      "(Validation) Loss: 941673.6152, MAE: 3646.7102, R2: 0.2045\n",
      "==========================================================================================\n",
      "Epoch [4866/5000] | Time: 0.30s\n",
      "(Training) Loss: 927171.2754\n",
      "(Validation) Loss: 941541.3486, MAE: 3646.3799, R2: 0.2046\n",
      "==========================================================================================\n",
      "Epoch [4867/5000] | Time: 0.29s\n",
      "(Training) Loss: 911011.6555\n",
      "(Validation) Loss: 941410.2806, MAE: 3646.0527, R2: 0.2047\n",
      "==========================================================================================\n",
      "Epoch [4868/5000] | Time: 0.29s\n",
      "(Training) Loss: 903893.8823\n",
      "(Validation) Loss: 941281.5949, MAE: 3645.2683, R2: 0.2048\n",
      "==========================================================================================\n",
      "Epoch [4869/5000] | Time: 0.25s\n",
      "(Training) Loss: 910353.9454\n",
      "(Validation) Loss: 941153.6305, MAE: 3645.2131, R2: 0.2049\n",
      "==========================================================================================\n",
      "Epoch [4870/5000] | Time: 0.27s\n",
      "(Training) Loss: 924767.5888\n",
      "(Validation) Loss: 941023.3651, MAE: 3643.5454, R2: 0.2050\n",
      "==========================================================================================\n",
      "Epoch [4871/5000] | Time: 0.29s\n",
      "(Training) Loss: 907355.3648\n",
      "(Validation) Loss: 940887.9441, MAE: 3642.5920, R2: 0.2051\n",
      "==========================================================================================\n",
      "Epoch [4872/5000] | Time: 0.33s\n",
      "(Training) Loss: 913133.1237\n",
      "(Validation) Loss: 940759.6648, MAE: 3642.3423, R2: 0.2052\n",
      "==========================================================================================\n",
      "Epoch [4873/5000] | Time: 0.35s\n",
      "(Training) Loss: 929019.2481\n",
      "(Validation) Loss: 940632.3098, MAE: 3643.7261, R2: 0.2053\n",
      "==========================================================================================\n",
      "Epoch [4874/5000] | Time: 0.31s\n",
      "(Training) Loss: 915088.5590\n",
      "(Validation) Loss: 940500.1346, MAE: 3642.8711, R2: 0.2054\n",
      "==========================================================================================\n",
      "Epoch [4875/5000] | Time: 0.31s\n",
      "(Training) Loss: 906090.8918\n",
      "(Validation) Loss: 940371.2406, MAE: 3642.4333, R2: 0.2055\n",
      "==========================================================================================\n",
      "Epoch [4876/5000] | Time: 0.38s\n",
      "(Training) Loss: 917533.1999\n",
      "(Validation) Loss: 940235.3422, MAE: 3639.4514, R2: 0.2057\n",
      "==========================================================================================\n",
      "Epoch [4877/5000] | Time: 0.33s\n",
      "(Training) Loss: 926394.2671\n",
      "(Validation) Loss: 940113.4324, MAE: 3642.9368, R2: 0.2058\n",
      "==========================================================================================\n",
      "Epoch [4878/5000] | Time: 0.23s\n",
      "(Training) Loss: 914474.9753\n",
      "(Validation) Loss: 939981.6686, MAE: 3640.7344, R2: 0.2059\n",
      "==========================================================================================\n",
      "Epoch [4879/5000] | Time: 0.29s\n",
      "(Training) Loss: 916344.2373\n",
      "(Validation) Loss: 939850.6667, MAE: 3640.2153, R2: 0.2060\n",
      "==========================================================================================\n",
      "Epoch [4880/5000] | Time: 0.29s\n",
      "(Training) Loss: 909848.0457\n",
      "(Validation) Loss: 939717.9429, MAE: 3638.6038, R2: 0.2061\n",
      "==========================================================================================\n",
      "Epoch [4881/5000] | Time: 0.28s\n",
      "(Training) Loss: 927059.8731\n",
      "(Validation) Loss: 939598.5575, MAE: 3641.3159, R2: 0.2062\n",
      "==========================================================================================\n",
      "Epoch [4882/5000] | Time: 0.27s\n",
      "(Training) Loss: 921257.0964\n",
      "(Validation) Loss: 939467.8197, MAE: 3642.5869, R2: 0.2063\n",
      "==========================================================================================\n",
      "Epoch [4883/5000] | Time: 0.28s\n",
      "(Training) Loss: 903856.4486\n",
      "(Validation) Loss: 930461.5111, MAE: 3611.1196, R2: 0.2138\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4884/5000] | Time: 0.30s\n",
      "(Training) Loss: 912518.9169\n",
      "(Validation) Loss: 930326.5168, MAE: 3607.5029, R2: 0.2139\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4885/5000] | Time: 0.30s\n",
      "(Training) Loss: 901235.3750\n",
      "(Validation) Loss: 938626.3213, MAE: 3636.5715, R2: 0.2070\n",
      "==========================================================================================\n",
      "Epoch [4886/5000] | Time: 0.25s\n",
      "(Training) Loss: 914383.2170\n",
      "(Validation) Loss: 938476.2870, MAE: 3633.4771, R2: 0.2071\n",
      "==========================================================================================\n",
      "Epoch [4887/5000] | Time: 0.31s\n",
      "(Training) Loss: 929353.5742\n",
      "(Validation) Loss: 938338.6413, MAE: 3633.5400, R2: 0.2072\n",
      "==========================================================================================\n",
      "Epoch [4888/5000] | Time: 0.26s\n",
      "(Training) Loss: 919849.2589\n",
      "(Validation) Loss: 938195.6063, MAE: 3631.9810, R2: 0.2074\n",
      "==========================================================================================\n",
      "Epoch [4889/5000] | Time: 0.34s\n",
      "(Training) Loss: 910480.4892\n",
      "(Validation) Loss: 938059.3575, MAE: 3633.2471, R2: 0.2075\n",
      "==========================================================================================\n",
      "Epoch [4890/5000] | Time: 0.28s\n",
      "(Training) Loss: 909847.9201\n",
      "(Validation) Loss: 937925.6178, MAE: 3632.4331, R2: 0.2076\n",
      "==========================================================================================\n",
      "Epoch [4891/5000] | Time: 0.26s\n",
      "(Training) Loss: 932534.7291\n",
      "(Validation) Loss: 933331.2305, MAE: 3621.9221, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [4892/5000] | Time: 0.28s\n",
      "(Training) Loss: 918471.9264\n",
      "(Validation) Loss: 935254.4610, MAE: 3625.0271, R2: 0.2098\n",
      "==========================================================================================\n",
      "Epoch [4893/5000] | Time: 0.24s\n",
      "(Training) Loss: 916570.6485\n",
      "(Validation) Loss: 935114.1486, MAE: 3627.8350, R2: 0.2099\n",
      "==========================================================================================\n",
      "Epoch [4894/5000] | Time: 0.27s\n",
      "(Training) Loss: 929822.3845\n",
      "(Validation) Loss: 934974.2375, MAE: 3623.0923, R2: 0.2100\n",
      "==========================================================================================\n",
      "Epoch [4895/5000] | Time: 0.30s\n",
      "(Training) Loss: 909251.9918\n",
      "(Validation) Loss: 934833.2952, MAE: 3623.4207, R2: 0.2102\n",
      "==========================================================================================\n",
      "Epoch [4896/5000] | Time: 0.29s\n",
      "(Training) Loss: 898372.2774\n",
      "(Validation) Loss: 934700.9625, MAE: 3621.7480, R2: 0.2103\n",
      "==========================================================================================\n",
      "Epoch [4897/5000] | Time: 0.30s\n",
      "(Training) Loss: 902644.4797\n",
      "(Validation) Loss: 934567.8730, MAE: 3621.7380, R2: 0.2104\n",
      "==========================================================================================\n",
      "Epoch [4898/5000] | Time: 0.27s\n",
      "(Training) Loss: 918088.6339\n",
      "(Validation) Loss: 934437.4908, MAE: 3621.8574, R2: 0.2105\n",
      "==========================================================================================\n",
      "Epoch [4899/5000] | Time: 0.24s\n",
      "(Training) Loss: 903116.1954\n",
      "(Validation) Loss: 934312.7924, MAE: 3625.2590, R2: 0.2106\n",
      "==========================================================================================\n",
      "Epoch [4900/5000] | Time: 0.31s\n",
      "(Training) Loss: 923649.0260\n",
      "(Validation) Loss: 934165.7854, MAE: 3621.8669, R2: 0.2107\n",
      "==========================================================================================\n",
      "Epoch [4901/5000] | Time: 0.34s\n",
      "(Training) Loss: 915120.7786\n",
      "(Validation) Loss: 934028.0076, MAE: 3620.9121, R2: 0.2108\n",
      "==========================================================================================\n",
      "Epoch [4902/5000] | Time: 0.31s\n",
      "(Training) Loss: 925290.8629\n",
      "(Validation) Loss: 933899.1340, MAE: 3621.2644, R2: 0.2109\n",
      "==========================================================================================\n",
      "Epoch [4903/5000] | Time: 0.30s\n",
      "(Training) Loss: 899087.8782\n",
      "(Validation) Loss: 933764.9371, MAE: 3621.9629, R2: 0.2110\n",
      "==========================================================================================\n",
      "Epoch [4904/5000] | Time: 0.32s\n",
      "(Training) Loss: 899873.2779\n",
      "(Validation) Loss: 933631.2940, MAE: 3621.2974, R2: 0.2112\n",
      "==========================================================================================\n",
      "Epoch [4905/5000] | Time: 0.36s\n",
      "(Training) Loss: 909741.0013\n",
      "(Validation) Loss: 933495.9898, MAE: 3620.0762, R2: 0.2113\n",
      "==========================================================================================\n",
      "Epoch [4906/5000] | Time: 0.23s\n",
      "(Training) Loss: 904443.7297\n",
      "(Validation) Loss: 933367.7206, MAE: 3620.8967, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [4907/5000] | Time: 0.32s\n",
      "(Training) Loss: 911246.0451\n",
      "(Validation) Loss: 933229.4146, MAE: 3617.8066, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [4908/5000] | Time: 0.28s\n",
      "(Training) Loss: 904762.2214\n",
      "(Validation) Loss: 933275.8705, MAE: 3628.1096, R2: 0.2114\n",
      "==========================================================================================\n",
      "Epoch [4909/5000] | Time: 0.27s\n",
      "(Training) Loss: 906691.3553\n",
      "(Validation) Loss: 933143.1721, MAE: 3627.2708, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [4910/5000] | Time: 0.29s\n",
      "(Training) Loss: 896515.1169\n",
      "(Validation) Loss: 933007.9390, MAE: 3627.5315, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [4911/5000] | Time: 0.30s\n",
      "(Training) Loss: 909591.7728\n",
      "(Validation) Loss: 932878.7251, MAE: 3626.7407, R2: 0.2118\n",
      "==========================================================================================\n",
      "Epoch [4912/5000] | Time: 0.28s\n",
      "(Training) Loss: 897912.2065\n",
      "(Validation) Loss: 932744.4571, MAE: 3625.8669, R2: 0.2119\n",
      "==========================================================================================\n",
      "Epoch [4913/5000] | Time: 0.27s\n",
      "(Training) Loss: 905096.0784\n",
      "(Validation) Loss: 932616.8686, MAE: 3627.1741, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [4914/5000] | Time: 0.33s\n",
      "(Training) Loss: 900083.0628\n",
      "(Validation) Loss: 932483.9111, MAE: 3626.6328, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [4915/5000] | Time: 0.22s\n",
      "(Training) Loss: 899003.5508\n",
      "(Validation) Loss: 932361.7168, MAE: 3628.3347, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [4916/5000] | Time: 0.28s\n",
      "(Training) Loss: 895660.6253\n",
      "(Validation) Loss: 932223.5175, MAE: 3626.6077, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [4917/5000] | Time: 0.35s\n",
      "(Training) Loss: 895296.4802\n",
      "(Validation) Loss: 932090.7276, MAE: 3626.6892, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [4918/5000] | Time: 0.26s\n",
      "(Training) Loss: 928645.8566\n",
      "(Validation) Loss: 931953.5137, MAE: 3623.5444, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [4919/5000] | Time: 0.28s\n",
      "(Training) Loss: 915985.6142\n",
      "(Validation) Loss: 931824.3302, MAE: 3624.6301, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [4920/5000] | Time: 0.21s\n",
      "(Training) Loss: 936008.0850\n",
      "(Validation) Loss: 931690.2146, MAE: 3623.2883, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [4921/5000] | Time: 0.31s\n",
      "(Training) Loss: 896080.7132\n",
      "(Validation) Loss: 931552.8635, MAE: 3623.0325, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [4922/5000] | Time: 0.33s\n",
      "(Training) Loss: 911975.6161\n",
      "(Validation) Loss: 931427.5606, MAE: 3623.7051, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [4923/5000] | Time: 0.31s\n",
      "(Training) Loss: 899023.2170\n",
      "(Validation) Loss: 931291.5708, MAE: 3622.5684, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [4924/5000] | Time: 0.22s\n",
      "(Training) Loss: 925004.5279\n",
      "(Validation) Loss: 931165.4806, MAE: 3626.2273, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [4925/5000] | Time: 0.25s\n",
      "(Training) Loss: 919296.0273\n",
      "(Validation) Loss: 931030.0698, MAE: 3623.7175, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [4926/5000] | Time: 0.23s\n",
      "(Training) Loss: 897793.7360\n",
      "(Validation) Loss: 930894.1816, MAE: 3622.0596, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [4927/5000] | Time: 0.31s\n",
      "(Training) Loss: 907420.3585\n",
      "(Validation) Loss: 930762.9816, MAE: 3621.7009, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [4928/5000] | Time: 0.27s\n",
      "(Training) Loss: 920279.4480\n",
      "(Validation) Loss: 930631.5530, MAE: 3620.6550, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [4929/5000] | Time: 0.28s\n",
      "(Training) Loss: 924853.6339\n",
      "(Validation) Loss: 930499.3879, MAE: 3620.3020, R2: 0.2138\n",
      "==========================================================================================\n",
      "Epoch [4930/5000] | Time: 0.34s\n",
      "(Training) Loss: 911865.4816\n",
      "(Validation) Loss: 930390.1663, MAE: 3623.0024, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [4931/5000] | Time: 0.27s\n",
      "(Training) Loss: 905846.0539\n",
      "(Validation) Loss: 930231.1213, MAE: 3619.7915, R2: 0.2140\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4932/5000] | Time: 0.38s\n",
      "(Training) Loss: 898939.6472\n",
      "(Validation) Loss: 930103.9086, MAE: 3619.5095, R2: 0.2141\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4933/5000] | Time: 0.35s\n",
      "(Training) Loss: 902763.2557\n",
      "(Validation) Loss: 929974.2324, MAE: 3618.3813, R2: 0.2142\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4934/5000] | Time: 0.33s\n",
      "(Training) Loss: 901790.1079\n",
      "(Validation) Loss: 929848.0813, MAE: 3619.7961, R2: 0.2143\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4935/5000] | Time: 0.29s\n",
      "(Training) Loss: 909790.1022\n",
      "(Validation) Loss: 929712.5638, MAE: 3617.9526, R2: 0.2144\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4936/5000] | Time: 0.35s\n",
      "(Training) Loss: 900046.3661\n",
      "(Validation) Loss: 929582.2883, MAE: 3617.6938, R2: 0.2145\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4937/5000] | Time: 0.35s\n",
      "(Training) Loss: 923914.0086\n",
      "(Validation) Loss: 929450.8546, MAE: 3617.3538, R2: 0.2146\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4938/5000] | Time: 0.28s\n",
      "(Training) Loss: 895813.3096\n",
      "(Validation) Loss: 929315.4794, MAE: 3618.2512, R2: 0.2148\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4939/5000] | Time: 0.33s\n",
      "(Training) Loss: 913516.4803\n",
      "(Validation) Loss: 929186.2197, MAE: 3617.2334, R2: 0.2149\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4940/5000] | Time: 0.30s\n",
      "(Training) Loss: 903630.3782\n",
      "(Validation) Loss: 929051.5860, MAE: 3615.7615, R2: 0.2150\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4941/5000] | Time: 0.32s\n",
      "(Training) Loss: 899573.9981\n",
      "(Validation) Loss: 928922.0267, MAE: 3615.1912, R2: 0.2151\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4942/5000] | Time: 0.31s\n",
      "(Training) Loss: 901890.2230\n",
      "(Validation) Loss: 928792.8533, MAE: 3614.6360, R2: 0.2152\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4943/5000] | Time: 0.35s\n",
      "(Training) Loss: 902031.5520\n",
      "(Validation) Loss: 928670.2425, MAE: 3617.8457, R2: 0.2153\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4944/5000] | Time: 0.31s\n",
      "(Training) Loss: 928329.8668\n",
      "(Validation) Loss: 928534.9689, MAE: 3615.6423, R2: 0.2154\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4945/5000] | Time: 0.30s\n",
      "(Training) Loss: 899686.8052\n",
      "(Validation) Loss: 928398.6641, MAE: 3615.1641, R2: 0.2155\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4946/5000] | Time: 0.36s\n",
      "(Training) Loss: 898026.4004\n",
      "(Validation) Loss: 928269.1860, MAE: 3614.6289, R2: 0.2156\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4947/5000] | Time: 0.31s\n",
      "(Training) Loss: 900170.8723\n",
      "(Validation) Loss: 928138.9257, MAE: 3614.1978, R2: 0.2157\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4948/5000] | Time: 0.32s\n",
      "(Training) Loss: 902067.8090\n",
      "(Validation) Loss: 928027.0222, MAE: 3617.1396, R2: 0.2158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4949/5000] | Time: 0.33s\n",
      "(Training) Loss: 896476.5006\n",
      "(Validation) Loss: 933170.7378, MAE: 3632.7974, R2: 0.2115\n",
      "==========================================================================================\n",
      "Epoch [4950/5000] | Time: 0.28s\n",
      "(Training) Loss: 913113.8737\n",
      "(Validation) Loss: 933038.9790, MAE: 3630.2407, R2: 0.2116\n",
      "==========================================================================================\n",
      "Epoch [4951/5000] | Time: 0.28s\n",
      "(Training) Loss: 906635.0368\n",
      "(Validation) Loss: 932913.7676, MAE: 3630.8306, R2: 0.2117\n",
      "==========================================================================================\n",
      "Epoch [4952/5000] | Time: 0.24s\n",
      "(Training) Loss: 901003.4188\n",
      "(Validation) Loss: 932785.0667, MAE: 3629.7107, R2: 0.2119\n",
      "==========================================================================================\n",
      "Epoch [4953/5000] | Time: 0.36s\n",
      "(Training) Loss: 914846.5701\n",
      "(Validation) Loss: 932661.3079, MAE: 3630.7805, R2: 0.2120\n",
      "==========================================================================================\n",
      "Epoch [4954/5000] | Time: 0.32s\n",
      "(Training) Loss: 908490.0958\n",
      "(Validation) Loss: 932531.4794, MAE: 3628.8989, R2: 0.2121\n",
      "==========================================================================================\n",
      "Epoch [4955/5000] | Time: 0.27s\n",
      "(Training) Loss: 924645.6003\n",
      "(Validation) Loss: 932408.6756, MAE: 3629.0864, R2: 0.2122\n",
      "==========================================================================================\n",
      "Epoch [4956/5000] | Time: 0.29s\n",
      "(Training) Loss: 900350.3572\n",
      "(Validation) Loss: 932274.9663, MAE: 3628.4304, R2: 0.2123\n",
      "==========================================================================================\n",
      "Epoch [4957/5000] | Time: 0.28s\n",
      "(Training) Loss: 914442.6364\n",
      "(Validation) Loss: 932151.3143, MAE: 3627.0984, R2: 0.2124\n",
      "==========================================================================================\n",
      "Epoch [4958/5000] | Time: 0.29s\n",
      "(Training) Loss: 909754.7957\n",
      "(Validation) Loss: 932024.5384, MAE: 3627.1599, R2: 0.2125\n",
      "==========================================================================================\n",
      "Epoch [4959/5000] | Time: 0.29s\n",
      "(Training) Loss: 907932.2957\n",
      "(Validation) Loss: 931900.1600, MAE: 3628.0901, R2: 0.2126\n",
      "==========================================================================================\n",
      "Epoch [4960/5000] | Time: 0.25s\n",
      "(Training) Loss: 899733.4448\n",
      "(Validation) Loss: 931773.9378, MAE: 3627.2725, R2: 0.2127\n",
      "==========================================================================================\n",
      "Epoch [4961/5000] | Time: 0.26s\n",
      "(Training) Loss: 915833.0571\n",
      "(Validation) Loss: 931644.1295, MAE: 3625.4045, R2: 0.2128\n",
      "==========================================================================================\n",
      "Epoch [4962/5000] | Time: 0.30s\n",
      "(Training) Loss: 914381.7792\n",
      "(Validation) Loss: 931517.0997, MAE: 3624.7610, R2: 0.2129\n",
      "==========================================================================================\n",
      "Epoch [4963/5000] | Time: 0.28s\n",
      "(Training) Loss: 907836.4283\n",
      "(Validation) Loss: 931391.2483, MAE: 3625.5781, R2: 0.2130\n",
      "==========================================================================================\n",
      "Epoch [4964/5000] | Time: 0.23s\n",
      "(Training) Loss: 897722.9918\n",
      "(Validation) Loss: 931265.1683, MAE: 3624.4517, R2: 0.2131\n",
      "==========================================================================================\n",
      "Epoch [4965/5000] | Time: 0.24s\n",
      "(Training) Loss: 918469.6390\n",
      "(Validation) Loss: 931139.1390, MAE: 3624.3022, R2: 0.2132\n",
      "==========================================================================================\n",
      "Epoch [4966/5000] | Time: 0.24s\n",
      "(Training) Loss: 897602.7360\n",
      "(Validation) Loss: 931014.4559, MAE: 3624.3147, R2: 0.2133\n",
      "==========================================================================================\n",
      "Epoch [4967/5000] | Time: 0.26s\n",
      "(Training) Loss: 898460.6478\n",
      "(Validation) Loss: 930887.2025, MAE: 3623.8401, R2: 0.2134\n",
      "==========================================================================================\n",
      "Epoch [4968/5000] | Time: 0.28s\n",
      "(Training) Loss: 903826.6980\n",
      "(Validation) Loss: 930765.0590, MAE: 3623.7654, R2: 0.2135\n",
      "==========================================================================================\n",
      "Epoch [4969/5000] | Time: 0.21s\n",
      "(Training) Loss: 894585.2088\n",
      "(Validation) Loss: 930637.4756, MAE: 3623.5156, R2: 0.2136\n",
      "==========================================================================================\n",
      "Epoch [4970/5000] | Time: 0.25s\n",
      "(Training) Loss: 907767.1009\n",
      "(Validation) Loss: 930519.3549, MAE: 3624.1956, R2: 0.2137\n",
      "==========================================================================================\n",
      "Epoch [4971/5000] | Time: 0.22s\n",
      "(Training) Loss: 899446.0190\n",
      "(Validation) Loss: 930387.6165, MAE: 3622.8118, R2: 0.2139\n",
      "==========================================================================================\n",
      "Epoch [4972/5000] | Time: 0.21s\n",
      "(Training) Loss: 934721.8528\n",
      "(Validation) Loss: 930257.5898, MAE: 3621.6648, R2: 0.2140\n",
      "==========================================================================================\n",
      "Epoch [4973/5000] | Time: 0.23s\n",
      "(Training) Loss: 921003.8020\n",
      "(Validation) Loss: 930134.0089, MAE: 3621.9653, R2: 0.2141\n",
      "==========================================================================================\n",
      "Epoch [4974/5000] | Time: 0.24s\n",
      "(Training) Loss: 924118.7855\n",
      "(Validation) Loss: 930002.9816, MAE: 3619.6907, R2: 0.2142\n",
      "==========================================================================================\n",
      "Epoch [4975/5000] | Time: 0.21s\n",
      "(Training) Loss: 908226.0400\n",
      "(Validation) Loss: 929876.4698, MAE: 3621.1077, R2: 0.2143\n",
      "==========================================================================================\n",
      "Epoch [4976/5000] | Time: 0.30s\n",
      "(Training) Loss: 907683.6409\n",
      "(Validation) Loss: 929749.7295, MAE: 3620.2324, R2: 0.2144\n",
      "==========================================================================================\n",
      "Epoch [4977/5000] | Time: 0.34s\n",
      "(Training) Loss: 909691.2456\n",
      "(Validation) Loss: 929625.9657, MAE: 3619.9663, R2: 0.2145\n",
      "==========================================================================================\n",
      "Epoch [4978/5000] | Time: 0.33s\n",
      "(Training) Loss: 908717.7798\n",
      "(Validation) Loss: 929500.5003, MAE: 3619.8015, R2: 0.2146\n",
      "==========================================================================================\n",
      "Epoch [4979/5000] | Time: 0.27s\n",
      "(Training) Loss: 900745.1758\n",
      "(Validation) Loss: 929375.6597, MAE: 3620.3994, R2: 0.2147\n",
      "==========================================================================================\n",
      "Epoch [4980/5000] | Time: 0.27s\n",
      "(Training) Loss: 906422.1865\n",
      "(Validation) Loss: 929248.4775, MAE: 3619.1648, R2: 0.2148\n",
      "==========================================================================================\n",
      "Epoch [4981/5000] | Time: 0.27s\n",
      "(Training) Loss: 900669.4499\n",
      "(Validation) Loss: 929122.3670, MAE: 3618.7258, R2: 0.2149\n",
      "==========================================================================================\n",
      "Epoch [4982/5000] | Time: 0.25s\n",
      "(Training) Loss: 900377.6174\n",
      "(Validation) Loss: 928998.1054, MAE: 3618.5823, R2: 0.2150\n",
      "==========================================================================================\n",
      "Epoch [4983/5000] | Time: 0.26s\n",
      "(Training) Loss: 900170.4334\n",
      "(Validation) Loss: 928875.0933, MAE: 3619.3411, R2: 0.2151\n",
      "==========================================================================================\n",
      "Epoch [4984/5000] | Time: 0.35s\n",
      "(Training) Loss: 905375.6161\n",
      "(Validation) Loss: 928748.4597, MAE: 3617.0515, R2: 0.2152\n",
      "==========================================================================================\n",
      "Epoch [4985/5000] | Time: 0.23s\n",
      "(Training) Loss: 910225.4334\n",
      "(Validation) Loss: 928622.5016, MAE: 3616.3132, R2: 0.2153\n",
      "==========================================================================================\n",
      "Epoch [4986/5000] | Time: 0.29s\n",
      "(Training) Loss: 901422.9486\n",
      "(Validation) Loss: 928502.7098, MAE: 3617.6382, R2: 0.2154\n",
      "==========================================================================================\n",
      "Epoch [4987/5000] | Time: 0.28s\n",
      "(Training) Loss: 906157.7373\n",
      "(Validation) Loss: 928378.1079, MAE: 3618.0620, R2: 0.2155\n",
      "==========================================================================================\n",
      "Epoch [4988/5000] | Time: 0.29s\n",
      "(Training) Loss: 898556.8928\n",
      "(Validation) Loss: 928246.9892, MAE: 3615.9873, R2: 0.2156\n",
      "==========================================================================================\n",
      "Epoch [4989/5000] | Time: 0.30s\n",
      "(Training) Loss: 903107.3395\n",
      "(Validation) Loss: 928123.3371, MAE: 3616.3140, R2: 0.2157\n",
      "==========================================================================================\n",
      "Epoch [4990/5000] | Time: 0.34s\n",
      "(Training) Loss: 912771.5082\n",
      "(Validation) Loss: 927998.5219, MAE: 3615.8220, R2: 0.2158\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4991/5000] | Time: 0.28s\n",
      "(Training) Loss: 902815.0971\n",
      "(Validation) Loss: 927873.9098, MAE: 3615.8174, R2: 0.2160\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4992/5000] | Time: 0.31s\n",
      "(Training) Loss: 911362.6732\n",
      "(Validation) Loss: 927746.3111, MAE: 3614.3481, R2: 0.2161\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4993/5000] | Time: 0.32s\n",
      "(Training) Loss: 918147.0349\n",
      "(Validation) Loss: 927619.5149, MAE: 3614.0500, R2: 0.2162\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4994/5000] | Time: 0.27s\n",
      "(Training) Loss: 895151.8268\n",
      "(Validation) Loss: 927498.1079, MAE: 3614.2053, R2: 0.2163\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4995/5000] | Time: 0.26s\n",
      "(Training) Loss: 897672.2532\n",
      "(Validation) Loss: 927366.5575, MAE: 3613.0942, R2: 0.2164\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4996/5000] | Time: 0.27s\n",
      "(Training) Loss: 912457.2595\n",
      "(Validation) Loss: 927245.9276, MAE: 3613.4893, R2: 0.2165\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4997/5000] | Time: 0.31s\n",
      "(Training) Loss: 914363.2773\n",
      "(Validation) Loss: 927129.8590, MAE: 3615.8118, R2: 0.2166\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4998/5000] | Time: 0.26s\n",
      "(Training) Loss: 891482.4421\n",
      "(Validation) Loss: 926994.3060, MAE: 3612.9744, R2: 0.2167\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [4999/5000] | Time: 0.26s\n",
      "(Training) Loss: 893331.4699\n",
      "(Validation) Loss: 926870.8622, MAE: 3614.6006, R2: 0.2168\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "==========================================================================================\n",
      "Epoch [5000/5000] | Time: 0.27s\n",
      "(Training) Loss: 922948.1973\n",
      "(Validation) Loss: 926750.4152, MAE: 3613.6870, R2: 0.2169\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_BEST_R2.pth\n",
      "✅ Model saved: saved_models\\CryptoGRU_2025-03-16_20-57-42\\CryptoGRU_epoch5000.pth\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1390000.2125634518,\n",
       "  1372912.942893401,\n",
       "  1383858.975888325,\n",
       "  1386313.6700507614,\n",
       "  1407402.9137055837,\n",
       "  1380637.192893401,\n",
       "  1394004.1967005075,\n",
       "  1402521.0875634518,\n",
       "  1397204.423857868,\n",
       "  1376074.7093908628,\n",
       "  1372981.1802030457,\n",
       "  1399780.4441624365,\n",
       "  1373959.2842639594,\n",
       "  1385133.7055837563,\n",
       "  1405020.2538071065,\n",
       "  1382348.0456852792,\n",
       "  1374058.9124365482,\n",
       "  1398155.4111675126,\n",
       "  1367981.5888324874,\n",
       "  1367921.88071066,\n",
       "  1374171.7360406092,\n",
       "  1396919.109137056,\n",
       "  1417763.052030457,\n",
       "  1376429.3946700508,\n",
       "  1379502.2246192894,\n",
       "  1375520.4194162437,\n",
       "  1370036.9593908628,\n",
       "  1359882.9660532996,\n",
       "  1403071.521573604,\n",
       "  1363520.4365482233,\n",
       "  1375612.361675127,\n",
       "  1373295.5850253806,\n",
       "  1380863.6104060914,\n",
       "  1383416.7829949239,\n",
       "  1376395.5507614212,\n",
       "  1368165.3134517767,\n",
       "  1377616.6395939086,\n",
       "  1389057.8197969543,\n",
       "  1373566.7277918782,\n",
       "  1385580.1269035533,\n",
       "  1380766.2461928935,\n",
       "  1376945.8375634518,\n",
       "  1362950.519035533,\n",
       "  1372928.0996192894,\n",
       "  1364426.1243654822,\n",
       "  1362678.1763959392,\n",
       "  1358566.7817258884,\n",
       "  1385585.9149746194,\n",
       "  1355008.4441624365,\n",
       "  1370897.0139593908,\n",
       "  1372997.6675126904,\n",
       "  1371697.1611675126,\n",
       "  1365153.883248731,\n",
       "  1367314.8705583757,\n",
       "  1375507.668781726,\n",
       "  1365250.5736040608,\n",
       "  1396215.6040609137,\n",
       "  1375088.2664974618,\n",
       "  1367412.5710659898,\n",
       "  1399658.3210659898,\n",
       "  1356105.375,\n",
       "  1359355.752538071,\n",
       "  1400728.9289340102,\n",
       "  1351433.163388325,\n",
       "  1364400.697969543,\n",
       "  1381086.6065989847,\n",
       "  1377453.752538071,\n",
       "  1369955.5672588833,\n",
       "  1356492.6497461929,\n",
       "  1358834.7385786802,\n",
       "  1375968.583756345,\n",
       "  1366742.833756345,\n",
       "  1369968.755076142,\n",
       "  1363531.114213198,\n",
       "  1374840.6611675126,\n",
       "  1360812.5507614212,\n",
       "  1366754.9137055837,\n",
       "  1354860.4746192894,\n",
       "  1357469.062182741,\n",
       "  1387919.4987309645,\n",
       "  1381206.0012690355,\n",
       "  1368736.0406091372,\n",
       "  1357845.1472081218,\n",
       "  1348249.4352791877,\n",
       "  1349057.5279187816,\n",
       "  1349552.932106599,\n",
       "  1389521.4746192894,\n",
       "  1359637.758248731,\n",
       "  1351179.114213198,\n",
       "  1384593.4314720812,\n",
       "  1373219.024111675,\n",
       "  1370361.3629441625,\n",
       "  1351582.75,\n",
       "  1363623.1002538071,\n",
       "  1365774.728426396,\n",
       "  1366004.4276649747,\n",
       "  1362914.7246192894,\n",
       "  1344355.4815989847,\n",
       "  1366607.4657360406,\n",
       "  1341384.918781726,\n",
       "  1346446.5590101522,\n",
       "  1371656.75,\n",
       "  1359914.2411167512,\n",
       "  1355702.0558375635,\n",
       "  1359137.99428934,\n",
       "  1351335.866751269,\n",
       "  1338630.4470177665,\n",
       "  1378563.826142132,\n",
       "  1351618.1421319798,\n",
       "  1356855.1967005075,\n",
       "  1345104.9771573604,\n",
       "  1353349.6065989847,\n",
       "  1350869.8210659898,\n",
       "  1350225.4543147208,\n",
       "  1373356.804568528,\n",
       "  1355125.9720812184,\n",
       "  1357900.2322335024,\n",
       "  1358489.276649746,\n",
       "  1358553.6535532996,\n",
       "  1346215.7791878174,\n",
       "  1344448.7538071065,\n",
       "  1355915.8083756345,\n",
       "  1349015.9568527918,\n",
       "  1345385.6345177665,\n",
       "  1344253.095177665,\n",
       "  1352067.859137056,\n",
       "  1367691.6345177665,\n",
       "  1392000.502538071,\n",
       "  1340634.2398477157,\n",
       "  1359876.9822335024,\n",
       "  1337434.1656091372,\n",
       "  1341829.0431472082,\n",
       "  1337105.6732233502,\n",
       "  1348392.5818527918,\n",
       "  1346860.771573604,\n",
       "  1354833.7906091372,\n",
       "  1336041.3109137055,\n",
       "  1364589.9365482233,\n",
       "  1338515.109137056,\n",
       "  1354849.494923858,\n",
       "  1333826.6395939086,\n",
       "  1339928.975888325,\n",
       "  1368606.5939086294,\n",
       "  1369674.197969543,\n",
       "  1338044.2982233502,\n",
       "  1349378.7398477157,\n",
       "  1369842.3604060914,\n",
       "  1334559.0406091372,\n",
       "  1347921.513324873,\n",
       "  1329508.9003807106,\n",
       "  1343047.1097715737,\n",
       "  1346620.3318527918,\n",
       "  1357509.9098984771,\n",
       "  1338497.6053299492,\n",
       "  1361594.7576142133,\n",
       "  1342352.9695431471,\n",
       "  1377597.0469543147,\n",
       "  1340695.5989847716,\n",
       "  1347562.970177665,\n",
       "  1349213.9670050761,\n",
       "  1339643.8324873096,\n",
       "  1343203.5342639594,\n",
       "  1341816.2461928935,\n",
       "  1356177.5152284263,\n",
       "  1336938.1345177665,\n",
       "  1330208.6967005075,\n",
       "  1333741.5901015229,\n",
       "  1331863.6598984771,\n",
       "  1336956.997461929,\n",
       "  1341334.0710659898,\n",
       "  1332050.6789340102,\n",
       "  1335687.114213198,\n",
       "  1345313.973350254,\n",
       "  1347863.9961928935,\n",
       "  1341350.964467005,\n",
       "  1319773.7350095178,\n",
       "  1323952.1326142133,\n",
       "  1341253.4492385788,\n",
       "  1351039.7322335024,\n",
       "  1321112.1342005075,\n",
       "  1347007.494923858,\n",
       "  1340209.0393401014,\n",
       "  1326512.9593908628,\n",
       "  1346727.964467005,\n",
       "  1336541.9302030457,\n",
       "  1331033.361675127,\n",
       "  1320571.640862944,\n",
       "  1331949.923857868,\n",
       "  1326143.8769035533,\n",
       "  1350150.019035533,\n",
       "  1355813.4289340102,\n",
       "  1336314.9175126904,\n",
       "  1326090.0063451778,\n",
       "  1339058.5862944163,\n",
       "  1331884.081218274,\n",
       "  1343568.9593908628,\n",
       "  1330550.1700507614,\n",
       "  1353400.0926395939,\n",
       "  1349902.173857868,\n",
       "  1325442.6370558375,\n",
       "  1339691.2956852792,\n",
       "  1334638.578680203,\n",
       "  1321789.9200507614,\n",
       "  1325106.8718274112,\n",
       "  1375695.6890862945,\n",
       "  1359553.6472081218,\n",
       "  1330251.4517766498,\n",
       "  1336517.9492385788,\n",
       "  1313006.0701142133,\n",
       "  1336297.7576142133,\n",
       "  1328080.8864213198,\n",
       "  1335356.802030457,\n",
       "  1342013.8781725888,\n",
       "  1330565.9397208123,\n",
       "  1330670.1763959392,\n",
       "  1325055.1002538071,\n",
       "  1340704.752538071,\n",
       "  1320944.1294416243,\n",
       "  1348618.9352791877,\n",
       "  1329642.7842639594,\n",
       "  1318589.3343908628,\n",
       "  1331368.8109137055,\n",
       "  1334986.5926395939,\n",
       "  1315985.0184010153,\n",
       "  1328346.7868020304,\n",
       "  1320760.9441624365,\n",
       "  1354110.3864213198,\n",
       "  1340254.1865482233,\n",
       "  1317942.0862944163,\n",
       "  1318960.4010152284,\n",
       "  1339839.2538071065,\n",
       "  1324128.1522842639,\n",
       "  1336416.788071066,\n",
       "  1342967.364213198,\n",
       "  1320857.2563451778,\n",
       "  1333556.5291878174,\n",
       "  1332010.6472081218,\n",
       "  1333032.1751269035,\n",
       "  1315854.9593908628,\n",
       "  1329894.7538071065,\n",
       "  1326781.6535532996,\n",
       "  1327009.019035533,\n",
       "  1313854.3197969543,\n",
       "  1335513.6351522843,\n",
       "  1325962.654822335,\n",
       "  1341291.3851522843,\n",
       "  1308785.706218274,\n",
       "  1316542.673857868,\n",
       "  1306270.9175126904,\n",
       "  1322865.247461929,\n",
       "  1330869.1852791877,\n",
       "  1310621.1865482233,\n",
       "  1322874.5824873096,\n",
       "  1300286.5047588833,\n",
       "  1316904.9543147208,\n",
       "  1351574.1751269035,\n",
       "  1307606.7893401014,\n",
       "  1308395.961928934,\n",
       "  1326217.7874365482,\n",
       "  1337899.0494923857,\n",
       "  1313944.9835025382,\n",
       "  1301080.9739847716,\n",
       "  1300936.4311548222,\n",
       "  1311094.8788071065,\n",
       "  1318421.140862944,\n",
       "  1299424.7163705584,\n",
       "  1334256.8223350253,\n",
       "  1325098.3946700508,\n",
       "  1306776.2385786802,\n",
       "  1322958.927030457,\n",
       "  1321031.888324873,\n",
       "  1315754.3870558375,\n",
       "  1319901.4263959392,\n",
       "  1307027.3109137055,\n",
       "  1300464.8718274112,\n",
       "  1309988.6256345178,\n",
       "  1326296.8705583757,\n",
       "  1308570.6725888324,\n",
       "  1313419.5774111676,\n",
       "  1303509.9911167512,\n",
       "  1310821.6700507614,\n",
       "  1306465.187817259,\n",
       "  1295527.1056472082,\n",
       "  1313917.5964467004,\n",
       "  1306239.4149746194,\n",
       "  1314124.0964467004,\n",
       "  1317641.9568527918,\n",
       "  1314862.6085025382,\n",
       "  1307268.6395939086,\n",
       "  1296886.883248731,\n",
       "  1310981.8134517767,\n",
       "  1306107.9606598986,\n",
       "  1303006.771573604,\n",
       "  1292029.5701142133,\n",
       "  1303362.0977157361,\n",
       "  1299556.5736040608,\n",
       "  1316498.1154822335,\n",
       "  1319660.116751269,\n",
       "  1331095.7804568529,\n",
       "  1307024.9060913706,\n",
       "  1297892.442893401,\n",
       "  1293668.361675127,\n",
       "  1314341.0659898478,\n",
       "  1299632.687817259,\n",
       "  1294907.692893401,\n",
       "  1321150.8851522843,\n",
       "  1298222.8997461929,\n",
       "  1299911.5291878174,\n",
       "  1321902.1751269035,\n",
       "  1322263.0342639594,\n",
       "  1292429.1706852792,\n",
       "  1308609.1967005075,\n",
       "  1307822.1072335024,\n",
       "  1328661.0723350253,\n",
       "  1289873.7645939086,\n",
       "  1291628.611675127,\n",
       "  1306329.9714467004,\n",
       "  1294421.3743654822,\n",
       "  1294848.8439086294,\n",
       "  1284462.0142766498,\n",
       "  1294873.519035533,\n",
       "  1292088.9670050761,\n",
       "  1293284.3705583757,\n",
       "  1299162.0672588833,\n",
       "  1282931.515862944,\n",
       "  1298585.4156091372,\n",
       "  1318764.7439720812,\n",
       "  1305680.7512690355,\n",
       "  1285158.513324873,\n",
       "  1296368.6078680202,\n",
       "  1302249.9574873096,\n",
       "  1308247.361675127,\n",
       "  1320845.8718274112,\n",
       "  1302225.524111675,\n",
       "  1294419.706218274,\n",
       "  1299116.8819796955,\n",
       "  1335167.3946700508,\n",
       "  1303184.9524111676,\n",
       "  1299420.9257614212,\n",
       "  1301407.252538071,\n",
       "  1279337.0504441625,\n",
       "  1295538.923857868,\n",
       "  1310749.6484771573,\n",
       "  1307325.0085659898,\n",
       "  1312625.0038071065,\n",
       "  1295885.8477157361,\n",
       "  1279279.510469543,\n",
       "  1322068.2055837563,\n",
       "  1281909.505076142,\n",
       "  1300116.6802030457,\n",
       "  1291266.0101522843,\n",
       "  1299772.0088832488,\n",
       "  1285412.3350253806,\n",
       "  1284044.0602791877,\n",
       "  1304115.1338832488,\n",
       "  1305146.4098984771,\n",
       "  1285738.3629441625,\n",
       "  1302743.3553299492,\n",
       "  1285959.541243655,\n",
       "  1297689.7347715737,\n",
       "  1301524.135786802,\n",
       "  1283645.7887055837,\n",
       "  1309512.776649746,\n",
       "  1303994.3921319798,\n",
       "  1284170.052030457,\n",
       "  1320405.345177665,\n",
       "  1280382.1281725888,\n",
       "  1284167.736675127,\n",
       "  1286882.214467005,\n",
       "  1283517.4828680202,\n",
       "  1285965.4314720812,\n",
       "  1287769.8388324874,\n",
       "  1311770.6459390863,\n",
       "  1312209.4314720812,\n",
       "  1296641.3934010153,\n",
       "  1287298.1123096447,\n",
       "  1294641.5317258884,\n",
       "  1275519.25571066,\n",
       "  1288082.0469543147,\n",
       "  1296087.4822335024,\n",
       "  1284197.776649746,\n",
       "  1287646.3210659898,\n",
       "  1298508.6484771573,\n",
       "  1271669.6129441625,\n",
       "  1275762.4352791877,\n",
       "  1282113.1560913706,\n",
       "  1269239.4800126904,\n",
       "  1278450.9086294416,\n",
       "  1276518.2005076143,\n",
       "  1301554.822969543,\n",
       "  1278521.2106598986,\n",
       "  1290996.7322335024,\n",
       "  1275680.56535533,\n",
       "  1298766.244923858,\n",
       "  1279111.6560913706,\n",
       "  1283339.8401015229,\n",
       "  1286663.6484771573,\n",
       "  1286980.4835025382,\n",
       "  1293526.6281725888,\n",
       "  1277754.109137056,\n",
       "  1276978.2220812184,\n",
       "  1281267.8489847716,\n",
       "  1281209.3388324874,\n",
       "  1299444.5114213198,\n",
       "  1288956.4352791877,\n",
       "  1284584.81535533,\n",
       "  1271537.4022842639,\n",
       "  1280695.7195431471,\n",
       "  1276229.9555837563,\n",
       "  1279420.0469543147,\n",
       "  1286973.7626903553,\n",
       "  1288715.4314720812,\n",
       "  1281113.8553299492,\n",
       "  1263321.2319162437,\n",
       "  1272848.8191624365,\n",
       "  1266340.2182741116,\n",
       "  1288058.6681472082,\n",
       "  1267341.6040609137,\n",
       "  1263122.2271573604,\n",
       "  1274627.3578680202,\n",
       "  1266854.1472081218,\n",
       "  1272219.3426395939,\n",
       "  1288637.2779187816,\n",
       "  1273453.2220812184,\n",
       "  1271174.1065989847,\n",
       "  1293354.13071066,\n",
       "  1269733.3236040608,\n",
       "  1269942.046319797,\n",
       "  1262822.484137056,\n",
       "  1267952.4682741116,\n",
       "  1283866.0101522843,\n",
       "  1268915.730964467,\n",
       "  1263390.921319797,\n",
       "  1255876.004600254,\n",
       "  1271382.6649746194,\n",
       "  1273397.9137055837,\n",
       "  1266524.3185279188,\n",
       "  1264414.276649746,\n",
       "  1274523.8997461929,\n",
       "  1253849.1930520304,\n",
       "  1285142.3635786802,\n",
       "  1262939.3895939086,\n",
       "  1269978.3109137055,\n",
       "  1266584.6618020304,\n",
       "  1278592.776649746,\n",
       "  1287313.0926395939,\n",
       "  1258289.4911167512,\n",
       "  1267425.7918781727,\n",
       "  1267439.8946700508,\n",
       "  1267441.2829949239,\n",
       "  1271783.9695431471,\n",
       "  1269738.8489847716,\n",
       "  1258163.345177665,\n",
       "  1271494.5101522843,\n",
       "  1263718.0888324874,\n",
       "  1264095.7779187816,\n",
       "  1259185.1256345178,\n",
       "  1274264.2956852792,\n",
       "  1266778.9302030457,\n",
       "  1251651.3949873096,\n",
       "  1263307.7081218273,\n",
       "  1266043.5114213198,\n",
       "  1248295.9568527918,\n",
       "  1267021.2322335024,\n",
       "  1269049.4251269035,\n",
       "  1255930.692893401,\n",
       "  1262362.138324873,\n",
       "  1261532.133248731,\n",
       "  1260777.611675127,\n",
       "  1266837.8172588833,\n",
       "  1260829.416243655,\n",
       "  1260297.9010152284,\n",
       "  1246309.8202728427,\n",
       "  1269771.6472081218,\n",
       "  1261865.3604060914,\n",
       "  1252858.5456852792,\n",
       "  1265439.3527918782,\n",
       "  1263793.845177665,\n",
       "  1252968.9359137055,\n",
       "  1282326.4505076143,\n",
       "  1251660.785532995,\n",
       "  1268470.6789340102,\n",
       "  1263246.2017766498,\n",
       "  1277187.0329949239,\n",
       "  1280153.80964467,\n",
       "  1272288.7747461929,\n",
       "  1246913.8597715737,\n",
       "  1249321.4352791877,\n",
       "  1276050.3629441625,\n",
       "  1252492.904822335,\n",
       "  1271431.1586294416,\n",
       "  1268915.5272842639,\n",
       "  1255436.9092639594,\n",
       "  1252028.4010152284,\n",
       "  1250295.399111675,\n",
       "  1271741.3248730965,\n",
       "  1263079.945431472,\n",
       "  1240025.3727791877,\n",
       "  1245106.0932741116,\n",
       "  1251789.2131979696,\n",
       "  1280743.5583756345,\n",
       "  1252838.8248730965,\n",
       "  1258045.725888325,\n",
       "  1250178.4670050761,\n",
       "  1248256.9898477157,\n",
       "  1256277.345177665,\n",
       "  1246406.2588832488,\n",
       "  1261215.7043147208,\n",
       "  1258744.0260152284,\n",
       "  1258092.7068527918,\n",
       "  1246772.9263959392,\n",
       "  1270114.75,\n",
       "  1251528.4762055837,\n",
       "  1237335.6732233502,\n",
       "  1258255.526649746,\n",
       "  1260801.2614213198,\n",
       "  1253142.8147208123,\n",
       "  1251212.4574873096,\n",
       "  1254192.285532995,\n",
       "  1261286.1947969543,\n",
       "  1244406.5228426396,\n",
       "  1245310.269035533,\n",
       "  1248563.7950507614,\n",
       "  1247832.0748730965,\n",
       "  1260532.1319796955,\n",
       "  1248412.804568528,\n",
       "  1244193.3502538071,\n",
       "  1238684.5862944163,\n",
       "  1239564.6484771573,\n",
       "  1260282.7944162437,\n",
       "  1245828.9073604061,\n",
       "  1267622.0799492386,\n",
       "  1246775.2804568529,\n",
       "  1257543.394035533,\n",
       "  1264072.8781725888,\n",
       "  1266104.776649746,\n",
       "  1239010.8521573604,\n",
       "  1239785.0939086294,\n",
       "  1249270.3375634518,\n",
       "  1246021.0145939086,\n",
       "  1247300.7005076143,\n",
       "  1250786.984137056,\n",
       "  1231354.2639593908,\n",
       "  1242551.9847715737,\n",
       "  1255852.3109137055,\n",
       "  1240319.9124365482,\n",
       "  1239883.1376903553,\n",
       "  1259638.7918781727,\n",
       "  1234643.095177665,\n",
       "  1264105.964467005,\n",
       "  1270011.8921319798,\n",
       "  1259714.9460659898,\n",
       "  1267497.7918781727,\n",
       "  1254420.2208121826,\n",
       "  1244549.4060913706,\n",
       "  1238809.8819796955,\n",
       "  1252266.3711928935,\n",
       "  1263671.0672588833,\n",
       "  1237690.2055837563,\n",
       "  1233868.8185279188,\n",
       "  1228348.4022842639,\n",
       "  1252363.9175126904,\n",
       "  1235092.0672588833,\n",
       "  1252708.1364213198,\n",
       "  1232773.9822335024,\n",
       "  1231359.3489847716,\n",
       "  1234674.285532995,\n",
       "  1240975.0348984771,\n",
       "  1233994.6535532996,\n",
       "  1251511.4390862945,\n",
       "  1226856.5532994925,\n",
       "  1232690.4631979696,\n",
       "  1222350.9235406092,\n",
       "  1245643.918781726,\n",
       "  1246023.8921319798,\n",
       "  1244161.5926395939,\n",
       "  1248078.3248730965,\n",
       "  1228647.5964467004,\n",
       "  1241291.7664974618,\n",
       "  1228002.8521573604,\n",
       "  1251040.8730964467,\n",
       "  1232385.274111675,\n",
       "  1239510.916243655,\n",
       "  1229661.0196700508,\n",
       "  1270883.4060913706,\n",
       "  1226397.2385786802,\n",
       "  1226194.5736040608,\n",
       "  1243136.5824873096,\n",
       "  1246850.6395939086,\n",
       "  1243083.6700507614,\n",
       "  1235496.7461928935,\n",
       "  1229620.1656091372,\n",
       "  1238676.994923858,\n",
       "  1223440.2823604061,\n",
       "  1248075.883248731,\n",
       "  1267590.7493654822,\n",
       "  1242410.7614213198,\n",
       "  1227134.4860406092,\n",
       "  1227893.896573604,\n",
       "  1241995.7246192894,\n",
       "  1239092.4149746194,\n",
       "  1255445.524111675,\n",
       "  1249055.035532995,\n",
       "  1229448.848350254,\n",
       "  1255010.1763959392,\n",
       "  1240006.7195431471,\n",
       "  1229666.1065989847,\n",
       "  1245447.2195431471,\n",
       "  1240503.3388324874,\n",
       "  1247834.6040609137,\n",
       "  1234356.364213198,\n",
       "  1230884.899111675,\n",
       "  1234799.7322335024,\n",
       "  1231230.9314720812,\n",
       "  1228667.25,\n",
       "  1233281.4739847716,\n",
       "  1226875.25,\n",
       "  1225962.980964467,\n",
       "  1248294.973350254,\n",
       "  1231147.404822335,\n",
       "  1224624.3769035533,\n",
       "  1236809.4961928935,\n",
       "  1214480.5530615482,\n",
       "  1217976.4124365482,\n",
       "  1240202.3274111676,\n",
       "  1241576.0222081218,\n",
       "  1214696.4156091372,\n",
       "  1217277.0939086294,\n",
       "  1255542.8185279188,\n",
       "  1224573.61928934,\n",
       "  1236642.7994923857,\n",
       "  1219159.2112944163,\n",
       "  1219307.7455583757,\n",
       "  1244672.1560913706,\n",
       "  1234169.7246192894,\n",
       "  1240391.4682741116,\n",
       "  1234922.9467005075,\n",
       "  1216171.458756345,\n",
       "  1225034.2043147208,\n",
       "  1218821.4657360406,\n",
       "  1214300.2722081218,\n",
       "  1237194.1535532996,\n",
       "  1215107.4251269035,\n",
       "  1224561.3870558375,\n",
       "  1228227.961928934,\n",
       "  1213819.214467005,\n",
       "  1227013.6085025382,\n",
       "  1228383.4612944163,\n",
       "  1219116.9308375635,\n",
       "  1256635.2112944163,\n",
       "  1229177.4670050761,\n",
       "  1218947.7703045686,\n",
       "  1212933.6097715737,\n",
       "  1220196.0291878174,\n",
       "  1235766.1129441625,\n",
       "  1224847.3058375635,\n",
       "  1226057.9232233502,\n",
       "  1233621.8007614212,\n",
       "  1225936.7182741116,\n",
       "  1227800.502538071,\n",
       "  1229489.9568527918,\n",
       "  1230554.9073604061,\n",
       "  1209978.5509993655,\n",
       "  1235621.1453045686,\n",
       "  1226445.480964467,\n",
       "  1227940.2354060914,\n",
       "  1216971.7829949239,\n",
       "  1241464.2195431471,\n",
       "  1224872.9200507614,\n",
       "  1225147.8654822335,\n",
       "  1257867.671319797,\n",
       "  1222791.9200507614,\n",
       "  1233422.2322335024,\n",
       "  1217704.3331218273,\n",
       "  1234350.7220812184,\n",
       "  1215176.0558375635,\n",
       "  1206674.9601840102,\n",
       "  1214191.526649746,\n",
       "  1238976.4771573604,\n",
       "  1219167.6675126904,\n",
       "  1222474.7538071065,\n",
       "  1228496.7918781727,\n",
       "  1220119.192893401,\n",
       "  1231173.6040609137,\n",
       "  1221860.6789340102,\n",
       "  1227058.4930203045,\n",
       "  1210119.2246192894,\n",
       "  1222003.828680203,\n",
       "  1209404.0431472082,\n",
       "  1208208.4606598986,\n",
       "  1240204.1744923857,\n",
       "  1238616.505076142,\n",
       "  1239790.2614213198,\n",
       "  1212079.1497461929,\n",
       "  1221681.1015228427,\n",
       "  1230783.197969543,\n",
       "  1206064.5755076143,\n",
       "  1233137.8997461929,\n",
       "  1215266.5634517767,\n",
       "  1215041.1598984771,\n",
       "  1247005.7081218273,\n",
       "  1206807.4164022843,\n",
       "  1241121.497461929,\n",
       "  1227270.8972081218,\n",
       "  1226649.5444162437,\n",
       "  1208367.9327411167,\n",
       "  1232460.8934010153,\n",
       "  1213047.649111675,\n",
       "  1204157.3588991116,\n",
       "  1230106.1637055837,\n",
       "  1204156.6004124365,\n",
       "  1208759.0843908628,\n",
       "  1215152.5647208123,\n",
       "  1213673.6694162437,\n",
       "  1207279.4612944163,\n",
       "  1210546.9822335024,\n",
       "  1231456.4568527918,\n",
       "  1210234.3026649747,\n",
       "  1233424.5393401014,\n",
       "  1205596.3851522843,\n",
       "  1221429.0393401014,\n",
       "  1234961.728426396,\n",
       "  1201303.148001269,\n",
       "  1212303.6814720812,\n",
       "  1224354.2753807106,\n",
       "  1204486.0279187816,\n",
       "  1212970.4828680202,\n",
       "  1209692.6814720812,\n",
       "  1222389.390862944,\n",
       "  1205137.8477157361,\n",
       "  1220134.6649746194,\n",
       "  1216251.2131979696,\n",
       "  1232233.8464467004,\n",
       "  1213899.2538071065,\n",
       "  1224063.8737309645,\n",
       "  1237757.1027918782,\n",
       "  1212450.0513959392,\n",
       "  1231809.2131979696,\n",
       "  1222131.2779187816,\n",
       "  1202056.8159898478,\n",
       "  1219077.274111675,\n",
       "  1211699.1751269035,\n",
       "  1235593.2639593908,\n",
       "  1221775.5799492386,\n",
       "  1226672.9359137055,\n",
       "  1203776.9302030457,\n",
       "  1202296.0532994925,\n",
       "  1217595.5456852792,\n",
       "  1207429.038071066,\n",
       "  1223618.68464467,\n",
       "  1226364.3527918782,\n",
       "  1198613.2544416243,\n",
       "  1220589.5006345178,\n",
       "  1207696.7677664976,\n",
       "  1195791.7290609137,\n",
       "  1223303.4149746194,\n",
       "  1210151.1205583757,\n",
       "  1205363.3578680202,\n",
       "  1208947.9289340102,\n",
       "  1211452.6427664976,\n",
       "  1199906.3540609137,\n",
       "  1197088.2823604061,\n",
       "  1192551.9597081218,\n",
       "  1208252.7737944163,\n",
       "  1194870.7024111676,\n",
       "  1211482.5501269035,\n",
       "  1208952.491751269,\n",
       "  1218095.2005076143,\n",
       "  1213206.5101522843,\n",
       "  1202313.4098984771,\n",
       "  1193183.6998730965,\n",
       "  1199338.2335025382,\n",
       "  1198246.2373096447,\n",
       "  1204338.543781726,\n",
       "  1219335.7680837563,\n",
       "  1205595.2944162437,\n",
       "  1209449.3502538071,\n",
       "  1191620.494923858,\n",
       "  1192847.5482233502,\n",
       "  1229288.5279187816,\n",
       "  1192434.1446700508,\n",
       "  1200219.2360406092,\n",
       "  1228884.6782994925,\n",
       "  1200985.956218274,\n",
       "  1193520.5850253806,\n",
       "  1195033.1802030457,\n",
       "  1188375.0317258884,\n",
       "  1199835.9847715737,\n",
       "  1211408.769035533,\n",
       "  1188061.4749365482,\n",
       "  1203602.5926395939,\n",
       "  1195295.4276649747,\n",
       "  1208230.5209390863,\n",
       "  1207036.812182741,\n",
       "  1199240.5304568529,\n",
       "  1192903.0088832488,\n",
       "  1193523.6434010153,\n",
       "  1193913.947969543,\n",
       "  1189103.625,\n",
       "  1184247.1729060914,\n",
       "  1191745.3718274112,\n",
       "  1186574.68464467,\n",
       "  1198854.8527918782,\n",
       "  1193475.2664974618,\n",
       "  1206830.0329949239,\n",
       "  1190734.062182741,\n",
       "  1208356.109137056,\n",
       "  1213153.0228426396,\n",
       "  1203682.464467005,\n",
       "  1196933.7290609137,\n",
       "  1201505.2296954314,\n",
       "  1218577.3343908628,\n",
       "  1188873.4777918782,\n",
       "  1190979.6002538071,\n",
       "  1189023.4631979696,\n",
       "  1214344.6598984771,\n",
       "  1206692.4441624365,\n",
       "  1190335.6015228427,\n",
       "  1222484.2512690355,\n",
       "  1188378.5126903553,\n",
       "  1182430.8267766498,\n",
       "  1205183.7404822335,\n",
       "  1197408.3654822335,\n",
       "  1180362.8263404188,\n",
       "  1200327.872461929,\n",
       "  1200565.3730964467,\n",
       "  1191334.2810913706,\n",
       "  1192605.473350254,\n",
       "  1196241.3388324874,\n",
       "  1181468.0720177665,\n",
       "  1190055.918781726,\n",
       "  1182550.1345177665,\n",
       "  1199908.828680203,\n",
       "  1178794.061072335,\n",
       "  1189803.9435279188,\n",
       "  1189590.3223350253,\n",
       "  1195190.9149746194,\n",
       "  1185681.752538071,\n",
       "  1197143.8565989847,\n",
       "  1202681.864213198,\n",
       "  1187692.5228426396,\n",
       "  1190479.331218274,\n",
       "  1197729.151649746,\n",
       "  1206688.3585025382,\n",
       "  1209417.904822335,\n",
       "  1194148.2487309645,\n",
       "  1181522.6104060914,\n",
       "  1187086.2804568529,\n",
       "  1199547.5793147208,\n",
       "  1180192.7677664976,\n",
       "  1178141.052030457,\n",
       "  1191674.239213198,\n",
       "  1202890.0368020304,\n",
       "  1218226.4251269035,\n",
       "  1190522.3401015229,\n",
       "  1180212.817893401,\n",
       "  1175936.3029822335,\n",
       "  1194744.2068527918,\n",
       "  1209930.1960659898,\n",
       "  1179563.4803299492,\n",
       "  1179556.4505076143,\n",
       "  1205398.6421319798,\n",
       "  1190042.8388324874,\n",
       "  1214358.054568528,\n",
       "  1207323.0926395939,\n",
       "  1179838.5945431471,\n",
       "  1219968.9314720812,\n",
       "  1176486.345177665,\n",
       "  1185886.2208121826,\n",
       "  1192505.6180203045,\n",
       "  1183211.4473350253,\n",
       "  1186896.3876903553,\n",
       "  1212443.5767766498,\n",
       "  1190145.359137056,\n",
       "  1202815.9606598986,\n",
       "  1171317.36928934,\n",
       "  1176532.1085025382,\n",
       "  1193689.785532995,\n",
       "  1178410.7626903553,\n",
       "  1191426.8388324874,\n",
       "  1170946.3972081218,\n",
       "  1183544.173857868,\n",
       "  1182959.937817259,\n",
       "  1177586.5456852792,\n",
       "  1170710.3102791877,\n",
       "  1173590.8331218273,\n",
       "  1196673.896573604,\n",
       "  1184859.6421319798,\n",
       "  1173524.682106599,\n",
       "  1203841.8870558375,\n",
       "  1212691.3388324874,\n",
       "  1165191.2455583757,\n",
       "  1185977.2918781727,\n",
       "  1196593.7461928935,\n",
       "  1172166.640862944,\n",
       "  1165616.5293464467,\n",
       "  1178964.0126903553,\n",
       "  1186048.8565989847,\n",
       "  1203317.0152284263,\n",
       "  1175782.9308375635,\n",
       "  1181394.7335025382,\n",
       "  1173970.5532994925,\n",
       "  1169836.244923858,\n",
       "  1174720.8058375635,\n",
       "  1178602.812182741,\n",
       "  1190221.9898477157,\n",
       "  1199014.703680203,\n",
       "  1170221.013324873,\n",
       "  1172873.6129441625,\n",
       "  1182539.7519035533,\n",
       "  1209288.845177665,\n",
       "  1178392.973350254,\n",
       "  1177505.4232233502,\n",
       "  1166271.326142132,\n",
       "  1167197.4416243655,\n",
       "  1163585.5044416243,\n",
       "  1168407.703680203,\n",
       "  1186528.644035533,\n",
       "  1185483.1478426396,\n",
       "  1203022.2296954314,\n",
       "  1173833.437182741,\n",
       "  1180937.2734771573,\n",
       "  1167422.4435279188,\n",
       "  1168112.0425126904,\n",
       "  1158871.9757296955,\n",
       "  1166929.1649746194,\n",
       "  1159222.6579949239,\n",
       "  1166989.0799492386,\n",
       "  1175213.5406091372,\n",
       "  1159418.605964467,\n",
       "  1163969.9930203045,\n",
       "  1179878.6294416243,\n",
       "  1163589.7373096447,\n",
       "  1168620.8109137055,\n",
       "  1176019.543781726,\n",
       "  1196437.947969543,\n",
       "  1163680.228426396,\n",
       "  1175342.0317258884,\n",
       "  1171646.1154822335,\n",
       "  1174634.6027918782,\n",
       "  1183568.5685279188,\n",
       "  1175493.6053299492,\n",
       "  1174830.1472081218,\n",
       "  1169569.5989847716,\n",
       "  1175433.1567258884,\n",
       "  1178058.4581218273,\n",
       "  1177691.7906091372,\n",
       "  1166872.0901015229,\n",
       "  1163547.2480964467,\n",
       "  1190835.187817259,\n",
       "  1155682.5672588833,\n",
       "  1167363.9022842639,\n",
       "  1179545.8946700508,\n",
       "  1167565.6015228427,\n",
       "  1159531.7975888324,\n",
       "  1169483.7893401014,\n",
       "  1161348.0843908628,\n",
       "  1173074.1434010153,\n",
       "  1159875.1827411167,\n",
       "  1168113.0076142133,\n",
       "  1170603.30964467,\n",
       "  1171016.1986040608,\n",
       "  1180656.6269035533,\n",
       "  1169232.4035532996,\n",
       "  1170789.9441624365,\n",
       "  1162186.8527918782,\n",
       "  1156580.0888324874,\n",
       "  1160752.1732233502,\n",
       "  1175602.9365482233,\n",
       "  1166598.1922588833,\n",
       "  1164960.6833756345,\n",
       "  1166622.2601522843,\n",
       "  1168092.2848984771,\n",
       "  1169361.1700507614,\n",
       "  1166642.7785532996,\n",
       "  1155558.3610406092,\n",
       "  1159622.1700507614,\n",
       "  1146089.5355528237,\n",
       "  1150625.3813451778,\n",
       "  1160912.8565989847,\n",
       "  1168654.524111675,\n",
       "  1159877.9720812184,\n",
       "  1173845.0913705584,\n",
       "  1159325.7956852792,\n",
       "  1176642.3413705584,\n",
       "  1145264.24428934,\n",
       "  1171398.456218274,\n",
       "  1153087.5742385788,\n",
       "  1175492.2956852792,\n",
       "  1157271.9803299492,\n",
       "  1156774.651649746,\n",
       "  1175886.1345177665,\n",
       "  1161261.7296954314,\n",
       "  1160963.5196700508,\n",
       "  1156477.807106599,\n",
       "  1155565.260786802,\n",
       "  1179353.3864213198,\n",
       "  1161402.7354060914,\n",
       "  1183022.1973350253,\n",
       "  1150830.3578680202,\n",
       "  ...],\n",
       " [1439565.3587301588,\n",
       "  1439236.3073015872,\n",
       "  1438906.9053968254,\n",
       "  1438574.0393650793,\n",
       "  1438265.4273015873,\n",
       "  1437966.08,\n",
       "  1437679.354920635,\n",
       "  1437367.8984126984,\n",
       "  1437058.3111111112,\n",
       "  1436744.4266666668,\n",
       "  1436434.0063492064,\n",
       "  1436127.5123809525,\n",
       "  1435825.7625396824,\n",
       "  1435529.1479365078,\n",
       "  1435231.0857142857,\n",
       "  1434937.5034920634,\n",
       "  1434641.0158730159,\n",
       "  1434346.7123809524,\n",
       "  1434053.5974603174,\n",
       "  1433767.2076190477,\n",
       "  1433445.5365079364,\n",
       "  1433147.4082539682,\n",
       "  1432847.9796825396,\n",
       "  1432540.48,\n",
       "  1432245.12,\n",
       "  1431952.060952381,\n",
       "  1431656.7517460317,\n",
       "  1431368.0304761904,\n",
       "  1431078.5726984127,\n",
       "  1430780.5104761904,\n",
       "  1430491.7993650793,\n",
       "  1430200.193015873,\n",
       "  1429908.424126984,\n",
       "  1429615.7714285713,\n",
       "  1429328.62984127,\n",
       "  1429035.5098412698,\n",
       "  1428748.485079365,\n",
       "  1428460.0787301587,\n",
       "  1428165.2266666666,\n",
       "  1427878.8520634922,\n",
       "  1427589.6736507937,\n",
       "  1427301.0996825397,\n",
       "  1427011.073015873,\n",
       "  1426726.1612698413,\n",
       "  1426437.4095238096,\n",
       "  1426151.5276190476,\n",
       "  1425864.4774603175,\n",
       "  1425581.953015873,\n",
       "  1425286.09015873,\n",
       "  1425002.041904762,\n",
       "  1424715.9415873017,\n",
       "  1424433.412063492,\n",
       "  1424143.3244444444,\n",
       "  1423855.608888889,\n",
       "  1423569.2393650794,\n",
       "  1423283.7079365079,\n",
       "  1422996.3377777778,\n",
       "  1422708.9726984126,\n",
       "  1422422.9587301586,\n",
       "  1422139.575873016,\n",
       "  1421845.9936507936,\n",
       "  1421563.7993650793,\n",
       "  1421282.0571428572,\n",
       "  1420989.754920635,\n",
       "  1420711.37015873,\n",
       "  1420424.0101587302,\n",
       "  1420136.9853968255,\n",
       "  1419848.706031746,\n",
       "  1419564.6526984128,\n",
       "  1419284.6679365078,\n",
       "  1418998.6844444445,\n",
       "  1418715.5606349206,\n",
       "  1418428.419047619,\n",
       "  1418140.1244444444,\n",
       "  1417857.3815873016,\n",
       "  1417572.5968253969,\n",
       "  1417291.387936508,\n",
       "  1417002.4685714287,\n",
       "  1416724.4292063492,\n",
       "  1416439.3752380952,\n",
       "  1416152.3250793652,\n",
       "  1415863.354920635,\n",
       "  1415578.1942857143,\n",
       "  1415296.177777778,\n",
       "  1415013.0946031746,\n",
       "  1414732.7187301586,\n",
       "  1414454.5168253968,\n",
       "  1414169.4374603175,\n",
       "  1413884.601904762,\n",
       "  1413604.860952381,\n",
       "  1413320.700952381,\n",
       "  1413032.6653968254,\n",
       "  1412750.7453968255,\n",
       "  1412467.4488888888,\n",
       "  1412185.6863492064,\n",
       "  1411901.6533333333,\n",
       "  1411618.300952381,\n",
       "  1411337.406984127,\n",
       "  1411055.7307936507,\n",
       "  1410774.405079365,\n",
       "  1410492.794920635,\n",
       "  1410213.9885714285,\n",
       "  1409929.0107936508,\n",
       "  1409644.9676190477,\n",
       "  1409365.6584126984,\n",
       "  1409084.1295238095,\n",
       "  1408801.6609523809,\n",
       "  1408525.252063492,\n",
       "  1408238.3847619048,\n",
       "  1407958.6184126984,\n",
       "  1407677.8006349206,\n",
       "  1407398.587936508,\n",
       "  1407115.001904762,\n",
       "  1406834.6006349206,\n",
       "  1406553.2698412698,\n",
       "  1406269.5111111111,\n",
       "  1405987.8095238095,\n",
       "  1405705.2342857143,\n",
       "  1405424.137142857,\n",
       "  1405142.4406349207,\n",
       "  1404862.593015873,\n",
       "  1404585.4273015873,\n",
       "  1404302.9384126985,\n",
       "  1404021.9682539683,\n",
       "  1403744.6704761905,\n",
       "  1403464.0914285714,\n",
       "  1403184.8939682539,\n",
       "  1402900.6374603175,\n",
       "  1402615.1263492063,\n",
       "  1402340.4444444445,\n",
       "  1402057.6304761905,\n",
       "  1401775.7815873015,\n",
       "  1401502.0088888889,\n",
       "  1401219.8755555556,\n",
       "  1400940.8965079365,\n",
       "  1400662.6133333333,\n",
       "  1400377.8895238095,\n",
       "  1400101.633015873,\n",
       "  1399821.1809523809,\n",
       "  1399542.4,\n",
       "  1399260.485079365,\n",
       "  1398983.806984127,\n",
       "  1398704.5333333334,\n",
       "  1398425.1784126984,\n",
       "  1398142.6539682539,\n",
       "  1397865.0615873015,\n",
       "  1397582.857142857,\n",
       "  1397300.3326984127,\n",
       "  1397024.8076190476,\n",
       "  1396742.1765079366,\n",
       "  1396468.8761904761,\n",
       "  1396190.643809524,\n",
       "  1395913.1834920635,\n",
       "  1395630.2425396824,\n",
       "  1395352.9346031747,\n",
       "  1395072.4622222222,\n",
       "  1394793.0768253969,\n",
       "  1394514.372063492,\n",
       "  1394233.4222222222,\n",
       "  1393955.4184126984,\n",
       "  1393680.9193650794,\n",
       "  1393396.7187301586,\n",
       "  1393123.5250793651,\n",
       "  1392843.8095238095,\n",
       "  1392565.6736507937,\n",
       "  1392356.7847619047,\n",
       "  1392011.2304761906,\n",
       "  1391734.8114285714,\n",
       "  1391970.6565079365,\n",
       "  1391177.4882539683,\n",
       "  1390902.2222222222,\n",
       "  1390625.1479365078,\n",
       "  1390344.4419047618,\n",
       "  1390068.3225396825,\n",
       "  1389791.2838095238,\n",
       "  1389513.8438095239,\n",
       "  1389241.594920635,\n",
       "  1388964.220952381,\n",
       "  1388685.9631746032,\n",
       "  1388408.3606349207,\n",
       "  1388132.3885714286,\n",
       "  1387849.8946031746,\n",
       "  1387575.1822222222,\n",
       "  1387299.7841269842,\n",
       "  1387021.379047619,\n",
       "  1386742.0444444444,\n",
       "  1386467.2203174604,\n",
       "  1386193.9504761905,\n",
       "  1385917.0641269842,\n",
       "  1385638.5676190476,\n",
       "  1385360.7314285715,\n",
       "  1385086.3695238095,\n",
       "  1384805.7447619047,\n",
       "  1384533.4247619049,\n",
       "  1384257.1631746031,\n",
       "  1383978.0368253968,\n",
       "  1383697.8234920634,\n",
       "  1383426.4634920636,\n",
       "  1383147.6317460318,\n",
       "  1382868.1549206348,\n",
       "  1382592.0,\n",
       "  1382313.58984127,\n",
       "  1382040.4622222222,\n",
       "  1381765.5923809523,\n",
       "  1381491.2711111112,\n",
       "  1381209.5593650793,\n",
       "  1380931.1593650794,\n",
       "  1380653.2419047619,\n",
       "  1380383.4717460317,\n",
       "  1380111.5022222223,\n",
       "  1379836.0025396824,\n",
       "  1379563.575873016,\n",
       "  1379287.3244444444,\n",
       "  1379009.356190476,\n",
       "  1378734.1815873017,\n",
       "  1378461.048888889,\n",
       "  1378187.6165079365,\n",
       "  1377911.9542857143,\n",
       "  1377638.9942857143,\n",
       "  1377361.097142857,\n",
       "  1377084.419047619,\n",
       "  1376810.6463492063,\n",
       "  1376539.5047619047,\n",
       "  1376264.4215873017,\n",
       "  1375992.4317460319,\n",
       "  1375716.0380952382,\n",
       "  1375445.7396825396,\n",
       "  1375167.6546031747,\n",
       "  1374890.753015873,\n",
       "  1374620.4292063492,\n",
       "  1374345.8793650793,\n",
       "  1374072.7365079366,\n",
       "  1373801.0107936508,\n",
       "  1373525.10984127,\n",
       "  1373248.0203174604,\n",
       "  1372975.944126984,\n",
       "  1372699.8298412699,\n",
       "  1372425.5542857142,\n",
       "  1372156.2565079364,\n",
       "  1371882.1282539682,\n",
       "  1371607.7104761906,\n",
       "  1371336.0355555555,\n",
       "  1371063.4565079366,\n",
       "  1370792.1676190477,\n",
       "  1370515.144126984,\n",
       "  1370238.5168253968,\n",
       "  1369967.7561904762,\n",
       "  1369695.4717460317,\n",
       "  1369423.4463492064,\n",
       "  1369156.165079365,\n",
       "  1368882.046984127,\n",
       "  1368605.4349206348,\n",
       "  1368336.6857142858,\n",
       "  1368063.4615873017,\n",
       "  1367793.4831746032,\n",
       "  1367523.5047619047,\n",
       "  1367245.638095238,\n",
       "  1366979.84,\n",
       "  1366707.5555555555,\n",
       "  1366435.7587301587,\n",
       "  1366159.5174603174,\n",
       "  1365891.3625396825,\n",
       "  1365620.485079365,\n",
       "  1365353.7726984126,\n",
       "  1365079.9847619047,\n",
       "  1364810.9968253968,\n",
       "  1364540.6476190477,\n",
       "  1364268.226031746,\n",
       "  1363994.1688888888,\n",
       "  1363722.0622222223,\n",
       "  1363449.9911111111,\n",
       "  1363176.1015873016,\n",
       "  1362909.048888889,\n",
       "  1362636.1396825397,\n",
       "  1362365.693968254,\n",
       "  1362098.0520634921,\n",
       "  1361828.673015873,\n",
       "  1361554.499047619,\n",
       "  1361283.2507936507,\n",
       "  1361016.4419047618,\n",
       "  1360742.7606349206,\n",
       "  1360473.1377777779,\n",
       "  1360205.7447619047,\n",
       "  1359936.2184126985,\n",
       "  1359665.7015873017,\n",
       "  1359395.8806349207,\n",
       "  1359123.073015873,\n",
       "  1358853.4806349205,\n",
       "  1358584.3047619048,\n",
       "  1358317.7346031745,\n",
       "  1358049.28,\n",
       "  1357776.706031746,\n",
       "  1357504.0914285714,\n",
       "  1357236.165079365,\n",
       "  1356966.9993650794,\n",
       "  1356699.8146031746,\n",
       "  1356432.3453968253,\n",
       "  1356161.9149206348,\n",
       "  1355885.9987301587,\n",
       "  1355613.693968254,\n",
       "  1355344.2438095238,\n",
       "  1355076.353015873,\n",
       "  1354810.4482539683,\n",
       "  1354541.500952381,\n",
       "  1354270.526984127,\n",
       "  1354002.499047619,\n",
       "  1353727.68,\n",
       "  1353462.9892063492,\n",
       "  1353193.1885714286,\n",
       "  1354216.5282539683,\n",
       "  1352648.700952381,\n",
       "  1352386.4431746032,\n",
       "  1352121.5441269842,\n",
       "  1351844.8355555555,\n",
       "  1351576.3403174602,\n",
       "  1351306.88,\n",
       "  1351040.904126984,\n",
       "  1350772.6222222222,\n",
       "  1350508.4139682539,\n",
       "  1350238.902857143,\n",
       "  1349972.6679365078,\n",
       "  1349705.7574603176,\n",
       "  1349440.0355555555,\n",
       "  1349172.1092063491,\n",
       "  1348903.233015873,\n",
       "  1348638.1307936509,\n",
       "  1348370.7682539683,\n",
       "  1348101.754920635,\n",
       "  1347835.067936508,\n",
       "  1347564.347936508,\n",
       "  1347297.153015873,\n",
       "  1347032.5028571428,\n",
       "  1346762.3314285714,\n",
       "  1346493.3993650794,\n",
       "  1346223.8323809523,\n",
       "  1345954.8342857142,\n",
       "  1345689.7980952382,\n",
       "  1345418.8647619048,\n",
       "  1345150.7707936508,\n",
       "  1344882.361904762,\n",
       "  1344615.740952381,\n",
       "  1344350.4812698413,\n",
       "  1344088.2082539683,\n",
       "  1343816.6247619048,\n",
       "  1343547.3574603174,\n",
       "  1343279.3752380952,\n",
       "  1343015.426031746,\n",
       "  1342755.0882539682,\n",
       "  1342478.6793650794,\n",
       "  1342216.9904761906,\n",
       "  1341952.4012698412,\n",
       "  1341683.4133333333,\n",
       "  1341416.7517460317,\n",
       "  1341152.2285714287,\n",
       "  1340886.9333333333,\n",
       "  1340625.539047619,\n",
       "  1340357.2266666666,\n",
       "  1340091.8044444444,\n",
       "  1339820.2971428572,\n",
       "  1339559.426031746,\n",
       "  1339293.3536507937,\n",
       "  1339027.4946031745,\n",
       "  1338762.9104761905,\n",
       "  1338493.5161904762,\n",
       "  1338227.0425396825,\n",
       "  1337967.9238095237,\n",
       "  1337695.095873016,\n",
       "  1337433.0463492062,\n",
       "  1337166.4152380952,\n",
       "  1336904.7365079366,\n",
       "  1336639.5428571429,\n",
       "  1336382.1409523808,\n",
       "  1336109.958095238,\n",
       "  1335846.3949206348,\n",
       "  1335579.713015873,\n",
       "  1335312.0152380953,\n",
       "  1335047.873015873,\n",
       "  1334784.573968254,\n",
       "  1334520.3047619048,\n",
       "  1334255.68,\n",
       "  1333990.3187301587,\n",
       "  1333728.126984127,\n",
       "  1333461.10984127,\n",
       "  1333196.8660317461,\n",
       "  1332935.9898412698,\n",
       "  1332672.0101587302,\n",
       "  1332407.6342857142,\n",
       "  1332149.8565079365,\n",
       "  1331887.100952381,\n",
       "  1331621.9073015873,\n",
       "  1331359.299047619,\n",
       "  1331095.410793651,\n",
       "  1330830.1815873017,\n",
       "  1330566.2476190475,\n",
       "  1330303.4006349207,\n",
       "  1330042.1587301588,\n",
       "  1329777.6406349207,\n",
       "  1329514.8342857142,\n",
       "  1329249.0565079364,\n",
       "  1328983.0755555555,\n",
       "  1328719.233015873,\n",
       "  1328459.8450793652,\n",
       "  1328193.7523809525,\n",
       "  1327932.5561904763,\n",
       "  1327667.2863492065,\n",
       "  1327404.673015873,\n",
       "  1327140.9117460318,\n",
       "  1326878.8926984128,\n",
       "  1326615.867936508,\n",
       "  1326356.1193650793,\n",
       "  1326091.7841269842,\n",
       "  1325826.56,\n",
       "  1325572.9777777777,\n",
       "  1325304.766984127,\n",
       "  1325045.048888889,\n",
       "  1324783.994920635,\n",
       "  1324527.288888889,\n",
       "  1324258.4584126985,\n",
       "  1323997.6838095237,\n",
       "  1323739.646984127,\n",
       "  1323476.403809524,\n",
       "  1323214.8114285714,\n",
       "  1322954.9714285715,\n",
       "  1322693.0641269842,\n",
       "  1322429.6584126984,\n",
       "  1322167.492063492,\n",
       "  1321905.9301587301,\n",
       "  1321644.7238095237,\n",
       "  1321384.0965079365,\n",
       "  1321122.7123809524,\n",
       "  1320864.177777778,\n",
       "  1320600.5587301587,\n",
       "  1320341.0387301587,\n",
       "  1320080.1625396826,\n",
       "  1319821.5466666666,\n",
       "  1319559.9542857143,\n",
       "  1319298.0114285715,\n",
       "  1319036.220952381,\n",
       "  1318778.686984127,\n",
       "  1318520.9346031747,\n",
       "  1318259.8044444444,\n",
       "  1317995.773968254,\n",
       "  1317738.179047619,\n",
       "  1317477.4907936507,\n",
       "  1317216.5841269842,\n",
       "  1316956.9371428571,\n",
       "  1316692.4647619047,\n",
       "  1316429.9276190477,\n",
       "  1316178.9765079366,\n",
       "  1315909.3892063492,\n",
       "  1315651.5301587302,\n",
       "  1315418.6615873016,\n",
       "  1315130.8241269842,\n",
       "  1314872.904126984,\n",
       "  1314610.306031746,\n",
       "  1314353.274920635,\n",
       "  1314093.0234920634,\n",
       "  1313829.186031746,\n",
       "  1313570.951111111,\n",
       "  1313307.144126984,\n",
       "  1313052.9777777777,\n",
       "  1312788.2057142856,\n",
       "  1312529.5695238095,\n",
       "  1312268.5307936508,\n",
       "  1312012.281904762,\n",
       "  1311746.9257142858,\n",
       "  1311488.0812698412,\n",
       "  1311231.6342857142,\n",
       "  1310973.7853968253,\n",
       "  1310712.0965079365,\n",
       "  1310453.0793650793,\n",
       "  1310195.8653968254,\n",
       "  1309935.04,\n",
       "  1309675.9415873017,\n",
       "  1309417.2952380953,\n",
       "  1309160.827936508,\n",
       "  1308898.86984127,\n",
       "  1308638.9993650794,\n",
       "  1308376.253968254,\n",
       "  1308122.0622222223,\n",
       "  1307855.36,\n",
       "  1307595.895873016,\n",
       "  1307340.1396825397,\n",
       "  1307079.4615873017,\n",
       "  1306820.7644444443,\n",
       "  1306556.8660317461,\n",
       "  1306299.7536507936,\n",
       "  1306045.9123809524,\n",
       "  1305789.7955555555,\n",
       "  1305526.7149206349,\n",
       "  1305270.2323809525,\n",
       "  1305008.2184126985,\n",
       "  1304747.9568253967,\n",
       "  1304495.9136507937,\n",
       "  1304233.2088888888,\n",
       "  1303977.4628571428,\n",
       "  1303717.627936508,\n",
       "  1303458.9714285715,\n",
       "  1303206.7606349206,\n",
       "  1302946.8444444444,\n",
       "  1302692.860952381,\n",
       "  1302437.2673015874,\n",
       "  1302172.932063492,\n",
       "  1301918.5574603174,\n",
       "  1301666.9968253968,\n",
       "  1301404.2412698413,\n",
       "  1301146.7022222222,\n",
       "  1300890.3365079365,\n",
       "  1300632.96,\n",
       "  1300374.1561904761,\n",
       "  1300117.368888889,\n",
       "  1299860.8965079365,\n",
       "  1299607.0146031745,\n",
       "  1299347.4133333333,\n",
       "  1299096.3098412699,\n",
       "  1298837.4653968255,\n",
       "  1298576.4673015873,\n",
       "  1298321.9149206348,\n",
       "  1298066.1130158731,\n",
       "  1297813.0692063493,\n",
       "  1297550.0292063493,\n",
       "  1297297.1784126984,\n",
       "  1297035.6926984128,\n",
       "  1296779.3726984127,\n",
       "  1296524.606984127,\n",
       "  1296266.2247619047,\n",
       "  1296011.7942857144,\n",
       "  1295760.5638095238,\n",
       "  1295502.2019047618,\n",
       "  1295243.6977777777,\n",
       "  1294990.725079365,\n",
       "  1294733.9022222222,\n",
       "  1294472.380952381,\n",
       "  1294216.2641269842,\n",
       "  1293966.1968253967,\n",
       "  1293703.933968254,\n",
       "  1293447.034920635,\n",
       "  1293191.862857143,\n",
       "  1292936.96,\n",
       "  1292684.0838095238,\n",
       "  1292425.8285714285,\n",
       "  1292172.1853968254,\n",
       "  1291914.7682539683,\n",
       "  1291665.2292063492,\n",
       "  1291413.0641269842,\n",
       "  1291152.9803174604,\n",
       "  1290902.013968254,\n",
       "  1290643.5504761904,\n",
       "  1290389.699047619,\n",
       "  1290141.7803174604,\n",
       "  1289881.1022222221,\n",
       "  1289618.433015873,\n",
       "  1289362.9663492064,\n",
       "  1289106.1993650794,\n",
       "  1288851.1949206349,\n",
       "  1288599.2584126985,\n",
       "  1288336.645079365,\n",
       "  1288087.1314285714,\n",
       "  1287833.6253968254,\n",
       "  1287578.6107936508,\n",
       "  1287331.1085714286,\n",
       "  1287072.4368253967,\n",
       "  1286817.4526984126,\n",
       "  1286566.6336507937,\n",
       "  1286311.37015873,\n",
       "  1286059.4336507937,\n",
       "  1285802.7174603175,\n",
       "  1285552.1625396826,\n",
       "  1285299.8450793652,\n",
       "  1285048.0457142857,\n",
       "  1284788.2920634921,\n",
       "  1284537.1276190476,\n",
       "  1284283.4996825396,\n",
       "  1284039.1466666667,\n",
       "  1283787.4488888888,\n",
       "  1283524.0431746033,\n",
       "  1283268.7288888888,\n",
       "  1283015.5276190476,\n",
       "  1284930.5295238094,\n",
       "  1282512.0507936508,\n",
       "  1282265.9301587301,\n",
       "  1282007.5580952382,\n",
       "  1281750.6285714286,\n",
       "  1281503.238095238,\n",
       "  1281246.8012698414,\n",
       "  1285555.895873016,\n",
       "  1285301.6787301588,\n",
       "  1285052.9676190477,\n",
       "  1284792.7365079366,\n",
       "  1284540.5358730159,\n",
       "  1284287.0095238094,\n",
       "  1284040.772063492,\n",
       "  1283781.9377777777,\n",
       "  1283527.1923809524,\n",
       "  1283274.2806349206,\n",
       "  1283019.8907936509,\n",
       "  1282770.7225396826,\n",
       "  1282510.7403174604,\n",
       "  1282262.0495238095,\n",
       "  1282005.1047619048,\n",
       "  1281754.1587301588,\n",
       "  1281500.5257142857,\n",
       "  1281242.940952381,\n",
       "  1280998.2171428571,\n",
       "  1280736.5638095238,\n",
       "  1280477.5111111111,\n",
       "  1280224.4063492063,\n",
       "  1279971.9365079366,\n",
       "  1279719.3092063493,\n",
       "  1279465.2901587302,\n",
       "  1279218.295873016,\n",
       "  1278958.1409523808,\n",
       "  1278704.6196825397,\n",
       "  1278458.0520634921,\n",
       "  1278201.2698412698,\n",
       "  1277951.2076190477,\n",
       "  1277696.3555555556,\n",
       "  1277447.2228571428,\n",
       "  1277198.2628571428,\n",
       "  1276942.5066666666,\n",
       "  1276688.126984127,\n",
       "  1276439.8933333333,\n",
       "  1276198.7606349206,\n",
       "  1275934.6793650794,\n",
       "  1275683.7282539683,\n",
       "  1275434.1434920635,\n",
       "  1275178.626031746,\n",
       "  1274929.1733333333,\n",
       "  1274684.860952381,\n",
       "  1274428.8,\n",
       "  1274179.4234920635,\n",
       "  1273924.3885714286,\n",
       "  1273680.6603174603,\n",
       "  1273425.1276190476,\n",
       "  1273174.8063492063,\n",
       "  1272926.6946031747,\n",
       "  1272671.2634920634,\n",
       "  1272415.0704761904,\n",
       "  1272171.393015873,\n",
       "  1271920.4825396826,\n",
       "  1271671.7155555557,\n",
       "  1271425.219047619,\n",
       "  1271169.9352380952,\n",
       "  1270919.9847619047,\n",
       "  1270679.0806349206,\n",
       "  1270420.8812698412,\n",
       "  1270343.1619047618,\n",
       "  1274937.7523809525,\n",
       "  1274687.4666666666,\n",
       "  1274436.2514285715,\n",
       "  1274179.84,\n",
       "  1273930.0876190476,\n",
       "  1273681.5238095238,\n",
       "  1273431.2584126985,\n",
       "  1273178.2603174604,\n",
       "  1272923.398095238,\n",
       "  1272674.8190476191,\n",
       "  1272429.186031746,\n",
       "  1272168.0761904763,\n",
       "  1271923.636825397,\n",
       "  1271668.1346031746,\n",
       "  1271417.3714285714,\n",
       "  1271161.9758730158,\n",
       "  1270916.4901587302,\n",
       "  1270663.2228571428,\n",
       "  1270415.7561904762,\n",
       "  1270159.233015873,\n",
       "  1269909.9682539683,\n",
       "  1269673.1834920635,\n",
       "  1269408.0761904763,\n",
       "  1269163.7028571428,\n",
       "  1268904.0203174604,\n",
       "  1268651.083174603,\n",
       "  1268399.0247619047,\n",
       "  1268150.4253968254,\n",
       "  1267897.3104761904,\n",
       "  1267647.2533333334,\n",
       "  1267401.7422222223,\n",
       "  1267156.0177777777,\n",
       "  1266904.706031746,\n",
       "  1266650.2603174604,\n",
       "  1266407.0450793651,\n",
       "  1266149.9276190477,\n",
       "  1265902.902857143,\n",
       "  1265652.6831746032,\n",
       "  1265402.8952380952,\n",
       "  1265150.1612698413,\n",
       "  1264900.7288888888,\n",
       "  1264655.2584126985,\n",
       "  1264405.6634920635,\n",
       "  1264157.2774603174,\n",
       "  1263906.295873016,\n",
       "  1263654.8368253969,\n",
       "  1263405.0946031746,\n",
       "  1263155.713015873,\n",
       "  1262910.5676190476,\n",
       "  1262660.3784126984,\n",
       "  1262413.8565079365,\n",
       "  1267535.2025396826,\n",
       "  1267286.3949206348,\n",
       "  1267038.918095238,\n",
       "  1266781.0996825397,\n",
       "  1266534.1714285715,\n",
       "  1266296.2742857144,\n",
       "  1266033.3612698412,\n",
       "  1265780.0126984126,\n",
       "  1265531.5657142857,\n",
       "  1265286.4863492064,\n",
       "  1265028.733968254,\n",
       "  1264782.4863492064,\n",
       "  1264530.620952381,\n",
       "  1264283.0425396825,\n",
       "  1264038.344126984,\n",
       "  1263787.4031746031,\n",
       "  1263536.1015873016,\n",
       "  1263286.6234920635,\n",
       "  1263039.7866666666,\n",
       "  1262793.4933333334,\n",
       "  1262540.4901587302,\n",
       "  1262283.5352380953,\n",
       "  1262041.986031746,\n",
       "  1261796.0025396824,\n",
       "  1261541.1555555556,\n",
       "  1261289.0920634922,\n",
       "  1261045.6888888888,\n",
       "  1260794.2044444445,\n",
       "  1260544.5587301587,\n",
       "  1260307.5911111112,\n",
       "  1260049.0107936508,\n",
       "  1259797.693968254,\n",
       "  1259549.2317460317,\n",
       "  1259300.2311111111,\n",
       "  1259052.9422222222,\n",
       "  1258801.335873016,\n",
       "  1258554.3111111112,\n",
       "  1261175.8577777778,\n",
       "  1258057.6457142858,\n",
       "  1257813.9834920636,\n",
       "  1257557.5111111111,\n",
       "  1257301.4298412697,\n",
       "  1257062.9434920636,\n",
       "  1256812.1904761905,\n",
       "  1256561.4984126985,\n",
       "  1256316.0990476192,\n",
       "  1256062.3238095238,\n",
       "  1255813.4196825398,\n",
       "  1255570.5447619047,\n",
       "  1255315.596190476,\n",
       "  1255070.4965079366,\n",
       "  1254822.4558730158,\n",
       "  1254579.4488888888,\n",
       "  1254327.6749206348,\n",
       "  1254079.156825397,\n",
       "  1253837.2622222223,\n",
       "  1253589.2622222223,\n",
       "  1253347.3117460317,\n",
       "  1253090.9358730158,\n",
       "  1252848.9498412698,\n",
       "  1252595.9415873017,\n",
       "  1252351.624126984,\n",
       "  1252103.0044444446,\n",
       "  1251858.0520634921,\n",
       "  1251610.885079365,\n",
       "  1251372.0126984126,\n",
       "  1251122.5498412699,\n",
       "  1250876.5714285714,\n",
       "  1250628.5612698412,\n",
       "  1250379.9314285715,\n",
       "  1250128.9701587302,\n",
       "  1249888.568888889,\n",
       "  1249642.4126984128,\n",
       "  1249395.9974603176,\n",
       "  1249151.5377777778,\n",
       "  1248901.373968254,\n",
       "  1248659.1187301588,\n",
       "  1248407.873015873,\n",
       "  1248163.8196825397,\n",
       "  1247922.5955555555,\n",
       "  1247673.7980952382,\n",
       "  1247422.5422222223,\n",
       "  1247182.4761904762,\n",
       "  1246933.9784126985,\n",
       "  1246684.2158730158,\n",
       "  1246440.7923809523,\n",
       "  1246188.5612698412,\n",
       "  1245949.8717460318,\n",
       "  1245704.0203174604,\n",
       "  1245461.2012698413,\n",
       "  1245217.219047619,\n",
       "  1244966.019047619,\n",
       "  1244723.1492063492,\n",
       "  1244484.4546031747,\n",
       "  1244238.846984127,\n",
       "  1243984.2031746032,\n",
       "  1243741.2622222223,\n",
       "  1243494.1053968254,\n",
       "  1243249.8336507936,\n",
       "  1243007.3803174603,\n",
       "  1242755.7536507936,\n",
       "  1242518.7758730159,\n",
       "  1242272.8584126984,\n",
       "  1242034.3974603175,\n",
       "  1241785.986031746,\n",
       "  1241538.1587301588,\n",
       "  1241293.5212698414,\n",
       "  1241052.3326984127,\n",
       "  1240801.6355555556,\n",
       "  1240557.754920635,\n",
       "  1243382.5980952382,\n",
       "  1243136.6907936507,\n",
       "  1242901.3028571429,\n",
       "  1242654.2882539683,\n",
       "  1242445.44,\n",
       "  1242171.9466666668,\n",
       "  1241927.7968253968,\n",
       "  1241690.7276190475,\n",
       "  1241440.904126984,\n",
       "  1241201.2698412698,\n",
       "  1240959.04,\n",
       "  1240715.646984127,\n",
       "  1240473.1225396825,\n",
       "  1240238.8215873016,\n",
       "  1239990.6996825398,\n",
       "  1239753.1784126984,\n",
       "  1239512.4774603175,\n",
       "  1239289.1022222221,\n",
       "  1239031.2584126985,\n",
       "  1238792.1422222222,\n",
       "  1238547.2,\n",
       "  1238306.5142857144,\n",
       "  1238068.1803174603,\n",
       "  1237827.8653968254,\n",
       "  1237586.7428571428,\n",
       "  1237347.5301587302,\n",
       "  1237108.4495238096,\n",
       "  1236865.478095238,\n",
       "  1236629.7955555555,\n",
       "  1236385.5796825397,\n",
       "  1236145.4323809524,\n",
       "  1235914.9815873015,\n",
       "  1235663.0603174602,\n",
       "  1235423.2177777777,\n",
       "  1235189.2165079366,\n",
       "  1234966.9993650794,\n",
       "  1234702.786031746,\n",
       "  1234459.6825396826,\n",
       "  1234214.786031746,\n",
       "  1234006.9638095237,\n",
       "  1233746.4533333334,\n",
       "  1233503.873015873,\n",
       "  1233273.356190476,\n",
       "  1233022.3949206348,\n",
       "  1232780.8203174602,\n",
       "  1232556.9422222222,\n",
       "  1232298.1282539682,\n",
       "  1232060.617142857,\n",
       "  1231834.4076190477,\n",
       "  1231582.1765079366,\n",
       "  1231344.0355555555,\n",
       "  1231100.871111111,\n",
       "  1230864.0863492063,\n",
       "  1230625.528888889,\n",
       "  1230388.4393650794,\n",
       "  1230143.3955555556,\n",
       "  1229905.4984126985,\n",
       "  1229660.5561904763,\n",
       "  1229422.3187301587,\n",
       "  1229182.7047619047,\n",
       "  1228965.693968254,\n",
       "  1228706.4685714287,\n",
       "  1228467.7841269842,\n",
       "  1228227.4946031745,\n",
       "  1227992.126984127,\n",
       "  1227766.4914285715,\n",
       "  1227515.2761904763,\n",
       "  1227277.0641269842,\n",
       "  1227031.7765079364,\n",
       "  1226810.4736507935,\n",
       "  1226558.5777777778,\n",
       "  1226321.7473015874,\n",
       "  1226085.876825397,\n",
       "  1225850.372063492,\n",
       "  1225612.3936507937,\n",
       "  1225374.72,\n",
       "  1225136.2133333334,\n",
       "  1224901.0336507936,\n",
       "  1224745.28,\n",
       "  1224431.3803174603,\n",
       "  1224192.8634920635,\n",
       "  1223951.4565079366,\n",
       "  1223708.6222222222,\n",
       "  1223465.219047619,\n",
       "  1223239.939047619,\n",
       "  1222996.2006349207,\n",
       "  1222762.4787301586,\n",
       "  1222523.1746031747,\n",
       "  1222289.9707936507,\n",
       "  1222060.6425396826,\n",
       "  1221814.6234920635,\n",
       "  1221571.1085714286,\n",
       "  1221334.6844444445,\n",
       "  1221097.142857143,\n",
       "  1220862.902857143,\n",
       "  1220625.3663492063,\n",
       "  1220393.2444444445,\n",
       "  1220157.4653968255,\n",
       "  1219918.135873016,\n",
       "  1219676.8304761904,\n",
       "  1219442.2247619047,\n",
       "  1219214.6539682539,\n",
       "  1218976.4876190475,\n",
       "  1218728.1726984128,\n",
       "  1218490.4431746032,\n",
       "  1218255.608888889,\n",
       "  1218018.493968254,\n",
       "  1217788.027936508,\n",
       "  1217554.366984127,\n",
       "  1217311.2228571428,\n",
       "  1217081.8387301587,\n",
       "  1216838.013968254,\n",
       "  1216598.0393650793,\n",
       "  1216363.773968254,\n",
       "  1216124.6425396826,\n",
       "  1215892.733968254,\n",
       "  1215656.8482539682,\n",
       "  1215424.9803174604,\n",
       "  1215188.6273015873,\n",
       "  1214966.6692063492,\n",
       "  1214721.7828571429,\n",
       "  1214489.5238095238,\n",
       "  1214248.8634920635,\n",
       "  1214014.4965079366,\n",
       "  1213777.925079365,\n",
       "  1213546.1993650794,\n",
       "  1213313.9758730158,\n",
       "  1213075.1847619046,\n",
       "  1212845.4704761906,\n",
       "  1212601.351111111,\n",
       "  1212360.4723809524,\n",
       "  1212128.3047619048,\n",
       "  1211893.815873016,\n",
       "  1211652.926984127,\n",
       "  1211416.6146031746,\n",
       "  1211180.226031746,\n",
       "  1210948.2768253968,\n",
       "  1210733.368888889,\n",
       "  1210475.0425396825,\n",
       "  1210242.0622222223,\n",
       "  1210010.2044444445,\n",
       "  1209784.7415873015,\n",
       "  1209528.965079365,\n",
       "  1209296.2082539683,\n",
       "  1209058.1333333333,\n",
       "  1208824.573968254,\n",
       "  1208591.4768253968,\n",
       "  1208360.9752380953,\n",
       "  1208127.1517460318,\n",
       "  1207893.5568253968,\n",
       "  1207681.9961904762,\n",
       "  1207419.575873016,\n",
       "  1207185.1022222221,\n",
       "  1206947.4285714286,\n",
       "  1206791.1415873016,\n",
       "  1206481.8031746033,\n",
       "  1206247.4361904762,\n",
       "  1206015.6698412697,\n",
       "  1205772.419047619,\n",
       "  1205539.575873016,\n",
       "  1205316.3276190476,\n",
       "  1205077.0895238095,\n",
       "  1204843.773968254,\n",
       "  1204603.8552380952,\n",
       "  1204375.5022222223,\n",
       "  1204135.426031746,\n",
       "  1203920.452063492,\n",
       "  1203663.7765079364,\n",
       "  1203434.306031746,\n",
       "  1203200.5587301587,\n",
       "  1202970.3365079365,\n",
       "  1202747.266031746,\n",
       "  1202517.384126984,\n",
       "  1202275.4996825396,\n",
       "  1202036.4749206349,\n",
       "  1201823.238095238,\n",
       "  1201570.2857142857,\n",
       "  1201335.0806349206,\n",
       "  1201110.0596825397,\n",
       "  1200869.3892063492,\n",
       "  1200637.7295238096,\n",
       "  1200406.6692063492,\n",
       "  1200168.0253968255,\n",
       "  1200009.7726984126,\n",
       "  1199704.5231746032,\n",
       "  1199464.888888889,\n",
       "  1199229.4857142856,\n",
       "  1198995.9923809525,\n",
       "  1198768.4317460319,\n",
       "  1198527.878095238,\n",
       "  1198298.7834920634,\n",
       "  1198060.673015873,\n",
       "  ...],\n",
       " [5493.0205078125,\n",
       "  5490.3779296875,\n",
       "  5487.6552734375,\n",
       "  5484.94287109375,\n",
       "  5482.41845703125,\n",
       "  5479.9580078125,\n",
       "  5477.61767578125,\n",
       "  5475.11767578125,\n",
       "  5472.6630859375,\n",
       "  5470.201171875,\n",
       "  5467.71728515625,\n",
       "  5465.25439453125,\n",
       "  5462.87353515625,\n",
       "  5460.60888671875,\n",
       "  5458.36181640625,\n",
       "  5456.1884765625,\n",
       "  5454.01513671875,\n",
       "  5451.90234375,\n",
       "  5449.83642578125,\n",
       "  5447.81787109375,\n",
       "  5445.59375,\n",
       "  5443.5732421875,\n",
       "  5441.517578125,\n",
       "  5439.42236328125,\n",
       "  5437.45703125,\n",
       "  5435.478515625,\n",
       "  5433.59130859375,\n",
       "  5431.64697265625,\n",
       "  5429.763671875,\n",
       "  5427.8671875,\n",
       "  5425.9658203125,\n",
       "  5424.06396484375,\n",
       "  5422.2109375,\n",
       "  5420.29443359375,\n",
       "  5418.52587890625,\n",
       "  5416.69482421875,\n",
       "  5414.91748046875,\n",
       "  5413.26171875,\n",
       "  5411.375,\n",
       "  5409.60009765625,\n",
       "  5407.9052734375,\n",
       "  5406.22802734375,\n",
       "  5404.48876953125,\n",
       "  5402.93212890625,\n",
       "  5401.232421875,\n",
       "  5399.7138671875,\n",
       "  5397.8935546875,\n",
       "  5396.74072265625,\n",
       "  5394.794921875,\n",
       "  5393.1982421875,\n",
       "  5391.6611328125,\n",
       "  5390.02587890625,\n",
       "  5388.427734375,\n",
       "  5386.919921875,\n",
       "  5385.6767578125,\n",
       "  5383.966796875,\n",
       "  5382.40869140625,\n",
       "  5380.90234375,\n",
       "  5379.42138671875,\n",
       "  5378.18212890625,\n",
       "  5376.92236328125,\n",
       "  5375.2451171875,\n",
       "  5373.7646484375,\n",
       "  5372.44384765625,\n",
       "  5371.06982421875,\n",
       "  5369.58935546875,\n",
       "  5368.50341796875,\n",
       "  5366.9013671875,\n",
       "  5365.3828125,\n",
       "  5364.16455078125,\n",
       "  5362.82861328125,\n",
       "  5361.50048828125,\n",
       "  5360.28173828125,\n",
       "  5358.68994140625,\n",
       "  5358.11572265625,\n",
       "  5355.99755859375,\n",
       "  5354.90673828125,\n",
       "  5353.84521484375,\n",
       "  5352.1826171875,\n",
       "  5350.79345703125,\n",
       "  5349.48486328125,\n",
       "  5348.16845703125,\n",
       "  5346.88427734375,\n",
       "  5346.0234375,\n",
       "  5344.28173828125,\n",
       "  5342.89013671875,\n",
       "  5341.65185546875,\n",
       "  5340.46923828125,\n",
       "  5338.951171875,\n",
       "  5337.75732421875,\n",
       "  5336.37158203125,\n",
       "  5335.13134765625,\n",
       "  5333.73388671875,\n",
       "  5332.5205078125,\n",
       "  5331.26904296875,\n",
       "  5329.8876953125,\n",
       "  5329.017578125,\n",
       "  5327.45068359375,\n",
       "  5326.05224609375,\n",
       "  5325.0439453125,\n",
       "  5323.6103515625,\n",
       "  5322.6298828125,\n",
       "  5320.90576171875,\n",
       "  5319.5712890625,\n",
       "  5318.64404296875,\n",
       "  5317.3369140625,\n",
       "  5315.7470703125,\n",
       "  5314.99462890625,\n",
       "  5313.59033203125,\n",
       "  5311.99951171875,\n",
       "  5310.8681640625,\n",
       "  5309.55224609375,\n",
       "  5308.2587890625,\n",
       "  5307.11376953125,\n",
       "  5305.56005859375,\n",
       "  5304.55224609375,\n",
       "  5303.37548828125,\n",
       "  5301.79638671875,\n",
       "  5301.13037109375,\n",
       "  5299.41259765625,\n",
       "  5298.16552734375,\n",
       "  5296.96484375,\n",
       "  5295.482421875,\n",
       "  5294.2763671875,\n",
       "  5293.3251953125,\n",
       "  5291.8623046875,\n",
       "  5290.99169921875,\n",
       "  5289.34130859375,\n",
       "  5288.73388671875,\n",
       "  5286.83984375,\n",
       "  5285.51025390625,\n",
       "  5284.5078125,\n",
       "  5282.96875,\n",
       "  5281.77734375,\n",
       "  5280.822265625,\n",
       "  5279.2626953125,\n",
       "  5278.36767578125,\n",
       "  5277.43408203125,\n",
       "  5275.65966796875,\n",
       "  5274.67822265625,\n",
       "  5273.2314453125,\n",
       "  5272.046875,\n",
       "  5270.892578125,\n",
       "  5269.36328125,\n",
       "  5268.57763671875,\n",
       "  5266.9208984375,\n",
       "  5265.7353515625,\n",
       "  5264.51416015625,\n",
       "  5263.09228515625,\n",
       "  5262.06689453125,\n",
       "  5261.0771484375,\n",
       "  5259.58203125,\n",
       "  5258.58935546875,\n",
       "  5257.19189453125,\n",
       "  5255.943359375,\n",
       "  5255.04443359375,\n",
       "  5253.80224609375,\n",
       "  5252.67578125,\n",
       "  5251.2734375,\n",
       "  5250.20654296875,\n",
       "  5248.82958984375,\n",
       "  5247.49951171875,\n",
       "  5246.4677734375,\n",
       "  5245.234375,\n",
       "  5244.04541015625,\n",
       "  5243.53564453125,\n",
       "  5241.75146484375,\n",
       "  5240.642578125,\n",
       "  5243.30859375,\n",
       "  5237.947265625,\n",
       "  5236.65673828125,\n",
       "  5235.62939453125,\n",
       "  5234.66552734375,\n",
       "  5233.2109375,\n",
       "  5231.845703125,\n",
       "  5231.3623046875,\n",
       "  5230.0859375,\n",
       "  5228.42626953125,\n",
       "  5227.05908203125,\n",
       "  5226.5380859375,\n",
       "  5225.3779296875,\n",
       "  5223.62548828125,\n",
       "  5222.68994140625,\n",
       "  5221.23779296875,\n",
       "  5220.07080078125,\n",
       "  5218.87353515625,\n",
       "  5217.71533203125,\n",
       "  5216.4560546875,\n",
       "  5215.66015625,\n",
       "  5214.15380859375,\n",
       "  5212.87744140625,\n",
       "  5212.0634765625,\n",
       "  5211.41259765625,\n",
       "  5209.5,\n",
       "  5207.9951171875,\n",
       "  5206.89990234375,\n",
       "  5205.78076171875,\n",
       "  5204.5859375,\n",
       "  5203.32080078125,\n",
       "  5201.962890625,\n",
       "  5200.80615234375,\n",
       "  5199.96728515625,\n",
       "  5198.69384765625,\n",
       "  5197.494140625,\n",
       "  5196.54833984375,\n",
       "  5195.06298828125,\n",
       "  5193.4609375,\n",
       "  5192.60546875,\n",
       "  5192.23388671875,\n",
       "  5190.6015625,\n",
       "  5189.900390625,\n",
       "  5188.41748046875,\n",
       "  5186.8173828125,\n",
       "  5185.64111328125,\n",
       "  5184.6591796875,\n",
       "  5182.9580078125,\n",
       "  5182.0693359375,\n",
       "  5180.43701171875,\n",
       "  5179.56591796875,\n",
       "  5178.23046875,\n",
       "  5177.34619140625,\n",
       "  5175.9423828125,\n",
       "  5174.85400390625,\n",
       "  5173.4716796875,\n",
       "  5172.4755859375,\n",
       "  5171.51953125,\n",
       "  5170.296875,\n",
       "  5169.12548828125,\n",
       "  5167.6328125,\n",
       "  5167.1640625,\n",
       "  5166.05712890625,\n",
       "  5164.68603515625,\n",
       "  5163.7265625,\n",
       "  5162.34521484375,\n",
       "  5160.830078125,\n",
       "  5160.376953125,\n",
       "  5159.13818359375,\n",
       "  5157.68359375,\n",
       "  5156.55224609375,\n",
       "  5155.02880859375,\n",
       "  5153.9169921875,\n",
       "  5152.88037109375,\n",
       "  5151.375,\n",
       "  5150.25,\n",
       "  5149.0087890625,\n",
       "  5147.82373046875,\n",
       "  5146.54150390625,\n",
       "  5145.35693359375,\n",
       "  5144.33984375,\n",
       "  5143.17724609375,\n",
       "  5141.7900390625,\n",
       "  5141.33642578125,\n",
       "  5139.9111328125,\n",
       "  5138.3916015625,\n",
       "  5137.376953125,\n",
       "  5136.0126953125,\n",
       "  5135.2490234375,\n",
       "  5133.99560546875,\n",
       "  5132.634765625,\n",
       "  5131.41845703125,\n",
       "  5130.13134765625,\n",
       "  5129.02587890625,\n",
       "  5128.10986328125,\n",
       "  5126.61474609375,\n",
       "  5125.59228515625,\n",
       "  5124.505859375,\n",
       "  5122.9892578125,\n",
       "  5122.03857421875,\n",
       "  5120.64501953125,\n",
       "  5119.59423828125,\n",
       "  5118.54296875,\n",
       "  5117.26416015625,\n",
       "  5116.7666015625,\n",
       "  5115.3310546875,\n",
       "  5114.03125,\n",
       "  5112.6728515625,\n",
       "  5111.48388671875,\n",
       "  5110.6337890625,\n",
       "  5109.08544921875,\n",
       "  5107.87158203125,\n",
       "  5106.68994140625,\n",
       "  5105.61865234375,\n",
       "  5104.43994140625,\n",
       "  5103.3330078125,\n",
       "  5102.029296875,\n",
       "  5101.27099609375,\n",
       "  5100.07177734375,\n",
       "  5098.44140625,\n",
       "  5097.58740234375,\n",
       "  5096.41064453125,\n",
       "  5095.31005859375,\n",
       "  5094.80712890625,\n",
       "  5093.01513671875,\n",
       "  5091.841796875,\n",
       "  5090.39404296875,\n",
       "  5089.3623046875,\n",
       "  5088.4013671875,\n",
       "  5087.474609375,\n",
       "  5085.91455078125,\n",
       "  5085.1845703125,\n",
       "  5083.55029296875,\n",
       "  5082.212890625,\n",
       "  5081.1650390625,\n",
       "  5081.205078125,\n",
       "  5080.1484375,\n",
       "  5078.71728515625,\n",
       "  5076.7734375,\n",
       "  5075.6484375,\n",
       "  5074.65234375,\n",
       "  5079.17138671875,\n",
       "  5072.1904296875,\n",
       "  5071.58447265625,\n",
       "  5069.83642578125,\n",
       "  5068.48681640625,\n",
       "  5067.87158203125,\n",
       "  5066.38623046875,\n",
       "  5064.91552734375,\n",
       "  5063.91552734375,\n",
       "  5062.7919921875,\n",
       "  5061.71923828125,\n",
       "  5060.44873046875,\n",
       "  5059.6220703125,\n",
       "  5058.99755859375,\n",
       "  5056.9794921875,\n",
       "  5056.4072265625,\n",
       "  5054.77880859375,\n",
       "  5053.796875,\n",
       "  5052.4541015625,\n",
       "  5051.59375,\n",
       "  5050.24365234375,\n",
       "  5049.34228515625,\n",
       "  5047.72998046875,\n",
       "  5047.22900390625,\n",
       "  5046.0458984375,\n",
       "  5044.8134765625,\n",
       "  5043.4677734375,\n",
       "  5042.208984375,\n",
       "  5041.14013671875,\n",
       "  5039.92724609375,\n",
       "  5038.888671875,\n",
       "  5037.40185546875,\n",
       "  5036.51513671875,\n",
       "  5037.00244140625,\n",
       "  5034.1337890625,\n",
       "  5033.09228515625,\n",
       "  5032.69384765625,\n",
       "  5030.8603515625,\n",
       "  5029.583984375,\n",
       "  5028.65771484375,\n",
       "  5027.212890625,\n",
       "  5027.26953125,\n",
       "  5024.75,\n",
       "  5023.93310546875,\n",
       "  5023.14306640625,\n",
       "  5022.68017578125,\n",
       "  5020.8662109375,\n",
       "  5019.37646484375,\n",
       "  5018.3525390625,\n",
       "  5016.91357421875,\n",
       "  5015.88232421875,\n",
       "  5014.75439453125,\n",
       "  5014.0302734375,\n",
       "  5012.48388671875,\n",
       "  5011.03173828125,\n",
       "  5010.21484375,\n",
       "  5010.03173828125,\n",
       "  5007.91015625,\n",
       "  5006.93896484375,\n",
       "  5005.39013671875,\n",
       "  5004.60205078125,\n",
       "  5004.0595703125,\n",
       "  5003.50390625,\n",
       "  5001.255859375,\n",
       "  5000.40869140625,\n",
       "  4998.78369140625,\n",
       "  4998.40283203125,\n",
       "  4996.64111328125,\n",
       "  4996.03466796875,\n",
       "  4995.02294921875,\n",
       "  4993.6328125,\n",
       "  4992.5205078125,\n",
       "  4991.05419921875,\n",
       "  4989.9755859375,\n",
       "  4989.60498046875,\n",
       "  4988.421875,\n",
       "  4986.6064453125,\n",
       "  4985.48974609375,\n",
       "  4984.40380859375,\n",
       "  4984.33837890625,\n",
       "  4982.98876953125,\n",
       "  4981.25244140625,\n",
       "  4980.19189453125,\n",
       "  4978.9814453125,\n",
       "  4977.8623046875,\n",
       "  4976.84130859375,\n",
       "  4976.60791015625,\n",
       "  4974.88427734375,\n",
       "  4974.45751953125,\n",
       "  4972.21484375,\n",
       "  4971.3974609375,\n",
       "  4970.89990234375,\n",
       "  4969.560546875,\n",
       "  4967.8115234375,\n",
       "  4967.29443359375,\n",
       "  4965.97705078125,\n",
       "  4964.88330078125,\n",
       "  4963.7265625,\n",
       "  4962.79736328125,\n",
       "  4962.20458984375,\n",
       "  4960.38134765625,\n",
       "  4959.01611328125,\n",
       "  4958.06787109375,\n",
       "  4957.8017578125,\n",
       "  4956.83984375,\n",
       "  4955.408203125,\n",
       "  4954.09423828125,\n",
       "  4954.060546875,\n",
       "  4952.91943359375,\n",
       "  4951.4140625,\n",
       "  4949.58935546875,\n",
       "  4948.5322265625,\n",
       "  4947.39599609375,\n",
       "  4947.17578125,\n",
       "  4945.6474609375,\n",
       "  4944.51025390625,\n",
       "  4943.0146484375,\n",
       "  4942.19873046875,\n",
       "  4941.9140625,\n",
       "  4940.99072265625,\n",
       "  4939.61669921875,\n",
       "  4938.349609375,\n",
       "  4937.71484375,\n",
       "  4935.6455078125,\n",
       "  4935.47412109375,\n",
       "  4933.818359375,\n",
       "  4932.6015625,\n",
       "  4931.669921875,\n",
       "  4930.75439453125,\n",
       "  4929.68994140625,\n",
       "  4929.3642578125,\n",
       "  4927.607421875,\n",
       "  4926.0751953125,\n",
       "  4925.34814453125,\n",
       "  4924.05322265625,\n",
       "  4923.30908203125,\n",
       "  4922.73486328125,\n",
       "  4922.1484375,\n",
       "  4920.53662109375,\n",
       "  4920.62548828125,\n",
       "  4918.3935546875,\n",
       "  4917.4072265625,\n",
       "  4921.04052734375,\n",
       "  4914.791015625,\n",
       "  4914.24609375,\n",
       "  4912.85693359375,\n",
       "  4911.107421875,\n",
       "  4911.40283203125,\n",
       "  4908.83251953125,\n",
       "  4907.93701171875,\n",
       "  4906.85302734375,\n",
       "  4905.5869140625,\n",
       "  4905.0400390625,\n",
       "  4904.01513671875,\n",
       "  4902.4921875,\n",
       "  4902.20166015625,\n",
       "  4900.67822265625,\n",
       "  4898.96826171875,\n",
       "  4898.58642578125,\n",
       "  4897.43798828125,\n",
       "  4896.34423828125,\n",
       "  4894.9775390625,\n",
       "  4896.04931640625,\n",
       "  4893.19384765625,\n",
       "  4892.1669921875,\n",
       "  4891.4111328125,\n",
       "  4891.1953125,\n",
       "  4888.9990234375,\n",
       "  4889.92431640625,\n",
       "  4887.13818359375,\n",
       "  4885.7861328125,\n",
       "  4884.9521484375,\n",
       "  4884.15576171875,\n",
       "  4884.27734375,\n",
       "  4881.796875,\n",
       "  4881.1025390625,\n",
       "  4879.7265625,\n",
       "  4878.8828125,\n",
       "  4879.40234375,\n",
       "  4877.966796875,\n",
       "  4876.31005859375,\n",
       "  4875.3427734375,\n",
       "  4874.78759765625,\n",
       "  4872.18359375,\n",
       "  4872.15625,\n",
       "  4870.4189453125,\n",
       "  4869.5302734375,\n",
       "  4869.0537109375,\n",
       "  4867.17919921875,\n",
       "  4866.5458984375,\n",
       "  4865.64111328125,\n",
       "  4864.89208984375,\n",
       "  4864.60888671875,\n",
       "  4862.20263671875,\n",
       "  4861.23095703125,\n",
       "  4860.36962890625,\n",
       "  4859.8447265625,\n",
       "  4858.083984375,\n",
       "  4856.99853515625,\n",
       "  4856.69140625,\n",
       "  4855.52392578125,\n",
       "  4854.7607421875,\n",
       "  4852.84423828125,\n",
       "  4852.6240234375,\n",
       "  4852.08740234375,\n",
       "  4852.33544921875,\n",
       "  4849.22998046875,\n",
       "  4848.7998046875,\n",
       "  4848.23779296875,\n",
       "  4846.1748046875,\n",
       "  4846.9326171875,\n",
       "  4845.2705078125,\n",
       "  4845.49755859375,\n",
       "  4842.02392578125,\n",
       "  4840.98291015625,\n",
       "  4841.66748046875,\n",
       "  4840.22802734375,\n",
       "  4838.623046875,\n",
       "  4838.9931640625,\n",
       "  4836.3505859375,\n",
       "  4834.9052734375,\n",
       "  4834.33837890625,\n",
       "  4832.96240234375,\n",
       "  4832.5185546875,\n",
       "  4830.97998046875,\n",
       "  4833.2109375,\n",
       "  4831.73828125,\n",
       "  4830.64013671875,\n",
       "  4828.3447265625,\n",
       "  4827.298828125,\n",
       "  4826.42333984375,\n",
       "  4825.0380859375,\n",
       "  4824.39501953125,\n",
       "  4824.8291015625,\n",
       "  4823.55419921875,\n",
       "  4823.0947265625,\n",
       "  4820.40625,\n",
       "  4821.3662109375,\n",
       "  4817.474609375,\n",
       "  4817.74072265625,\n",
       "  4818.02001953125,\n",
       "  4814.61279296875,\n",
       "  4813.47021484375,\n",
       "  4812.8544921875,\n",
       "  4812.68994140625,\n",
       "  4811.82763671875,\n",
       "  4812.29638671875,\n",
       "  4809.1689453125,\n",
       "  4808.5400390625,\n",
       "  4807.12109375,\n",
       "  4806.46630859375,\n",
       "  4807.978515625,\n",
       "  4804.01025390625,\n",
       "  4803.14013671875,\n",
       "  4803.19287109375,\n",
       "  4802.44970703125,\n",
       "  4801.76806640625,\n",
       "  4798.3837890625,\n",
       "  4798.953125,\n",
       "  4798.28125,\n",
       "  4798.00146484375,\n",
       "  4795.0517578125,\n",
       "  4794.45947265625,\n",
       "  4794.1650390625,\n",
       "  4794.0166015625,\n",
       "  4793.79443359375,\n",
       "  4791.21728515625,\n",
       "  4789.55419921875,\n",
       "  4788.80810546875,\n",
       "  4798.771484375,\n",
       "  4787.5888671875,\n",
       "  4789.03662109375,\n",
       "  4787.0498046875,\n",
       "  4784.65283203125,\n",
       "  4785.45068359375,\n",
       "  4782.39990234375,\n",
       "  4799.9638671875,\n",
       "  4797.15185546875,\n",
       "  4796.60205078125,\n",
       "  4794.79638671875,\n",
       "  4794.34716796875,\n",
       "  4793.650390625,\n",
       "  4792.98876953125,\n",
       "  4792.0478515625,\n",
       "  4790.9033203125,\n",
       "  4790.15576171875,\n",
       "  4788.97607421875,\n",
       "  4792.5908203125,\n",
       "  4788.1044921875,\n",
       "  4789.5732421875,\n",
       "  4785.513671875,\n",
       "  4784.560546875,\n",
       "  4783.439453125,\n",
       "  4782.88134765625,\n",
       "  4782.83056640625,\n",
       "  4782.36669921875,\n",
       "  4778.9560546875,\n",
       "  4780.06689453125,\n",
       "  4777.06298828125,\n",
       "  4776.93408203125,\n",
       "  4777.0986328125,\n",
       "  4776.81884765625,\n",
       "  4774.865234375,\n",
       "  4774.62451171875,\n",
       "  4774.6142578125,\n",
       "  4771.580078125,\n",
       "  4770.416015625,\n",
       "  4769.4912109375,\n",
       "  4768.38134765625,\n",
       "  4767.5947265625,\n",
       "  4766.6904296875,\n",
       "  4765.12744140625,\n",
       "  4764.98193359375,\n",
       "  4765.59033203125,\n",
       "  4762.9189453125,\n",
       "  4761.27490234375,\n",
       "  4760.99951171875,\n",
       "  4759.03857421875,\n",
       "  4758.1611328125,\n",
       "  4758.93505859375,\n",
       "  4756.77978515625,\n",
       "  4757.083984375,\n",
       "  4754.61572265625,\n",
       "  4756.64013671875,\n",
       "  4753.99853515625,\n",
       "  4752.7919921875,\n",
       "  4753.50634765625,\n",
       "  4751.0849609375,\n",
       "  4749.6826171875,\n",
       "  4750.46923828125,\n",
       "  4747.19287109375,\n",
       "  4748.74951171875,\n",
       "  4748.45654296875,\n",
       "  4746.77978515625,\n",
       "  4744.73046875,\n",
       "  4747.775390625,\n",
       "  4744.62158203125,\n",
       "  4745.0947265625,\n",
       "  4759.5126953125,\n",
       "  4758.64013671875,\n",
       "  4757.1103515625,\n",
       "  4756.45263671875,\n",
       "  4756.3046875,\n",
       "  4755.76123046875,\n",
       "  4753.93603515625,\n",
       "  4754.19140625,\n",
       "  4752.38525390625,\n",
       "  4750.3349609375,\n",
       "  4754.42431640625,\n",
       "  4749.2314453125,\n",
       "  4750.92138671875,\n",
       "  4747.53515625,\n",
       "  4747.05419921875,\n",
       "  4744.5859375,\n",
       "  4743.28173828125,\n",
       "  4743.74267578125,\n",
       "  4743.5693359375,\n",
       "  4741.03955078125,\n",
       "  4740.62451171875,\n",
       "  4741.18603515625,\n",
       "  4741.1357421875,\n",
       "  4741.02783203125,\n",
       "  4737.58203125,\n",
       "  4736.46435546875,\n",
       "  4735.78076171875,\n",
       "  4734.4951171875,\n",
       "  4733.45361328125,\n",
       "  4731.12841796875,\n",
       "  4733.48828125,\n",
       "  4730.87890625,\n",
       "  4731.55224609375,\n",
       "  4728.658203125,\n",
       "  4730.13916015625,\n",
       "  4726.0166015625,\n",
       "  4725.4296875,\n",
       "  4724.7060546875,\n",
       "  4724.0322265625,\n",
       "  4724.1845703125,\n",
       "  4721.0654296875,\n",
       "  4721.75830078125,\n",
       "  4719.5888671875,\n",
       "  4718.96728515625,\n",
       "  4718.68359375,\n",
       "  4717.92626953125,\n",
       "  4718.34423828125,\n",
       "  4717.4951171875,\n",
       "  4716.56689453125,\n",
       "  4719.2158203125,\n",
       "  4716.5849609375,\n",
       "  4731.3837890625,\n",
       "  4731.26611328125,\n",
       "  4730.814453125,\n",
       "  4729.1494140625,\n",
       "  4728.58984375,\n",
       "  4732.03955078125,\n",
       "  4726.69091796875,\n",
       "  4724.83642578125,\n",
       "  4724.8642578125,\n",
       "  4725.3662109375,\n",
       "  4723.6572265625,\n",
       "  4721.30615234375,\n",
       "  4720.6640625,\n",
       "  4719.900390625,\n",
       "  4720.60595703125,\n",
       "  4718.7724609375,\n",
       "  4717.05224609375,\n",
       "  4716.33251953125,\n",
       "  4715.62646484375,\n",
       "  4716.302734375,\n",
       "  4713.80322265625,\n",
       "  4711.845703125,\n",
       "  4711.67578125,\n",
       "  4712.51708984375,\n",
       "  4711.3037109375,\n",
       "  4708.6328125,\n",
       "  4708.86572265625,\n",
       "  4707.90966796875,\n",
       "  4705.9306640625,\n",
       "  4710.23291015625,\n",
       "  4703.90869140625,\n",
       "  4703.60986328125,\n",
       "  4702.5947265625,\n",
       "  4701.92431640625,\n",
       "  4700.6455078125,\n",
       "  4699.7392578125,\n",
       "  4698.044921875,\n",
       "  4714.74462890625,\n",
       "  4698.6240234375,\n",
       "  4700.12841796875,\n",
       "  4697.314453125,\n",
       "  4693.6337890625,\n",
       "  4695.09130859375,\n",
       "  4693.587890625,\n",
       "  4692.1474609375,\n",
       "  4692.560546875,\n",
       "  4689.7685546875,\n",
       "  4690.03857421875,\n",
       "  4690.3564453125,\n",
       "  4686.42431640625,\n",
       "  4685.7763671875,\n",
       "  4685.08056640625,\n",
       "  4686.11474609375,\n",
       "  4683.35595703125,\n",
       "  4682.5029296875,\n",
       "  4682.40625,\n",
       "  4682.00048828125,\n",
       "  4682.42236328125,\n",
       "  4679.58642578125,\n",
       "  4679.298828125,\n",
       "  4677.4658203125,\n",
       "  4675.8603515625,\n",
       "  4674.0478515625,\n",
       "  4675.0947265625,\n",
       "  4673.40234375,\n",
       "  4675.1591796875,\n",
       "  4672.0439453125,\n",
       "  4669.794921875,\n",
       "  4671.1591796875,\n",
       "  4668.75146484375,\n",
       "  4666.9052734375,\n",
       "  4668.60009765625,\n",
       "  4667.533203125,\n",
       "  4666.3408203125,\n",
       "  4665.93701171875,\n",
       "  4664.23291015625,\n",
       "  4662.71923828125,\n",
       "  4661.365234375,\n",
       "  4660.298828125,\n",
       "  4663.22265625,\n",
       "  4659.13818359375,\n",
       "  4657.40966796875,\n",
       "  4659.50341796875,\n",
       "  4658.49072265625,\n",
       "  4654.8798828125,\n",
       "  4655.0673828125,\n",
       "  4652.02880859375,\n",
       "  4652.81689453125,\n",
       "  4652.853515625,\n",
       "  4650.5986328125,\n",
       "  4651.01123046875,\n",
       "  4648.619140625,\n",
       "  4648.49169921875,\n",
       "  4648.0341796875,\n",
       "  4650.13720703125,\n",
       "  4645.72900390625,\n",
       "  4645.2529296875,\n",
       "  4644.58837890625,\n",
       "  4644.650390625,\n",
       "  4644.41162109375,\n",
       "  4641.43310546875,\n",
       "  4641.4248046875,\n",
       "  4640.92529296875,\n",
       "  4641.4384765625,\n",
       "  4639.328125,\n",
       "  4636.36474609375,\n",
       "  4635.76611328125,\n",
       "  4636.28564453125,\n",
       "  4634.11083984375,\n",
       "  4634.06396484375,\n",
       "  4646.1171875,\n",
       "  4642.849609375,\n",
       "  4643.669921875,\n",
       "  4642.2890625,\n",
       "  4644.203125,\n",
       "  4643.42236328125,\n",
       "  4638.6962890625,\n",
       "  4638.62353515625,\n",
       "  4636.35888671875,\n",
       "  4635.5966796875,\n",
       "  4634.693359375,\n",
       "  4634.3369140625,\n",
       "  4633.60400390625,\n",
       "  4632.38720703125,\n",
       "  4630.69482421875,\n",
       "  4631.61181640625,\n",
       "  4629.81005859375,\n",
       "  4636.0947265625,\n",
       "  4630.271484375,\n",
       "  4626.87353515625,\n",
       "  4626.29541015625,\n",
       "  4626.60546875,\n",
       "  4624.68359375,\n",
       "  4624.517578125,\n",
       "  4623.46484375,\n",
       "  4622.2880859375,\n",
       "  4621.82763671875,\n",
       "  4619.92529296875,\n",
       "  4619.8427734375,\n",
       "  4619.4248046875,\n",
       "  4616.99853515625,\n",
       "  4619.87060546875,\n",
       "  4616.67724609375,\n",
       "  4614.87890625,\n",
       "  4616.85498046875,\n",
       "  4617.31787109375,\n",
       "  4613.62109375,\n",
       "  4612.74609375,\n",
       "  4610.47216796875,\n",
       "  4614.0302734375,\n",
       "  4610.6796875,\n",
       "  4611.107421875,\n",
       "  4612.6630859375,\n",
       "  4606.3662109375,\n",
       "  4605.42431640625,\n",
       "  4605.68896484375,\n",
       "  4604.1953125,\n",
       "  4603.5751953125,\n",
       "  4608.4619140625,\n",
       "  4601.4169921875,\n",
       "  4601.8193359375,\n",
       "  4599.3544921875,\n",
       "  4597.63916015625,\n",
       "  4598.158203125,\n",
       "  4597.76708984375,\n",
       "  4595.931640625,\n",
       "  4595.787109375,\n",
       "  4594.5634765625,\n",
       "  4593.697265625,\n",
       "  4594.06494140625,\n",
       "  4592.4423828125,\n",
       "  4590.45166015625,\n",
       "  4590.58935546875,\n",
       "  4588.55419921875,\n",
       "  4588.00244140625,\n",
       "  4591.71484375,\n",
       "  4587.35400390625,\n",
       "  4588.27685546875,\n",
       "  4584.3603515625,\n",
       "  4586.14990234375,\n",
       "  4583.32568359375,\n",
       "  4581.89306640625,\n",
       "  4582.09130859375,\n",
       "  4582.32177734375,\n",
       "  4579.5693359375,\n",
       "  4578.3291015625,\n",
       "  4578.6025390625,\n",
       "  4578.63818359375,\n",
       "  4583.83251953125,\n",
       "  4579.158203125,\n",
       "  4577.60107421875,\n",
       "  4574.7109375,\n",
       "  4571.728515625,\n",
       "  4571.50537109375,\n",
       "  4571.71630859375,\n",
       "  4568.7998046875,\n",
       "  4570.66552734375,\n",
       "  4569.896484375,\n",
       "  4567.15673828125,\n",
       "  4570.4453125,\n",
       "  4566.39892578125,\n",
       "  4564.30078125,\n",
       "  4564.09912109375,\n",
       "  4562.6298828125,\n",
       "  4562.84130859375,\n",
       "  4561.109375,\n",
       "  4561.02783203125,\n",
       "  4560.61767578125,\n",
       "  4559.3642578125,\n",
       "  4559.6044921875,\n",
       "  4557.62841796875,\n",
       "  4562.02294921875,\n",
       "  4559.80810546875,\n",
       "  4556.146484375,\n",
       "  4553.75537109375,\n",
       "  4552.9677734375,\n",
       "  4552.2705078125,\n",
       "  4552.7119140625,\n",
       "  4553.0654296875,\n",
       "  4549.775390625,\n",
       "  4551.7197265625,\n",
       "  4548.2646484375,\n",
       "  4547.49365234375,\n",
       "  4546.27734375,\n",
       "  4544.53955078125,\n",
       "  4544.09130859375,\n",
       "  4544.6357421875,\n",
       "  4542.8642578125,\n",
       "  4541.85986328125,\n",
       "  4547.63134765625,\n",
       "  4541.1181640625,\n",
       "  4542.32373046875,\n",
       "  4538.8662109375,\n",
       "  4538.4853515625,\n",
       "  4537.25830078125,\n",
       "  4537.29345703125,\n",
       "  4536.7978515625,\n",
       "  4535.2939453125,\n",
       "  4538.1162109375,\n",
       "  4533.97412109375,\n",
       "  4532.25537109375,\n",
       "  4532.3984375,\n",
       "  4531.92822265625,\n",
       "  4528.75390625,\n",
       "  4528.29345703125,\n",
       "  4527.48291015625,\n",
       "  4529.07958984375,\n",
       "  4535.931640625,\n",
       "  4527.07275390625,\n",
       "  4525.8623046875,\n",
       "  4526.41552734375,\n",
       "  4528.34033203125,\n",
       "  4523.12744140625,\n",
       "  4521.30078125,\n",
       "  4519.201171875,\n",
       "  4518.37841796875,\n",
       "  4519.22021484375,\n",
       "  4519.6005859375,\n",
       "  4519.056640625,\n",
       "  4516.3525390625,\n",
       "  4518.3642578125,\n",
       "  4515.46240234375,\n",
       "  4513.27978515625,\n",
       "  4511.876953125,\n",
       "  4517.52783203125,\n",
       "  4512.47900390625,\n",
       "  4511.82470703125,\n",
       "  4510.5185546875,\n",
       "  4507.56396484375,\n",
       "  4507.46923828125,\n",
       "  4508.47705078125,\n",
       "  4507.40185546875,\n",
       "  4507.044921875,\n",
       "  4503.78369140625,\n",
       "  4505.09912109375,\n",
       "  4504.30224609375,\n",
       "  4503.93408203125,\n",
       "  4500.70361328125,\n",
       "  4499.85595703125,\n",
       "  4498.5849609375,\n",
       "  4498.265625,\n",
       "  4498.48046875,\n",
       "  4501.1318359375,\n",
       "  4498.21142578125,\n",
       "  4494.18310546875,\n",
       "  4495.38134765625,\n",
       "  4494.55859375,\n",
       "  4492.86083984375,\n",
       "  4493.1796875,\n",
       "  4492.33935546875,\n",
       "  4490.45703125,\n",
       "  4491.837890625,\n",
       "  4488.236328125,\n",
       "  4490.7041015625,\n",
       "  4487.54345703125,\n",
       "  4485.58740234375,\n",
       "  4484.1845703125,\n",
       "  4482.69677734375,\n",
       "  4483.50927734375,\n",
       "  4481.78173828125,\n",
       "  4481.15185546875,\n",
       "  4481.47119140625,\n",
       "  ...],\n",
       " [-0.21040821075439453,\n",
       "  -0.21013367176055908,\n",
       "  -0.20985889434814453,\n",
       "  -0.20958125591278076,\n",
       "  -0.20932400226593018,\n",
       "  -0.2090742588043213,\n",
       "  -0.20883512496948242,\n",
       "  -0.20857524871826172,\n",
       "  -0.20831704139709473,\n",
       "  -0.20805537700653076,\n",
       "  -0.20779645442962646,\n",
       "  -0.2075408697128296,\n",
       "  -0.2072892189025879,\n",
       "  -0.20704174041748047,\n",
       "  -0.20679306983947754,\n",
       "  -0.20654833316802979,\n",
       "  -0.20630085468292236,\n",
       "  -0.20605552196502686,\n",
       "  -0.20581114292144775,\n",
       "  -0.20557236671447754,\n",
       "  -0.20530402660369873,\n",
       "  -0.2050553560256958,\n",
       "  -0.20480573177337646,\n",
       "  -0.20454919338226318,\n",
       "  -0.20430278778076172,\n",
       "  -0.20405828952789307,\n",
       "  -0.20381224155426025,\n",
       "  -0.20357143878936768,\n",
       "  -0.20333003997802734,\n",
       "  -0.20308136940002441,\n",
       "  -0.2028406858444214,\n",
       "  -0.20259737968444824,\n",
       "  -0.2023540735244751,\n",
       "  -0.20211005210876465,\n",
       "  -0.20187056064605713,\n",
       "  -0.20162642002105713,\n",
       "  -0.20138680934906006,\n",
       "  -0.20114624500274658,\n",
       "  -0.20090055465698242,\n",
       "  -0.20066165924072266,\n",
       "  -0.20042061805725098,\n",
       "  -0.2001800537109375,\n",
       "  -0.19993793964385986,\n",
       "  -0.1997004747390747,\n",
       "  -0.19945979118347168,\n",
       "  -0.19922125339508057,\n",
       "  -0.19898200035095215,\n",
       "  -0.19874632358551025,\n",
       "  -0.1984996795654297,\n",
       "  -0.19826269149780273,\n",
       "  -0.19802415370941162,\n",
       "  -0.19778859615325928,\n",
       "  -0.1975466012954712,\n",
       "  -0.19730687141418457,\n",
       "  -0.19706809520721436,\n",
       "  -0.19682979583740234,\n",
       "  -0.19659018516540527,\n",
       "  -0.19635069370269775,\n",
       "  -0.19611215591430664,\n",
       "  -0.19587576389312744,\n",
       "  -0.1956310272216797,\n",
       "  -0.195395827293396,\n",
       "  -0.1951608657836914,\n",
       "  -0.1949169635772705,\n",
       "  -0.1946849822998047,\n",
       "  -0.19444537162780762,\n",
       "  -0.19420623779296875,\n",
       "  -0.19396579265594482,\n",
       "  -0.19372892379760742,\n",
       "  -0.19349539279937744,\n",
       "  -0.19325697422027588,\n",
       "  -0.19302070140838623,\n",
       "  -0.1927814483642578,\n",
       "  -0.1925410032272339,\n",
       "  -0.192305326461792,\n",
       "  -0.1920679807662964,\n",
       "  -0.19183337688446045,\n",
       "  -0.19159245491027832,\n",
       "  -0.1913607120513916,\n",
       "  -0.1911228895187378,\n",
       "  -0.19088363647460938,\n",
       "  -0.19064271450042725,\n",
       "  -0.190405011177063,\n",
       "  -0.1901698112487793,\n",
       "  -0.18993377685546875,\n",
       "  -0.18970012664794922,\n",
       "  -0.1894681453704834,\n",
       "  -0.18923044204711914,\n",
       "  -0.18899297714233398,\n",
       "  -0.18875956535339355,\n",
       "  -0.1885228157043457,\n",
       "  -0.18828260898590088,\n",
       "  -0.1880476474761963,\n",
       "  -0.18781137466430664,\n",
       "  -0.18757641315460205,\n",
       "  -0.1873394250869751,\n",
       "  -0.18710339069366455,\n",
       "  -0.18686926364898682,\n",
       "  -0.18663430213928223,\n",
       "  -0.18639981746673584,\n",
       "  -0.18616509437561035,\n",
       "  -0.18593251705169678,\n",
       "  -0.18569493293762207,\n",
       "  -0.18545806407928467,\n",
       "  -0.18522512912750244,\n",
       "  -0.1849905252456665,\n",
       "  -0.1847550868988037,\n",
       "  -0.18452465534210205,\n",
       "  -0.18428552150726318,\n",
       "  -0.1840522289276123,\n",
       "  -0.18381810188293457,\n",
       "  -0.1835852861404419,\n",
       "  -0.1833488941192627,\n",
       "  -0.1831148862838745,\n",
       "  -0.18288064002990723,\n",
       "  -0.18264400959014893,\n",
       "  -0.1824091672897339,\n",
       "  -0.1821737289428711,\n",
       "  -0.1819392442703247,\n",
       "  -0.18170440196990967,\n",
       "  -0.18147099018096924,\n",
       "  -0.18123984336853027,\n",
       "  -0.18100440502166748,\n",
       "  -0.18077027797698975,\n",
       "  -0.18053901195526123,\n",
       "  -0.1803051233291626,\n",
       "  -0.18007242679595947,\n",
       "  -0.17983543872833252,\n",
       "  -0.17959749698638916,\n",
       "  -0.179368257522583,\n",
       "  -0.1791325807571411,\n",
       "  -0.17889773845672607,\n",
       "  -0.17866945266723633,\n",
       "  -0.17843425273895264,\n",
       "  -0.1782015562057495,\n",
       "  -0.17796969413757324,\n",
       "  -0.17773222923278809,\n",
       "  -0.17750203609466553,\n",
       "  -0.1772681474685669,\n",
       "  -0.17703568935394287,\n",
       "  -0.17680084705352783,\n",
       "  -0.17657005786895752,\n",
       "  -0.17633724212646484,\n",
       "  -0.17610442638397217,\n",
       "  -0.17586886882781982,\n",
       "  -0.17563748359680176,\n",
       "  -0.17540228366851807,\n",
       "  -0.17516672611236572,\n",
       "  -0.17493700981140137,\n",
       "  -0.17470145225524902,\n",
       "  -0.17447352409362793,\n",
       "  -0.17424166202545166,\n",
       "  -0.17401039600372314,\n",
       "  -0.17377448081970215,\n",
       "  -0.17354333400726318,\n",
       "  -0.1733095645904541,\n",
       "  -0.17307662963867188,\n",
       "  -0.17284440994262695,\n",
       "  -0.17261004447937012,\n",
       "  -0.17237818241119385,\n",
       "  -0.17214953899383545,\n",
       "  -0.17191267013549805,\n",
       "  -0.17168498039245605,\n",
       "  -0.17145180702209473,\n",
       "  -0.1712198257446289,\n",
       "  -0.17104732990264893,\n",
       "  -0.17075765132904053,\n",
       "  -0.17052733898162842,\n",
       "  -0.17072522640228271,\n",
       "  -0.17006278038024902,\n",
       "  -0.16983342170715332,\n",
       "  -0.1696023941040039,\n",
       "  -0.16936826705932617,\n",
       "  -0.1691380739212036,\n",
       "  -0.1689072847366333,\n",
       "  -0.16867589950561523,\n",
       "  -0.1684490442276001,\n",
       "  -0.16821777820587158,\n",
       "  -0.16798579692840576,\n",
       "  -0.1677544116973877,\n",
       "  -0.16752445697784424,\n",
       "  -0.1672888994216919,\n",
       "  -0.16705989837646484,\n",
       "  -0.1668304204940796,\n",
       "  -0.16659843921661377,\n",
       "  -0.16636550426483154,\n",
       "  -0.1661365032196045,\n",
       "  -0.1659085750579834,\n",
       "  -0.16567790508270264,\n",
       "  -0.16544568538665771,\n",
       "  -0.1652141809463501,\n",
       "  -0.1649855375289917,\n",
       "  -0.16475152969360352,\n",
       "  -0.16452455520629883,\n",
       "  -0.16429424285888672,\n",
       "  -0.16406166553497314,\n",
       "  -0.1638280153274536,\n",
       "  -0.16360187530517578,\n",
       "  -0.16336941719055176,\n",
       "  -0.16313636302947998,\n",
       "  -0.16290616989135742,\n",
       "  -0.1626741886138916,\n",
       "  -0.1624464988708496,\n",
       "  -0.16221749782562256,\n",
       "  -0.16198885440826416,\n",
       "  -0.16175401210784912,\n",
       "  -0.16152191162109375,\n",
       "  -0.16129028797149658,\n",
       "  -0.16106557846069336,\n",
       "  -0.16083872318267822,\n",
       "  -0.16060912609100342,\n",
       "  -0.16038215160369873,\n",
       "  -0.16015183925628662,\n",
       "  -0.15991997718811035,\n",
       "  -0.1596909761428833,\n",
       "  -0.15946316719055176,\n",
       "  -0.1592351198196411,\n",
       "  -0.1590055227279663,\n",
       "  -0.15877795219421387,\n",
       "  -0.15854644775390625,\n",
       "  -0.1583157777786255,\n",
       "  -0.15808749198913574,\n",
       "  -0.15786147117614746,\n",
       "  -0.15763211250305176,\n",
       "  -0.15740549564361572,\n",
       "  -0.15717506408691406,\n",
       "  -0.15694987773895264,\n",
       "  -0.15671813488006592,\n",
       "  -0.15648722648620605,\n",
       "  -0.15626204013824463,\n",
       "  -0.15603315830230713,\n",
       "  -0.1558055877685547,\n",
       "  -0.15557897090911865,\n",
       "  -0.15534913539886475,\n",
       "  -0.15511822700500488,\n",
       "  -0.1548914909362793,\n",
       "  -0.15466129779815674,\n",
       "  -0.15443265438079834,\n",
       "  -0.15420830249786377,\n",
       "  -0.15397965908050537,\n",
       "  -0.15375089645385742,\n",
       "  -0.15352463722229004,\n",
       "  -0.1532973051071167,\n",
       "  -0.15307140350341797,\n",
       "  -0.15284037590026855,\n",
       "  -0.1526099443435669,\n",
       "  -0.15238416194915771,\n",
       "  -0.15215718746185303,\n",
       "  -0.151930570602417,\n",
       "  -0.15170776844024658,\n",
       "  -0.15147936344146729,\n",
       "  -0.15124869346618652,\n",
       "  -0.15102481842041016,\n",
       "  -0.1507970094680786,\n",
       "  -0.1505720615386963,\n",
       "  -0.15034699440002441,\n",
       "  -0.1501154899597168,\n",
       "  -0.1498938798904419,\n",
       "  -0.14966702461242676,\n",
       "  -0.14944052696228027,\n",
       "  -0.14921021461486816,\n",
       "  -0.14898681640625,\n",
       "  -0.14876103401184082,\n",
       "  -0.1485387086868286,\n",
       "  -0.14831054210662842,\n",
       "  -0.14808642864227295,\n",
       "  -0.14786100387573242,\n",
       "  -0.14763402938842773,\n",
       "  -0.14740562438964844,\n",
       "  -0.14717888832092285,\n",
       "  -0.14695203304290771,\n",
       "  -0.14672386646270752,\n",
       "  -0.1465013027191162,\n",
       "  -0.14627385139465332,\n",
       "  -0.14604830741882324,\n",
       "  -0.14582538604736328,\n",
       "  -0.1456007957458496,\n",
       "  -0.1453723907470703,\n",
       "  -0.14514625072479248,\n",
       "  -0.14492392539978027,\n",
       "  -0.14469575881958008,\n",
       "  -0.1444711685180664,\n",
       "  -0.14424824714660645,\n",
       "  -0.14402365684509277,\n",
       "  -0.1437983512878418,\n",
       "  -0.14357340335845947,\n",
       "  -0.14334607124328613,\n",
       "  -0.1431213617324829,\n",
       "  -0.1428971290588379,\n",
       "  -0.14267492294311523,\n",
       "  -0.14245116710662842,\n",
       "  -0.14222395420074463,\n",
       "  -0.1419968605041504,\n",
       "  -0.14177346229553223,\n",
       "  -0.1415492296218872,\n",
       "  -0.14132654666900635,\n",
       "  -0.14110374450683594,\n",
       "  -0.14087820053100586,\n",
       "  -0.14064836502075195,\n",
       "  -0.14042150974273682,\n",
       "  -0.1401968002319336,\n",
       "  -0.13997364044189453,\n",
       "  -0.13975191116333008,\n",
       "  -0.13952815532684326,\n",
       "  -0.13930225372314453,\n",
       "  -0.13907885551452637,\n",
       "  -0.13884973526000977,\n",
       "  -0.13862895965576172,\n",
       "  -0.13840413093566895,\n",
       "  -0.13925707340240479,\n",
       "  -0.13795053958892822,\n",
       "  -0.13773202896118164,\n",
       "  -0.1375112533569336,\n",
       "  -0.13728058338165283,\n",
       "  -0.13705682754516602,\n",
       "  -0.13683223724365234,\n",
       "  -0.13661062717437744,\n",
       "  -0.13638699054718018,\n",
       "  -0.13616681098937988,\n",
       "  -0.13594233989715576,\n",
       "  -0.13572049140930176,\n",
       "  -0.13549792766571045,\n",
       "  -0.1352766752243042,\n",
       "  -0.13505339622497559,\n",
       "  -0.13482928276062012,\n",
       "  -0.13460826873779297,\n",
       "  -0.13438546657562256,\n",
       "  -0.13416147232055664,\n",
       "  -0.13393914699554443,\n",
       "  -0.1337134838104248,\n",
       "  -0.13349080085754395,\n",
       "  -0.13327014446258545,\n",
       "  -0.13304543495178223,\n",
       "  -0.1328212022781372,\n",
       "  -0.13259649276733398,\n",
       "  -0.13237237930297852,\n",
       "  -0.13215136528015137,\n",
       "  -0.1319255828857422,\n",
       "  -0.13170230388641357,\n",
       "  -0.1314786672592163,\n",
       "  -0.13125646114349365,\n",
       "  -0.1310354471206665,\n",
       "  -0.13081693649291992,\n",
       "  -0.130590558052063,\n",
       "  -0.13036608695983887,\n",
       "  -0.13014280796051025,\n",
       "  -0.12992286682128906,\n",
       "  -0.12970590591430664,\n",
       "  -0.12947559356689453,\n",
       "  -0.12925755977630615,\n",
       "  -0.1290372610092163,\n",
       "  -0.12881290912628174,\n",
       "  -0.12859070301055908,\n",
       "  -0.1283702850341797,\n",
       "  -0.12814927101135254,\n",
       "  -0.1279313564300537,\n",
       "  -0.12770771980285645,\n",
       "  -0.1274867057800293,\n",
       "  -0.12726032733917236,\n",
       "  -0.1270430088043213,\n",
       "  -0.12682127952575684,\n",
       "  -0.12659978866577148,\n",
       "  -0.1263793706893921,\n",
       "  -0.12615478038787842,\n",
       "  -0.1259326934814453,\n",
       "  -0.1257169246673584,\n",
       "  -0.1254894733428955,\n",
       "  -0.12527120113372803,\n",
       "  -0.12504899501800537,\n",
       "  -0.12483084201812744,\n",
       "  -0.12460982799530029,\n",
       "  -0.12439560890197754,\n",
       "  -0.12416863441467285,\n",
       "  -0.12394905090332031,\n",
       "  -0.12372684478759766,\n",
       "  -0.12350380420684814,\n",
       "  -0.1232837438583374,\n",
       "  -0.12306427955627441,\n",
       "  -0.12284409999847412,\n",
       "  -0.12262356281280518,\n",
       "  -0.12240242958068848,\n",
       "  -0.12218403816223145,\n",
       "  -0.12196159362792969,\n",
       "  -0.12174129486083984,\n",
       "  -0.12152409553527832,\n",
       "  -0.12130403518676758,\n",
       "  -0.12108361721038818,\n",
       "  -0.12086892127990723,\n",
       "  -0.12065005302429199,\n",
       "  -0.12042891979217529,\n",
       "  -0.12021017074584961,\n",
       "  -0.11999022960662842,\n",
       "  -0.11976933479309082,\n",
       "  -0.11954927444458008,\n",
       "  -0.11933040618896484,\n",
       "  -0.11911261081695557,\n",
       "  -0.11889231204986572,\n",
       "  -0.11867320537567139,\n",
       "  -0.11845183372497559,\n",
       "  -0.11823022365570068,\n",
       "  -0.11801040172576904,\n",
       "  -0.11779415607452393,\n",
       "  -0.11757254600524902,\n",
       "  -0.1173548698425293,\n",
       "  -0.1171337366104126,\n",
       "  -0.11691498756408691,\n",
       "  -0.11669528484344482,\n",
       "  -0.11647701263427734,\n",
       "  -0.11625790596008301,\n",
       "  -0.11604130268096924,\n",
       "  -0.1158210039138794,\n",
       "  -0.1156001091003418,\n",
       "  -0.11538910865783691,\n",
       "  -0.1151653528213501,\n",
       "  -0.11494910717010498,\n",
       "  -0.11473143100738525,\n",
       "  -0.11451756954193115,\n",
       "  -0.11429357528686523,\n",
       "  -0.11407625675201416,\n",
       "  -0.11386120319366455,\n",
       "  -0.11364197731018066,\n",
       "  -0.11342394351959229,\n",
       "  -0.11320745944976807,\n",
       "  -0.11298918724060059,\n",
       "  -0.1127697229385376,\n",
       "  -0.11255133152008057,\n",
       "  -0.11233341693878174,\n",
       "  -0.11211574077606201,\n",
       "  -0.11189854145050049,\n",
       "  -0.11168098449707031,\n",
       "  -0.1114654541015625,\n",
       "  -0.11124575138092041,\n",
       "  -0.11102962493896484,\n",
       "  -0.11081242561340332,\n",
       "  -0.11059677600860596,\n",
       "  -0.11037874221801758,\n",
       "  -0.11016058921813965,\n",
       "  -0.10994231700897217,\n",
       "  -0.10972774028778076,\n",
       "  -0.10951316356658936,\n",
       "  -0.10929524898529053,\n",
       "  -0.10907542705535889,\n",
       "  -0.10886073112487793,\n",
       "  -0.1086435317993164,\n",
       "  -0.10842621326446533,\n",
       "  -0.10820996761322021,\n",
       "  -0.10798978805541992,\n",
       "  -0.10777080059051514,\n",
       "  -0.10756170749664307,\n",
       "  -0.1073371171951294,\n",
       "  -0.10712230205535889,\n",
       "  -0.10692942142486572,\n",
       "  -0.10668838024139404,\n",
       "  -0.10647344589233398,\n",
       "  -0.10625481605529785,\n",
       "  -0.10604047775268555,\n",
       "  -0.10582363605499268,\n",
       "  -0.10560381412506104,\n",
       "  -0.10538876056671143,\n",
       "  -0.10516881942749023,\n",
       "  -0.10495734214782715,\n",
       "  -0.1047365665435791,\n",
       "  -0.10452115535736084,\n",
       "  -0.10430383682250977,\n",
       "  -0.10409009456634521,\n",
       "  -0.10386908054351807,\n",
       "  -0.1036534309387207,\n",
       "  -0.1034398078918457,\n",
       "  -0.10322487354278564,\n",
       "  -0.10300683975219727,\n",
       "  -0.10279130935668945,\n",
       "  -0.10257697105407715,\n",
       "  -0.10235965251922607,\n",
       "  -0.10214364528656006,\n",
       "  -0.1019282341003418,\n",
       "  -0.10171473026275635,\n",
       "  -0.10149633884429932,\n",
       "  -0.10127997398376465,\n",
       "  -0.10106074810028076,\n",
       "  -0.10084915161132812,\n",
       "  -0.10062682628631592,\n",
       "  -0.10041069984436035,\n",
       "  -0.100197434425354,\n",
       "  -0.09998023509979248,\n",
       "  -0.09976494312286377,\n",
       "  -0.09954512119293213,\n",
       "  -0.09933078289031982,\n",
       "  -0.09911942481994629,\n",
       "  -0.09890580177307129,\n",
       "  -0.09868693351745605,\n",
       "  -0.09847307205200195,\n",
       "  -0.09825491905212402,\n",
       "  -0.0980379581451416,\n",
       "  -0.09782803058624268,\n",
       "  -0.09760916233062744,\n",
       "  -0.0973961353302002,\n",
       "  -0.09717953205108643,\n",
       "  -0.09696400165557861,\n",
       "  -0.09675395488739014,\n",
       "  -0.09653747081756592,\n",
       "  -0.09632587432861328,\n",
       "  -0.09611272811889648,\n",
       "  -0.09589266777038574,\n",
       "  -0.095680832862854,\n",
       "  -0.09547114372253418,\n",
       "  -0.09525227546691895,\n",
       "  -0.09503769874572754,\n",
       "  -0.09482407569885254,\n",
       "  -0.09460973739624023,\n",
       "  -0.09439408779144287,\n",
       "  -0.09418010711669922,\n",
       "  -0.09396648406982422,\n",
       "  -0.09375488758087158,\n",
       "  -0.09353876113891602,\n",
       "  -0.09332942962646484,\n",
       "  -0.09311389923095703,\n",
       "  -0.09289658069610596,\n",
       "  -0.09268426895141602,\n",
       "  -0.09247136116027832,\n",
       "  -0.09226024150848389,\n",
       "  -0.09204137325286865,\n",
       "  -0.09183073043823242,\n",
       "  -0.09161293506622314,\n",
       "  -0.0913994312286377,\n",
       "  -0.09118711948394775,\n",
       "  -0.09097170829772949,\n",
       "  -0.09075987339019775,\n",
       "  -0.09055089950561523,\n",
       "  -0.09033536911010742,\n",
       "  -0.09012007713317871,\n",
       "  -0.08990919589996338,\n",
       "  -0.08969521522521973,\n",
       "  -0.0894775390625,\n",
       "  -0.08926403522491455,\n",
       "  -0.08905601501464844,\n",
       "  -0.08883750438690186,\n",
       "  -0.0886235237121582,\n",
       "  -0.08841097354888916,\n",
       "  -0.08819854259490967,\n",
       "  -0.08798778057098389,\n",
       "  -0.08777272701263428,\n",
       "  -0.08756136894226074,\n",
       "  -0.08734691143035889,\n",
       "  -0.08713924884796143,\n",
       "  -0.08692896366119385,\n",
       "  -0.08671224117279053,\n",
       "  -0.08650362491607666,\n",
       "  -0.08628785610198975,\n",
       "  -0.08607637882232666,\n",
       "  -0.08587014675140381,\n",
       "  -0.08565282821655273,\n",
       "  -0.0854339599609375,\n",
       "  -0.0852210521697998,\n",
       "  -0.08500730991363525,\n",
       "  -0.08479487895965576,\n",
       "  -0.08458483219146729,\n",
       "  -0.0843660831451416,\n",
       "  -0.08415842056274414,\n",
       "  -0.08394718170166016,\n",
       "  -0.08373475074768066,\n",
       "  -0.08352887630462646,\n",
       "  -0.08331298828125,\n",
       "  -0.08310067653656006,\n",
       "  -0.08289170265197754,\n",
       "  -0.08267927169799805,\n",
       "  -0.08246922492980957,\n",
       "  -0.08225524425506592,\n",
       "  -0.08204662799835205,\n",
       "  -0.08183670043945312,\n",
       "  -0.0816267728805542,\n",
       "  -0.08141028881072998,\n",
       "  -0.08120107650756836,\n",
       "  -0.08098983764648438,\n",
       "  -0.08078646659851074,\n",
       "  -0.08057689666748047,\n",
       "  -0.08035719394683838,\n",
       "  -0.08014452457427979,\n",
       "  -0.0799335241317749,\n",
       "  -0.08152234554290771,\n",
       "  -0.07951414585113525,\n",
       "  -0.07930946350097656,\n",
       "  -0.07909393310546875,\n",
       "  -0.0788799524307251,\n",
       "  -0.07867372035980225,\n",
       "  -0.07846009731292725,\n",
       "  -0.08204972743988037,\n",
       "  -0.08183801174163818,\n",
       "  -0.08163082599639893,\n",
       "  -0.08141398429870605,\n",
       "  -0.08120393753051758,\n",
       "  -0.0809926986694336,\n",
       "  -0.08078813552856445,\n",
       "  -0.08057200908660889,\n",
       "  -0.0803598165512085,\n",
       "  -0.08014905452728271,\n",
       "  -0.07993721961975098,\n",
       "  -0.07973003387451172,\n",
       "  -0.07951319217681885,\n",
       "  -0.07930612564086914,\n",
       "  -0.07909190654754639,\n",
       "  -0.07888293266296387,\n",
       "  -0.07867145538330078,\n",
       "  -0.07845687866210938,\n",
       "  -0.07825362682342529,\n",
       "  -0.07803535461425781,\n",
       "  -0.0778193473815918,\n",
       "  -0.07760858535766602,\n",
       "  -0.07739818096160889,\n",
       "  -0.07718765735626221,\n",
       "  -0.07697618007659912,\n",
       "  -0.07677078247070312,\n",
       "  -0.0765538215637207,\n",
       "  -0.07634270191192627,\n",
       "  -0.07613742351531982,\n",
       "  -0.07592320442199707,\n",
       "  -0.0757150650024414,\n",
       "  -0.07550263404846191,\n",
       "  -0.07529520988464355,\n",
       "  -0.07508730888366699,\n",
       "  -0.07487475872039795,\n",
       "  -0.07466280460357666,\n",
       "  -0.0744560956954956,\n",
       "  -0.07425570487976074,\n",
       "  -0.07403504848480225,\n",
       "  -0.07382619380950928,\n",
       "  -0.07361817359924316,\n",
       "  -0.07340526580810547,\n",
       "  -0.07319760322570801,\n",
       "  -0.07299411296844482,\n",
       "  -0.07278084754943848,\n",
       "  -0.07257330417633057,\n",
       "  -0.07236063480377197,\n",
       "  -0.07215774059295654,\n",
       "  -0.07194483280181885,\n",
       "  -0.07173621654510498,\n",
       "  -0.07152950763702393,\n",
       "  -0.07131683826446533,\n",
       "  -0.07110333442687988,\n",
       "  -0.07090044021606445,\n",
       "  -0.07069146633148193,\n",
       "  -0.07048428058624268,\n",
       "  -0.07027900218963623,\n",
       "  -0.07006633281707764,\n",
       "  -0.06985795497894287,\n",
       "  -0.06965756416320801,\n",
       "  -0.0694425106048584,\n",
       "  -0.06938636302947998,\n",
       "  -0.07320475578308105,\n",
       "  -0.07299613952636719,\n",
       "  -0.07278680801391602,\n",
       "  -0.07257342338562012,\n",
       "  -0.072365403175354,\n",
       "  -0.0721585750579834,\n",
       "  -0.07194983959197998,\n",
       "  -0.0717393159866333,\n",
       "  -0.07152688503265381,\n",
       "  -0.0713198184967041,\n",
       "  -0.07111537456512451,\n",
       "  -0.07089769840240479,\n",
       "  -0.0706942081451416,\n",
       "  -0.07048118114471436,\n",
       "  -0.07027244567871094,\n",
       "  -0.07005953788757324,\n",
       "  -0.06985509395599365,\n",
       "  -0.06964421272277832,\n",
       "  -0.06943833827972412,\n",
       "  -0.06922435760498047,\n",
       "  -0.06901681423187256,\n",
       "  -0.06882035732269287,\n",
       "  -0.06859886646270752,\n",
       "  -0.06839478015899658,\n",
       "  -0.06817889213562012,\n",
       "  -0.06796824932098389,\n",
       "  -0.06775820255279541,\n",
       "  -0.0675511360168457,\n",
       "  -0.06734013557434082,\n",
       "  -0.06713175773620605,\n",
       "  -0.06692743301391602,\n",
       "  -0.06672263145446777,\n",
       "  -0.0665132999420166,\n",
       "  -0.06630146503448486,\n",
       "  -0.06609892845153809,\n",
       "  -0.06588459014892578,\n",
       "  -0.06567895412445068,\n",
       "  -0.06547045707702637,\n",
       "  -0.0652623176574707,\n",
       "  -0.06505203247070312,\n",
       "  -0.06484413146972656,\n",
       "  -0.06463944911956787,\n",
       "  -0.06443166732788086,\n",
       "  -0.06422483921051025,\n",
       "  -0.06401586532592773,\n",
       "  -0.06380617618560791,\n",
       "  -0.06359827518463135,\n",
       "  -0.06339073181152344,\n",
       "  -0.06318628787994385,\n",
       "  -0.06297838687896729,\n",
       "  -0.06277287006378174,\n",
       "  -0.06703853607177734,\n",
       "  -0.06683123111724854,\n",
       "  -0.06662511825561523,\n",
       "  -0.06641030311584473,\n",
       "  -0.06620478630065918,\n",
       "  -0.06600630283355713,\n",
       "  -0.06578755378723145,\n",
       "  -0.06557631492614746,\n",
       "  -0.0653696060180664,\n",
       "  -0.06516540050506592,\n",
       "  -0.06495058536529541,\n",
       "  -0.06474554538726807,\n",
       "  -0.06453585624694824,\n",
       "  -0.06432974338531494,\n",
       "  -0.0641258955001831,\n",
       "  -0.06391692161560059,\n",
       "  -0.06370747089385986,\n",
       "  -0.0634995698928833,\n",
       "  -0.06329381465911865,\n",
       "  -0.06308901309967041,\n",
       "  -0.06287813186645508,\n",
       "  -0.06266391277313232,\n",
       "  -0.06246292591094971,\n",
       "  -0.06225788593292236,\n",
       "  -0.062045931816101074,\n",
       "  -0.061835646629333496,\n",
       "  -0.06163287162780762,\n",
       "  -0.061423659324645996,\n",
       "  -0.06121551990509033,\n",
       "  -0.06101858615875244,\n",
       "  -0.06080269813537598,\n",
       "  -0.060593366622924805,\n",
       "  -0.0603863000869751,\n",
       "  -0.06017899513244629,\n",
       "  -0.05997300148010254,\n",
       "  -0.059763431549072266,\n",
       "  -0.05955767631530762,\n",
       "  -0.061742186546325684,\n",
       "  -0.05914425849914551,\n",
       "  -0.05894148349761963,\n",
       "  -0.05872750282287598,\n",
       "  -0.05851399898529053,\n",
       "  -0.05831551551818848,\n",
       "  -0.05810666084289551,\n",
       "  -0.05789792537689209,\n",
       "  -0.0576937198638916,\n",
       "  -0.057482004165649414,\n",
       "  -0.057274580001831055,\n",
       "  -0.05707263946533203,\n",
       "  -0.05685997009277344,\n",
       "  -0.0566556453704834,\n",
       "  -0.056449174880981445,\n",
       "  -0.05624687671661377,\n",
       "  -0.056037068367004395,\n",
       "  -0.05583000183105469,\n",
       "  -0.05562877655029297,\n",
       "  -0.05542182922363281,\n",
       "  -0.055220842361450195,\n",
       "  -0.05500686168670654,\n",
       "  -0.05480539798736572,\n",
       "  -0.05459487438201904,\n",
       "  -0.05439114570617676,\n",
       "  -0.0541839599609375,\n",
       "  -0.05397987365722656,\n",
       "  -0.053774118423461914,\n",
       "  -0.05357539653778076,\n",
       "  -0.0533674955368042,\n",
       "  -0.053162455558776855,\n",
       "  -0.05295610427856445,\n",
       "  -0.052748680114746094,\n",
       "  -0.052539706230163574,\n",
       "  -0.05233967304229736,\n",
       "  -0.05213463306427002,\n",
       "  -0.05192923545837402,\n",
       "  -0.05172586441040039,\n",
       "  -0.05151724815368652,\n",
       "  -0.05131542682647705,\n",
       "  -0.05110609531402588,\n",
       "  -0.0509028434753418,\n",
       "  -0.05070233345031738,\n",
       "  -0.05049479007720947,\n",
       "  -0.0502854585647583,\n",
       "  -0.05008590221405029,\n",
       "  -0.049878597259521484,\n",
       "  -0.04967021942138672,\n",
       "  -0.04946780204772949,\n",
       "  -0.04925739765167236,\n",
       "  -0.04905867576599121,\n",
       "  -0.04885411262512207,\n",
       "  -0.048651695251464844,\n",
       "  -0.04844844341278076,\n",
       "  -0.04823923110961914,\n",
       "  -0.048037052154541016,\n",
       "  -0.047838568687438965,\n",
       "  -0.047634005546569824,\n",
       "  -0.04742145538330078,\n",
       "  -0.04721951484680176,\n",
       "  -0.047013282775878906,\n",
       "  -0.046810030937194824,\n",
       "  -0.0466080904006958,\n",
       "  -0.046398043632507324,\n",
       "  -0.04620075225830078,\n",
       "  -0.04599595069885254,\n",
       "  -0.04579746723175049,\n",
       "  -0.045590758323669434,\n",
       "  -0.04538404941558838,\n",
       "  -0.04518020153045654,\n",
       "  -0.04497957229614258,\n",
       "  -0.04477059841156006,\n",
       "  -0.04456758499145508,\n",
       "  -0.04692041873931885,\n",
       "  -0.046715378761291504,\n",
       "  -0.04651975631713867,\n",
       "  -0.04631388187408447,\n",
       "  -0.04613912105560303,\n",
       "  -0.04591214656829834,\n",
       "  -0.045708656311035156,\n",
       "  -0.04551124572753906,\n",
       "  -0.04530298709869385,\n",
       "  -0.04510343074798584,\n",
       "  -0.04490172863006592,\n",
       "  -0.04469895362854004,\n",
       "  -0.044496893882751465,\n",
       "  -0.04430198669433594,\n",
       "  -0.04409492015838623,\n",
       "  -0.043897151947021484,\n",
       "  -0.04369652271270752,\n",
       "  -0.04351174831390381,\n",
       "  -0.04329633712768555,\n",
       "  -0.04309678077697754,\n",
       "  -0.0428926944732666,\n",
       "  -0.04269230365753174,\n",
       "  -0.04249382019042969,\n",
       "  -0.04229378700256348,\n",
       "  -0.04209280014038086,\n",
       "  -0.04189348220825195,\n",
       "  -0.0416945219039917,\n",
       "  -0.04149198532104492,\n",
       "  -0.041295766830444336,\n",
       "  -0.04109227657318115,\n",
       "  -0.04089200496673584,\n",
       "  -0.04070091247558594,\n",
       "  -0.04049050807952881,\n",
       "  -0.04029059410095215,\n",
       "  -0.04009568691253662,\n",
       "  -0.03991079330444336,\n",
       "  -0.039690256118774414,\n",
       "  -0.03948807716369629,\n",
       "  -0.0392841100692749,\n",
       "  -0.03911280632019043,\n",
       "  -0.03889453411102295,\n",
       "  -0.03869223594665527,\n",
       "  -0.03850066661834717,\n",
       "  -0.03829085826873779,\n",
       "  -0.038089632987976074,\n",
       "  -0.03790390491485596,\n",
       "  -0.03768754005432129,\n",
       "  -0.03748965263366699,\n",
       "  -0.03730201721191406,\n",
       "  -0.03709113597869873,\n",
       "  -0.03689301013946533,\n",
       "  -0.036690354347229004,\n",
       "  -0.03649306297302246,\n",
       "  -0.03629457950592041,\n",
       "  -0.036096930503845215,\n",
       "  -0.03589272499084473,\n",
       "  -0.03569459915161133,\n",
       "  -0.03549063205718994,\n",
       "  -0.03529226779937744,\n",
       "  -0.03509259223937988,\n",
       "  -0.03491330146789551,\n",
       "  -0.03469586372375488,\n",
       "  -0.03449726104736328,\n",
       "  -0.03429698944091797,\n",
       "  -0.034101009368896484,\n",
       "  -0.03391385078430176,\n",
       "  -0.03370392322540283,\n",
       "  -0.03350543975830078,\n",
       "  -0.03330099582672119,\n",
       "  -0.03311753273010254,\n",
       "  -0.03290665149688721,\n",
       "  -0.032709598541259766,\n",
       "  -0.03251290321350098,\n",
       "  -0.03231704235076904,\n",
       "  -0.03211855888366699,\n",
       "  -0.031920552253723145,\n",
       "  -0.031722068786621094,\n",
       "  -0.03152632713317871,\n",
       "  -0.03139698505401611,\n",
       "  -0.03113555908203125,\n",
       "  -0.030936717987060547,\n",
       "  -0.030735373497009277,\n",
       "  -0.0305328369140625,\n",
       "  -0.030330300331115723,\n",
       "  -0.030142664909362793,\n",
       "  -0.02993953227996826,\n",
       "  -0.029745101928710938,\n",
       "  -0.02954566478729248,\n",
       "  -0.029351234436035156,\n",
       "  -0.029160737991333008,\n",
       "  -0.02895534038543701,\n",
       "  -0.028752565383911133,\n",
       "  -0.028555750846862793,\n",
       "  -0.028357744216918945,\n",
       "  -0.028162837028503418,\n",
       "  -0.02796471118927002,\n",
       "  -0.027771592140197754,\n",
       "  -0.027575135231018066,\n",
       "  -0.02737581729888916,\n",
       "  -0.027174711227416992,\n",
       "  -0.02697932720184326,\n",
       "  -0.026790142059326172,\n",
       "  -0.02659142017364502,\n",
       "  -0.026384711265563965,\n",
       "  -0.026186585426330566,\n",
       "  -0.025990962982177734,\n",
       "  -0.02579331398010254,\n",
       "  -0.025601506233215332,\n",
       "  -0.025407075881958008,\n",
       "  -0.02520430088043213,\n",
       "  -0.025013446807861328,\n",
       "  -0.024810194969177246,\n",
       "  -0.024610400199890137,\n",
       "  -0.024415135383605957,\n",
       "  -0.02421581745147705,\n",
       "  -0.024022698402404785,\n",
       "  -0.023826241493225098,\n",
       "  -0.023633241653442383,\n",
       "  -0.02343606948852539,\n",
       "  -0.023251891136169434,\n",
       "  -0.023047327995300293,\n",
       "  -0.022853851318359375,\n",
       "  -0.02265346050262451,\n",
       "  -0.022458314895629883,\n",
       "  -0.02226126194000244,\n",
       "  -0.022068381309509277,\n",
       "  -0.02187526226043701,\n",
       "  -0.021676063537597656,\n",
       "  -0.021484732627868652,\n",
       "  -0.02128136157989502,\n",
       "  -0.021080613136291504,\n",
       "  -0.020887136459350586,\n",
       "  -0.02069222927093506,\n",
       "  -0.02049100399017334,\n",
       "  -0.0202944278717041,\n",
       "  -0.02009749412536621,\n",
       "  -0.019904494285583496,\n",
       "  -0.01972639560699463,\n",
       "  -0.01951003074645996,\n",
       "  -0.01931619644165039,\n",
       "  -0.019123435020446777,\n",
       "  -0.01893627643585205,\n",
       "  -0.018722057342529297,\n",
       "  -0.018528103828430176,\n",
       "  -0.018329739570617676,\n",
       "  -0.0181351900100708,\n",
       "  -0.01794135570526123,\n",
       "  -0.01774919033050537,\n",
       "  -0.017554759979248047,\n",
       "  -0.017360210418701172,\n",
       "  -0.01718425750732422,\n",
       "  -0.016965150833129883,\n",
       "  -0.0167696475982666,\n",
       "  -0.016571640968322754,\n",
       "  -0.016441941261291504,\n",
       "  -0.016183972358703613,\n",
       "  -0.015988707542419434,\n",
       "  -0.015795111656188965,\n",
       "  -0.015592813491821289,\n",
       "  -0.01539909839630127,\n",
       "  -0.015213251113891602,\n",
       "  -0.015013813972473145,\n",
       "  -0.014819741249084473,\n",
       "  -0.01461946964263916,\n",
       "  -0.014429926872253418,\n",
       "  -0.014229416847229004,\n",
       "  -0.014050483703613281,\n",
       "  -0.013836503028869629,\n",
       "  -0.013645648956298828,\n",
       "  -0.0134507417678833,\n",
       "  -0.013258934020996094,\n",
       "  -0.013072848320007324,\n",
       "  -0.012881875038146973,\n",
       "  -0.012680292129516602,\n",
       "  -0.012480974197387695,\n",
       "  -0.012303709983825684,\n",
       "  -0.012092828750610352,\n",
       "  -0.011896967887878418,\n",
       "  -0.011708974838256836,\n",
       "  -0.011508941650390625,\n",
       "  -0.01131594181060791,\n",
       "  -0.01112353801727295,\n",
       "  -0.010924816131591797,\n",
       "  -0.010792374610900879,\n",
       "  -0.010538816452026367,\n",
       "  -0.010339021682739258,\n",
       "  -0.010142683982849121,\n",
       "  -0.009948134422302246,\n",
       "  -0.009758830070495605,\n",
       "  -0.009558320045471191,\n",
       "  -0.009367704391479492,\n",
       "  -0.009169220924377441,\n",
       "  ...])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.001 # standard for Adam\n",
    "num_epochs = 5000\n",
    "save_interval = num_epochs // 10\n",
    "\n",
    "model = CryptoGRU(input_size=4, embed_dim=4, hidden_size=64, num_layers=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "training_loss_history, validation_loss_history, mae_history, r2_history = train_model(\n",
    "    model, optimizer, train_loader, val_loader,\n",
    "    num_epochs=num_epochs, save_interval=save_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Training\n",
    "Training can be resumed by loading model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model parameters\n",
    "model_save_path = \"saved_models/CryptoGRU_2025-03-16_20-57-42/CryptoGRU_BEST_R2.pth\"\n",
    "model = CryptoGRU(input_size=4, embed_dim=4, hidden_size=64, num_layers=1)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "training_loss_history, validation_loss_history, mae_history, r2_history = train_model(\n",
    "    model, optimizer, train_loader, val_loader,\n",
    "    num_epochs=num_epochs, save_interval=save_interval\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "term6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
